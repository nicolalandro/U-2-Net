nohup: ignoring input
---
train images:  187
---
---define optimizer...
---start training...
/usr/local/lib/python3.7/dist-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.
  from .collection import imread_collection_wrapper
/home/supreme/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
l0: 0.853018, l1: 0.850619, l2: 0.548027, l3: 0.674108, l4: 0.511948, l5: 0.752989, l6: 0.708966

[epoch:   1/100000, batch:     2/  187, ite: 1] train loss: 4.899674, tar: 0.853018 
l0: 1.330016, l1: 0.643667, l2: 0.403932, l3: 0.386138, l4: 0.244791, l5: 0.218583, l6: 0.202633

[epoch:   1/100000, batch:     4/  187, ite: 2] train loss: 4.164717, tar: 1.091517 
l0: 1.447219, l1: 0.420133, l2: 0.411836, l3: 0.516418, l4: 0.450571, l5: 0.231185, l6: 0.231316

[epoch:   1/100000, batch:     6/  187, ite: 3] train loss: 4.012704, tar: 1.210084 
l0: 1.269310, l1: 0.347392, l2: 0.383765, l3: 0.344192, l4: 0.420504, l5: 0.446155, l6: 0.454653

[epoch:   1/100000, batch:     8/  187, ite: 4] train loss: 3.926021, tar: 1.224890 
l0: 1.298982, l1: 0.218398, l2: 0.310971, l3: 0.147636, l4: 0.224800, l5: 0.129479, l6: 0.145801

[epoch:   1/100000, batch:    10/  187, ite: 5] train loss: 3.636030, tar: 1.239709 
l0: 0.927834, l1: 0.175418, l2: 0.359928, l3: 0.143886, l4: 0.335128, l5: 0.087834, l6: 0.107665

[epoch:   1/100000, batch:    12/  187, ite: 6] train loss: 3.386307, tar: 1.187730 
l0: 0.794478, l1: 0.222029, l2: 0.399232, l3: 0.211193, l4: 0.357515, l5: 0.342233, l6: 0.255450

[epoch:   1/100000, batch:    14/  187, ite: 7] train loss: 3.271425, tar: 1.131551 
l0: 0.687288, l1: 0.209772, l2: 0.386494, l3: 0.206460, l4: 0.385529, l5: 0.472865, l6: 0.318106

[epoch:   1/100000, batch:    16/  187, ite: 8] train loss: 3.195811, tar: 1.076018 
l0: 0.622276, l1: 0.302303, l2: 0.387773, l3: 0.326199, l4: 0.442390, l5: 0.876021, l6: 0.434821

[epoch:   1/100000, batch:    18/  187, ite: 9] train loss: 3.217586, tar: 1.025602 
l0: 0.626027, l1: 0.216363, l2: 0.334291, l3: 0.208777, l4: 0.399786, l5: 0.406959, l6: 0.300303

[epoch:   1/100000, batch:    20/  187, ite: 10] train loss: 3.145078, tar: 0.985645 
l0: 0.572329, l1: 0.154666, l2: 0.323917, l3: 0.288886, l4: 0.332556, l5: 0.990108, l6: 0.276894

[epoch:   1/100000, batch:    22/  187, ite: 11] train loss: 3.126376, tar: 0.948071 
l0: 0.516305, l1: 0.257463, l2: 0.320085, l3: 0.242239, l4: 0.393877, l5: 0.317221, l6: 0.237053

[epoch:   1/100000, batch:    24/  187, ite: 12] train loss: 3.056198, tar: 0.912090 
l0: 0.548790, l1: 0.179791, l2: 0.279758, l3: 0.186974, l4: 0.268526, l5: 0.146642, l6: 0.142572

[epoch:   1/100000, batch:    26/  187, ite: 13] train loss: 2.955956, tar: 0.884144 
l0: 0.546928, l1: 0.126027, l2: 0.227363, l3: 0.143226, l4: 0.234939, l5: 0.122106, l6: 0.185368

[epoch:   1/100000, batch:    28/  187, ite: 14] train loss: 2.858099, tar: 0.860057 
l0: 0.645849, l1: 0.213425, l2: 0.234230, l3: 0.206863, l4: 0.228262, l5: 0.729330, l6: 0.213653

[epoch:   1/100000, batch:    30/  187, ite: 15] train loss: 2.832333, tar: 0.845777 
l0: 0.525014, l1: 0.131049, l2: 0.205151, l3: 0.134243, l4: 0.188722, l5: 0.116063, l6: 0.130105

[epoch:   1/100000, batch:    32/  187, ite: 16] train loss: 2.744709, tar: 0.825729 
l0: 0.525958, l1: 0.085900, l2: 0.187952, l3: 0.102037, l4: 0.128907, l5: 0.122543, l6: 0.083836

[epoch:   1/100000, batch:    34/  187, ite: 17] train loss: 2.656029, tar: 0.808095 
l0: 0.510228, l1: 0.127125, l2: 0.196347, l3: 0.109434, l4: 0.143531, l5: 0.110330, l6: 0.108104

[epoch:   1/100000, batch:    36/  187, ite: 18] train loss: 2.580977, tar: 0.791547 
l0: 0.448741, l1: 0.194893, l2: 0.232084, l3: 0.141482, l4: 0.172168, l5: 0.141532, l6: 0.131942

[epoch:   1/100000, batch:    38/  187, ite: 19] train loss: 2.522128, tar: 0.773505 
l0: 0.425371, l1: 0.241274, l2: 0.249000, l3: 0.165293, l4: 0.207186, l5: 0.756799, l6: 0.187549

[epoch:   1/100000, batch:    40/  187, ite: 20] train loss: 2.507645, tar: 0.756098 
l0: 0.376743, l1: 0.342398, l2: 0.262177, l3: 0.212977, l4: 0.226328, l5: 0.289582, l6: 0.195257

[epoch:   1/100000, batch:    42/  187, ite: 21] train loss: 2.478969, tar: 0.738034 
l0: 0.362785, l1: 0.150113, l2: 0.220138, l3: 0.131414, l4: 0.178391, l5: 0.733611, l6: 0.128347

[epoch:   1/100000, batch:    44/  187, ite: 22] train loss: 2.452871, tar: 0.720977 
l0: 0.295548, l1: 0.184224, l2: 0.220157, l3: 0.146341, l4: 0.209529, l5: 0.117924, l6: 0.153825

[epoch:   1/100000, batch:    46/  187, ite: 23] train loss: 2.403944, tar: 0.702480 
l0: 0.282655, l1: 0.082355, l2: 0.169598, l3: 0.101695, l4: 0.179073, l5: 0.273099, l6: 0.128187

[epoch:   1/100000, batch:    48/  187, ite: 24] train loss: 2.354474, tar: 0.684987 
l0: 0.352163, l1: 0.265759, l2: 0.243970, l3: 0.189555, l4: 0.253714, l5: 1.568810, l6: 0.236185

[epoch:   1/100000, batch:    50/  187, ite: 25] train loss: 2.384701, tar: 0.671674 
l0: 0.263430, l1: 0.100046, l2: 0.164968, l3: 0.113093, l4: 0.192880, l5: 0.224721, l6: 0.171697

[epoch:   1/100000, batch:    52/  187, ite: 26] train loss: 2.340321, tar: 0.655973 
l0: 0.299410, l1: 0.227567, l2: 0.185996, l3: 0.141164, l4: 0.192185, l5: 0.440046, l6: 0.189916

[epoch:   1/100000, batch:    54/  187, ite: 27] train loss: 2.315727, tar: 0.642766 
l0: 0.340161, l1: 0.298868, l2: 0.220347, l3: 0.195644, l4: 0.224114, l5: 1.260600, l6: 0.229478

[epoch:   1/100000, batch:    56/  187, ite: 28] train loss: 2.331923, tar: 0.631959 
l0: 0.262484, l1: 0.060241, l2: 0.115508, l3: 0.080237, l4: 0.114910, l5: 0.039081, l6: 0.072624

[epoch:   1/100000, batch:    58/  187, ite: 29] train loss: 2.277205, tar: 0.619219 
l0: 0.286898, l1: 0.204053, l2: 0.168288, l3: 0.151931, l4: 0.169166, l5: 0.231730, l6: 0.136679

[epoch:   1/100000, batch:    60/  187, ite: 30] train loss: 2.246256, tar: 0.608141 
l0: 0.289929, l1: 0.191591, l2: 0.158984, l3: 0.130925, l4: 0.156745, l5: 0.130693, l6: 0.128979

[epoch:   1/100000, batch:    62/  187, ite: 31] train loss: 2.212114, tar: 0.597876 
l0: 0.307384, l1: 0.282421, l2: 0.185637, l3: 0.168482, l4: 0.170624, l5: 0.248857, l6: 0.185017

[epoch:   1/100000, batch:    64/  187, ite: 32] train loss: 2.191373, tar: 0.588798 
l0: 0.305519, l1: 0.393390, l2: 0.215062, l3: 0.202035, l4: 0.195938, l5: 0.223193, l6: 0.205038

[epoch:   1/100000, batch:    66/  187, ite: 33] train loss: 2.177701, tar: 0.580214 
l0: 0.281309, l1: 0.198207, l2: 0.182001, l3: 0.156141, l4: 0.169080, l5: 0.472916, l6: 0.173946

[epoch:   1/100000, batch:    68/  187, ite: 34] train loss: 2.161698, tar: 0.571423 
l0: 0.273348, l1: 0.182190, l2: 0.149559, l3: 0.088483, l4: 0.110181, l5: 0.082138, l6: 0.086475

[epoch:   1/100000, batch:    70/  187, ite: 35] train loss: 2.127717, tar: 0.562906 
l0: 0.229414, l1: 0.172505, l2: 0.167869, l3: 0.112918, l4: 0.153939, l5: 0.114208, l6: 0.112918

[epoch:   1/100000, batch:    72/  187, ite: 36] train loss: 2.098163, tar: 0.553643 
l0: 0.232232, l1: 0.277148, l2: 0.191801, l3: 0.152058, l4: 0.186215, l5: 0.177533, l6: 0.165403

[epoch:   1/100000, batch:    74/  187, ite: 37] train loss: 2.078818, tar: 0.544956 
l0: 0.273337, l1: 0.455011, l2: 0.213751, l3: 0.225523, l4: 0.230144, l5: 0.667077, l6: 0.236735

[epoch:   1/100000, batch:    76/  187, ite: 38] train loss: 2.084680, tar: 0.537808 
l0: 0.206221, l1: 0.099445, l2: 0.139046, l3: 0.104106, l4: 0.137145, l5: 0.085523, l6: 0.093472

[epoch:   1/100000, batch:    78/  187, ite: 39] train loss: 2.053405, tar: 0.529306 
l0: 0.254785, l1: 0.261944, l2: 0.173801, l3: 0.161737, l4: 0.171249, l5: 0.218009, l6: 0.174086

[epoch:   1/100000, batch:    80/  187, ite: 40] train loss: 2.037460, tar: 0.522443 
l0: 0.227607, l1: 0.102913, l2: 0.130690, l3: 0.099392, l4: 0.124771, l5: 0.099322, l6: 0.107397

[epoch:   1/100000, batch:    82/  187, ite: 41] train loss: 2.009524, tar: 0.515252 
l0: 0.257783, l1: 0.416713, l2: 0.204032, l3: 0.195706, l4: 0.195412, l5: 0.291332, l6: 0.189166

[epoch:   1/100000, batch:    84/  187, ite: 42] train loss: 2.003349, tar: 0.509122 
l0: 0.253300, l1: 0.291380, l2: 0.174228, l3: 0.145187, l4: 0.169263, l5: 0.172793, l6: 0.148882

[epoch:   1/100000, batch:    86/  187, ite: 43] train loss: 1.988272, tar: 0.503172 
l0: 0.216201, l1: 0.210294, l2: 0.162498, l3: 0.143357, l4: 0.164202, l5: 0.225012, l6: 0.136875

[epoch:   1/100000, batch:    88/  187, ite: 44] train loss: 1.971684, tar: 0.496650 
l0: 0.206244, l1: 0.215323, l2: 0.150573, l3: 0.133192, l4: 0.150058, l5: 0.208513, l6: 0.137894

[epoch:   1/100000, batch:    90/  187, ite: 45] train loss: 1.954576, tar: 0.490197 
l0: 0.213753, l1: 0.201005, l2: 0.151887, l3: 0.129301, l4: 0.152162, l5: 0.153699, l6: 0.128599

[epoch:   1/100000, batch:    92/  187, ite: 46] train loss: 1.936659, tar: 0.484187 
l0: 0.214542, l1: 0.124815, l2: 0.138023, l3: 0.108320, l4: 0.114500, l5: 0.106906, l6: 0.106527

[epoch:   1/100000, batch:    94/  187, ite: 47] train loss: 1.914893, tar: 0.478450 
l0: 0.200015, l1: 0.212389, l2: 0.150199, l3: 0.121956, l4: 0.137952, l5: 0.102850, l6: 0.107314

[epoch:   1/100000, batch:    96/  187, ite: 48] train loss: 1.896513, tar: 0.472649 
l0: 0.168642, l1: 0.122887, l2: 0.135394, l3: 0.113731, l4: 0.127046, l5: 0.126540, l6: 0.118901

[epoch:   1/100000, batch:    98/  187, ite: 49] train loss: 1.876444, tar: 0.466445 
l0: 0.212846, l1: 0.296075, l2: 0.172290, l3: 0.155220, l4: 0.170314, l5: 0.275748, l6: 0.168552

[epoch:   1/100000, batch:   100/  187, ite: 50] train loss: 1.867936, tar: 0.461373 
l0: 0.182816, l1: 0.135355, l2: 0.132162, l3: 0.113632, l4: 0.120948, l5: 0.123444, l6: 0.110946

[epoch:   1/100000, batch:   102/  187, ite: 51] train loss: 1.849336, tar: 0.455911 
l0: 0.216392, l1: 0.295694, l2: 0.171109, l3: 0.158509, l4: 0.165640, l5: 0.168532, l6: 0.162094

[epoch:   1/100000, batch:   104/  187, ite: 52] train loss: 1.839502, tar: 0.451305 
l0: 0.180013, l1: 0.106779, l2: 0.125944, l3: 0.111586, l4: 0.124045, l5: 0.106206, l6: 0.107184

[epoch:   1/100000, batch:   106/  187, ite: 53] train loss: 1.821054, tar: 0.446186 
l0: 0.234337, l1: 0.483758, l2: 0.213724, l3: 0.220237, l4: 0.254937, l5: 0.305014, l6: 0.244768

[epoch:   1/100000, batch:   108/  187, ite: 54] train loss: 1.823567, tar: 0.442263 
l0: 0.239338, l1: 0.346355, l2: 0.187027, l3: 0.180637, l4: 0.196387, l5: 0.246590, l6: 0.182042

[epoch:   1/100000, batch:   110/  187, ite: 55] train loss: 1.819109, tar: 0.438574 
l0: 0.220077, l1: 0.149332, l2: 0.142209, l3: 0.121101, l4: 0.146142, l5: 0.122454, l6: 0.117310

[epoch:   1/100000, batch:   112/  187, ite: 56] train loss: 1.804815, tar: 0.434672 
l0: 0.244838, l1: 0.126765, l2: 0.141598, l3: 0.120729, l4: 0.122392, l5: 0.141254, l6: 0.102861

[epoch:   1/100000, batch:   114/  187, ite: 57] train loss: 1.790703, tar: 0.431341 
l0: 0.209056, l1: 0.167031, l2: 0.150858, l3: 0.158314, l4: 0.151730, l5: 0.151168, l6: 0.143803

[epoch:   1/100000, batch:   116/  187, ite: 58] train loss: 1.779345, tar: 0.427509 
l0: 0.203996, l1: 0.131280, l2: 0.135315, l3: 0.110225, l4: 0.136150, l5: 0.105105, l6: 0.110363

[epoch:   1/100000, batch:   118/  187, ite: 59] train loss: 1.764991, tar: 0.423721 
l0: 0.189097, l1: 0.081477, l2: 0.113306, l3: 0.079191, l4: 0.110878, l5: 0.087711, l6: 0.076322

[epoch:   1/100000, batch:   120/  187, ite: 60] train loss: 1.747874, tar: 0.419810 
l0: 0.205156, l1: 0.141887, l2: 0.150645, l3: 0.135118, l4: 0.143729, l5: 0.126949, l6: 0.120976

[epoch:   1/100000, batch:   122/  187, ite: 61] train loss: 1.736015, tar: 0.416291 
l0: 0.239541, l1: 0.424820, l2: 0.214528, l3: 0.204145, l4: 0.169001, l5: 0.199431, l6: 0.175840

[epoch:   1/100000, batch:   124/  187, ite: 62] train loss: 1.734261, tar: 0.413440 
l0: 0.209663, l1: 0.195669, l2: 0.162446, l3: 0.140994, l4: 0.158470, l5: 0.138794, l6: 0.130675

[epoch:   1/100000, batch:   126/  187, ite: 63] train loss: 1.724776, tar: 0.410206 
l0: 0.232452, l1: 0.192204, l2: 0.141874, l3: 0.119057, l4: 0.129887, l5: 0.112697, l6: 0.146549

[epoch:   1/100000, batch:   128/  187, ite: 64] train loss: 1.714619, tar: 0.407428 
l0: 0.250900, l1: 0.397064, l2: 0.201995, l3: 0.199953, l4: 0.215079, l5: 0.478103, l6: 0.268727

[epoch:   1/100000, batch:   130/  187, ite: 65] train loss: 1.719192, tar: 0.405020 
l0: 0.184411, l1: 0.176723, l2: 0.132015, l3: 0.122080, l4: 0.130845, l5: 0.107163, l6: 0.143550

[epoch:   1/100000, batch:   132/  187, ite: 66] train loss: 1.708246, tar: 0.401678 
l0: 0.214553, l1: 0.246568, l2: 0.160273, l3: 0.152492, l4: 0.163493, l5: 0.162263, l6: 0.185181

[epoch:   1/100000, batch:   134/  187, ite: 67] train loss: 1.701926, tar: 0.398885 
l0: 0.313661, l1: 0.502660, l2: 0.246180, l3: 0.256865, l4: 0.267625, l5: 1.002512, l6: 0.272919

[epoch:   1/100000, batch:   136/  187, ite: 68] train loss: 1.718992, tar: 0.397632 
l0: 0.198552, l1: 0.220580, l2: 0.133869, l3: 0.139064, l4: 0.134179, l5: 0.144833, l6: 0.152532

[epoch:   1/100000, batch:   138/  187, ite: 69] train loss: 1.710364, tar: 0.394746 
l0: 0.194841, l1: 0.179350, l2: 0.143160, l3: 0.130148, l4: 0.139337, l5: 0.135363, l6: 0.141403

[epoch:   1/100000, batch:   140/  187, ite: 70] train loss: 1.701124, tar: 0.391891 
l0: 0.217100, l1: 0.238100, l2: 0.157835, l3: 0.155835, l4: 0.159553, l5: 0.145035, l6: 0.161054

[epoch:   1/100000, batch:   142/  187, ite: 71] train loss: 1.694552, tar: 0.389429 
l0: 0.190678, l1: 0.153838, l2: 0.135105, l3: 0.114863, l4: 0.129312, l5: 0.112648, l6: 0.121575

[epoch:   1/100000, batch:   144/  187, ite: 72] train loss: 1.684323, tar: 0.386668 
l0: 0.184526, l1: 0.158155, l2: 0.141700, l3: 0.113164, l4: 0.131253, l5: 0.118063, l6: 0.119019

[epoch:   1/100000, batch:   146/  187, ite: 73] train loss: 1.674481, tar: 0.383899 
l0: 0.216304, l1: 0.272561, l2: 0.183123, l3: 0.155400, l4: 0.171405, l5: 0.198503, l6: 0.153807

[epoch:   1/100000, batch:   148/  187, ite: 74] train loss: 1.670111, tar: 0.381634 
l0: 0.214957, l1: 0.291211, l2: 0.186446, l3: 0.184144, l4: 0.182390, l5: 0.192294, l6: 0.252818

[epoch:   1/100000, batch:   150/  187, ite: 75] train loss: 1.667900, tar: 0.379412 
l0: 0.220430, l1: 0.248631, l2: 0.182226, l3: 0.168669, l4: 0.162716, l5: 0.165498, l6: 0.218256

[epoch:   1/100000, batch:   152/  187, ite: 76] train loss: 1.663933, tar: 0.377320 
l0: 0.175328, l1: 0.169511, l2: 0.144887, l3: 0.131310, l4: 0.142295, l5: 0.116278, l6: 0.193015

[epoch:   1/100000, batch:   154/  187, ite: 77] train loss: 1.656253, tar: 0.374697 
l0: 0.186905, l1: 0.230514, l2: 0.168899, l3: 0.158281, l4: 0.170821, l5: 0.181525, l6: 0.180803

[epoch:   1/100000, batch:   156/  187, ite: 78] train loss: 1.651401, tar: 0.372289 
l0: 0.208279, l1: 0.165447, l2: 0.148716, l3: 0.136081, l4: 0.138939, l5: 0.151706, l6: 0.190854

[epoch:   1/100000, batch:   158/  187, ite: 79] train loss: 1.644928, tar: 0.370213 
l0: 0.220712, l1: 0.253836, l2: 0.159567, l3: 0.158518, l4: 0.162687, l5: 0.152236, l6: 0.156072

[epoch:   1/100000, batch:   160/  187, ite: 80] train loss: 1.640161, tar: 0.368344 
l0: 0.180019, l1: 0.080028, l2: 0.098580, l3: 0.081885, l4: 0.083311, l5: 0.059215, l6: 0.072544

[epoch:   1/100000, batch:   162/  187, ite: 81] train loss: 1.628006, tar: 0.366019 
l0: 0.310673, l1: 0.578736, l2: 0.253271, l3: 0.272461, l4: 0.230703, l5: 0.293666, l6: 0.227233

[epoch:   1/100000, batch:   164/  187, ite: 82] train loss: 1.634576, tar: 0.365345 
l0: 0.219657, l1: 0.160787, l2: 0.146746, l3: 0.124484, l4: 0.131836, l5: 0.163625, l6: 0.149199

[epoch:   1/100000, batch:   166/  187, ite: 83] train loss: 1.628091, tar: 0.363589 
l0: 0.226822, l1: 0.211606, l2: 0.171374, l3: 0.163252, l4: 0.168970, l5: 0.162444, l6: 0.194745

[epoch:   1/100000, batch:   168/  187, ite: 84] train loss: 1.624176, tar: 0.361961 
l0: 0.221927, l1: 0.197179, l2: 0.165007, l3: 0.145655, l4: 0.160758, l5: 0.167454, l6: 0.219213

[epoch:   1/100000, batch:   170/  187, ite: 85] train loss: 1.620094, tar: 0.360314 
l0: 0.167544, l1: 0.039613, l2: 0.100450, l3: 0.063073, l4: 0.111695, l5: 0.048573, l6: 0.049736

[epoch:   1/100000, batch:   172/  187, ite: 86] train loss: 1.608008, tar: 0.358072 
l0: 0.212435, l1: 0.230057, l2: 0.171911, l3: 0.170830, l4: 0.194340, l5: 0.262064, l6: 0.227458

[epoch:   1/100000, batch:   174/  187, ite: 87] train loss: 1.606411, tar: 0.356398 
l0: 0.209365, l1: 0.203267, l2: 0.164128, l3: 0.157302, l4: 0.167723, l5: 0.166700, l6: 0.198478

[epoch:   1/100000, batch:   176/  187, ite: 88] train loss: 1.602554, tar: 0.354727 
l0: 0.142620, l1: 0.053468, l2: 0.090384, l3: 0.066871, l4: 0.081014, l5: 0.060056, l6: 0.077342

[epoch:   1/100000, batch:   178/  187, ite: 89] train loss: 1.590972, tar: 0.352344 
l0: 0.203165, l1: 0.248227, l2: 0.147841, l3: 0.148842, l4: 0.146821, l5: 0.188725, l6: 0.237332

[epoch:   1/100000, batch:   180/  187, ite: 90] train loss: 1.587971, tar: 0.350687 
l0: 0.190052, l1: 0.146840, l2: 0.119878, l3: 0.104616, l4: 0.110617, l5: 0.097721, l6: 0.109525

[epoch:   1/100000, batch:   182/  187, ite: 91] train loss: 1.580183, tar: 0.348921 
l0: 0.187899, l1: 0.199195, l2: 0.141942, l3: 0.145310, l4: 0.143391, l5: 0.159425, l6: 0.170088

[epoch:   1/100000, batch:   184/  187, ite: 92] train loss: 1.575477, tar: 0.347171 
l0: 0.148967, l1: 0.173120, l2: 0.121295, l3: 0.099242, l4: 0.113051, l5: 0.124122, l6: 0.105332

[epoch:   1/100000, batch:   186/  187, ite: 93] train loss: 1.568054, tar: 0.345040 
l0: 0.195278, l1: 0.270830, l2: 0.127399, l3: 0.122083, l4: 0.120183, l5: 0.130426, l6: 0.111894

[epoch:   1/100000, batch:   188/  187, ite: 94] train loss: 1.562842, tar: 0.343447 
/home/supreme/.local/lib/python3.7/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/home/supreme/.local/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode)
/home/supreme/.local/lib/python3.7/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
l0: 0.180364, l1: 0.257867, l2: 0.148948, l3: 0.144945, l4: 0.148590, l5: 0.157506, l6: 0.127730

[epoch:   2/100000, batch:     2/  187, ite: 95] train loss: 1.558664, tar: 0.341730 
l0: 0.160325, l1: 0.193894, l2: 0.120214, l3: 0.117743, l4: 0.118900, l5: 0.102683, l6: 0.107564

[epoch:   2/100000, batch:     4/  187, ite: 96] train loss: 1.552025, tar: 0.339840 
l0: 0.183971, l1: 0.322278, l2: 0.169746, l3: 0.161955, l4: 0.162981, l5: 0.217819, l6: 0.170668

[epoch:   2/100000, batch:     6/  187, ite: 97] train loss: 1.550349, tar: 0.338233 
l0: 0.199188, l1: 0.241954, l2: 0.148071, l3: 0.143998, l4: 0.147677, l5: 0.153610, l6: 0.189954

[epoch:   2/100000, batch:     8/  187, ite: 98] train loss: 1.547023, tar: 0.336815 
l0: 0.170217, l1: 0.104848, l2: 0.106500, l3: 0.092977, l4: 0.112492, l5: 0.116403, l6: 0.120781

[epoch:   2/100000, batch:    10/  187, ite: 99] train loss: 1.539722, tar: 0.335132 
l0: 0.181815, l1: 0.120189, l2: 0.113503, l3: 0.111433, l4: 0.112328, l5: 0.095591, l6: 0.096102

[epoch:   2/100000, batch:    12/  187, ite: 100] train loss: 1.532635, tar: 0.333599 
l0: 0.322100, l1: 0.478439, l2: 0.259932, l3: 0.276068, l4: 0.278996, l5: 1.505428, l6: 0.308371

[epoch:   2/100000, batch:    14/  187, ite: 101] train loss: 1.551414, tar: 0.333485 
l0: 0.165867, l1: 0.210640, l2: 0.143775, l3: 0.131137, l4: 0.147846, l5: 0.149582, l6: 0.196601

[epoch:   2/100000, batch:    16/  187, ite: 102] train loss: 1.547434, tar: 0.331841 
l0: 0.228042, l1: 0.358819, l2: 0.186358, l3: 0.189510, l4: 0.174487, l5: 0.189145, l6: 0.209430

[epoch:   2/100000, batch:    18/  187, ite: 103] train loss: 1.547321, tar: 0.330834 
l0: 0.243232, l1: 0.298610, l2: 0.198773, l3: 0.203296, l4: 0.202601, l5: 0.763579, l6: 0.219383

[epoch:   2/100000, batch:    20/  187, ite: 104] train loss: 1.552918, tar: 0.329991 
l0: 0.180488, l1: 0.164481, l2: 0.113821, l3: 0.097886, l4: 0.117275, l5: 0.098498, l6: 0.113588

[epoch:   2/100000, batch:    22/  187, ite: 105] train loss: 1.546567, tar: 0.328568 
l0: 0.204631, l1: 0.301067, l2: 0.177358, l3: 0.196441, l4: 0.181057, l5: 0.189534, l6: 0.191039

[epoch:   2/100000, batch:    24/  187, ite: 106] train loss: 1.545573, tar: 0.327398 
l0: 0.189126, l1: 0.262095, l2: 0.173366, l3: 0.155396, l4: 0.172234, l5: 0.176346, l6: 0.173642

[epoch:   2/100000, batch:    26/  187, ite: 107] train loss: 1.543298, tar: 0.326106 
l0: 0.184370, l1: 0.201578, l2: 0.134199, l3: 0.134588, l4: 0.134344, l5: 0.127549, l6: 0.156814

[epoch:   2/100000, batch:    28/  187, ite: 108] train loss: 1.538948, tar: 0.324794 
l0: 0.187608, l1: 0.088196, l2: 0.121315, l3: 0.105147, l4: 0.130029, l5: 0.089307, l6: 0.123108

[epoch:   2/100000, batch:    30/  187, ite: 109] train loss: 1.532578, tar: 0.323535 
l0: 0.243325, l1: 0.257718, l2: 0.166832, l3: 0.171636, l4: 0.165574, l5: 0.182399, l6: 0.163242

[epoch:   2/100000, batch:    32/  187, ite: 110] train loss: 1.530925, tar: 0.322806 
l0: 0.227787, l1: 0.285575, l2: 0.183440, l3: 0.192605, l4: 0.182557, l5: 0.195072, l6: 0.182684

[epoch:   2/100000, batch:    34/  187, ite: 111] train loss: 1.530194, tar: 0.321950 
l0: 0.183473, l1: 0.187305, l2: 0.142847, l3: 0.142177, l4: 0.151603, l5: 0.142057, l6: 0.137686

[epoch:   2/100000, batch:    36/  187, ite: 112] train loss: 1.526238, tar: 0.320714 
l0: 0.176511, l1: 0.092822, l2: 0.109586, l3: 0.090474, l4: 0.104397, l5: 0.091187, l6: 0.091524

[epoch:   2/100000, batch:    38/  187, ite: 113] train loss: 1.519426, tar: 0.319437 
l0: 0.194745, l1: 0.208081, l2: 0.146688, l3: 0.145734, l4: 0.147365, l5: 0.146416, l6: 0.173022

[epoch:   2/100000, batch:    40/  187, ite: 114] train loss: 1.516291, tar: 0.318344 
l0: 0.196038, l1: 0.158181, l2: 0.128983, l3: 0.110452, l4: 0.128660, l5: 0.118631, l6: 0.133334

[epoch:   2/100000, batch:    42/  187, ite: 115] train loss: 1.511578, tar: 0.317280 
l0: 0.172099, l1: 0.128266, l2: 0.124016, l3: 0.105259, l4: 0.126471, l5: 0.116670, l6: 0.112862

[epoch:   2/100000, batch:    44/  187, ite: 116] train loss: 1.506182, tar: 0.316028 
l0: 0.184393, l1: 0.160285, l2: 0.134461, l3: 0.117362, l4: 0.130691, l5: 0.123518, l6: 0.159314

[epoch:   2/100000, batch:    46/  187, ite: 117] train loss: 1.501941, tar: 0.314903 
l0: 0.178731, l1: 0.202423, l2: 0.143654, l3: 0.128227, l4: 0.144199, l5: 0.136536, l6: 0.141621

[epoch:   2/100000, batch:    48/  187, ite: 118] train loss: 1.498327, tar: 0.313749 
l0: 0.192373, l1: 0.324630, l2: 0.188281, l3: 0.188924, l4: 0.185140, l5: 0.201505, l6: 0.194968

[epoch:   2/100000, batch:    50/  187, ite: 119] train loss: 1.498137, tar: 0.312729 
l0: 0.155332, l1: 0.146133, l2: 0.119225, l3: 0.103263, l4: 0.117182, l5: 0.107761, l6: 0.112619

[epoch:   2/100000, batch:    52/  187, ite: 120] train loss: 1.492832, tar: 0.311418 
l0: 0.202824, l1: 0.212355, l2: 0.134606, l3: 0.125806, l4: 0.137556, l5: 0.176907, l6: 0.137657

[epoch:   2/100000, batch:    54/  187, ite: 121] train loss: 1.489815, tar: 0.310520 
l0: 0.206580, l1: 0.277555, l2: 0.169986, l3: 0.179364, l4: 0.167326, l5: 0.219450, l6: 0.220343

[epoch:   2/100000, batch:    56/  187, ite: 122] train loss: 1.489411, tar: 0.309668 
l0: 0.175496, l1: 0.171662, l2: 0.132292, l3: 0.127838, l4: 0.129943, l5: 0.138356, l6: 0.153416

[epoch:   2/100000, batch:    58/  187, ite: 123] train loss: 1.485668, tar: 0.308578 
l0: 0.149539, l1: 0.101616, l2: 0.118334, l3: 0.111743, l4: 0.124950, l5: 0.099798, l6: 0.147533

[epoch:   2/100000, batch:    60/  187, ite: 124] train loss: 1.480570, tar: 0.307295 
l0: 0.133375, l1: 0.046298, l2: 0.087950, l3: 0.065393, l4: 0.085242, l5: 0.070615, l6: 0.106346

[epoch:   2/100000, batch:    62/  187, ite: 125] train loss: 1.473487, tar: 0.305904 
l0: 0.144338, l1: 0.099996, l2: 0.108031, l3: 0.097144, l4: 0.104852, l5: 0.103872, l6: 0.094091

[epoch:   2/100000, batch:    64/  187, ite: 126] train loss: 1.467764, tar: 0.304621 
l0: 0.208278, l1: 0.369624, l2: 0.163595, l3: 0.156973, l4: 0.158641, l5: 0.145740, l6: 0.175591

[epoch:   2/100000, batch:    66/  187, ite: 127] train loss: 1.467060, tar: 0.303863 
l0: 0.197969, l1: 0.287630, l2: 0.165385, l3: 0.163017, l4: 0.160277, l5: 0.154752, l6: 0.208283

[epoch:   2/100000, batch:    68/  187, ite: 128] train loss: 1.466047, tar: 0.303035 
l0: 0.141105, l1: 0.058491, l2: 0.089410, l3: 0.064056, l4: 0.068362, l5: 0.064726, l6: 0.063494

[epoch:   2/100000, batch:    70/  187, ite: 129] train loss: 1.458943, tar: 0.301780 
l0: 0.190021, l1: 0.219529, l2: 0.145345, l3: 0.133896, l4: 0.141619, l5: 0.134512, l6: 0.135413

[epoch:   2/100000, batch:    72/  187, ite: 130] train loss: 1.456184, tar: 0.300920 
l0: 0.190316, l1: 0.261629, l2: 0.150607, l3: 0.156683, l4: 0.157725, l5: 0.156721, l6: 0.172012

[epoch:   2/100000, batch:    74/  187, ite: 131] train loss: 1.454578, tar: 0.300076 
l0: 0.183568, l1: 0.219452, l2: 0.153559, l3: 0.135191, l4: 0.143402, l5: 0.148148, l6: 0.152536

[epoch:   2/100000, batch:    76/  187, ite: 132] train loss: 1.452163, tar: 0.299194 
l0: 0.167196, l1: 0.128991, l2: 0.128129, l3: 0.102586, l4: 0.124044, l5: 0.093583, l6: 0.097154

[epoch:   2/100000, batch:    78/  187, ite: 133] train loss: 1.447573, tar: 0.298201 
l0: 0.208420, l1: 0.300343, l2: 0.177552, l3: 0.170179, l4: 0.186778, l5: 0.228390, l6: 0.176688

[epoch:   2/100000, batch:    80/  187, ite: 134] train loss: 1.447579, tar: 0.297531 
l0: 0.193824, l1: 0.192631, l2: 0.152343, l3: 0.161594, l4: 0.150308, l5: 0.146540, l6: 0.143606

[epoch:   2/100000, batch:    82/  187, ite: 135] train loss: 1.445307, tar: 0.296763 
l0: 0.221775, l1: 0.320070, l2: 0.212874, l3: 0.221574, l4: 0.207471, l5: 0.218172, l6: 0.163009

[epoch:   2/100000, batch:    84/  187, ite: 136] train loss: 1.446186, tar: 0.296211 
l0: 0.175135, l1: 0.140468, l2: 0.140810, l3: 0.131101, l4: 0.148501, l5: 0.117103, l6: 0.133966

[epoch:   2/100000, batch:    86/  187, ite: 137] train loss: 1.442835, tar: 0.295328 
l0: 0.175859, l1: 0.150973, l2: 0.136592, l3: 0.121878, l4: 0.140766, l5: 0.104782, l6: 0.135706

[epoch:   2/100000, batch:    88/  187, ite: 138] train loss: 1.439384, tar: 0.294462 
l0: 0.192269, l1: 0.137508, l2: 0.141379, l3: 0.127562, l4: 0.142491, l5: 0.129960, l6: 0.154663

[epoch:   2/100000, batch:    90/  187, ite: 139] train loss: 1.436409, tar: 0.293727 
l0: 0.174085, l1: 0.136900, l2: 0.121013, l3: 0.108350, l4: 0.138152, l5: 0.138202, l6: 0.154557

[epoch:   2/100000, batch:    92/  187, ite: 140] train loss: 1.433086, tar: 0.292872 
l0: 0.203510, l1: 0.255816, l2: 0.163293, l3: 0.162261, l4: 0.174721, l5: 0.212097, l6: 0.162198

[epoch:   2/100000, batch:    94/  187, ite: 141] train loss: 1.432383, tar: 0.292238 
l0: 0.237106, l1: 0.315484, l2: 0.212327, l3: 0.208500, l4: 0.199034, l5: 0.268242, l6: 0.253056

[epoch:   2/100000, batch:    96/  187, ite: 142] train loss: 1.434223, tar: 0.291850 
l0: 0.194420, l1: 0.207468, l2: 0.162956, l3: 0.150033, l4: 0.148938, l5: 0.135155, l6: 0.153895

[epoch:   2/100000, batch:    98/  187, ite: 143] train loss: 1.432256, tar: 0.291169 
l0: 0.214215, l1: 0.235456, l2: 0.176614, l3: 0.178135, l4: 0.161838, l5: 0.169082, l6: 0.162726

[epoch:   2/100000, batch:   100/  187, ite: 144] train loss: 1.431324, tar: 0.290634 
l0: 0.146957, l1: 0.091646, l2: 0.101887, l3: 0.086761, l4: 0.115273, l5: 0.105632, l6: 0.093270

[epoch:   2/100000, batch:   102/  187, ite: 145] train loss: 1.426566, tar: 0.289644 
l0: 0.187348, l1: 0.129469, l2: 0.123900, l3: 0.104692, l4: 0.119726, l5: 0.117697, l6: 0.128270

[epoch:   2/100000, batch:   104/  187, ite: 146] train loss: 1.423036, tar: 0.288943 
l0: 0.173446, l1: 0.092323, l2: 0.098657, l3: 0.084950, l4: 0.094490, l5: 0.082697, l6: 0.077614

[epoch:   2/100000, batch:   106/  187, ite: 147] train loss: 1.418145, tar: 0.288157 
l0: 0.210769, l1: 0.291519, l2: 0.186480, l3: 0.196706, l4: 0.182868, l5: 0.167024, l6: 0.194737

[epoch:   2/100000, batch:   108/  187, ite: 148] train loss: 1.418226, tar: 0.287634 
l0: 0.182084, l1: 0.177006, l2: 0.145415, l3: 0.169428, l4: 0.139093, l5: 0.164021, l6: 0.159804

[epoch:   2/100000, batch:   110/  187, ite: 149] train loss: 1.416338, tar: 0.286926 
l0: 0.166465, l1: 0.154648, l2: 0.109100, l3: 0.101987, l4: 0.108561, l5: 0.112378, l6: 0.111812

[epoch:   2/100000, batch:   112/  187, ite: 150] train loss: 1.412662, tar: 0.286123 
l0: 0.179397, l1: 0.201406, l2: 0.154704, l3: 0.159536, l4: 0.148271, l5: 0.177534, l6: 0.165978

[epoch:   2/100000, batch:   114/  187, ite: 151] train loss: 1.411166, tar: 0.285416 
l0: 0.184658, l1: 0.217831, l2: 0.166911, l3: 0.167561, l4: 0.147364, l5: 0.185607, l6: 0.152351

[epoch:   2/100000, batch:   116/  187, ite: 152] train loss: 1.409924, tar: 0.284753 
l0: 0.118743, l1: 0.037228, l2: 0.067313, l3: 0.040863, l4: 0.087542, l5: 0.050671, l6: 0.046840

[epoch:   2/100000, batch:   118/  187, ite: 153] train loss: 1.403644, tar: 0.283668 
l0: 0.144445, l1: 0.140034, l2: 0.127643, l3: 0.116321, l4: 0.129723, l5: 0.106784, l6: 0.112277

[epoch:   2/100000, batch:   120/  187, ite: 154] train loss: 1.400226, tar: 0.282764 
l0: 0.182879, l1: 0.276383, l2: 0.167756, l3: 0.166458, l4: 0.160802, l5: 0.175570, l6: 0.187039

[epoch:   2/100000, batch:   122/  187, ite: 155] train loss: 1.399688, tar: 0.282120 
l0: 0.166351, l1: 0.203383, l2: 0.145183, l3: 0.124383, l4: 0.134401, l5: 0.127962, l6: 0.144640

[epoch:   2/100000, batch:   124/  187, ite: 156] train loss: 1.397423, tar: 0.281378 
l0: 0.184483, l1: 0.253506, l2: 0.152470, l3: 0.151635, l4: 0.159281, l5: 0.176546, l6: 0.168799

[epoch:   2/100000, batch:   126/  187, ite: 157] train loss: 1.396463, tar: 0.280760 
l0: 0.168795, l1: 0.187786, l2: 0.146502, l3: 0.140108, l4: 0.143881, l5: 0.137621, l6: 0.135850

[epoch:   2/100000, batch:   128/  187, ite: 158] train loss: 1.394337, tar: 0.280052 
l0: 0.190198, l1: 0.152973, l2: 0.139963, l3: 0.114920, l4: 0.119754, l5: 0.120537, l6: 0.122319

[epoch:   2/100000, batch:   130/  187, ite: 159] train loss: 1.391610, tar: 0.279487 
l0: 0.224774, l1: 0.335184, l2: 0.186775, l3: 0.193920, l4: 0.186904, l5: 0.207340, l6: 0.181775

[epoch:   2/100000, batch:   132/  187, ite: 160] train loss: 1.392391, tar: 0.279145 
l0: 0.176498, l1: 0.146270, l2: 0.131312, l3: 0.129899, l4: 0.130500, l5: 0.115940, l6: 0.130047

[epoch:   2/100000, batch:   134/  187, ite: 161] train loss: 1.389708, tar: 0.278507 
l0: 0.178141, l1: 0.189347, l2: 0.150502, l3: 0.139777, l4: 0.135315, l5: 0.130610, l6: 0.122314

[epoch:   2/100000, batch:   136/  187, ite: 162] train loss: 1.387587, tar: 0.277888 
l0: 0.187006, l1: 0.229620, l2: 0.164536, l3: 0.151975, l4: 0.153563, l5: 0.160291, l6: 0.168075

[epoch:   2/100000, batch:   138/  187, ite: 163] train loss: 1.386528, tar: 0.277330 
l0: 0.184355, l1: 0.105497, l2: 0.125704, l3: 0.130754, l4: 0.134434, l5: 0.151692, l6: 0.144725

[epoch:   2/100000, batch:   140/  187, ite: 164] train loss: 1.384032, tar: 0.276763 
l0: 0.167962, l1: 0.163909, l2: 0.143840, l3: 0.125485, l4: 0.141516, l5: 0.121204, l6: 0.128821

[epoch:   2/100000, batch:   142/  187, ite: 165] train loss: 1.381661, tar: 0.276104 
l0: 0.198224, l1: 0.244723, l2: 0.178127, l3: 0.187224, l4: 0.212585, l5: 0.394840, l6: 0.190377

[epoch:   2/100000, batch:   144/  187, ite: 166] train loss: 1.383013, tar: 0.275635 
l0: 0.196613, l1: 0.203126, l2: 0.168234, l3: 0.171029, l4: 0.173510, l5: 0.160264, l6: 0.163348

[epoch:   2/100000, batch:   146/  187, ite: 167] train loss: 1.382133, tar: 0.275161 
l0: 0.207884, l1: 0.288298, l2: 0.197023, l3: 0.211143, l4: 0.193701, l5: 0.225122, l6: 0.197544

[epoch:   2/100000, batch:   148/  187, ite: 168] train loss: 1.382958, tar: 0.274761 
l0: 0.162479, l1: 0.132979, l2: 0.133946, l3: 0.121421, l4: 0.124905, l5: 0.144347, l6: 0.119026

[epoch:   2/100000, batch:   150/  187, ite: 169] train loss: 1.380332, tar: 0.274097 
l0: 0.167588, l1: 0.104176, l2: 0.124408, l3: 0.108164, l4: 0.113367, l5: 0.109523, l6: 0.094455

[epoch:   2/100000, batch:   152/  187, ite: 170] train loss: 1.377046, tar: 0.273470 
l0: 0.186711, l1: 0.113422, l2: 0.140140, l3: 0.136483, l4: 0.135674, l5: 0.132826, l6: 0.117173

[epoch:   2/100000, batch:   154/  187, ite: 171] train loss: 1.374621, tar: 0.272963 
l0: 0.167083, l1: 0.140369, l2: 0.151939, l3: 0.157538, l4: 0.152187, l5: 0.135700, l6: 0.122309

[epoch:   2/100000, batch:   156/  187, ite: 172] train loss: 1.372601, tar: 0.272347 
l0: 0.165762, l1: 0.097950, l2: 0.100125, l3: 0.071239, l4: 0.098203, l5: 0.076725, l6: 0.080820

[epoch:   2/100000, batch:   158/  187, ite: 173] train loss: 1.368660, tar: 0.271731 
l0: 0.192386, l1: 0.208049, l2: 0.142595, l3: 0.138659, l4: 0.138947, l5: 0.169364, l6: 0.137400

[epoch:   2/100000, batch:   160/  187, ite: 174] train loss: 1.367273, tar: 0.271275 
l0: 0.208958, l1: 0.291918, l2: 0.165512, l3: 0.184764, l4: 0.177548, l5: 0.273129, l6: 0.242065

[epoch:   2/100000, batch:   162/  187, ite: 175] train loss: 1.368282, tar: 0.270919 
l0: 0.213856, l1: 0.320359, l2: 0.166766, l3: 0.169592, l4: 0.160399, l5: 0.225180, l6: 0.217192

[epoch:   2/100000, batch:   164/  187, ite: 176] train loss: 1.368879, tar: 0.270595 
l0: 0.178369, l1: 0.210759, l2: 0.134238, l3: 0.148068, l4: 0.135964, l5: 0.166677, l6: 0.164478

[epoch:   2/100000, batch:   166/  187, ite: 177] train loss: 1.367578, tar: 0.270074 
l0: 0.120996, l1: 0.073181, l2: 0.084489, l3: 0.068003, l4: 0.089273, l5: 0.065376, l6: 0.068278

[epoch:   2/100000, batch:   168/  187, ite: 178] train loss: 1.363095, tar: 0.269236 
l0: 0.165055, l1: 0.166856, l2: 0.104360, l3: 0.103013, l4: 0.115910, l5: 0.113316, l6: 0.123866

[epoch:   2/100000, batch:   170/  187, ite: 179] train loss: 1.360465, tar: 0.268654 
l0: 0.162319, l1: 0.128455, l2: 0.126181, l3: 0.114848, l4: 0.130398, l5: 0.117382, l6: 0.126208

[epoch:   2/100000, batch:   172/  187, ite: 180] train loss: 1.357939, tar: 0.268063 
l0: 0.180652, l1: 0.204180, l2: 0.149337, l3: 0.157731, l4: 0.149974, l5: 0.250148, l6: 0.180601

[epoch:   2/100000, batch:   174/  187, ite: 181] train loss: 1.357468, tar: 0.267580 
l0: 0.201141, l1: 0.276681, l2: 0.173703, l3: 0.191003, l4: 0.185545, l5: 0.266867, l6: 0.241468

[epoch:   2/100000, batch:   176/  187, ite: 182] train loss: 1.358451, tar: 0.267215 
l0: 0.192270, l1: 0.258623, l2: 0.196640, l3: 0.201958, l4: 0.197778, l5: 0.237663, l6: 0.173507

[epoch:   2/100000, batch:   178/  187, ite: 183] train loss: 1.358998, tar: 0.266806 
l0: 0.165990, l1: 0.135790, l2: 0.124936, l3: 0.109615, l4: 0.122985, l5: 0.123855, l6: 0.144017

[epoch:   2/100000, batch:   180/  187, ite: 184] train loss: 1.356651, tar: 0.266258 
l0: 0.181625, l1: 0.172933, l2: 0.152400, l3: 0.140411, l4: 0.151865, l5: 0.187193, l6: 0.139773

[epoch:   2/100000, batch:   182/  187, ite: 185] train loss: 1.355405, tar: 0.265800 
l0: 0.132551, l1: 0.086606, l2: 0.109639, l3: 0.093096, l4: 0.112693, l5: 0.086455, l6: 0.107548

[epoch:   2/100000, batch:   184/  187, ite: 186] train loss: 1.352035, tar: 0.265084 
l0: 0.170941, l1: 0.171347, l2: 0.147473, l3: 0.141356, l4: 0.147034, l5: 0.134817, l6: 0.137739

[epoch:   2/100000, batch:   186/  187, ite: 187] train loss: 1.350424, tar: 0.264581 
l0: 0.186319, l1: 0.199913, l2: 0.145104, l3: 0.138987, l4: 0.165003, l5: 0.158082, l6: 0.146012

[epoch:   2/100000, batch:   188/  187, ite: 188] train loss: 1.349301, tar: 0.264164 
l0: 0.151198, l1: 0.151339, l2: 0.127898, l3: 0.124260, l4: 0.128242, l5: 0.118036, l6: 0.113486

[epoch:   3/100000, batch:     2/  187, ite: 189] train loss: 1.347001, tar: 0.263567 
l0: 0.240264, l1: 0.331305, l2: 0.188573, l3: 0.202569, l4: 0.168943, l5: 0.261501, l6: 0.212236

[epoch:   3/100000, batch:     4/  187, ite: 190] train loss: 1.348361, tar: 0.263444 
l0: 0.205868, l1: 0.260964, l2: 0.167460, l3: 0.167102, l4: 0.164503, l5: 0.191200, l6: 0.186497

[epoch:   3/100000, batch:     6/  187, ite: 191] train loss: 1.348336, tar: 0.263143 
l0: 0.181127, l1: 0.215229, l2: 0.161571, l3: 0.162962, l4: 0.169178, l5: 0.166609, l6: 0.187269

[epoch:   3/100000, batch:     8/  187, ite: 192] train loss: 1.347792, tar: 0.262715 
l0: 0.167381, l1: 0.115611, l2: 0.107294, l3: 0.100920, l4: 0.110080, l5: 0.107910, l6: 0.116542

[epoch:   3/100000, batch:    10/  187, ite: 193] train loss: 1.345087, tar: 0.262221 
l0: 0.163826, l1: 0.163000, l2: 0.131059, l3: 0.131752, l4: 0.134927, l5: 0.125744, l6: 0.134494

[epoch:   3/100000, batch:    12/  187, ite: 194] train loss: 1.343230, tar: 0.261714 
l0: 0.170224, l1: 0.207571, l2: 0.147110, l3: 0.154956, l4: 0.148271, l5: 0.170735, l6: 0.154290

[epoch:   3/100000, batch:    14/  187, ite: 195] train loss: 1.342255, tar: 0.261245 
l0: 0.147645, l1: 0.131663, l2: 0.118986, l3: 0.109897, l4: 0.124660, l5: 0.110374, l6: 0.102241

[epoch:   3/100000, batch:    16/  187, ite: 196] train loss: 1.339720, tar: 0.260665 
l0: 0.137934, l1: 0.128530, l2: 0.119157, l3: 0.112435, l4: 0.133421, l5: 0.121571, l6: 0.115322

[epoch:   3/100000, batch:    18/  187, ite: 197] train loss: 1.337328, tar: 0.260042 
l0: 0.147064, l1: 0.179940, l2: 0.144700, l3: 0.145015, l4: 0.148921, l5: 0.158240, l6: 0.141699

[epoch:   3/100000, batch:    20/  187, ite: 198] train loss: 1.335955, tar: 0.259472 
l0: 0.168130, l1: 0.164489, l2: 0.143842, l3: 0.128392, l4: 0.128133, l5: 0.112719, l6: 0.138748

[epoch:   3/100000, batch:    22/  187, ite: 199] train loss: 1.334189, tar: 0.259013 
l0: 0.179351, l1: 0.236251, l2: 0.163813, l3: 0.170004, l4: 0.166986, l5: 0.190988, l6: 0.167883

[epoch:   3/100000, batch:    24/  187, ite: 200] train loss: 1.333894, tar: 0.258615 
l0: 0.118436, l1: 0.046135, l2: 0.089207, l3: 0.069257, l4: 0.070604, l5: 0.060551, l6: 0.068819

[epoch:   3/100000, batch:    26/  187, ite: 201] train loss: 1.329860, tar: 0.257917 
l0: 0.142927, l1: 0.159737, l2: 0.134989, l3: 0.135548, l4: 0.110974, l5: 0.115349, l6: 0.113254

[epoch:   3/100000, batch:    28/  187, ite: 202] train loss: 1.327795, tar: 0.257348 
l0: 0.150385, l1: 0.174061, l2: 0.130255, l3: 0.128922, l4: 0.137985, l5: 0.149841, l6: 0.159001

[epoch:   3/100000, batch:    30/  187, ite: 203] train loss: 1.326331, tar: 0.256821 
l0: 0.181689, l1: 0.300864, l2: 0.183444, l3: 0.195466, l4: 0.186960, l5: 0.203586, l6: 0.171609

[epoch:   3/100000, batch:    32/  187, ite: 204] train loss: 1.326808, tar: 0.256453 
l0: 0.163992, l1: 0.147184, l2: 0.136168, l3: 0.117773, l4: 0.124380, l5: 0.106134, l6: 0.117554

[epoch:   3/100000, batch:    34/  187, ite: 205] train loss: 1.324790, tar: 0.256002 
l0: 0.134126, l1: 0.100423, l2: 0.108980, l3: 0.101205, l4: 0.102758, l5: 0.097597, l6: 0.092130

[epoch:   3/100000, batch:    36/  187, ite: 206] train loss: 1.321938, tar: 0.255410 
l0: 0.135684, l1: 0.118569, l2: 0.110212, l3: 0.106716, l4: 0.112126, l5: 0.103199, l6: 0.099414

[epoch:   3/100000, batch:    38/  187, ite: 207] train loss: 1.319348, tar: 0.254832 
l0: 0.138424, l1: 0.124244, l2: 0.107186, l3: 0.102674, l4: 0.114827, l5: 0.098503, l6: 0.088317

[epoch:   3/100000, batch:    40/  187, ite: 208] train loss: 1.316727, tar: 0.254272 
l0: 0.175800, l1: 0.208161, l2: 0.168409, l3: 0.193131, l4: 0.177530, l5: 0.179510, l6: 0.178778

[epoch:   3/100000, batch:    42/  187, ite: 209] train loss: 1.316558, tar: 0.253896 
l0: 0.154818, l1: 0.164554, l2: 0.141039, l3: 0.147966, l4: 0.142399, l5: 0.142042, l6: 0.141656

[epoch:   3/100000, batch:    44/  187, ite: 210] train loss: 1.315214, tar: 0.253425 
l0: 0.141915, l1: 0.142500, l2: 0.122169, l3: 0.113396, l4: 0.120101, l5: 0.115005, l6: 0.103152

[epoch:   3/100000, batch:    46/  187, ite: 211] train loss: 1.313049, tar: 0.252896 
l0: 0.143864, l1: 0.115989, l2: 0.121293, l3: 0.116020, l4: 0.119575, l5: 0.120039, l6: 0.136682

[epoch:   3/100000, batch:    48/  187, ite: 212] train loss: 1.310975, tar: 0.252382 
l0: 0.134107, l1: 0.131442, l2: 0.118518, l3: 0.110065, l4: 0.116666, l5: 0.128032, l6: 0.118236

[epoch:   3/100000, batch:    50/  187, ite: 213] train loss: 1.308844, tar: 0.251827 
l0: 0.110687, l1: 0.080431, l2: 0.092912, l3: 0.085253, l4: 0.084868, l5: 0.074676, l6: 0.071595

[epoch:   3/100000, batch:    52/  187, ite: 214] train loss: 1.305534, tar: 0.251167 
l0: 0.130943, l1: 0.098798, l2: 0.098123, l3: 0.102167, l4: 0.103975, l5: 0.089145, l6: 0.090302

[epoch:   3/100000, batch:    54/  187, ite: 215] train loss: 1.302780, tar: 0.250608 
l0: 0.143131, l1: 0.148218, l2: 0.113956, l3: 0.119785, l4: 0.118498, l5: 0.121774, l6: 0.125446

[epoch:   3/100000, batch:    56/  187, ite: 216] train loss: 1.300873, tar: 0.250110 
l0: 0.122635, l1: 0.063337, l2: 0.072454, l3: 0.070580, l4: 0.072297, l5: 0.063566, l6: 0.052545

[epoch:   3/100000, batch:    58/  187, ite: 217] train loss: 1.297262, tar: 0.249523 
l0: 0.154370, l1: 0.148406, l2: 0.135479, l3: 0.143285, l4: 0.135294, l5: 0.136327, l6: 0.168046

[epoch:   3/100000, batch:    60/  187, ite: 218] train loss: 1.295996, tar: 0.249086 
l0: 0.133899, l1: 0.124231, l2: 0.090624, l3: 0.089641, l4: 0.095266, l5: 0.092681, l6: 0.095871

[epoch:   3/100000, batch:    62/  187, ite: 219] train loss: 1.293376, tar: 0.248560 
l0: 0.117099, l1: 0.116007, l2: 0.091816, l3: 0.086636, l4: 0.094045, l5: 0.082668, l6: 0.079742

[epoch:   3/100000, batch:    64/  187, ite: 220] train loss: 1.290533, tar: 0.247963 
l0: 0.144083, l1: 0.167484, l2: 0.121988, l3: 0.116142, l4: 0.127297, l5: 0.124918, l6: 0.109811

[epoch:   3/100000, batch:    66/  187, ite: 221] train loss: 1.288819, tar: 0.247493 
l0: 0.237730, l1: 0.496512, l2: 0.251600, l3: 0.257030, l4: 0.244778, l5: 0.300678, l6: 0.306462

[epoch:   3/100000, batch:    68/  187, ite: 222] train loss: 1.292450, tar: 0.247449 
l0: 0.135138, l1: 0.147362, l2: 0.126756, l3: 0.146993, l4: 0.127382, l5: 0.127499, l6: 0.152253

[epoch:   3/100000, batch:    70/  187, ite: 223] train loss: 1.290974, tar: 0.246945 
l0: 0.123379, l1: 0.080363, l2: 0.087426, l3: 0.082205, l4: 0.086064, l5: 0.076216, l6: 0.098436

[epoch:   3/100000, batch:    72/  187, ite: 224] train loss: 1.288042, tar: 0.246394 
l0: 0.297427, l1: 0.572269, l2: 0.309635, l3: 0.339628, l4: 0.324098, l5: 0.651843, l6: 0.415183

[epoch:   3/100000, batch:    74/  187, ite: 225] train loss: 1.295251, tar: 0.246620 
l0: 0.206223, l1: 0.319985, l2: 0.181756, l3: 0.190233, l4: 0.182141, l5: 0.171757, l6: 0.132326

[epoch:   3/100000, batch:    76/  187, ite: 226] train loss: 1.295645, tar: 0.246442 
l0: 0.147668, l1: 0.100904, l2: 0.109238, l3: 0.105392, l4: 0.123863, l5: 0.105332, l6: 0.117640

[epoch:   3/100000, batch:    78/  187, ite: 227] train loss: 1.293506, tar: 0.246007 
l0: 0.173503, l1: 0.184518, l2: 0.147523, l3: 0.149793, l4: 0.160094, l5: 0.140012, l6: 0.128073

[epoch:   3/100000, batch:    80/  187, ite: 228] train loss: 1.292585, tar: 0.245689 
l0: 0.191817, l1: 0.179874, l2: 0.155058, l3: 0.157243, l4: 0.163542, l5: 0.154016, l6: 0.150259

[epoch:   3/100000, batch:    82/  187, ite: 229] train loss: 1.291970, tar: 0.245453 
l0: 0.167601, l1: 0.160165, l2: 0.148200, l3: 0.150281, l4: 0.149290, l5: 0.134748, l6: 0.123845

[epoch:   3/100000, batch:    84/  187, ite: 230] train loss: 1.290849, tar: 0.245115 
l0: 0.244480, l1: 0.279047, l2: 0.217349, l3: 0.216441, l4: 0.171723, l5: 0.341467, l6: 0.229923

[epoch:   3/100000, batch:    86/  187, ite: 231] train loss: 1.292622, tar: 0.245112 
l0: 0.208920, l1: 0.195224, l2: 0.163391, l3: 0.175855, l4: 0.162929, l5: 0.163272, l6: 0.139413

[epoch:   3/100000, batch:    88/  187, ite: 232] train loss: 1.292262, tar: 0.244956 
l0: 0.209179, l1: 0.240806, l2: 0.178206, l3: 0.178857, l4: 0.180832, l5: 0.178464, l6: 0.187662

[epoch:   3/100000, batch:    90/  187, ite: 233] train loss: 1.292527, tar: 0.244802 
l0: 0.155997, l1: 0.143619, l2: 0.135623, l3: 0.121335, l4: 0.146495, l5: 0.113251, l6: 0.125558

[epoch:   3/100000, batch:    92/  187, ite: 234] train loss: 1.291028, tar: 0.244423 
l0: 0.260622, l1: 0.377514, l2: 0.217165, l3: 0.247322, l4: 0.277684, l5: 0.498071, l6: 0.325217

[epoch:   3/100000, batch:    94/  187, ite: 235] train loss: 1.294912, tar: 0.244492 
l0: 0.181263, l1: 0.196097, l2: 0.163885, l3: 0.183892, l4: 0.170325, l5: 0.190976, l6: 0.213834

[epoch:   3/100000, batch:    96/  187, ite: 236] train loss: 1.294934, tar: 0.244224 
l0: 0.181487, l1: 0.226853, l2: 0.180524, l3: 0.213818, l4: 0.168773, l5: 0.169113, l6: 0.179804

[epoch:   3/100000, batch:    98/  187, ite: 237] train loss: 1.295042, tar: 0.243959 
l0: 0.180097, l1: 0.222957, l2: 0.175603, l3: 0.183178, l4: 0.182232, l5: 0.233761, l6: 0.253653

[epoch:   3/100000, batch:   100/  187, ite: 238] train loss: 1.295615, tar: 0.243691 
l0: 0.156420, l1: 0.198690, l2: 0.152252, l3: 0.154375, l4: 0.151100, l5: 0.191365, l6: 0.202779

[epoch:   3/100000, batch:   102/  187, ite: 239] train loss: 1.295244, tar: 0.243326 
l0: 0.168048, l1: 0.236290, l2: 0.180160, l3: 0.167374, l4: 0.193959, l5: 0.190251, l6: 0.164753

[epoch:   3/100000, batch:   104/  187, ite: 240] train loss: 1.295267, tar: 0.243012 
l0: 0.241632, l1: 0.337879, l2: 0.205534, l3: 0.198306, l4: 0.193075, l5: 0.445890, l6: 0.196150

[epoch:   3/100000, batch:   106/  187, ite: 241] train loss: 1.297438, tar: 0.243006 
l0: 0.211065, l1: 0.256643, l2: 0.182684, l3: 0.191001, l4: 0.204033, l5: 0.228439, l6: 0.202910

[epoch:   3/100000, batch:   108/  187, ite: 242] train loss: 1.298179, tar: 0.242874 
l0: 0.154316, l1: 0.112272, l2: 0.120497, l3: 0.107918, l4: 0.096213, l5: 0.159970, l6: 0.153411

[epoch:   3/100000, batch:   110/  187, ite: 243] train loss: 1.296560, tar: 0.242510 
l0: 0.230331, l1: 0.284863, l2: 0.209131, l3: 0.234370, l4: 0.229200, l5: 0.413035, l6: 0.248045

[epoch:   3/100000, batch:   112/  187, ite: 244] train loss: 1.298824, tar: 0.242460 
l0: 0.193588, l1: 0.241931, l2: 0.153949, l3: 0.142722, l4: 0.136823, l5: 0.152165, l6: 0.151693

[epoch:   3/100000, batch:   114/  187, ite: 245] train loss: 1.298310, tar: 0.242261 
l0: 0.180080, l1: 0.185862, l2: 0.156322, l3: 0.171517, l4: 0.162698, l5: 0.216558, l6: 0.179550

[epoch:   3/100000, batch:   116/  187, ite: 246] train loss: 1.298124, tar: 0.242008 
l0: 0.151097, l1: 0.147815, l2: 0.148594, l3: 0.162331, l4: 0.145278, l5: 0.139955, l6: 0.130837

[epoch:   3/100000, batch:   118/  187, ite: 247] train loss: 1.297022, tar: 0.241640 
l0: 0.286290, l1: 0.382565, l2: 0.231675, l3: 0.248663, l4: 0.249816, l5: 0.763755, l6: 0.285450

[epoch:   3/100000, batch:   120/  187, ite: 248] train loss: 1.301664, tar: 0.241820 
l0: 0.185062, l1: 0.243724, l2: 0.169128, l3: 0.185650, l4: 0.166150, l5: 0.216192, l6: 0.257506

[epoch:   3/100000, batch:   122/  187, ite: 249] train loss: 1.302153, tar: 0.241592 
l0: 0.107134, l1: 0.044213, l2: 0.085697, l3: 0.058561, l4: 0.089178, l5: 0.052191, l6: 0.057570

[epoch:   3/100000, batch:   124/  187, ite: 250] train loss: 1.298922, tar: 0.241054 
l0: 0.129227, l1: 0.102516, l2: 0.120792, l3: 0.128525, l4: 0.127951, l5: 0.164379, l6: 0.108484

[epoch:   3/100000, batch:   126/  187, ite: 251] train loss: 1.297261, tar: 0.240609 
l0: 0.168913, l1: 0.184264, l2: 0.163107, l3: 0.165293, l4: 0.169878, l5: 0.169409, l6: 0.174875

[epoch:   3/100000, batch:   128/  187, ite: 252] train loss: 1.296858, tar: 0.240324 
l0: 0.150020, l1: 0.105002, l2: 0.113777, l3: 0.098289, l4: 0.104178, l5: 0.104896, l6: 0.117088

[epoch:   3/100000, batch:   130/  187, ite: 253] train loss: 1.294867, tar: 0.239967 
l0: 0.203911, l1: 0.294818, l2: 0.178397, l3: 0.176565, l4: 0.187035, l5: 0.190524, l6: 0.175767

[epoch:   3/100000, batch:   132/  187, ite: 254] train loss: 1.295309, tar: 0.239825 
l0: 0.178049, l1: 0.177903, l2: 0.158039, l3: 0.169159, l4: 0.173306, l5: 0.193839, l6: 0.161429

[epoch:   3/100000, batch:   134/  187, ite: 255] train loss: 1.294981, tar: 0.239583 
l0: 0.185921, l1: 0.215412, l2: 0.171353, l3: 0.172038, l4: 0.159837, l5: 0.179341, l6: 0.168697

[epoch:   3/100000, batch:   136/  187, ite: 256] train loss: 1.294815, tar: 0.239373 
l0: 0.176251, l1: 0.148883, l2: 0.139585, l3: 0.128256, l4: 0.120023, l5: 0.164191, l6: 0.122280

[epoch:   3/100000, batch:   138/  187, ite: 257] train loss: 1.293666, tar: 0.239128 
l0: 0.205936, l1: 0.241941, l2: 0.204483, l3: 0.181883, l4: 0.174254, l5: 0.219464, l6: 0.190428

[epoch:   3/100000, batch:   140/  187, ite: 258] train loss: 1.294150, tar: 0.238999 
l0: 0.176964, l1: 0.142529, l2: 0.137864, l3: 0.131079, l4: 0.144360, l5: 0.161708, l6: 0.134101

[epoch:   3/100000, batch:   142/  187, ite: 259] train loss: 1.293124, tar: 0.238759 
l0: 0.208392, l1: 0.208993, l2: 0.186745, l3: 0.196032, l4: 0.210724, l5: 0.212932, l6: 0.215127

[epoch:   3/100000, batch:   144/  187, ite: 260] train loss: 1.293685, tar: 0.238643 
l0: 0.176994, l1: 0.128238, l2: 0.128142, l3: 0.124514, l4: 0.120772, l5: 0.121365, l6: 0.121365

[epoch:   3/100000, batch:   146/  187, ite: 261] train loss: 1.292259, tar: 0.238406 
l0: 0.155235, l1: 0.066928, l2: 0.092216, l3: 0.078123, l4: 0.079566, l5: 0.091374, l6: 0.077109

[epoch:   3/100000, batch:   148/  187, ite: 262] train loss: 1.289771, tar: 0.238089 
l0: 0.201281, l1: 0.173606, l2: 0.154444, l3: 0.155255, l4: 0.146724, l5: 0.189985, l6: 0.152663

[epoch:   3/100000, batch:   150/  187, ite: 263] train loss: 1.289331, tar: 0.237949 
l0: 0.151303, l1: 0.098384, l2: 0.098993, l3: 0.089912, l4: 0.096173, l5: 0.094671, l6: 0.094312

[epoch:   3/100000, batch:   152/  187, ite: 264] train loss: 1.287189, tar: 0.237621 
l0: 0.195955, l1: 0.222033, l2: 0.184168, l3: 0.197639, l4: 0.190272, l5: 0.201625, l6: 0.183913

[epoch:   3/100000, batch:   154/  187, ite: 265] train loss: 1.287522, tar: 0.237464 
l0: 0.140780, l1: 0.116751, l2: 0.116630, l3: 0.115890, l4: 0.119597, l5: 0.114010, l6: 0.115026

[epoch:   3/100000, batch:   156/  187, ite: 266] train loss: 1.285835, tar: 0.237100 
l0: 0.141237, l1: 0.103654, l2: 0.116883, l3: 0.092292, l4: 0.128172, l5: 0.106253, l6: 0.098408

[epoch:   3/100000, batch:   158/  187, ite: 267] train loss: 1.283966, tar: 0.236741 
l0: 0.172242, l1: 0.211396, l2: 0.160176, l3: 0.157792, l4: 0.169110, l5: 0.149645, l6: 0.172236

[epoch:   3/100000, batch:   160/  187, ite: 268] train loss: 1.283625, tar: 0.236500 
l0: 0.158659, l1: 0.172167, l2: 0.142980, l3: 0.161866, l4: 0.152917, l5: 0.181987, l6: 0.181085

[epoch:   3/100000, batch:   162/  187, ite: 269] train loss: 1.283135, tar: 0.236211 
l0: 0.093466, l1: 0.033423, l2: 0.061305, l3: 0.053718, l4: 0.077870, l5: 0.041178, l6: 0.077149

[epoch:   3/100000, batch:   164/  187, ite: 270] train loss: 1.280005, tar: 0.235682 
l0: 0.168297, l1: 0.203853, l2: 0.169221, l3: 0.180069, l4: 0.179361, l5: 0.190345, l6: 0.170189

[epoch:   3/100000, batch:   166/  187, ite: 271] train loss: 1.279936, tar: 0.235434 
l0: 0.202637, l1: 0.277447, l2: 0.193743, l3: 0.208417, l4: 0.210885, l5: 0.352411, l6: 0.262366

[epoch:   3/100000, batch:   168/  187, ite: 272] train loss: 1.281509, tar: 0.235313 
l0: 0.167381, l1: 0.173440, l2: 0.146293, l3: 0.147586, l4: 0.141609, l5: 0.163739, l6: 0.152606

[epoch:   3/100000, batch:   170/  187, ite: 273] train loss: 1.280818, tar: 0.235064 
l0: 0.159316, l1: 0.153360, l2: 0.132073, l3: 0.127959, l4: 0.133302, l5: 0.131844, l6: 0.126593

[epoch:   3/100000, batch:   172/  187, ite: 274] train loss: 1.279663, tar: 0.234788 
l0: 0.174982, l1: 0.206129, l2: 0.164053, l3: 0.170988, l4: 0.166265, l5: 0.145161, l6: 0.120206

[epoch:   3/100000, batch:   174/  187, ite: 275] train loss: 1.279183, tar: 0.234570 
l0: 0.193079, l1: 0.244908, l2: 0.170546, l3: 0.164809, l4: 0.169451, l5: 0.173034, l6: 0.184847

[epoch:   3/100000, batch:   176/  187, ite: 276] train loss: 1.279261, tar: 0.234420 
l0: 0.138591, l1: 0.096245, l2: 0.101862, l3: 0.094965, l4: 0.106147, l5: 0.094996, l6: 0.098464

[epoch:   3/100000, batch:   178/  187, ite: 277] train loss: 1.277283, tar: 0.234074 
l0: 0.168021, l1: 0.173207, l2: 0.133516, l3: 0.138813, l4: 0.141746, l5: 0.126203, l6: 0.110778

[epoch:   3/100000, batch:   180/  187, ite: 278] train loss: 1.276258, tar: 0.233837 
l0: 0.153305, l1: 0.149245, l2: 0.131598, l3: 0.139792, l4: 0.131696, l5: 0.151590, l6: 0.122109

[epoch:   3/100000, batch:   182/  187, ite: 279] train loss: 1.275194, tar: 0.233548 
l0: 0.180149, l1: 0.208591, l2: 0.157457, l3: 0.169374, l4: 0.164856, l5: 0.186777, l6: 0.183557

[epoch:   3/100000, batch:   184/  187, ite: 280] train loss: 1.275106, tar: 0.233357 
l0: 0.168343, l1: 0.194175, l2: 0.159870, l3: 0.171274, l4: 0.185652, l5: 0.137209, l6: 0.171860

[epoch:   3/100000, batch:   186/  187, ite: 281] train loss: 1.274798, tar: 0.233126 
l0: 0.125203, l1: 0.055877, l2: 0.079069, l3: 0.063115, l4: 0.071457, l5: 0.085876, l6: 0.094873

[epoch:   3/100000, batch:   188/  187, ite: 282] train loss: 1.272318, tar: 0.232743 
l0: 0.156245, l1: 0.149383, l2: 0.130714, l3: 0.129430, l4: 0.136727, l5: 0.123826, l6: 0.135138

[epoch:   4/100000, batch:     2/  187, ite: 283] train loss: 1.271219, tar: 0.232473 
l0: 0.100816, l1: 0.029554, l2: 0.056166, l3: 0.038078, l4: 0.057028, l5: 0.039822, l6: 0.063375

[epoch:   4/100000, batch:     4/  187, ite: 284] train loss: 1.268098, tar: 0.232009 
l0: 0.172573, l1: 0.236237, l2: 0.182844, l3: 0.190226, l4: 0.181442, l5: 0.185269, l6: 0.191250

[epoch:   4/100000, batch:     6/  187, ite: 285] train loss: 1.268350, tar: 0.231801 
l0: 0.148111, l1: 0.165138, l2: 0.132521, l3: 0.133357, l4: 0.130596, l5: 0.141375, l6: 0.169237

[epoch:   4/100000, batch:     8/  187, ite: 286] train loss: 1.267483, tar: 0.231508 
l0: 0.159684, l1: 0.172430, l2: 0.161970, l3: 0.168496, l4: 0.153423, l5: 0.132002, l6: 0.123005

[epoch:   4/100000, batch:    10/  187, ite: 287] train loss: 1.266798, tar: 0.231258 
l0: 0.184070, l1: 0.249242, l2: 0.188263, l3: 0.205646, l4: 0.180967, l5: 0.244754, l6: 0.206430

[epoch:   4/100000, batch:    12/  187, ite: 288] train loss: 1.267467, tar: 0.231094 
l0: 0.116923, l1: 0.080914, l2: 0.095036, l3: 0.087015, l4: 0.108920, l5: 0.099540, l6: 0.114668

[epoch:   4/100000, batch:    14/  187, ite: 289] train loss: 1.265514, tar: 0.230699 
l0: 0.134192, l1: 0.089937, l2: 0.104253, l3: 0.109490, l4: 0.107420, l5: 0.116208, l6: 0.118617

[epoch:   4/100000, batch:    16/  187, ite: 290] train loss: 1.263840, tar: 0.230366 
l0: 0.168072, l1: 0.186998, l2: 0.154086, l3: 0.161133, l4: 0.179828, l5: 0.200231, l6: 0.176961

[epoch:   4/100000, batch:    18/  187, ite: 291] train loss: 1.263715, tar: 0.230152 
l0: 0.209695, l1: 0.296282, l2: 0.215948, l3: 0.218682, l4: 0.210570, l5: 0.284661, l6: 0.272859

[epoch:   4/100000, batch:    20/  187, ite: 292] train loss: 1.265238, tar: 0.230082 
l0: 0.158064, l1: 0.166631, l2: 0.137387, l3: 0.131683, l4: 0.143643, l5: 0.139128, l6: 0.142096

[epoch:   4/100000, batch:    22/  187, ite: 293] train loss: 1.264397, tar: 0.229836 
l0: 0.132139, l1: 0.108393, l2: 0.116433, l3: 0.108816, l4: 0.122776, l5: 0.125031, l6: 0.135350

[epoch:   4/100000, batch:    24/  187, ite: 294] train loss: 1.262984, tar: 0.229504 
l0: 0.158992, l1: 0.126127, l2: 0.138289, l3: 0.120100, l4: 0.119809, l5: 0.113762, l6: 0.097992

[epoch:   4/100000, batch:    26/  187, ite: 295] train loss: 1.261669, tar: 0.229265 
l0: 0.159649, l1: 0.149822, l2: 0.139253, l3: 0.126780, l4: 0.135932, l5: 0.133381, l6: 0.133546

[epoch:   4/100000, batch:    28/  187, ite: 296] train loss: 1.260712, tar: 0.229030 
l0: 0.153243, l1: 0.140755, l2: 0.135079, l3: 0.132089, l4: 0.153824, l5: 0.130521, l6: 0.115370

[epoch:   4/100000, batch:    30/  187, ite: 297] train loss: 1.259702, tar: 0.228774 
l0: 0.180198, l1: 0.208908, l2: 0.172999, l3: 0.166442, l4: 0.157832, l5: 0.149835, l6: 0.132113

[epoch:   4/100000, batch:    32/  187, ite: 298] train loss: 1.259395, tar: 0.228611 
l0: 0.192737, l1: 0.229470, l2: 0.177835, l3: 0.177831, l4: 0.173813, l5: 0.160724, l6: 0.149678

[epoch:   4/100000, batch:    34/  187, ite: 299] train loss: 1.259404, tar: 0.228491 
l0: 0.188963, l1: 0.206297, l2: 0.181533, l3: 0.184103, l4: 0.183507, l5: 0.169096, l6: 0.183632

[epoch:   4/100000, batch:    36/  187, ite: 300] train loss: 1.259530, tar: 0.228360 
l0: 0.164813, l1: 0.152688, l2: 0.145615, l3: 0.157274, l4: 0.153301, l5: 0.151598, l6: 0.133888

[epoch:   4/100000, batch:    38/  187, ite: 301] train loss: 1.258865, tar: 0.228149 
l0: 0.182301, l1: 0.188274, l2: 0.169867, l3: 0.175892, l4: 0.159584, l5: 0.170565, l6: 0.176250

[epoch:   4/100000, batch:    40/  187, ite: 302] train loss: 1.258745, tar: 0.227997 
l0: 0.163708, l1: 0.127338, l2: 0.143484, l3: 0.140737, l4: 0.136716, l5: 0.124090, l6: 0.124525

[epoch:   4/100000, batch:    42/  187, ite: 303] train loss: 1.257761, tar: 0.227785 
l0: 0.178413, l1: 0.180718, l2: 0.170019, l3: 0.172533, l4: 0.181676, l5: 0.162934, l6: 0.151642

[epoch:   4/100000, batch:    44/  187, ite: 304] train loss: 1.257564, tar: 0.227622 
l0: 0.175773, l1: 0.156371, l2: 0.149768, l3: 0.143371, l4: 0.145048, l5: 0.147437, l6: 0.158544

[epoch:   4/100000, batch:    46/  187, ite: 305] train loss: 1.256970, tar: 0.227452 
l0: 0.148187, l1: 0.113878, l2: 0.128329, l3: 0.123794, l4: 0.127405, l5: 0.112922, l6: 0.107188

[epoch:   4/100000, batch:    48/  187, ite: 306] train loss: 1.255678, tar: 0.227193 
l0: 0.150045, l1: 0.112148, l2: 0.121479, l3: 0.117577, l4: 0.126115, l5: 0.123682, l6: 0.123771

[epoch:   4/100000, batch:    50/  187, ite: 307] train loss: 1.254438, tar: 0.226942 
l0: 0.146908, l1: 0.111937, l2: 0.125905, l3: 0.134772, l4: 0.134629, l5: 0.142256, l6: 0.147664

[epoch:   4/100000, batch:    52/  187, ite: 308] train loss: 1.253430, tar: 0.226682 
l0: 0.146392, l1: 0.087589, l2: 0.109951, l3: 0.095822, l4: 0.113890, l5: 0.092654, l6: 0.081533

[epoch:   4/100000, batch:    54/  187, ite: 309] train loss: 1.251729, tar: 0.226422 
l0: 0.142404, l1: 0.120810, l2: 0.123528, l3: 0.115700, l4: 0.120278, l5: 0.112830, l6: 0.117350

[epoch:   4/100000, batch:    56/  187, ite: 310] train loss: 1.250442, tar: 0.226151 
l0: 0.129714, l1: 0.089728, l2: 0.098260, l3: 0.095263, l4: 0.091530, l5: 0.093203, l6: 0.104089

[epoch:   4/100000, batch:    58/  187, ite: 311] train loss: 1.248678, tar: 0.225841 
l0: 0.170323, l1: 0.157657, l2: 0.161604, l3: 0.173173, l4: 0.167477, l5: 0.164737, l6: 0.174506

[epoch:   4/100000, batch:    60/  187, ite: 312] train loss: 1.248424, tar: 0.225663 
l0: 0.140277, l1: 0.139491, l2: 0.138605, l3: 0.153179, l4: 0.145466, l5: 0.190131, l6: 0.149310

[epoch:   4/100000, batch:    62/  187, ite: 313] train loss: 1.247811, tar: 0.225390 
l0: 0.177345, l1: 0.242551, l2: 0.206363, l3: 0.214793, l4: 0.224801, l5: 0.249725, l6: 0.228308

[epoch:   4/100000, batch:    64/  187, ite: 314] train loss: 1.248754, tar: 0.225237 
l0: 0.160477, l1: 0.194331, l2: 0.152400, l3: 0.152413, l4: 0.163171, l5: 0.201887, l6: 0.234363

[epoch:   4/100000, batch:    66/  187, ite: 315] train loss: 1.248787, tar: 0.225032 
l0: 0.128788, l1: 0.125684, l2: 0.118783, l3: 0.123969, l4: 0.111398, l5: 0.111240, l6: 0.129868

[epoch:   4/100000, batch:    68/  187, ite: 316] train loss: 1.247524, tar: 0.224727 
l0: 0.139575, l1: 0.131122, l2: 0.132307, l3: 0.125545, l4: 0.131806, l5: 0.119514, l6: 0.111767

[epoch:   4/100000, batch:    70/  187, ite: 317] train loss: 1.246401, tar: 0.224459 
l0: 0.168869, l1: 0.209405, l2: 0.183765, l3: 0.193684, l4: 0.197944, l5: 0.209170, l6: 0.180046

[epoch:   4/100000, batch:    72/  187, ite: 318] train loss: 1.246705, tar: 0.224284 
l0: 0.120733, l1: 0.107623, l2: 0.112446, l3: 0.116627, l4: 0.108323, l5: 0.104014, l6: 0.128521

[epoch:   4/100000, batch:    74/  187, ite: 319] train loss: 1.245299, tar: 0.223959 
l0: 0.149788, l1: 0.156256, l2: 0.137405, l3: 0.137753, l4: 0.138748, l5: 0.112545, l6: 0.143756

[epoch:   4/100000, batch:    76/  187, ite: 320] train loss: 1.244458, tar: 0.223727 
l0: 0.128483, l1: 0.122428, l2: 0.122394, l3: 0.122910, l4: 0.126782, l5: 0.117186, l6: 0.103491

[epoch:   4/100000, batch:    78/  187, ite: 321] train loss: 1.243210, tar: 0.223431 
l0: 0.092468, l1: 0.052159, l2: 0.078473, l3: 0.071315, l4: 0.065253, l5: 0.072115, l6: 0.054443

[epoch:   4/100000, batch:    80/  187, ite: 322] train loss: 1.240859, tar: 0.223024 
l0: 0.173735, l1: 0.204365, l2: 0.162027, l3: 0.169614, l4: 0.154873, l5: 0.149099, l6: 0.145657

[epoch:   4/100000, batch:    82/  187, ite: 323] train loss: 1.240606, tar: 0.222871 
l0: 0.134829, l1: 0.131386, l2: 0.124785, l3: 0.121900, l4: 0.141619, l5: 0.130658, l6: 0.127004

[epoch:   4/100000, batch:    84/  187, ite: 324] train loss: 1.239593, tar: 0.222600 
l0: 0.124148, l1: 0.122492, l2: 0.117973, l3: 0.117605, l4: 0.122383, l5: 0.096625, l6: 0.102900

[epoch:   4/100000, batch:    86/  187, ite: 325] train loss: 1.238253, tar: 0.222297 
l0: 0.109262, l1: 0.058978, l2: 0.079531, l3: 0.077638, l4: 0.090304, l5: 0.079268, l6: 0.091952

[epoch:   4/100000, batch:    88/  187, ite: 326] train loss: 1.236255, tar: 0.221950 
l0: 0.146186, l1: 0.166520, l2: 0.123432, l3: 0.124144, l4: 0.121169, l5: 0.134462, l6: 0.114148

[epoch:   4/100000, batch:    90/  187, ite: 327] train loss: 1.235318, tar: 0.221718 
l0: 0.139049, l1: 0.137731, l2: 0.130945, l3: 0.132819, l4: 0.134580, l5: 0.163922, l6: 0.148375

[epoch:   4/100000, batch:    92/  187, ite: 328] train loss: 1.234563, tar: 0.221466 
l0: 0.131608, l1: 0.142680, l2: 0.103526, l3: 0.100204, l4: 0.098419, l5: 0.087432, l6: 0.085327

[epoch:   4/100000, batch:    94/  187, ite: 329] train loss: 1.233087, tar: 0.221193 
l0: 0.108152, l1: 0.095536, l2: 0.100088, l3: 0.105678, l4: 0.099520, l5: 0.088909, l6: 0.091934

[epoch:   4/100000, batch:    96/  187, ite: 330] train loss: 1.231441, tar: 0.220851 
l0: 0.163840, l1: 0.226096, l2: 0.169049, l3: 0.173674, l4: 0.164326, l5: 0.183742, l6: 0.190799

[epoch:   4/100000, batch:    98/  187, ite: 331] train loss: 1.231562, tar: 0.220678 
l0: 0.112875, l1: 0.089065, l2: 0.099849, l3: 0.099915, l4: 0.103108, l5: 0.110974, l6: 0.113810

[epoch:   4/100000, batch:   100/  187, ite: 332] train loss: 1.230050, tar: 0.220354 
l0: 0.111749, l1: 0.096900, l2: 0.096804, l3: 0.096858, l4: 0.096000, l5: 0.084840, l6: 0.099461

[epoch:   4/100000, batch:   102/  187, ite: 333] train loss: 1.228406, tar: 0.220027 
l0: 0.141595, l1: 0.145135, l2: 0.129508, l3: 0.132520, l4: 0.128309, l5: 0.122935, l6: 0.116470

[epoch:   4/100000, batch:   104/  187, ite: 334] train loss: 1.227472, tar: 0.219793 
l0: 0.133207, l1: 0.129586, l2: 0.133278, l3: 0.139362, l4: 0.129818, l5: 0.146128, l6: 0.119762

[epoch:   4/100000, batch:   106/  187, ite: 335] train loss: 1.226588, tar: 0.219534 
l0: 0.134037, l1: 0.101465, l2: 0.123436, l3: 0.111000, l4: 0.108510, l5: 0.109180, l6: 0.127056

[epoch:   4/100000, batch:   108/  187, ite: 336] train loss: 1.225362, tar: 0.219280 
l0: 0.188625, l1: 0.242838, l2: 0.194588, l3: 0.210070, l4: 0.198738, l5: 0.266744, l6: 0.228688

[epoch:   4/100000, batch:   110/  187, ite: 337] train loss: 1.226267, tar: 0.219189 
l0: 0.108162, l1: 0.093890, l2: 0.106065, l3: 0.101779, l4: 0.101434, l5: 0.107810, l6: 0.100022

[epoch:   4/100000, batch:   112/  187, ite: 338] train loss: 1.224766, tar: 0.218860 
l0: 0.128790, l1: 0.131851, l2: 0.132091, l3: 0.133313, l4: 0.142373, l5: 0.122990, l6: 0.121490

[epoch:   4/100000, batch:   114/  187, ite: 339] train loss: 1.223846, tar: 0.218595 
l0: 0.134149, l1: 0.145745, l2: 0.141090, l3: 0.135789, l4: 0.147458, l5: 0.123398, l6: 0.112976

[epoch:   4/100000, batch:   116/  187, ite: 340] train loss: 1.223013, tar: 0.218346 
l0: 0.132059, l1: 0.153025, l2: 0.129749, l3: 0.138054, l4: 0.134455, l5: 0.119270, l6: 0.116413

[epoch:   4/100000, batch:   118/  187, ite: 341] train loss: 1.222134, tar: 0.218093 
l0: 0.164351, l1: 0.198002, l2: 0.173686, l3: 0.177216, l4: 0.169141, l5: 0.178888, l6: 0.173981

[epoch:   4/100000, batch:   120/  187, ite: 342] train loss: 1.222172, tar: 0.217936 
l0: 0.167351, l1: 0.200388, l2: 0.155748, l3: 0.154561, l4: 0.157747, l5: 0.159882, l6: 0.182193

[epoch:   4/100000, batch:   122/  187, ite: 343] train loss: 1.222043, tar: 0.217789 
l0: 0.132709, l1: 0.128011, l2: 0.129645, l3: 0.135517, l4: 0.127821, l5: 0.133133, l6: 0.140851

[epoch:   4/100000, batch:   124/  187, ite: 344] train loss: 1.221187, tar: 0.217541 
l0: 0.145322, l1: 0.144937, l2: 0.153479, l3: 0.143913, l4: 0.149406, l5: 0.148678, l6: 0.151917

[epoch:   4/100000, batch:   126/  187, ite: 345] train loss: 1.220655, tar: 0.217332 
l0: 0.165101, l1: 0.176771, l2: 0.166688, l3: 0.168754, l4: 0.169541, l5: 0.181611, l6: 0.204437

[epoch:   4/100000, batch:   128/  187, ite: 346] train loss: 1.220691, tar: 0.217181 
l0: 0.147340, l1: 0.145575, l2: 0.143242, l3: 0.132971, l4: 0.134640, l5: 0.147025, l6: 0.128312

[epoch:   4/100000, batch:   130/  187, ite: 347] train loss: 1.219994, tar: 0.216980 
l0: 0.104285, l1: 0.059632, l2: 0.083168, l3: 0.078531, l4: 0.083595, l5: 0.092678, l6: 0.066796

[epoch:   4/100000, batch:   132/  187, ite: 348] train loss: 1.218123, tar: 0.216656 
l0: 0.168109, l1: 0.172487, l2: 0.161631, l3: 0.170387, l4: 0.155589, l5: 0.152334, l6: 0.165327

[epoch:   4/100000, batch:   134/  187, ite: 349] train loss: 1.217916, tar: 0.216517 
l0: 0.180861, l1: 0.220684, l2: 0.170556, l3: 0.181888, l4: 0.189676, l5: 0.188909, l6: 0.232817

[epoch:   4/100000, batch:   136/  187, ite: 350] train loss: 1.218337, tar: 0.216415 
l0: 0.153505, l1: 0.145524, l2: 0.151809, l3: 0.161197, l4: 0.155175, l5: 0.150038, l6: 0.225514

[epoch:   4/100000, batch:   138/  187, ite: 351] train loss: 1.218122, tar: 0.216236 
l0: 0.135576, l1: 0.116219, l2: 0.129814, l3: 0.126860, l4: 0.135172, l5: 0.125811, l6: 0.146443

[epoch:   4/100000, batch:   140/  187, ite: 352] train loss: 1.217263, tar: 0.216006 
l0: 0.117018, l1: 0.084315, l2: 0.094018, l3: 0.091850, l4: 0.093538, l5: 0.068471, l6: 0.066992

[epoch:   4/100000, batch:   142/  187, ite: 353] train loss: 1.215561, tar: 0.215726 
l0: 0.124171, l1: 0.094444, l2: 0.089025, l3: 0.082647, l4: 0.092383, l5: 0.079817, l6: 0.099236

[epoch:   4/100000, batch:   144/  187, ite: 354] train loss: 1.213996, tar: 0.215467 
l0: 0.176608, l1: 0.181812, l2: 0.180291, l3: 0.193760, l4: 0.182406, l5: 0.192890, l6: 0.170048

[epoch:   4/100000, batch:   146/  187, ite: 355] train loss: 1.214176, tar: 0.215358 
l0: 0.132171, l1: 0.107861, l2: 0.111430, l3: 0.113069, l4: 0.116118, l5: 0.132272, l6: 0.122601

[epoch:   4/100000, batch:   148/  187, ite: 356] train loss: 1.213112, tar: 0.215124 
l0: 0.141271, l1: 0.132338, l2: 0.127882, l3: 0.127770, l4: 0.138699, l5: 0.133268, l6: 0.118541

[epoch:   4/100000, batch:   150/  187, ite: 357] train loss: 1.212290, tar: 0.214917 
l0: 0.135198, l1: 0.118233, l2: 0.126510, l3: 0.128425, l4: 0.131593, l5: 0.121583, l6: 0.132935

[epoch:   4/100000, batch:   152/  187, ite: 358] train loss: 1.211403, tar: 0.214695 
l0: 0.204739, l1: 0.266118, l2: 0.219303, l3: 0.214936, l4: 0.238584, l5: 0.272453, l6: 0.259932

[epoch:   4/100000, batch:   154/  187, ite: 359] train loss: 1.212697, tar: 0.214667 
l0: 0.127016, l1: 0.098915, l2: 0.109669, l3: 0.102705, l4: 0.113971, l5: 0.112713, l6: 0.114432

[epoch:   4/100000, batch:   156/  187, ite: 360] train loss: 1.211493, tar: 0.214423 
l0: 0.146350, l1: 0.140466, l2: 0.131919, l3: 0.130686, l4: 0.123930, l5: 0.134555, l6: 0.132436

[epoch:   4/100000, batch:   158/  187, ite: 361] train loss: 1.210742, tar: 0.214235 
l0: 0.152297, l1: 0.153788, l2: 0.136870, l3: 0.126621, l4: 0.142971, l5: 0.131227, l6: 0.136693

[epoch:   4/100000, batch:   160/  187, ite: 362] train loss: 1.210106, tar: 0.214064 
l0: 0.139679, l1: 0.122991, l2: 0.126865, l3: 0.134336, l4: 0.165085, l5: 0.180919, l6: 0.156497

[epoch:   4/100000, batch:   162/  187, ite: 363] train loss: 1.209600, tar: 0.213859 
l0: 0.129092, l1: 0.125126, l2: 0.112954, l3: 0.117878, l4: 0.120073, l5: 0.102690, l6: 0.107331

[epoch:   4/100000, batch:   164/  187, ite: 364] train loss: 1.208516, tar: 0.213626 
l0: 0.155996, l1: 0.163923, l2: 0.144786, l3: 0.128280, l4: 0.153501, l5: 0.145204, l6: 0.136716

[epoch:   4/100000, batch:   166/  187, ite: 365] train loss: 1.208023, tar: 0.213468 
l0: 0.123886, l1: 0.108796, l2: 0.098538, l3: 0.101539, l4: 0.105745, l5: 0.095957, l6: 0.090163

[epoch:   4/100000, batch:   168/  187, ite: 366] train loss: 1.206702, tar: 0.213223 
l0: 0.141400, l1: 0.139299, l2: 0.133168, l3: 0.128603, l4: 0.139491, l5: 0.123816, l6: 0.125181

[epoch:   4/100000, batch:   170/  187, ite: 367] train loss: 1.205951, tar: 0.213028 
l0: 0.096968, l1: 0.066431, l2: 0.075124, l3: 0.071069, l4: 0.076104, l5: 0.087876, l6: 0.104363

[epoch:   4/100000, batch:   172/  187, ite: 368] train loss: 1.204244, tar: 0.212712 
l0: 0.116002, l1: 0.102440, l2: 0.112254, l3: 0.109039, l4: 0.099059, l5: 0.110078, l6: 0.126644

[epoch:   4/100000, batch:   174/  187, ite: 369] train loss: 1.203082, tar: 0.212450 
l0: 0.140433, l1: 0.159526, l2: 0.157537, l3: 0.163781, l4: 0.151364, l5: 0.124864, l6: 0.131037

[epoch:   4/100000, batch:   176/  187, ite: 370] train loss: 1.202611, tar: 0.212256 
l0: 0.107690, l1: 0.096996, l2: 0.095650, l3: 0.086569, l4: 0.100080, l5: 0.095336, l6: 0.085714

[epoch:   4/100000, batch:   178/  187, ite: 371] train loss: 1.201170, tar: 0.211974 
l0: 0.134458, l1: 0.146576, l2: 0.140159, l3: 0.165762, l4: 0.141642, l5: 0.201048, l6: 0.239303

[epoch:   4/100000, batch:   180/  187, ite: 372] train loss: 1.201083, tar: 0.211765 
l0: 0.123452, l1: 0.119229, l2: 0.118870, l3: 0.122592, l4: 0.146956, l5: 0.133064, l6: 0.117888

[epoch:   4/100000, batch:   182/  187, ite: 373] train loss: 1.200228, tar: 0.211529 
l0: 0.159524, l1: 0.200188, l2: 0.159980, l3: 0.176111, l4: 0.200338, l5: 0.178830, l6: 0.212675

[epoch:   4/100000, batch:   184/  187, ite: 374] train loss: 1.200462, tar: 0.211390 
l0: 0.128081, l1: 0.141739, l2: 0.141216, l3: 0.139676, l4: 0.148656, l5: 0.129789, l6: 0.139617

[epoch:   4/100000, batch:   186/  187, ite: 375] train loss: 1.199844, tar: 0.211167 
l0: 0.101894, l1: 0.071015, l2: 0.088316, l3: 0.087145, l4: 0.065077, l5: 0.073668, l6: 0.086658

[epoch:   4/100000, batch:   188/  187, ite: 376] train loss: 1.198179, tar: 0.210877 
l0: 0.160201, l1: 0.200214, l2: 0.159875, l3: 0.163595, l4: 0.149687, l5: 0.154655, l6: 0.137081

[epoch:   5/100000, batch:     2/  187, ite: 377] train loss: 1.197985, tar: 0.210742 
l0: 0.126480, l1: 0.113696, l2: 0.123562, l3: 0.128234, l4: 0.162386, l5: 0.129293, l6: 0.153258

[epoch:   5/100000, batch:     4/  187, ite: 378] train loss: 1.197295, tar: 0.210519 
l0: 0.174273, l1: 0.220773, l2: 0.208552, l3: 0.213032, l4: 0.179065, l5: 0.141874, l6: 0.190196

[epoch:   5/100000, batch:     6/  187, ite: 379] train loss: 1.197639, tar: 0.210424 
l0: 0.147020, l1: 0.160979, l2: 0.149378, l3: 0.145738, l4: 0.174750, l5: 0.140045, l6: 0.156916

[epoch:   5/100000, batch:     8/  187, ite: 380] train loss: 1.197316, tar: 0.210257 
l0: 0.122380, l1: 0.093134, l2: 0.104889, l3: 0.101913, l4: 0.132483, l5: 0.143278, l6: 0.141321

[epoch:   5/100000, batch:    10/  187, ite: 381] train loss: 1.196376, tar: 0.210026 
l0: 0.096600, l1: 0.073948, l2: 0.081660, l3: 0.075175, l4: 0.100283, l5: 0.077335, l6: 0.077301

[epoch:   5/100000, batch:    12/  187, ite: 382] train loss: 1.194769, tar: 0.209729 
l0: 0.130852, l1: 0.133805, l2: 0.124079, l3: 0.121502, l4: 0.124583, l5: 0.114163, l6: 0.103010

[epoch:   5/100000, batch:    14/  187, ite: 383] train loss: 1.193874, tar: 0.209523 
l0: 0.139397, l1: 0.142223, l2: 0.157662, l3: 0.161341, l4: 0.152779, l5: 0.124257, l6: 0.125817

[epoch:   5/100000, batch:    16/  187, ite: 384] train loss: 1.193378, tar: 0.209341 
l0: 0.133195, l1: 0.140125, l2: 0.137093, l3: 0.138234, l4: 0.139160, l5: 0.118674, l6: 0.116136

[epoch:   5/100000, batch:    18/  187, ite: 385] train loss: 1.192675, tar: 0.209143 
l0: 0.159050, l1: 0.184603, l2: 0.173189, l3: 0.172380, l4: 0.134966, l5: 0.140050, l6: 0.145333

[epoch:   5/100000, batch:    20/  187, ite: 386] train loss: 1.192459, tar: 0.209013 
l0: 0.117358, l1: 0.105481, l2: 0.099242, l3: 0.100673, l4: 0.104412, l5: 0.098310, l6: 0.097311

[epoch:   5/100000, batch:    22/  187, ite: 387] train loss: 1.191246, tar: 0.208776 
l0: 0.098335, l1: 0.060742, l2: 0.073775, l3: 0.070345, l4: 0.066179, l5: 0.068749, l6: 0.062788

[epoch:   5/100000, batch:    24/  187, ite: 388] train loss: 1.189467, tar: 0.208492 
l0: 0.101870, l1: 0.082508, l2: 0.091036, l3: 0.088243, l4: 0.096854, l5: 0.096345, l6: 0.093243

[epoch:   5/100000, batch:    26/  187, ite: 389] train loss: 1.188080, tar: 0.208218 
l0: 0.137176, l1: 0.142052, l2: 0.140028, l3: 0.138583, l4: 0.135603, l5: 0.109561, l6: 0.135130

[epoch:   5/100000, batch:    28/  187, ite: 390] train loss: 1.187439, tar: 0.208036 
l0: 0.175828, l1: 0.220425, l2: 0.171397, l3: 0.171512, l4: 0.185526, l5: 0.168073, l6: 0.183729

[epoch:   5/100000, batch:    30/  187, ite: 391] train loss: 1.187667, tar: 0.207953 
l0: 0.138410, l1: 0.151982, l2: 0.153043, l3: 0.152751, l4: 0.149700, l5: 0.140888, l6: 0.178182

[epoch:   5/100000, batch:    32/  187, ite: 392] train loss: 1.187354, tar: 0.207776 
l0: 0.146135, l1: 0.176699, l2: 0.143499, l3: 0.143241, l4: 0.152232, l5: 0.131912, l6: 0.124442

[epoch:   5/100000, batch:    34/  187, ite: 393] train loss: 1.186923, tar: 0.207619 
l0: 0.095085, l1: 0.085472, l2: 0.082451, l3: 0.074048, l4: 0.103443, l5: 0.085846, l6: 0.144349

[epoch:   5/100000, batch:    36/  187, ite: 394] train loss: 1.185613, tar: 0.207333 
l0: 0.088716, l1: 0.064296, l2: 0.083267, l3: 0.075678, l4: 0.108268, l5: 0.084883, l6: 0.109003

[epoch:   5/100000, batch:    38/  187, ite: 395] train loss: 1.184166, tar: 0.207033 
l0: 0.126405, l1: 0.130865, l2: 0.131102, l3: 0.127549, l4: 0.121402, l5: 0.129633, l6: 0.136839

[epoch:   5/100000, batch:    40/  187, ite: 396] train loss: 1.183458, tar: 0.206829 
l0: 0.094295, l1: 0.090687, l2: 0.100241, l3: 0.091965, l4: 0.098518, l5: 0.080032, l6: 0.091240

[epoch:   5/100000, batch:    42/  187, ite: 397] train loss: 1.182107, tar: 0.206546 
l0: 0.148761, l1: 0.162994, l2: 0.148176, l3: 0.159360, l4: 0.166127, l5: 0.172507, l6: 0.208833

[epoch:   5/100000, batch:    44/  187, ite: 398] train loss: 1.182068, tar: 0.206401 
l0: 0.069186, l1: 0.042040, l2: 0.063584, l3: 0.055284, l4: 0.065641, l5: 0.048342, l6: 0.026790

[epoch:   5/100000, batch:    46/  187, ite: 399] train loss: 1.180035, tar: 0.206057 
l0: 0.129030, l1: 0.122694, l2: 0.126881, l3: 0.128840, l4: 0.133717, l5: 0.152446, l6: 0.142122

[epoch:   5/100000, batch:    48/  187, ite: 400] train loss: 1.179425, tar: 0.205864 
l0: 0.092522, l1: 0.089182, l2: 0.094559, l3: 0.093318, l4: 0.089077, l5: 0.079543, l6: 0.088100

[epoch:   5/100000, batch:    50/  187, ite: 401] train loss: 1.178045, tar: 0.205582 
l0: 0.087818, l1: 0.080062, l2: 0.080196, l3: 0.070698, l4: 0.068812, l5: 0.069202, l6: 0.058553

[epoch:   5/100000, batch:    52/  187, ite: 402] train loss: 1.176397, tar: 0.205289 
l0: 0.097696, l1: 0.077692, l2: 0.074252, l3: 0.083641, l4: 0.082873, l5: 0.116879, l6: 0.116665

[epoch:   5/100000, batch:    54/  187, ite: 403] train loss: 1.175090, tar: 0.205022 
l0: 0.113281, l1: 0.115764, l2: 0.109516, l3: 0.108801, l4: 0.140353, l5: 0.119923, l6: 0.100239

[epoch:   5/100000, batch:    56/  187, ite: 404] train loss: 1.174181, tar: 0.204795 
l0: 0.160731, l1: 0.212416, l2: 0.183042, l3: 0.182995, l4: 0.192528, l5: 0.175745, l6: 0.156354

[epoch:   5/100000, batch:    58/  187, ite: 405] train loss: 1.174402, tar: 0.204686 
l0: 0.164940, l1: 0.219794, l2: 0.191791, l3: 0.195761, l4: 0.235378, l5: 0.180264, l6: 0.159173

[epoch:   5/100000, batch:    60/  187, ite: 406] train loss: 1.174827, tar: 0.204588 
l0: 0.105083, l1: 0.100195, l2: 0.093625, l3: 0.087080, l4: 0.094068, l5: 0.089079, l6: 0.100607

[epoch:   5/100000, batch:    62/  187, ite: 407] train loss: 1.173586, tar: 0.204343 
l0: 0.143597, l1: 0.161239, l2: 0.154419, l3: 0.161712, l4: 0.139997, l5: 0.143770, l6: 0.162927

[epoch:   5/100000, batch:    64/  187, ite: 408] train loss: 1.173327, tar: 0.204195 
l0: 0.098979, l1: 0.095460, l2: 0.104804, l3: 0.105014, l4: 0.106078, l5: 0.109585, l6: 0.114719

[epoch:   5/100000, batch:    66/  187, ite: 409] train loss: 1.172254, tar: 0.203937 
l0: 0.136979, l1: 0.157127, l2: 0.152473, l3: 0.157230, l4: 0.131401, l5: 0.116286, l6: 0.104164

[epoch:   5/100000, batch:    68/  187, ite: 410] train loss: 1.171726, tar: 0.203774 
l0: 0.134135, l1: 0.155040, l2: 0.148061, l3: 0.153491, l4: 0.124941, l5: 0.109491, l6: 0.099303

[epoch:   5/100000, batch:    70/  187, ite: 411] train loss: 1.171124, tar: 0.203605 
l0: 0.133465, l1: 0.130198, l2: 0.133626, l3: 0.150041, l4: 0.129606, l5: 0.113752, l6: 0.141890

[epoch:   5/100000, batch:    72/  187, ite: 412] train loss: 1.170545, tar: 0.203434 
l0: 0.167135, l1: 0.200226, l2: 0.189325, l3: 0.204025, l4: 0.162890, l5: 0.180449, l6: 0.182930

[epoch:   5/100000, batch:    74/  187, ite: 413] train loss: 1.170827, tar: 0.203346 
l0: 0.122728, l1: 0.115083, l2: 0.107479, l3: 0.103442, l4: 0.125073, l5: 0.122828, l6: 0.139938

[epoch:   5/100000, batch:    76/  187, ite: 414] train loss: 1.170020, tar: 0.203152 
l0: 0.108109, l1: 0.086272, l2: 0.095819, l3: 0.094044, l4: 0.097088, l5: 0.082784, l6: 0.086217

[epoch:   5/100000, batch:    78/  187, ite: 415] train loss: 1.168768, tar: 0.202923 
l0: 0.129008, l1: 0.128266, l2: 0.121556, l3: 0.121491, l4: 0.138863, l5: 0.117881, l6: 0.121557

[epoch:   5/100000, batch:    80/  187, ite: 416] train loss: 1.168070, tar: 0.202745 
l0: 0.145003, l1: 0.126143, l2: 0.131674, l3: 0.128648, l4: 0.140955, l5: 0.168824, l6: 0.183670

[epoch:   5/100000, batch:    82/  187, ite: 417] train loss: 1.167727, tar: 0.202606 
l0: 0.170452, l1: 0.195505, l2: 0.204446, l3: 0.199090, l4: 0.174761, l5: 0.151613, l6: 0.161565

[epoch:   5/100000, batch:    84/  187, ite: 418] train loss: 1.167942, tar: 0.202530 
l0: 0.144069, l1: 0.145899, l2: 0.151866, l3: 0.148121, l4: 0.146805, l5: 0.134044, l6: 0.132777

[epoch:   5/100000, batch:    86/  187, ite: 419] train loss: 1.167549, tar: 0.202390 
l0: 0.073144, l1: 0.033218, l2: 0.041288, l3: 0.037053, l4: 0.072656, l5: 0.042450, l6: 0.070909

[epoch:   5/100000, batch:    88/  187, ite: 420] train loss: 1.165652, tar: 0.202082 
l0: 0.124650, l1: 0.106480, l2: 0.121772, l3: 0.128427, l4: 0.107525, l5: 0.111645, l6: 0.105006

[epoch:   5/100000, batch:    90/  187, ite: 421] train loss: 1.164797, tar: 0.201898 
l0: 0.120068, l1: 0.123429, l2: 0.125402, l3: 0.119110, l4: 0.118211, l5: 0.097967, l6: 0.099906

[epoch:   5/100000, batch:    92/  187, ite: 422] train loss: 1.163942, tar: 0.201704 
l0: 0.125587, l1: 0.110712, l2: 0.126636, l3: 0.126661, l4: 0.111152, l5: 0.118235, l6: 0.127589

[epoch:   5/100000, batch:    94/  187, ite: 423] train loss: 1.163192, tar: 0.201525 
l0: 0.134190, l1: 0.126352, l2: 0.131417, l3: 0.131571, l4: 0.124622, l5: 0.124392, l6: 0.128923

[epoch:   5/100000, batch:    96/  187, ite: 424] train loss: 1.162574, tar: 0.201366 
l0: 0.134706, l1: 0.130870, l2: 0.138475, l3: 0.141334, l4: 0.143484, l5: 0.160379, l6: 0.134700

[epoch:   5/100000, batch:    98/  187, ite: 425] train loss: 1.162154, tar: 0.201209 
l0: 0.141490, l1: 0.150249, l2: 0.151727, l3: 0.153169, l4: 0.145769, l5: 0.164103, l6: 0.161741

[epoch:   5/100000, batch:   100/  187, ite: 426] train loss: 1.161934, tar: 0.201069 
l0: 0.141107, l1: 0.139519, l2: 0.139696, l3: 0.143805, l4: 0.145246, l5: 0.131968, l6: 0.125176

[epoch:   5/100000, batch:   102/  187, ite: 427] train loss: 1.161476, tar: 0.200928 
l0: 0.140530, l1: 0.147239, l2: 0.139352, l3: 0.142218, l4: 0.148448, l5: 0.144772, l6: 0.169731

[epoch:   5/100000, batch:   104/  187, ite: 428] train loss: 1.161174, tar: 0.200787 
l0: 0.097741, l1: 0.082645, l2: 0.092911, l3: 0.079763, l4: 0.081541, l5: 0.080393, l6: 0.118190

[epoch:   5/100000, batch:   106/  187, ite: 429] train loss: 1.159943, tar: 0.200547 
l0: 0.106367, l1: 0.093356, l2: 0.102991, l3: 0.101129, l4: 0.108678, l5: 0.112754, l6: 0.100396

[epoch:   5/100000, batch:   108/  187, ite: 430] train loss: 1.158933, tar: 0.200328 
l0: 0.112649, l1: 0.101965, l2: 0.119148, l3: 0.123073, l4: 0.128520, l5: 0.111735, l6: 0.117428

[epoch:   5/100000, batch:   110/  187, ite: 431] train loss: 1.158134, tar: 0.200124 
l0: 0.146341, l1: 0.151983, l2: 0.151922, l3: 0.151475, l4: 0.142655, l5: 0.150383, l6: 0.181977

[epoch:   5/100000, batch:   112/  187, ite: 432] train loss: 1.157946, tar: 0.200000 
l0: 0.108329, l1: 0.104471, l2: 0.101752, l3: 0.100759, l4: 0.099138, l5: 0.107859, l6: 0.086917

[epoch:   5/100000, batch:   114/  187, ite: 433] train loss: 1.156910, tar: 0.199788 
l0: 0.150920, l1: 0.165196, l2: 0.146830, l3: 0.142940, l4: 0.144386, l5: 0.142348, l6: 0.181334

[epoch:   5/100000, batch:   116/  187, ite: 434] train loss: 1.156718, tar: 0.199676 
l0: 0.084986, l1: 0.085761, l2: 0.077312, l3: 0.079671, l4: 0.085228, l5: 0.072097, l6: 0.074459

[epoch:   5/100000, batch:   118/  187, ite: 435] train loss: 1.155346, tar: 0.199412 
l0: 0.186173, l1: 0.225515, l2: 0.243824, l3: 0.217129, l4: 0.220681, l5: 0.257684, l6: 0.288738

[epoch:   5/100000, batch:   120/  187, ite: 436] train loss: 1.156457, tar: 0.199382 
l0: 0.131814, l1: 0.139286, l2: 0.134125, l3: 0.133484, l4: 0.133297, l5: 0.144113, l6: 0.157907

[epoch:   5/100000, batch:   122/  187, ite: 437] train loss: 1.156039, tar: 0.199227 
l0: 0.102514, l1: 0.092561, l2: 0.106720, l3: 0.101658, l4: 0.109378, l5: 0.089153, l6: 0.096323

[epoch:   5/100000, batch:   124/  187, ite: 438] train loss: 1.154994, tar: 0.199006 
l0: 0.127165, l1: 0.121857, l2: 0.125762, l3: 0.123289, l4: 0.134101, l5: 0.130437, l6: 0.123263

[epoch:   5/100000, batch:   126/  187, ite: 439] train loss: 1.154381, tar: 0.198843 
l0: 0.130018, l1: 0.121251, l2: 0.112514, l3: 0.114127, l4: 0.126600, l5: 0.122759, l6: 0.148013

[epoch:   5/100000, batch:   128/  187, ite: 440] train loss: 1.153747, tar: 0.198686 
l0: 0.119300, l1: 0.116228, l2: 0.102057, l3: 0.100089, l4: 0.101391, l5: 0.097272, l6: 0.157824

[epoch:   5/100000, batch:   130/  187, ite: 441] train loss: 1.152931, tar: 0.198506 
l0: 0.208833, l1: 0.276202, l2: 0.201278, l3: 0.213362, l4: 0.186001, l5: 0.199099, l6: 0.166828

[epoch:   5/100000, batch:   132/  187, ite: 442] train loss: 1.153607, tar: 0.198530 
l0: 0.120009, l1: 0.131803, l2: 0.118852, l3: 0.125900, l4: 0.108323, l5: 0.119715, l6: 0.138197

[epoch:   5/100000, batch:   134/  187, ite: 443] train loss: 1.152951, tar: 0.198352 
l0: 0.111165, l1: 0.096964, l2: 0.099321, l3: 0.094678, l4: 0.093382, l5: 0.106235, l6: 0.098957

[epoch:   5/100000, batch:   136/  187, ite: 444] train loss: 1.151932, tar: 0.198156 
l0: 0.112412, l1: 0.102860, l2: 0.103026, l3: 0.097534, l4: 0.111308, l5: 0.126442, l6: 0.105640

[epoch:   5/100000, batch:   138/  187, ite: 445] train loss: 1.151049, tar: 0.197963 
l0: 0.128634, l1: 0.129617, l2: 0.124010, l3: 0.121794, l4: 0.124006, l5: 0.128365, l6: 0.130145

[epoch:   5/100000, batch:   140/  187, ite: 446] train loss: 1.150456, tar: 0.197808 
l0: 0.174042, l1: 0.189403, l2: 0.178609, l3: 0.194886, l4: 0.214070, l5: 0.264698, l6: 0.211198

[epoch:   5/100000, batch:   142/  187, ite: 447] train loss: 1.151075, tar: 0.197755 
l0: 0.133315, l1: 0.146634, l2: 0.140230, l3: 0.145597, l4: 0.137019, l5: 0.134960, l6: 0.159011

[epoch:   5/100000, batch:   144/  187, ite: 448] train loss: 1.150730, tar: 0.197611 
l0: 0.140330, l1: 0.147492, l2: 0.145628, l3: 0.145020, l4: 0.142856, l5: 0.138421, l6: 0.146405

[epoch:   5/100000, batch:   146/  187, ite: 449] train loss: 1.150408, tar: 0.197483 
l0: 0.107999, l1: 0.092954, l2: 0.100781, l3: 0.097211, l4: 0.107187, l5: 0.102568, l6: 0.104974

[epoch:   5/100000, batch:   148/  187, ite: 450] train loss: 1.149438, tar: 0.197284 
l0: 0.110013, l1: 0.108973, l2: 0.102910, l3: 0.106213, l4: 0.106170, l5: 0.100335, l6: 0.087853

[epoch:   5/100000, batch:   150/  187, ite: 451] train loss: 1.148491, tar: 0.197091 
l0: 0.145670, l1: 0.144907, l2: 0.140988, l3: 0.138765, l4: 0.148543, l5: 0.148719, l6: 0.129482

[epoch:   5/100000, batch:   152/  187, ite: 452] train loss: 1.148156, tar: 0.196977 
l0: 0.097868, l1: 0.071119, l2: 0.078577, l3: 0.076961, l4: 0.078604, l5: 0.077939, l6: 0.087619

[epoch:   5/100000, batch:   154/  187, ite: 453] train loss: 1.146877, tar: 0.196758 
l0: 0.124793, l1: 0.122757, l2: 0.121194, l3: 0.118970, l4: 0.119497, l5: 0.117119, l6: 0.117081

[epoch:   5/100000, batch:   156/  187, ite: 454] train loss: 1.146204, tar: 0.196600 
l0: 0.099780, l1: 0.088023, l2: 0.092413, l3: 0.093092, l4: 0.093662, l5: 0.084490, l6: 0.092924

[epoch:   5/100000, batch:   158/  187, ite: 455] train loss: 1.145101, tar: 0.196387 
l0: 0.143410, l1: 0.145560, l2: 0.142058, l3: 0.140703, l4: 0.151143, l5: 0.162174, l6: 0.146705

[epoch:   5/100000, batch:   160/  187, ite: 456] train loss: 1.144853, tar: 0.196271 
l0: 0.146985, l1: 0.150845, l2: 0.141981, l3: 0.141854, l4: 0.143255, l5: 0.135604, l6: 0.149396

[epoch:   5/100000, batch:   162/  187, ite: 457] train loss: 1.144558, tar: 0.196163 
l0: 0.143481, l1: 0.145811, l2: 0.139508, l3: 0.135765, l4: 0.144808, l5: 0.140322, l6: 0.161440

[epoch:   5/100000, batch:   164/  187, ite: 458] train loss: 1.144266, tar: 0.196048 
l0: 0.112408, l1: 0.097827, l2: 0.107505, l3: 0.108462, l4: 0.118851, l5: 0.115263, l6: 0.109066

[epoch:   5/100000, batch:   166/  187, ite: 459] train loss: 1.143449, tar: 0.195866 
l0: 0.214528, l1: 0.266773, l2: 0.232795, l3: 0.267110, l4: 0.248114, l5: 0.366607, l6: 0.215332

[epoch:   5/100000, batch:   168/  187, ite: 460] train loss: 1.144901, tar: 0.195906 
l0: 0.105257, l1: 0.086130, l2: 0.091668, l3: 0.098929, l4: 0.119497, l5: 0.117229, l6: 0.135003

[epoch:   5/100000, batch:   170/  187, ite: 461] train loss: 1.144053, tar: 0.195710 
l0: 0.173795, l1: 0.203094, l2: 0.184547, l3: 0.179667, l4: 0.223769, l5: 0.230774, l6: 0.207915

[epoch:   5/100000, batch:   172/  187, ite: 462] train loss: 1.144614, tar: 0.195662 
l0: 0.129253, l1: 0.131095, l2: 0.123288, l3: 0.126326, l4: 0.129998, l5: 0.144667, l6: 0.102453

[epoch:   5/100000, batch:   174/  187, ite: 463] train loss: 1.144058, tar: 0.195519 
l0: 0.114694, l1: 0.118443, l2: 0.119456, l3: 0.106951, l4: 0.121527, l5: 0.114138, l6: 0.150875

[epoch:   5/100000, batch:   176/  187, ite: 464] train loss: 1.143416, tar: 0.195345 
l0: 0.140004, l1: 0.141602, l2: 0.138130, l3: 0.146160, l4: 0.144933, l5: 0.135224, l6: 0.147433

[epoch:   5/100000, batch:   178/  187, ite: 465] train loss: 1.143094, tar: 0.195226 
l0: 0.121100, l1: 0.113302, l2: 0.113753, l3: 0.118905, l4: 0.140210, l5: 0.132399, l6: 0.128492

[epoch:   5/100000, batch:   180/  187, ite: 466] train loss: 1.142504, tar: 0.195067 
l0: 0.118326, l1: 0.104686, l2: 0.112687, l3: 0.118608, l4: 0.115974, l5: 0.113630, l6: 0.133322

[epoch:   5/100000, batch:   182/  187, ite: 467] train loss: 1.141807, tar: 0.194902 
l0: 0.136801, l1: 0.128390, l2: 0.113246, l3: 0.114988, l4: 0.141856, l5: 0.143505, l6: 0.112011

[epoch:   5/100000, batch:   184/  187, ite: 468] train loss: 1.141271, tar: 0.194778 
l0: 0.135465, l1: 0.138749, l2: 0.133889, l3: 0.134225, l4: 0.143178, l5: 0.138028, l6: 0.134247

[epoch:   5/100000, batch:   186/  187, ite: 469] train loss: 1.140879, tar: 0.194652 
l0: 0.104417, l1: 0.093743, l2: 0.102409, l3: 0.096458, l4: 0.110539, l5: 0.093494, l6: 0.093862

[epoch:   5/100000, batch:   188/  187, ite: 470] train loss: 1.139931, tar: 0.194460 
l0: 0.123871, l1: 0.110693, l2: 0.109226, l3: 0.112352, l4: 0.120342, l5: 0.105681, l6: 0.127096

[epoch:   6/100000, batch:     2/  187, ite: 471] train loss: 1.139229, tar: 0.194310 
l0: 0.216003, l1: 0.296126, l2: 0.226820, l3: 0.237518, l4: 0.261217, l5: 0.243227, l6: 0.232577

[epoch:   6/100000, batch:     4/  187, ite: 472] train loss: 1.140445, tar: 0.194356 
l0: 0.144430, l1: 0.152137, l2: 0.148864, l3: 0.158445, l4: 0.184250, l5: 0.155180, l6: 0.162865

[epoch:   6/100000, batch:     6/  187, ite: 473] train loss: 1.140373, tar: 0.194250 
l0: 0.114127, l1: 0.096029, l2: 0.101417, l3: 0.106619, l4: 0.112848, l5: 0.106545, l6: 0.104382

[epoch:   6/100000, batch:     8/  187, ite: 474] train loss: 1.139532, tar: 0.194081 
l0: 0.155215, l1: 0.135750, l2: 0.137856, l3: 0.154413, l4: 0.169717, l5: 0.195718, l6: 0.160130

[epoch:   6/100000, batch:    10/  187, ite: 475] train loss: 1.139467, tar: 0.193999 
l0: 0.228687, l1: 0.297029, l2: 0.266768, l3: 0.277856, l4: 0.256852, l5: 0.240487, l6: 0.254941

[epoch:   6/100000, batch:    12/  187, ite: 476] train loss: 1.140903, tar: 0.194072 
l0: 0.165498, l1: 0.186746, l2: 0.166737, l3: 0.172960, l4: 0.189955, l5: 0.198220, l6: 0.211762

[epoch:   6/100000, batch:    14/  187, ite: 477] train loss: 1.141219, tar: 0.194012 
l0: 0.151586, l1: 0.146826, l2: 0.145178, l3: 0.144686, l4: 0.165738, l5: 0.162493, l6: 0.185060

[epoch:   6/100000, batch:    16/  187, ite: 478] train loss: 1.141136, tar: 0.193923 
l0: 0.135649, l1: 0.123736, l2: 0.124740, l3: 0.125111, l4: 0.154957, l5: 0.142092, l6: 0.155380

[epoch:   6/100000, batch:    18/  187, ite: 479] train loss: 1.140762, tar: 0.193802 
l0: 0.122361, l1: 0.110134, l2: 0.115234, l3: 0.107376, l4: 0.128448, l5: 0.128226, l6: 0.117091

[epoch:   6/100000, batch:    20/  187, ite: 480] train loss: 1.140112, tar: 0.193653 
l0: 0.121081, l1: 0.117741, l2: 0.134085, l3: 0.125574, l4: 0.139480, l5: 0.139092, l6: 0.149071

[epoch:   6/100000, batch:    22/  187, ite: 481] train loss: 1.139667, tar: 0.193502 
l0: 0.161703, l1: 0.182521, l2: 0.165223, l3: 0.170258, l4: 0.170020, l5: 0.155101, l6: 0.174226

[epoch:   6/100000, batch:    24/  187, ite: 482] train loss: 1.139749, tar: 0.193436 
l0: 0.132102, l1: 0.134895, l2: 0.152614, l3: 0.143466, l4: 0.125564, l5: 0.117484, l6: 0.125202

[epoch:   6/100000, batch:    26/  187, ite: 483] train loss: 1.139317, tar: 0.193309 
l0: 0.086367, l1: 0.069656, l2: 0.075477, l3: 0.068924, l4: 0.066150, l5: 0.064629, l6: 0.051350

[epoch:   6/100000, batch:    28/  187, ite: 484] train loss: 1.137960, tar: 0.193088 
l0: 0.119879, l1: 0.106220, l2: 0.118535, l3: 0.102312, l4: 0.107821, l5: 0.112649, l6: 0.112238

[epoch:   6/100000, batch:    30/  187, ite: 485] train loss: 1.137221, tar: 0.192937 
l0: 0.079077, l1: 0.058811, l2: 0.063909, l3: 0.058448, l4: 0.052764, l5: 0.061057, l6: 0.057087

[epoch:   6/100000, batch:    32/  187, ite: 486] train loss: 1.135769, tar: 0.192703 
l0: 0.141503, l1: 0.135070, l2: 0.147366, l3: 0.150751, l4: 0.166094, l5: 0.155153, l6: 0.199959

[epoch:   6/100000, batch:    34/  187, ite: 487] train loss: 1.135687, tar: 0.192598 
l0: 0.167654, l1: 0.182698, l2: 0.174127, l3: 0.195510, l4: 0.197456, l5: 0.192902, l6: 0.211690

[epoch:   6/100000, batch:    36/  187, ite: 488] train loss: 1.136069, tar: 0.192547 
l0: 0.157192, l1: 0.158169, l2: 0.186224, l3: 0.191796, l4: 0.196272, l5: 0.204815, l6: 0.193040

[epoch:   6/100000, batch:    38/  187, ite: 489] train loss: 1.136378, tar: 0.192474 
l0: 0.159643, l1: 0.165721, l2: 0.191146, l3: 0.187670, l4: 0.198970, l5: 0.215727, l6: 0.184475

[epoch:   6/100000, batch:    40/  187, ite: 490] train loss: 1.136719, tar: 0.192407 
l0: 0.086866, l1: 0.060233, l2: 0.063174, l3: 0.067629, l4: 0.071936, l5: 0.077266, l6: 0.087676

[epoch:   6/100000, batch:    42/  187, ite: 491] train loss: 1.135452, tar: 0.192192 
l0: 0.113094, l1: 0.106243, l2: 0.114843, l3: 0.112815, l4: 0.122945, l5: 0.127876, l6: 0.168843

[epoch:   6/100000, batch:    44/  187, ite: 492] train loss: 1.134906, tar: 0.192032 
l0: 0.141695, l1: 0.152443, l2: 0.157397, l3: 0.156579, l4: 0.140333, l5: 0.133139, l6: 0.147829

[epoch:   6/100000, batch:    46/  187, ite: 493] train loss: 1.134692, tar: 0.191930 
l0: 0.144504, l1: 0.148414, l2: 0.155816, l3: 0.170040, l4: 0.168599, l5: 0.151245, l6: 0.153097

[epoch:   6/100000, batch:    48/  187, ite: 494] train loss: 1.134605, tar: 0.191834 
l0: 0.111784, l1: 0.094732, l2: 0.105419, l3: 0.113831, l4: 0.121337, l5: 0.111274, l6: 0.124659

[epoch:   6/100000, batch:    50/  187, ite: 495] train loss: 1.133895, tar: 0.191672 
l0: 0.110735, l1: 0.108548, l2: 0.107807, l3: 0.110929, l4: 0.111026, l5: 0.111833, l6: 0.087967

[epoch:   6/100000, batch:    52/  187, ite: 496] train loss: 1.133118, tar: 0.191509 
l0: 0.094863, l1: 0.080252, l2: 0.091659, l3: 0.086657, l4: 0.100939, l5: 0.090927, l6: 0.085851

[epoch:   6/100000, batch:    54/  187, ite: 497] train loss: 1.132108, tar: 0.191314 
l0: 0.127260, l1: 0.126839, l2: 0.132868, l3: 0.139010, l4: 0.128146, l5: 0.118835, l6: 0.146891

[epoch:   6/100000, batch:    56/  187, ite: 498] train loss: 1.131682, tar: 0.191186 
l0: 0.107434, l1: 0.094494, l2: 0.100633, l3: 0.112077, l4: 0.108834, l5: 0.096838, l6: 0.101961

[epoch:   6/100000, batch:    58/  187, ite: 499] train loss: 1.130862, tar: 0.191018 
l0: 0.121629, l1: 0.141955, l2: 0.135751, l3: 0.131267, l4: 0.107362, l5: 0.117108, l6: 0.121921

[epoch:   6/100000, batch:    60/  187, ite: 500] train loss: 1.130354, tar: 0.190879 
l0: 0.163330, l1: 0.185430, l2: 0.174346, l3: 0.192457, l4: 0.222766, l5: 0.216156, l6: 0.263877

[epoch:   6/100000, batch:    62/  187, ite: 501] train loss: 1.130929, tar: 0.190824 
l0: 0.173061, l1: 0.218512, l2: 0.184498, l3: 0.187356, l4: 0.197732, l5: 0.179534, l6: 0.210810

[epoch:   6/100000, batch:    64/  187, ite: 502] train loss: 1.131368, tar: 0.190789 
l0: 0.107478, l1: 0.104856, l2: 0.111489, l3: 0.110683, l4: 0.113618, l5: 0.093390, l6: 0.130362

[epoch:   6/100000, batch:    66/  187, ite: 503] train loss: 1.130654, tar: 0.190623 
l0: 0.129423, l1: 0.124920, l2: 0.125430, l3: 0.130440, l4: 0.148380, l5: 0.144698, l6: 0.150177

[epoch:   6/100000, batch:    68/  187, ite: 504] train loss: 1.130302, tar: 0.190502 
l0: 0.138211, l1: 0.157189, l2: 0.138814, l3: 0.139060, l4: 0.152416, l5: 0.154795, l6: 0.157972

[epoch:   6/100000, batch:    70/  187, ite: 505] train loss: 1.130120, tar: 0.190398 
l0: 0.088085, l1: 0.074707, l2: 0.084893, l3: 0.081901, l4: 0.096359, l5: 0.080303, l6: 0.088384

[epoch:   6/100000, batch:    72/  187, ite: 506] train loss: 1.129062, tar: 0.190196 
l0: 0.110724, l1: 0.101986, l2: 0.108072, l3: 0.109219, l4: 0.117429, l5: 0.110596, l6: 0.112786

[epoch:   6/100000, batch:    74/  187, ite: 507] train loss: 1.128355, tar: 0.190039 
l0: 0.142040, l1: 0.156002, l2: 0.144566, l3: 0.143414, l4: 0.150821, l5: 0.161563, l6: 0.150479

[epoch:   6/100000, batch:    76/  187, ite: 508] train loss: 1.128199, tar: 0.189945 
l0: 0.107787, l1: 0.107326, l2: 0.109518, l3: 0.107007, l4: 0.115295, l5: 0.119991, l6: 0.114563

[epoch:   6/100000, batch:    78/  187, ite: 509] train loss: 1.127518, tar: 0.189783 
l0: 0.117815, l1: 0.108779, l2: 0.111171, l3: 0.106882, l4: 0.140755, l5: 0.149758, l6: 0.185939

[epoch:   6/100000, batch:    80/  187, ite: 510] train loss: 1.127113, tar: 0.189642 
l0: 0.071865, l1: 0.061079, l2: 0.067783, l3: 0.067313, l4: 0.085002, l5: 0.081615, l6: 0.095852

[epoch:   6/100000, batch:    82/  187, ite: 511] train loss: 1.125945, tar: 0.189412 
l0: 0.135680, l1: 0.132818, l2: 0.134277, l3: 0.133960, l4: 0.153994, l5: 0.147805, l6: 0.166091

[epoch:   6/100000, batch:    84/  187, ite: 512] train loss: 1.125708, tar: 0.189307 
l0: 0.088419, l1: 0.071866, l2: 0.077972, l3: 0.081229, l4: 0.085233, l5: 0.078264, l6: 0.072542

[epoch:   6/100000, batch:    86/  187, ite: 513] train loss: 1.124597, tar: 0.189110 
l0: 0.175252, l1: 0.233862, l2: 0.178187, l3: 0.178223, l4: 0.139075, l5: 0.132389, l6: 0.122591

[epoch:   6/100000, batch:    88/  187, ite: 514] train loss: 1.124665, tar: 0.189083 
l0: 0.140651, l1: 0.153584, l2: 0.144065, l3: 0.148582, l4: 0.150543, l5: 0.144059, l6: 0.158495

[epoch:   6/100000, batch:    90/  187, ite: 515] train loss: 1.124501, tar: 0.188989 
l0: 0.109017, l1: 0.105514, l2: 0.113901, l3: 0.124042, l4: 0.108459, l5: 0.105074, l6: 0.117132

[epoch:   6/100000, batch:    92/  187, ite: 516] train loss: 1.123839, tar: 0.188834 
l0: 0.117944, l1: 0.106827, l2: 0.112725, l3: 0.112159, l4: 0.127180, l5: 0.123200, l6: 0.120604

[epoch:   6/100000, batch:    94/  187, ite: 517] train loss: 1.123253, tar: 0.188697 
l0: 0.113297, l1: 0.112863, l2: 0.115127, l3: 0.117259, l4: 0.107316, l5: 0.107568, l6: 0.120283

[epoch:   6/100000, batch:    96/  187, ite: 518] train loss: 1.122616, tar: 0.188551 
l0: 0.103996, l1: 0.099177, l2: 0.100246, l3: 0.095489, l4: 0.094611, l5: 0.098349, l6: 0.103868

[epoch:   6/100000, batch:    98/  187, ite: 519] train loss: 1.121794, tar: 0.188388 
l0: 0.152945, l1: 0.167700, l2: 0.123478, l3: 0.134167, l4: 0.146256, l5: 0.142387, l6: 0.150746

[epoch:   6/100000, batch:   100/  187, ite: 520] train loss: 1.121594, tar: 0.188320 
l0: 0.146827, l1: 0.156663, l2: 0.151919, l3: 0.167331, l4: 0.142611, l5: 0.136286, l6: 0.141284

[epoch:   6/100000, batch:   102/  187, ite: 521] train loss: 1.121443, tar: 0.188241 
l0: 0.141815, l1: 0.140915, l2: 0.131890, l3: 0.159042, l4: 0.162349, l5: 0.164538, l6: 0.183086

[epoch:   6/100000, batch:   104/  187, ite: 522] train loss: 1.121370, tar: 0.188152 
l0: 0.099498, l1: 0.083384, l2: 0.096626, l3: 0.098469, l4: 0.091450, l5: 0.086937, l6: 0.096758

[epoch:   6/100000, batch:   106/  187, ite: 523] train loss: 1.120475, tar: 0.187982 
l0: 0.114323, l1: 0.103648, l2: 0.108853, l3: 0.105966, l4: 0.142165, l5: 0.136107, l6: 0.131386

[epoch:   6/100000, batch:   108/  187, ite: 524] train loss: 1.119944, tar: 0.187842 
l0: 0.133151, l1: 0.132650, l2: 0.126883, l3: 0.132216, l4: 0.156010, l5: 0.150283, l6: 0.132906

[epoch:   6/100000, batch:   110/  187, ite: 525] train loss: 1.119648, tar: 0.187737 
l0: 0.080293, l1: 0.067887, l2: 0.075044, l3: 0.074806, l4: 0.083017, l5: 0.077498, l6: 0.074533

[epoch:   6/100000, batch:   112/  187, ite: 526] train loss: 1.118532, tar: 0.187533 
l0: 0.165469, l1: 0.199023, l2: 0.208179, l3: 0.214046, l4: 0.208756, l5: 0.194933, l6: 0.216352

[epoch:   6/100000, batch:   114/  187, ite: 527] train loss: 1.119079, tar: 0.187491 
l0: 0.093345, l1: 0.080207, l2: 0.091728, l3: 0.102652, l4: 0.084622, l5: 0.091155, l6: 0.093518

[epoch:   6/100000, batch:   116/  187, ite: 528] train loss: 1.118167, tar: 0.187313 
l0: 0.126277, l1: 0.119803, l2: 0.112345, l3: 0.116292, l4: 0.136173, l5: 0.118785, l6: 0.149819

[epoch:   6/100000, batch:   118/  187, ite: 529] train loss: 1.117716, tar: 0.187198 
l0: 0.092386, l1: 0.082033, l2: 0.093769, l3: 0.094620, l4: 0.113086, l5: 0.097944, l6: 0.091802

[epoch:   6/100000, batch:   120/  187, ite: 530] train loss: 1.116863, tar: 0.187019 
l0: 0.094465, l1: 0.080770, l2: 0.090513, l3: 0.109310, l4: 0.088633, l5: 0.095452, l6: 0.097430

[epoch:   6/100000, batch:   122/  187, ite: 531] train loss: 1.115996, tar: 0.186844 
l0: 0.082542, l1: 0.077069, l2: 0.088095, l3: 0.096171, l4: 0.074386, l5: 0.066117, l6: 0.068632

[epoch:   6/100000, batch:   124/  187, ite: 532] train loss: 1.114937, tar: 0.186648 
l0: 0.104672, l1: 0.104166, l2: 0.116343, l3: 0.123245, l4: 0.118902, l5: 0.108809, l6: 0.120547

[epoch:   6/100000, batch:   126/  187, ite: 533] train loss: 1.114340, tar: 0.186495 
l0: 0.104738, l1: 0.102583, l2: 0.106971, l3: 0.108652, l4: 0.105688, l5: 0.104464, l6: 0.110477

[epoch:   6/100000, batch:   128/  187, ite: 534] train loss: 1.113646, tar: 0.186341 
l0: 0.166943, l1: 0.197697, l2: 0.162264, l3: 0.163978, l4: 0.165365, l5: 0.157669, l6: 0.169906

[epoch:   6/100000, batch:   130/  187, ite: 535] train loss: 1.113777, tar: 0.186305 
l0: 0.190546, l1: 0.238015, l2: 0.204690, l3: 0.200555, l4: 0.194250, l5: 0.241748, l6: 0.173585

[epoch:   6/100000, batch:   132/  187, ite: 536] train loss: 1.114392, tar: 0.186313 
l0: 0.122967, l1: 0.119771, l2: 0.121502, l3: 0.120315, l4: 0.125538, l5: 0.125882, l6: 0.127010

[epoch:   6/100000, batch:   134/  187, ite: 537] train loss: 1.113924, tar: 0.186195 
l0: 0.138009, l1: 0.139645, l2: 0.136007, l3: 0.138319, l4: 0.146830, l5: 0.126655, l6: 0.126287

[epoch:   6/100000, batch:   136/  187, ite: 538] train loss: 1.113623, tar: 0.186106 
l0: 0.162611, l1: 0.167178, l2: 0.163380, l3: 0.173244, l4: 0.208554, l5: 0.203724, l6: 0.172850

[epoch:   6/100000, batch:   138/  187, ite: 539] train loss: 1.113878, tar: 0.186062 
l0: 0.103045, l1: 0.093494, l2: 0.106225, l3: 0.097054, l4: 0.108559, l5: 0.096871, l6: 0.121029

[epoch:   6/100000, batch:   140/  187, ite: 540] train loss: 1.113161, tar: 0.185908 
l0: 0.147059, l1: 0.153238, l2: 0.167783, l3: 0.168577, l4: 0.158759, l5: 0.148322, l6: 0.151872

[epoch:   6/100000, batch:   142/  187, ite: 541] train loss: 1.113128, tar: 0.185836 
l0: 0.117242, l1: 0.108439, l2: 0.130514, l3: 0.139553, l4: 0.134559, l5: 0.127434, l6: 0.111680

[epoch:   6/100000, batch:   144/  187, ite: 542] train loss: 1.112679, tar: 0.185710 
l0: 0.167537, l1: 0.177080, l2: 0.182890, l3: 0.188493, l4: 0.174810, l5: 0.213458, l6: 0.174625

[epoch:   6/100000, batch:   146/  187, ite: 543] train loss: 1.112985, tar: 0.185676 
l0: 0.133700, l1: 0.128882, l2: 0.133916, l3: 0.133367, l4: 0.144414, l5: 0.142235, l6: 0.142306

[epoch:   6/100000, batch:   148/  187, ite: 544] train loss: 1.112701, tar: 0.185581 
l0: 0.134384, l1: 0.127066, l2: 0.136071, l3: 0.132697, l4: 0.135134, l5: 0.134954, l6: 0.137373

[epoch:   6/100000, batch:   150/  187, ite: 545] train loss: 1.112380, tar: 0.185487 
l0: 0.109101, l1: 0.101368, l2: 0.104734, l3: 0.107605, l4: 0.100298, l5: 0.093491, l6: 0.085356

[epoch:   6/100000, batch:   152/  187, ite: 546] train loss: 1.111628, tar: 0.185347 
l0: 0.135862, l1: 0.136057, l2: 0.150314, l3: 0.145830, l4: 0.137177, l5: 0.141420, l6: 0.145723

[epoch:   6/100000, batch:   154/  187, ite: 547] train loss: 1.111410, tar: 0.185257 
l0: 0.173163, l1: 0.179341, l2: 0.192836, l3: 0.199447, l4: 0.189376, l5: 0.183076, l6: 0.211934

[epoch:   6/100000, batch:   156/  187, ite: 548] train loss: 1.111808, tar: 0.185234 
l0: 0.105583, l1: 0.102843, l2: 0.110452, l3: 0.114376, l4: 0.115374, l5: 0.103727, l6: 0.093385

[epoch:   6/100000, batch:   158/  187, ite: 549] train loss: 1.111141, tar: 0.185089 
l0: 0.100779, l1: 0.094013, l2: 0.095911, l3: 0.094260, l4: 0.100745, l5: 0.093216, l6: 0.085833

[epoch:   6/100000, batch:   160/  187, ite: 550] train loss: 1.110329, tar: 0.184936 
l0: 0.127255, l1: 0.119556, l2: 0.125203, l3: 0.135516, l4: 0.130664, l5: 0.123038, l6: 0.112374

[epoch:   6/100000, batch:   162/  187, ite: 551] train loss: 1.109900, tar: 0.184831 
l0: 0.113434, l1: 0.108854, l2: 0.095918, l3: 0.092951, l4: 0.096380, l5: 0.101352, l6: 0.108496

[epoch:   6/100000, batch:   164/  187, ite: 552] train loss: 1.109189, tar: 0.184702 
l0: 0.100474, l1: 0.088913, l2: 0.100670, l3: 0.099150, l4: 0.102537, l5: 0.090523, l6: 0.079547

[epoch:   6/100000, batch:   166/  187, ite: 553] train loss: 1.108380, tar: 0.184550 
l0: 0.111577, l1: 0.114529, l2: 0.111824, l3: 0.109032, l4: 0.110800, l5: 0.109822, l6: 0.114337

[epoch:   6/100000, batch:   168/  187, ite: 554] train loss: 1.107790, tar: 0.184418 
l0: 0.089730, l1: 0.082587, l2: 0.086624, l3: 0.083636, l4: 0.088281, l5: 0.072725, l6: 0.069128

[epoch:   6/100000, batch:   170/  187, ite: 555] train loss: 1.106826, tar: 0.184247 
l0: 0.123996, l1: 0.124053, l2: 0.130295, l3: 0.130676, l4: 0.125301, l5: 0.137202, l6: 0.118129

[epoch:   6/100000, batch:   172/  187, ite: 556] train loss: 1.106436, tar: 0.184139 
l0: 0.087581, l1: 0.086150, l2: 0.082618, l3: 0.089452, l4: 0.085770, l5: 0.084631, l6: 0.095783

[epoch:   6/100000, batch:   174/  187, ite: 557] train loss: 1.105548, tar: 0.183966 
l0: 0.100336, l1: 0.111152, l2: 0.113879, l3: 0.113629, l4: 0.128885, l5: 0.119293, l6: 0.098829

[epoch:   6/100000, batch:   176/  187, ite: 558] train loss: 1.104975, tar: 0.183816 
l0: 0.156140, l1: 0.166059, l2: 0.174780, l3: 0.191833, l4: 0.175407, l5: 0.195105, l6: 0.214257

[epoch:   6/100000, batch:   178/  187, ite: 559] train loss: 1.105277, tar: 0.183766 
l0: 0.090801, l1: 0.086532, l2: 0.093594, l3: 0.093806, l4: 0.093523, l5: 0.089888, l6: 0.117245

[epoch:   6/100000, batch:   180/  187, ite: 560] train loss: 1.104491, tar: 0.183600 
l0: 0.115839, l1: 0.119315, l2: 0.126826, l3: 0.126874, l4: 0.129104, l5: 0.128197, l6: 0.111411

[epoch:   6/100000, batch:   182/  187, ite: 561] train loss: 1.104051, tar: 0.183480 
l0: 0.050250, l1: 0.039072, l2: 0.046210, l3: 0.045620, l4: 0.043688, l5: 0.035614, l6: 0.029007

[epoch:   6/100000, batch:   184/  187, ite: 562] train loss: 1.102602, tar: 0.183242 
l0: 0.116516, l1: 0.125563, l2: 0.117608, l3: 0.119002, l4: 0.117072, l5: 0.121467, l6: 0.111575

[epoch:   6/100000, batch:   186/  187, ite: 563] train loss: 1.102116, tar: 0.183124 
l0: 0.172829, l1: 0.192465, l2: 0.195915, l3: 0.194379, l4: 0.223051, l5: 0.183082, l6: 0.147264

[epoch:   6/100000, batch:   188/  187, ite: 564] train loss: 1.102482, tar: 0.183106 
l0: 0.152867, l1: 0.165320, l2: 0.158854, l3: 0.152752, l4: 0.175470, l5: 0.156769, l6: 0.120848

[epoch:   7/100000, batch:     2/  187, ite: 565] train loss: 1.102448, tar: 0.183052 
l0: 0.159681, l1: 0.175405, l2: 0.164684, l3: 0.168182, l4: 0.163052, l5: 0.156566, l6: 0.144883

[epoch:   7/100000, batch:     4/  187, ite: 566] train loss: 1.102501, tar: 0.183011 
l0: 0.095839, l1: 0.083805, l2: 0.098611, l3: 0.114481, l4: 0.107295, l5: 0.096612, l6: 0.140982

[epoch:   7/100000, batch:     6/  187, ite: 567] train loss: 1.101857, tar: 0.182857 
l0: 0.157802, l1: 0.154277, l2: 0.159122, l3: 0.163739, l4: 0.169343, l5: 0.190176, l6: 0.221291

[epoch:   7/100000, batch:     8/  187, ite: 568] train loss: 1.102058, tar: 0.182813 
l0: 0.071378, l1: 0.056206, l2: 0.078129, l3: 0.096003, l4: 0.099285, l5: 0.075658, l6: 0.089134

[epoch:   7/100000, batch:    10/  187, ite: 569] train loss: 1.101115, tar: 0.182617 
l0: 0.100294, l1: 0.090263, l2: 0.106175, l3: 0.116169, l4: 0.112716, l5: 0.106801, l6: 0.093885

[epoch:   7/100000, batch:    12/  187, ite: 570] train loss: 1.100458, tar: 0.182473 
l0: 0.128749, l1: 0.123007, l2: 0.133029, l3: 0.130894, l4: 0.145679, l5: 0.138959, l6: 0.154489

[epoch:   7/100000, batch:    14/  187, ite: 571] train loss: 1.100203, tar: 0.182379 
l0: 0.093085, l1: 0.091906, l2: 0.094328, l3: 0.090819, l4: 0.090101, l5: 0.095355, l6: 0.074437

[epoch:   7/100000, batch:    16/  187, ite: 572] train loss: 1.099381, tar: 0.182223 
l0: 0.119456, l1: 0.111473, l2: 0.120026, l3: 0.126993, l4: 0.143811, l5: 0.133185, l6: 0.178072

[epoch:   7/100000, batch:    18/  187, ite: 573] train loss: 1.099090, tar: 0.182113 
l0: 0.134051, l1: 0.134424, l2: 0.150094, l3: 0.163758, l4: 0.139962, l5: 0.135484, l6: 0.194453

[epoch:   7/100000, batch:    20/  187, ite: 574] train loss: 1.099009, tar: 0.182029 
l0: 0.156591, l1: 0.138922, l2: 0.157751, l3: 0.182357, l4: 0.208693, l5: 0.211186, l6: 0.327762

[epoch:   7/100000, batch:    22/  187, ite: 575] train loss: 1.099503, tar: 0.181985 
l0: 0.106562, l1: 0.108644, l2: 0.116395, l3: 0.120747, l4: 0.114597, l5: 0.104351, l6: 0.114573

[epoch:   7/100000, batch:    24/  187, ite: 576] train loss: 1.098958, tar: 0.181854 
l0: 0.128366, l1: 0.123960, l2: 0.130246, l3: 0.135526, l4: 0.149895, l5: 0.136974, l6: 0.136628

[epoch:   7/100000, batch:    26/  187, ite: 577] train loss: 1.098686, tar: 0.181761 
l0: 0.136778, l1: 0.128730, l2: 0.130675, l3: 0.134149, l4: 0.140272, l5: 0.165563, l6: 0.209304

[epoch:   7/100000, batch:    28/  187, ite: 578] train loss: 1.098594, tar: 0.181684 
l0: 0.096120, l1: 0.086191, l2: 0.089697, l3: 0.087775, l4: 0.099285, l5: 0.092037, l6: 0.106860

[epoch:   7/100000, batch:    30/  187, ite: 579] train loss: 1.097833, tar: 0.181536 
l0: 0.148533, l1: 0.145884, l2: 0.175468, l3: 0.174798, l4: 0.182431, l5: 0.196554, l6: 0.141053

[epoch:   7/100000, batch:    32/  187, ite: 580] train loss: 1.097948, tar: 0.181479 
l0: 0.073424, l1: 0.058601, l2: 0.060754, l3: 0.071371, l4: 0.088969, l5: 0.073485, l6: 0.181062

[epoch:   7/100000, batch:    34/  187, ite: 581] train loss: 1.097104, tar: 0.181293 
l0: 0.109641, l1: 0.114775, l2: 0.114303, l3: 0.115510, l4: 0.128456, l5: 0.117813, l6: 0.140271

[epoch:   7/100000, batch:    36/  187, ite: 582] train loss: 1.096664, tar: 0.181170 
l0: 0.093479, l1: 0.089220, l2: 0.093189, l3: 0.097491, l4: 0.110665, l5: 0.102528, l6: 0.091963

[epoch:   7/100000, batch:    38/  187, ite: 583] train loss: 1.095946, tar: 0.181019 
l0: 0.106917, l1: 0.099535, l2: 0.107732, l3: 0.102474, l4: 0.124715, l5: 0.120029, l6: 0.113989

[epoch:   7/100000, batch:    40/  187, ite: 584] train loss: 1.095398, tar: 0.180892 
l0: 0.098502, l1: 0.091800, l2: 0.101162, l3: 0.102167, l4: 0.112638, l5: 0.101989, l6: 0.109791

[epoch:   7/100000, batch:    42/  187, ite: 585] train loss: 1.094753, tar: 0.180752 
l0: 0.112055, l1: 0.101153, l2: 0.112485, l3: 0.109774, l4: 0.144460, l5: 0.148434, l6: 0.154547

[epoch:   7/100000, batch:    44/  187, ite: 586] train loss: 1.094391, tar: 0.180634 
l0: 0.128438, l1: 0.142271, l2: 0.145085, l3: 0.141978, l4: 0.137439, l5: 0.132729, l6: 0.147069

[epoch:   7/100000, batch:    46/  187, ite: 587] train loss: 1.094188, tar: 0.180546 
l0: 0.093287, l1: 0.084249, l2: 0.090382, l3: 0.088490, l4: 0.111961, l5: 0.099171, l6: 0.121578

[epoch:   7/100000, batch:    48/  187, ite: 588] train loss: 1.093499, tar: 0.180397 
l0: 0.092354, l1: 0.090679, l2: 0.098236, l3: 0.096868, l4: 0.100600, l5: 0.097938, l6: 0.102800

[epoch:   7/100000, batch:    50/  187, ite: 589] train loss: 1.092796, tar: 0.180248 
l0: 0.139532, l1: 0.159277, l2: 0.163590, l3: 0.166901, l4: 0.143581, l5: 0.131530, l6: 0.147527

[epoch:   7/100000, batch:    52/  187, ite: 590] train loss: 1.092727, tar: 0.180179 
l0: 0.092340, l1: 0.093053, l2: 0.113962, l3: 0.112062, l4: 0.100212, l5: 0.095913, l6: 0.087696

[epoch:   7/100000, batch:    54/  187, ite: 591] train loss: 1.092054, tar: 0.180030 
l0: 0.081069, l1: 0.080017, l2: 0.089472, l3: 0.096775, l4: 0.093110, l5: 0.092749, l6: 0.097783

[epoch:   7/100000, batch:    56/  187, ite: 592] train loss: 1.091275, tar: 0.179863 
l0: 0.113799, l1: 0.132805, l2: 0.133974, l3: 0.125959, l4: 0.118701, l5: 0.113075, l6: 0.107513

[epoch:   7/100000, batch:    58/  187, ite: 593] train loss: 1.090861, tar: 0.179751 
l0: 0.117403, l1: 0.110543, l2: 0.145053, l3: 0.155550, l4: 0.149865, l5: 0.152981, l6: 0.160239

[epoch:   7/100000, batch:    60/  187, ite: 594] train loss: 1.090694, tar: 0.179646 
l0: 0.145600, l1: 0.140530, l2: 0.139389, l3: 0.169054, l4: 0.206239, l5: 0.217085, l6: 0.234317

[epoch:   7/100000, batch:    62/  187, ite: 595] train loss: 1.090966, tar: 0.179589 
l0: 0.127775, l1: 0.133154, l2: 0.142767, l3: 0.138365, l4: 0.131587, l5: 0.132388, l6: 0.127201

[epoch:   7/100000, batch:    64/  187, ite: 596] train loss: 1.090701, tar: 0.179502 
l0: 0.101594, l1: 0.098184, l2: 0.096587, l3: 0.097693, l4: 0.095301, l5: 0.099604, l6: 0.103274

[epoch:   7/100000, batch:    66/  187, ite: 597] train loss: 1.090034, tar: 0.179372 
l0: 0.087779, l1: 0.087091, l2: 0.096450, l3: 0.094436, l4: 0.089758, l5: 0.084602, l6: 0.085067

[epoch:   7/100000, batch:    68/  187, ite: 598] train loss: 1.089256, tar: 0.179219 
l0: 0.103668, l1: 0.112515, l2: 0.128357, l3: 0.129588, l4: 0.120850, l5: 0.110884, l6: 0.101490

[epoch:   7/100000, batch:    70/  187, ite: 599] train loss: 1.088786, tar: 0.179093 
l0: 0.108062, l1: 0.118179, l2: 0.123761, l3: 0.128282, l4: 0.125612, l5: 0.113113, l6: 0.111630

[epoch:   7/100000, batch:    72/  187, ite: 600] train loss: 1.088352, tar: 0.178974 
l0: 0.155929, l1: 0.172510, l2: 0.163074, l3: 0.188743, l4: 0.169206, l5: 0.173713, l6: 0.169014

[epoch:   7/100000, batch:    74/  187, ite: 601] train loss: 1.088525, tar: 0.178936 
l0: 0.121108, l1: 0.124977, l2: 0.127882, l3: 0.133974, l4: 0.119590, l5: 0.118051, l6: 0.118225

[epoch:   7/100000, batch:    76/  187, ite: 602] train loss: 1.088152, tar: 0.178840 
l0: 0.097687, l1: 0.097082, l2: 0.109271, l3: 0.103406, l4: 0.105283, l5: 0.100716, l6: 0.099123

[epoch:   7/100000, batch:    78/  187, ite: 603] train loss: 1.087529, tar: 0.178705 
l0: 0.113483, l1: 0.120130, l2: 0.117237, l3: 0.121642, l4: 0.120330, l5: 0.115087, l6: 0.124684

[epoch:   7/100000, batch:    80/  187, ite: 604] train loss: 1.087107, tar: 0.178597 
l0: 0.149357, l1: 0.184146, l2: 0.177975, l3: 0.190360, l4: 0.133156, l5: 0.125813, l6: 0.119881

[epoch:   7/100000, batch:    82/  187, ite: 605] train loss: 1.087096, tar: 0.178549 
l0: 0.126105, l1: 0.118228, l2: 0.125251, l3: 0.127715, l4: 0.140408, l5: 0.152282, l6: 0.146651

[epoch:   7/100000, batch:    84/  187, ite: 606] train loss: 1.086848, tar: 0.178462 
l0: 0.116371, l1: 0.105670, l2: 0.120219, l3: 0.111942, l4: 0.126280, l5: 0.117691, l6: 0.129042

[epoch:   7/100000, batch:    86/  187, ite: 607] train loss: 1.086420, tar: 0.178360 
l0: 0.117825, l1: 0.129817, l2: 0.115009, l3: 0.101964, l4: 0.118334, l5: 0.126469, l6: 0.115001

[epoch:   7/100000, batch:    88/  187, ite: 608] train loss: 1.085989, tar: 0.178260 
l0: 0.107860, l1: 0.098126, l2: 0.098625, l3: 0.091215, l4: 0.123856, l5: 0.128939, l6: 0.137516

[epoch:   7/100000, batch:    90/  187, ite: 609] train loss: 1.085497, tar: 0.178145 
l0: 0.147055, l1: 0.175556, l2: 0.146631, l3: 0.149534, l4: 0.149493, l5: 0.154954, l6: 0.141209

[epoch:   7/100000, batch:    92/  187, ite: 610] train loss: 1.085462, tar: 0.178094 
l0: 0.104256, l1: 0.102774, l2: 0.105747, l3: 0.106186, l4: 0.103643, l5: 0.099589, l6: 0.102045

[epoch:   7/100000, batch:    94/  187, ite: 611] train loss: 1.084871, tar: 0.177973 
l0: 0.102239, l1: 0.097879, l2: 0.095790, l3: 0.105625, l4: 0.113260, l5: 0.107359, l6: 0.095345

[epoch:   7/100000, batch:    96/  187, ite: 612] train loss: 1.084271, tar: 0.177849 
l0: 0.113467, l1: 0.124120, l2: 0.114252, l3: 0.120581, l4: 0.111997, l5: 0.107921, l6: 0.099792

[epoch:   7/100000, batch:    98/  187, ite: 613] train loss: 1.083794, tar: 0.177744 
l0: 0.132060, l1: 0.143914, l2: 0.137598, l3: 0.144770, l4: 0.145586, l5: 0.145701, l6: 0.145951

[epoch:   7/100000, batch:   100/  187, ite: 614] train loss: 1.083650, tar: 0.177670 
l0: 0.124232, l1: 0.122214, l2: 0.132872, l3: 0.144218, l4: 0.144324, l5: 0.137675, l6: 0.149571

[epoch:   7/100000, batch:   102/  187, ite: 615] train loss: 1.083441, tar: 0.177583 
l0: 0.148902, l1: 0.156789, l2: 0.197487, l3: 0.218447, l4: 0.152812, l5: 0.155463, l6: 0.160357

[epoch:   7/100000, batch:   104/  187, ite: 616] train loss: 1.083615, tar: 0.177536 
l0: 0.079377, l1: 0.081115, l2: 0.092647, l3: 0.093780, l4: 0.072172, l5: 0.068131, l6: 0.073888

[epoch:   7/100000, batch:   106/  187, ite: 617] train loss: 1.082768, tar: 0.177377 
l0: 0.170650, l1: 0.199361, l2: 0.183855, l3: 0.196712, l4: 0.202214, l5: 0.205127, l6: 0.218091

[epoch:   7/100000, batch:   108/  187, ite: 618] train loss: 1.083242, tar: 0.177366 
l0: 0.197642, l1: 0.261565, l2: 0.196426, l3: 0.171417, l4: 0.214113, l5: 0.213813, l6: 0.235664

[epoch:   7/100000, batch:   110/  187, ite: 619] train loss: 1.083901, tar: 0.177399 
l0: 0.151551, l1: 0.159211, l2: 0.146246, l3: 0.164864, l4: 0.151270, l5: 0.139196, l6: 0.160183

[epoch:   7/100000, batch:   112/  187, ite: 620] train loss: 1.083882, tar: 0.177357 
l0: 0.090467, l1: 0.084803, l2: 0.089283, l3: 0.088649, l4: 0.094624, l5: 0.087014, l6: 0.084888

[epoch:   7/100000, batch:   114/  187, ite: 621] train loss: 1.083135, tar: 0.177218 
l0: 0.118429, l1: 0.109176, l2: 0.131667, l3: 0.138496, l4: 0.122766, l5: 0.129447, l6: 0.146772

[epoch:   7/100000, batch:   116/  187, ite: 622] train loss: 1.082835, tar: 0.177123 
l0: 0.103037, l1: 0.108498, l2: 0.099347, l3: 0.100376, l4: 0.087134, l5: 0.082862, l6: 0.104940

[epoch:   7/100000, batch:   118/  187, ite: 623] train loss: 1.082198, tar: 0.177004 
l0: 0.143513, l1: 0.136019, l2: 0.138989, l3: 0.140865, l4: 0.178267, l5: 0.167034, l6: 0.186893

[epoch:   7/100000, batch:   120/  187, ite: 624] train loss: 1.082214, tar: 0.176950 
l0: 0.144270, l1: 0.147709, l2: 0.157860, l3: 0.164793, l4: 0.158197, l5: 0.147676, l6: 0.133200

[epoch:   7/100000, batch:   122/  187, ite: 625] train loss: 1.082168, tar: 0.176898 
l0: 0.124204, l1: 0.118640, l2: 0.120804, l3: 0.126964, l4: 0.141394, l5: 0.131968, l6: 0.147842

[epoch:   7/100000, batch:   124/  187, ite: 626] train loss: 1.081896, tar: 0.176814 
l0: 0.159611, l1: 0.165430, l2: 0.168689, l3: 0.165260, l4: 0.167360, l5: 0.152587, l6: 0.170717

[epoch:   7/100000, batch:   126/  187, ite: 627] train loss: 1.082004, tar: 0.176787 
l0: 0.146021, l1: 0.151578, l2: 0.151658, l3: 0.146906, l4: 0.152239, l5: 0.172719, l6: 0.144683

[epoch:   7/100000, batch:   128/  187, ite: 628] train loss: 1.081978, tar: 0.176738 
l0: 0.139951, l1: 0.137047, l2: 0.138553, l3: 0.146351, l4: 0.143484, l5: 0.137940, l6: 0.120327

[epoch:   7/100000, batch:   130/  187, ite: 629] train loss: 1.081790, tar: 0.176679 
l0: 0.112764, l1: 0.110229, l2: 0.115099, l3: 0.114500, l4: 0.118984, l5: 0.131928, l6: 0.144855

[epoch:   7/100000, batch:   132/  187, ite: 630] train loss: 1.081419, tar: 0.176578 
l0: 0.115661, l1: 0.111610, l2: 0.117460, l3: 0.120510, l4: 0.110056, l5: 0.108841, l6: 0.094339

[epoch:   7/100000, batch:   134/  187, ite: 631] train loss: 1.080939, tar: 0.176481 
l0: 0.097159, l1: 0.087451, l2: 0.105056, l3: 0.105213, l4: 0.104594, l5: 0.100178, l6: 0.099996

[epoch:   7/100000, batch:   136/  187, ite: 632] train loss: 1.080336, tar: 0.176356 
l0: 0.125086, l1: 0.113423, l2: 0.125693, l3: 0.131896, l4: 0.145341, l5: 0.151035, l6: 0.155389

[epoch:   7/100000, batch:   138/  187, ite: 633] train loss: 1.080127, tar: 0.176275 
l0: 0.102839, l1: 0.090830, l2: 0.098656, l3: 0.103199, l4: 0.108704, l5: 0.108906, l6: 0.094195

[epoch:   7/100000, batch:   140/  187, ite: 634] train loss: 1.079539, tar: 0.176159 
l0: 0.117406, l1: 0.117981, l2: 0.124967, l3: 0.128615, l4: 0.127589, l5: 0.120175, l6: 0.113889

[epoch:   7/100000, batch:   142/  187, ite: 635] train loss: 1.079178, tar: 0.176066 
l0: 0.126996, l1: 0.127006, l2: 0.132099, l3: 0.141616, l4: 0.136327, l5: 0.118420, l6: 0.114494

[epoch:   7/100000, batch:   144/  187, ite: 636] train loss: 1.078892, tar: 0.175989 
l0: 0.088803, l1: 0.078620, l2: 0.081668, l3: 0.085821, l4: 0.090318, l5: 0.087715, l6: 0.099558

[epoch:   7/100000, batch:   146/  187, ite: 637] train loss: 1.078160, tar: 0.175852 
l0: 0.080796, l1: 0.070344, l2: 0.073143, l3: 0.075930, l4: 0.084997, l5: 0.073528, l6: 0.077955

[epoch:   7/100000, batch:   148/  187, ite: 638] train loss: 1.077311, tar: 0.175703 
l0: 0.110477, l1: 0.103282, l2: 0.103371, l3: 0.109047, l4: 0.111455, l5: 0.114867, l6: 0.104156

[epoch:   7/100000, batch:   150/  187, ite: 639] train loss: 1.076809, tar: 0.175601 
l0: 0.096223, l1: 0.091318, l2: 0.103781, l3: 0.105160, l4: 0.099373, l5: 0.092469, l6: 0.083942

[epoch:   7/100000, batch:   152/  187, ite: 640] train loss: 1.076177, tar: 0.175477 
l0: 0.100840, l1: 0.101265, l2: 0.115912, l3: 0.116588, l4: 0.120870, l5: 0.112810, l6: 0.113353

[epoch:   7/100000, batch:   154/  187, ite: 641] train loss: 1.075717, tar: 0.175361 
l0: 0.058791, l1: 0.051598, l2: 0.058947, l3: 0.050323, l4: 0.051414, l5: 0.056298, l6: 0.047002

[epoch:   7/100000, batch:   156/  187, ite: 642] train loss: 1.074625, tar: 0.175179 
l0: 0.089567, l1: 0.108919, l2: 0.111152, l3: 0.097075, l4: 0.090194, l5: 0.092722, l6: 0.096923

[epoch:   7/100000, batch:   158/  187, ite: 643] train loss: 1.074021, tar: 0.175046 
l0: 0.050291, l1: 0.044456, l2: 0.056726, l3: 0.052486, l4: 0.047018, l5: 0.044188, l6: 0.038131

[epoch:   7/100000, batch:   160/  187, ite: 644] train loss: 1.072871, tar: 0.174852 
l0: 0.095980, l1: 0.113657, l2: 0.089653, l3: 0.081248, l4: 0.091783, l5: 0.082103, l6: 0.105922

[epoch:   7/100000, batch:   162/  187, ite: 645] train loss: 1.072232, tar: 0.174730 
l0: 0.109481, l1: 0.138381, l2: 0.093349, l3: 0.095539, l4: 0.088939, l5: 0.089496, l6: 0.092784

[epoch:   7/100000, batch:   164/  187, ite: 646] train loss: 1.071668, tar: 0.174629 
l0: 0.106920, l1: 0.119926, l2: 0.103316, l3: 0.099133, l4: 0.101563, l5: 0.121407, l6: 0.124566

[epoch:   7/100000, batch:   166/  187, ite: 647] train loss: 1.071212, tar: 0.174524 
l0: 0.076026, l1: 0.075345, l2: 0.086738, l3: 0.082988, l4: 0.081599, l5: 0.076734, l6: 0.075032

[epoch:   7/100000, batch:   168/  187, ite: 648] train loss: 1.070415, tar: 0.174372 
l0: 0.131207, l1: 0.149287, l2: 0.114935, l3: 0.113726, l4: 0.110573, l5: 0.139602, l6: 0.137858

[epoch:   7/100000, batch:   170/  187, ite: 649] train loss: 1.070148, tar: 0.174306 
l0: 0.131259, l1: 0.140660, l2: 0.143853, l3: 0.145898, l4: 0.165094, l5: 0.158483, l6: 0.142085

[epoch:   7/100000, batch:   172/  187, ite: 650] train loss: 1.070082, tar: 0.174240 
l0: 0.059651, l1: 0.047630, l2: 0.057554, l3: 0.059242, l4: 0.057953, l5: 0.069277, l6: 0.088814

[epoch:   7/100000, batch:   174/  187, ite: 651] train loss: 1.069114, tar: 0.174064 
l0: 0.109794, l1: 0.102310, l2: 0.107786, l3: 0.121938, l4: 0.118933, l5: 0.154105, l6: 0.171522

[epoch:   7/100000, batch:   176/  187, ite: 652] train loss: 1.068834, tar: 0.173965 
l0: 0.082340, l1: 0.077913, l2: 0.083412, l3: 0.086402, l4: 0.077251, l5: 0.079138, l6: 0.078021

[epoch:   7/100000, batch:   178/  187, ite: 653] train loss: 1.068062, tar: 0.173825 
l0: 0.089757, l1: 0.109801, l2: 0.093618, l3: 0.078187, l4: 0.080819, l5: 0.074819, l6: 0.075541

[epoch:   7/100000, batch:   180/  187, ite: 654] train loss: 1.067350, tar: 0.173696 
l0: 0.109372, l1: 0.107135, l2: 0.111367, l3: 0.109198, l4: 0.111287, l5: 0.113027, l6: 0.110018

[epoch:   7/100000, batch:   182/  187, ite: 655] train loss: 1.066898, tar: 0.173598 
l0: 0.111176, l1: 0.114845, l2: 0.118057, l3: 0.118064, l4: 0.122712, l5: 0.102561, l6: 0.104219

[epoch:   7/100000, batch:   184/  187, ite: 656] train loss: 1.066478, tar: 0.173503 
l0: 0.112060, l1: 0.115334, l2: 0.113930, l3: 0.113641, l4: 0.108132, l5: 0.102645, l6: 0.115483

[epoch:   7/100000, batch:   186/  187, ite: 657] train loss: 1.066044, tar: 0.173409 
l0: 0.110018, l1: 0.101659, l2: 0.119673, l3: 0.125041, l4: 0.118064, l5: 0.148842, l6: 0.108583

[epoch:   7/100000, batch:   188/  187, ite: 658] train loss: 1.065688, tar: 0.173313 
l0: 0.162009, l1: 0.182060, l2: 0.161364, l3: 0.180526, l4: 0.172978, l5: 0.163296, l6: 0.195142

[epoch:   8/100000, batch:     2/  187, ite: 659] train loss: 1.065918, tar: 0.173296 
l0: 0.139678, l1: 0.142635, l2: 0.140470, l3: 0.145910, l4: 0.143509, l5: 0.133719, l6: 0.156533

[epoch:   8/100000, batch:     4/  187, ite: 660] train loss: 1.065822, tar: 0.173245 
l0: 0.097308, l1: 0.094869, l2: 0.096973, l3: 0.093596, l4: 0.102423, l5: 0.093977, l6: 0.080447

[epoch:   8/100000, batch:     6/  187, ite: 661] train loss: 1.065208, tar: 0.173130 
l0: 0.135871, l1: 0.139520, l2: 0.150747, l3: 0.142717, l4: 0.153753, l5: 0.157610, l6: 0.134830

[epoch:   8/100000, batch:     8/  187, ite: 662] train loss: 1.065132, tar: 0.173074 
l0: 0.100687, l1: 0.093948, l2: 0.106335, l3: 0.110982, l4: 0.109391, l5: 0.105793, l6: 0.132140

[epoch:   8/100000, batch:    10/  187, ite: 663] train loss: 1.064671, tar: 0.172964 
l0: 0.075645, l1: 0.062833, l2: 0.068901, l3: 0.072874, l4: 0.074965, l5: 0.075090, l6: 0.098137

[epoch:   8/100000, batch:    12/  187, ite: 664] train loss: 1.063863, tar: 0.172818 
l0: 0.085143, l1: 0.073644, l2: 0.083822, l3: 0.076148, l4: 0.083563, l5: 0.087697, l6: 0.080169

[epoch:   8/100000, batch:    14/  187, ite: 665] train loss: 1.063121, tar: 0.172686 
l0: 0.086052, l1: 0.089332, l2: 0.108208, l3: 0.110404, l4: 0.094661, l5: 0.088446, l6: 0.074414

[epoch:   8/100000, batch:    16/  187, ite: 666] train loss: 1.062503, tar: 0.172556 
l0: 0.144923, l1: 0.159513, l2: 0.166020, l3: 0.161985, l4: 0.150148, l5: 0.141378, l6: 0.164376

[epoch:   8/100000, batch:    18/  187, ite: 667] train loss: 1.062541, tar: 0.172515 
l0: 0.089570, l1: 0.086606, l2: 0.087896, l3: 0.080664, l4: 0.084770, l5: 0.080198, l6: 0.099441

[epoch:   8/100000, batch:    20/  187, ite: 668] train loss: 1.061863, tar: 0.172390 
l0: 0.076915, l1: 0.072784, l2: 0.077548, l3: 0.080399, l4: 0.075684, l5: 0.074416, l6: 0.074506

[epoch:   8/100000, batch:    22/  187, ite: 669] train loss: 1.061071, tar: 0.172248 
l0: 0.130190, l1: 0.135540, l2: 0.134954, l3: 0.126616, l4: 0.144392, l5: 0.133115, l6: 0.171169

[epoch:   8/100000, batch:    24/  187, ite: 670] train loss: 1.060944, tar: 0.172185 
l0: 0.102260, l1: 0.094987, l2: 0.104285, l3: 0.090796, l4: 0.100814, l5: 0.095408, l6: 0.157281

[epoch:   8/100000, batch:    26/  187, ite: 671] train loss: 1.060474, tar: 0.172081 
l0: 0.080081, l1: 0.080317, l2: 0.075910, l3: 0.072015, l4: 0.078835, l5: 0.081211, l6: 0.064777

[epoch:   8/100000, batch:    28/  187, ite: 672] train loss: 1.059690, tar: 0.171944 
l0: 0.154924, l1: 0.153245, l2: 0.161427, l3: 0.175232, l4: 0.209031, l5: 0.222435, l6: 0.184195

[epoch:   8/100000, batch:    30/  187, ite: 673] train loss: 1.059988, tar: 0.171918 
l0: 0.079078, l1: 0.074221, l2: 0.084879, l3: 0.081815, l4: 0.076840, l5: 0.075855, l6: 0.065047

[epoch:   8/100000, batch:    32/  187, ite: 674] train loss: 1.059213, tar: 0.171781 
l0: 0.203245, l1: 0.217681, l2: 0.225603, l3: 0.241540, l4: 0.259890, l5: 0.270416, l6: 0.239695

[epoch:   8/100000, batch:    34/  187, ite: 675] train loss: 1.060100, tar: 0.171827 
l0: 0.134743, l1: 0.132882, l2: 0.137596, l3: 0.137678, l4: 0.150360, l5: 0.142653, l6: 0.130831

[epoch:   8/100000, batch:    36/  187, ite: 676] train loss: 1.059962, tar: 0.171772 
l0: 0.109719, l1: 0.109538, l2: 0.109724, l3: 0.111237, l4: 0.100886, l5: 0.101648, l6: 0.132718

[epoch:   8/100000, batch:    38/  187, ite: 677] train loss: 1.059542, tar: 0.171681 
l0: 0.134314, l1: 0.134575, l2: 0.137357, l3: 0.143111, l4: 0.155481, l5: 0.158980, l6: 0.147058

[epoch:   8/100000, batch:    40/  187, ite: 678] train loss: 1.059470, tar: 0.171626 
l0: 0.105274, l1: 0.095140, l2: 0.098434, l3: 0.099013, l4: 0.107208, l5: 0.128619, l6: 0.126980

[epoch:   8/100000, batch:    42/  187, ite: 679] train loss: 1.059030, tar: 0.171528 
l0: 0.094698, l1: 0.097083, l2: 0.097707, l3: 0.089497, l4: 0.103626, l5: 0.110530, l6: 0.097851

[epoch:   8/100000, batch:    44/  187, ite: 680] train loss: 1.058489, tar: 0.171415 
l0: 0.121057, l1: 0.112226, l2: 0.137252, l3: 0.134234, l4: 0.142771, l5: 0.162067, l6: 0.164605

[epoch:   8/100000, batch:    46/  187, ite: 681] train loss: 1.058365, tar: 0.171341 
l0: 0.118189, l1: 0.108840, l2: 0.116049, l3: 0.120437, l4: 0.134688, l5: 0.133416, l6: 0.132129

[epoch:   8/100000, batch:    48/  187, ite: 682] train loss: 1.058080, tar: 0.171263 
l0: 0.110185, l1: 0.104488, l2: 0.116978, l3: 0.122925, l4: 0.119182, l5: 0.111740, l6: 0.106990

[epoch:   8/100000, batch:    50/  187, ite: 683] train loss: 1.057691, tar: 0.171174 
l0: 0.109058, l1: 0.110469, l2: 0.115278, l3: 0.119752, l4: 0.114039, l5: 0.107141, l6: 0.103815

[epoch:   8/100000, batch:    52/  187, ite: 684] train loss: 1.057284, tar: 0.171083 
l0: 0.126572, l1: 0.128508, l2: 0.127808, l3: 0.126065, l4: 0.131415, l5: 0.126339, l6: 0.141362

[epoch:   8/100000, batch:    54/  187, ite: 685] train loss: 1.057067, tar: 0.171018 
l0: 0.135365, l1: 0.127424, l2: 0.145368, l3: 0.141986, l4: 0.161410, l5: 0.163611, l6: 0.153088

[epoch:   8/100000, batch:    56/  187, ite: 686] train loss: 1.057025, tar: 0.170966 
l0: 0.108332, l1: 0.101524, l2: 0.109543, l3: 0.104552, l4: 0.121169, l5: 0.138839, l6: 0.141826

[epoch:   8/100000, batch:    58/  187, ite: 687] train loss: 1.056688, tar: 0.170875 
l0: 0.115973, l1: 0.113068, l2: 0.138710, l3: 0.131623, l4: 0.125070, l5: 0.123048, l6: 0.134747

[epoch:   8/100000, batch:    60/  187, ite: 688] train loss: 1.056434, tar: 0.170795 
l0: 0.131769, l1: 0.141341, l2: 0.139376, l3: 0.137084, l4: 0.132741, l5: 0.134769, l6: 0.145481

[epoch:   8/100000, batch:    62/  187, ite: 689] train loss: 1.056298, tar: 0.170738 
l0: 0.051141, l1: 0.052277, l2: 0.048828, l3: 0.048333, l4: 0.057072, l5: 0.043339, l6: 0.041119

[epoch:   8/100000, batch:    64/  187, ite: 690] train loss: 1.055263, tar: 0.170565 
l0: 0.129823, l1: 0.132971, l2: 0.121996, l3: 0.121361, l4: 0.133148, l5: 0.147945, l6: 0.134422

[epoch:   8/100000, batch:    66/  187, ite: 691] train loss: 1.055070, tar: 0.170506 
l0: 0.143614, l1: 0.139314, l2: 0.168216, l3: 0.185599, l4: 0.150151, l5: 0.154493, l6: 0.161669

[epoch:   8/100000, batch:    68/  187, ite: 692] train loss: 1.055139, tar: 0.170467 
l0: 0.107169, l1: 0.096736, l2: 0.110979, l3: 0.110446, l4: 0.117340, l5: 0.107513, l6: 0.123784

[epoch:   8/100000, batch:    70/  187, ite: 693] train loss: 1.054733, tar: 0.170376 
l0: 0.124642, l1: 0.131105, l2: 0.129307, l3: 0.119392, l4: 0.141226, l5: 0.138536, l6: 0.126774

[epoch:   8/100000, batch:    72/  187, ite: 694] train loss: 1.054526, tar: 0.170310 
l0: 0.125401, l1: 0.124233, l2: 0.136156, l3: 0.147290, l4: 0.129415, l5: 0.124826, l6: 0.121346

[epoch:   8/100000, batch:    74/  187, ite: 695] train loss: 1.054316, tar: 0.170245 
l0: 0.116173, l1: 0.121556, l2: 0.118033, l3: 0.116881, l4: 0.128346, l5: 0.123532, l6: 0.118776

[epoch:   8/100000, batch:    76/  187, ite: 696] train loss: 1.054013, tar: 0.170168 
l0: 0.083416, l1: 0.075336, l2: 0.084520, l3: 0.079421, l4: 0.096268, l5: 0.102635, l6: 0.097690

[epoch:   8/100000, batch:    78/  187, ite: 697] train loss: 1.053389, tar: 0.170043 
l0: 0.124941, l1: 0.122160, l2: 0.135797, l3: 0.137339, l4: 0.151918, l5: 0.144111, l6: 0.131517

[epoch:   8/100000, batch:    80/  187, ite: 698] train loss: 1.053238, tar: 0.169979 
l0: 0.117068, l1: 0.133597, l2: 0.119414, l3: 0.115698, l4: 0.114325, l5: 0.109990, l6: 0.111284

[epoch:   8/100000, batch:    82/  187, ite: 699] train loss: 1.052906, tar: 0.169903 
l0: 0.107308, l1: 0.102650, l2: 0.107257, l3: 0.099148, l4: 0.121583, l5: 0.122811, l6: 0.100606

[epoch:   8/100000, batch:    84/  187, ite: 700] train loss: 1.052490, tar: 0.169813 
l0: 0.101095, l1: 0.096632, l2: 0.101271, l3: 0.102533, l4: 0.103499, l5: 0.103615, l6: 0.089499

[epoch:   8/100000, batch:    86/  187, ite: 701] train loss: 1.051984, tar: 0.169715 
l0: 0.091209, l1: 0.087798, l2: 0.091407, l3: 0.091542, l4: 0.102226, l5: 0.093959, l6: 0.089964

[epoch:   8/100000, batch:    88/  187, ite: 702] train loss: 1.051409, tar: 0.169604 
l0: 0.140064, l1: 0.147268, l2: 0.135043, l3: 0.126606, l4: 0.145957, l5: 0.134825, l6: 0.159386

[epoch:   8/100000, batch:    90/  187, ite: 703] train loss: 1.051321, tar: 0.169562 
l0: 0.124715, l1: 0.129932, l2: 0.138042, l3: 0.146958, l4: 0.135548, l5: 0.115110, l6: 0.112991

[epoch:   8/100000, batch:    92/  187, ite: 704] train loss: 1.051110, tar: 0.169498 
l0: 0.088016, l1: 0.073195, l2: 0.078657, l3: 0.079163, l4: 0.091026, l5: 0.106356, l6: 0.123465

[epoch:   8/100000, batch:    94/  187, ite: 705] train loss: 1.050527, tar: 0.169382 
l0: 0.149297, l1: 0.138678, l2: 0.156604, l3: 0.138544, l4: 0.192509, l5: 0.188271, l6: 0.187424

[epoch:   8/100000, batch:    96/  187, ite: 706] train loss: 1.050670, tar: 0.169354 
l0: 0.093383, l1: 0.092015, l2: 0.094704, l3: 0.091800, l4: 0.097475, l5: 0.097894, l6: 0.100485

[epoch:   8/100000, batch:    98/  187, ite: 707] train loss: 1.050128, tar: 0.169246 
l0: 0.082873, l1: 0.084236, l2: 0.092059, l3: 0.098054, l4: 0.092662, l5: 0.082462, l6: 0.079512

[epoch:   8/100000, batch:   100/  187, ite: 708] train loss: 1.049509, tar: 0.169124 
l0: 0.076626, l1: 0.070488, l2: 0.085081, l3: 0.083233, l4: 0.102186, l5: 0.085475, l6: 0.076133

[epoch:   8/100000, batch:   102/  187, ite: 709] train loss: 1.048846, tar: 0.168994 
l0: 0.069231, l1: 0.059720, l2: 0.067236, l3: 0.066429, l4: 0.093454, l5: 0.079532, l6: 0.096924

[epoch:   8/100000, batch:   104/  187, ite: 710] train loss: 1.048119, tar: 0.168853 
l0: 0.103651, l1: 0.099051, l2: 0.113662, l3: 0.111373, l4: 0.124503, l5: 0.115993, l6: 0.105128

[epoch:   8/100000, batch:   106/  187, ite: 711] train loss: 1.047732, tar: 0.168762 
l0: 0.108152, l1: 0.106441, l2: 0.119901, l3: 0.122981, l4: 0.119280, l5: 0.120046, l6: 0.112246

[epoch:   8/100000, batch:   108/  187, ite: 712] train loss: 1.047397, tar: 0.168677 
l0: 0.077626, l1: 0.078661, l2: 0.075914, l3: 0.076297, l4: 0.080913, l5: 0.088797, l6: 0.077501

[epoch:   8/100000, batch:   110/  187, ite: 713] train loss: 1.046707, tar: 0.168549 
l0: 0.135827, l1: 0.167187, l2: 0.143757, l3: 0.147484, l4: 0.133315, l5: 0.122448, l6: 0.128256

[epoch:   8/100000, batch:   112/  187, ite: 714] train loss: 1.046612, tar: 0.168503 
l0: 0.116372, l1: 0.117123, l2: 0.123416, l3: 0.128004, l4: 0.137101, l5: 0.148416, l6: 0.143500

[epoch:   8/100000, batch:   114/  187, ite: 715] train loss: 1.046426, tar: 0.168430 
l0: 0.180788, l1: 0.199529, l2: 0.202248, l3: 0.221617, l4: 0.214978, l5: 0.234447, l6: 0.247890

[epoch:   8/100000, batch:   116/  187, ite: 716] train loss: 1.047062, tar: 0.168447 
l0: 0.062021, l1: 0.069172, l2: 0.066924, l3: 0.063287, l4: 0.060142, l5: 0.073910, l6: 0.056782

[epoch:   8/100000, batch:   118/  187, ite: 717] train loss: 1.046232, tar: 0.168299 
l0: 0.230406, l1: 0.309035, l2: 0.225319, l3: 0.239238, l4: 0.213930, l5: 0.220363, l6: 0.216657

[epoch:   8/100000, batch:   120/  187, ite: 718] train loss: 1.047080, tar: 0.168385 
l0: 0.109184, l1: 0.118865, l2: 0.120316, l3: 0.119029, l4: 0.136312, l5: 0.110631, l6: 0.103116

[epoch:   8/100000, batch:   122/  187, ite: 719] train loss: 1.046760, tar: 0.168303 
l0: 0.086727, l1: 0.089712, l2: 0.091734, l3: 0.091471, l4: 0.097747, l5: 0.096716, l6: 0.086239

[epoch:   8/100000, batch:   124/  187, ite: 720] train loss: 1.046196, tar: 0.168190 
l0: 0.069443, l1: 0.070429, l2: 0.073429, l3: 0.060212, l4: 0.060689, l5: 0.078123, l6: 0.071763

[epoch:   8/100000, batch:   126/  187, ite: 721] train loss: 1.045416, tar: 0.168053 
l0: 0.139354, l1: 0.152692, l2: 0.154921, l3: 0.151028, l4: 0.174314, l5: 0.145982, l6: 0.162427

[epoch:   8/100000, batch:   128/  187, ite: 722] train loss: 1.045465, tar: 0.168013 
l0: 0.133735, l1: 0.146646, l2: 0.147858, l3: 0.145975, l4: 0.169964, l5: 0.150846, l6: 0.139287

[epoch:   8/100000, batch:   130/  187, ite: 723] train loss: 1.045450, tar: 0.167966 
l0: 0.103907, l1: 0.109099, l2: 0.108299, l3: 0.102797, l4: 0.130518, l5: 0.114452, l6: 0.097683

[epoch:   8/100000, batch:   132/  187, ite: 724] train loss: 1.045065, tar: 0.167877 
l0: 0.120228, l1: 0.137093, l2: 0.111697, l3: 0.103371, l4: 0.127151, l5: 0.119569, l6: 0.112286

[epoch:   8/100000, batch:   134/  187, ite: 725] train loss: 1.044770, tar: 0.167811 
l0: 0.112409, l1: 0.114225, l2: 0.115747, l3: 0.110903, l4: 0.121813, l5: 0.125696, l6: 0.108171

[epoch:   8/100000, batch:   136/  187, ite: 726] train loss: 1.044445, tar: 0.167735 
l0: 0.136925, l1: 0.136864, l2: 0.155573, l3: 0.155381, l4: 0.156416, l5: 0.150239, l6: 0.142626

[epoch:   8/100000, batch:   138/  187, ite: 727] train loss: 1.044431, tar: 0.167693 
l0: 0.143536, l1: 0.137372, l2: 0.136297, l3: 0.142766, l4: 0.145073, l5: 0.171473, l6: 0.172308

[epoch:   8/100000, batch:   140/  187, ite: 728] train loss: 1.044437, tar: 0.167660 
l0: 0.072545, l1: 0.071897, l2: 0.066559, l3: 0.071715, l4: 0.081944, l5: 0.064733, l6: 0.077936

[epoch:   8/100000, batch:   142/  187, ite: 729] train loss: 1.043700, tar: 0.167529 
l0: 0.072226, l1: 0.069053, l2: 0.073693, l3: 0.070239, l4: 0.081580, l5: 0.067585, l6: 0.066301

[epoch:   8/100000, batch:   144/  187, ite: 730] train loss: 1.042956, tar: 0.167399 
l0: 0.077922, l1: 0.087047, l2: 0.092216, l3: 0.091240, l4: 0.094090, l5: 0.078780, l6: 0.061490

[epoch:   8/100000, batch:   146/  187, ite: 731] train loss: 1.042327, tar: 0.167276 
l0: 0.111324, l1: 0.117445, l2: 0.092998, l3: 0.106566, l4: 0.117191, l5: 0.121096, l6: 0.103723

[epoch:   8/100000, batch:   148/  187, ite: 732] train loss: 1.041955, tar: 0.167200 
l0: 0.111598, l1: 0.104858, l2: 0.127146, l3: 0.141902, l4: 0.114402, l5: 0.111997, l6: 0.127059

[epoch:   8/100000, batch:   150/  187, ite: 733] train loss: 1.041678, tar: 0.167124 
l0: 0.153749, l1: 0.148058, l2: 0.168024, l3: 0.186461, l4: 0.150321, l5: 0.156045, l6: 0.195364

[epoch:   8/100000, batch:   152/  187, ite: 734] train loss: 1.041837, tar: 0.167106 
l0: 0.130048, l1: 0.121982, l2: 0.131337, l3: 0.141827, l4: 0.139264, l5: 0.134927, l6: 0.174228

[epoch:   8/100000, batch:   154/  187, ite: 735] train loss: 1.041744, tar: 0.167055 
l0: 0.096340, l1: 0.092265, l2: 0.094252, l3: 0.093520, l4: 0.107517, l5: 0.104141, l6: 0.098946

[epoch:   8/100000, batch:   156/  187, ite: 736] train loss: 1.041262, tar: 0.166959 
l0: 0.116271, l1: 0.122029, l2: 0.105989, l3: 0.115176, l4: 0.113192, l5: 0.110386, l6: 0.128964

[epoch:   8/100000, batch:   158/  187, ite: 737] train loss: 1.040951, tar: 0.166890 
l0: 0.095235, l1: 0.087618, l2: 0.094707, l3: 0.096504, l4: 0.102848, l5: 0.127087, l6: 0.128537

[epoch:   8/100000, batch:   160/  187, ite: 738] train loss: 1.040533, tar: 0.166793 
l0: 0.096618, l1: 0.095057, l2: 0.105328, l3: 0.107713, l4: 0.106516, l5: 0.102618, l6: 0.105004

[epoch:   8/100000, batch:   162/  187, ite: 739] train loss: 1.040098, tar: 0.166698 
l0: 0.113359, l1: 0.110835, l2: 0.118228, l3: 0.116270, l4: 0.121826, l5: 0.123303, l6: 0.125134

[epoch:   8/100000, batch:   164/  187, ite: 740] train loss: 1.039812, tar: 0.166626 
l0: 0.118336, l1: 0.117339, l2: 0.125365, l3: 0.128279, l4: 0.116900, l5: 0.112351, l6: 0.118714

[epoch:   8/100000, batch:   166/  187, ite: 741] train loss: 1.039539, tar: 0.166561 
l0: 0.122605, l1: 0.122481, l2: 0.138427, l3: 0.133623, l4: 0.145350, l5: 0.152022, l6: 0.164156

[epoch:   8/100000, batch:   168/  187, ite: 742] train loss: 1.039457, tar: 0.166502 
l0: 0.058210, l1: 0.050441, l2: 0.054211, l3: 0.055307, l4: 0.048063, l5: 0.054233, l6: 0.068340

[epoch:   8/100000, batch:   170/  187, ite: 743] train loss: 1.038581, tar: 0.166356 
l0: 0.107905, l1: 0.109436, l2: 0.111217, l3: 0.113892, l4: 0.117261, l5: 0.106014, l6: 0.101582

[epoch:   8/100000, batch:   172/  187, ite: 744] train loss: 1.038217, tar: 0.166278 
l0: 0.118081, l1: 0.115157, l2: 0.123106, l3: 0.125429, l4: 0.130653, l5: 0.121482, l6: 0.129714

[epoch:   8/100000, batch:   174/  187, ite: 745] train loss: 1.037982, tar: 0.166213 
l0: 0.162776, l1: 0.184306, l2: 0.182741, l3: 0.192924, l4: 0.164785, l5: 0.160424, l6: 0.171563

[epoch:   8/100000, batch:   176/  187, ite: 746] train loss: 1.038226, tar: 0.166208 
l0: 0.061763, l1: 0.057741, l2: 0.064527, l3: 0.058503, l4: 0.052572, l5: 0.056247, l6: 0.049261

[epoch:   8/100000, batch:   178/  187, ite: 747] train loss: 1.037372, tar: 0.166068 
l0: 0.124744, l1: 0.120611, l2: 0.125381, l3: 0.126884, l4: 0.125556, l5: 0.131967, l6: 0.151509

[epoch:   8/100000, batch:   180/  187, ite: 748] train loss: 1.037197, tar: 0.166013 
l0: 0.072096, l1: 0.067042, l2: 0.073128, l3: 0.070997, l4: 0.071276, l5: 0.071161, l6: 0.067450

[epoch:   8/100000, batch:   182/  187, ite: 749] train loss: 1.036471, tar: 0.165888 
l0: 0.100343, l1: 0.104112, l2: 0.102293, l3: 0.102363, l4: 0.101173, l5: 0.094714, l6: 0.098434

[epoch:   8/100000, batch:   184/  187, ite: 750] train loss: 1.036027, tar: 0.165800 
l0: 0.111075, l1: 0.121119, l2: 0.111159, l3: 0.112220, l4: 0.109875, l5: 0.113639, l6: 0.116169

[epoch:   8/100000, batch:   186/  187, ite: 751] train loss: 1.035706, tar: 0.165728 
l0: 0.162385, l1: 0.167658, l2: 0.163879, l3: 0.161811, l4: 0.209218, l5: 0.212040, l6: 0.198704

[epoch:   8/100000, batch:   188/  187, ite: 752] train loss: 1.036026, tar: 0.165723 
l0: 0.163908, l1: 0.183450, l2: 0.178583, l3: 0.170810, l4: 0.192261, l5: 0.198449, l6: 0.188213

[epoch:   9/100000, batch:     2/  187, ite: 753] train loss: 1.036344, tar: 0.165721 
l0: 0.111907, l1: 0.112725, l2: 0.119426, l3: 0.114203, l4: 0.128471, l5: 0.126685, l6: 0.126257

[epoch:   9/100000, batch:     4/  187, ite: 754] train loss: 1.036083, tar: 0.165649 
l0: 0.112703, l1: 0.106981, l2: 0.117605, l3: 0.115204, l4: 0.118180, l5: 0.111758, l6: 0.113489

[epoch:   9/100000, batch:     6/  187, ite: 755] train loss: 1.035765, tar: 0.165579 
l0: 0.117476, l1: 0.118807, l2: 0.124048, l3: 0.115421, l4: 0.125868, l5: 0.117387, l6: 0.123408

[epoch:   9/100000, batch:     8/  187, ite: 756] train loss: 1.035509, tar: 0.165516 
l0: 0.087084, l1: 0.071125, l2: 0.071762, l3: 0.089236, l4: 0.089663, l5: 0.093808, l6: 0.113256

[epoch:   9/100000, batch:    10/  187, ite: 757] train loss: 1.034955, tar: 0.165412 
l0: 0.120023, l1: 0.117540, l2: 0.112831, l3: 0.124956, l4: 0.153052, l5: 0.133653, l6: 0.141161

[epoch:   9/100000, batch:    12/  187, ite: 758] train loss: 1.034781, tar: 0.165352 
l0: 0.119626, l1: 0.098423, l2: 0.106652, l3: 0.119488, l4: 0.133373, l5: 0.190304, l6: 0.158525

[epoch:   9/100000, batch:    14/  187, ite: 759] train loss: 1.034638, tar: 0.165292 
l0: 0.098839, l1: 0.086757, l2: 0.097188, l3: 0.113667, l4: 0.103882, l5: 0.120216, l6: 0.115867

[epoch:   9/100000, batch:    16/  187, ite: 760] train loss: 1.034246, tar: 0.165204 
l0: 0.206408, l1: 0.245769, l2: 0.175804, l3: 0.217847, l4: 0.168761, l5: 0.209701, l6: 0.185790

[epoch:   9/100000, batch:    18/  187, ite: 761] train loss: 1.034740, tar: 0.165258 
l0: 0.155366, l1: 0.158951, l2: 0.157827, l3: 0.152825, l4: 0.172677, l5: 0.175126, l6: 0.164855

[epoch:   9/100000, batch:    20/  187, ite: 762] train loss: 1.034875, tar: 0.165246 
l0: 0.125661, l1: 0.123722, l2: 0.124696, l3: 0.130071, l4: 0.126656, l5: 0.136891, l6: 0.134305

[epoch:   9/100000, batch:    22/  187, ite: 763] train loss: 1.034701, tar: 0.165194 
l0: 0.089361, l1: 0.083647, l2: 0.094100, l3: 0.091689, l4: 0.084399, l5: 0.101505, l6: 0.096924

[epoch:   9/100000, batch:    24/  187, ite: 764] train loss: 1.034186, tar: 0.165094 
l0: 0.097562, l1: 0.099731, l2: 0.101724, l3: 0.096363, l4: 0.094897, l5: 0.099153, l6: 0.088440

[epoch:   9/100000, batch:    26/  187, ite: 765] train loss: 1.033720, tar: 0.165006 
l0: 0.124829, l1: 0.116466, l2: 0.116563, l3: 0.136494, l4: 0.181707, l5: 0.142427, l6: 0.166105

[epoch:   9/100000, batch:    28/  187, ite: 766] train loss: 1.033656, tar: 0.164954 
l0: 0.099113, l1: 0.098035, l2: 0.096452, l3: 0.104160, l4: 0.099636, l5: 0.100430, l6: 0.101862

[epoch:   9/100000, batch:    30/  187, ite: 767] train loss: 1.033221, tar: 0.164868 
l0: 0.100329, l1: 0.108011, l2: 0.100418, l3: 0.091982, l4: 0.109230, l5: 0.098027, l6: 0.102219

[epoch:   9/100000, batch:    32/  187, ite: 768] train loss: 1.032800, tar: 0.164784 
l0: 0.093191, l1: 0.093180, l2: 0.085888, l3: 0.086939, l4: 0.091780, l5: 0.087830, l6: 0.090284

[epoch:   9/100000, batch:    34/  187, ite: 769] train loss: 1.032275, tar: 0.164691 
l0: 0.128786, l1: 0.135650, l2: 0.130658, l3: 0.124009, l4: 0.131351, l5: 0.131508, l6: 0.135149

[epoch:   9/100000, batch:    36/  187, ite: 770] train loss: 1.032126, tar: 0.164644 
l0: 0.073769, l1: 0.078389, l2: 0.068225, l3: 0.074378, l4: 0.079649, l5: 0.062700, l6: 0.078000

[epoch:   9/100000, batch:    38/  187, ite: 771] train loss: 1.031455, tar: 0.164526 
l0: 0.068028, l1: 0.066195, l2: 0.073244, l3: 0.070352, l4: 0.080585, l5: 0.069100, l6: 0.068310

[epoch:   9/100000, batch:    40/  187, ite: 772] train loss: 1.030761, tar: 0.164401 
l0: 0.146137, l1: 0.163031, l2: 0.155478, l3: 0.148663, l4: 0.141588, l5: 0.151823, l6: 0.154422

[epoch:   9/100000, batch:    42/  187, ite: 773] train loss: 1.030800, tar: 0.164378 
l0: 0.100655, l1: 0.106604, l2: 0.120545, l3: 0.104509, l4: 0.108617, l5: 0.106872, l6: 0.099028

[epoch:   9/100000, batch:    44/  187, ite: 774] train loss: 1.030434, tar: 0.164295 
l0: 0.140254, l1: 0.151471, l2: 0.138603, l3: 0.147536, l4: 0.126652, l5: 0.132701, l6: 0.167046

[epoch:   9/100000, batch:    46/  187, ite: 775] train loss: 1.030400, tar: 0.164264 
l0: 0.108318, l1: 0.107659, l2: 0.096525, l3: 0.106434, l4: 0.123430, l5: 0.124612, l6: 0.114520

[epoch:   9/100000, batch:    48/  187, ite: 776] train loss: 1.030079, tar: 0.164192 
l0: 0.130367, l1: 0.126599, l2: 0.141561, l3: 0.129535, l4: 0.143511, l5: 0.147955, l6: 0.154503

[epoch:   9/100000, batch:    50/  187, ite: 777] train loss: 1.030007, tar: 0.164149 
l0: 0.135939, l1: 0.141470, l2: 0.149705, l3: 0.143595, l4: 0.145048, l5: 0.145009, l6: 0.138988

[epoch:   9/100000, batch:    52/  187, ite: 778] train loss: 1.029968, tar: 0.164112 
l0: 0.115467, l1: 0.131928, l2: 0.130077, l3: 0.115929, l4: 0.127651, l5: 0.124889, l6: 0.123153

[epoch:   9/100000, batch:    54/  187, ite: 779] train loss: 1.029762, tar: 0.164050 
l0: 0.129859, l1: 0.142545, l2: 0.139397, l3: 0.133477, l4: 0.135358, l5: 0.143395, l6: 0.140041

[epoch:   9/100000, batch:    56/  187, ite: 780] train loss: 1.029677, tar: 0.164006 
l0: 0.111936, l1: 0.113007, l2: 0.120895, l3: 0.109768, l4: 0.107303, l5: 0.123084, l6: 0.128333

[epoch:   9/100000, batch:    58/  187, ite: 781] train loss: 1.029402, tar: 0.163939 
l0: 0.115699, l1: 0.119086, l2: 0.110321, l3: 0.116757, l4: 0.127515, l5: 0.113121, l6: 0.104752

[epoch:   9/100000, batch:    60/  187, ite: 782] train loss: 1.029118, tar: 0.163878 
l0: 0.107122, l1: 0.100699, l2: 0.113912, l3: 0.121907, l4: 0.127124, l5: 0.127717, l6: 0.140499

[epoch:   9/100000, batch:    62/  187, ite: 783] train loss: 1.028875, tar: 0.163805 
l0: 0.111648, l1: 0.110495, l2: 0.119228, l3: 0.117566, l4: 0.128174, l5: 0.127197, l6: 0.119815

[epoch:   9/100000, batch:    64/  187, ite: 784] train loss: 1.028626, tar: 0.163739 
l0: 0.108956, l1: 0.110703, l2: 0.121482, l3: 0.121350, l4: 0.111909, l5: 0.113220, l6: 0.105509

[epoch:   9/100000, batch:    66/  187, ite: 785] train loss: 1.028326, tar: 0.163669 
l0: 0.088929, l1: 0.086078, l2: 0.094114, l3: 0.092510, l4: 0.090412, l5: 0.087641, l6: 0.091282

[epoch:   9/100000, batch:    68/  187, ite: 786] train loss: 1.027821, tar: 0.163574 
l0: 0.090613, l1: 0.082761, l2: 0.088334, l3: 0.087011, l4: 0.092971, l5: 0.099897, l6: 0.092987

[epoch:   9/100000, batch:    70/  187, ite: 787] train loss: 1.027321, tar: 0.163481 
l0: 0.153849, l1: 0.160603, l2: 0.165961, l3: 0.168814, l4: 0.182699, l5: 0.170058, l6: 0.155044

[epoch:   9/100000, batch:    72/  187, ite: 788] train loss: 1.027486, tar: 0.163469 
l0: 0.108717, l1: 0.109191, l2: 0.110127, l3: 0.105323, l4: 0.118570, l5: 0.118420, l6: 0.117629

[epoch:   9/100000, batch:    74/  187, ite: 789] train loss: 1.027182, tar: 0.163399 
l0: 0.156065, l1: 0.170147, l2: 0.164002, l3: 0.170470, l4: 0.166960, l5: 0.159206, l6: 0.161796

[epoch:   9/100000, batch:    76/  187, ite: 790] train loss: 1.027336, tar: 0.163390 
l0: 0.126669, l1: 0.123861, l2: 0.121105, l3: 0.133617, l4: 0.129837, l5: 0.133305, l6: 0.130647

[epoch:   9/100000, batch:    78/  187, ite: 791] train loss: 1.027174, tar: 0.163344 
l0: 0.095620, l1: 0.089567, l2: 0.092140, l3: 0.095507, l4: 0.105184, l5: 0.104563, l6: 0.103730

[epoch:   9/100000, batch:    80/  187, ite: 792] train loss: 1.026743, tar: 0.163258 
l0: 0.124522, l1: 0.112182, l2: 0.116087, l3: 0.136972, l4: 0.130796, l5: 0.136838, l6: 0.133619

[epoch:   9/100000, batch:    82/  187, ite: 793] train loss: 1.026572, tar: 0.163209 
l0: 0.179771, l1: 0.195473, l2: 0.210539, l3: 0.201469, l4: 0.186932, l5: 0.193011, l6: 0.178894

[epoch:   9/100000, batch:    84/  187, ite: 794] train loss: 1.026975, tar: 0.163230 
l0: 0.164735, l1: 0.174028, l2: 0.174931, l3: 0.171282, l4: 0.164675, l5: 0.171176, l6: 0.152765

[epoch:   9/100000, batch:    86/  187, ite: 795] train loss: 1.027159, tar: 0.163232 
l0: 0.115650, l1: 0.107882, l2: 0.111296, l3: 0.118535, l4: 0.120853, l5: 0.117131, l6: 0.116171

[epoch:   9/100000, batch:    88/  187, ite: 796] train loss: 1.026883, tar: 0.163172 
l0: 0.115617, l1: 0.109617, l2: 0.111365, l3: 0.121306, l4: 0.119690, l5: 0.120491, l6: 0.118139

[epoch:   9/100000, batch:    90/  187, ite: 797] train loss: 1.026619, tar: 0.163113 
l0: 0.090430, l1: 0.088096, l2: 0.091200, l3: 0.097966, l4: 0.107024, l5: 0.096349, l6: 0.097224

[epoch:   9/100000, batch:    92/  187, ite: 798] train loss: 1.026170, tar: 0.163022 
l0: 0.124234, l1: 0.117399, l2: 0.119280, l3: 0.121944, l4: 0.133171, l5: 0.137420, l6: 0.122884

[epoch:   9/100000, batch:    94/  187, ite: 799] train loss: 1.025982, tar: 0.162973 
l0: 0.149496, l1: 0.141877, l2: 0.144400, l3: 0.151170, l4: 0.176325, l5: 0.186441, l6: 0.163989

[epoch:   9/100000, batch:    96/  187, ite: 800] train loss: 1.026092, tar: 0.162956 
l0: 0.128391, l1: 0.119324, l2: 0.117962, l3: 0.126174, l4: 0.139727, l5: 0.140205, l6: 0.134051

[epoch:   9/100000, batch:    98/  187, ite: 801] train loss: 1.025942, tar: 0.162913 
l0: 0.089066, l1: 0.084161, l2: 0.087832, l3: 0.089357, l4: 0.089795, l5: 0.084979, l6: 0.085624

[epoch:   9/100000, batch:   100/  187, ite: 802] train loss: 1.025424, tar: 0.162821 
l0: 0.084951, l1: 0.075372, l2: 0.076343, l3: 0.085176, l4: 0.092489, l5: 0.097827, l6: 0.087816

[epoch:   9/100000, batch:   102/  187, ite: 803] train loss: 1.024894, tar: 0.162724 
l0: 0.138769, l1: 0.131634, l2: 0.145356, l3: 0.151697, l4: 0.160592, l5: 0.167704, l6: 0.170100

[epoch:   9/100000, batch:   104/  187, ite: 804] train loss: 1.024945, tar: 0.162694 
l0: 0.113970, l1: 0.119228, l2: 0.121948, l3: 0.098998, l4: 0.123117, l5: 0.129116, l6: 0.107908

[epoch:   9/100000, batch:   106/  187, ite: 805] train loss: 1.024683, tar: 0.162634 
l0: 0.151407, l1: 0.155351, l2: 0.155395, l3: 0.157944, l4: 0.163679, l5: 0.178109, l6: 0.164564

[epoch:   9/100000, batch:   108/  187, ite: 806] train loss: 1.024810, tar: 0.162620 
l0: 0.101551, l1: 0.105732, l2: 0.117468, l3: 0.102225, l4: 0.130940, l5: 0.127473, l6: 0.115460

[epoch:   9/100000, batch:   110/  187, ite: 807] train loss: 1.024532, tar: 0.162544 
l0: 0.126198, l1: 0.133939, l2: 0.140880, l3: 0.134085, l4: 0.122952, l5: 0.123901, l6: 0.111011

[epoch:   9/100000, batch:   112/  187, ite: 808] train loss: 1.024369, tar: 0.162499 
l0: 0.103270, l1: 0.101988, l2: 0.102420, l3: 0.115808, l4: 0.118788, l5: 0.113435, l6: 0.118678

[epoch:   9/100000, batch:   114/  187, ite: 809] train loss: 1.024060, tar: 0.162426 
l0: 0.111977, l1: 0.137576, l2: 0.124684, l3: 0.116545, l4: 0.098658, l5: 0.094679, l6: 0.094561

[epoch:   9/100000, batch:   116/  187, ite: 810] train loss: 1.023757, tar: 0.162364 
l0: 0.125462, l1: 0.113050, l2: 0.124437, l3: 0.133128, l4: 0.145906, l5: 0.155513, l6: 0.146078

[epoch:   9/100000, batch:   118/  187, ite: 811] train loss: 1.023659, tar: 0.162318 
l0: 0.096625, l1: 0.094940, l2: 0.101330, l3: 0.106558, l4: 0.105982, l5: 0.100861, l6: 0.097820

[epoch:   9/100000, batch:   120/  187, ite: 812] train loss: 1.023265, tar: 0.162237 
l0: 0.117697, l1: 0.113797, l2: 0.108825, l3: 0.119330, l4: 0.113098, l5: 0.121886, l6: 0.134970

[epoch:   9/100000, batch:   122/  187, ite: 813] train loss: 1.023027, tar: 0.162182 
l0: 0.098195, l1: 0.099156, l2: 0.092511, l3: 0.093501, l4: 0.112029, l5: 0.105476, l6: 0.101505

[epoch:   9/100000, batch:   124/  187, ite: 814] train loss: 1.022633, tar: 0.162104 
l0: 0.086753, l1: 0.088265, l2: 0.080363, l3: 0.073976, l4: 0.098649, l5: 0.094863, l6: 0.093886

[epoch:   9/100000, batch:   126/  187, ite: 815] train loss: 1.022135, tar: 0.162011 
l0: 0.099673, l1: 0.118226, l2: 0.112108, l3: 0.104992, l4: 0.086626, l5: 0.092958, l6: 0.085981

[epoch:   9/100000, batch:   128/  187, ite: 816] train loss: 1.021741, tar: 0.161935 
l0: 0.090346, l1: 0.100967, l2: 0.096081, l3: 0.093773, l4: 0.098188, l5: 0.095836, l6: 0.095965

[epoch:   9/100000, batch:   130/  187, ite: 817] train loss: 1.021312, tar: 0.161847 
l0: 0.100398, l1: 0.089281, l2: 0.095644, l3: 0.088192, l4: 0.116137, l5: 0.131473, l6: 0.135282

[epoch:   9/100000, batch:   132/  187, ite: 818] train loss: 1.020988, tar: 0.161772 
l0: 0.100763, l1: 0.107075, l2: 0.116345, l3: 0.119915, l4: 0.122316, l5: 0.104365, l6: 0.096821

[epoch:   9/100000, batch:   134/  187, ite: 819] train loss: 1.020678, tar: 0.161698 
l0: 0.140933, l1: 0.146855, l2: 0.138064, l3: 0.155723, l4: 0.132381, l5: 0.169862, l6: 0.147602

[epoch:   9/100000, batch:   136/  187, ite: 820] train loss: 1.020692, tar: 0.161672 
l0: 0.098078, l1: 0.104878, l2: 0.101822, l3: 0.109914, l4: 0.138299, l5: 0.108513, l6: 0.108213

[epoch:   9/100000, batch:   138/  187, ite: 821] train loss: 1.020386, tar: 0.161595 
l0: 0.064876, l1: 0.060402, l2: 0.074330, l3: 0.077961, l4: 0.074755, l5: 0.068593, l6: 0.062538

[epoch:   9/100000, batch:   140/  187, ite: 822] train loss: 1.019733, tar: 0.161477 
l0: 0.172623, l1: 0.194964, l2: 0.214826, l3: 0.195472, l4: 0.208587, l5: 0.198772, l6: 0.229352

[epoch:   9/100000, batch:   142/  187, ite: 823] train loss: 1.020212, tar: 0.161491 
l0: 0.091625, l1: 0.107792, l2: 0.104456, l3: 0.119492, l4: 0.088249, l5: 0.076248, l6: 0.077407

[epoch:   9/100000, batch:   144/  187, ite: 824] train loss: 1.019782, tar: 0.161406 
l0: 0.072672, l1: 0.077792, l2: 0.098941, l3: 0.098220, l4: 0.080528, l5: 0.071790, l6: 0.074951

[epoch:   9/100000, batch:   146/  187, ite: 825] train loss: 1.019242, tar: 0.161298 
l0: 0.082740, l1: 0.073786, l2: 0.080665, l3: 0.086795, l4: 0.104846, l5: 0.113097, l6: 0.104232

[epoch:   9/100000, batch:   148/  187, ite: 826] train loss: 1.018791, tar: 0.161203 
l0: 0.120807, l1: 0.120766, l2: 0.130195, l3: 0.135099, l4: 0.138246, l5: 0.129616, l6: 0.132170

[epoch:   9/100000, batch:   150/  187, ite: 827] train loss: 1.018655, tar: 0.161155 
l0: 0.113963, l1: 0.115678, l2: 0.122209, l3: 0.116757, l4: 0.127239, l5: 0.120230, l6: 0.127862

[epoch:   9/100000, batch:   152/  187, ite: 828] train loss: 1.018444, tar: 0.161098 
l0: 0.116013, l1: 0.130830, l2: 0.105496, l3: 0.107259, l4: 0.125856, l5: 0.122718, l6: 0.104232

[epoch:   9/100000, batch:   154/  187, ite: 829] train loss: 1.018196, tar: 0.161043 
l0: 0.120076, l1: 0.121738, l2: 0.124199, l3: 0.127215, l4: 0.134132, l5: 0.124334, l6: 0.119552

[epoch:   9/100000, batch:   156/  187, ite: 830] train loss: 1.018019, tar: 0.160994 
l0: 0.123911, l1: 0.116986, l2: 0.137229, l3: 0.140315, l4: 0.150682, l5: 0.163033, l6: 0.155032

[epoch:   9/100000, batch:   158/  187, ite: 831] train loss: 1.017982, tar: 0.160949 
l0: 0.118782, l1: 0.126716, l2: 0.116965, l3: 0.122211, l4: 0.105230, l5: 0.114441, l6: 0.125462

[epoch:   9/100000, batch:   160/  187, ite: 832] train loss: 1.017756, tar: 0.160898 
l0: 0.062213, l1: 0.057725, l2: 0.058860, l3: 0.064594, l4: 0.071879, l5: 0.077817, l6: 0.078919

[epoch:   9/100000, batch:   162/  187, ite: 833] train loss: 1.017100, tar: 0.160780 
l0: 0.117540, l1: 0.117788, l2: 0.117662, l3: 0.122065, l4: 0.123301, l5: 0.115134, l6: 0.114652

[epoch:   9/100000, batch:   164/  187, ite: 834] train loss: 1.016874, tar: 0.160728 
l0: 0.103392, l1: 0.108170, l2: 0.107122, l3: 0.105846, l4: 0.106397, l5: 0.108553, l6: 0.109094

[epoch:   9/100000, batch:   166/  187, ite: 835] train loss: 1.016553, tar: 0.160660 
l0: 0.073982, l1: 0.071683, l2: 0.073836, l3: 0.073892, l4: 0.075739, l5: 0.075870, l6: 0.081849

[epoch:   9/100000, batch:   168/  187, ite: 836] train loss: 1.015967, tar: 0.160556 
l0: 0.081035, l1: 0.078189, l2: 0.084176, l3: 0.089312, l4: 0.085378, l5: 0.078384, l6: 0.071430

[epoch:   9/100000, batch:   170/  187, ite: 837] train loss: 1.015431, tar: 0.160461 
l0: 0.100376, l1: 0.102118, l2: 0.109943, l3: 0.108625, l4: 0.112611, l5: 0.097896, l6: 0.092051

[epoch:   9/100000, batch:   172/  187, ite: 838] train loss: 1.015083, tar: 0.160389 
l0: 0.054128, l1: 0.055931, l2: 0.054205, l3: 0.048885, l4: 0.050958, l5: 0.054032, l6: 0.049788

[epoch:   9/100000, batch:   174/  187, ite: 839] train loss: 1.014312, tar: 0.160262 
l0: 0.133732, l1: 0.142204, l2: 0.143219, l3: 0.145751, l4: 0.142493, l5: 0.127202, l6: 0.145130

[epoch:   9/100000, batch:   176/  187, ite: 840] train loss: 1.014271, tar: 0.160231 
l0: 0.063203, l1: 0.059218, l2: 0.062866, l3: 0.063273, l4: 0.062945, l5: 0.068104, l6: 0.061127

[epoch:   9/100000, batch:   178/  187, ite: 841] train loss: 1.013589, tar: 0.160116 
l0: 0.081523, l1: 0.082147, l2: 0.078762, l3: 0.080185, l4: 0.086495, l5: 0.075459, l6: 0.084127

[epoch:   9/100000, batch:   180/  187, ite: 842] train loss: 1.013060, tar: 0.160022 
l0: 0.044032, l1: 0.044177, l2: 0.049725, l3: 0.045482, l4: 0.040298, l5: 0.041095, l6: 0.039332

[epoch:   9/100000, batch:   182/  187, ite: 843] train loss: 1.012219, tar: 0.159885 
l0: 0.078706, l1: 0.082123, l2: 0.082640, l3: 0.082109, l4: 0.086933, l5: 0.081093, l6: 0.082425

[epoch:   9/100000, batch:   184/  187, ite: 844] train loss: 1.011703, tar: 0.159788 
l0: 0.138899, l1: 0.140623, l2: 0.146504, l3: 0.162667, l4: 0.151788, l5: 0.171828, l6: 0.157595

[epoch:   9/100000, batch:   186/  187, ite: 845] train loss: 1.011772, tar: 0.159764 
l0: 0.131236, l1: 0.124546, l2: 0.147246, l3: 0.128786, l4: 0.150859, l5: 0.175236, l6: 0.167566

[epoch:   9/100000, batch:   188/  187, ite: 846] train loss: 1.011788, tar: 0.159730 
l0: 0.134640, l1: 0.141247, l2: 0.144984, l3: 0.137262, l4: 0.155230, l5: 0.147096, l6: 0.128471

[epoch:  10/100000, batch:     2/  187, ite: 847] train loss: 1.011761, tar: 0.159700 
l0: 0.054705, l1: 0.054820, l2: 0.052740, l3: 0.053377, l4: 0.077059, l5: 0.050435, l6: 0.045149

[epoch:  10/100000, batch:     4/  187, ite: 848] train loss: 1.011025, tar: 0.159577 
l0: 0.098115, l1: 0.098989, l2: 0.102743, l3: 0.104670, l4: 0.102642, l5: 0.102188, l6: 0.101511

[epoch:  10/100000, batch:     6/  187, ite: 849] train loss: 1.010672, tar: 0.159504 
l0: 0.110590, l1: 0.116916, l2: 0.124969, l3: 0.122592, l4: 0.116478, l5: 0.112659, l6: 0.102315

[epoch:  10/100000, batch:     8/  187, ite: 850] train loss: 1.010432, tar: 0.159447 
l0: 0.167705, l1: 0.199022, l2: 0.168329, l3: 0.164694, l4: 0.146983, l5: 0.148805, l6: 0.129673

[epoch:  10/100000, batch:    10/  187, ite: 851] train loss: 1.010567, tar: 0.159456 
l0: 0.130943, l1: 0.134266, l2: 0.142546, l3: 0.144131, l4: 0.145973, l5: 0.140719, l6: 0.152615

[epoch:  10/100000, batch:    12/  187, ite: 852] train loss: 1.010544, tar: 0.159423 
l0: 0.087016, l1: 0.077190, l2: 0.091272, l3: 0.085449, l4: 0.102393, l5: 0.108055, l6: 0.121069

[epoch:  10/100000, batch:    14/  187, ite: 853] train loss: 1.010148, tar: 0.159338 
l0: 0.123292, l1: 0.118803, l2: 0.120158, l3: 0.103727, l4: 0.127431, l5: 0.121756, l6: 0.120014

[epoch:  10/100000, batch:    16/  187, ite: 854] train loss: 1.009943, tar: 0.159296 
l0: 0.107236, l1: 0.103020, l2: 0.117234, l3: 0.108222, l4: 0.132963, l5: 0.119371, l6: 0.106356

[epoch:  10/100000, batch:    18/  187, ite: 855] train loss: 1.009691, tar: 0.159235 
l0: 0.088203, l1: 0.089475, l2: 0.088583, l3: 0.087882, l4: 0.084470, l5: 0.090248, l6: 0.103100

[epoch:  10/100000, batch:    20/  187, ite: 856] train loss: 1.009249, tar: 0.159152 
l0: 0.100747, l1: 0.100642, l2: 0.111412, l3: 0.120232, l4: 0.127331, l5: 0.106354, l6: 0.099844

[epoch:  10/100000, batch:    22/  187, ite: 857] train loss: 1.008966, tar: 0.159084 
l0: 0.072376, l1: 0.075076, l2: 0.072699, l3: 0.072615, l4: 0.072956, l5: 0.068903, l6: 0.062259

[epoch:  10/100000, batch:    24/  187, ite: 858] train loss: 1.008369, tar: 0.158983 
l0: 0.104039, l1: 0.110757, l2: 0.100858, l3: 0.089461, l4: 0.104662, l5: 0.095811, l6: 0.086077

[epoch:  10/100000, batch:    26/  187, ite: 859] train loss: 1.008001, tar: 0.158919 
l0: 0.184391, l1: 0.225612, l2: 0.180606, l3: 0.185195, l4: 0.184213, l5: 0.173790, l6: 0.210585

[epoch:  10/100000, batch:    28/  187, ite: 860] train loss: 1.008392, tar: 0.158948 
l0: 0.107381, l1: 0.109387, l2: 0.118521, l3: 0.123448, l4: 0.127762, l5: 0.119799, l6: 0.109151

[epoch:  10/100000, batch:    30/  187, ite: 861] train loss: 1.008168, tar: 0.158888 
l0: 0.103022, l1: 0.106137, l2: 0.110818, l3: 0.095793, l4: 0.100172, l5: 0.101384, l6: 0.116538

[epoch:  10/100000, batch:    32/  187, ite: 862] train loss: 1.007849, tar: 0.158824 
l0: 0.126747, l1: 0.134013, l2: 0.132832, l3: 0.144204, l4: 0.124468, l5: 0.127801, l6: 0.140573

[epoch:  10/100000, batch:    34/  187, ite: 863] train loss: 1.007760, tar: 0.158786 
l0: 0.092694, l1: 0.097007, l2: 0.088934, l3: 0.081916, l4: 0.100369, l5: 0.095711, l6: 0.089626

[epoch:  10/100000, batch:    36/  187, ite: 864] train loss: 1.007342, tar: 0.158710 
l0: 0.126082, l1: 0.121500, l2: 0.133821, l3: 0.134677, l4: 0.145498, l5: 0.145787, l6: 0.138088

[epoch:  10/100000, batch:    38/  187, ite: 865] train loss: 1.007270, tar: 0.158672 
l0: 0.131426, l1: 0.136340, l2: 0.142677, l3: 0.137405, l4: 0.133100, l5: 0.124054, l6: 0.120368

[epoch:  10/100000, batch:    40/  187, ite: 866] train loss: 1.007175, tar: 0.158641 
l0: 0.123177, l1: 0.122181, l2: 0.111771, l3: 0.114237, l4: 0.139508, l5: 0.146983, l6: 0.123561

[epoch:  10/100000, batch:    42/  187, ite: 867] train loss: 1.007030, tar: 0.158600 
l0: 0.140280, l1: 0.136319, l2: 0.148974, l3: 0.156309, l4: 0.162227, l5: 0.177897, l6: 0.168727

[epoch:  10/100000, batch:    44/  187, ite: 868] train loss: 1.007127, tar: 0.158579 
l0: 0.099197, l1: 0.095734, l2: 0.096609, l3: 0.102869, l4: 0.129328, l5: 0.121641, l6: 0.122163

[epoch:  10/100000, batch:    46/  187, ite: 869] train loss: 1.006851, tar: 0.158510 
l0: 0.097100, l1: 0.097481, l2: 0.085670, l3: 0.089024, l4: 0.104610, l5: 0.094343, l6: 0.105094

[epoch:  10/100000, batch:    48/  187, ite: 870] train loss: 1.006468, tar: 0.158440 
l0: 0.094234, l1: 0.089662, l2: 0.091651, l3: 0.106415, l4: 0.100667, l5: 0.107235, l6: 0.121140

[epoch:  10/100000, batch:    50/  187, ite: 871] train loss: 1.006129, tar: 0.158366 
l0: 0.129759, l1: 0.127115, l2: 0.132817, l3: 0.126200, l4: 0.128670, l5: 0.153095, l6: 0.155268

[epoch:  10/100000, batch:    52/  187, ite: 872] train loss: 1.006068, tar: 0.158333 
l0: 0.063511, l1: 0.058270, l2: 0.056617, l3: 0.063479, l4: 0.063867, l5: 0.079965, l6: 0.086797

[epoch:  10/100000, batch:    54/  187, ite: 873] train loss: 1.005456, tar: 0.158225 
l0: 0.154414, l1: 0.171107, l2: 0.151831, l3: 0.145645, l4: 0.150604, l5: 0.146555, l6: 0.154549

[epoch:  10/100000, batch:    56/  187, ite: 874] train loss: 1.005536, tar: 0.158220 
l0: 0.125288, l1: 0.133673, l2: 0.115393, l3: 0.114324, l4: 0.132392, l5: 0.126038, l6: 0.124522

[epoch:  10/100000, batch:    58/  187, ite: 875] train loss: 1.005383, tar: 0.158183 
l0: 0.130302, l1: 0.126757, l2: 0.122057, l3: 0.123617, l4: 0.144046, l5: 0.143366, l6: 0.153647

[epoch:  10/100000, batch:    60/  187, ite: 876] train loss: 1.005312, tar: 0.158151 
l0: 0.117620, l1: 0.121006, l2: 0.128655, l3: 0.122827, l4: 0.123553, l5: 0.123533, l6: 0.115667

[epoch:  10/100000, batch:    62/  187, ite: 877] train loss: 1.005138, tar: 0.158105 
l0: 0.085435, l1: 0.085603, l2: 0.089788, l3: 0.090802, l4: 0.078904, l5: 0.081642, l6: 0.098255

[epoch:  10/100000, batch:    64/  187, ite: 878] train loss: 1.004689, tar: 0.158022 
l0: 0.122523, l1: 0.118550, l2: 0.115678, l3: 0.113455, l4: 0.125068, l5: 0.133092, l6: 0.116573

[epoch:  10/100000, batch:    66/  187, ite: 879] train loss: 1.004507, tar: 0.157981 
l0: 0.113441, l1: 0.113749, l2: 0.110871, l3: 0.120049, l4: 0.117771, l5: 0.111030, l6: 0.109172

[epoch:  10/100000, batch:    68/  187, ite: 880] train loss: 1.004270, tar: 0.157931 
l0: 0.048685, l1: 0.046612, l2: 0.057821, l3: 0.058323, l4: 0.047514, l5: 0.046779, l6: 0.045964

[epoch:  10/100000, batch:    70/  187, ite: 881] train loss: 1.003530, tar: 0.157807 
l0: 0.067708, l1: 0.065643, l2: 0.080052, l3: 0.077801, l4: 0.066918, l5: 0.067563, l6: 0.066460

[epoch:  10/100000, batch:    72/  187, ite: 882] train loss: 1.002950, tar: 0.157705 
l0: 0.105319, l1: 0.110493, l2: 0.102904, l3: 0.102370, l4: 0.107288, l5: 0.100931, l6: 0.094189

[epoch:  10/100000, batch:    74/  187, ite: 883] train loss: 1.002633, tar: 0.157645 
l0: 0.051251, l1: 0.049717, l2: 0.062312, l3: 0.063271, l4: 0.055831, l5: 0.044976, l6: 0.049379

[epoch:  10/100000, batch:    76/  187, ite: 884] train loss: 1.001925, tar: 0.157525 
l0: 0.070832, l1: 0.070379, l2: 0.069300, l3: 0.068823, l4: 0.073001, l5: 0.066040, l6: 0.066037

[epoch:  10/100000, batch:    78/  187, ite: 885] train loss: 1.001340, tar: 0.157427 
l0: 0.109826, l1: 0.109078, l2: 0.099786, l3: 0.100631, l4: 0.113010, l5: 0.109951, l6: 0.104749

[epoch:  10/100000, batch:    80/  187, ite: 886] train loss: 1.001053, tar: 0.157373 
l0: 0.103721, l1: 0.099399, l2: 0.107966, l3: 0.105969, l4: 0.103539, l5: 0.114257, l6: 0.123602

[epoch:  10/100000, batch:    82/  187, ite: 887] train loss: 1.000780, tar: 0.157313 
l0: 0.099927, l1: 0.100749, l2: 0.108581, l3: 0.108314, l4: 0.099468, l5: 0.099232, l6: 0.119448

[epoch:  10/100000, batch:    84/  187, ite: 888] train loss: 1.000481, tar: 0.157248 
l0: 0.096028, l1: 0.095310, l2: 0.088421, l3: 0.089292, l4: 0.098117, l5: 0.098367, l6: 0.099845

[epoch:  10/100000, batch:    86/  187, ite: 889] train loss: 1.000104, tar: 0.157179 
l0: 0.104007, l1: 0.096714, l2: 0.097206, l3: 0.099401, l4: 0.120985, l5: 0.117687, l6: 0.128486

[epoch:  10/100000, batch:    88/  187, ite: 890] train loss: 0.999840, tar: 0.157120 
l0: 0.089791, l1: 0.097935, l2: 0.091378, l3: 0.081960, l4: 0.080565, l5: 0.097105, l6: 0.095574

[epoch:  10/100000, batch:    90/  187, ite: 891] train loss: 0.999429, tar: 0.157044 
l0: 0.127251, l1: 0.132594, l2: 0.137462, l3: 0.133435, l4: 0.123627, l5: 0.132169, l6: 0.115472

[epoch:  10/100000, batch:    92/  187, ite: 892] train loss: 0.999320, tar: 0.157011 
l0: 0.120776, l1: 0.120109, l2: 0.127705, l3: 0.131779, l4: 0.108304, l5: 0.119358, l6: 0.118837

[epoch:  10/100000, batch:    94/  187, ite: 893] train loss: 0.999150, tar: 0.156970 
l0: 0.143626, l1: 0.133545, l2: 0.137126, l3: 0.130822, l4: 0.194121, l5: 0.200678, l6: 0.182141

[epoch:  10/100000, batch:    96/  187, ite: 894] train loss: 0.999287, tar: 0.156955 
l0: 0.130254, l1: 0.142707, l2: 0.131796, l3: 0.136589, l4: 0.157530, l5: 0.134509, l6: 0.142703

[epoch:  10/100000, batch:    98/  187, ite: 895] train loss: 0.999261, tar: 0.156925 
l0: 0.083946, l1: 0.086410, l2: 0.088979, l3: 0.096518, l4: 0.087599, l5: 0.080207, l6: 0.088632

[epoch:  10/100000, batch:   100/  187, ite: 896] train loss: 0.998829, tar: 0.156844 
l0: 0.090935, l1: 0.094333, l2: 0.096383, l3: 0.116211, l4: 0.085143, l5: 0.084452, l6: 0.090493

[epoch:  10/100000, batch:   102/  187, ite: 897] train loss: 0.998449, tar: 0.156770 
l0: 0.106005, l1: 0.102514, l2: 0.106315, l3: 0.113821, l4: 0.117550, l5: 0.116349, l6: 0.114590

[epoch:  10/100000, batch:   104/  187, ite: 898] train loss: 0.998203, tar: 0.156714 
l0: 0.169483, l1: 0.188241, l2: 0.173369, l3: 0.184043, l4: 0.197075, l5: 0.175629, l6: 0.165954

[epoch:  10/100000, batch:   106/  187, ite: 899] train loss: 0.998487, tar: 0.156728 
l0: 0.083307, l1: 0.080978, l2: 0.078396, l3: 0.074116, l4: 0.089605, l5: 0.089287, l6: 0.095822

[epoch:  10/100000, batch:   108/  187, ite: 900] train loss: 0.998035, tar: 0.156647 
l0: 0.124658, l1: 0.129705, l2: 0.131994, l3: 0.120480, l4: 0.139821, l5: 0.139850, l6: 0.148310

[epoch:  10/100000, batch:   110/  187, ite: 901] train loss: 0.997965, tar: 0.156611 
l0: 0.089340, l1: 0.091043, l2: 0.094698, l3: 0.093586, l4: 0.091869, l5: 0.093991, l6: 0.097372

[epoch:  10/100000, batch:   112/  187, ite: 902] train loss: 0.997581, tar: 0.156536 
l0: 0.123609, l1: 0.119364, l2: 0.134577, l3: 0.140256, l4: 0.122852, l5: 0.128311, l6: 0.147017

[epoch:  10/100000, batch:   114/  187, ite: 903] train loss: 0.997491, tar: 0.156500 
l0: 0.137204, l1: 0.158517, l2: 0.142226, l3: 0.137760, l4: 0.118263, l5: 0.113879, l6: 0.136575

[epoch:  10/100000, batch:   116/  187, ite: 904] train loss: 0.997432, tar: 0.156479 
l0: 0.094784, l1: 0.105726, l2: 0.097992, l3: 0.103375, l4: 0.087192, l5: 0.087867, l6: 0.083307

[epoch:  10/100000, batch:   118/  187, ite: 905] train loss: 0.997059, tar: 0.156410 
l0: 0.111344, l1: 0.104364, l2: 0.102508, l3: 0.105449, l4: 0.120642, l5: 0.114854, l6: 0.119214

[epoch:  10/100000, batch:   120/  187, ite: 906] train loss: 0.996818, tar: 0.156361 
l0: 0.123380, l1: 0.126732, l2: 0.120104, l3: 0.119428, l4: 0.135488, l5: 0.125986, l6: 0.137613

[epoch:  10/100000, batch:   122/  187, ite: 907] train loss: 0.996699, tar: 0.156324 
l0: 0.096729, l1: 0.098724, l2: 0.104779, l3: 0.101726, l4: 0.147929, l5: 0.123236, l6: 0.096795

[epoch:  10/100000, batch:   124/  187, ite: 908] train loss: 0.996449, tar: 0.156259 
l0: 0.100305, l1: 0.095835, l2: 0.097654, l3: 0.104236, l4: 0.104226, l5: 0.104417, l6: 0.103602

[epoch:  10/100000, batch:   126/  187, ite: 909] train loss: 0.996134, tar: 0.156197 
l0: 0.113472, l1: 0.111023, l2: 0.109909, l3: 0.114969, l4: 0.124110, l5: 0.117592, l6: 0.128491

[epoch:  10/100000, batch:   128/  187, ite: 910] train loss: 0.995940, tar: 0.156150 
l0: 0.113697, l1: 0.113051, l2: 0.113511, l3: 0.113114, l4: 0.108407, l5: 0.108455, l6: 0.127141

[epoch:  10/100000, batch:   130/  187, ite: 911] train loss: 0.995722, tar: 0.156104 
l0: 0.115712, l1: 0.107326, l2: 0.111914, l3: 0.113974, l4: 0.120748, l5: 0.119519, l6: 0.124992

[epoch:  10/100000, batch:   132/  187, ite: 912] train loss: 0.995523, tar: 0.156059 
l0: 0.064759, l1: 0.068101, l2: 0.060841, l3: 0.067928, l4: 0.063935, l5: 0.056973, l6: 0.062275

[epoch:  10/100000, batch:   134/  187, ite: 913] train loss: 0.994920, tar: 0.155959 
l0: 0.086013, l1: 0.087163, l2: 0.087475, l3: 0.093668, l4: 0.093852, l5: 0.089329, l6: 0.091589

[epoch:  10/100000, batch:   136/  187, ite: 914] train loss: 0.994520, tar: 0.155883 
l0: 0.106800, l1: 0.102030, l2: 0.107614, l3: 0.105378, l4: 0.101474, l5: 0.096895, l6: 0.102446

[epoch:  10/100000, batch:   138/  187, ite: 915] train loss: 0.994223, tar: 0.155829 
l0: 0.106687, l1: 0.108057, l2: 0.105793, l3: 0.108345, l4: 0.107634, l5: 0.110760, l6: 0.107966

[epoch:  10/100000, batch:   140/  187, ite: 916] train loss: 0.993962, tar: 0.155775 
l0: 0.101110, l1: 0.095696, l2: 0.091252, l3: 0.092388, l4: 0.134189, l5: 0.133377, l6: 0.124175

[epoch:  10/100000, batch:   142/  187, ite: 917] train loss: 0.993720, tar: 0.155716 
l0: 0.121619, l1: 0.118555, l2: 0.119781, l3: 0.116706, l4: 0.149419, l5: 0.139189, l6: 0.121308

[epoch:  10/100000, batch:   144/  187, ite: 918] train loss: 0.993603, tar: 0.155679 
l0: 0.081907, l1: 0.078407, l2: 0.080581, l3: 0.083051, l4: 0.100124, l5: 0.092484, l6: 0.080469

[epoch:  10/100000, batch:   146/  187, ite: 919] train loss: 0.993172, tar: 0.155598 
l0: 0.072814, l1: 0.071481, l2: 0.075660, l3: 0.074685, l4: 0.071586, l5: 0.074232, l6: 0.075705

[epoch:  10/100000, batch:   148/  187, ite: 920] train loss: 0.992653, tar: 0.155508 
l0: 0.175959, l1: 0.179230, l2: 0.201918, l3: 0.234162, l4: 0.196938, l5: 0.198501, l6: 0.205910

[epoch:  10/100000, batch:   150/  187, ite: 921] train loss: 0.993087, tar: 0.155531 
l0: 0.062296, l1: 0.062443, l2: 0.064614, l3: 0.071792, l4: 0.059630, l5: 0.065674, l6: 0.078205

[epoch:  10/100000, batch:   152/  187, ite: 922] train loss: 0.992514, tar: 0.155430 
l0: 0.066674, l1: 0.064529, l2: 0.069926, l3: 0.068846, l4: 0.077639, l5: 0.082087, l6: 0.064040

[epoch:  10/100000, batch:   154/  187, ite: 923] train loss: 0.991974, tar: 0.155333 
l0: 0.084471, l1: 0.084494, l2: 0.089601, l3: 0.085142, l4: 0.094283, l5: 0.093670, l6: 0.082724

[epoch:  10/100000, batch:   156/  187, ite: 924] train loss: 0.991565, tar: 0.155257 
l0: 0.145509, l1: 0.143992, l2: 0.141788, l3: 0.150787, l4: 0.169681, l5: 0.138604, l6: 0.157711

[epoch:  10/100000, batch:   158/  187, ite: 925] train loss: 0.991626, tar: 0.155246 
l0: 0.090863, l1: 0.089894, l2: 0.094884, l3: 0.099358, l4: 0.103685, l5: 0.093875, l6: 0.088504

[epoch:  10/100000, batch:   160/  187, ite: 926] train loss: 0.991269, tar: 0.155177 
l0: 0.082994, l1: 0.082872, l2: 0.083671, l3: 0.079853, l4: 0.089239, l5: 0.087419, l6: 0.079375

[epoch:  10/100000, batch:   162/  187, ite: 927] train loss: 0.990832, tar: 0.155099 
l0: 0.093430, l1: 0.094424, l2: 0.087235, l3: 0.092349, l4: 0.084215, l5: 0.096777, l6: 0.082223

[epoch:  10/100000, batch:   164/  187, ite: 928] train loss: 0.990443, tar: 0.155032 
l0: 0.134628, l1: 0.142442, l2: 0.152715, l3: 0.133854, l4: 0.138026, l5: 0.149011, l6: 0.158426

[epoch:  10/100000, batch:   166/  187, ite: 929] train loss: 0.990464, tar: 0.155010 
l0: 0.097985, l1: 0.092562, l2: 0.098075, l3: 0.098387, l4: 0.104717, l5: 0.094782, l6: 0.099967

[epoch:  10/100000, batch:   168/  187, ite: 930] train loss: 0.990137, tar: 0.154949 
l0: 0.070023, l1: 0.066545, l2: 0.069042, l3: 0.067298, l4: 0.088700, l5: 0.074807, l6: 0.066471

[epoch:  10/100000, batch:   170/  187, ite: 931] train loss: 0.989613, tar: 0.154858 
l0: 0.120288, l1: 0.119456, l2: 0.123663, l3: 0.129435, l4: 0.125104, l5: 0.127696, l6: 0.135656

[epoch:  10/100000, batch:   172/  187, ite: 932] train loss: 0.989497, tar: 0.154821 
l0: 0.102152, l1: 0.100208, l2: 0.108069, l3: 0.104646, l4: 0.117230, l5: 0.106261, l6: 0.102620

[epoch:  10/100000, batch:   174/  187, ite: 933] train loss: 0.989231, tar: 0.154764 
l0: 0.081693, l1: 0.081027, l2: 0.084829, l3: 0.088878, l4: 0.093525, l5: 0.086468, l6: 0.068705

[epoch:  10/100000, batch:   176/  187, ite: 934] train loss: 0.988798, tar: 0.154686 
l0: 0.100050, l1: 0.111655, l2: 0.109736, l3: 0.112332, l4: 0.098243, l5: 0.098793, l6: 0.097084

[epoch:  10/100000, batch:   178/  187, ite: 935] train loss: 0.988519, tar: 0.154628 
l0: 0.150162, l1: 0.162017, l2: 0.143548, l3: 0.132911, l4: 0.158024, l5: 0.156420, l6: 0.159845

[epoch:  10/100000, batch:   180/  187, ite: 936] train loss: 0.988599, tar: 0.154623 
l0: 0.122093, l1: 0.113478, l2: 0.105006, l3: 0.112009, l4: 0.140621, l5: 0.148597, l6: 0.184471

[epoch:  10/100000, batch:   182/  187, ite: 937] train loss: 0.988532, tar: 0.154588 
l0: 0.110711, l1: 0.111889, l2: 0.100867, l3: 0.101601, l4: 0.113445, l5: 0.115776, l6: 0.126791

[epoch:  10/100000, batch:   184/  187, ite: 938] train loss: 0.988311, tar: 0.154541 
l0: 0.081300, l1: 0.077411, l2: 0.079297, l3: 0.082140, l4: 0.082785, l5: 0.079986, l6: 0.082895

[epoch:  10/100000, batch:   186/  187, ite: 939] train loss: 0.987861, tar: 0.154463 
l0: 0.097460, l1: 0.097325, l2: 0.096284, l3: 0.097797, l4: 0.112690, l5: 0.102986, l6: 0.103547

[epoch:  10/100000, batch:   188/  187, ite: 940] train loss: 0.987563, tar: 0.154403 
l0: 0.100009, l1: 0.101331, l2: 0.094292, l3: 0.096669, l4: 0.115480, l5: 0.112680, l6: 0.108085

[epoch:  11/100000, batch:     2/  187, ite: 941] train loss: 0.987288, tar: 0.154345 
l0: 0.201281, l1: 0.254321, l2: 0.213662, l3: 0.183251, l4: 0.200735, l5: 0.187940, l6: 0.192250

[epoch:  11/100000, batch:     4/  187, ite: 942] train loss: 0.987762, tar: 0.154395 
l0: 0.089712, l1: 0.104345, l2: 0.100560, l3: 0.094996, l4: 0.100206, l5: 0.089719, l6: 0.079633

[epoch:  11/100000, batch:     6/  187, ite: 943] train loss: 0.987413, tar: 0.154326 
l0: 0.129219, l1: 0.120363, l2: 0.128349, l3: 0.129000, l4: 0.136580, l5: 0.145712, l6: 0.150264

[epoch:  11/100000, batch:     8/  187, ite: 944] train loss: 0.987363, tar: 0.154300 
l0: 0.097853, l1: 0.103782, l2: 0.100329, l3: 0.090336, l4: 0.114433, l5: 0.108099, l6: 0.087027

[epoch:  11/100000, batch:    10/  187, ite: 945] train loss: 0.987060, tar: 0.154240 
l0: 0.087944, l1: 0.094075, l2: 0.097980, l3: 0.098814, l4: 0.094725, l5: 0.102772, l6: 0.083246

[epoch:  11/100000, batch:    12/  187, ite: 946] train loss: 0.986714, tar: 0.154170 
l0: 0.083225, l1: 0.078982, l2: 0.084940, l3: 0.087756, l4: 0.102816, l5: 0.097689, l6: 0.098441

[epoch:  11/100000, batch:    14/  187, ite: 947] train loss: 0.986342, tar: 0.154095 
l0: 0.071802, l1: 0.078750, l2: 0.072189, l3: 0.067625, l4: 0.081299, l5: 0.083383, l6: 0.079143

[epoch:  11/100000, batch:    16/  187, ite: 948] train loss: 0.985865, tar: 0.154008 
l0: 0.130663, l1: 0.143825, l2: 0.122563, l3: 0.127657, l4: 0.124968, l5: 0.129010, l6: 0.110668

[epoch:  11/100000, batch:    18/  187, ite: 949] train loss: 0.985763, tar: 0.153983 
l0: 0.121370, l1: 0.118794, l2: 0.123828, l3: 0.124524, l4: 0.139708, l5: 0.131365, l6: 0.145011

[epoch:  11/100000, batch:    20/  187, ite: 950] train loss: 0.985678, tar: 0.153949 
l0: 0.214196, l1: 0.256207, l2: 0.268183, l3: 0.258517, l4: 0.208979, l5: 0.202023, l6: 0.186499

[epoch:  11/100000, batch:    22/  187, ite: 951] train loss: 0.986318, tar: 0.154012 
l0: 0.096884, l1: 0.098591, l2: 0.113854, l3: 0.118410, l4: 0.100733, l5: 0.096557, l6: 0.103784

[epoch:  11/100000, batch:    24/  187, ite: 952] train loss: 0.986047, tar: 0.153952 
l0: 0.102264, l1: 0.101855, l2: 0.108706, l3: 0.106370, l4: 0.120651, l5: 0.108916, l6: 0.119687

[epoch:  11/100000, batch:    26/  187, ite: 953] train loss: 0.985819, tar: 0.153898 
l0: 0.059300, l1: 0.056910, l2: 0.056674, l3: 0.053738, l4: 0.069732, l5: 0.076889, l6: 0.063874

[epoch:  11/100000, batch:    28/  187, ite: 954] train loss: 0.985244, tar: 0.153799 
l0: 0.090380, l1: 0.085098, l2: 0.080516, l3: 0.077695, l4: 0.105550, l5: 0.111890, l6: 0.095317

[epoch:  11/100000, batch:    30/  187, ite: 955] train loss: 0.984889, tar: 0.153733 
l0: 0.060596, l1: 0.060323, l2: 0.061596, l3: 0.060193, l4: 0.068542, l5: 0.075792, l6: 0.066147

[epoch:  11/100000, batch:    32/  187, ite: 956] train loss: 0.984333, tar: 0.153635 
l0: 0.087294, l1: 0.086357, l2: 0.075890, l3: 0.073898, l4: 0.094467, l5: 0.088638, l6: 0.089753

[epoch:  11/100000, batch:    34/  187, ite: 957] train loss: 0.983928, tar: 0.153566 
l0: 0.101122, l1: 0.095320, l2: 0.103444, l3: 0.101004, l4: 0.110186, l5: 0.108647, l6: 0.109568

[epoch:  11/100000, batch:    36/  187, ite: 958] train loss: 0.983662, tar: 0.153511 
l0: 0.181666, l1: 0.194617, l2: 0.183802, l3: 0.226709, l4: 0.180093, l5: 0.176129, l6: 0.166610

[epoch:  11/100000, batch:    38/  187, ite: 959] train loss: 0.984002, tar: 0.153540 
l0: 0.098996, l1: 0.101213, l2: 0.098729, l3: 0.101405, l4: 0.092598, l5: 0.099121, l6: 0.096539

[epoch:  11/100000, batch:    40/  187, ite: 960] train loss: 0.983694, tar: 0.153484 
l0: 0.140504, l1: 0.157704, l2: 0.171847, l3: 0.167705, l4: 0.180305, l5: 0.156001, l6: 0.153241

[epoch:  11/100000, batch:    42/  187, ite: 961] train loss: 0.983843, tar: 0.153470 
l0: 0.087350, l1: 0.085738, l2: 0.087409, l3: 0.086598, l4: 0.098975, l5: 0.095122, l6: 0.088754

[epoch:  11/100000, batch:    44/  187, ite: 962] train loss: 0.983475, tar: 0.153401 
l0: 0.102103, l1: 0.101046, l2: 0.106869, l3: 0.112684, l4: 0.100503, l5: 0.107528, l6: 0.095601

[epoch:  11/100000, batch:    46/  187, ite: 963] train loss: 0.983208, tar: 0.153348 
l0: 0.101781, l1: 0.098854, l2: 0.102620, l3: 0.099296, l4: 0.127315, l5: 0.123340, l6: 0.119538

[epoch:  11/100000, batch:    48/  187, ite: 964] train loss: 0.982990, tar: 0.153295 
l0: 0.116131, l1: 0.131375, l2: 0.112459, l3: 0.108764, l4: 0.121124, l5: 0.123958, l6: 0.129263

[epoch:  11/100000, batch:    50/  187, ite: 965] train loss: 0.982845, tar: 0.153256 
l0: 0.090620, l1: 0.092579, l2: 0.088406, l3: 0.082160, l4: 0.095218, l5: 0.093968, l6: 0.077119

[epoch:  11/100000, batch:    52/  187, ite: 966] train loss: 0.982470, tar: 0.153191 
l0: 0.155448, l1: 0.171820, l2: 0.148076, l3: 0.145422, l4: 0.148343, l5: 0.149662, l6: 0.149596

[epoch:  11/100000, batch:    54/  187, ite: 967] train loss: 0.982558, tar: 0.153194 
l0: 0.075213, l1: 0.072724, l2: 0.079400, l3: 0.075713, l4: 0.087968, l5: 0.081897, l6: 0.072494

[epoch:  11/100000, batch:    56/  187, ite: 968] train loss: 0.982107, tar: 0.153113 
l0: 0.112330, l1: 0.113498, l2: 0.121526, l3: 0.130478, l4: 0.118279, l5: 0.104731, l6: 0.099803

[epoch:  11/100000, batch:    58/  187, ite: 969] train loss: 0.981920, tar: 0.153071 
l0: 0.142569, l1: 0.129981, l2: 0.116941, l3: 0.116308, l4: 0.183579, l5: 0.188934, l6: 0.187535

[epoch:  11/100000, batch:    60/  187, ite: 970] train loss: 0.982006, tar: 0.153060 
l0: 0.154223, l1: 0.149248, l2: 0.143268, l3: 0.145299, l4: 0.178392, l5: 0.160645, l6: 0.162777

[epoch:  11/100000, batch:    62/  187, ite: 971] train loss: 0.982121, tar: 0.153061 
l0: 0.120010, l1: 0.115586, l2: 0.115974, l3: 0.117804, l4: 0.139086, l5: 0.143915, l6: 0.132740

[epoch:  11/100000, batch:    64/  187, ite: 972] train loss: 0.982021, tar: 0.153027 
l0: 0.111860, l1: 0.100375, l2: 0.111010, l3: 0.107370, l4: 0.128731, l5: 0.146458, l6: 0.131549

[epoch:  11/100000, batch:    66/  187, ite: 973] train loss: 0.981873, tar: 0.152985 
l0: 0.112341, l1: 0.120579, l2: 0.127324, l3: 0.124469, l4: 0.108525, l5: 0.149315, l6: 0.125580

[epoch:  11/100000, batch:    68/  187, ite: 974] train loss: 0.981756, tar: 0.152943 
l0: 0.152890, l1: 0.168460, l2: 0.173034, l3: 0.184045, l4: 0.145674, l5: 0.149760, l6: 0.139433

[epoch:  11/100000, batch:    70/  187, ite: 975] train loss: 0.981891, tar: 0.152943 
l0: 0.095719, l1: 0.094367, l2: 0.094158, l3: 0.088972, l4: 0.099982, l5: 0.102210, l6: 0.099998

[epoch:  11/100000, batch:    72/  187, ite: 976] train loss: 0.981577, tar: 0.152885 
l0: 0.113981, l1: 0.118399, l2: 0.108541, l3: 0.103989, l4: 0.135422, l5: 0.135680, l6: 0.134720

[epoch:  11/100000, batch:    74/  187, ite: 977] train loss: 0.981443, tar: 0.152845 
l0: 0.172007, l1: 0.197259, l2: 0.182166, l3: 0.211442, l4: 0.177289, l5: 0.181392, l6: 0.188056

[epoch:  11/100000, batch:    76/  187, ite: 978] train loss: 0.981779, tar: 0.152864 
l0: 0.079203, l1: 0.077200, l2: 0.075888, l3: 0.082544, l4: 0.083958, l5: 0.083168, l6: 0.076633

[epoch:  11/100000, batch:    78/  187, ite: 979] train loss: 0.981346, tar: 0.152789 
l0: 0.110135, l1: 0.110953, l2: 0.113497, l3: 0.109844, l4: 0.111139, l5: 0.129368, l6: 0.117334

[epoch:  11/100000, batch:    80/  187, ite: 980] train loss: 0.981164, tar: 0.152746 
l0: 0.086804, l1: 0.087313, l2: 0.094941, l3: 0.097871, l4: 0.098823, l5: 0.098697, l6: 0.104411

[epoch:  11/100000, batch:    82/  187, ite: 981] train loss: 0.980845, tar: 0.152678 
l0: 0.097402, l1: 0.086611, l2: 0.105119, l3: 0.100498, l4: 0.114374, l5: 0.149488, l6: 0.125461

[epoch:  11/100000, batch:    84/  187, ite: 982] train loss: 0.980640, tar: 0.152622 
l0: 0.076913, l1: 0.073952, l2: 0.075675, l3: 0.083083, l4: 0.090299, l5: 0.088968, l6: 0.083325

[epoch:  11/100000, batch:    86/  187, ite: 983] train loss: 0.980224, tar: 0.152545 
l0: 0.093054, l1: 0.099161, l2: 0.091790, l3: 0.089283, l4: 0.104161, l5: 0.104962, l6: 0.108784

[epoch:  11/100000, batch:    88/  187, ite: 984] train loss: 0.979930, tar: 0.152485 
l0: 0.097065, l1: 0.094190, l2: 0.094502, l3: 0.104909, l4: 0.104461, l5: 0.107520, l6: 0.089480

[epoch:  11/100000, batch:    90/  187, ite: 985] train loss: 0.979638, tar: 0.152428 
l0: 0.107069, l1: 0.109348, l2: 0.112214, l3: 0.107673, l4: 0.118201, l5: 0.121993, l6: 0.111130

[epoch:  11/100000, batch:    92/  187, ite: 986] train loss: 0.979443, tar: 0.152382 
l0: 0.116385, l1: 0.112126, l2: 0.120459, l3: 0.119579, l4: 0.110224, l5: 0.123899, l6: 0.119220

[epoch:  11/100000, batch:    94/  187, ite: 987] train loss: 0.979284, tar: 0.152346 
l0: 0.099264, l1: 0.097088, l2: 0.084809, l3: 0.087604, l4: 0.115330, l5: 0.119108, l6: 0.112170

[epoch:  11/100000, batch:    96/  187, ite: 988] train loss: 0.979017, tar: 0.152292 
l0: 0.070107, l1: 0.071522, l2: 0.075870, l3: 0.078423, l4: 0.077258, l5: 0.078797, l6: 0.069718

[epoch:  11/100000, batch:    98/  187, ite: 989] train loss: 0.978554, tar: 0.152209 
l0: 0.125363, l1: 0.133984, l2: 0.135343, l3: 0.139916, l4: 0.114997, l5: 0.115438, l6: 0.112357

[epoch:  11/100000, batch:   100/  187, ite: 990] train loss: 0.978452, tar: 0.152182 
l0: 0.078340, l1: 0.075513, l2: 0.077926, l3: 0.077487, l4: 0.084535, l5: 0.081046, l6: 0.081834

[epoch:  11/100000, batch:   102/  187, ite: 991] train loss: 0.978027, tar: 0.152107 
l0: 0.086535, l1: 0.090083, l2: 0.100375, l3: 0.094943, l4: 0.098419, l5: 0.105238, l6: 0.108594

[epoch:  11/100000, batch:   104/  187, ite: 992] train loss: 0.977730, tar: 0.152041 
l0: 0.072350, l1: 0.068793, l2: 0.082389, l3: 0.082524, l4: 0.077227, l5: 0.081591, l6: 0.074832

[epoch:  11/100000, batch:   106/  187, ite: 993] train loss: 0.977289, tar: 0.151961 
l0: 0.121050, l1: 0.129990, l2: 0.132595, l3: 0.135035, l4: 0.109782, l5: 0.119798, l6: 0.100049

[epoch:  11/100000, batch:   108/  187, ite: 994] train loss: 0.977159, tar: 0.151930 
l0: 0.070995, l1: 0.068354, l2: 0.060388, l3: 0.060601, l4: 0.082416, l5: 0.089728, l6: 0.087689

[epoch:  11/100000, batch:   110/  187, ite: 995] train loss: 0.976700, tar: 0.151849 
l0: 0.071692, l1: 0.064292, l2: 0.066798, l3: 0.065776, l4: 0.077280, l5: 0.076591, l6: 0.088122

[epoch:  11/100000, batch:   112/  187, ite: 996] train loss: 0.976232, tar: 0.151768 
l0: 0.156150, l1: 0.171199, l2: 0.145845, l3: 0.143621, l4: 0.164765, l5: 0.166146, l6: 0.177071

[epoch:  11/100000, batch:   114/  187, ite: 997] train loss: 0.976381, tar: 0.151773 
l0: 0.155775, l1: 0.153270, l2: 0.172969, l3: 0.183798, l4: 0.167937, l5: 0.172380, l6: 0.179650

[epoch:  11/100000, batch:   116/  187, ite: 998] train loss: 0.976591, tar: 0.151777 
l0: 0.146030, l1: 0.157535, l2: 0.150419, l3: 0.157153, l4: 0.142848, l5: 0.133570, l6: 0.147874

[epoch:  11/100000, batch:   118/  187, ite: 999] train loss: 0.976650, tar: 0.151771 
l0: 0.075866, l1: 0.075576, l2: 0.088678, l3: 0.082533, l4: 0.084876, l5: 0.083285, l6: 0.082789

[epoch:  11/100000, batch:   120/  187, ite: 1000] train loss: 0.976247, tar: 0.151695 
l0: 0.098409, l1: 0.093840, l2: 0.099291, l3: 0.100273, l4: 0.114802, l5: 0.120618, l6: 0.110323

[epoch:  11/100000, batch:   122/  187, ite: 1001] train loss: 0.976008, tar: 0.151642 
l0: 0.056876, l1: 0.051611, l2: 0.059726, l3: 0.060257, l4: 0.067353, l5: 0.063180, l6: 0.062223

[epoch:  11/100000, batch:   124/  187, ite: 1002] train loss: 0.975455, tar: 0.151547 
l0: 0.122593, l1: 0.118307, l2: 0.107705, l3: 0.115428, l4: 0.140826, l5: 0.151359, l6: 0.134164

[epoch:  11/100000, batch:   126/  187, ite: 1003] train loss: 0.975370, tar: 0.151518 
l0: 0.078598, l1: 0.080079, l2: 0.085224, l3: 0.080437, l4: 0.079535, l5: 0.078360, l6: 0.074247

[epoch:  11/100000, batch:   128/  187, ite: 1004] train loss: 0.974953, tar: 0.151446 
l0: 0.075179, l1: 0.074995, l2: 0.079819, l3: 0.083817, l4: 0.070905, l5: 0.070815, l6: 0.071311

[epoch:  11/100000, batch:   130/  187, ite: 1005] train loss: 0.974507, tar: 0.151370 
l0: 0.092063, l1: 0.088555, l2: 0.082896, l3: 0.084878, l4: 0.090321, l5: 0.097741, l6: 0.101724

[epoch:  11/100000, batch:   132/  187, ite: 1006] train loss: 0.974172, tar: 0.151311 
l0: 0.119173, l1: 0.104344, l2: 0.114201, l3: 0.120631, l4: 0.160507, l5: 0.171501, l6: 0.161737

[epoch:  11/100000, batch:   134/  187, ite: 1007] train loss: 0.974151, tar: 0.151279 
l0: 0.095065, l1: 0.100524, l2: 0.096705, l3: 0.104059, l4: 0.089550, l5: 0.090530, l6: 0.087040

[epoch:  11/100000, batch:   136/  187, ite: 1008] train loss: 0.973842, tar: 0.151223 
l0: 0.147339, l1: 0.150834, l2: 0.151358, l3: 0.148579, l4: 0.153283, l5: 0.155733, l6: 0.151736

[epoch:  11/100000, batch:   138/  187, ite: 1009] train loss: 0.973927, tar: 0.151219 
l0: 0.085475, l1: 0.080998, l2: 0.084404, l3: 0.083265, l4: 0.088668, l5: 0.092127, l6: 0.084249

[epoch:  11/100000, batch:   140/  187, ite: 1010] train loss: 0.973556, tar: 0.151154 
l0: 0.081264, l1: 0.071549, l2: 0.077097, l3: 0.079916, l4: 0.082260, l5: 0.101063, l6: 0.096864

[epoch:  11/100000, batch:   142/  187, ite: 1011] train loss: 0.973176, tar: 0.151085 
l0: 0.091430, l1: 0.089371, l2: 0.083858, l3: 0.085505, l4: 0.094095, l5: 0.093763, l6: 0.089735

[epoch:  11/100000, batch:   144/  187, ite: 1012] train loss: 0.972835, tar: 0.151026 
l0: 0.115055, l1: 0.115444, l2: 0.120923, l3: 0.116814, l4: 0.126935, l5: 0.125989, l6: 0.120725

[epoch:  11/100000, batch:   146/  187, ite: 1013] train loss: 0.972706, tar: 0.150991 
l0: 0.084696, l1: 0.072574, l2: 0.080923, l3: 0.079949, l4: 0.083215, l5: 0.102735, l6: 0.090335

[epoch:  11/100000, batch:   148/  187, ite: 1014] train loss: 0.972333, tar: 0.150925 
l0: 0.133227, l1: 0.135957, l2: 0.138134, l3: 0.140448, l4: 0.139473, l5: 0.133747, l6: 0.140611

[epoch:  11/100000, batch:   150/  187, ite: 1015] train loss: 0.972322, tar: 0.150908 
l0: 0.050839, l1: 0.051956, l2: 0.058629, l3: 0.062573, l4: 0.059066, l5: 0.057374, l6: 0.052264

[epoch:  11/100000, batch:   152/  187, ite: 1016] train loss: 0.971751, tar: 0.150809 
l0: 0.080980, l1: 0.083581, l2: 0.088743, l3: 0.086960, l4: 0.085991, l5: 0.083414, l6: 0.090824

[epoch:  11/100000, batch:   154/  187, ite: 1017] train loss: 0.971386, tar: 0.150741 
l0: 0.099962, l1: 0.101969, l2: 0.094278, l3: 0.088549, l4: 0.108085, l5: 0.120946, l6: 0.115500

[epoch:  11/100000, batch:   156/  187, ite: 1018] train loss: 0.971149, tar: 0.150691 
l0: 0.127619, l1: 0.131053, l2: 0.138092, l3: 0.147565, l4: 0.132806, l5: 0.130071, l6: 0.144477

[epoch:  11/100000, batch:   158/  187, ite: 1019] train loss: 0.971129, tar: 0.150668 
l0: 0.133651, l1: 0.129701, l2: 0.136892, l3: 0.144123, l4: 0.144860, l5: 0.131765, l6: 0.139889

[epoch:  11/100000, batch:   160/  187, ite: 1020] train loss: 0.971119, tar: 0.150651 
l0: 0.086893, l1: 0.085914, l2: 0.097228, l3: 0.102077, l4: 0.086323, l5: 0.099591, l6: 0.090929

[epoch:  11/100000, batch:   162/  187, ite: 1021] train loss: 0.970804, tar: 0.150589 
l0: 0.099550, l1: 0.096464, l2: 0.098157, l3: 0.102936, l4: 0.107212, l5: 0.118264, l6: 0.107877

[epoch:  11/100000, batch:   164/  187, ite: 1022] train loss: 0.970569, tar: 0.150539 
l0: 0.060347, l1: 0.064605, l2: 0.065909, l3: 0.062177, l4: 0.059000, l5: 0.060913, l6: 0.053108

[epoch:  11/100000, batch:   166/  187, ite: 1023] train loss: 0.970036, tar: 0.150451 
l0: 0.076433, l1: 0.074988, l2: 0.076521, l3: 0.078333, l4: 0.084321, l5: 0.095355, l6: 0.088207

[epoch:  11/100000, batch:   168/  187, ite: 1024] train loss: 0.969650, tar: 0.150379 
l0: 0.135761, l1: 0.137917, l2: 0.141549, l3: 0.160320, l4: 0.142278, l5: 0.141409, l6: 0.135402

[epoch:  11/100000, batch:   170/  187, ite: 1025] train loss: 0.969674, tar: 0.150364 
l0: 0.100713, l1: 0.119560, l2: 0.104566, l3: 0.093349, l4: 0.116815, l5: 0.092379, l6: 0.092026

[epoch:  11/100000, batch:   172/  187, ite: 1026] train loss: 0.969430, tar: 0.150316 
l0: 0.133082, l1: 0.118465, l2: 0.126089, l3: 0.124354, l4: 0.133131, l5: 0.159584, l6: 0.149880

[epoch:  11/100000, batch:   174/  187, ite: 1027] train loss: 0.969406, tar: 0.150299 
l0: 0.053138, l1: 0.052980, l2: 0.052675, l3: 0.053451, l4: 0.067323, l5: 0.059799, l6: 0.051180

[epoch:  11/100000, batch:   176/  187, ite: 1028] train loss: 0.968843, tar: 0.150205 
l0: 0.108365, l1: 0.100106, l2: 0.104391, l3: 0.106954, l4: 0.102515, l5: 0.115729, l6: 0.110713

[epoch:  11/100000, batch:   178/  187, ite: 1029] train loss: 0.968629, tar: 0.150164 
l0: 0.122058, l1: 0.116737, l2: 0.123512, l3: 0.124310, l4: 0.141495, l5: 0.137565, l6: 0.161693

[epoch:  11/100000, batch:   180/  187, ite: 1030] train loss: 0.968589, tar: 0.150137 
l0: 0.086538, l1: 0.081185, l2: 0.089315, l3: 0.093428, l4: 0.103581, l5: 0.096920, l6: 0.091743

[epoch:  11/100000, batch:   182/  187, ite: 1031] train loss: 0.968273, tar: 0.150075 
l0: 0.170871, l1: 0.174680, l2: 0.172016, l3: 0.172738, l4: 0.192828, l5: 0.177325, l6: 0.182622

[epoch:  11/100000, batch:   184/  187, ite: 1032] train loss: 0.968539, tar: 0.150095 
l0: 0.080469, l1: 0.083795, l2: 0.076803, l3: 0.081606, l4: 0.095442, l5: 0.089029, l6: 0.075258

[epoch:  11/100000, batch:   186/  187, ite: 1033] train loss: 0.968165, tar: 0.150028 
l0: 0.079000, l1: 0.071500, l2: 0.075640, l3: 0.078408, l4: 0.091640, l5: 0.082418, l6: 0.086435

[epoch:  11/100000, batch:   188/  187, ite: 1034] train loss: 0.967776, tar: 0.149959 
l0: 0.085060, l1: 0.082068, l2: 0.081700, l3: 0.084086, l4: 0.085324, l5: 0.090453, l6: 0.082272

[epoch:  12/100000, batch:     2/  187, ite: 1035] train loss: 0.967412, tar: 0.149896 
l0: 0.049987, l1: 0.047948, l2: 0.053053, l3: 0.069648, l4: 0.059899, l5: 0.058069, l6: 0.070060

[epoch:  12/100000, batch:     4/  187, ite: 1036] train loss: 0.966872, tar: 0.149800 
l0: 0.124338, l1: 0.116331, l2: 0.103404, l3: 0.103885, l4: 0.123803, l5: 0.125343, l6: 0.111578

[epoch:  12/100000, batch:     6/  187, ite: 1037] train loss: 0.966720, tar: 0.149775 
l0: 0.084109, l1: 0.093698, l2: 0.101150, l3: 0.097945, l4: 0.080483, l5: 0.089035, l6: 0.078213

[epoch:  12/100000, batch:     8/  187, ite: 1038] train loss: 0.966390, tar: 0.149712 
l0: 0.141413, l1: 0.149553, l2: 0.155413, l3: 0.169446, l4: 0.171697, l5: 0.159775, l6: 0.167404

[epoch:  12/100000, batch:    10/  187, ite: 1039] train loss: 0.966533, tar: 0.149704 
l0: 0.114622, l1: 0.102063, l2: 0.100347, l3: 0.101437, l4: 0.126857, l5: 0.120343, l6: 0.127154

[epoch:  12/100000, batch:    12/  187, ite: 1040] train loss: 0.966366, tar: 0.149670 
l0: 0.100145, l1: 0.089184, l2: 0.085510, l3: 0.092955, l4: 0.109270, l5: 0.113996, l6: 0.128753

[epoch:  12/100000, batch:    14/  187, ite: 1041] train loss: 0.966129, tar: 0.149623 
l0: 0.100821, l1: 0.098678, l2: 0.099399, l3: 0.110955, l4: 0.105825, l5: 0.111722, l6: 0.112805

[epoch:  12/100000, batch:    16/  187, ite: 1042] train loss: 0.965912, tar: 0.149576 
l0: 0.098506, l1: 0.114454, l2: 0.121162, l3: 0.099696, l4: 0.095529, l5: 0.097597, l6: 0.092771

[epoch:  12/100000, batch:    18/  187, ite: 1043] train loss: 0.965676, tar: 0.149527 
l0: 0.097563, l1: 0.117546, l2: 0.113135, l3: 0.114020, l4: 0.109493, l5: 0.090992, l6: 0.092061

[epoch:  12/100000, batch:    20/  187, ite: 1044] train loss: 0.965455, tar: 0.149477 
l0: 0.122176, l1: 0.116441, l2: 0.127895, l3: 0.129091, l4: 0.131452, l5: 0.136560, l6: 0.161921

[epoch:  12/100000, batch:    22/  187, ite: 1045] train loss: 0.965417, tar: 0.149451 
l0: 0.096109, l1: 0.105890, l2: 0.109632, l3: 0.099977, l4: 0.114470, l5: 0.102168, l6: 0.098996

[epoch:  12/100000, batch:    24/  187, ite: 1046] train loss: 0.965189, tar: 0.149400 
l0: 0.098186, l1: 0.097672, l2: 0.099605, l3: 0.093105, l4: 0.110643, l5: 0.123504, l6: 0.104314

[epoch:  12/100000, batch:    26/  187, ite: 1047] train loss: 0.964962, tar: 0.149351 
l0: 0.078376, l1: 0.092771, l2: 0.086993, l3: 0.084922, l4: 0.086366, l5: 0.080522, l6: 0.074590

[epoch:  12/100000, batch:    28/  187, ite: 1048] train loss: 0.964599, tar: 0.149283 
l0: 0.068180, l1: 0.071769, l2: 0.076312, l3: 0.070248, l4: 0.089512, l5: 0.081258, l6: 0.078553

[epoch:  12/100000, batch:    30/  187, ite: 1049] train loss: 0.964190, tar: 0.149206 
l0: 0.145855, l1: 0.148503, l2: 0.161084, l3: 0.160938, l4: 0.134238, l5: 0.159609, l6: 0.151295

[epoch:  12/100000, batch:    32/  187, ite: 1050] train loss: 0.964283, tar: 0.149203 
l0: 0.124822, l1: 0.115311, l2: 0.123172, l3: 0.130814, l4: 0.164581, l5: 0.150324, l6: 0.148813

[epoch:  12/100000, batch:    34/  187, ite: 1051] train loss: 0.964276, tar: 0.149180 
l0: 0.172930, l1: 0.202223, l2: 0.200345, l3: 0.202818, l4: 0.185297, l5: 0.168350, l6: 0.163958

[epoch:  12/100000, batch:    36/  187, ite: 1052] train loss: 0.964592, tar: 0.149202 
l0: 0.126505, l1: 0.128434, l2: 0.128208, l3: 0.127823, l4: 0.135562, l5: 0.139426, l6: 0.123098

[epoch:  12/100000, batch:    38/  187, ite: 1053] train loss: 0.964539, tar: 0.149181 
l0: 0.080790, l1: 0.083378, l2: 0.080435, l3: 0.083326, l4: 0.072992, l5: 0.100829, l6: 0.111762

[epoch:  12/100000, batch:    40/  187, ite: 1054] train loss: 0.964206, tar: 0.149116 
l0: 0.128702, l1: 0.119469, l2: 0.127111, l3: 0.138281, l4: 0.120426, l5: 0.142182, l6: 0.128173

[epoch:  12/100000, batch:    42/  187, ite: 1055] train loss: 0.964149, tar: 0.149097 
l0: 0.113615, l1: 0.115175, l2: 0.119440, l3: 0.126253, l4: 0.107527, l5: 0.116737, l6: 0.114087

[epoch:  12/100000, batch:    44/  187, ite: 1056] train loss: 0.964006, tar: 0.149063 
l0: 0.076262, l1: 0.076554, l2: 0.079884, l3: 0.079236, l4: 0.085079, l5: 0.083665, l6: 0.087923

[epoch:  12/100000, batch:    46/  187, ite: 1057] train loss: 0.963632, tar: 0.148994 
l0: 0.103285, l1: 0.099190, l2: 0.102859, l3: 0.095983, l4: 0.100028, l5: 0.116107, l6: 0.121793

[epoch:  12/100000, batch:    48/  187, ite: 1058] train loss: 0.963420, tar: 0.148951 
l0: 0.090090, l1: 0.084407, l2: 0.084677, l3: 0.085992, l4: 0.080077, l5: 0.091310, l6: 0.093042

[epoch:  12/100000, batch:    50/  187, ite: 1059] train loss: 0.963086, tar: 0.148895 
l0: 0.158626, l1: 0.159718, l2: 0.175049, l3: 0.158327, l4: 0.149329, l5: 0.179911, l6: 0.157502

[epoch:  12/100000, batch:    52/  187, ite: 1060] train loss: 0.963251, tar: 0.148904 
l0: 0.104774, l1: 0.111973, l2: 0.120784, l3: 0.117696, l4: 0.088281, l5: 0.097920, l6: 0.110760

[epoch:  12/100000, batch:    54/  187, ite: 1061] train loss: 0.963052, tar: 0.148863 
l0: 0.060810, l1: 0.053345, l2: 0.057978, l3: 0.064655, l4: 0.065836, l5: 0.075636, l6: 0.073360

[epoch:  12/100000, batch:    56/  187, ite: 1062] train loss: 0.962571, tar: 0.148780 
l0: 0.086618, l1: 0.086136, l2: 0.093564, l3: 0.094303, l4: 0.096207, l5: 0.090232, l6: 0.074629

[epoch:  12/100000, batch:    58/  187, ite: 1063] train loss: 0.962250, tar: 0.148721 
l0: 0.100898, l1: 0.100677, l2: 0.118809, l3: 0.126047, l4: 0.128593, l5: 0.093730, l6: 0.098806

[epoch:  12/100000, batch:    60/  187, ite: 1064] train loss: 0.962067, tar: 0.148677 
l0: 0.071579, l1: 0.068098, l2: 0.083536, l3: 0.096610, l4: 0.090954, l5: 0.075245, l6: 0.071959

[epoch:  12/100000, batch:    62/  187, ite: 1065] train loss: 0.961687, tar: 0.148604 
l0: 0.091506, l1: 0.085898, l2: 0.095402, l3: 0.093370, l4: 0.124266, l5: 0.118592, l6: 0.128302

[epoch:  12/100000, batch:    64/  187, ite: 1066] train loss: 0.961477, tar: 0.148551 
l0: 0.151011, l1: 0.154149, l2: 0.159206, l3: 0.158500, l4: 0.157564, l5: 0.169104, l6: 0.172586

[epoch:  12/100000, batch:    66/  187, ite: 1067] train loss: 0.961628, tar: 0.148553 
l0: 0.117670, l1: 0.107751, l2: 0.117578, l3: 0.126025, l4: 0.133942, l5: 0.144169, l6: 0.138020

[epoch:  12/100000, batch:    68/  187, ite: 1068] train loss: 0.961556, tar: 0.148524 
l0: 0.098495, l1: 0.097688, l2: 0.100160, l3: 0.105621, l4: 0.092353, l5: 0.091142, l6: 0.090667

[epoch:  12/100000, batch:    70/  187, ite: 1069] train loss: 0.961289, tar: 0.148477 
l0: 0.078986, l1: 0.077631, l2: 0.083871, l3: 0.086232, l4: 0.088282, l5: 0.099557, l6: 0.087807

[epoch:  12/100000, batch:    72/  187, ite: 1070] train loss: 0.960954, tar: 0.148412 
l0: 0.094101, l1: 0.090734, l2: 0.094038, l3: 0.099071, l4: 0.110769, l5: 0.095031, l6: 0.103397

[epoch:  12/100000, batch:    74/  187, ite: 1071] train loss: 0.960698, tar: 0.148362 
l0: 0.113238, l1: 0.107087, l2: 0.107128, l3: 0.113799, l4: 0.120748, l5: 0.130056, l6: 0.132048

[epoch:  12/100000, batch:    76/  187, ite: 1072] train loss: 0.960570, tar: 0.148329 
l0: 0.077973, l1: 0.070991, l2: 0.083893, l3: 0.093073, l4: 0.091102, l5: 0.100134, l6: 0.092562

[epoch:  12/100000, batch:    78/  187, ite: 1073] train loss: 0.960243, tar: 0.148263 
l0: 0.096762, l1: 0.101498, l2: 0.101527, l3: 0.111885, l4: 0.085427, l5: 0.098236, l6: 0.089770

[epoch:  12/100000, batch:    80/  187, ite: 1074] train loss: 0.959987, tar: 0.148215 
l0: 0.047389, l1: 0.047773, l2: 0.061423, l3: 0.058168, l4: 0.081539, l5: 0.064702, l6: 0.062940

[epoch:  12/100000, batch:    82/  187, ite: 1075] train loss: 0.959489, tar: 0.148121 
l0: 0.059760, l1: 0.056635, l2: 0.057395, l3: 0.063764, l4: 0.065142, l5: 0.074780, l6: 0.083789

[epoch:  12/100000, batch:    84/  187, ite: 1076] train loss: 0.959026, tar: 0.148039 
l0: 0.143626, l1: 0.127833, l2: 0.140357, l3: 0.152870, l4: 0.159043, l5: 0.170463, l6: 0.160624

[epoch:  12/100000, batch:    86/  187, ite: 1077] train loss: 0.959115, tar: 0.148035 
l0: 0.123440, l1: 0.115359, l2: 0.129005, l3: 0.135595, l4: 0.138595, l5: 0.145099, l6: 0.149473

[epoch:  12/100000, batch:    88/  187, ite: 1078] train loss: 0.959094, tar: 0.148012 
l0: 0.081526, l1: 0.083434, l2: 0.086102, l3: 0.087220, l4: 0.084064, l5: 0.083635, l6: 0.087815

[epoch:  12/100000, batch:    90/  187, ite: 1079] train loss: 0.958755, tar: 0.147951 
l0: 0.170455, l1: 0.186636, l2: 0.178403, l3: 0.182526, l4: 0.171625, l5: 0.165280, l6: 0.188021

[epoch:  12/100000, batch:    92/  187, ite: 1080] train loss: 0.959018, tar: 0.147972 
l0: 0.040384, l1: 0.038345, l2: 0.043380, l3: 0.043234, l4: 0.047519, l5: 0.049615, l6: 0.040354

[epoch:  12/100000, batch:    94/  187, ite: 1081] train loss: 0.958411, tar: 0.147872 
l0: 0.137261, l1: 0.144789, l2: 0.126957, l3: 0.134184, l4: 0.128295, l5: 0.133770, l6: 0.127302

[epoch:  12/100000, batch:    96/  187, ite: 1082] train loss: 0.958387, tar: 0.147862 
l0: 0.116943, l1: 0.107604, l2: 0.124254, l3: 0.127460, l4: 0.121013, l5: 0.116136, l6: 0.114661

[epoch:  12/100000, batch:    98/  187, ite: 1083] train loss: 0.958267, tar: 0.147834 
l0: 0.106574, l1: 0.108596, l2: 0.105257, l3: 0.107162, l4: 0.108619, l5: 0.108855, l6: 0.102294

[epoch:  12/100000, batch:   100/  187, ite: 1084] train loss: 0.958072, tar: 0.147796 
l0: 0.084546, l1: 0.086858, l2: 0.094427, l3: 0.091953, l4: 0.093697, l5: 0.094536, l6: 0.090700

[epoch:  12/100000, batch:   102/  187, ite: 1085] train loss: 0.957776, tar: 0.147737 
l0: 0.107214, l1: 0.110936, l2: 0.115540, l3: 0.124875, l4: 0.119786, l5: 0.110386, l6: 0.116859

[epoch:  12/100000, batch:   104/  187, ite: 1086] train loss: 0.957636, tar: 0.147700 
l0: 0.102330, l1: 0.097421, l2: 0.120356, l3: 0.126265, l4: 0.121344, l5: 0.116246, l6: 0.130227

[epoch:  12/100000, batch:   106/  187, ite: 1087] train loss: 0.957504, tar: 0.147658 
l0: 0.087469, l1: 0.081712, l2: 0.093709, l3: 0.093613, l4: 0.101035, l5: 0.097553, l6: 0.093084

[epoch:  12/100000, batch:   108/  187, ite: 1088] train loss: 0.957220, tar: 0.147603 
l0: 0.099186, l1: 0.096310, l2: 0.101749, l3: 0.105644, l4: 0.104453, l5: 0.108491, l6: 0.109303

[epoch:  12/100000, batch:   110/  187, ite: 1089] train loss: 0.957007, tar: 0.147559 
l0: 0.115374, l1: 0.107603, l2: 0.111391, l3: 0.112901, l4: 0.130166, l5: 0.137802, l6: 0.150217

[epoch:  12/100000, batch:   112/  187, ite: 1090] train loss: 0.956923, tar: 0.147529 
l0: 0.107671, l1: 0.107649, l2: 0.107408, l3: 0.115088, l4: 0.145421, l5: 0.125738, l6: 0.135958

[epoch:  12/100000, batch:   114/  187, ite: 1091] train loss: 0.956820, tar: 0.147492 
l0: 0.126570, l1: 0.119130, l2: 0.117116, l3: 0.115999, l4: 0.142026, l5: 0.166194, l6: 0.175766

[epoch:  12/100000, batch:   116/  187, ite: 1092] train loss: 0.956826, tar: 0.147473 
l0: 0.123409, l1: 0.123895, l2: 0.133789, l3: 0.130354, l4: 0.122237, l5: 0.123101, l6: 0.121501

[epoch:  12/100000, batch:   118/  187, ite: 1093] train loss: 0.956754, tar: 0.147451 
l0: 0.082106, l1: 0.084255, l2: 0.083763, l3: 0.086613, l4: 0.084329, l5: 0.086599, l6: 0.084374

[epoch:  12/100000, batch:   120/  187, ite: 1094] train loss: 0.956420, tar: 0.147392 
l0: 0.174242, l1: 0.200207, l2: 0.177271, l3: 0.154871, l4: 0.188045, l5: 0.181130, l6: 0.205842

[epoch:  12/100000, batch:   122/  187, ite: 1095] train loss: 0.956717, tar: 0.147416 
l0: 0.079223, l1: 0.073736, l2: 0.080199, l3: 0.084200, l4: 0.088242, l5: 0.093949, l6: 0.080069

[epoch:  12/100000, batch:   124/  187, ite: 1096] train loss: 0.956373, tar: 0.147354 
l0: 0.094005, l1: 0.086436, l2: 0.096537, l3: 0.099156, l4: 0.106212, l5: 0.106764, l6: 0.108310

[epoch:  12/100000, batch:   126/  187, ite: 1097] train loss: 0.956137, tar: 0.147305 
l0: 0.117425, l1: 0.119986, l2: 0.111277, l3: 0.114750, l4: 0.121087, l5: 0.121910, l6: 0.111795

[epoch:  12/100000, batch:   128/  187, ite: 1098] train loss: 0.956012, tar: 0.147278 
l0: 0.102222, l1: 0.103455, l2: 0.102332, l3: 0.103459, l4: 0.117974, l5: 0.107438, l6: 0.106497

[epoch:  12/100000, batch:   130/  187, ite: 1099] train loss: 0.955818, tar: 0.147237 
l0: 0.067634, l1: 0.064523, l2: 0.064009, l3: 0.067076, l4: 0.085381, l5: 0.080977, l6: 0.082773

[epoch:  12/100000, batch:   132/  187, ite: 1100] train loss: 0.955415, tar: 0.147165 
l0: 0.153389, l1: 0.179276, l2: 0.170550, l3: 0.165914, l4: 0.144557, l5: 0.142816, l6: 0.134529

[epoch:  12/100000, batch:   134/  187, ite: 1101] train loss: 0.955538, tar: 0.147170 
l0: 0.058110, l1: 0.060184, l2: 0.058700, l3: 0.058245, l4: 0.057633, l5: 0.059588, l6: 0.063665

[epoch:  12/100000, batch:   136/  187, ite: 1102] train loss: 0.955049, tar: 0.147089 
l0: 0.083228, l1: 0.080962, l2: 0.088577, l3: 0.087900, l4: 0.094978, l5: 0.087335, l6: 0.092001

[epoch:  12/100000, batch:   138/  187, ite: 1103] train loss: 0.954740, tar: 0.147032 
l0: 0.102004, l1: 0.114318, l2: 0.113006, l3: 0.108107, l4: 0.116672, l5: 0.118455, l6: 0.097614

[epoch:  12/100000, batch:   140/  187, ite: 1104] train loss: 0.954573, tar: 0.146991 
l0: 0.077415, l1: 0.079155, l2: 0.075752, l3: 0.074218, l4: 0.084403, l5: 0.089314, l6: 0.099367

[epoch:  12/100000, batch:   142/  187, ite: 1105] train loss: 0.954234, tar: 0.146928 
l0: 0.097996, l1: 0.116320, l2: 0.117962, l3: 0.109639, l4: 0.098946, l5: 0.100363, l6: 0.090694

[epoch:  12/100000, batch:   144/  187, ite: 1106] train loss: 0.954033, tar: 0.146884 
l0: 0.125109, l1: 0.133068, l2: 0.140602, l3: 0.146618, l4: 0.171759, l5: 0.135505, l6: 0.128635

[epoch:  12/100000, batch:   146/  187, ite: 1107] train loss: 0.954057, tar: 0.146864 
l0: 0.052539, l1: 0.047426, l2: 0.052262, l3: 0.055612, l4: 0.058037, l5: 0.057710, l6: 0.061835

[epoch:  12/100000, batch:   148/  187, ite: 1108] train loss: 0.953544, tar: 0.146779 
l0: 0.133096, l1: 0.130042, l2: 0.148113, l3: 0.158786, l4: 0.135615, l5: 0.135746, l6: 0.134392

[epoch:  12/100000, batch:   150/  187, ite: 1109] train loss: 0.953564, tar: 0.146766 
l0: 0.112696, l1: 0.114041, l2: 0.120501, l3: 0.112929, l4: 0.117440, l5: 0.124885, l6: 0.119644

[epoch:  12/100000, batch:   152/  187, ite: 1110] train loss: 0.953446, tar: 0.146736 
l0: 0.130133, l1: 0.128741, l2: 0.116569, l3: 0.122283, l4: 0.132033, l5: 0.170887, l6: 0.155291

[epoch:  12/100000, batch:   154/  187, ite: 1111] train loss: 0.953448, tar: 0.146721 
l0: 0.118900, l1: 0.130636, l2: 0.128513, l3: 0.126112, l4: 0.107067, l5: 0.104285, l6: 0.107032

[epoch:  12/100000, batch:   156/  187, ite: 1112] train loss: 0.953330, tar: 0.146696 
l0: 0.135915, l1: 0.136220, l2: 0.146896, l3: 0.150675, l4: 0.132374, l5: 0.134610, l6: 0.131872

[epoch:  12/100000, batch:   158/  187, ite: 1113] train loss: 0.953344, tar: 0.146686 
l0: 0.144673, l1: 0.157209, l2: 0.155846, l3: 0.155243, l4: 0.137782, l5: 0.135449, l6: 0.129989

[epoch:  12/100000, batch:   160/  187, ite: 1114] train loss: 0.953400, tar: 0.146684 
l0: 0.066922, l1: 0.064784, l2: 0.073527, l3: 0.078822, l4: 0.086281, l5: 0.076070, l6: 0.074473

[epoch:  12/100000, batch:   162/  187, ite: 1115] train loss: 0.953013, tar: 0.146613 
l0: 0.108618, l1: 0.107227, l2: 0.118194, l3: 0.117219, l4: 0.107979, l5: 0.109957, l6: 0.115270

[epoch:  12/100000, batch:   164/  187, ite: 1116] train loss: 0.952862, tar: 0.146579 
l0: 0.104926, l1: 0.105377, l2: 0.110100, l3: 0.114795, l4: 0.122166, l5: 0.125648, l6: 0.122733

[epoch:  12/100000, batch:   166/  187, ite: 1117] train loss: 0.952730, tar: 0.146541 
l0: 0.100915, l1: 0.107690, l2: 0.105728, l3: 0.112927, l4: 0.131587, l5: 0.107422, l6: 0.098099

[epoch:  12/100000, batch:   168/  187, ite: 1118] train loss: 0.952561, tar: 0.146501 
l0: 0.122122, l1: 0.133080, l2: 0.120454, l3: 0.130769, l4: 0.104891, l5: 0.112494, l6: 0.114701

[epoch:  12/100000, batch:   170/  187, ite: 1119] train loss: 0.952459, tar: 0.146479 
l0: 0.135405, l1: 0.135004, l2: 0.131556, l3: 0.137140, l4: 0.138626, l5: 0.136318, l6: 0.138492

[epoch:  12/100000, batch:   172/  187, ite: 1120] train loss: 0.952460, tar: 0.146469 
l0: 0.073199, l1: 0.082414, l2: 0.084338, l3: 0.079851, l4: 0.068106, l5: 0.070952, l6: 0.056196

[epoch:  12/100000, batch:   174/  187, ite: 1121] train loss: 0.952069, tar: 0.146404 
l0: 0.133583, l1: 0.137855, l2: 0.133051, l3: 0.132341, l4: 0.128852, l5: 0.117178, l6: 0.127518

[epoch:  12/100000, batch:   176/  187, ite: 1122] train loss: 0.952032, tar: 0.146392 
l0: 0.083994, l1: 0.081802, l2: 0.090890, l3: 0.090240, l4: 0.086494, l5: 0.089371, l6: 0.087080

[epoch:  12/100000, batch:   178/  187, ite: 1123] train loss: 0.951727, tar: 0.146337 
l0: 0.073666, l1: 0.073254, l2: 0.068294, l3: 0.071970, l4: 0.066429, l5: 0.083776, l6: 0.086016

[epoch:  12/100000, batch:   180/  187, ite: 1124] train loss: 0.951346, tar: 0.146272 
l0: 0.083592, l1: 0.086246, l2: 0.094660, l3: 0.096173, l4: 0.103269, l5: 0.096665, l6: 0.097478

[epoch:  12/100000, batch:   182/  187, ite: 1125] train loss: 0.951086, tar: 0.146216 
l0: 0.086915, l1: 0.084488, l2: 0.080304, l3: 0.081500, l4: 0.088270, l5: 0.106354, l6: 0.090662

[epoch:  12/100000, batch:   184/  187, ite: 1126] train loss: 0.950790, tar: 0.146164 
l0: 0.126984, l1: 0.115908, l2: 0.121878, l3: 0.126850, l4: 0.138317, l5: 0.165885, l6: 0.135602

[epoch:  12/100000, batch:   186/  187, ite: 1127] train loss: 0.950773, tar: 0.146147 
l0: 0.118928, l1: 0.118658, l2: 0.120723, l3: 0.119334, l4: 0.162365, l5: 0.147245, l6: 0.141521

[epoch:  12/100000, batch:   188/  187, ite: 1128] train loss: 0.950754, tar: 0.146122 
l0: 0.044686, l1: 0.046709, l2: 0.045913, l3: 0.045722, l4: 0.046698, l5: 0.051359, l6: 0.046987

[epoch:  13/100000, batch:     2/  187, ite: 1129] train loss: 0.950202, tar: 0.146033 
l0: 0.088849, l1: 0.083732, l2: 0.080478, l3: 0.080846, l4: 0.082086, l5: 0.105603, l6: 0.088014

[epoch:  13/100000, batch:     4/  187, ite: 1130] train loss: 0.949901, tar: 0.145982 
l0: 0.110986, l1: 0.105890, l2: 0.124651, l3: 0.130957, l4: 0.141204, l5: 0.124455, l6: 0.142283

[epoch:  13/100000, batch:     6/  187, ite: 1131] train loss: 0.949839, tar: 0.145951 
l0: 0.096879, l1: 0.092885, l2: 0.105455, l3: 0.097336, l4: 0.100469, l5: 0.132298, l6: 0.094539

[epoch:  13/100000, batch:     8/  187, ite: 1132] train loss: 0.949636, tar: 0.145908 
l0: 0.110442, l1: 0.108709, l2: 0.110614, l3: 0.113546, l4: 0.119899, l5: 0.112375, l6: 0.105708

[epoch:  13/100000, batch:    10/  187, ite: 1133] train loss: 0.949488, tar: 0.145876 
l0: 0.140148, l1: 0.144815, l2: 0.142545, l3: 0.145111, l4: 0.137392, l5: 0.142486, l6: 0.129762

[epoch:  13/100000, batch:    12/  187, ite: 1134] train loss: 0.949516, tar: 0.145871 
l0: 0.103036, l1: 0.097224, l2: 0.105710, l3: 0.109200, l4: 0.113026, l5: 0.113269, l6: 0.110201

[epoch:  13/100000, batch:    14/  187, ite: 1135] train loss: 0.949342, tar: 0.145834 
l0: 0.156779, l1: 0.154920, l2: 0.159121, l3: 0.162063, l4: 0.156128, l5: 0.146163, l6: 0.143037

[epoch:  13/100000, batch:    16/  187, ite: 1136] train loss: 0.949456, tar: 0.145843 
l0: 0.088046, l1: 0.089968, l2: 0.094899, l3: 0.095235, l4: 0.103157, l5: 0.107881, l6: 0.090675

[epoch:  13/100000, batch:    18/  187, ite: 1137] train loss: 0.949210, tar: 0.145792 
l0: 0.091599, l1: 0.093176, l2: 0.104205, l3: 0.093757, l4: 0.094227, l5: 0.095138, l6: 0.092264

[epoch:  13/100000, batch:    20/  187, ite: 1138] train loss: 0.948959, tar: 0.145745 
l0: 0.067040, l1: 0.067817, l2: 0.075138, l3: 0.073572, l4: 0.077543, l5: 0.090235, l6: 0.068466

[epoch:  13/100000, batch:    22/  187, ite: 1139] train loss: 0.948583, tar: 0.145676 
l0: 0.084127, l1: 0.083097, l2: 0.086254, l3: 0.082949, l4: 0.091292, l5: 0.095241, l6: 0.098401

[epoch:  13/100000, batch:    24/  187, ite: 1140] train loss: 0.948296, tar: 0.145622 
l0: 0.089395, l1: 0.083070, l2: 0.089032, l3: 0.086946, l4: 0.097638, l5: 0.094770, l6: 0.086069

[epoch:  13/100000, batch:    26/  187, ite: 1141] train loss: 0.948014, tar: 0.145572 
l0: 0.081374, l1: 0.078400, l2: 0.088193, l3: 0.103391, l4: 0.125519, l5: 0.111429, l6: 0.114024

[epoch:  13/100000, batch:    28/  187, ite: 1142] train loss: 0.947799, tar: 0.145516 
l0: 0.099133, l1: 0.105594, l2: 0.111057, l3: 0.111758, l4: 0.103969, l5: 0.104010, l6: 0.100932

[epoch:  13/100000, batch:    30/  187, ite: 1143] train loss: 0.947614, tar: 0.145476 
l0: 0.081275, l1: 0.085600, l2: 0.086460, l3: 0.095113, l4: 0.099005, l5: 0.095753, l6: 0.102973

[epoch:  13/100000, batch:    32/  187, ite: 1144] train loss: 0.947350, tar: 0.145419 
l0: 0.113114, l1: 0.129903, l2: 0.096289, l3: 0.093789, l4: 0.100402, l5: 0.102603, l6: 0.103674

[epoch:  13/100000, batch:    34/  187, ite: 1145] train loss: 0.947169, tar: 0.145391 
l0: 0.117760, l1: 0.126767, l2: 0.129294, l3: 0.121050, l4: 0.130566, l5: 0.138036, l6: 0.148896

[epoch:  13/100000, batch:    36/  187, ite: 1146] train loss: 0.947139, tar: 0.145367 
l0: 0.077694, l1: 0.075937, l2: 0.077315, l3: 0.073223, l4: 0.083894, l5: 0.081966, l6: 0.080597

[epoch:  13/100000, batch:    38/  187, ite: 1147] train loss: 0.946793, tar: 0.145308 
l0: 0.137686, l1: 0.133619, l2: 0.147428, l3: 0.155762, l4: 0.194915, l5: 0.191119, l6: 0.201748

[epoch:  13/100000, batch:    40/  187, ite: 1148] train loss: 0.946981, tar: 0.145302 
l0: 0.115874, l1: 0.108205, l2: 0.127280, l3: 0.127807, l4: 0.119603, l5: 0.125320, l6: 0.125545

[epoch:  13/100000, batch:    42/  187, ite: 1149] train loss: 0.946896, tar: 0.145276 
l0: 0.054771, l1: 0.052828, l2: 0.052552, l3: 0.051163, l4: 0.061413, l5: 0.057411, l6: 0.056113

[epoch:  13/100000, batch:    44/  187, ite: 1150] train loss: 0.946408, tar: 0.145197 
l0: 0.095352, l1: 0.107537, l2: 0.095682, l3: 0.101818, l4: 0.090750, l5: 0.100140, l6: 0.113080

[epoch:  13/100000, batch:    46/  187, ite: 1151] train loss: 0.946198, tar: 0.145154 
l0: 0.099597, l1: 0.096844, l2: 0.102247, l3: 0.100714, l4: 0.113325, l5: 0.116390, l6: 0.114866

[epoch:  13/100000, batch:    48/  187, ite: 1152] train loss: 0.946023, tar: 0.145114 
l0: 0.140272, l1: 0.146151, l2: 0.161065, l3: 0.182350, l4: 0.142968, l5: 0.137730, l6: 0.134251

[epoch:  13/100000, batch:    50/  187, ite: 1153] train loss: 0.946108, tar: 0.145110 
l0: 0.067953, l1: 0.068223, l2: 0.067518, l3: 0.063967, l4: 0.079382, l5: 0.072406, l6: 0.069682

[epoch:  13/100000, batch:    52/  187, ite: 1154] train loss: 0.945712, tar: 0.145043 
l0: 0.096574, l1: 0.106444, l2: 0.106271, l3: 0.098388, l4: 0.109573, l5: 0.101925, l6: 0.097268

[epoch:  13/100000, batch:    54/  187, ite: 1155] train loss: 0.945514, tar: 0.145001 
l0: 0.076243, l1: 0.077284, l2: 0.082258, l3: 0.085814, l4: 0.080806, l5: 0.078384, l6: 0.069506

[epoch:  13/100000, batch:    56/  187, ite: 1156] train loss: 0.945172, tar: 0.144942 
l0: 0.114613, l1: 0.104478, l2: 0.112581, l3: 0.120101, l4: 0.122788, l5: 0.123882, l6: 0.114169

[epoch:  13/100000, batch:    58/  187, ite: 1157] train loss: 0.945057, tar: 0.144916 
l0: 0.069076, l1: 0.070828, l2: 0.063234, l3: 0.061848, l4: 0.071424, l5: 0.079302, l6: 0.073984

[epoch:  13/100000, batch:    60/  187, ite: 1158] train loss: 0.944664, tar: 0.144850 
l0: 0.071396, l1: 0.072291, l2: 0.073137, l3: 0.070496, l4: 0.078894, l5: 0.075587, l6: 0.075841

[epoch:  13/100000, batch:    62/  187, ite: 1159] train loss: 0.944296, tar: 0.144787 
l0: 0.080769, l1: 0.083001, l2: 0.080241, l3: 0.074303, l4: 0.086535, l5: 0.085160, l6: 0.084517

[epoch:  13/100000, batch:    64/  187, ite: 1160] train loss: 0.943977, tar: 0.144732 
l0: 0.090321, l1: 0.084144, l2: 0.083276, l3: 0.087929, l4: 0.109666, l5: 0.101567, l6: 0.095853

[epoch:  13/100000, batch:    66/  187, ite: 1161] train loss: 0.943726, tar: 0.144685 
l0: 0.079144, l1: 0.081683, l2: 0.086065, l3: 0.076041, l4: 0.074526, l5: 0.082828, l6: 0.086144

[epoch:  13/100000, batch:    68/  187, ite: 1162] train loss: 0.943401, tar: 0.144628 
l0: 0.078904, l1: 0.088332, l2: 0.087056, l3: 0.090949, l4: 0.077022, l5: 0.078298, l6: 0.081361

[epoch:  13/100000, batch:    70/  187, ite: 1163] train loss: 0.943091, tar: 0.144572 
l0: 0.094526, l1: 0.095992, l2: 0.101580, l3: 0.098807, l4: 0.097287, l5: 0.100921, l6: 0.099022

[epoch:  13/100000, batch:    72/  187, ite: 1164] train loss: 0.942872, tar: 0.144529 
l0: 0.100008, l1: 0.088900, l2: 0.092758, l3: 0.095025, l4: 0.123725, l5: 0.116889, l6: 0.109396

[epoch:  13/100000, batch:    74/  187, ite: 1165] train loss: 0.942686, tar: 0.144491 
l0: 0.142311, l1: 0.139099, l2: 0.150326, l3: 0.137696, l4: 0.167387, l5: 0.165640, l6: 0.162773

[epoch:  13/100000, batch:    76/  187, ite: 1166] train loss: 0.942791, tar: 0.144489 
l0: 0.117340, l1: 0.116639, l2: 0.116051, l3: 0.114040, l4: 0.120932, l5: 0.121761, l6: 0.109949

[epoch:  13/100000, batch:    78/  187, ite: 1167] train loss: 0.942683, tar: 0.144465 
l0: 0.075313, l1: 0.066663, l2: 0.081132, l3: 0.088979, l4: 0.083235, l5: 0.092337, l6: 0.087334

[epoch:  13/100000, batch:    80/  187, ite: 1168] train loss: 0.942368, tar: 0.144406 
l0: 0.089087, l1: 0.081477, l2: 0.083927, l3: 0.091368, l4: 0.088671, l5: 0.098589, l6: 0.091921

[epoch:  13/100000, batch:    82/  187, ite: 1169] train loss: 0.942097, tar: 0.144359 
l0: 0.111627, l1: 0.116746, l2: 0.110327, l3: 0.111689, l4: 0.110833, l5: 0.113682, l6: 0.119887

[epoch:  13/100000, batch:    84/  187, ite: 1170] train loss: 0.941971, tar: 0.144331 
l0: 0.080408, l1: 0.079607, l2: 0.089240, l3: 0.086816, l4: 0.098635, l5: 0.097335, l6: 0.093181

[epoch:  13/100000, batch:    86/  187, ite: 1171] train loss: 0.941700, tar: 0.144276 
l0: 0.061993, l1: 0.070204, l2: 0.074467, l3: 0.081132, l4: 0.082829, l5: 0.079614, l6: 0.059821

[epoch:  13/100000, batch:    88/  187, ite: 1172] train loss: 0.941332, tar: 0.144206 
l0: 0.098299, l1: 0.095869, l2: 0.090729, l3: 0.091732, l4: 0.094169, l5: 0.102414, l6: 0.092956

[epoch:  13/100000, batch:    90/  187, ite: 1173] train loss: 0.941098, tar: 0.144167 
l0: 0.098058, l1: 0.108369, l2: 0.098857, l3: 0.094828, l4: 0.116091, l5: 0.105797, l6: 0.097258

[epoch:  13/100000, batch:    92/  187, ite: 1174] train loss: 0.940909, tar: 0.144128 
l0: 0.076231, l1: 0.078478, l2: 0.080327, l3: 0.088983, l4: 0.077323, l5: 0.084070, l6: 0.069819

[epoch:  13/100000, batch:    94/  187, ite: 1175] train loss: 0.940580, tar: 0.144070 
l0: 0.082990, l1: 0.086541, l2: 0.085790, l3: 0.080939, l4: 0.094554, l5: 0.092529, l6: 0.095713

[epoch:  13/100000, batch:    96/  187, ite: 1176] train loss: 0.940307, tar: 0.144018 
l0: 0.086157, l1: 0.091718, l2: 0.102358, l3: 0.099270, l4: 0.092268, l5: 0.085584, l6: 0.084036

[epoch:  13/100000, batch:    98/  187, ite: 1177] train loss: 0.940053, tar: 0.143969 
l0: 0.105453, l1: 0.101845, l2: 0.119565, l3: 0.119833, l4: 0.106762, l5: 0.107804, l6: 0.101129

[epoch:  13/100000, batch:   100/  187, ite: 1178] train loss: 0.939902, tar: 0.143936 
l0: 0.097034, l1: 0.109804, l2: 0.106454, l3: 0.098022, l4: 0.111450, l5: 0.107972, l6: 0.095918

[epoch:  13/100000, batch:   102/  187, ite: 1179] train loss: 0.939721, tar: 0.143896 
l0: 0.045915, l1: 0.048312, l2: 0.044621, l3: 0.042855, l4: 0.050123, l5: 0.054431, l6: 0.047816

[epoch:  13/100000, batch:   104/  187, ite: 1180] train loss: 0.939208, tar: 0.143813 
l0: 0.119242, l1: 0.124029, l2: 0.113422, l3: 0.118616, l4: 0.186446, l5: 0.145441, l6: 0.154012

[epoch:  13/100000, batch:   106/  187, ite: 1181] train loss: 0.939227, tar: 0.143793 
l0: 0.120540, l1: 0.144949, l2: 0.139928, l3: 0.132058, l4: 0.140297, l5: 0.114754, l6: 0.123661

[epoch:  13/100000, batch:   108/  187, ite: 1182] train loss: 0.939207, tar: 0.143773 
l0: 0.106003, l1: 0.112039, l2: 0.120055, l3: 0.116341, l4: 0.091872, l5: 0.093434, l6: 0.091426

[epoch:  13/100000, batch:   110/  187, ite: 1183] train loss: 0.939031, tar: 0.143741 
l0: 0.087053, l1: 0.096709, l2: 0.095954, l3: 0.095180, l4: 0.097962, l5: 0.084569, l6: 0.088730

[epoch:  13/100000, batch:   112/  187, ite: 1184] train loss: 0.938784, tar: 0.143693 
l0: 0.059654, l1: 0.063497, l2: 0.061925, l3: 0.067349, l4: 0.061319, l5: 0.068291, l6: 0.065722

[epoch:  13/100000, batch:   114/  187, ite: 1185] train loss: 0.938370, tar: 0.143622 
l0: 0.044959, l1: 0.046330, l2: 0.045359, l3: 0.042578, l4: 0.052371, l5: 0.055450, l6: 0.046804

[epoch:  13/100000, batch:   116/  187, ite: 1186] train loss: 0.937860, tar: 0.143539 
l0: 0.155858, l1: 0.146126, l2: 0.144700, l3: 0.140998, l4: 0.166770, l5: 0.181786, l6: 0.212962

[epoch:  13/100000, batch:   118/  187, ite: 1187] train loss: 0.938038, tar: 0.143549 
l0: 0.125964, l1: 0.135833, l2: 0.142942, l3: 0.142943, l4: 0.136052, l5: 0.123952, l6: 0.122937

[epoch:  13/100000, batch:   120/  187, ite: 1188] train loss: 0.938032, tar: 0.143535 
l0: 0.080923, l1: 0.084054, l2: 0.077398, l3: 0.080561, l4: 0.086188, l5: 0.092024, l6: 0.088731

[epoch:  13/100000, batch:   122/  187, ite: 1189] train loss: 0.937739, tar: 0.143482 
l0: 0.070725, l1: 0.080576, l2: 0.078510, l3: 0.085619, l4: 0.084529, l5: 0.091501, l6: 0.068778

[epoch:  13/100000, batch:   124/  187, ite: 1190] train loss: 0.937422, tar: 0.143421 
l0: 0.146516, l1: 0.129512, l2: 0.128837, l3: 0.132777, l4: 0.150610, l5: 0.180619, l6: 0.201223

[epoch:  13/100000, batch:   126/  187, ite: 1191] train loss: 0.937533, tar: 0.143423 
l0: 0.121927, l1: 0.129780, l2: 0.133774, l3: 0.135100, l4: 0.132519, l5: 0.133656, l6: 0.124680

[epoch:  13/100000, batch:   128/  187, ite: 1192] train loss: 0.937511, tar: 0.143405 
l0: 0.083332, l1: 0.077005, l2: 0.095050, l3: 0.097751, l4: 0.119479, l5: 0.116744, l6: 0.111275

[epoch:  13/100000, batch:   130/  187, ite: 1193] train loss: 0.937313, tar: 0.143355 
l0: 0.091991, l1: 0.092693, l2: 0.101226, l3: 0.102699, l4: 0.107546, l5: 0.101183, l6: 0.088684

[epoch:  13/100000, batch:   132/  187, ite: 1194] train loss: 0.937102, tar: 0.143312 
l0: 0.089063, l1: 0.094180, l2: 0.091701, l3: 0.098813, l4: 0.105616, l5: 0.086153, l6: 0.106747

[epoch:  13/100000, batch:   134/  187, ite: 1195] train loss: 0.936880, tar: 0.143267 
l0: 0.113326, l1: 0.102765, l2: 0.115529, l3: 0.128138, l4: 0.133043, l5: 0.128798, l6: 0.118753

[epoch:  13/100000, batch:   136/  187, ite: 1196] train loss: 0.936800, tar: 0.143241 
l0: 0.111121, l1: 0.110354, l2: 0.114875, l3: 0.114097, l4: 0.119209, l5: 0.126987, l6: 0.118084

[epoch:  13/100000, batch:   138/  187, ite: 1197] train loss: 0.936698, tar: 0.143215 
l0: 0.121986, l1: 0.110200, l2: 0.120465, l3: 0.120245, l4: 0.128440, l5: 0.130262, l6: 0.120273

[epoch:  13/100000, batch:   140/  187, ite: 1198] train loss: 0.936627, tar: 0.143197 
l0: 0.105848, l1: 0.122810, l2: 0.116562, l3: 0.115258, l4: 0.103104, l5: 0.098603, l6: 0.113694

[epoch:  13/100000, batch:   142/  187, ite: 1199] train loss: 0.936493, tar: 0.143166 
l0: 0.083003, l1: 0.082746, l2: 0.086824, l3: 0.097651, l4: 0.109677, l5: 0.091548, l6: 0.116526

[epoch:  13/100000, batch:   144/  187, ite: 1200] train loss: 0.936269, tar: 0.143116 
l0: 0.088803, l1: 0.094536, l2: 0.091950, l3: 0.099252, l4: 0.081276, l5: 0.082526, l6: 0.077415

[epoch:  13/100000, batch:   146/  187, ite: 1201] train loss: 0.936002, tar: 0.143070 
l0: 0.096306, l1: 0.094314, l2: 0.107093, l3: 0.114534, l4: 0.102790, l5: 0.091323, l6: 0.105028

[epoch:  13/100000, batch:   148/  187, ite: 1202] train loss: 0.935815, tar: 0.143032 
l0: 0.100768, l1: 0.097660, l2: 0.097326, l3: 0.101384, l4: 0.118571, l5: 0.098798, l6: 0.126977

[epoch:  13/100000, batch:   150/  187, ite: 1203] train loss: 0.935654, tar: 0.142996 
l0: 0.079055, l1: 0.079515, l2: 0.079545, l3: 0.079378, l4: 0.079031, l5: 0.090297, l6: 0.085905

[epoch:  13/100000, batch:   152/  187, ite: 1204] train loss: 0.935352, tar: 0.142943 
l0: 0.074221, l1: 0.073476, l2: 0.077328, l3: 0.074869, l4: 0.079878, l5: 0.072289, l6: 0.081949

[epoch:  13/100000, batch:   154/  187, ite: 1205] train loss: 0.935019, tar: 0.142886 
l0: 0.098288, l1: 0.103455, l2: 0.104091, l3: 0.100072, l4: 0.108087, l5: 0.096255, l6: 0.090919

[epoch:  13/100000, batch:   156/  187, ite: 1206] train loss: 0.934825, tar: 0.142849 
l0: 0.070825, l1: 0.076514, l2: 0.062406, l3: 0.067801, l4: 0.066870, l5: 0.079794, l6: 0.069370

[epoch:  13/100000, batch:   158/  187, ite: 1207] train loss: 0.934460, tar: 0.142790 
l0: 0.102299, l1: 0.116555, l2: 0.109809, l3: 0.112212, l4: 0.095951, l5: 0.099177, l6: 0.107621

[epoch:  13/100000, batch:   160/  187, ite: 1208] train loss: 0.934302, tar: 0.142756 
l0: 0.093062, l1: 0.089939, l2: 0.108599, l3: 0.103755, l4: 0.110457, l5: 0.097731, l6: 0.097912

[epoch:  13/100000, batch:   162/  187, ite: 1209] train loss: 0.934109, tar: 0.142715 
l0: 0.075200, l1: 0.072917, l2: 0.075867, l3: 0.075300, l4: 0.085647, l5: 0.082483, l6: 0.082752

[epoch:  13/100000, batch:   164/  187, ite: 1210] train loss: 0.933792, tar: 0.142659 
l0: 0.127593, l1: 0.115632, l2: 0.139675, l3: 0.137270, l4: 0.126176, l5: 0.143759, l6: 0.146572

[epoch:  13/100000, batch:   166/  187, ite: 1211] train loss: 0.933794, tar: 0.142647 
l0: 0.099089, l1: 0.093950, l2: 0.106741, l3: 0.112387, l4: 0.098485, l5: 0.096299, l6: 0.114889

[epoch:  13/100000, batch:   168/  187, ite: 1212] train loss: 0.933620, tar: 0.142611 
l0: 0.106691, l1: 0.095187, l2: 0.098853, l3: 0.103901, l4: 0.106100, l5: 0.116365, l6: 0.119758

[epoch:  13/100000, batch:   170/  187, ite: 1213] train loss: 0.933466, tar: 0.142581 
l0: 0.127157, l1: 0.124734, l2: 0.132895, l3: 0.129430, l4: 0.129883, l5: 0.130784, l6: 0.141756

[epoch:  13/100000, batch:   172/  187, ite: 1214] train loss: 0.933452, tar: 0.142568 
l0: 0.127869, l1: 0.115077, l2: 0.139606, l3: 0.140099, l4: 0.143592, l5: 0.155346, l6: 0.140281

[epoch:  13/100000, batch:   174/  187, ite: 1215] train loss: 0.933475, tar: 0.142556 
l0: 0.109876, l1: 0.105648, l2: 0.107101, l3: 0.117990, l4: 0.127554, l5: 0.116223, l6: 0.108434

[epoch:  13/100000, batch:   176/  187, ite: 1216] train loss: 0.933359, tar: 0.142530 
l0: 0.085459, l1: 0.087576, l2: 0.094947, l3: 0.095575, l4: 0.108811, l5: 0.092854, l6: 0.107140

[epoch:  13/100000, batch:   178/  187, ite: 1217] train loss: 0.933145, tar: 0.142483 
l0: 0.076179, l1: 0.082211, l2: 0.091541, l3: 0.085653, l4: 0.094091, l5: 0.073119, l6: 0.077358

[epoch:  13/100000, batch:   180/  187, ite: 1218] train loss: 0.932855, tar: 0.142428 
l0: 0.063529, l1: 0.065403, l2: 0.072225, l3: 0.065870, l4: 0.084628, l5: 0.077127, l6: 0.075629

[epoch:  13/100000, batch:   182/  187, ite: 1219] train loss: 0.932504, tar: 0.142363 
l0: 0.109724, l1: 0.105181, l2: 0.111633, l3: 0.128292, l4: 0.107958, l5: 0.126283, l6: 0.127179

[epoch:  13/100000, batch:   184/  187, ite: 1220] train loss: 0.932408, tar: 0.142337 
l0: 0.141796, l1: 0.152527, l2: 0.145141, l3: 0.146494, l4: 0.124983, l5: 0.133638, l6: 0.134800

[epoch:  13/100000, batch:   186/  187, ite: 1221] train loss: 0.932447, tar: 0.142336 
l0: 0.088200, l1: 0.075829, l2: 0.082014, l3: 0.081903, l4: 0.107252, l5: 0.114284, l6: 0.108984

[epoch:  13/100000, batch:   188/  187, ite: 1222] train loss: 0.932223, tar: 0.142292 
l0: 0.105879, l1: 0.109642, l2: 0.116865, l3: 0.141864, l4: 0.096170, l5: 0.116476, l6: 0.115419

[epoch:  14/100000, batch:     2/  187, ite: 1223] train loss: 0.932116, tar: 0.142262 
l0: 0.100933, l1: 0.102871, l2: 0.103344, l3: 0.122666, l4: 0.104150, l5: 0.109673, l6: 0.109443

[epoch:  14/100000, batch:     4/  187, ite: 1224] train loss: 0.931970, tar: 0.142228 
l0: 0.068683, l1: 0.082337, l2: 0.077055, l3: 0.084839, l4: 0.056152, l5: 0.064918, l6: 0.057086

[epoch:  14/100000, batch:     6/  187, ite: 1225] train loss: 0.931610, tar: 0.142168 
l0: 0.089418, l1: 0.087832, l2: 0.094567, l3: 0.099649, l4: 0.100108, l5: 0.105252, l6: 0.093510

[epoch:  14/100000, batch:     8/  187, ite: 1226] train loss: 0.931397, tar: 0.142125 
l0: 0.108505, l1: 0.108033, l2: 0.091787, l3: 0.086114, l4: 0.127546, l5: 0.134876, l6: 0.129232

[epoch:  14/100000, batch:    10/  187, ite: 1227] train loss: 0.931279, tar: 0.142098 
l0: 0.067809, l1: 0.065374, l2: 0.077302, l3: 0.075790, l4: 0.071294, l5: 0.068083, l6: 0.075671

[epoch:  14/100000, batch:    12/  187, ite: 1228] train loss: 0.930929, tar: 0.142037 
l0: 0.073859, l1: 0.074604, l2: 0.069551, l3: 0.068699, l4: 0.082121, l5: 0.091287, l6: 0.095062

[epoch:  14/100000, batch:    14/  187, ite: 1229] train loss: 0.930623, tar: 0.141982 
l0: 0.111229, l1: 0.129459, l2: 0.121908, l3: 0.111290, l4: 0.110190, l5: 0.106096, l6: 0.096417

[epoch:  14/100000, batch:    16/  187, ite: 1230] train loss: 0.930506, tar: 0.141957 
l0: 0.067030, l1: 0.061851, l2: 0.064930, l3: 0.071426, l4: 0.072255, l5: 0.076251, l6: 0.084456

[epoch:  14/100000, batch:    18/  187, ite: 1231] train loss: 0.930155, tar: 0.141896 
l0: 0.165941, l1: 0.183239, l2: 0.189796, l3: 0.178011, l4: 0.160111, l5: 0.151468, l6: 0.176153

[epoch:  14/100000, batch:    20/  187, ite: 1232] train loss: 0.930377, tar: 0.141916 
l0: 0.062346, l1: 0.074079, l2: 0.061645, l3: 0.058406, l4: 0.066712, l5: 0.068373, l6: 0.065748

[epoch:  14/100000, batch:    22/  187, ite: 1233] train loss: 0.929994, tar: 0.141851 
l0: 0.074812, l1: 0.066700, l2: 0.072230, l3: 0.078040, l4: 0.079820, l5: 0.084628, l6: 0.081550

[epoch:  14/100000, batch:    24/  187, ite: 1234] train loss: 0.929676, tar: 0.141797 
l0: 0.118767, l1: 0.098920, l2: 0.114184, l3: 0.120582, l4: 0.114360, l5: 0.138979, l6: 0.157825

[epoch:  14/100000, batch:    26/  187, ite: 1235] train loss: 0.929622, tar: 0.141778 
l0: 0.062544, l1: 0.070766, l2: 0.074200, l3: 0.060419, l4: 0.081790, l5: 0.074175, l6: 0.062536

[epoch:  14/100000, batch:    28/  187, ite: 1236] train loss: 0.929264, tar: 0.141714 
l0: 0.099151, l1: 0.110297, l2: 0.102296, l3: 0.106085, l4: 0.126142, l5: 0.114982, l6: 0.111667

[epoch:  14/100000, batch:    30/  187, ite: 1237] train loss: 0.929136, tar: 0.141680 
l0: 0.084584, l1: 0.095534, l2: 0.094267, l3: 0.106247, l4: 0.117019, l5: 0.103673, l6: 0.081967

[epoch:  14/100000, batch:    32/  187, ite: 1238] train loss: 0.928937, tar: 0.141633 
l0: 0.070304, l1: 0.065491, l2: 0.079453, l3: 0.077117, l4: 0.075278, l5: 0.075965, l6: 0.081068

[epoch:  14/100000, batch:    34/  187, ite: 1239] train loss: 0.928611, tar: 0.141576 
l0: 0.086470, l1: 0.085700, l2: 0.082245, l3: 0.085876, l4: 0.093732, l5: 0.097123, l6: 0.092284

[epoch:  14/100000, batch:    36/  187, ite: 1240] train loss: 0.928365, tar: 0.141531 
l0: 0.071205, l1: 0.071862, l2: 0.071235, l3: 0.072236, l4: 0.073109, l5: 0.070877, l6: 0.074349

[epoch:  14/100000, batch:    38/  187, ite: 1241] train loss: 0.928023, tar: 0.141475 
l0: 0.073016, l1: 0.069394, l2: 0.081431, l3: 0.069573, l4: 0.078613, l5: 0.080021, l6: 0.080639

[epoch:  14/100000, batch:    40/  187, ite: 1242] train loss: 0.927705, tar: 0.141420 
l0: 0.057686, l1: 0.065540, l2: 0.065165, l3: 0.059096, l4: 0.062163, l5: 0.072159, l6: 0.055525

[epoch:  14/100000, batch:    42/  187, ite: 1243] train loss: 0.927311, tar: 0.141352 
l0: 0.122520, l1: 0.111724, l2: 0.118425, l3: 0.143063, l4: 0.132323, l5: 0.133316, l6: 0.125343

[epoch:  14/100000, batch:    44/  187, ite: 1244] train loss: 0.927278, tar: 0.141337 
l0: 0.106860, l1: 0.113354, l2: 0.129066, l3: 0.105013, l4: 0.110421, l5: 0.106618, l6: 0.120796

[epoch:  14/100000, batch:    46/  187, ite: 1245] train loss: 0.927169, tar: 0.141310 
l0: 0.078909, l1: 0.075703, l2: 0.084749, l3: 0.090318, l4: 0.079781, l5: 0.078092, l6: 0.073152

[epoch:  14/100000, batch:    48/  187, ite: 1246] train loss: 0.926875, tar: 0.141259 
l0: 0.068825, l1: 0.067132, l2: 0.069758, l3: 0.072155, l4: 0.084849, l5: 0.072943, l6: 0.070574

[epoch:  14/100000, batch:    50/  187, ite: 1247] train loss: 0.926538, tar: 0.141201 
l0: 0.106890, l1: 0.099778, l2: 0.105272, l3: 0.108663, l4: 0.122745, l5: 0.116413, l6: 0.123743

[epoch:  14/100000, batch:    52/  187, ite: 1248] train loss: 0.926423, tar: 0.141174 
l0: 0.096601, l1: 0.101682, l2: 0.104053, l3: 0.098096, l4: 0.096118, l5: 0.084599, l6: 0.084484

[epoch:  14/100000, batch:    54/  187, ite: 1249] train loss: 0.926215, tar: 0.141138 
l0: 0.125171, l1: 0.116950, l2: 0.137715, l3: 0.132985, l4: 0.136927, l5: 0.161427, l6: 0.134353

[epoch:  14/100000, batch:    56/  187, ite: 1250] train loss: 0.926230, tar: 0.141125 
l0: 0.073952, l1: 0.068668, l2: 0.078396, l3: 0.088272, l4: 0.073008, l5: 0.074293, l6: 0.082593

[epoch:  14/100000, batch:    58/  187, ite: 1251] train loss: 0.925921, tar: 0.141072 
l0: 0.117994, l1: 0.118890, l2: 0.118224, l3: 0.101205, l4: 0.128692, l5: 0.133027, l6: 0.129504

[epoch:  14/100000, batch:    60/  187, ite: 1252] train loss: 0.925858, tar: 0.141053 
l0: 0.116235, l1: 0.115599, l2: 0.108255, l3: 0.099497, l4: 0.122895, l5: 0.143472, l6: 0.108042

[epoch:  14/100000, batch:    62/  187, ite: 1253] train loss: 0.925769, tar: 0.141033 
l0: 0.096227, l1: 0.089603, l2: 0.095151, l3: 0.089126, l4: 0.115964, l5: 0.122929, l6: 0.121842

[epoch:  14/100000, batch:    64/  187, ite: 1254] train loss: 0.925613, tar: 0.140998 
l0: 0.084404, l1: 0.077837, l2: 0.091581, l3: 0.102267, l4: 0.100498, l5: 0.095033, l6: 0.090100

[epoch:  14/100000, batch:    66/  187, ite: 1255] train loss: 0.925387, tar: 0.140953 
l0: 0.098690, l1: 0.095038, l2: 0.099962, l3: 0.101480, l4: 0.110410, l5: 0.105562, l6: 0.117347

[epoch:  14/100000, batch:    68/  187, ite: 1256] train loss: 0.925230, tar: 0.140919 
l0: 0.072313, l1: 0.074994, l2: 0.079270, l3: 0.081942, l4: 0.093726, l5: 0.095883, l6: 0.081948

[epoch:  14/100000, batch:    70/  187, ite: 1257] train loss: 0.924956, tar: 0.140864 
l0: 0.098974, l1: 0.105999, l2: 0.103013, l3: 0.091636, l4: 0.115832, l5: 0.123466, l6: 0.126698

[epoch:  14/100000, batch:    72/  187, ite: 1258] train loss: 0.924829, tar: 0.140831 
l0: 0.084997, l1: 0.096524, l2: 0.087077, l3: 0.090711, l4: 0.108824, l5: 0.101211, l6: 0.086947

[epoch:  14/100000, batch:    74/  187, ite: 1259] train loss: 0.924616, tar: 0.140787 
l0: 0.087062, l1: 0.090953, l2: 0.109414, l3: 0.113625, l4: 0.116064, l5: 0.103127, l6: 0.099319

[epoch:  14/100000, batch:    76/  187, ite: 1260] train loss: 0.924453, tar: 0.140744 
l0: 0.070047, l1: 0.064004, l2: 0.077928, l3: 0.081351, l4: 0.084525, l5: 0.080223, l6: 0.072157

[epoch:  14/100000, batch:    78/  187, ite: 1261] train loss: 0.924140, tar: 0.140688 
l0: 0.081446, l1: 0.089121, l2: 0.095538, l3: 0.096834, l4: 0.116728, l5: 0.086405, l6: 0.074013

[epoch:  14/100000, batch:    80/  187, ite: 1262] train loss: 0.923915, tar: 0.140641 
l0: 0.138503, l1: 0.165639, l2: 0.142499, l3: 0.147620, l4: 0.129503, l5: 0.128557, l6: 0.124190

[epoch:  14/100000, batch:    82/  187, ite: 1263] train loss: 0.923957, tar: 0.140639 
l0: 0.094927, l1: 0.098982, l2: 0.099253, l3: 0.095878, l4: 0.117076, l5: 0.110233, l6: 0.103279

[epoch:  14/100000, batch:    84/  187, ite: 1264] train loss: 0.923795, tar: 0.140603 
l0: 0.063914, l1: 0.066346, l2: 0.064990, l3: 0.065962, l4: 0.073841, l5: 0.074869, l6: 0.067924

[epoch:  14/100000, batch:    86/  187, ite: 1265] train loss: 0.923443, tar: 0.140543 
l0: 0.083335, l1: 0.096503, l2: 0.091028, l3: 0.089742, l4: 0.072510, l5: 0.076801, l6: 0.082520

[epoch:  14/100000, batch:    88/  187, ite: 1266] train loss: 0.923181, tar: 0.140497 
l0: 0.123727, l1: 0.119152, l2: 0.141288, l3: 0.125873, l4: 0.170134, l5: 0.173679, l6: 0.179311

[epoch:  14/100000, batch:    90/  187, ite: 1267] train loss: 0.923268, tar: 0.140484 
l0: 0.079772, l1: 0.078323, l2: 0.095186, l3: 0.087677, l4: 0.100135, l5: 0.100147, l6: 0.099677

[epoch:  14/100000, batch:    92/  187, ite: 1268] train loss: 0.923045, tar: 0.140436 
l0: 0.115917, l1: 0.108647, l2: 0.114673, l3: 0.112850, l4: 0.130158, l5: 0.125619, l6: 0.124303

[epoch:  14/100000, batch:    94/  187, ite: 1269] train loss: 0.922974, tar: 0.140417 
l0: 0.087570, l1: 0.082597, l2: 0.084864, l3: 0.089561, l4: 0.099299, l5: 0.108496, l6: 0.114021

[epoch:  14/100000, batch:    96/  187, ite: 1270] train loss: 0.922772, tar: 0.140375 
l0: 0.064672, l1: 0.066469, l2: 0.057256, l3: 0.060122, l4: 0.070148, l5: 0.066698, l6: 0.079247

[epoch:  14/100000, batch:    98/  187, ite: 1271] train loss: 0.922411, tar: 0.140316 
l0: 0.156038, l1: 0.162846, l2: 0.149666, l3: 0.161359, l4: 0.147653, l5: 0.162762, l6: 0.177821

[epoch:  14/100000, batch:   100/  187, ite: 1272] train loss: 0.922565, tar: 0.140328 
l0: 0.070385, l1: 0.072541, l2: 0.074703, l3: 0.076100, l4: 0.079864, l5: 0.078900, l6: 0.090443

[epoch:  14/100000, batch:   102/  187, ite: 1273] train loss: 0.922267, tar: 0.140273 
l0: 0.117730, l1: 0.112434, l2: 0.131730, l3: 0.137603, l4: 0.141314, l5: 0.118530, l6: 0.110788

[epoch:  14/100000, batch:   104/  187, ite: 1274] train loss: 0.922226, tar: 0.140256 
l0: 0.138477, l1: 0.138272, l2: 0.139761, l3: 0.147519, l4: 0.157452, l5: 0.137446, l6: 0.126386

[epoch:  14/100000, batch:   106/  187, ite: 1275] train loss: 0.922276, tar: 0.140254 
l0: 0.095368, l1: 0.097991, l2: 0.095745, l3: 0.094340, l4: 0.099066, l5: 0.100516, l6: 0.109079

[epoch:  14/100000, batch:   108/  187, ite: 1276] train loss: 0.922095, tar: 0.140219 
l0: 0.082442, l1: 0.086904, l2: 0.083782, l3: 0.075170, l4: 0.081810, l5: 0.088695, l6: 0.092037

[epoch:  14/100000, batch:   110/  187, ite: 1277] train loss: 0.921836, tar: 0.140174 
l0: 0.152795, l1: 0.133657, l2: 0.151086, l3: 0.146244, l4: 0.236216, l5: 0.222097, l6: 0.223704

[epoch:  14/100000, batch:   112/  187, ite: 1278] train loss: 0.922105, tar: 0.140184 
l0: 0.126317, l1: 0.143225, l2: 0.142166, l3: 0.148891, l4: 0.104511, l5: 0.115490, l6: 0.113494

[epoch:  14/100000, batch:   114/  187, ite: 1279] train loss: 0.922083, tar: 0.140173 
l0: 0.071018, l1: 0.069628, l2: 0.087683, l3: 0.084809, l4: 0.079383, l5: 0.083342, l6: 0.081119

[epoch:  14/100000, batch:   116/  187, ite: 1280] train loss: 0.921798, tar: 0.140119 
l0: 0.102818, l1: 0.093066, l2: 0.110565, l3: 0.114473, l4: 0.117741, l5: 0.124126, l6: 0.130506

[epoch:  14/100000, batch:   118/  187, ite: 1281] train loss: 0.921697, tar: 0.140090 
l0: 0.147961, l1: 0.154559, l2: 0.164510, l3: 0.180229, l4: 0.154972, l5: 0.136271, l6: 0.144812

[epoch:  14/100000, batch:   120/  187, ite: 1282] train loss: 0.921824, tar: 0.140096 
l0: 0.075210, l1: 0.061781, l2: 0.074071, l3: 0.075164, l4: 0.094969, l5: 0.098416, l6: 0.093756

[epoch:  14/100000, batch:   122/  187, ite: 1283] train loss: 0.921552, tar: 0.140045 
l0: 0.067871, l1: 0.089931, l2: 0.070905, l3: 0.070732, l4: 0.071029, l5: 0.069428, l6: 0.059351

[epoch:  14/100000, batch:   124/  187, ite: 1284] train loss: 0.921223, tar: 0.139989 
l0: 0.107370, l1: 0.102422, l2: 0.121955, l3: 0.130184, l4: 0.113148, l5: 0.106655, l6: 0.114135

[epoch:  14/100000, batch:   126/  187, ite: 1285] train loss: 0.921125, tar: 0.139964 
l0: 0.089413, l1: 0.090513, l2: 0.089103, l3: 0.098352, l4: 0.086907, l5: 0.093903, l6: 0.087373

[epoch:  14/100000, batch:   128/  187, ite: 1286] train loss: 0.920903, tar: 0.139924 
l0: 0.157408, l1: 0.176538, l2: 0.174871, l3: 0.177036, l4: 0.164500, l5: 0.159708, l6: 0.159657

[epoch:  14/100000, batch:   130/  187, ite: 1287] train loss: 0.921097, tar: 0.139938 
l0: 0.103649, l1: 0.103529, l2: 0.102459, l3: 0.107345, l4: 0.102982, l5: 0.113249, l6: 0.117598

[epoch:  14/100000, batch:   132/  187, ite: 1288] train loss: 0.920965, tar: 0.139910 
l0: 0.097115, l1: 0.111143, l2: 0.088075, l3: 0.084363, l4: 0.094287, l5: 0.090621, l6: 0.095704

[epoch:  14/100000, batch:   134/  187, ite: 1289] train loss: 0.920763, tar: 0.139876 
l0: 0.146013, l1: 0.156730, l2: 0.168477, l3: 0.145349, l4: 0.162610, l5: 0.157128, l6: 0.156734

[epoch:  14/100000, batch:   136/  187, ite: 1290] train loss: 0.920897, tar: 0.139881 
l0: 0.098817, l1: 0.099922, l2: 0.104842, l3: 0.105832, l4: 0.094750, l5: 0.091935, l6: 0.103849

[epoch:  14/100000, batch:   138/  187, ite: 1291] train loss: 0.920726, tar: 0.139849 
l0: 0.055214, l1: 0.073354, l2: 0.054523, l3: 0.059475, l4: 0.061313, l5: 0.047856, l6: 0.043393

[epoch:  14/100000, batch:   140/  187, ite: 1292] train loss: 0.920319, tar: 0.139784 
l0: 0.080915, l1: 0.094550, l2: 0.082582, l3: 0.090491, l4: 0.089095, l5: 0.076544, l6: 0.079522

[epoch:  14/100000, batch:   142/  187, ite: 1293] train loss: 0.920066, tar: 0.139738 
l0: 0.087693, l1: 0.107259, l2: 0.088778, l3: 0.122643, l4: 0.065583, l5: 0.068716, l6: 0.059025

[epoch:  14/100000, batch:   144/  187, ite: 1294] train loss: 0.919819, tar: 0.139698 
l0: 0.089302, l1: 0.086472, l2: 0.087721, l3: 0.102850, l4: 0.101560, l5: 0.108038, l6: 0.103622

[epoch:  14/100000, batch:   146/  187, ite: 1295] train loss: 0.919633, tar: 0.139659 
l0: 0.098905, l1: 0.083140, l2: 0.111491, l3: 0.114162, l4: 0.112407, l5: 0.118141, l6: 0.113578

[epoch:  14/100000, batch:   148/  187, ite: 1296] train loss: 0.919503, tar: 0.139628 
l0: 0.087811, l1: 0.092523, l2: 0.090029, l3: 0.091746, l4: 0.079755, l5: 0.082478, l6: 0.074059

[epoch:  14/100000, batch:   150/  187, ite: 1297] train loss: 0.919256, tar: 0.139588 
l0: 0.093143, l1: 0.093401, l2: 0.098702, l3: 0.097796, l4: 0.090975, l5: 0.086745, l6: 0.085274

[epoch:  14/100000, batch:   152/  187, ite: 1298] train loss: 0.919045, tar: 0.139552 
l0: 0.094838, l1: 0.102273, l2: 0.099089, l3: 0.108864, l4: 0.105403, l5: 0.101828, l6: 0.089591

[epoch:  14/100000, batch:   154/  187, ite: 1299] train loss: 0.918878, tar: 0.139518 
l0: 0.083848, l1: 0.078865, l2: 0.082609, l3: 0.082829, l4: 0.092888, l5: 0.108312, l6: 0.092116

[epoch:  14/100000, batch:   156/  187, ite: 1300] train loss: 0.918649, tar: 0.139475 
l0: 0.159412, l1: 0.159431, l2: 0.140209, l3: 0.144604, l4: 0.198059, l5: 0.207674, l6: 0.182324

[epoch:  14/100000, batch:   158/  187, ite: 1301] train loss: 0.918859, tar: 0.139490 
l0: 0.112019, l1: 0.105109, l2: 0.111500, l3: 0.116702, l4: 0.140416, l5: 0.142421, l6: 0.128585

[epoch:  14/100000, batch:   160/  187, ite: 1302] train loss: 0.918812, tar: 0.139469 
l0: 0.119928, l1: 0.113290, l2: 0.108455, l3: 0.114151, l4: 0.121404, l5: 0.131294, l6: 0.128943

[epoch:  14/100000, batch:   162/  187, ite: 1303] train loss: 0.918749, tar: 0.139454 
l0: 0.115266, l1: 0.140825, l2: 0.147488, l3: 0.098734, l4: 0.120451, l5: 0.120735, l6: 0.121967

[epoch:  14/100000, batch:   164/  187, ite: 1304] train loss: 0.918708, tar: 0.139436 
l0: 0.110781, l1: 0.111925, l2: 0.116205, l3: 0.119827, l4: 0.129490, l5: 0.114730, l6: 0.123716

[epoch:  14/100000, batch:   166/  187, ite: 1305] train loss: 0.918638, tar: 0.139414 
l0: 0.075710, l1: 0.069183, l2: 0.077939, l3: 0.082961, l4: 0.083555, l5: 0.078351, l6: 0.085443

[epoch:  14/100000, batch:   168/  187, ite: 1306] train loss: 0.918358, tar: 0.139365 
l0: 0.088862, l1: 0.085743, l2: 0.078980, l3: 0.081051, l4: 0.112460, l5: 0.096614, l6: 0.103663

[epoch:  14/100000, batch:   170/  187, ite: 1307] train loss: 0.918151, tar: 0.139326 
l0: 0.104873, l1: 0.111107, l2: 0.107560, l3: 0.109613, l4: 0.120070, l5: 0.120574, l6: 0.120222

[epoch:  14/100000, batch:   172/  187, ite: 1308] train loss: 0.918056, tar: 0.139300 
l0: 0.110944, l1: 0.105120, l2: 0.108322, l3: 0.124313, l4: 0.122467, l5: 0.130321, l6: 0.149231

[epoch:  14/100000, batch:   174/  187, ite: 1309] train loss: 0.918004, tar: 0.139278 
l0: 0.094926, l1: 0.090880, l2: 0.093042, l3: 0.089748, l4: 0.099875, l5: 0.099907, l6: 0.097335

[epoch:  14/100000, batch:   176/  187, ite: 1310] train loss: 0.917812, tar: 0.139244 
l0: 0.098533, l1: 0.089552, l2: 0.090934, l3: 0.088425, l4: 0.119030, l5: 0.117373, l6: 0.134754

[epoch:  14/100000, batch:   178/  187, ite: 1311] train loss: 0.917675, tar: 0.139213 
l0: 0.107871, l1: 0.107643, l2: 0.105971, l3: 0.118885, l4: 0.113440, l5: 0.121692, l6: 0.130530

[epoch:  14/100000, batch:   180/  187, ite: 1312] train loss: 0.917590, tar: 0.139189 
l0: 0.127609, l1: 0.132420, l2: 0.132603, l3: 0.135173, l4: 0.148461, l5: 0.125621, l6: 0.133184

[epoch:  14/100000, batch:   182/  187, ite: 1313] train loss: 0.917603, tar: 0.139181 
l0: 0.080138, l1: 0.077580, l2: 0.078626, l3: 0.086214, l4: 0.090575, l5: 0.092226, l6: 0.091056

[epoch:  14/100000, batch:   184/  187, ite: 1314] train loss: 0.917359, tar: 0.139136 
l0: 0.077383, l1: 0.087582, l2: 0.085907, l3: 0.095948, l4: 0.083893, l5: 0.073725, l6: 0.062768

[epoch:  14/100000, batch:   186/  187, ite: 1315] train loss: 0.917093, tar: 0.139089 
l0: 0.071102, l1: 0.067394, l2: 0.077037, l3: 0.090966, l4: 0.080615, l5: 0.077494, l6: 0.076442

[epoch:  14/100000, batch:   188/  187, ite: 1316] train loss: 0.916807, tar: 0.139037 
l0: 0.139551, l1: 0.142623, l2: 0.158199, l3: 0.151243, l4: 0.154841, l5: 0.140043, l6: 0.172311

[epoch:  15/100000, batch:     2/  187, ite: 1317] train loss: 0.916915, tar: 0.139037 
l0: 0.083441, l1: 0.090738, l2: 0.103643, l3: 0.100701, l4: 0.117875, l5: 0.099304, l6: 0.099285

[epoch:  15/100000, batch:     4/  187, ite: 1318] train loss: 0.916746, tar: 0.138995 
l0: 0.080277, l1: 0.070760, l2: 0.081498, l3: 0.097660, l4: 0.092975, l5: 0.091628, l6: 0.077176

[epoch:  15/100000, batch:     6/  187, ite: 1319] train loss: 0.916500, tar: 0.138951 
l0: 0.092230, l1: 0.083496, l2: 0.096561, l3: 0.105531, l4: 0.113824, l5: 0.113029, l6: 0.108464

[epoch:  15/100000, batch:     8/  187, ite: 1320] train loss: 0.916346, tar: 0.138915 
l0: 0.132698, l1: 0.133206, l2: 0.134668, l3: 0.134853, l4: 0.152715, l5: 0.139284, l6: 0.158538

[epoch:  15/100000, batch:    10/  187, ite: 1321] train loss: 0.916399, tar: 0.138911 
l0: 0.114394, l1: 0.112898, l2: 0.125076, l3: 0.133375, l4: 0.111945, l5: 0.107817, l6: 0.127944

[epoch:  15/100000, batch:    12/  187, ite: 1322] train loss: 0.916336, tar: 0.138892 
l0: 0.099022, l1: 0.091465, l2: 0.097056, l3: 0.099133, l4: 0.116916, l5: 0.123294, l6: 0.122251

[epoch:  15/100000, batch:    14/  187, ite: 1323] train loss: 0.916210, tar: 0.138862 
l0: 0.078028, l1: 0.078620, l2: 0.078868, l3: 0.081519, l4: 0.081021, l5: 0.078640, l6: 0.070799

[epoch:  15/100000, batch:    16/  187, ite: 1324] train loss: 0.915931, tar: 0.138816 
l0: 0.058619, l1: 0.063649, l2: 0.062598, l3: 0.067850, l4: 0.068567, l5: 0.056409, l6: 0.065548

[epoch:  15/100000, batch:    18/  187, ite: 1325] train loss: 0.915574, tar: 0.138755 
l0: 0.078945, l1: 0.067521, l2: 0.074337, l3: 0.079215, l4: 0.084109, l5: 0.105216, l6: 0.102615

[epoch:  15/100000, batch:    20/  187, ite: 1326] train loss: 0.915330, tar: 0.138710 
l0: 0.120729, l1: 0.129601, l2: 0.129634, l3: 0.129440, l4: 0.120752, l5: 0.108532, l6: 0.120126

[epoch:  15/100000, batch:    22/  187, ite: 1327] train loss: 0.915288, tar: 0.138697 
l0: 0.086464, l1: 0.086013, l2: 0.090737, l3: 0.093431, l4: 0.099408, l5: 0.103180, l6: 0.099312

[epoch:  15/100000, batch:    24/  187, ite: 1328] train loss: 0.915094, tar: 0.138657 
l0: 0.134080, l1: 0.153552, l2: 0.153185, l3: 0.152832, l4: 0.121457, l5: 0.128878, l6: 0.105102

[epoch:  15/100000, batch:    26/  187, ite: 1329] train loss: 0.915120, tar: 0.138654 
l0: 0.103740, l1: 0.113294, l2: 0.105909, l3: 0.095493, l4: 0.102680, l5: 0.110556, l6: 0.094260

[epoch:  15/100000, batch:    28/  187, ite: 1330] train loss: 0.914978, tar: 0.138628 
l0: 0.095721, l1: 0.103912, l2: 0.098451, l3: 0.103302, l4: 0.103395, l5: 0.096461, l6: 0.103984

[epoch:  15/100000, batch:    30/  187, ite: 1331] train loss: 0.914820, tar: 0.138595 
l0: 0.073495, l1: 0.087891, l2: 0.090693, l3: 0.086857, l4: 0.084517, l5: 0.106929, l6: 0.079126

[epoch:  15/100000, batch:    32/  187, ite: 1332] train loss: 0.914591, tar: 0.138547 
l0: 0.086807, l1: 0.082482, l2: 0.093976, l3: 0.090141, l4: 0.092434, l5: 0.108708, l6: 0.103579

[epoch:  15/100000, batch:    34/  187, ite: 1333] train loss: 0.914398, tar: 0.138508 
l0: 0.107112, l1: 0.103516, l2: 0.118207, l3: 0.117812, l4: 0.110127, l5: 0.127868, l6: 0.129727

[epoch:  15/100000, batch:    36/  187, ite: 1334] train loss: 0.914323, tar: 0.138484 
l0: 0.058413, l1: 0.056858, l2: 0.064616, l3: 0.059526, l4: 0.057957, l5: 0.081593, l6: 0.078322

[epoch:  15/100000, batch:    38/  187, ite: 1335] train loss: 0.913981, tar: 0.138424 
l0: 0.095137, l1: 0.102675, l2: 0.086030, l3: 0.085086, l4: 0.107729, l5: 0.111111, l6: 0.106341

[epoch:  15/100000, batch:    40/  187, ite: 1336] train loss: 0.913817, tar: 0.138392 
l0: 0.132712, l1: 0.133777, l2: 0.130683, l3: 0.130229, l4: 0.153289, l5: 0.128253, l6: 0.153493

[epoch:  15/100000, batch:    42/  187, ite: 1337] train loss: 0.913853, tar: 0.138388 
l0: 0.130643, l1: 0.131516, l2: 0.137837, l3: 0.133273, l4: 0.167100, l5: 0.157003, l6: 0.161188

[epoch:  15/100000, batch:    44/  187, ite: 1338] train loss: 0.913931, tar: 0.138382 
l0: 0.116651, l1: 0.107617, l2: 0.123132, l3: 0.117150, l4: 0.143193, l5: 0.125373, l6: 0.131344

[epoch:  15/100000, batch:    46/  187, ite: 1339] train loss: 0.913894, tar: 0.138366 
l0: 0.081880, l1: 0.085114, l2: 0.084257, l3: 0.085158, l4: 0.083242, l5: 0.085697, l6: 0.096692

[epoch:  15/100000, batch:    48/  187, ite: 1340] train loss: 0.913661, tar: 0.138323 
l0: 0.155163, l1: 0.139920, l2: 0.163000, l3: 0.156024, l4: 0.198940, l5: 0.194713, l6: 0.226336

[epoch:  15/100000, batch:    50/  187, ite: 1341] train loss: 0.913900, tar: 0.138336 
l0: 0.125317, l1: 0.118024, l2: 0.131328, l3: 0.124435, l4: 0.145745, l5: 0.151250, l6: 0.139135

[epoch:  15/100000, batch:    52/  187, ite: 1342] train loss: 0.913916, tar: 0.138326 
l0: 0.069455, l1: 0.072834, l2: 0.069448, l3: 0.077983, l4: 0.094426, l5: 0.085599, l6: 0.075673

[epoch:  15/100000, batch:    54/  187, ite: 1343] train loss: 0.913642, tar: 0.138275 
l0: 0.101008, l1: 0.109555, l2: 0.122502, l3: 0.118729, l4: 0.113629, l5: 0.109039, l6: 0.107013

[epoch:  15/100000, batch:    56/  187, ite: 1344] train loss: 0.913544, tar: 0.138247 
l0: 0.098717, l1: 0.091914, l2: 0.100000, l3: 0.098842, l4: 0.102757, l5: 0.097301, l6: 0.101137

[epoch:  15/100000, batch:    58/  187, ite: 1345] train loss: 0.913378, tar: 0.138218 
l0: 0.126679, l1: 0.124021, l2: 0.121509, l3: 0.114424, l4: 0.125684, l5: 0.129695, l6: 0.125166

[epoch:  15/100000, batch:    60/  187, ite: 1346] train loss: 0.913344, tar: 0.138209 
l0: 0.096271, l1: 0.094042, l2: 0.113633, l3: 0.103570, l4: 0.120663, l5: 0.125976, l6: 0.117826

[epoch:  15/100000, batch:    62/  187, ite: 1347] train loss: 0.913239, tar: 0.138178 
l0: 0.072378, l1: 0.066372, l2: 0.085418, l3: 0.086533, l4: 0.097057, l5: 0.093276, l6: 0.101395

[epoch:  15/100000, batch:    64/  187, ite: 1348] train loss: 0.913008, tar: 0.138129 
l0: 0.078876, l1: 0.069381, l2: 0.089600, l3: 0.092801, l4: 0.090714, l5: 0.102420, l6: 0.100316

[epoch:  15/100000, batch:    66/  187, ite: 1349] train loss: 0.912794, tar: 0.138085 
l0: 0.077532, l1: 0.072075, l2: 0.086845, l3: 0.095289, l4: 0.085346, l5: 0.091570, l6: 0.094884

[epoch:  15/100000, batch:    68/  187, ite: 1350] train loss: 0.912565, tar: 0.138041 
l0: 0.106205, l1: 0.092991, l2: 0.100037, l3: 0.098549, l4: 0.133669, l5: 0.142241, l6: 0.150505

[epoch:  15/100000, batch:    70/  187, ite: 1351] train loss: 0.912499, tar: 0.138017 
l0: 0.172113, l1: 0.188293, l2: 0.180061, l3: 0.179826, l4: 0.183055, l5: 0.189717, l6: 0.168192

[epoch:  15/100000, batch:    72/  187, ite: 1352] train loss: 0.912757, tar: 0.138042 
l0: 0.115850, l1: 0.102463, l2: 0.106685, l3: 0.098758, l4: 0.155367, l5: 0.161459, l6: 0.151021

[epoch:  15/100000, batch:    74/  187, ite: 1353] train loss: 0.912742, tar: 0.138026 
l0: 0.085473, l1: 0.072761, l2: 0.081008, l3: 0.083920, l4: 0.107382, l5: 0.119922, l6: 0.100580

[epoch:  15/100000, batch:    76/  187, ite: 1354] train loss: 0.912548, tar: 0.137987 
l0: 0.112532, l1: 0.086487, l2: 0.111767, l3: 0.109634, l4: 0.150709, l5: 0.171152, l6: 0.259625

[epoch:  15/100000, batch:    78/  187, ite: 1355] train loss: 0.912614, tar: 0.137968 
l0: 0.119780, l1: 0.115555, l2: 0.124479, l3: 0.126028, l4: 0.166624, l5: 0.161940, l6: 0.182392

[epoch:  15/100000, batch:    80/  187, ite: 1356] train loss: 0.912676, tar: 0.137955 
l0: 0.084010, l1: 0.087836, l2: 0.084920, l3: 0.088264, l4: 0.092290, l5: 0.091120, l6: 0.095095

[epoch:  15/100000, batch:    82/  187, ite: 1357] train loss: 0.912463, tar: 0.137915 
l0: 0.084250, l1: 0.097454, l2: 0.073297, l3: 0.075709, l4: 0.081706, l5: 0.089894, l6: 0.090534

[epoch:  15/100000, batch:    84/  187, ite: 1358] train loss: 0.912228, tar: 0.137876 
l0: 0.140751, l1: 0.162426, l2: 0.157862, l3: 0.162986, l4: 0.132671, l5: 0.126514, l6: 0.122313

[epoch:  15/100000, batch:    86/  187, ite: 1359] train loss: 0.912297, tar: 0.137878 
l0: 0.127662, l1: 0.134771, l2: 0.185038, l3: 0.188054, l4: 0.130868, l5: 0.125409, l6: 0.115423

[epoch:  15/100000, batch:    88/  187, ite: 1360] train loss: 0.912367, tar: 0.137870 
l0: 0.082562, l1: 0.091216, l2: 0.098237, l3: 0.096867, l4: 0.081844, l5: 0.084340, l6: 0.084954

[epoch:  15/100000, batch:    90/  187, ite: 1361] train loss: 0.912152, tar: 0.137830 
l0: 0.142484, l1: 0.153259, l2: 0.163367, l3: 0.148709, l4: 0.137616, l5: 0.140279, l6: 0.127721

[epoch:  15/100000, batch:    92/  187, ite: 1362] train loss: 0.912226, tar: 0.137833 
l0: 0.074170, l1: 0.072098, l2: 0.067247, l3: 0.070630, l4: 0.084502, l5: 0.084955, l6: 0.078984

[epoch:  15/100000, batch:    94/  187, ite: 1363] train loss: 0.911948, tar: 0.137786 
l0: 0.117686, l1: 0.118617, l2: 0.115328, l3: 0.110147, l4: 0.124251, l5: 0.126255, l6: 0.109642

[epoch:  15/100000, batch:    96/  187, ite: 1364] train loss: 0.911882, tar: 0.137772 
l0: 0.096470, l1: 0.093612, l2: 0.115244, l3: 0.101148, l4: 0.104663, l5: 0.113188, l6: 0.100813

[epoch:  15/100000, batch:    98/  187, ite: 1365] train loss: 0.911745, tar: 0.137741 
l0: 0.069367, l1: 0.065029, l2: 0.074235, l3: 0.080268, l4: 0.080318, l5: 0.086111, l6: 0.073170

[epoch:  15/100000, batch:   100/  187, ite: 1366] train loss: 0.911464, tar: 0.137691 
l0: 0.071245, l1: 0.068214, l2: 0.077780, l3: 0.076863, l4: 0.079268, l5: 0.078331, l6: 0.072832

[epoch:  15/100000, batch:   102/  187, ite: 1367] train loss: 0.911181, tar: 0.137643 
l0: 0.098535, l1: 0.096732, l2: 0.094849, l3: 0.093765, l4: 0.106708, l5: 0.102078, l6: 0.097602

[epoch:  15/100000, batch:   104/  187, ite: 1368] train loss: 0.911020, tar: 0.137614 
l0: 0.089246, l1: 0.088443, l2: 0.086542, l3: 0.090904, l4: 0.092866, l5: 0.090623, l6: 0.088974

[epoch:  15/100000, batch:   106/  187, ite: 1369] train loss: 0.910813, tar: 0.137579 
l0: 0.139813, l1: 0.154180, l2: 0.128142, l3: 0.129129, l4: 0.137509, l5: 0.131653, l6: 0.140766

[epoch:  15/100000, batch:   108/  187, ite: 1370] train loss: 0.910849, tar: 0.137580 
l0: 0.106390, l1: 0.108611, l2: 0.097404, l3: 0.100003, l4: 0.100493, l5: 0.108860, l6: 0.103885

[epoch:  15/100000, batch:   110/  187, ite: 1371] train loss: 0.910714, tar: 0.137558 
l0: 0.099022, l1: 0.113791, l2: 0.111014, l3: 0.102052, l4: 0.097534, l5: 0.090811, l6: 0.084624

[epoch:  15/100000, batch:   112/  187, ite: 1372] train loss: 0.910560, tar: 0.137529 
l0: 0.098779, l1: 0.083422, l2: 0.098643, l3: 0.104007, l4: 0.111803, l5: 0.127327, l6: 0.150564

[epoch:  15/100000, batch:   114/  187, ite: 1373] train loss: 0.910461, tar: 0.137501 
l0: 0.078792, l1: 0.076208, l2: 0.074975, l3: 0.077132, l4: 0.082406, l5: 0.092657, l6: 0.077624

[epoch:  15/100000, batch:   116/  187, ite: 1374] train loss: 0.910206, tar: 0.137459 
l0: 0.106658, l1: 0.115959, l2: 0.113921, l3: 0.113218, l4: 0.108552, l5: 0.097332, l6: 0.101581

[epoch:  15/100000, batch:   118/  187, ite: 1375] train loss: 0.910094, tar: 0.137436 
l0: 0.080014, l1: 0.076449, l2: 0.090778, l3: 0.100755, l4: 0.092934, l5: 0.100309, l6: 0.078013

[epoch:  15/100000, batch:   120/  187, ite: 1376] train loss: 0.909883, tar: 0.137394 
l0: 0.084166, l1: 0.083100, l2: 0.088389, l3: 0.089696, l4: 0.093508, l5: 0.088448, l6: 0.090935

[epoch:  15/100000, batch:   122/  187, ite: 1377] train loss: 0.909671, tar: 0.137356 
l0: 0.118062, l1: 0.118088, l2: 0.105971, l3: 0.104667, l4: 0.131100, l5: 0.144257, l6: 0.139239

[epoch:  15/100000, batch:   124/  187, ite: 1378] train loss: 0.909636, tar: 0.137342 
l0: 0.099820, l1: 0.087400, l2: 0.101502, l3: 0.102447, l4: 0.120393, l5: 0.116824, l6: 0.127413

[epoch:  15/100000, batch:   126/  187, ite: 1379] train loss: 0.909525, tar: 0.137315 
l0: 0.103599, l1: 0.118002, l2: 0.102408, l3: 0.099644, l4: 0.102888, l5: 0.108898, l6: 0.101695

[epoch:  15/100000, batch:   128/  187, ite: 1380] train loss: 0.909400, tar: 0.137290 
l0: 0.070740, l1: 0.067154, l2: 0.071475, l3: 0.072963, l4: 0.075129, l5: 0.076858, l6: 0.077067

[epoch:  15/100000, batch:   130/  187, ite: 1381] train loss: 0.909111, tar: 0.137242 
l0: 0.087816, l1: 0.089999, l2: 0.087442, l3: 0.090733, l4: 0.108479, l5: 0.100585, l6: 0.090642

[epoch:  15/100000, batch:   132/  187, ite: 1382] train loss: 0.908928, tar: 0.137206 
l0: 0.082600, l1: 0.080882, l2: 0.077020, l3: 0.080021, l4: 0.096530, l5: 0.090806, l6: 0.093043

[epoch:  15/100000, batch:   134/  187, ite: 1383] train loss: 0.908705, tar: 0.137167 
l0: 0.106135, l1: 0.111739, l2: 0.095501, l3: 0.096329, l4: 0.095878, l5: 0.098624, l6: 0.096810

[epoch:  15/100000, batch:   136/  187, ite: 1384] train loss: 0.908555, tar: 0.137144 
l0: 0.061511, l1: 0.058897, l2: 0.063294, l3: 0.063516, l4: 0.071242, l5: 0.079677, l6: 0.069953

[epoch:  15/100000, batch:   138/  187, ite: 1385] train loss: 0.908237, tar: 0.137090 
l0: 0.071927, l1: 0.081761, l2: 0.079465, l3: 0.074768, l4: 0.074725, l5: 0.075494, l6: 0.076723

[epoch:  15/100000, batch:   140/  187, ite: 1386] train loss: 0.907968, tar: 0.137043 
l0: 0.115583, l1: 0.115562, l2: 0.128015, l3: 0.127295, l4: 0.128540, l5: 0.133040, l6: 0.135986

[epoch:  15/100000, batch:   142/  187, ite: 1387] train loss: 0.907951, tar: 0.137027 
l0: 0.122742, l1: 0.125787, l2: 0.133656, l3: 0.131846, l4: 0.118811, l5: 0.143003, l6: 0.137872

[epoch:  15/100000, batch:   144/  187, ite: 1388] train loss: 0.907955, tar: 0.137017 
l0: 0.076834, l1: 0.072674, l2: 0.071736, l3: 0.072243, l4: 0.086323, l5: 0.084210, l6: 0.091149

[epoch:  15/100000, batch:   146/  187, ite: 1389] train loss: 0.907701, tar: 0.136974 
l0: 0.083634, l1: 0.078020, l2: 0.077811, l3: 0.077514, l4: 0.100443, l5: 0.095388, l6: 0.090513

[epoch:  15/100000, batch:   148/  187, ite: 1390] train loss: 0.907482, tar: 0.136935 
l0: 0.082538, l1: 0.069705, l2: 0.079666, l3: 0.080311, l4: 0.098555, l5: 0.101974, l6: 0.097350

[epoch:  15/100000, batch:   150/  187, ite: 1391] train loss: 0.907268, tar: 0.136896 
l0: 0.066826, l1: 0.066242, l2: 0.058549, l3: 0.061215, l4: 0.069447, l5: 0.068349, l6: 0.071377

[epoch:  15/100000, batch:   152/  187, ite: 1392] train loss: 0.906948, tar: 0.136846 
l0: 0.100498, l1: 0.098059, l2: 0.101869, l3: 0.105576, l4: 0.100965, l5: 0.095846, l6: 0.103112

[epoch:  15/100000, batch:   154/  187, ite: 1393] train loss: 0.906804, tar: 0.136820 
l0: 0.079448, l1: 0.078710, l2: 0.087801, l3: 0.089373, l4: 0.091338, l5: 0.089253, l6: 0.081946

[epoch:  15/100000, batch:   156/  187, ite: 1394] train loss: 0.906582, tar: 0.136778 
l0: 0.162284, l1: 0.181390, l2: 0.182890, l3: 0.176650, l4: 0.175343, l5: 0.153553, l6: 0.157495

[epoch:  15/100000, batch:   158/  187, ite: 1395] train loss: 0.906785, tar: 0.136797 
l0: 0.098886, l1: 0.091509, l2: 0.107614, l3: 0.106880, l4: 0.108647, l5: 0.105757, l6: 0.108344

[epoch:  15/100000, batch:   160/  187, ite: 1396] train loss: 0.906657, tar: 0.136770 
l0: 0.116475, l1: 0.119103, l2: 0.121443, l3: 0.121312, l4: 0.118606, l5: 0.128644, l6: 0.117838

[epoch:  15/100000, batch:   162/  187, ite: 1397] train loss: 0.906611, tar: 0.136755 
l0: 0.074171, l1: 0.073745, l2: 0.072369, l3: 0.076463, l4: 0.100239, l5: 0.102860, l6: 0.105110

[epoch:  15/100000, batch:   164/  187, ite: 1398] train loss: 0.906396, tar: 0.136710 
l0: 0.097103, l1: 0.089486, l2: 0.108050, l3: 0.107448, l4: 0.103831, l5: 0.106618, l6: 0.105043

[epoch:  15/100000, batch:   166/  187, ite: 1399] train loss: 0.906261, tar: 0.136682 
l0: 0.058290, l1: 0.067094, l2: 0.062013, l3: 0.065658, l4: 0.080152, l5: 0.078487, l6: 0.069074

[epoch:  15/100000, batch:   168/  187, ite: 1400] train loss: 0.905957, tar: 0.136626 
l0: 0.121301, l1: 0.128547, l2: 0.123786, l3: 0.131611, l4: 0.141794, l5: 0.181994, l6: 0.171854

[epoch:  15/100000, batch:   170/  187, ite: 1401] train loss: 0.906025, tar: 0.136615 
l0: 0.125185, l1: 0.128775, l2: 0.113756, l3: 0.114660, l4: 0.132167, l5: 0.148926, l6: 0.167868

[epoch:  15/100000, batch:   172/  187, ite: 1402] train loss: 0.906043, tar: 0.136607 
l0: 0.084494, l1: 0.098017, l2: 0.094225, l3: 0.097076, l4: 0.079900, l5: 0.079171, l6: 0.079015

[epoch:  15/100000, batch:   174/  187, ite: 1403] train loss: 0.905833, tar: 0.136570 
l0: 0.066855, l1: 0.072495, l2: 0.078087, l3: 0.080417, l4: 0.086853, l5: 0.080820, l6: 0.070432

[epoch:  15/100000, batch:   176/  187, ite: 1404] train loss: 0.905570, tar: 0.136520 
l0: 0.112018, l1: 0.126946, l2: 0.124191, l3: 0.125331, l4: 0.120777, l5: 0.097163, l6: 0.095273

[epoch:  15/100000, batch:   178/  187, ite: 1405] train loss: 0.905496, tar: 0.136503 
l0: 0.063643, l1: 0.081402, l2: 0.080668, l3: 0.068482, l4: 0.063512, l5: 0.061882, l6: 0.066485

[epoch:  15/100000, batch:   180/  187, ite: 1406] train loss: 0.905197, tar: 0.136451 
l0: 0.116760, l1: 0.112575, l2: 0.111353, l3: 0.121013, l4: 0.120847, l5: 0.134622, l6: 0.129716

[epoch:  15/100000, batch:   182/  187, ite: 1407] train loss: 0.905156, tar: 0.136437 
l0: 0.083814, l1: 0.081023, l2: 0.076627, l3: 0.085745, l4: 0.080296, l5: 0.092703, l6: 0.088207

[epoch:  15/100000, batch:   184/  187, ite: 1408] train loss: 0.904931, tar: 0.136399 
l0: 0.101037, l1: 0.110477, l2: 0.104003, l3: 0.105785, l4: 0.090438, l5: 0.094825, l6: 0.085110

[epoch:  15/100000, batch:   186/  187, ite: 1409] train loss: 0.904780, tar: 0.136374 
l0: 0.051140, l1: 0.060655, l2: 0.047800, l3: 0.046120, l4: 0.041790, l5: 0.043414, l6: 0.049409

[epoch:  15/100000, batch:   188/  187, ite: 1410] train loss: 0.904379, tar: 0.136314 
l0: 0.103482, l1: 0.098852, l2: 0.110218, l3: 0.116548, l4: 0.120145, l5: 0.105579, l6: 0.093683

[epoch:  16/100000, batch:     2/  187, ite: 1411] train loss: 0.904269, tar: 0.136291 
l0: 0.094059, l1: 0.091834, l2: 0.096102, l3: 0.098343, l4: 0.094376, l5: 0.090999, l6: 0.090520

[epoch:  16/100000, batch:     4/  187, ite: 1412] train loss: 0.904093, tar: 0.136261 
l0: 0.074488, l1: 0.064853, l2: 0.075848, l3: 0.076683, l4: 0.080330, l5: 0.085459, l6: 0.083302

[epoch:  16/100000, batch:     6/  187, ite: 1413] train loss: 0.903836, tar: 0.136217 
l0: 0.085214, l1: 0.089420, l2: 0.089075, l3: 0.089133, l4: 0.116289, l5: 0.095545, l6: 0.101419

[epoch:  16/100000, batch:     8/  187, ite: 1414] train loss: 0.903668, tar: 0.136181 
l0: 0.086981, l1: 0.080081, l2: 0.090586, l3: 0.084522, l4: 0.092628, l5: 0.091126, l6: 0.092879

[epoch:  16/100000, batch:    10/  187, ite: 1415] train loss: 0.903467, tar: 0.136146 
l0: 0.067316, l1: 0.068933, l2: 0.067570, l3: 0.066012, l4: 0.067013, l5: 0.064321, l6: 0.057958

[epoch:  16/100000, batch:    12/  187, ite: 1416] train loss: 0.903153, tar: 0.136098 
l0: 0.095832, l1: 0.087623, l2: 0.098656, l3: 0.093942, l4: 0.094077, l5: 0.116376, l6: 0.108351

[epoch:  16/100000, batch:    14/  187, ite: 1417] train loss: 0.903006, tar: 0.136069 
l0: 0.188548, l1: 0.198319, l2: 0.203343, l3: 0.245900, l4: 0.184649, l5: 0.179732, l6: 0.215232

[epoch:  16/100000, batch:    16/  187, ite: 1418] train loss: 0.903367, tar: 0.136106 
l0: 0.095094, l1: 0.094475, l2: 0.093772, l3: 0.088403, l4: 0.095322, l5: 0.104042, l6: 0.102566

[epoch:  16/100000, batch:    18/  187, ite: 1419] train loss: 0.903206, tar: 0.136077 
l0: 0.127387, l1: 0.137305, l2: 0.125228, l3: 0.118652, l4: 0.108029, l5: 0.115727, l6: 0.105135

[epoch:  16/100000, batch:    20/  187, ite: 1420] train loss: 0.903159, tar: 0.136071 
l0: 0.083125, l1: 0.076026, l2: 0.085215, l3: 0.088098, l4: 0.094595, l5: 0.102282, l6: 0.103408

[epoch:  16/100000, batch:    22/  187, ite: 1421] train loss: 0.902969, tar: 0.136034 
l0: 0.114264, l1: 0.112017, l2: 0.120858, l3: 0.126471, l4: 0.135690, l5: 0.121601, l6: 0.122600

[epoch:  16/100000, batch:    24/  187, ite: 1422] train loss: 0.902934, tar: 0.136019 
l0: 0.073858, l1: 0.074950, l2: 0.084170, l3: 0.089786, l4: 0.092752, l5: 0.090854, l6: 0.104098

[epoch:  16/100000, batch:    26/  187, ite: 1423] train loss: 0.902729, tar: 0.135975 
l0: 0.078442, l1: 0.072900, l2: 0.075663, l3: 0.081526, l4: 0.094314, l5: 0.098921, l6: 0.094004

[epoch:  16/100000, batch:    28/  187, ite: 1424] train loss: 0.902513, tar: 0.135934 
l0: 0.091993, l1: 0.097597, l2: 0.102262, l3: 0.104776, l4: 0.098484, l5: 0.092064, l6: 0.087481

[epoch:  16/100000, batch:    30/  187, ite: 1425] train loss: 0.902353, tar: 0.135904 
l0: 0.073729, l1: 0.076806, l2: 0.085235, l3: 0.075704, l4: 0.082362, l5: 0.107332, l6: 0.093536

[epoch:  16/100000, batch:    32/  187, ite: 1426] train loss: 0.902137, tar: 0.135860 
l0: 0.118212, l1: 0.115529, l2: 0.128375, l3: 0.122252, l4: 0.126170, l5: 0.145602, l6: 0.161548

[epoch:  16/100000, batch:    34/  187, ite: 1427] train loss: 0.902148, tar: 0.135848 
l0: 0.076706, l1: 0.077609, l2: 0.091222, l3: 0.087371, l4: 0.097815, l5: 0.079896, l6: 0.084144

[epoch:  16/100000, batch:    36/  187, ite: 1428] train loss: 0.901933, tar: 0.135806 
l0: 0.088483, l1: 0.093712, l2: 0.087357, l3: 0.093327, l4: 0.091874, l5: 0.083447, l6: 0.085299

[epoch:  16/100000, batch:    38/  187, ite: 1429] train loss: 0.901738, tar: 0.135773 
l0: 0.184889, l1: 0.178485, l2: 0.204265, l3: 0.212727, l4: 0.188498, l5: 0.209822, l6: 0.235112

[epoch:  16/100000, batch:    40/  187, ite: 1430] train loss: 0.902096, tar: 0.135807 
l0: 0.081968, l1: 0.071983, l2: 0.077256, l3: 0.083433, l4: 0.088947, l5: 0.104233, l6: 0.098984

[epoch:  16/100000, batch:    42/  187, ite: 1431] train loss: 0.901890, tar: 0.135770 
l0: 0.084896, l1: 0.084319, l2: 0.089505, l3: 0.089361, l4: 0.103336, l5: 0.096117, l6: 0.095798

[epoch:  16/100000, batch:    44/  187, ite: 1432] train loss: 0.901709, tar: 0.135734 
l0: 0.108672, l1: 0.091992, l2: 0.097537, l3: 0.104318, l4: 0.132029, l5: 0.131982, l6: 0.125755

[epoch:  16/100000, batch:    46/  187, ite: 1433] train loss: 0.901633, tar: 0.135715 
l0: 0.076325, l1: 0.076098, l2: 0.071305, l3: 0.073342, l4: 0.079950, l5: 0.081720, l6: 0.077625

[epoch:  16/100000, batch:    48/  187, ite: 1434] train loss: 0.901378, tar: 0.135674 
l0: 0.110354, l1: 0.112690, l2: 0.108525, l3: 0.114329, l4: 0.106026, l5: 0.107499, l6: 0.095765

[epoch:  16/100000, batch:    50/  187, ite: 1435] train loss: 0.901276, tar: 0.135656 
l0: 0.094553, l1: 0.082014, l2: 0.083212, l3: 0.088642, l4: 0.098315, l5: 0.108061, l6: 0.109502

[epoch:  16/100000, batch:    52/  187, ite: 1436] train loss: 0.901111, tar: 0.135628 
l0: 0.104623, l1: 0.116143, l2: 0.107186, l3: 0.119060, l4: 0.127563, l5: 0.104659, l6: 0.105022

[epoch:  16/100000, batch:    54/  187, ite: 1437] train loss: 0.901030, tar: 0.135606 
l0: 0.122415, l1: 0.124115, l2: 0.132677, l3: 0.135385, l4: 0.137302, l5: 0.143343, l6: 0.141406

[epoch:  16/100000, batch:    56/  187, ite: 1438] train loss: 0.901055, tar: 0.135597 
l0: 0.062071, l1: 0.074766, l2: 0.064526, l3: 0.067362, l4: 0.067081, l5: 0.060584, l6: 0.066835

[epoch:  16/100000, batch:    58/  187, ite: 1439] train loss: 0.900751, tar: 0.135546 
l0: 0.093428, l1: 0.089688, l2: 0.096208, l3: 0.090831, l4: 0.108726, l5: 0.120463, l6: 0.102814

[epoch:  16/100000, batch:    60/  187, ite: 1440] train loss: 0.900613, tar: 0.135517 
l0: 0.072332, l1: 0.080557, l2: 0.068976, l3: 0.068130, l4: 0.090532, l5: 0.087691, l6: 0.066136

[epoch:  16/100000, batch:    62/  187, ite: 1441] train loss: 0.900359, tar: 0.135473 
l0: 0.041499, l1: 0.040182, l2: 0.044676, l3: 0.045306, l4: 0.048732, l5: 0.051997, l6: 0.046033

[epoch:  16/100000, batch:    64/  187, ite: 1442] train loss: 0.899955, tar: 0.135408 
l0: 0.080594, l1: 0.090718, l2: 0.088029, l3: 0.073572, l4: 0.097556, l5: 0.087716, l6: 0.083086

[epoch:  16/100000, batch:    66/  187, ite: 1443] train loss: 0.899748, tar: 0.135370 
l0: 0.050740, l1: 0.053456, l2: 0.050221, l3: 0.046974, l4: 0.060323, l5: 0.054891, l6: 0.050409

[epoch:  16/100000, batch:    68/  187, ite: 1444] train loss: 0.899379, tar: 0.135311 
l0: 0.138413, l1: 0.140037, l2: 0.147472, l3: 0.146247, l4: 0.172791, l5: 0.135307, l6: 0.137341

[epoch:  16/100000, batch:    70/  187, ite: 1445] train loss: 0.899461, tar: 0.135313 
l0: 0.113146, l1: 0.117485, l2: 0.121320, l3: 0.129804, l4: 0.114527, l5: 0.104206, l6: 0.110668

[epoch:  16/100000, batch:    72/  187, ite: 1446] train loss: 0.899400, tar: 0.135298 
l0: 0.044348, l1: 0.051214, l2: 0.046017, l3: 0.042379, l4: 0.046141, l5: 0.043831, l6: 0.038346

[epoch:  16/100000, batch:    74/  187, ite: 1447] train loss: 0.898994, tar: 0.135235 
l0: 0.064278, l1: 0.060649, l2: 0.064988, l3: 0.062957, l4: 0.068286, l5: 0.061934, l6: 0.061846

[epoch:  16/100000, batch:    76/  187, ite: 1448] train loss: 0.898680, tar: 0.135186 
l0: 0.131517, l1: 0.131598, l2: 0.119337, l3: 0.127637, l4: 0.145932, l5: 0.168961, l6: 0.175170

[epoch:  16/100000, batch:    78/  187, ite: 1449] train loss: 0.898751, tar: 0.135184 
l0: 0.086674, l1: 0.082062, l2: 0.093008, l3: 0.088161, l4: 0.094949, l5: 0.109406, l6: 0.087624

[epoch:  16/100000, batch:    80/  187, ite: 1450] train loss: 0.898573, tar: 0.135150 
l0: 0.119142, l1: 0.114562, l2: 0.123779, l3: 0.128033, l4: 0.125014, l5: 0.117515, l6: 0.115483

[epoch:  16/100000, batch:    82/  187, ite: 1451] train loss: 0.898535, tar: 0.135139 
l0: 0.108717, l1: 0.101075, l2: 0.101465, l3: 0.103216, l4: 0.127102, l5: 0.139736, l6: 0.141665

[epoch:  16/100000, batch:    84/  187, ite: 1452] train loss: 0.898483, tar: 0.135121 
l0: 0.105024, l1: 0.095296, l2: 0.110055, l3: 0.120798, l4: 0.116519, l5: 0.122359, l6: 0.114607

[epoch:  16/100000, batch:    86/  187, ite: 1453] train loss: 0.898405, tar: 0.135100 
l0: 0.063298, l1: 0.057773, l2: 0.064446, l3: 0.070210, l4: 0.077793, l5: 0.076031, l6: 0.072934

[epoch:  16/100000, batch:    88/  187, ite: 1454] train loss: 0.898119, tar: 0.135051 
l0: 0.111275, l1: 0.116028, l2: 0.117291, l3: 0.122650, l4: 0.119777, l5: 0.126595, l6: 0.134189

[epoch:  16/100000, batch:    90/  187, ite: 1455] train loss: 0.898084, tar: 0.135034 
l0: 0.084326, l1: 0.086103, l2: 0.079869, l3: 0.091528, l4: 0.091829, l5: 0.099855, l6: 0.091534

[epoch:  16/100000, batch:    92/  187, ite: 1456] train loss: 0.897897, tar: 0.135000 
l0: 0.073753, l1: 0.076701, l2: 0.087538, l3: 0.091917, l4: 0.092302, l5: 0.089651, l6: 0.090910

[epoch:  16/100000, batch:    94/  187, ite: 1457] train loss: 0.897694, tar: 0.134958 
l0: 0.096728, l1: 0.103155, l2: 0.103471, l3: 0.107031, l4: 0.103619, l5: 0.105423, l6: 0.089450

[epoch:  16/100000, batch:    96/  187, ite: 1458] train loss: 0.897565, tar: 0.134931 
l0: 0.080301, l1: 0.081345, l2: 0.086778, l3: 0.089362, l4: 0.083324, l5: 0.085622, l6: 0.080387

[epoch:  16/100000, batch:    98/  187, ite: 1459] train loss: 0.897352, tar: 0.134894 
l0: 0.070338, l1: 0.079027, l2: 0.077217, l3: 0.076882, l4: 0.071616, l5: 0.078366, l6: 0.073742

[epoch:  16/100000, batch:   100/  187, ite: 1460] train loss: 0.897099, tar: 0.134850 
l0: 0.083919, l1: 0.075823, l2: 0.092945, l3: 0.092056, l4: 0.101542, l5: 0.091242, l6: 0.094818

[epoch:  16/100000, batch:   102/  187, ite: 1461] train loss: 0.896917, tar: 0.134815 
l0: 0.086476, l1: 0.080682, l2: 0.085356, l3: 0.085339, l4: 0.093180, l5: 0.099446, l6: 0.099904

[epoch:  16/100000, batch:   104/  187, ite: 1462] train loss: 0.896735, tar: 0.134782 
l0: 0.081889, l1: 0.072788, l2: 0.081439, l3: 0.078987, l4: 0.100477, l5: 0.100284, l6: 0.097470

[epoch:  16/100000, batch:   106/  187, ite: 1463] train loss: 0.896541, tar: 0.134746 
l0: 0.053400, l1: 0.053888, l2: 0.051486, l3: 0.056113, l4: 0.064916, l5: 0.068295, l6: 0.064549

[epoch:  16/100000, batch:   108/  187, ite: 1464] train loss: 0.896211, tar: 0.134690 
l0: 0.076211, l1: 0.067241, l2: 0.072773, l3: 0.070661, l4: 0.084247, l5: 0.090376, l6: 0.087868

[epoch:  16/100000, batch:   110/  187, ite: 1465] train loss: 0.895974, tar: 0.134650 
l0: 0.058153, l1: 0.062136, l2: 0.059810, l3: 0.060609, l4: 0.055709, l5: 0.063523, l6: 0.058632

[epoch:  16/100000, batch:   112/  187, ite: 1466] train loss: 0.895648, tar: 0.134598 
l0: 0.060434, l1: 0.066123, l2: 0.066318, l3: 0.063638, l4: 0.091029, l5: 0.080642, l6: 0.085252

[epoch:  16/100000, batch:   114/  187, ite: 1467] train loss: 0.895388, tar: 0.134547 
l0: 0.096044, l1: 0.110924, l2: 0.129584, l3: 0.105132, l4: 0.104335, l5: 0.103497, l6: 0.104743

[epoch:  16/100000, batch:   116/  187, ite: 1468] train loss: 0.895292, tar: 0.134521 
l0: 0.120091, l1: 0.113991, l2: 0.129915, l3: 0.144273, l4: 0.168866, l5: 0.140669, l6: 0.135248

[epoch:  16/100000, batch:   118/  187, ite: 1469] train loss: 0.895331, tar: 0.134511 
l0: 0.085724, l1: 0.089604, l2: 0.092370, l3: 0.089256, l4: 0.075427, l5: 0.090250, l6: 0.097320

[epoch:  16/100000, batch:   120/  187, ite: 1470] train loss: 0.895144, tar: 0.134478 
l0: 0.112431, l1: 0.102097, l2: 0.129794, l3: 0.137393, l4: 0.127898, l5: 0.129464, l6: 0.136726

[epoch:  16/100000, batch:   122/  187, ite: 1471] train loss: 0.895131, tar: 0.134463 
l0: 0.049901, l1: 0.053783, l2: 0.058133, l3: 0.059506, l4: 0.059940, l5: 0.053977, l6: 0.049052

[epoch:  16/100000, batch:   124/  187, ite: 1472] train loss: 0.894783, tar: 0.134406 
l0: 0.042412, l1: 0.049553, l2: 0.047529, l3: 0.047919, l4: 0.048510, l5: 0.047506, l6: 0.037479

[epoch:  16/100000, batch:   126/  187, ite: 1473] train loss: 0.894394, tar: 0.134343 
l0: 0.084767, l1: 0.078076, l2: 0.089268, l3: 0.085390, l4: 0.087274, l5: 0.106336, l6: 0.098724

[epoch:  16/100000, batch:   128/  187, ite: 1474] train loss: 0.894214, tar: 0.134310 
l0: 0.210252, l1: 0.252211, l2: 0.227138, l3: 0.242254, l4: 0.226524, l5: 0.182510, l6: 0.198636

[epoch:  16/100000, batch:   130/  187, ite: 1475] train loss: 0.894652, tar: 0.134361 
l0: 0.079972, l1: 0.089898, l2: 0.079970, l3: 0.082401, l4: 0.088797, l5: 0.091102, l6: 0.081496

[epoch:  16/100000, batch:   132/  187, ite: 1476] train loss: 0.894448, tar: 0.134324 
l0: 0.113592, l1: 0.123358, l2: 0.132923, l3: 0.137014, l4: 0.106190, l5: 0.112968, l6: 0.116470

[epoch:  16/100000, batch:   134/  187, ite: 1477] train loss: 0.894413, tar: 0.134310 
l0: 0.132159, l1: 0.112079, l2: 0.110409, l3: 0.121536, l4: 0.163980, l5: 0.247854, l6: 0.232859

[epoch:  16/100000, batch:   136/  187, ite: 1478] train loss: 0.894566, tar: 0.134309 
l0: 0.140073, l1: 0.171484, l2: 0.185699, l3: 0.164618, l4: 0.163978, l5: 0.134065, l6: 0.131172

[epoch:  16/100000, batch:   138/  187, ite: 1479] train loss: 0.894699, tar: 0.134313 
l0: 0.063702, l1: 0.070863, l2: 0.067498, l3: 0.072092, l4: 0.068482, l5: 0.072727, l6: 0.076925

[epoch:  16/100000, batch:   140/  187, ite: 1480] train loss: 0.894427, tar: 0.134265 
l0: 0.087049, l1: 0.095887, l2: 0.083059, l3: 0.083017, l4: 0.095659, l5: 0.102596, l6: 0.103904

[epoch:  16/100000, batch:   142/  187, ite: 1481] train loss: 0.894263, tar: 0.134233 
l0: 0.101748, l1: 0.103258, l2: 0.099057, l3: 0.097538, l4: 0.101295, l5: 0.112528, l6: 0.102283

[epoch:  16/100000, batch:   144/  187, ite: 1482] train loss: 0.894144, tar: 0.134211 
l0: 0.111789, l1: 0.096685, l2: 0.103008, l3: 0.116326, l4: 0.116832, l5: 0.140314, l6: 0.167040

[epoch:  16/100000, batch:   146/  187, ite: 1483] train loss: 0.894115, tar: 0.134196 
l0: 0.102734, l1: 0.092232, l2: 0.104949, l3: 0.109882, l4: 0.125253, l5: 0.127316, l6: 0.129937

[epoch:  16/100000, batch:   148/  187, ite: 1484] train loss: 0.894047, tar: 0.134175 
l0: 0.085993, l1: 0.084889, l2: 0.084389, l3: 0.092710, l4: 0.101315, l5: 0.093135, l6: 0.094056

[epoch:  16/100000, batch:   150/  187, ite: 1485] train loss: 0.893873, tar: 0.134142 
l0: 0.076686, l1: 0.077008, l2: 0.085161, l3: 0.084581, l4: 0.095286, l5: 0.097756, l6: 0.098429

[epoch:  16/100000, batch:   152/  187, ite: 1486] train loss: 0.893685, tar: 0.134104 
l0: 0.115583, l1: 0.113683, l2: 0.123430, l3: 0.125825, l4: 0.153883, l5: 0.133723, l6: 0.132064

[epoch:  16/100000, batch:   154/  187, ite: 1487] train loss: 0.893688, tar: 0.134091 
l0: 0.172375, l1: 0.169541, l2: 0.200192, l3: 0.207512, l4: 0.224027, l5: 0.204407, l6: 0.180418

[epoch:  16/100000, batch:   156/  187, ite: 1488] train loss: 0.894001, tar: 0.134117 
l0: 0.105580, l1: 0.103445, l2: 0.130452, l3: 0.125956, l4: 0.122117, l5: 0.114610, l6: 0.123625

[epoch:  16/100000, batch:   158/  187, ite: 1489] train loss: 0.893955, tar: 0.134098 
l0: 0.105780, l1: 0.095673, l2: 0.118251, l3: 0.128362, l4: 0.126970, l5: 0.127909, l6: 0.119469

[epoch:  16/100000, batch:   160/  187, ite: 1490] train loss: 0.893907, tar: 0.134079 
l0: 0.086860, l1: 0.088851, l2: 0.081193, l3: 0.091214, l4: 0.103016, l5: 0.108973, l6: 0.105848

[epoch:  16/100000, batch:   162/  187, ite: 1491] train loss: 0.893754, tar: 0.134047 
l0: 0.091144, l1: 0.095405, l2: 0.092461, l3: 0.094900, l4: 0.100061, l5: 0.109165, l6: 0.098752

[epoch:  16/100000, batch:   164/  187, ite: 1492] train loss: 0.893612, tar: 0.134018 
l0: 0.086116, l1: 0.078636, l2: 0.088267, l3: 0.101776, l4: 0.103641, l5: 0.102861, l6: 0.095971

[epoch:  16/100000, batch:   166/  187, ite: 1493] train loss: 0.893454, tar: 0.133986 
l0: 0.099158, l1: 0.089733, l2: 0.098291, l3: 0.110816, l4: 0.117751, l5: 0.118374, l6: 0.112735

[epoch:  16/100000, batch:   168/  187, ite: 1494] train loss: 0.893356, tar: 0.133963 
l0: 0.114136, l1: 0.113072, l2: 0.118371, l3: 0.129495, l4: 0.127695, l5: 0.126285, l6: 0.132347

[epoch:  16/100000, batch:   170/  187, ite: 1495] train loss: 0.893334, tar: 0.133950 
l0: 0.113049, l1: 0.110196, l2: 0.119155, l3: 0.136773, l4: 0.127530, l5: 0.120569, l6: 0.113325

[epoch:  16/100000, batch:   172/  187, ite: 1496] train loss: 0.893299, tar: 0.133936 
l0: 0.166655, l1: 0.167931, l2: 0.165311, l3: 0.175938, l4: 0.188195, l5: 0.193177, l6: 0.188530

[epoch:  16/100000, batch:   174/  187, ite: 1497] train loss: 0.893534, tar: 0.133958 
l0: 0.095442, l1: 0.084639, l2: 0.110340, l3: 0.123429, l4: 0.128062, l5: 0.116889, l6: 0.113604

[epoch:  16/100000, batch:   176/  187, ite: 1498] train loss: 0.893454, tar: 0.133932 
l0: 0.110922, l1: 0.099611, l2: 0.111326, l3: 0.118760, l4: 0.134201, l5: 0.136664, l6: 0.127277

[epoch:  16/100000, batch:   178/  187, ite: 1499] train loss: 0.893417, tar: 0.133917 
l0: 0.113434, l1: 0.108362, l2: 0.124676, l3: 0.141358, l4: 0.128289, l5: 0.126253, l6: 0.118142

[epoch:  16/100000, batch:   180/  187, ite: 1500] train loss: 0.893395, tar: 0.133903 
l0: 0.114890, l1: 0.112807, l2: 0.139218, l3: 0.141980, l4: 0.129781, l5: 0.129291, l6: 0.130935

[epoch:  16/100000, batch:   182/  187, ite: 1501] train loss: 0.893399, tar: 0.133890 
l0: 0.110261, l1: 0.128394, l2: 0.098793, l3: 0.092935, l4: 0.112649, l5: 0.111949, l6: 0.107678

[epoch:  16/100000, batch:   184/  187, ite: 1502] train loss: 0.893312, tar: 0.133874 
l0: 0.145127, l1: 0.186691, l2: 0.134946, l3: 0.122813, l4: 0.131440, l5: 0.130851, l6: 0.130729

[epoch:  16/100000, batch:   186/  187, ite: 1503] train loss: 0.893371, tar: 0.133882 
l0: 0.091446, l1: 0.085225, l2: 0.099194, l3: 0.103270, l4: 0.098444, l5: 0.103695, l6: 0.121921

[epoch:  16/100000, batch:   188/  187, ite: 1504] train loss: 0.893245, tar: 0.133854 
l0: 0.077189, l1: 0.089082, l2: 0.091015, l3: 0.093202, l4: 0.093011, l5: 0.092516, l6: 0.095007

[epoch:  17/100000, batch:     2/  187, ite: 1505] train loss: 0.893071, tar: 0.133816 
l0: 0.120478, l1: 0.133472, l2: 0.142838, l3: 0.139171, l4: 0.113983, l5: 0.113989, l6: 0.113964

[epoch:  17/100000, batch:     4/  187, ite: 1506] train loss: 0.893060, tar: 0.133807 
l0: 0.090354, l1: 0.092725, l2: 0.096170, l3: 0.097248, l4: 0.095942, l5: 0.097735, l6: 0.099051

[epoch:  17/100000, batch:     6/  187, ite: 1507] train loss: 0.892912, tar: 0.133778 
l0: 0.089089, l1: 0.088951, l2: 0.096838, l3: 0.102384, l4: 0.104664, l5: 0.103115, l6: 0.113707

[epoch:  17/100000, batch:     8/  187, ite: 1508] train loss: 0.892783, tar: 0.133749 
l0: 0.077223, l1: 0.084255, l2: 0.083860, l3: 0.075984, l4: 0.078872, l5: 0.082218, l6: 0.082499

[epoch:  17/100000, batch:    10/  187, ite: 1509] train loss: 0.892566, tar: 0.133711 
l0: 0.052815, l1: 0.061048, l2: 0.057074, l3: 0.051297, l4: 0.055469, l5: 0.055221, l6: 0.051434

[epoch:  17/100000, batch:    12/  187, ite: 1510] train loss: 0.892229, tar: 0.133658 
l0: 0.093082, l1: 0.085989, l2: 0.100496, l3: 0.107498, l4: 0.114097, l5: 0.107094, l6: 0.101792

[epoch:  17/100000, batch:    14/  187, ite: 1511] train loss: 0.892109, tar: 0.133631 
l0: 0.139392, l1: 0.171895, l2: 0.097241, l3: 0.083700, l4: 0.117645, l5: 0.139722, l6: 0.166861

[epoch:  17/100000, batch:    16/  187, ite: 1512] train loss: 0.892125, tar: 0.133635 
l0: 0.079029, l1: 0.078043, l2: 0.077456, l3: 0.086486, l4: 0.084796, l5: 0.086830, l6: 0.078568

[epoch:  17/100000, batch:    18/  187, ite: 1513] train loss: 0.891913, tar: 0.133599 
l0: 0.067961, l1: 0.065487, l2: 0.074560, l3: 0.077308, l4: 0.075823, l5: 0.072318, l6: 0.074563

[epoch:  17/100000, batch:    20/  187, ite: 1514] train loss: 0.891659, tar: 0.133555 
l0: 0.087025, l1: 0.082882, l2: 0.097389, l3: 0.101317, l4: 0.105953, l5: 0.108692, l6: 0.113743

[epoch:  17/100000, batch:    22/  187, ite: 1515] train loss: 0.891531, tar: 0.133525 
l0: 0.037711, l1: 0.041292, l2: 0.039672, l3: 0.046193, l4: 0.045230, l5: 0.034273, l6: 0.038608

[epoch:  17/100000, batch:    24/  187, ite: 1516] train loss: 0.891129, tar: 0.133461 
l0: 0.043831, l1: 0.043302, l2: 0.049035, l3: 0.054917, l4: 0.050400, l5: 0.049554, l6: 0.054255

[epoch:  17/100000, batch:    26/  187, ite: 1517] train loss: 0.890769, tar: 0.133402 
l0: 0.074261, l1: 0.066823, l2: 0.075274, l3: 0.075880, l4: 0.080072, l5: 0.080182, l6: 0.091424

[epoch:  17/100000, batch:    28/  187, ite: 1518] train loss: 0.890541, tar: 0.133363 
l0: 0.086867, l1: 0.090071, l2: 0.076831, l3: 0.081759, l4: 0.085426, l5: 0.094942, l6: 0.112705

[epoch:  17/100000, batch:    30/  187, ite: 1519] train loss: 0.890369, tar: 0.133333 
l0: 0.109560, l1: 0.120355, l2: 0.141028, l3: 0.129361, l4: 0.121578, l5: 0.111159, l6: 0.110179

[epoch:  17/100000, batch:    32/  187, ite: 1520] train loss: 0.890338, tar: 0.133317 
l0: 0.139450, l1: 0.142919, l2: 0.129687, l3: 0.139365, l4: 0.136978, l5: 0.136972, l6: 0.149605

[epoch:  17/100000, batch:    34/  187, ite: 1521] train loss: 0.890393, tar: 0.133321 
l0: 0.123045, l1: 0.131141, l2: 0.122632, l3: 0.107972, l4: 0.128828, l5: 0.133745, l6: 0.140220

[epoch:  17/100000, batch:    36/  187, ite: 1522] train loss: 0.890391, tar: 0.133314 
l0: 0.091601, l1: 0.093411, l2: 0.096596, l3: 0.081503, l4: 0.117189, l5: 0.108444, l6: 0.100838

[epoch:  17/100000, batch:    38/  187, ite: 1523] train loss: 0.890259, tar: 0.133287 
l0: 0.089804, l1: 0.086038, l2: 0.097597, l3: 0.092815, l4: 0.089339, l5: 0.088597, l6: 0.084533

[epoch:  17/100000, batch:    40/  187, ite: 1524] train loss: 0.890088, tar: 0.133258 
l0: 0.051018, l1: 0.051480, l2: 0.059132, l3: 0.055876, l4: 0.063544, l5: 0.056348, l6: 0.056085

[epoch:  17/100000, batch:    42/  187, ite: 1525] train loss: 0.889762, tar: 0.133204 
l0: 0.125386, l1: 0.143587, l2: 0.138539, l3: 0.149639, l4: 0.145772, l5: 0.147039, l6: 0.124464

[epoch:  17/100000, batch:    44/  187, ite: 1526] train loss: 0.889818, tar: 0.133199 
l0: 0.073713, l1: 0.066351, l2: 0.073420, l3: 0.070094, l4: 0.085065, l5: 0.091235, l6: 0.084476

[epoch:  17/100000, batch:    46/  187, ite: 1527] train loss: 0.889591, tar: 0.133160 
l0: 0.124571, l1: 0.130997, l2: 0.132162, l3: 0.137597, l4: 0.144048, l5: 0.129665, l6: 0.138987

[epoch:  17/100000, batch:    48/  187, ite: 1528] train loss: 0.889623, tar: 0.133155 
l0: 0.076803, l1: 0.079099, l2: 0.082050, l3: 0.083566, l4: 0.085935, l5: 0.076421, l6: 0.087040

[epoch:  17/100000, batch:    50/  187, ite: 1529] train loss: 0.889415, tar: 0.133118 
l0: 0.117250, l1: 0.113329, l2: 0.102569, l3: 0.102970, l4: 0.133781, l5: 0.165878, l6: 0.129287

[epoch:  17/100000, batch:    52/  187, ite: 1530] train loss: 0.889399, tar: 0.133108 
l0: 0.086430, l1: 0.080122, l2: 0.085846, l3: 0.089322, l4: 0.089235, l5: 0.101516, l6: 0.100037

[epoch:  17/100000, batch:    54/  187, ite: 1531] train loss: 0.889231, tar: 0.133077 
l0: 0.092918, l1: 0.090434, l2: 0.095746, l3: 0.095846, l4: 0.093436, l5: 0.114316, l6: 0.108869

[epoch:  17/100000, batch:    56/  187, ite: 1532] train loss: 0.889102, tar: 0.133051 
l0: 0.098423, l1: 0.090571, l2: 0.110283, l3: 0.092774, l4: 0.128152, l5: 0.126771, l6: 0.131088

[epoch:  17/100000, batch:    58/  187, ite: 1533] train loss: 0.889030, tar: 0.133028 
l0: 0.084702, l1: 0.078462, l2: 0.090026, l3: 0.092371, l4: 0.097316, l5: 0.095407, l6: 0.100785

[epoch:  17/100000, batch:    60/  187, ite: 1534] train loss: 0.888867, tar: 0.132997 
l0: 0.137971, l1: 0.151931, l2: 0.136359, l3: 0.122127, l4: 0.155025, l5: 0.151260, l6: 0.167974

[epoch:  17/100000, batch:    62/  187, ite: 1535] train loss: 0.888954, tar: 0.133000 
l0: 0.079977, l1: 0.078714, l2: 0.084225, l3: 0.084063, l4: 0.092097, l5: 0.091908, l6: 0.093457

[epoch:  17/100000, batch:    64/  187, ite: 1536] train loss: 0.888769, tar: 0.132965 
l0: 0.090353, l1: 0.097536, l2: 0.095298, l3: 0.087876, l4: 0.087784, l5: 0.095580, l6: 0.100908

[epoch:  17/100000, batch:    66/  187, ite: 1537] train loss: 0.888617, tar: 0.132938 
l0: 0.087840, l1: 0.092852, l2: 0.085360, l3: 0.087583, l4: 0.087006, l5: 0.082996, l6: 0.086375

[epoch:  17/100000, batch:    68/  187, ite: 1538] train loss: 0.888435, tar: 0.132908 
l0: 0.080479, l1: 0.077986, l2: 0.077543, l3: 0.076877, l4: 0.082237, l5: 0.104516, l6: 0.078442

[epoch:  17/100000, batch:    70/  187, ite: 1539] train loss: 0.888234, tar: 0.132874 
l0: 0.085015, l1: 0.087525, l2: 0.092908, l3: 0.088375, l4: 0.092053, l5: 0.086107, l6: 0.096770

[epoch:  17/100000, batch:    72/  187, ite: 1540] train loss: 0.888065, tar: 0.132843 
l0: 0.100065, l1: 0.103075, l2: 0.098580, l3: 0.100030, l4: 0.099566, l5: 0.111042, l6: 0.105157

[epoch:  17/100000, batch:    74/  187, ite: 1541] train loss: 0.887955, tar: 0.132822 
l0: 0.064804, l1: 0.057613, l2: 0.062073, l3: 0.061999, l4: 0.072906, l5: 0.075943, l6: 0.076020

[epoch:  17/100000, batch:    76/  187, ite: 1542] train loss: 0.887684, tar: 0.132778 
l0: 0.055768, l1: 0.069353, l2: 0.051409, l3: 0.050673, l4: 0.052780, l5: 0.062928, l6: 0.056881

[epoch:  17/100000, batch:    78/  187, ite: 1543] train loss: 0.887368, tar: 0.132728 
l0: 0.092085, l1: 0.095094, l2: 0.105638, l3: 0.098362, l4: 0.101017, l5: 0.101742, l6: 0.093896

[epoch:  17/100000, batch:    80/  187, ite: 1544] train loss: 0.887239, tar: 0.132702 
l0: 0.074941, l1: 0.072877, l2: 0.078133, l3: 0.078430, l4: 0.084405, l5: 0.081598, l6: 0.087302

[epoch:  17/100000, batch:    82/  187, ite: 1545] train loss: 0.887026, tar: 0.132664 
l0: 0.137918, l1: 0.131488, l2: 0.168821, l3: 0.159619, l4: 0.154487, l5: 0.139404, l6: 0.144874

[epoch:  17/100000, batch:    84/  187, ite: 1546] train loss: 0.887123, tar: 0.132668 
l0: 0.138504, l1: 0.157919, l2: 0.152507, l3: 0.149460, l4: 0.147131, l5: 0.123109, l6: 0.137961

[epoch:  17/100000, batch:    86/  187, ite: 1547] train loss: 0.887200, tar: 0.132671 
l0: 0.090018, l1: 0.100967, l2: 0.103783, l3: 0.103184, l4: 0.103146, l5: 0.085057, l6: 0.089665

[epoch:  17/100000, batch:    88/  187, ite: 1548] train loss: 0.887063, tar: 0.132644 
l0: 0.072335, l1: 0.066190, l2: 0.072740, l3: 0.069845, l4: 0.080180, l5: 0.087905, l6: 0.083207

[epoch:  17/100000, batch:    90/  187, ite: 1549] train loss: 0.886834, tar: 0.132605 
l0: 0.147846, l1: 0.146866, l2: 0.146865, l3: 0.161914, l4: 0.181579, l5: 0.155523, l6: 0.179274

[epoch:  17/100000, batch:    92/  187, ite: 1550] train loss: 0.886985, tar: 0.132615 
l0: 0.139695, l1: 0.124708, l2: 0.122367, l3: 0.144768, l4: 0.211139, l5: 0.182400, l6: 0.226124

[epoch:  17/100000, batch:    94/  187, ite: 1551] train loss: 0.887155, tar: 0.132619 
l0: 0.082568, l1: 0.084898, l2: 0.106650, l3: 0.114474, l4: 0.098576, l5: 0.093333, l6: 0.094269

[epoch:  17/100000, batch:    96/  187, ite: 1552] train loss: 0.887018, tar: 0.132587 
l0: 0.091603, l1: 0.094911, l2: 0.113543, l3: 0.112828, l4: 0.120271, l5: 0.107047, l6: 0.117148

[epoch:  17/100000, batch:    98/  187, ite: 1553] train loss: 0.886935, tar: 0.132561 
l0: 0.072517, l1: 0.075487, l2: 0.086881, l3: 0.095700, l4: 0.091797, l5: 0.092209, l6: 0.089501

[epoch:  17/100000, batch:   100/  187, ite: 1554] train loss: 0.886753, tar: 0.132522 
l0: 0.108016, l1: 0.113727, l2: 0.108913, l3: 0.121842, l4: 0.129049, l5: 0.122009, l6: 0.123656

[epoch:  17/100000, batch:   102/  187, ite: 1555] train loss: 0.886714, tar: 0.132506 
l0: 0.095688, l1: 0.093604, l2: 0.095558, l3: 0.103049, l4: 0.115665, l5: 0.117076, l6: 0.108122

[epoch:  17/100000, batch:   104/  187, ite: 1556] train loss: 0.886613, tar: 0.132483 
l0: 0.125665, l1: 0.135796, l2: 0.144244, l3: 0.131463, l4: 0.158753, l5: 0.150693, l6: 0.125859

[epoch:  17/100000, batch:   106/  187, ite: 1557] train loss: 0.886668, tar: 0.132478 
l0: 0.096130, l1: 0.098778, l2: 0.105961, l3: 0.110345, l4: 0.104290, l5: 0.107981, l6: 0.105575

[epoch:  17/100000, batch:   108/  187, ite: 1558] train loss: 0.886567, tar: 0.132455 
l0: 0.107309, l1: 0.105774, l2: 0.113201, l3: 0.117738, l4: 0.132234, l5: 0.121651, l6: 0.117227

[epoch:  17/100000, batch:   110/  187, ite: 1559] train loss: 0.886521, tar: 0.132439 
l0: 0.099325, l1: 0.102973, l2: 0.084504, l3: 0.090626, l4: 0.111400, l5: 0.108349, l6: 0.087391

[epoch:  17/100000, batch:   112/  187, ite: 1560] train loss: 0.886391, tar: 0.132418 
l0: 0.070347, l1: 0.062723, l2: 0.079876, l3: 0.081001, l4: 0.087381, l5: 0.093620, l6: 0.084326

[epoch:  17/100000, batch:   114/  187, ite: 1561] train loss: 0.886182, tar: 0.132378 
l0: 0.162544, l1: 0.194914, l2: 0.203125, l3: 0.179961, l4: 0.141878, l5: 0.134153, l6: 0.138190

[epoch:  17/100000, batch:   116/  187, ite: 1562] train loss: 0.886354, tar: 0.132397 
l0: 0.092374, l1: 0.078704, l2: 0.081512, l3: 0.089497, l4: 0.108330, l5: 0.114648, l6: 0.124967

[epoch:  17/100000, batch:   118/  187, ite: 1563] train loss: 0.886228, tar: 0.132372 
l0: 0.125094, l1: 0.107131, l2: 0.118777, l3: 0.126180, l4: 0.171986, l5: 0.179658, l6: 0.199817

[epoch:  17/100000, batch:   120/  187, ite: 1564] train loss: 0.886319, tar: 0.132367 
l0: 0.074385, l1: 0.092849, l2: 0.076287, l3: 0.072198, l4: 0.088870, l5: 0.070052, l6: 0.068683

[epoch:  17/100000, batch:   122/  187, ite: 1565] train loss: 0.886100, tar: 0.132330 
l0: 0.121901, l1: 0.122282, l2: 0.132731, l3: 0.127059, l4: 0.123482, l5: 0.134702, l6: 0.128712

[epoch:  17/100000, batch:   124/  187, ite: 1566] train loss: 0.886103, tar: 0.132323 
l0: 0.080934, l1: 0.085170, l2: 0.092367, l3: 0.091241, l4: 0.105948, l5: 0.089434, l6: 0.088316

[epoch:  17/100000, batch:   126/  187, ite: 1567] train loss: 0.885942, tar: 0.132290 
l0: 0.125404, l1: 0.139064, l2: 0.130166, l3: 0.127353, l4: 0.116219, l5: 0.110872, l6: 0.112086

[epoch:  17/100000, batch:   128/  187, ite: 1568] train loss: 0.885926, tar: 0.132286 
l0: 0.124012, l1: 0.120519, l2: 0.125245, l3: 0.120579, l4: 0.143342, l5: 0.134530, l6: 0.136666

[epoch:  17/100000, batch:   130/  187, ite: 1569] train loss: 0.885938, tar: 0.132281 
l0: 0.118414, l1: 0.135239, l2: 0.116419, l3: 0.121618, l4: 0.110768, l5: 0.117622, l6: 0.113497

[epoch:  17/100000, batch:   132/  187, ite: 1570] train loss: 0.885905, tar: 0.132272 
l0: 0.076978, l1: 0.096266, l2: 0.092729, l3: 0.089659, l4: 0.072647, l5: 0.075899, l6: 0.062408

[epoch:  17/100000, batch:   134/  187, ite: 1571] train loss: 0.885702, tar: 0.132237 
l0: 0.122811, l1: 0.125960, l2: 0.127438, l3: 0.135787, l4: 0.120096, l5: 0.111907, l6: 0.120100

[epoch:  17/100000, batch:   136/  187, ite: 1572] train loss: 0.885688, tar: 0.132231 
l0: 0.096296, l1: 0.093721, l2: 0.094386, l3: 0.095259, l4: 0.106187, l5: 0.109473, l6: 0.107233

[epoch:  17/100000, batch:   138/  187, ite: 1573] train loss: 0.885571, tar: 0.132208 
l0: 0.101940, l1: 0.110891, l2: 0.096739, l3: 0.100507, l4: 0.110062, l5: 0.100711, l6: 0.110445

[epoch:  17/100000, batch:   140/  187, ite: 1574] train loss: 0.885473, tar: 0.132189 
l0: 0.133964, l1: 0.124897, l2: 0.150250, l3: 0.146844, l4: 0.146572, l5: 0.132458, l6: 0.151521

[epoch:  17/100000, batch:   142/  187, ite: 1575] train loss: 0.885538, tar: 0.132190 
l0: 0.069448, l1: 0.070199, l2: 0.072065, l3: 0.080568, l4: 0.095501, l5: 0.089635, l6: 0.069943

[epoch:  17/100000, batch:   144/  187, ite: 1576] train loss: 0.885323, tar: 0.132150 
l0: 0.092297, l1: 0.088465, l2: 0.096354, l3: 0.096892, l4: 0.109033, l5: 0.117336, l6: 0.119481

[epoch:  17/100000, batch:   146/  187, ite: 1577] train loss: 0.885218, tar: 0.132125 
l0: 0.071784, l1: 0.077644, l2: 0.075341, l3: 0.071105, l4: 0.076004, l5: 0.091899, l6: 0.079701

[epoch:  17/100000, batch:   148/  187, ite: 1578] train loss: 0.885002, tar: 0.132086 
l0: 0.074818, l1: 0.074406, l2: 0.075845, l3: 0.071535, l4: 0.077987, l5: 0.089687, l6: 0.079487

[epoch:  17/100000, batch:   150/  187, ite: 1579] train loss: 0.884785, tar: 0.132050 
l0: 0.097501, l1: 0.090340, l2: 0.107034, l3: 0.104245, l4: 0.103706, l5: 0.106010, l6: 0.092450

[epoch:  17/100000, batch:   152/  187, ite: 1580] train loss: 0.884669, tar: 0.132028 
l0: 0.070045, l1: 0.069405, l2: 0.081639, l3: 0.076091, l4: 0.074464, l5: 0.068259, l6: 0.074823

[epoch:  17/100000, batch:   154/  187, ite: 1581] train loss: 0.884435, tar: 0.131989 
l0: 0.077626, l1: 0.074623, l2: 0.081813, l3: 0.087231, l4: 0.081479, l5: 0.073071, l6: 0.071685

[epoch:  17/100000, batch:   156/  187, ite: 1582] train loss: 0.884222, tar: 0.131955 
l0: 0.050274, l1: 0.047659, l2: 0.057419, l3: 0.057254, l4: 0.065144, l5: 0.065170, l6: 0.065075

[epoch:  17/100000, batch:   158/  187, ite: 1583] train loss: 0.883921, tar: 0.131903 
l0: 0.061399, l1: 0.061923, l2: 0.066499, l3: 0.060055, l4: 0.067311, l5: 0.066646, l6: 0.068534

[epoch:  17/100000, batch:   160/  187, ite: 1584] train loss: 0.883649, tar: 0.131859 
l0: 0.099140, l1: 0.090353, l2: 0.106430, l3: 0.105534, l4: 0.114179, l5: 0.120330, l6: 0.111006

[epoch:  17/100000, batch:   162/  187, ite: 1585] train loss: 0.883563, tar: 0.131838 
l0: 0.109572, l1: 0.111703, l2: 0.125477, l3: 0.109792, l4: 0.120702, l5: 0.121003, l6: 0.106319

[epoch:  17/100000, batch:   164/  187, ite: 1586] train loss: 0.883513, tar: 0.131824 
l0: 0.110961, l1: 0.110376, l2: 0.104461, l3: 0.103907, l4: 0.101869, l5: 0.102367, l6: 0.113748

[epoch:  17/100000, batch:   166/  187, ite: 1587] train loss: 0.883427, tar: 0.131811 
l0: 0.141168, l1: 0.137933, l2: 0.142590, l3: 0.141769, l4: 0.147910, l5: 0.172633, l6: 0.150655

[epoch:  17/100000, batch:   168/  187, ite: 1588] train loss: 0.883523, tar: 0.131817 
l0: 0.073784, l1: 0.067649, l2: 0.077154, l3: 0.083063, l4: 0.097491, l5: 0.096915, l6: 0.095273

[epoch:  17/100000, batch:   170/  187, ite: 1589] train loss: 0.883339, tar: 0.131780 
l0: 0.106383, l1: 0.124508, l2: 0.112705, l3: 0.121954, l4: 0.113148, l5: 0.101059, l6: 0.099520

[epoch:  17/100000, batch:   172/  187, ite: 1590] train loss: 0.883273, tar: 0.131764 
l0: 0.062833, l1: 0.058968, l2: 0.072807, l3: 0.073392, l4: 0.073620, l5: 0.077371, l6: 0.075168

[epoch:  17/100000, batch:   174/  187, ite: 1591] train loss: 0.883029, tar: 0.131721 
l0: 0.149792, l1: 0.162805, l2: 0.157056, l3: 0.150481, l4: 0.122338, l5: 0.131995, l6: 0.155936

[epoch:  17/100000, batch:   176/  187, ite: 1592] train loss: 0.883121, tar: 0.131732 
l0: 0.056290, l1: 0.050741, l2: 0.059406, l3: 0.065213, l4: 0.074352, l5: 0.075199, l6: 0.070425

[epoch:  17/100000, batch:   178/  187, ite: 1593] train loss: 0.882850, tar: 0.131685 
l0: 0.062578, l1: 0.062339, l2: 0.069049, l3: 0.067984, l4: 0.072513, l5: 0.069901, l6: 0.066018

[epoch:  17/100000, batch:   180/  187, ite: 1594] train loss: 0.882592, tar: 0.131641 
l0: 0.075954, l1: 0.073248, l2: 0.087866, l3: 0.093984, l4: 0.089052, l5: 0.089433, l6: 0.083739

[epoch:  17/100000, batch:   182/  187, ite: 1595] train loss: 0.882410, tar: 0.131607 
l0: 0.103646, l1: 0.096879, l2: 0.111537, l3: 0.105128, l4: 0.123079, l5: 0.114074, l6: 0.118656

[epoch:  17/100000, batch:   184/  187, ite: 1596] train loss: 0.882342, tar: 0.131589 
l0: 0.084110, l1: 0.085401, l2: 0.091340, l3: 0.088159, l4: 0.085425, l5: 0.081923, l6: 0.080525

[epoch:  17/100000, batch:   186/  187, ite: 1597] train loss: 0.882163, tar: 0.131559 
l0: 0.111041, l1: 0.125527, l2: 0.108678, l3: 0.115394, l4: 0.121311, l5: 0.119480, l6: 0.095769

[epoch:  17/100000, batch:   188/  187, ite: 1598] train loss: 0.882110, tar: 0.131546 
l0: 0.116755, l1: 0.114562, l2: 0.121504, l3: 0.128219, l4: 0.125349, l5: 0.118592, l6: 0.127235

[epoch:  18/100000, batch:     2/  187, ite: 1599] train loss: 0.882091, tar: 0.131537 
l0: 0.114449, l1: 0.107226, l2: 0.121378, l3: 0.125644, l4: 0.123074, l5: 0.117115, l6: 0.121334

[epoch:  18/100000, batch:     4/  187, ite: 1600] train loss: 0.882059, tar: 0.131527 
l0: 0.069170, l1: 0.065337, l2: 0.072570, l3: 0.074950, l4: 0.091743, l5: 0.096185, l6: 0.088314

[epoch:  18/100000, batch:     6/  187, ite: 1601] train loss: 0.881856, tar: 0.131488 
l0: 0.091855, l1: 0.082915, l2: 0.102521, l3: 0.096363, l4: 0.112172, l5: 0.098326, l6: 0.104579

[epoch:  18/100000, batch:     8/  187, ite: 1602] train loss: 0.881736, tar: 0.131463 
l0: 0.062132, l1: 0.058618, l2: 0.071856, l3: 0.067728, l4: 0.078268, l5: 0.079373, l6: 0.081492

[epoch:  18/100000, batch:    10/  187, ite: 1603] train loss: 0.881497, tar: 0.131420 
l0: 0.103141, l1: 0.110479, l2: 0.110348, l3: 0.110456, l4: 0.137181, l5: 0.138662, l6: 0.112428

[epoch:  18/100000, batch:    12/  187, ite: 1604] train loss: 0.881461, tar: 0.131402 
l0: 0.078236, l1: 0.069371, l2: 0.095717, l3: 0.089776, l4: 0.111761, l5: 0.111729, l6: 0.114818

[epoch:  18/100000, batch:    14/  187, ite: 1605] train loss: 0.881330, tar: 0.131369 
l0: 0.065838, l1: 0.085837, l2: 0.076260, l3: 0.066545, l4: 0.068194, l5: 0.057983, l6: 0.064404

[epoch:  18/100000, batch:    16/  187, ite: 1606] train loss: 0.881083, tar: 0.131328 
l0: 0.125161, l1: 0.131227, l2: 0.115667, l3: 0.114017, l4: 0.155138, l5: 0.167668, l6: 0.137936

[epoch:  18/100000, batch:    18/  187, ite: 1607] train loss: 0.881124, tar: 0.131324 
l0: 0.077210, l1: 0.069702, l2: 0.090778, l3: 0.084443, l4: 0.098195, l5: 0.103784, l6: 0.095440

[epoch:  18/100000, batch:    20/  187, ite: 1608] train loss: 0.880961, tar: 0.131291 
l0: 0.062906, l1: 0.053617, l2: 0.069732, l3: 0.065276, l4: 0.095053, l5: 0.094238, l6: 0.087418

[epoch:  18/100000, batch:    22/  187, ite: 1609] train loss: 0.880742, tar: 0.131248 
l0: 0.085137, l1: 0.088443, l2: 0.094555, l3: 0.094990, l4: 0.088853, l5: 0.086546, l6: 0.079105

[epoch:  18/100000, batch:    24/  187, ite: 1610] train loss: 0.880579, tar: 0.131219 
l0: 0.078319, l1: 0.082397, l2: 0.084022, l3: 0.096259, l4: 0.074383, l5: 0.067304, l6: 0.066684

[epoch:  18/100000, batch:    26/  187, ite: 1611] train loss: 0.880373, tar: 0.131187 
l0: 0.168431, l1: 0.178975, l2: 0.219873, l3: 0.205465, l4: 0.190703, l5: 0.157854, l6: 0.178439

[epoch:  18/100000, batch:    28/  187, ite: 1612] train loss: 0.880633, tar: 0.131210 
l0: 0.078224, l1: 0.069137, l2: 0.083472, l3: 0.081054, l4: 0.083010, l5: 0.097219, l6: 0.084266

[epoch:  18/100000, batch:    30/  187, ite: 1613] train loss: 0.880445, tar: 0.131177 
l0: 0.119503, l1: 0.105423, l2: 0.145563, l3: 0.149395, l4: 0.144930, l5: 0.148439, l6: 0.149806

[epoch:  18/100000, batch:    32/  187, ite: 1614] train loss: 0.880496, tar: 0.131170 
l0: 0.052779, l1: 0.055637, l2: 0.053318, l3: 0.055775, l4: 0.066018, l5: 0.065116, l6: 0.057228

[epoch:  18/100000, batch:    34/  187, ite: 1615] train loss: 0.880202, tar: 0.131121 
l0: 0.072697, l1: 0.086558, l2: 0.073498, l3: 0.073836, l4: 0.093511, l5: 0.075842, l6: 0.070510

[epoch:  18/100000, batch:    36/  187, ite: 1616] train loss: 0.879995, tar: 0.131085 
l0: 0.093089, l1: 0.084882, l2: 0.098422, l3: 0.090932, l4: 0.106534, l5: 0.114004, l6: 0.107963

[epoch:  18/100000, batch:    38/  187, ite: 1617] train loss: 0.879882, tar: 0.131061 
l0: 0.104275, l1: 0.106658, l2: 0.113295, l3: 0.109878, l4: 0.114601, l5: 0.115752, l6: 0.118520

[epoch:  18/100000, batch:    40/  187, ite: 1618] train loss: 0.879822, tar: 0.131045 
l0: 0.090970, l1: 0.104052, l2: 0.100528, l3: 0.100442, l4: 0.102139, l5: 0.087259, l6: 0.092386

[epoch:  18/100000, batch:    42/  187, ite: 1619] train loss: 0.879697, tar: 0.131020 
l0: 0.064676, l1: 0.060689, l2: 0.071423, l3: 0.070866, l4: 0.070246, l5: 0.083691, l6: 0.089811

[epoch:  18/100000, batch:    44/  187, ite: 1620] train loss: 0.879470, tar: 0.130979 
l0: 0.093712, l1: 0.102638, l2: 0.096037, l3: 0.101691, l4: 0.100811, l5: 0.091107, l6: 0.087823

[epoch:  18/100000, batch:    46/  187, ite: 1621] train loss: 0.879343, tar: 0.130956 
l0: 0.136222, l1: 0.155010, l2: 0.156758, l3: 0.148377, l4: 0.148095, l5: 0.143964, l6: 0.136972

[epoch:  18/100000, batch:    48/  187, ite: 1622] train loss: 0.879433, tar: 0.130959 
l0: 0.088621, l1: 0.087232, l2: 0.090737, l3: 0.082126, l4: 0.090387, l5: 0.104228, l6: 0.098248

[epoch:  18/100000, batch:    50/  187, ite: 1623] train loss: 0.879286, tar: 0.130933 
l0: 0.081186, l1: 0.080750, l2: 0.110272, l3: 0.103170, l4: 0.115358, l5: 0.114200, l6: 0.118678

[epoch:  18/100000, batch:    52/  187, ite: 1624] train loss: 0.879190, tar: 0.130903 
l0: 0.096937, l1: 0.087091, l2: 0.116579, l3: 0.119076, l4: 0.103653, l5: 0.102651, l6: 0.105377

[epoch:  18/100000, batch:    54/  187, ite: 1625] train loss: 0.879099, tar: 0.130882 
l0: 0.100166, l1: 0.107299, l2: 0.110520, l3: 0.111944, l4: 0.123058, l5: 0.104806, l6: 0.101337

[epoch:  18/100000, batch:    56/  187, ite: 1626] train loss: 0.879026, tar: 0.130863 
l0: 0.078113, l1: 0.086616, l2: 0.079461, l3: 0.085466, l4: 0.066481, l5: 0.066793, l6: 0.105407

[epoch:  18/100000, batch:    58/  187, ite: 1627] train loss: 0.878835, tar: 0.130830 
l0: 0.056573, l1: 0.057297, l2: 0.054630, l3: 0.059968, l4: 0.051360, l5: 0.061189, l6: 0.071980

[epoch:  18/100000, batch:    60/  187, ite: 1628] train loss: 0.878548, tar: 0.130785 
l0: 0.095767, l1: 0.100685, l2: 0.103269, l3: 0.108062, l4: 0.090652, l5: 0.095587, l6: 0.095025

[epoch:  18/100000, batch:    62/  187, ite: 1629] train loss: 0.878432, tar: 0.130763 
l0: 0.120270, l1: 0.115961, l2: 0.149803, l3: 0.151747, l4: 0.149051, l5: 0.120534, l6: 0.121606

[epoch:  18/100000, batch:    64/  187, ite: 1630] train loss: 0.878463, tar: 0.130757 
l0: 0.101633, l1: 0.093686, l2: 0.112529, l3: 0.101551, l4: 0.137414, l5: 0.134181, l6: 0.132875

[epoch:  18/100000, batch:    66/  187, ite: 1631] train loss: 0.878424, tar: 0.130739 
l0: 0.092569, l1: 0.080205, l2: 0.103342, l3: 0.096059, l4: 0.105940, l5: 0.119994, l6: 0.104105

[epoch:  18/100000, batch:    68/  187, ite: 1632] train loss: 0.878316, tar: 0.130716 
l0: 0.076416, l1: 0.074776, l2: 0.090810, l3: 0.091730, l4: 0.084015, l5: 0.081645, l6: 0.077105

[epoch:  18/100000, batch:    70/  187, ite: 1633] train loss: 0.878131, tar: 0.130682 
l0: 0.094086, l1: 0.088094, l2: 0.096392, l3: 0.096428, l4: 0.122130, l5: 0.123618, l6: 0.137655

[epoch:  18/100000, batch:    72/  187, ite: 1634] train loss: 0.878057, tar: 0.130660 
l0: 0.102473, l1: 0.096459, l2: 0.114054, l3: 0.108706, l4: 0.121943, l5: 0.126043, l6: 0.120820

[epoch:  18/100000, batch:    74/  187, ite: 1635] train loss: 0.878004, tar: 0.130643 
l0: 0.113304, l1: 0.116156, l2: 0.107088, l3: 0.100167, l4: 0.107933, l5: 0.117544, l6: 0.121671

[epoch:  18/100000, batch:    76/  187, ite: 1636] train loss: 0.877946, tar: 0.130632 
l0: 0.059725, l1: 0.063070, l2: 0.062657, l3: 0.064976, l4: 0.067131, l5: 0.068824, l6: 0.060871

[epoch:  18/100000, batch:    78/  187, ite: 1637] train loss: 0.877683, tar: 0.130589 
l0: 0.077690, l1: 0.079221, l2: 0.086155, l3: 0.087086, l4: 0.102188, l5: 0.097852, l6: 0.088640

[epoch:  18/100000, batch:    80/  187, ite: 1638] train loss: 0.877525, tar: 0.130557 
l0: 0.122460, l1: 0.115334, l2: 0.123239, l3: 0.126804, l4: 0.167680, l5: 0.144216, l6: 0.144073

[epoch:  18/100000, batch:    82/  187, ite: 1639] train loss: 0.877566, tar: 0.130552 
l0: 0.075513, l1: 0.066265, l2: 0.083303, l3: 0.081683, l4: 0.082144, l5: 0.091028, l6: 0.095476

[epoch:  18/100000, batch:    84/  187, ite: 1640] train loss: 0.877381, tar: 0.130518 
l0: 0.092373, l1: 0.091755, l2: 0.081808, l3: 0.080583, l4: 0.084965, l5: 0.101379, l6: 0.091893

[epoch:  18/100000, batch:    86/  187, ite: 1641] train loss: 0.877227, tar: 0.130495 
l0: 0.066100, l1: 0.062403, l2: 0.071515, l3: 0.075087, l4: 0.077141, l5: 0.087316, l6: 0.094901

[epoch:  18/100000, batch:    88/  187, ite: 1642] train loss: 0.877019, tar: 0.130456 
l0: 0.093741, l1: 0.090810, l2: 0.106716, l3: 0.107453, l4: 0.099313, l5: 0.099347, l6: 0.113666

[epoch:  18/100000, batch:    90/  187, ite: 1643] train loss: 0.876918, tar: 0.130433 
l0: 0.093085, l1: 0.105878, l2: 0.090304, l3: 0.095929, l4: 0.108327, l5: 0.097483, l6: 0.095991

[epoch:  18/100000, batch:    92/  187, ite: 1644] train loss: 0.876802, tar: 0.130411 
l0: 0.085924, l1: 0.096495, l2: 0.082236, l3: 0.085010, l4: 0.092296, l5: 0.088118, l6: 0.087859

[epoch:  18/100000, batch:    94/  187, ite: 1645] train loss: 0.876645, tar: 0.130384 
l0: 0.055570, l1: 0.057911, l2: 0.060182, l3: 0.050703, l4: 0.063061, l5: 0.072679, l6: 0.060659

[epoch:  18/100000, batch:    96/  187, ite: 1646] train loss: 0.876368, tar: 0.130338 
l0: 0.074893, l1: 0.087617, l2: 0.081120, l3: 0.078657, l4: 0.076016, l5: 0.078181, l6: 0.082478

[epoch:  18/100000, batch:    98/  187, ite: 1647] train loss: 0.876175, tar: 0.130304 
l0: 0.087676, l1: 0.087890, l2: 0.097870, l3: 0.096087, l4: 0.117922, l5: 0.106046, l6: 0.111009

[epoch:  18/100000, batch:   100/  187, ite: 1648] train loss: 0.876071, tar: 0.130279 
l0: 0.064420, l1: 0.079730, l2: 0.074556, l3: 0.061403, l4: 0.074620, l5: 0.063803, l6: 0.063271

[epoch:  18/100000, batch:   102/  187, ite: 1649] train loss: 0.875832, tar: 0.130239 
l0: 0.128924, l1: 0.128708, l2: 0.149390, l3: 0.140604, l4: 0.122837, l5: 0.139944, l6: 0.124810

[epoch:  18/100000, batch:   104/  187, ite: 1650] train loss: 0.875868, tar: 0.130238 
l0: 0.042258, l1: 0.063847, l2: 0.053103, l3: 0.045307, l4: 0.041739, l5: 0.036589, l6: 0.033370

[epoch:  18/100000, batch:   106/  187, ite: 1651] train loss: 0.875529, tar: 0.130185 
l0: 0.066139, l1: 0.072539, l2: 0.056493, l3: 0.059143, l4: 0.065654, l5: 0.068503, l6: 0.067088

[epoch:  18/100000, batch:   108/  187, ite: 1652] train loss: 0.875275, tar: 0.130146 
l0: 0.037421, l1: 0.043397, l2: 0.040195, l3: 0.037579, l4: 0.039902, l5: 0.036183, l6: 0.037265

[epoch:  18/100000, batch:   110/  187, ite: 1653] train loss: 0.874910, tar: 0.130090 
l0: 0.074854, l1: 0.071704, l2: 0.096546, l3: 0.096559, l4: 0.088223, l5: 0.090486, l6: 0.081184

[epoch:  18/100000, batch:   112/  187, ite: 1654] train loss: 0.874743, tar: 0.130056 
l0: 0.048848, l1: 0.049653, l2: 0.054210, l3: 0.052561, l4: 0.054278, l5: 0.053887, l6: 0.053948

[epoch:  18/100000, batch:   114/  187, ite: 1655] train loss: 0.874437, tar: 0.130007 
l0: 0.091938, l1: 0.091270, l2: 0.089578, l3: 0.096568, l4: 0.090060, l5: 0.102846, l6: 0.098094

[epoch:  18/100000, batch:   116/  187, ite: 1656] train loss: 0.874307, tar: 0.129984 
l0: 0.073912, l1: 0.064540, l2: 0.072126, l3: 0.069287, l4: 0.082051, l5: 0.091438, l6: 0.089228

[epoch:  18/100000, batch:   118/  187, ite: 1657] train loss: 0.874107, tar: 0.129950 
l0: 0.068300, l1: 0.067684, l2: 0.077673, l3: 0.080957, l4: 0.086619, l5: 0.084193, l6: 0.075295

[epoch:  18/100000, batch:   120/  187, ite: 1658] train loss: 0.873906, tar: 0.129913 
l0: 0.044471, l1: 0.043769, l2: 0.047653, l3: 0.051844, l4: 0.060148, l5: 0.057548, l6: 0.058257

[epoch:  18/100000, batch:   122/  187, ite: 1659] train loss: 0.873599, tar: 0.129862 
l0: 0.067484, l1: 0.073142, l2: 0.071917, l3: 0.067122, l4: 0.071588, l5: 0.070432, l6: 0.063327

[epoch:  18/100000, batch:   124/  187, ite: 1660] train loss: 0.873364, tar: 0.129824 
l0: 0.111065, l1: 0.112867, l2: 0.139073, l3: 0.135932, l4: 0.136114, l5: 0.121742, l6: 0.123364

[epoch:  18/100000, batch:   126/  187, ite: 1661] train loss: 0.873369, tar: 0.129813 
l0: 0.079523, l1: 0.088988, l2: 0.071779, l3: 0.064845, l4: 0.076345, l5: 0.081881, l6: 0.071001

[epoch:  18/100000, batch:   128/  187, ite: 1662] train loss: 0.873165, tar: 0.129783 
l0: 0.126935, l1: 0.144263, l2: 0.146288, l3: 0.138539, l4: 0.115052, l5: 0.114540, l6: 0.120704

[epoch:  18/100000, batch:   130/  187, ite: 1663] train loss: 0.873185, tar: 0.129781 
l0: 0.086007, l1: 0.077716, l2: 0.094598, l3: 0.082100, l4: 0.091738, l5: 0.089714, l6: 0.099928

[epoch:  18/100000, batch:   132/  187, ite: 1664] train loss: 0.873033, tar: 0.129755 
l0: 0.068458, l1: 0.069625, l2: 0.072057, l3: 0.065195, l4: 0.084975, l5: 0.072708, l6: 0.066231

[epoch:  18/100000, batch:   134/  187, ite: 1665] train loss: 0.872809, tar: 0.129718 
l0: 0.092042, l1: 0.083164, l2: 0.107750, l3: 0.106206, l4: 0.111466, l5: 0.112035, l6: 0.097202

[epoch:  18/100000, batch:   136/  187, ite: 1666] train loss: 0.872711, tar: 0.129695 
l0: 0.093652, l1: 0.091458, l2: 0.111118, l3: 0.110927, l4: 0.137079, l5: 0.105193, l6: 0.104399

[epoch:  18/100000, batch:   138/  187, ite: 1667] train loss: 0.872640, tar: 0.129673 
l0: 0.077797, l1: 0.087604, l2: 0.079193, l3: 0.078319, l4: 0.081492, l5: 0.079520, l6: 0.060808

[epoch:  18/100000, batch:   140/  187, ite: 1668] train loss: 0.872443, tar: 0.129642 
l0: 0.068062, l1: 0.060698, l2: 0.079453, l3: 0.080660, l4: 0.079805, l5: 0.087916, l6: 0.096999

[epoch:  18/100000, batch:   142/  187, ite: 1669] train loss: 0.872252, tar: 0.129605 
l0: 0.107274, l1: 0.127612, l2: 0.121801, l3: 0.119330, l4: 0.097504, l5: 0.104448, l6: 0.110244

[epoch:  18/100000, batch:   144/  187, ite: 1670] train loss: 0.872202, tar: 0.129592 
l0: 0.105459, l1: 0.093171, l2: 0.149422, l3: 0.150053, l4: 0.193225, l5: 0.167432, l6: 0.164912

[epoch:  18/100000, batch:   146/  187, ite: 1671] train loss: 0.872293, tar: 0.129578 
l0: 0.071776, l1: 0.079531, l2: 0.088684, l3: 0.080991, l4: 0.086138, l5: 0.081828, l6: 0.078458

[epoch:  18/100000, batch:   148/  187, ite: 1672] train loss: 0.872110, tar: 0.129543 
l0: 0.088398, l1: 0.080753, l2: 0.089797, l3: 0.100065, l4: 0.101762, l5: 0.108085, l6: 0.110569

[epoch:  18/100000, batch:   150/  187, ite: 1673] train loss: 0.871995, tar: 0.129519 
l0: 0.091695, l1: 0.079235, l2: 0.096939, l3: 0.097354, l4: 0.124735, l5: 0.117011, l6: 0.116153

[epoch:  18/100000, batch:   152/  187, ite: 1674] train loss: 0.871906, tar: 0.129496 
l0: 0.050847, l1: 0.051088, l2: 0.061277, l3: 0.059939, l4: 0.056049, l5: 0.055617, l6: 0.058663

[epoch:  18/100000, batch:   154/  187, ite: 1675] train loss: 0.871620, tar: 0.129449 
l0: 0.099778, l1: 0.103302, l2: 0.090435, l3: 0.099363, l4: 0.105530, l5: 0.101239, l6: 0.103848

[epoch:  18/100000, batch:   156/  187, ite: 1676] train loss: 0.871520, tar: 0.129431 
l0: 0.126386, l1: 0.147678, l2: 0.133733, l3: 0.131821, l4: 0.114548, l5: 0.117379, l6: 0.111048

[epoch:  18/100000, batch:   158/  187, ite: 1677] train loss: 0.871527, tar: 0.129429 
l0: 0.074294, l1: 0.064759, l2: 0.075433, l3: 0.077983, l4: 0.095872, l5: 0.106448, l6: 0.107006

[epoch:  18/100000, batch:   160/  187, ite: 1678] train loss: 0.871366, tar: 0.129397 
l0: 0.079661, l1: 0.066417, l2: 0.097663, l3: 0.103417, l4: 0.111313, l5: 0.099764, l6: 0.091430

[epoch:  18/100000, batch:   162/  187, ite: 1679] train loss: 0.871234, tar: 0.129367 
l0: 0.087907, l1: 0.095945, l2: 0.095371, l3: 0.095018, l4: 0.101098, l5: 0.095441, l6: 0.102361

[epoch:  18/100000, batch:   164/  187, ite: 1680] train loss: 0.871116, tar: 0.129342 
l0: 0.094188, l1: 0.089278, l2: 0.118529, l3: 0.118441, l4: 0.102569, l5: 0.108368, l6: 0.104646

[epoch:  18/100000, batch:   166/  187, ite: 1681] train loss: 0.871036, tar: 0.129321 
l0: 0.046592, l1: 0.061535, l2: 0.045268, l3: 0.042821, l4: 0.057415, l5: 0.053409, l6: 0.053573

[epoch:  18/100000, batch:   168/  187, ite: 1682] train loss: 0.870732, tar: 0.129272 
l0: 0.068520, l1: 0.082387, l2: 0.058643, l3: 0.060979, l4: 0.067124, l5: 0.060411, l6: 0.055835

[epoch:  18/100000, batch:   170/  187, ite: 1683] train loss: 0.870485, tar: 0.129236 
l0: 0.073862, l1: 0.067329, l2: 0.074873, l3: 0.078539, l4: 0.088026, l5: 0.089088, l6: 0.094585

[epoch:  18/100000, batch:   172/  187, ite: 1684] train loss: 0.870304, tar: 0.129203 
l0: 0.098695, l1: 0.113005, l2: 0.096461, l3: 0.099855, l4: 0.090201, l5: 0.095803, l6: 0.097698

[epoch:  18/100000, batch:   174/  187, ite: 1685] train loss: 0.870198, tar: 0.129185 
l0: 0.074223, l1: 0.075518, l2: 0.079253, l3: 0.080009, l4: 0.085230, l5: 0.079466, l6: 0.077751

[epoch:  18/100000, batch:   176/  187, ite: 1686] train loss: 0.870009, tar: 0.129152 
l0: 0.094070, l1: 0.086194, l2: 0.097999, l3: 0.097110, l4: 0.137431, l5: 0.130410, l6: 0.125359

[epoch:  18/100000, batch:   178/  187, ite: 1687] train loss: 0.869949, tar: 0.129132 
l0: 0.074666, l1: 0.068430, l2: 0.082982, l3: 0.081558, l4: 0.099183, l5: 0.081987, l6: 0.090599

[epoch:  18/100000, batch:   180/  187, ite: 1688] train loss: 0.869777, tar: 0.129099 
l0: 0.115050, l1: 0.110929, l2: 0.118289, l3: 0.109112, l4: 0.109435, l5: 0.115873, l6: 0.117638

[epoch:  18/100000, batch:   182/  187, ite: 1689] train loss: 0.869733, tar: 0.129091 
l0: 0.096868, l1: 0.097006, l2: 0.103159, l3: 0.106438, l4: 0.117234, l5: 0.116118, l6: 0.105639

[epoch:  18/100000, batch:   184/  187, ite: 1690] train loss: 0.869658, tar: 0.129072 
l0: 0.078449, l1: 0.067952, l2: 0.089736, l3: 0.090804, l4: 0.089868, l5: 0.100074, l6: 0.105475

[epoch:  18/100000, batch:   186/  187, ite: 1691] train loss: 0.869512, tar: 0.129042 
l0: 0.068749, l1: 0.069825, l2: 0.083700, l3: 0.090180, l4: 0.080459, l5: 0.080658, l6: 0.079632

[epoch:  18/100000, batch:   188/  187, ite: 1692] train loss: 0.869325, tar: 0.129006 
l0: 0.068441, l1: 0.080080, l2: 0.074077, l3: 0.080310, l4: 0.076802, l5: 0.069754, l6: 0.073705

[epoch:  19/100000, batch:     2/  187, ite: 1693] train loss: 0.869120, tar: 0.128971 
l0: 0.089299, l1: 0.080778, l2: 0.085942, l3: 0.090137, l4: 0.092799, l5: 0.093316, l6: 0.089895

[epoch:  19/100000, batch:     4/  187, ite: 1694] train loss: 0.868974, tar: 0.128947 
l0: 0.048154, l1: 0.053718, l2: 0.052979, l3: 0.052136, l4: 0.055149, l5: 0.054951, l6: 0.057705

[epoch:  19/100000, batch:     6/  187, ite: 1695] train loss: 0.868683, tar: 0.128900 
l0: 0.109390, l1: 0.125122, l2: 0.103679, l3: 0.113768, l4: 0.099872, l5: 0.102350, l6: 0.123185

[epoch:  19/100000, batch:     8/  187, ite: 1696] train loss: 0.868629, tar: 0.128888 
l0: 0.089048, l1: 0.085039, l2: 0.082828, l3: 0.086364, l4: 0.094105, l5: 0.094035, l6: 0.091533

[epoch:  19/100000, batch:    10/  187, ite: 1697] train loss: 0.868484, tar: 0.128865 
l0: 0.062341, l1: 0.062895, l2: 0.072750, l3: 0.071493, l4: 0.067492, l5: 0.069323, l6: 0.074230

[epoch:  19/100000, batch:    12/  187, ite: 1698] train loss: 0.868256, tar: 0.128825 
l0: 0.095840, l1: 0.091563, l2: 0.102628, l3: 0.105585, l4: 0.106926, l5: 0.103185, l6: 0.112359

[epoch:  19/100000, batch:    14/  187, ite: 1699] train loss: 0.868167, tar: 0.128806 
l0: 0.071856, l1: 0.061597, l2: 0.073506, l3: 0.080557, l4: 0.082333, l5: 0.082114, l6: 0.078590

[epoch:  19/100000, batch:    16/  187, ite: 1700] train loss: 0.867969, tar: 0.128773 
l0: 0.100999, l1: 0.096484, l2: 0.095821, l3: 0.113969, l4: 0.101881, l5: 0.104613, l6: 0.104831

[epoch:  19/100000, batch:    18/  187, ite: 1701] train loss: 0.867881, tar: 0.128756 
l0: 0.070100, l1: 0.064903, l2: 0.064943, l3: 0.068328, l4: 0.089998, l5: 0.094992, l6: 0.077167

[epoch:  19/100000, batch:    20/  187, ite: 1702] train loss: 0.867683, tar: 0.128722 
l0: 0.075101, l1: 0.065082, l2: 0.066000, l3: 0.062888, l4: 0.089273, l5: 0.091942, l6: 0.099431

[epoch:  19/100000, batch:    22/  187, ite: 1703] train loss: 0.867496, tar: 0.128690 
l0: 0.057375, l1: 0.056546, l2: 0.079432, l3: 0.079380, l4: 0.073728, l5: 0.070490, l6: 0.077639

[epoch:  19/100000, batch:    24/  187, ite: 1704] train loss: 0.867277, tar: 0.128648 
l0: 0.079896, l1: 0.075745, l2: 0.081129, l3: 0.090333, l4: 0.073091, l5: 0.084867, l6: 0.089573

[epoch:  19/100000, batch:    26/  187, ite: 1705] train loss: 0.867105, tar: 0.128620 
l0: 0.079534, l1: 0.107023, l2: 0.089479, l3: 0.083497, l4: 0.104763, l5: 0.085272, l6: 0.070077

[epoch:  19/100000, batch:    28/  187, ite: 1706] train loss: 0.866960, tar: 0.128591 
l0: 0.046183, l1: 0.057304, l2: 0.052860, l3: 0.051054, l4: 0.056613, l5: 0.045971, l6: 0.048936

[epoch:  19/100000, batch:    30/  187, ite: 1707] train loss: 0.866663, tar: 0.128543 
l0: 0.050588, l1: 0.054447, l2: 0.060397, l3: 0.065199, l4: 0.052892, l5: 0.047105, l6: 0.058900

[epoch:  19/100000, batch:    32/  187, ite: 1708] train loss: 0.866383, tar: 0.128497 
l0: 0.062324, l1: 0.055008, l2: 0.058771, l3: 0.058183, l4: 0.069437, l5: 0.078668, l6: 0.078511

[epoch:  19/100000, batch:    34/  187, ite: 1709] train loss: 0.866146, tar: 0.128458 
l0: 0.149270, l1: 0.147598, l2: 0.168354, l3: 0.184326, l4: 0.200269, l5: 0.171543, l6: 0.193763

[epoch:  19/100000, batch:    36/  187, ite: 1710] train loss: 0.866350, tar: 0.128471 
l0: 0.066353, l1: 0.054849, l2: 0.071001, l3: 0.077041, l4: 0.079755, l5: 0.078480, l6: 0.087807

[epoch:  19/100000, batch:    38/  187, ite: 1711] train loss: 0.866145, tar: 0.128434 
l0: 0.080441, l1: 0.080026, l2: 0.081072, l3: 0.079177, l4: 0.108675, l5: 0.103203, l6: 0.097558

[epoch:  19/100000, batch:    40/  187, ite: 1712] train loss: 0.866007, tar: 0.128406 
l0: 0.119381, l1: 0.123674, l2: 0.115808, l3: 0.124691, l4: 0.129610, l5: 0.123078, l6: 0.132807

[epoch:  19/100000, batch:    42/  187, ite: 1713] train loss: 0.866009, tar: 0.128401 
l0: 0.158555, l1: 0.209039, l2: 0.121579, l3: 0.133522, l4: 0.154528, l5: 0.132396, l6: 0.144198

[epoch:  19/100000, batch:    44/  187, ite: 1714] train loss: 0.866119, tar: 0.128419 
l0: 0.098498, l1: 0.125695, l2: 0.102843, l3: 0.088039, l4: 0.108637, l5: 0.097616, l6: 0.084008

[epoch:  19/100000, batch:    46/  187, ite: 1715] train loss: 0.866025, tar: 0.128401 
l0: 0.051025, l1: 0.067142, l2: 0.053842, l3: 0.049845, l4: 0.049527, l5: 0.046850, l6: 0.041066

[epoch:  19/100000, batch:    48/  187, ite: 1716] train loss: 0.865730, tar: 0.128356 
l0: 0.073245, l1: 0.089043, l2: 0.096256, l3: 0.087522, l4: 0.093869, l5: 0.079457, l6: 0.067033

[epoch:  19/100000, batch:    50/  187, ite: 1717] train loss: 0.865567, tar: 0.128324 
l0: 0.035540, l1: 0.044927, l2: 0.040897, l3: 0.036740, l4: 0.038814, l5: 0.042587, l6: 0.041115

[epoch:  19/100000, batch:    52/  187, ite: 1718] train loss: 0.865226, tar: 0.128270 
l0: 0.071240, l1: 0.066864, l2: 0.085184, l3: 0.081388, l4: 0.088246, l5: 0.087836, l6: 0.067193

[epoch:  19/100000, batch:    54/  187, ite: 1719] train loss: 0.865042, tar: 0.128237 
l0: 0.114887, l1: 0.111905, l2: 0.133702, l3: 0.137148, l4: 0.192958, l5: 0.171308, l6: 0.133208

[epoch:  19/100000, batch:    56/  187, ite: 1720] train loss: 0.865117, tar: 0.128229 
l0: 0.104853, l1: 0.120547, l2: 0.111576, l3: 0.098695, l4: 0.119351, l5: 0.090949, l6: 0.093638

[epoch:  19/100000, batch:    58/  187, ite: 1721] train loss: 0.865045, tar: 0.128215 
l0: 0.096518, l1: 0.101530, l2: 0.104348, l3: 0.104402, l4: 0.132432, l5: 0.101714, l6: 0.081010

[epoch:  19/100000, batch:    60/  187, ite: 1722] train loss: 0.864961, tar: 0.128197 
l0: 0.082052, l1: 0.072637, l2: 0.085283, l3: 0.094775, l4: 0.159819, l5: 0.136700, l6: 0.123490

[epoch:  19/100000, batch:    62/  187, ite: 1723] train loss: 0.864897, tar: 0.128170 
l0: 0.097262, l1: 0.090885, l2: 0.098972, l3: 0.099493, l4: 0.102115, l5: 0.103834, l6: 0.126262

[epoch:  19/100000, batch:    64/  187, ite: 1724] train loss: 0.864813, tar: 0.128152 
l0: 0.115827, l1: 0.120481, l2: 0.127432, l3: 0.128897, l4: 0.167905, l5: 0.124977, l6: 0.113954

[epoch:  19/100000, batch:    66/  187, ite: 1725] train loss: 0.864833, tar: 0.128145 
l0: 0.067484, l1: 0.069772, l2: 0.065986, l3: 0.069201, l4: 0.072076, l5: 0.109863, l6: 0.067107

[epoch:  19/100000, batch:    68/  187, ite: 1726] train loss: 0.864634, tar: 0.128110 
l0: 0.071403, l1: 0.072731, l2: 0.063406, l3: 0.063792, l4: 0.080691, l5: 0.091335, l6: 0.073417

[epoch:  19/100000, batch:    70/  187, ite: 1727] train loss: 0.864432, tar: 0.128077 
l0: 0.104053, l1: 0.099194, l2: 0.107543, l3: 0.114883, l4: 0.127067, l5: 0.139989, l6: 0.120664

[epoch:  19/100000, batch:    72/  187, ite: 1728] train loss: 0.864403, tar: 0.128063 
l0: 0.084895, l1: 0.081819, l2: 0.092986, l3: 0.111010, l4: 0.118484, l5: 0.101619, l6: 0.112982

[epoch:  19/100000, batch:    74/  187, ite: 1729] train loss: 0.864310, tar: 0.128038 
l0: 0.096570, l1: 0.091680, l2: 0.096267, l3: 0.086474, l4: 0.112499, l5: 0.114661, l6: 0.105007

[epoch:  19/100000, batch:    76/  187, ite: 1730] train loss: 0.864217, tar: 0.128020 
l0: 0.105725, l1: 0.105284, l2: 0.116562, l3: 0.111917, l4: 0.121011, l5: 0.119256, l6: 0.112204

[epoch:  19/100000, batch:    78/  187, ite: 1731] train loss: 0.864175, tar: 0.128007 
l0: 0.052475, l1: 0.052051, l2: 0.063481, l3: 0.058922, l4: 0.078676, l5: 0.075124, l6: 0.060548

[epoch:  19/100000, batch:    80/  187, ite: 1732] train loss: 0.863931, tar: 0.127964 
l0: 0.080486, l1: 0.082461, l2: 0.090439, l3: 0.088318, l4: 0.091971, l5: 0.082799, l6: 0.088288

[epoch:  19/100000, batch:    82/  187, ite: 1733] train loss: 0.863781, tar: 0.127936 
l0: 0.103277, l1: 0.113793, l2: 0.102153, l3: 0.095088, l4: 0.128393, l5: 0.126055, l6: 0.113659

[epoch:  19/100000, batch:    84/  187, ite: 1734] train loss: 0.863735, tar: 0.127922 
l0: 0.109911, l1: 0.111219, l2: 0.115804, l3: 0.124131, l4: 0.127778, l5: 0.137379, l6: 0.130750

[epoch:  19/100000, batch:    86/  187, ite: 1735] train loss: 0.863731, tar: 0.127912 
l0: 0.108469, l1: 0.110781, l2: 0.114572, l3: 0.121479, l4: 0.122428, l5: 0.117230, l6: 0.107989

[epoch:  19/100000, batch:    88/  187, ite: 1736] train loss: 0.863696, tar: 0.127900 
l0: 0.082775, l1: 0.088927, l2: 0.095080, l3: 0.093182, l4: 0.101335, l5: 0.078187, l6: 0.073003

[epoch:  19/100000, batch:    90/  187, ite: 1737] train loss: 0.863551, tar: 0.127874 
l0: 0.100781, l1: 0.091149, l2: 0.106504, l3: 0.128116, l4: 0.117587, l5: 0.158377, l6: 0.139658

[epoch:  19/100000, batch:    92/  187, ite: 1738] train loss: 0.863539, tar: 0.127859 
l0: 0.091361, l1: 0.084528, l2: 0.092385, l3: 0.097044, l4: 0.118702, l5: 0.104157, l6: 0.116293

[epoch:  19/100000, batch:    94/  187, ite: 1739] train loss: 0.863447, tar: 0.127838 
l0: 0.085919, l1: 0.082687, l2: 0.085331, l3: 0.079602, l4: 0.087830, l5: 0.092333, l6: 0.070680

[epoch:  19/100000, batch:    96/  187, ite: 1740] train loss: 0.863287, tar: 0.127814 
l0: 0.071362, l1: 0.068859, l2: 0.077262, l3: 0.071510, l4: 0.079276, l5: 0.078645, l6: 0.074534

[epoch:  19/100000, batch:    98/  187, ite: 1741] train loss: 0.863090, tar: 0.127781 
l0: 0.132955, l1: 0.148623, l2: 0.142033, l3: 0.139658, l4: 0.140775, l5: 0.124975, l6: 0.127617

[epoch:  19/100000, batch:   100/  187, ite: 1742] train loss: 0.863144, tar: 0.127784 
l0: 0.100517, l1: 0.097616, l2: 0.110761, l3: 0.102630, l4: 0.100758, l5: 0.113750, l6: 0.109440

[epoch:  19/100000, batch:   102/  187, ite: 1743] train loss: 0.863071, tar: 0.127769 
l0: 0.087047, l1: 0.088056, l2: 0.077868, l3: 0.072793, l4: 0.092108, l5: 0.106831, l6: 0.087751

[epoch:  19/100000, batch:   104/  187, ite: 1744] train loss: 0.862927, tar: 0.127745 
l0: 0.103565, l1: 0.111280, l2: 0.097468, l3: 0.097674, l4: 0.099238, l5: 0.114741, l6: 0.094652

[epoch:  19/100000, batch:   106/  187, ite: 1745] train loss: 0.862845, tar: 0.127731 
l0: 0.107040, l1: 0.114368, l2: 0.120547, l3: 0.112975, l4: 0.107079, l5: 0.111592, l6: 0.110931

[epoch:  19/100000, batch:   108/  187, ite: 1746] train loss: 0.862800, tar: 0.127720 
l0: 0.101319, l1: 0.100374, l2: 0.097133, l3: 0.099615, l4: 0.124353, l5: 0.128710, l6: 0.117341

[epoch:  19/100000, batch:   110/  187, ite: 1747] train loss: 0.862746, tar: 0.127704 
l0: 0.150014, l1: 0.152899, l2: 0.165062, l3: 0.160366, l4: 0.176687, l5: 0.167828, l6: 0.174257

[epoch:  19/100000, batch:   112/  187, ite: 1748] train loss: 0.862909, tar: 0.127717 
l0: 0.068473, l1: 0.059314, l2: 0.073612, l3: 0.077752, l4: 0.111337, l5: 0.103452, l6: 0.133581

[epoch:  19/100000, batch:   114/  187, ite: 1749] train loss: 0.862774, tar: 0.127683 
l0: 0.049917, l1: 0.058375, l2: 0.057505, l3: 0.047971, l4: 0.055949, l5: 0.062715, l6: 0.050988

[epoch:  19/100000, batch:   116/  187, ite: 1750] train loss: 0.862500, tar: 0.127639 
l0: 0.082403, l1: 0.081488, l2: 0.087759, l3: 0.084018, l4: 0.097405, l5: 0.103152, l6: 0.100172

[epoch:  19/100000, batch:   118/  187, ite: 1751] train loss: 0.862371, tar: 0.127613 
l0: 0.056597, l1: 0.072616, l2: 0.060074, l3: 0.053666, l4: 0.059353, l5: 0.060429, l6: 0.050426

[epoch:  19/100000, batch:   120/  187, ite: 1752] train loss: 0.862115, tar: 0.127573 
l0: 0.122389, l1: 0.096124, l2: 0.123022, l3: 0.131914, l4: 0.155761, l5: 0.154686, l6: 0.202323

[epoch:  19/100000, batch:   122/  187, ite: 1753] train loss: 0.862185, tar: 0.127570 
l0: 0.124794, l1: 0.122831, l2: 0.138079, l3: 0.143139, l4: 0.172110, l5: 0.149613, l6: 0.171086

[epoch:  19/100000, batch:   124/  187, ite: 1754] train loss: 0.862276, tar: 0.127568 
l0: 0.079319, l1: 0.068201, l2: 0.078036, l3: 0.073946, l4: 0.094031, l5: 0.122249, l6: 0.107471

[epoch:  19/100000, batch:   126/  187, ite: 1755] train loss: 0.862140, tar: 0.127541 
l0: 0.078197, l1: 0.074599, l2: 0.069511, l3: 0.068654, l4: 0.078063, l5: 0.089560, l6: 0.099497

[epoch:  19/100000, batch:   128/  187, ite: 1756] train loss: 0.861967, tar: 0.127512 
l0: 0.077618, l1: 0.066519, l2: 0.079992, l3: 0.082947, l4: 0.076839, l5: 0.105084, l6: 0.093871

[epoch:  19/100000, batch:   130/  187, ite: 1757] train loss: 0.861808, tar: 0.127484 
l0: 0.063558, l1: 0.074936, l2: 0.065769, l3: 0.068390, l4: 0.060313, l5: 0.064318, l6: 0.061941

[epoch:  19/100000, batch:   132/  187, ite: 1758] train loss: 0.861579, tar: 0.127448 
l0: 0.091459, l1: 0.098224, l2: 0.086599, l3: 0.089145, l4: 0.090439, l5: 0.093293, l6: 0.080507

[epoch:  19/100000, batch:   134/  187, ite: 1759] train loss: 0.861447, tar: 0.127427 
l0: 0.067512, l1: 0.059291, l2: 0.075717, l3: 0.071384, l4: 0.087839, l5: 0.087398, l6: 0.099386

[epoch:  19/100000, batch:   136/  187, ite: 1760] train loss: 0.861269, tar: 0.127393 
l0: 0.061410, l1: 0.054788, l2: 0.066100, l3: 0.069914, l4: 0.072446, l5: 0.083512, l6: 0.091141

[epoch:  19/100000, batch:   138/  187, ite: 1761] train loss: 0.861064, tar: 0.127356 
l0: 0.087103, l1: 0.080347, l2: 0.104477, l3: 0.101558, l4: 0.115624, l5: 0.103138, l6: 0.109396

[epoch:  19/100000, batch:   140/  187, ite: 1762] train loss: 0.860973, tar: 0.127333 
l0: 0.083338, l1: 0.086520, l2: 0.083173, l3: 0.078021, l4: 0.095478, l5: 0.089125, l6: 0.081414

[epoch:  19/100000, batch:   142/  187, ite: 1763] train loss: 0.860824, tar: 0.127308 
l0: 0.066439, l1: 0.059112, l2: 0.067906, l3: 0.076184, l4: 0.095491, l5: 0.100004, l6: 0.098689

[epoch:  19/100000, batch:   144/  187, ite: 1764] train loss: 0.860655, tar: 0.127273 
l0: 0.102957, l1: 0.096833, l2: 0.129692, l3: 0.123330, l4: 0.117889, l5: 0.113172, l6: 0.125839

[epoch:  19/100000, batch:   146/  187, ite: 1765] train loss: 0.860626, tar: 0.127260 
l0: 0.099295, l1: 0.089954, l2: 0.104679, l3: 0.099703, l4: 0.111593, l5: 0.118920, l6: 0.128335

[epoch:  19/100000, batch:   148/  187, ite: 1766] train loss: 0.860565, tar: 0.127244 
l0: 0.058908, l1: 0.067818, l2: 0.057256, l3: 0.062665, l4: 0.068694, l5: 0.063341, l6: 0.057568

[epoch:  19/100000, batch:   150/  187, ite: 1767] train loss: 0.860325, tar: 0.127205 
l0: 0.095439, l1: 0.094117, l2: 0.089611, l3: 0.091892, l4: 0.088532, l5: 0.105839, l6: 0.110879

[epoch:  19/100000, batch:   152/  187, ite: 1768] train loss: 0.860221, tar: 0.127187 
l0: 0.050150, l1: 0.047832, l2: 0.049586, l3: 0.048871, l4: 0.062068, l5: 0.068733, l6: 0.065484

[epoch:  19/100000, batch:   154/  187, ite: 1769] train loss: 0.859957, tar: 0.127144 
l0: 0.072759, l1: 0.070510, l2: 0.075937, l3: 0.072849, l4: 0.082348, l5: 0.093856, l6: 0.093902

[epoch:  19/100000, batch:   156/  187, ite: 1770] train loss: 0.859789, tar: 0.127113 
l0: 0.095749, l1: 0.080065, l2: 0.105698, l3: 0.099351, l4: 0.127934, l5: 0.141642, l6: 0.141866

[epoch:  19/100000, batch:   158/  187, ite: 1771] train loss: 0.859750, tar: 0.127095 
l0: 0.061250, l1: 0.057861, l2: 0.067323, l3: 0.068132, l4: 0.065322, l5: 0.064857, l6: 0.069856

[epoch:  19/100000, batch:   160/  187, ite: 1772] train loss: 0.859522, tar: 0.127058 
l0: 0.083122, l1: 0.079875, l2: 0.079589, l3: 0.078335, l4: 0.111407, l5: 0.130819, l6: 0.119113

[epoch:  19/100000, batch:   162/  187, ite: 1773] train loss: 0.859422, tar: 0.127033 
l0: 0.088756, l1: 0.090921, l2: 0.092380, l3: 0.098115, l4: 0.101160, l5: 0.094139, l6: 0.094850

[epoch:  19/100000, batch:   164/  187, ite: 1774] train loss: 0.859310, tar: 0.127012 
l0: 0.063266, l1: 0.064735, l2: 0.069094, l3: 0.071775, l4: 0.081232, l5: 0.084960, l6: 0.084469

[epoch:  19/100000, batch:   166/  187, ite: 1775] train loss: 0.859118, tar: 0.126976 
l0: 0.068999, l1: 0.066995, l2: 0.103686, l3: 0.103157, l4: 0.084764, l5: 0.091243, l6: 0.090467

[epoch:  19/100000, batch:   168/  187, ite: 1776] train loss: 0.858977, tar: 0.126943 
l0: 0.095021, l1: 0.091533, l2: 0.102815, l3: 0.108991, l4: 0.108946, l5: 0.110862, l6: 0.117786

[epoch:  19/100000, batch:   170/  187, ite: 1777] train loss: 0.858908, tar: 0.126925 
l0: 0.059368, l1: 0.086849, l2: 0.070050, l3: 0.064677, l4: 0.060279, l5: 0.060367, l6: 0.062045

[epoch:  19/100000, batch:   172/  187, ite: 1778] train loss: 0.858686, tar: 0.126887 
l0: 0.092227, l1: 0.093249, l2: 0.099933, l3: 0.105868, l4: 0.082981, l5: 0.091711, l6: 0.093139

[epoch:  19/100000, batch:   174/  187, ite: 1779] train loss: 0.858574, tar: 0.126868 
l0: 0.082075, l1: 0.083111, l2: 0.120069, l3: 0.123110, l4: 0.111784, l5: 0.095742, l6: 0.111486

[epoch:  19/100000, batch:   176/  187, ite: 1780] train loss: 0.858500, tar: 0.126842 
l0: 0.092737, l1: 0.097656, l2: 0.101387, l3: 0.110409, l4: 0.118640, l5: 0.108013, l6: 0.092956

[epoch:  19/100000, batch:   178/  187, ite: 1781] train loss: 0.858423, tar: 0.126823 
l0: 0.083667, l1: 0.082382, l2: 0.079094, l3: 0.081078, l4: 0.086447, l5: 0.099657, l6: 0.090922

[epoch:  19/100000, batch:   180/  187, ite: 1782] train loss: 0.858280, tar: 0.126799 
l0: 0.109983, l1: 0.102911, l2: 0.110642, l3: 0.120466, l4: 0.117262, l5: 0.138315, l6: 0.140285

[epoch:  19/100000, batch:   182/  187, ite: 1783] train loss: 0.858270, tar: 0.126790 
l0: 0.115067, l1: 0.115368, l2: 0.108273, l3: 0.104902, l4: 0.120162, l5: 0.128241, l6: 0.121151

[epoch:  19/100000, batch:   184/  187, ite: 1784] train loss: 0.858244, tar: 0.126783 
l0: 0.074112, l1: 0.070573, l2: 0.098376, l3: 0.098222, l4: 0.083723, l5: 0.087078, l6: 0.098033

[epoch:  19/100000, batch:   186/  187, ite: 1785] train loss: 0.858105, tar: 0.126754 
l0: 0.106628, l1: 0.119800, l2: 0.109211, l3: 0.109992, l4: 0.079539, l5: 0.099970, l6: 0.101543

[epoch:  19/100000, batch:   188/  187, ite: 1786] train loss: 0.858032, tar: 0.126742 
l0: 0.074348, l1: 0.084698, l2: 0.078538, l3: 0.079667, l4: 0.090424, l5: 0.079731, l6: 0.077735

[epoch:  20/100000, batch:     2/  187, ite: 1787] train loss: 0.857868, tar: 0.126713 
l0: 0.062340, l1: 0.070191, l2: 0.066959, l3: 0.060354, l4: 0.080265, l5: 0.066583, l6: 0.061766

[epoch:  20/100000, batch:     4/  187, ite: 1788] train loss: 0.857650, tar: 0.126677 
l0: 0.082420, l1: 0.070437, l2: 0.093205, l3: 0.099405, l4: 0.100510, l5: 0.108339, l6: 0.094991

[epoch:  20/100000, batch:     6/  187, ite: 1789] train loss: 0.857534, tar: 0.126652 
l0: 0.057960, l1: 0.057159, l2: 0.058269, l3: 0.058932, l4: 0.065820, l5: 0.063697, l6: 0.076191

[epoch:  20/100000, batch:     8/  187, ite: 1790] train loss: 0.857299, tar: 0.126614 
l0: 0.068654, l1: 0.062584, l2: 0.073252, l3: 0.074886, l4: 0.082836, l5: 0.081644, l6: 0.081979

[epoch:  20/100000, batch:    10/  187, ite: 1791] train loss: 0.857114, tar: 0.126582 
l0: 0.075074, l1: 0.072876, l2: 0.080218, l3: 0.087091, l4: 0.078442, l5: 0.094704, l6: 0.085947

[epoch:  20/100000, batch:    12/  187, ite: 1792] train loss: 0.856957, tar: 0.126553 
l0: 0.086464, l1: 0.075819, l2: 0.080558, l3: 0.084043, l4: 0.094642, l5: 0.112940, l6: 0.098664

[epoch:  20/100000, batch:    14/  187, ite: 1793] train loss: 0.856832, tar: 0.126530 
l0: 0.035827, l1: 0.036869, l2: 0.040686, l3: 0.045437, l4: 0.048771, l5: 0.051544, l6: 0.044338

[epoch:  20/100000, batch:    16/  187, ite: 1794] train loss: 0.856523, tar: 0.126480 
l0: 0.103610, l1: 0.109435, l2: 0.102557, l3: 0.094830, l4: 0.115443, l5: 0.130907, l6: 0.127529

[epoch:  20/100000, batch:    18/  187, ite: 1795] train loss: 0.856483, tar: 0.126467 
l0: 0.068796, l1: 0.060471, l2: 0.076508, l3: 0.080734, l4: 0.102521, l5: 0.095562, l6: 0.096226

[epoch:  20/100000, batch:    20/  187, ite: 1796] train loss: 0.856330, tar: 0.126435 
l0: 0.142680, l1: 0.155110, l2: 0.154501, l3: 0.165764, l4: 0.158776, l5: 0.136270, l6: 0.136329

[epoch:  20/100000, batch:    22/  187, ite: 1797] train loss: 0.856437, tar: 0.126444 
l0: 0.059925, l1: 0.057930, l2: 0.074653, l3: 0.075912, l4: 0.075081, l5: 0.074105, l6: 0.077515

[epoch:  20/100000, batch:    24/  187, ite: 1798] train loss: 0.856236, tar: 0.126407 
l0: 0.073612, l1: 0.066221, l2: 0.076452, l3: 0.078117, l4: 0.090626, l5: 0.087788, l6: 0.096561

[epoch:  20/100000, batch:    26/  187, ite: 1799] train loss: 0.856077, tar: 0.126378 
l0: 0.118518, l1: 0.106412, l2: 0.104862, l3: 0.120292, l4: 0.126056, l5: 0.140435, l6: 0.148319

[epoch:  20/100000, batch:    28/  187, ite: 1800] train loss: 0.856081, tar: 0.126373 
l0: 0.049283, l1: 0.054552, l2: 0.055121, l3: 0.053483, l4: 0.066278, l5: 0.053939, l6: 0.050552

[epoch:  20/100000, batch:    30/  187, ite: 1801] train loss: 0.855819, tar: 0.126331 
l0: 0.082335, l1: 0.085232, l2: 0.092776, l3: 0.098346, l4: 0.091731, l5: 0.100012, l6: 0.093743

[epoch:  20/100000, batch:    32/  187, ite: 1802] train loss: 0.855701, tar: 0.126306 
l0: 0.052485, l1: 0.059014, l2: 0.052708, l3: 0.047543, l4: 0.076520, l5: 0.057576, l6: 0.075307

[epoch:  20/100000, batch:    34/  187, ite: 1803] train loss: 0.855460, tar: 0.126265 
l0: 0.105123, l1: 0.100430, l2: 0.119151, l3: 0.117332, l4: 0.155501, l5: 0.151783, l6: 0.161438

[epoch:  20/100000, batch:    36/  187, ite: 1804] train loss: 0.855491, tar: 0.126253 
l0: 0.086253, l1: 0.082036, l2: 0.083776, l3: 0.092264, l4: 0.096264, l5: 0.090902, l6: 0.096401

[epoch:  20/100000, batch:    38/  187, ite: 1805] train loss: 0.855365, tar: 0.126231 
l0: 0.098488, l1: 0.104731, l2: 0.100214, l3: 0.100785, l4: 0.096546, l5: 0.105400, l6: 0.109352

[epoch:  20/100000, batch:    40/  187, ite: 1806] train loss: 0.855288, tar: 0.126216 
l0: 0.098277, l1: 0.095386, l2: 0.096847, l3: 0.101267, l4: 0.124181, l5: 0.115869, l6: 0.116858

[epoch:  20/100000, batch:    42/  187, ite: 1807] train loss: 0.855229, tar: 0.126200 
l0: 0.063659, l1: 0.059660, l2: 0.063568, l3: 0.066476, l4: 0.092732, l5: 0.086008, l6: 0.083026

[epoch:  20/100000, batch:    44/  187, ite: 1808] train loss: 0.855040, tar: 0.126166 
l0: 0.112627, l1: 0.119359, l2: 0.123889, l3: 0.124037, l4: 0.119265, l5: 0.111224, l6: 0.104392

[epoch:  20/100000, batch:    46/  187, ite: 1809] train loss: 0.855018, tar: 0.126158 
l0: 0.081741, l1: 0.082842, l2: 0.080452, l3: 0.079053, l4: 0.090438, l5: 0.081755, l6: 0.088437

[epoch:  20/100000, batch:    48/  187, ite: 1810] train loss: 0.854869, tar: 0.126134 
l0: 0.066596, l1: 0.056508, l2: 0.076825, l3: 0.081500, l4: 0.089706, l5: 0.085782, l6: 0.094009

[epoch:  20/100000, batch:    50/  187, ite: 1811] train loss: 0.854701, tar: 0.126101 
l0: 0.058874, l1: 0.052823, l2: 0.063293, l3: 0.065765, l4: 0.071059, l5: 0.071240, l6: 0.065743

[epoch:  20/100000, batch:    52/  187, ite: 1812] train loss: 0.854477, tar: 0.126064 
l0: 0.052042, l1: 0.058911, l2: 0.052929, l3: 0.056208, l4: 0.059713, l5: 0.059028, l6: 0.065521

[epoch:  20/100000, batch:    54/  187, ite: 1813] train loss: 0.854229, tar: 0.126023 
l0: 0.104978, l1: 0.112251, l2: 0.100469, l3: 0.096617, l4: 0.111771, l5: 0.107869, l6: 0.106056

[epoch:  20/100000, batch:    56/  187, ite: 1814] train loss: 0.854166, tar: 0.126011 
l0: 0.107410, l1: 0.113282, l2: 0.097232, l3: 0.095420, l4: 0.103665, l5: 0.100738, l6: 0.094977

[epoch:  20/100000, batch:    58/  187, ite: 1815] train loss: 0.854088, tar: 0.126001 
l0: 0.067604, l1: 0.087756, l2: 0.073278, l3: 0.073759, l4: 0.063049, l5: 0.061204, l6: 0.064369

[epoch:  20/100000, batch:    60/  187, ite: 1816] train loss: 0.853888, tar: 0.125969 
l0: 0.068013, l1: 0.057745, l2: 0.065502, l3: 0.071441, l4: 0.097955, l5: 0.100994, l6: 0.106018

[epoch:  20/100000, batch:    62/  187, ite: 1817] train loss: 0.853730, tar: 0.125937 
l0: 0.104569, l1: 0.114921, l2: 0.093333, l3: 0.095050, l4: 0.102221, l5: 0.101629, l6: 0.105680

[epoch:  20/100000, batch:    64/  187, ite: 1818] train loss: 0.853655, tar: 0.125925 
l0: 0.090830, l1: 0.097397, l2: 0.089277, l3: 0.090286, l4: 0.094119, l5: 0.089514, l6: 0.091964

[epoch:  20/100000, batch:    66/  187, ite: 1819] train loss: 0.853540, tar: 0.125906 
l0: 0.045766, l1: 0.050606, l2: 0.048680, l3: 0.047209, l4: 0.068492, l5: 0.062536, l6: 0.057536

[epoch:  20/100000, batch:    68/  187, ite: 1820] train loss: 0.853280, tar: 0.125862 
l0: 0.107441, l1: 0.112001, l2: 0.124070, l3: 0.126425, l4: 0.113690, l5: 0.124703, l6: 0.111737

[epoch:  20/100000, batch:    70/  187, ite: 1821] train loss: 0.853262, tar: 0.125852 
l0: 0.112953, l1: 0.111266, l2: 0.121049, l3: 0.106789, l4: 0.133683, l5: 0.116567, l6: 0.126591

[epoch:  20/100000, batch:    72/  187, ite: 1822] train loss: 0.853248, tar: 0.125845 
l0: 0.055548, l1: 0.047580, l2: 0.048471, l3: 0.054493, l4: 0.082610, l5: 0.081912, l6: 0.076661

[epoch:  20/100000, batch:    74/  187, ite: 1823] train loss: 0.853026, tar: 0.125806 
l0: 0.086413, l1: 0.082534, l2: 0.074088, l3: 0.072744, l4: 0.106434, l5: 0.115522, l6: 0.106212

[epoch:  20/100000, batch:    76/  187, ite: 1824] train loss: 0.852911, tar: 0.125785 
l0: 0.104757, l1: 0.110939, l2: 0.148857, l3: 0.129690, l4: 0.112659, l5: 0.114972, l6: 0.103694

[epoch:  20/100000, batch:    78/  187, ite: 1825] train loss: 0.852896, tar: 0.125773 
l0: 0.072102, l1: 0.069711, l2: 0.077422, l3: 0.081104, l4: 0.067041, l5: 0.076043, l6: 0.069450

[epoch:  20/100000, batch:    80/  187, ite: 1826] train loss: 0.852710, tar: 0.125744 
l0: 0.078647, l1: 0.086904, l2: 0.091128, l3: 0.081171, l4: 0.096183, l5: 0.084887, l6: 0.077713

[epoch:  20/100000, batch:    82/  187, ite: 1827] train loss: 0.852570, tar: 0.125718 
l0: 0.063022, l1: 0.060271, l2: 0.068905, l3: 0.067141, l4: 0.077459, l5: 0.076979, l6: 0.073228

[epoch:  20/100000, batch:    84/  187, ite: 1828] train loss: 0.852370, tar: 0.125684 
l0: 0.065644, l1: 0.072037, l2: 0.072190, l3: 0.068834, l4: 0.071921, l5: 0.077283, l6: 0.070529

[epoch:  20/100000, batch:    86/  187, ite: 1829] train loss: 0.852176, tar: 0.125651 
l0: 0.069222, l1: 0.069199, l2: 0.068635, l3: 0.072242, l4: 0.058545, l5: 0.072312, l6: 0.061658

[epoch:  20/100000, batch:    88/  187, ite: 1830] train loss: 0.851968, tar: 0.125620 
l0: 0.057540, l1: 0.056501, l2: 0.061244, l3: 0.065745, l4: 0.073825, l5: 0.070585, l6: 0.067999

[epoch:  20/100000, batch:    90/  187, ite: 1831] train loss: 0.851751, tar: 0.125583 
l0: 0.075112, l1: 0.064288, l2: 0.076531, l3: 0.084727, l4: 0.091505, l5: 0.097921, l6: 0.093670

[epoch:  20/100000, batch:    92/  187, ite: 1832] train loss: 0.851605, tar: 0.125555 
l0: 0.077269, l1: 0.081403, l2: 0.097765, l3: 0.101740, l4: 0.075273, l5: 0.071731, l6: 0.080573

[epoch:  20/100000, batch:    94/  187, ite: 1833] train loss: 0.851459, tar: 0.125529 
l0: 0.075798, l1: 0.070332, l2: 0.078410, l3: 0.083578, l4: 0.075465, l5: 0.081848, l6: 0.086324

[epoch:  20/100000, batch:    96/  187, ite: 1834] train loss: 0.851296, tar: 0.125502 
l0: 0.054308, l1: 0.057986, l2: 0.060391, l3: 0.065537, l4: 0.048032, l5: 0.061817, l6: 0.060948

[epoch:  20/100000, batch:    98/  187, ite: 1835] train loss: 0.851055, tar: 0.125463 
l0: 0.126555, l1: 0.140078, l2: 0.130633, l3: 0.159459, l4: 0.123907, l5: 0.106645, l6: 0.120401

[epoch:  20/100000, batch:   100/  187, ite: 1836] train loss: 0.851086, tar: 0.125464 
l0: 0.076643, l1: 0.073568, l2: 0.081466, l3: 0.081116, l4: 0.084473, l5: 0.081463, l6: 0.088794

[epoch:  20/100000, batch:   102/  187, ite: 1837] train loss: 0.850932, tar: 0.125437 
l0: 0.059928, l1: 0.068897, l2: 0.069496, l3: 0.064867, l4: 0.072621, l5: 0.070978, l6: 0.070195

[epoch:  20/100000, batch:   104/  187, ite: 1838] train loss: 0.850728, tar: 0.125401 
l0: 0.073704, l1: 0.068561, l2: 0.072288, l3: 0.072560, l4: 0.079124, l5: 0.093485, l6: 0.083414

[epoch:  20/100000, batch:   106/  187, ite: 1839] train loss: 0.850561, tar: 0.125373 
l0: 0.078169, l1: 0.081834, l2: 0.094853, l3: 0.096075, l4: 0.086991, l5: 0.099123, l6: 0.090755

[epoch:  20/100000, batch:   108/  187, ite: 1840] train loss: 0.850440, tar: 0.125348 
l0: 0.087668, l1: 0.085600, l2: 0.086472, l3: 0.088455, l4: 0.098401, l5: 0.112056, l6: 0.096142

[epoch:  20/100000, batch:   110/  187, ite: 1841] train loss: 0.850333, tar: 0.125327 
l0: 0.089457, l1: 0.079554, l2: 0.077695, l3: 0.093510, l4: 0.099964, l5: 0.122814, l6: 0.124680

[epoch:  20/100000, batch:   112/  187, ite: 1842] train loss: 0.850245, tar: 0.125308 
l0: 0.058659, l1: 0.054839, l2: 0.057490, l3: 0.058698, l4: 0.055273, l5: 0.066672, l6: 0.055775

[epoch:  20/100000, batch:   114/  187, ite: 1843] train loss: 0.850005, tar: 0.125272 
l0: 0.058001, l1: 0.076509, l2: 0.059141, l3: 0.057431, l4: 0.054264, l5: 0.057025, l6: 0.049985

[epoch:  20/100000, batch:   116/  187, ite: 1844] train loss: 0.849768, tar: 0.125235 
l0: 0.130682, l1: 0.129604, l2: 0.129848, l3: 0.125904, l4: 0.153238, l5: 0.169086, l6: 0.168244

[epoch:  20/100000, batch:   118/  187, ite: 1845] train loss: 0.849853, tar: 0.125238 
l0: 0.082943, l1: 0.075421, l2: 0.086940, l3: 0.079409, l4: 0.091595, l5: 0.102025, l6: 0.097734

[epoch:  20/100000, batch:   120/  187, ite: 1846] train loss: 0.849726, tar: 0.125215 
l0: 0.066550, l1: 0.066572, l2: 0.073642, l3: 0.066335, l4: 0.064116, l5: 0.087195, l6: 0.070119

[epoch:  20/100000, batch:   122/  187, ite: 1847] train loss: 0.849534, tar: 0.125183 
l0: 0.065977, l1: 0.071896, l2: 0.061966, l3: 0.061756, l4: 0.089810, l5: 0.084553, l6: 0.085239

[epoch:  20/100000, batch:   124/  187, ite: 1848] train loss: 0.849356, tar: 0.125151 
l0: 0.032178, l1: 0.032470, l2: 0.032727, l3: 0.037094, l4: 0.042889, l5: 0.036805, l6: 0.033708

[epoch:  20/100000, batch:   126/  187, ite: 1849] train loss: 0.849031, tar: 0.125101 
l0: 0.074702, l1: 0.064802, l2: 0.064934, l3: 0.075558, l4: 0.098550, l5: 0.105882, l6: 0.113853

[epoch:  20/100000, batch:   128/  187, ite: 1850] train loss: 0.848895, tar: 0.125074 
l0: 0.156809, l1: 0.161792, l2: 0.176684, l3: 0.164059, l4: 0.123412, l5: 0.163480, l6: 0.162276

[epoch:  20/100000, batch:   130/  187, ite: 1851] train loss: 0.849035, tar: 0.125091 
l0: 0.049414, l1: 0.049304, l2: 0.056882, l3: 0.053646, l4: 0.061274, l5: 0.060469, l6: 0.064574

[epoch:  20/100000, batch:   132/  187, ite: 1852] train loss: 0.848790, tar: 0.125050 
l0: 0.116844, l1: 0.118147, l2: 0.115640, l3: 0.136070, l4: 0.141134, l5: 0.138031, l6: 0.150946

[epoch:  20/100000, batch:   134/  187, ite: 1853] train loss: 0.848827, tar: 0.125046 
l0: 0.059557, l1: 0.068227, l2: 0.071128, l3: 0.074788, l4: 0.067659, l5: 0.084804, l6: 0.073308

[epoch:  20/100000, batch:   136/  187, ite: 1854] train loss: 0.848639, tar: 0.125010 
l0: 0.083526, l1: 0.077115, l2: 0.096807, l3: 0.117754, l4: 0.103213, l5: 0.087898, l6: 0.096680

[epoch:  20/100000, batch:   138/  187, ite: 1855] train loss: 0.848539, tar: 0.124988 
l0: 0.154130, l1: 0.160701, l2: 0.157999, l3: 0.159039, l4: 0.190905, l5: 0.168713, l6: 0.201657

[epoch:  20/100000, batch:   140/  187, ite: 1856] train loss: 0.848724, tar: 0.125004 
l0: 0.091955, l1: 0.089076, l2: 0.099551, l3: 0.095734, l4: 0.101869, l5: 0.105329, l6: 0.110428

[epoch:  20/100000, batch:   142/  187, ite: 1857] train loss: 0.848641, tar: 0.124986 
l0: 0.097570, l1: 0.104663, l2: 0.118823, l3: 0.113625, l4: 0.110408, l5: 0.097753, l6: 0.090127

[epoch:  20/100000, batch:   144/  187, ite: 1858] train loss: 0.848579, tar: 0.124971 
l0: 0.075754, l1: 0.070837, l2: 0.078927, l3: 0.079512, l4: 0.102880, l5: 0.090109, l6: 0.086354

[epoch:  20/100000, batch:   146/  187, ite: 1859] train loss: 0.848437, tar: 0.124945 
l0: 0.092241, l1: 0.100636, l2: 0.079185, l3: 0.081509, l4: 0.098411, l5: 0.103779, l6: 0.114127

[epoch:  20/100000, batch:   148/  187, ite: 1860] train loss: 0.848341, tar: 0.124927 
l0: 0.078520, l1: 0.083162, l2: 0.084768, l3: 0.082879, l4: 0.084569, l5: 0.096407, l6: 0.110979

[epoch:  20/100000, batch:   150/  187, ite: 1861] train loss: 0.848219, tar: 0.124902 
l0: 0.122528, l1: 0.140784, l2: 0.123149, l3: 0.119359, l4: 0.115990, l5: 0.117526, l6: 0.121633

[epoch:  20/100000, batch:   152/  187, ite: 1862] train loss: 0.848225, tar: 0.124901 
l0: 0.080153, l1: 0.079466, l2: 0.081699, l3: 0.074022, l4: 0.090505, l5: 0.085789, l6: 0.082957

[epoch:  20/100000, batch:   154/  187, ite: 1863] train loss: 0.848079, tar: 0.124877 
l0: 0.077640, l1: 0.075581, l2: 0.073578, l3: 0.077443, l4: 0.092108, l5: 0.105012, l6: 0.127141

[epoch:  20/100000, batch:   156/  187, ite: 1864] train loss: 0.847961, tar: 0.124852 
l0: 0.101130, l1: 0.100848, l2: 0.110498, l3: 0.131027, l4: 0.137988, l5: 0.144013, l6: 0.101556

[epoch:  20/100000, batch:   158/  187, ite: 1865] train loss: 0.847950, tar: 0.124839 
l0: 0.070199, l1: 0.064964, l2: 0.075474, l3: 0.071098, l4: 0.095525, l5: 0.095694, l6: 0.091860

[epoch:  20/100000, batch:   160/  187, ite: 1866] train loss: 0.847798, tar: 0.124810 
l0: 0.079259, l1: 0.066850, l2: 0.080085, l3: 0.079806, l4: 0.103363, l5: 0.125711, l6: 0.109590

[epoch:  20/100000, batch:   162/  187, ite: 1867] train loss: 0.847689, tar: 0.124785 
l0: 0.101021, l1: 0.108769, l2: 0.087277, l3: 0.087940, l4: 0.100254, l5: 0.104484, l6: 0.105892

[epoch:  20/100000, batch:   164/  187, ite: 1868] train loss: 0.847608, tar: 0.124772 
l0: 0.094453, l1: 0.086822, l2: 0.096465, l3: 0.100802, l4: 0.115347, l5: 0.122127, l6: 0.108073

[epoch:  20/100000, batch:   166/  187, ite: 1869] train loss: 0.847542, tar: 0.124756 
l0: 0.081372, l1: 0.086799, l2: 0.071548, l3: 0.071646, l4: 0.081619, l5: 0.083461, l6: 0.093799

[epoch:  20/100000, batch:   168/  187, ite: 1870] train loss: 0.847393, tar: 0.124733 
l0: 0.070295, l1: 0.069400, l2: 0.072319, l3: 0.078481, l4: 0.090672, l5: 0.080321, l6: 0.088016

[epoch:  20/100000, batch:   170/  187, ite: 1871] train loss: 0.847234, tar: 0.124704 
l0: 0.117586, l1: 0.118360, l2: 0.126765, l3: 0.119031, l4: 0.129901, l5: 0.129131, l6: 0.146885

[epoch:  20/100000, batch:   172/  187, ite: 1872] train loss: 0.847256, tar: 0.124700 
l0: 0.070376, l1: 0.066680, l2: 0.070861, l3: 0.077988, l4: 0.094506, l5: 0.089072, l6: 0.111177

[epoch:  20/100000, batch:   174/  187, ite: 1873] train loss: 0.847113, tar: 0.124671 
l0: 0.105905, l1: 0.102422, l2: 0.107577, l3: 0.107301, l4: 0.123515, l5: 0.126321, l6: 0.125236

[epoch:  20/100000, batch:   176/  187, ite: 1874] train loss: 0.847087, tar: 0.124661 
l0: 0.133401, l1: 0.128809, l2: 0.131010, l3: 0.128213, l4: 0.182825, l5: 0.178972, l6: 0.178887

[epoch:  20/100000, batch:   178/  187, ite: 1875] train loss: 0.847202, tar: 0.124666 
l0: 0.109194, l1: 0.100271, l2: 0.121598, l3: 0.124357, l4: 0.156567, l5: 0.148906, l6: 0.156144

[epoch:  20/100000, batch:   180/  187, ite: 1876] train loss: 0.847239, tar: 0.124657 
l0: 0.066575, l1: 0.075935, l2: 0.073760, l3: 0.078718, l4: 0.102183, l5: 0.068398, l6: 0.070457

[epoch:  20/100000, batch:   182/  187, ite: 1877] train loss: 0.847073, tar: 0.124627 
l0: 0.112957, l1: 0.132409, l2: 0.128999, l3: 0.133835, l4: 0.108985, l5: 0.103869, l6: 0.097400

[epoch:  20/100000, batch:   184/  187, ite: 1878] train loss: 0.847058, tar: 0.124620 
l0: 0.095186, l1: 0.108890, l2: 0.101471, l3: 0.101032, l4: 0.100245, l5: 0.092709, l6: 0.099292

[epoch:  20/100000, batch:   186/  187, ite: 1879] train loss: 0.846979, tar: 0.124605 
l0: 0.104103, l1: 0.092945, l2: 0.108121, l3: 0.104810, l4: 0.122215, l5: 0.115864, l6: 0.123901

[epoch:  20/100000, batch:   188/  187, ite: 1880] train loss: 0.846939, tar: 0.124594 
l0: 0.113290, l1: 0.104007, l2: 0.116299, l3: 0.118433, l4: 0.126940, l5: 0.129709, l6: 0.137512

[epoch:  21/100000, batch:     2/  187, ite: 1881] train loss: 0.846939, tar: 0.124588 
l0: 0.086762, l1: 0.092694, l2: 0.114155, l3: 0.108156, l4: 0.071460, l5: 0.089410, l6: 0.093801

[epoch:  21/100000, batch:     4/  187, ite: 1882] train loss: 0.846838, tar: 0.124568 
l0: 0.084840, l1: 0.079226, l2: 0.082834, l3: 0.077060, l4: 0.107080, l5: 0.101966, l6: 0.103350

[epoch:  21/100000, batch:     6/  187, ite: 1883] train loss: 0.846726, tar: 0.124547 
l0: 0.091021, l1: 0.085233, l2: 0.096694, l3: 0.088636, l4: 0.109654, l5: 0.104201, l6: 0.105504

[epoch:  21/100000, batch:     8/  187, ite: 1884] train loss: 0.846638, tar: 0.124529 
l0: 0.060661, l1: 0.059602, l2: 0.065211, l3: 0.062719, l4: 0.050061, l5: 0.068569, l6: 0.058968

[epoch:  21/100000, batch:    10/  187, ite: 1885] train loss: 0.846415, tar: 0.124495 
l0: 0.116849, l1: 0.108100, l2: 0.118033, l3: 0.116521, l4: 0.150865, l5: 0.130043, l6: 0.134518

[epoch:  21/100000, batch:    12/  187, ite: 1886] train loss: 0.846430, tar: 0.124491 
l0: 0.074199, l1: 0.057604, l2: 0.066380, l3: 0.068472, l4: 0.086992, l5: 0.104712, l6: 0.106648

[epoch:  21/100000, batch:    14/  187, ite: 1887] train loss: 0.846281, tar: 0.124464 
l0: 0.136560, l1: 0.137442, l2: 0.128267, l3: 0.127218, l4: 0.124920, l5: 0.146710, l6: 0.158195

[epoch:  21/100000, batch:    16/  187, ite: 1888] train loss: 0.846341, tar: 0.124471 
l0: 0.088309, l1: 0.086106, l2: 0.087893, l3: 0.086207, l4: 0.089379, l5: 0.089065, l6: 0.088026

[epoch:  21/100000, batch:    18/  187, ite: 1889] train loss: 0.846218, tar: 0.124451 
l0: 0.045460, l1: 0.052078, l2: 0.055700, l3: 0.056980, l4: 0.067739, l5: 0.051212, l6: 0.051296

[epoch:  21/100000, batch:    20/  187, ite: 1890] train loss: 0.845972, tar: 0.124410 
l0: 0.130543, l1: 0.137545, l2: 0.142972, l3: 0.158194, l4: 0.137304, l5: 0.127509, l6: 0.126269

[epoch:  21/100000, batch:    22/  187, ite: 1891] train loss: 0.846032, tar: 0.124413 
l0: 0.060569, l1: 0.057477, l2: 0.068738, l3: 0.067575, l4: 0.125520, l5: 0.102787, l6: 0.086291

[epoch:  21/100000, batch:    24/  187, ite: 1892] train loss: 0.845886, tar: 0.124379 
l0: 0.074595, l1: 0.061790, l2: 0.076384, l3: 0.077768, l4: 0.089580, l5: 0.100710, l6: 0.100235

[epoch:  21/100000, batch:    26/  187, ite: 1893] train loss: 0.845746, tar: 0.124353 
l0: 0.172221, l1: 0.185475, l2: 0.183848, l3: 0.182110, l4: 0.205739, l5: 0.199271, l6: 0.193818

[epoch:  21/100000, batch:    28/  187, ite: 1894] train loss: 0.845997, tar: 0.124378 
l0: 0.097112, l1: 0.087222, l2: 0.108436, l3: 0.114982, l4: 0.114986, l5: 0.124923, l6: 0.135195

[epoch:  21/100000, batch:    30/  187, ite: 1895] train loss: 0.845964, tar: 0.124364 
l0: 0.085550, l1: 0.085398, l2: 0.098085, l3: 0.101601, l4: 0.102742, l5: 0.095823, l6: 0.098757

[epoch:  21/100000, batch:    32/  187, ite: 1896] train loss: 0.845870, tar: 0.124343 
l0: 0.086326, l1: 0.079561, l2: 0.088307, l3: 0.088033, l4: 0.100040, l5: 0.118857, l6: 0.112464

[epoch:  21/100000, batch:    34/  187, ite: 1897] train loss: 0.845779, tar: 0.124323 
l0: 0.098881, l1: 0.103944, l2: 0.103423, l3: 0.097664, l4: 0.111814, l5: 0.110440, l6: 0.102594

[epoch:  21/100000, batch:    36/  187, ite: 1898] train loss: 0.845718, tar: 0.124310 
l0: 0.099581, l1: 0.083561, l2: 0.106189, l3: 0.098371, l4: 0.116700, l5: 0.130093, l6: 0.133381

[epoch:  21/100000, batch:    38/  187, ite: 1899] train loss: 0.845677, tar: 0.124297 
l0: 0.132003, l1: 0.139952, l2: 0.138173, l3: 0.144407, l4: 0.148197, l5: 0.120523, l6: 0.117960

[epoch:  21/100000, batch:    40/  187, ite: 1900] train loss: 0.845727, tar: 0.124301 
l0: 0.100839, l1: 0.098704, l2: 0.105134, l3: 0.112642, l4: 0.105199, l5: 0.116847, l6: 0.111593

[epoch:  21/100000, batch:    42/  187, ite: 1901] train loss: 0.845677, tar: 0.124288 
l0: 0.080979, l1: 0.077092, l2: 0.089963, l3: 0.083869, l4: 0.082411, l5: 0.084384, l6: 0.087048

[epoch:  21/100000, batch:    44/  187, ite: 1902] train loss: 0.845541, tar: 0.124266 
l0: 0.088196, l1: 0.088855, l2: 0.094804, l3: 0.090932, l4: 0.099663, l5: 0.108737, l6: 0.096854

[epoch:  21/100000, batch:    46/  187, ite: 1903] train loss: 0.845447, tar: 0.124247 
l0: 0.085101, l1: 0.098078, l2: 0.099358, l3: 0.102733, l4: 0.091585, l5: 0.105023, l6: 0.094484

[epoch:  21/100000, batch:    48/  187, ite: 1904] train loss: 0.845358, tar: 0.124226 
l0: 0.083434, l1: 0.086781, l2: 0.091198, l3: 0.090331, l4: 0.094945, l5: 0.096962, l6: 0.099103

[epoch:  21/100000, batch:    50/  187, ite: 1905] train loss: 0.845252, tar: 0.124205 
l0: 0.107979, l1: 0.120490, l2: 0.131802, l3: 0.123431, l4: 0.113279, l5: 0.105067, l6: 0.106565

[epoch:  21/100000, batch:    52/  187, ite: 1906] train loss: 0.845233, tar: 0.124196 
l0: 0.091877, l1: 0.086890, l2: 0.095101, l3: 0.083860, l4: 0.108678, l5: 0.097886, l6: 0.100067

[epoch:  21/100000, batch:    54/  187, ite: 1907] train loss: 0.845138, tar: 0.124179 
l0: 0.069413, l1: 0.062736, l2: 0.077300, l3: 0.076444, l4: 0.083903, l5: 0.096167, l6: 0.089527

[epoch:  21/100000, batch:    56/  187, ite: 1908] train loss: 0.844986, tar: 0.124151 
l0: 0.089196, l1: 0.086952, l2: 0.103178, l3: 0.105934, l4: 0.112470, l5: 0.100690, l6: 0.112147

[epoch:  21/100000, batch:    58/  187, ite: 1909] train loss: 0.844916, tar: 0.124132 
l0: 0.094683, l1: 0.111689, l2: 0.095785, l3: 0.096280, l4: 0.090606, l5: 0.079564, l6: 0.078882

[epoch:  21/100000, batch:    60/  187, ite: 1910] train loss: 0.844812, tar: 0.124117 
l0: 0.078990, l1: 0.070155, l2: 0.084311, l3: 0.090327, l4: 0.099764, l5: 0.096127, l6: 0.102161

[epoch:  21/100000, batch:    62/  187, ite: 1911] train loss: 0.844696, tar: 0.124093 
l0: 0.073307, l1: 0.070491, l2: 0.077504, l3: 0.077802, l4: 0.085821, l5: 0.086217, l6: 0.082540

[epoch:  21/100000, batch:    64/  187, ite: 1912] train loss: 0.844544, tar: 0.124067 
l0: 0.106577, l1: 0.102841, l2: 0.122984, l3: 0.128091, l4: 0.125771, l5: 0.108367, l6: 0.122287

[epoch:  21/100000, batch:    66/  187, ite: 1913] train loss: 0.844529, tar: 0.124058 
l0: 0.063587, l1: 0.059488, l2: 0.071204, l3: 0.077901, l4: 0.071227, l5: 0.074030, l6: 0.064806

[epoch:  21/100000, batch:    68/  187, ite: 1914] train loss: 0.844340, tar: 0.124026 
l0: 0.074659, l1: 0.071169, l2: 0.078668, l3: 0.082043, l4: 0.085180, l5: 0.084159, l6: 0.094461

[epoch:  21/100000, batch:    70/  187, ite: 1915] train loss: 0.844197, tar: 0.124000 
l0: 0.106978, l1: 0.103297, l2: 0.114745, l3: 0.119369, l4: 0.113220, l5: 0.113584, l6: 0.107956

[epoch:  21/100000, batch:    72/  187, ite: 1916] train loss: 0.844163, tar: 0.123991 
l0: 0.148547, l1: 0.161480, l2: 0.169726, l3: 0.176056, l4: 0.149793, l5: 0.153827, l6: 0.227387

[epoch:  21/100000, batch:    74/  187, ite: 1917] train loss: 0.844342, tar: 0.124004 
l0: 0.065591, l1: 0.077804, l2: 0.074138, l3: 0.067834, l4: 0.077520, l5: 0.070125, l6: 0.076102

[epoch:  21/100000, batch:    76/  187, ite: 1918] train loss: 0.844167, tar: 0.123974 
l0: 0.066276, l1: 0.064265, l2: 0.072640, l3: 0.080170, l4: 0.098847, l5: 0.094542, l6: 0.101583

[epoch:  21/100000, batch:    78/  187, ite: 1919] train loss: 0.844028, tar: 0.123944 
l0: 0.097416, l1: 0.098075, l2: 0.107530, l3: 0.107082, l4: 0.104823, l5: 0.101810, l6: 0.094855

[epoch:  21/100000, batch:    80/  187, ite: 1920] train loss: 0.843959, tar: 0.123930 
l0: 0.048614, l1: 0.044952, l2: 0.059950, l3: 0.058907, l4: 0.068154, l5: 0.063880, l6: 0.068200

[epoch:  21/100000, batch:    82/  187, ite: 1921] train loss: 0.843735, tar: 0.123891 
l0: 0.077867, l1: 0.069443, l2: 0.088287, l3: 0.083801, l4: 0.097117, l5: 0.100670, l6: 0.100858

[epoch:  21/100000, batch:    84/  187, ite: 1922] train loss: 0.843617, tar: 0.123867 
l0: 0.043823, l1: 0.051084, l2: 0.061806, l3: 0.053238, l4: 0.064761, l5: 0.056388, l6: 0.052982

[epoch:  21/100000, batch:    86/  187, ite: 1923] train loss: 0.843378, tar: 0.123825 
l0: 0.096017, l1: 0.084929, l2: 0.094357, l3: 0.093030, l4: 0.106532, l5: 0.125411, l6: 0.129732

[epoch:  21/100000, batch:    88/  187, ite: 1924] train loss: 0.843319, tar: 0.123811 
l0: 0.094058, l1: 0.080997, l2: 0.093581, l3: 0.090503, l4: 0.107534, l5: 0.120192, l6: 0.121588

[epoch:  21/100000, batch:    90/  187, ite: 1925] train loss: 0.843249, tar: 0.123795 
l0: 0.091890, l1: 0.107030, l2: 0.086872, l3: 0.083647, l4: 0.098318, l5: 0.085619, l6: 0.093379

[epoch:  21/100000, batch:    92/  187, ite: 1926] train loss: 0.843147, tar: 0.123779 
l0: 0.053014, l1: 0.060642, l2: 0.068053, l3: 0.058032, l4: 0.075297, l5: 0.060110, l6: 0.060716

[epoch:  21/100000, batch:    94/  187, ite: 1927] train loss: 0.842936, tar: 0.123742 
l0: 0.089445, l1: 0.089854, l2: 0.101548, l3: 0.086894, l4: 0.105681, l5: 0.110941, l6: 0.108441

[epoch:  21/100000, batch:    96/  187, ite: 1928] train loss: 0.842858, tar: 0.123724 
l0: 0.074966, l1: 0.080678, l2: 0.093382, l3: 0.093479, l4: 0.085551, l5: 0.084623, l6: 0.080333

[epoch:  21/100000, batch:    98/  187, ite: 1929] train loss: 0.842729, tar: 0.123699 
l0: 0.061662, l1: 0.067875, l2: 0.068798, l3: 0.071967, l4: 0.070054, l5: 0.067765, l6: 0.060657

[epoch:  21/100000, batch:   100/  187, ite: 1930] train loss: 0.842535, tar: 0.123667 
l0: 0.126195, l1: 0.138892, l2: 0.145954, l3: 0.149662, l4: 0.145153, l5: 0.142982, l6: 0.134705

[epoch:  21/100000, batch:   102/  187, ite: 1931] train loss: 0.842608, tar: 0.123668 
l0: 0.079983, l1: 0.086184, l2: 0.078551, l3: 0.084860, l4: 0.104369, l5: 0.089339, l6: 0.086660

[epoch:  21/100000, batch:   104/  187, ite: 1932] train loss: 0.842487, tar: 0.123645 
l0: 0.079188, l1: 0.072064, l2: 0.082350, l3: 0.085107, l4: 0.077506, l5: 0.089274, l6: 0.086160

[epoch:  21/100000, batch:   106/  187, ite: 1933] train loss: 0.842347, tar: 0.123622 
l0: 0.073777, l1: 0.074467, l2: 0.069818, l3: 0.064770, l4: 0.089660, l5: 0.091985, l6: 0.086885

[epoch:  21/100000, batch:   108/  187, ite: 1934] train loss: 0.842197, tar: 0.123597 
l0: 0.057984, l1: 0.055286, l2: 0.061394, l3: 0.058447, l4: 0.076463, l5: 0.077938, l6: 0.067544

[epoch:  21/100000, batch:   110/  187, ite: 1935] train loss: 0.841997, tar: 0.123563 
l0: 0.108494, l1: 0.115309, l2: 0.132490, l3: 0.119024, l4: 0.163337, l5: 0.156192, l6: 0.130951

[epoch:  21/100000, batch:   112/  187, ite: 1936] train loss: 0.842040, tar: 0.123555 
l0: 0.081998, l1: 0.077691, l2: 0.082571, l3: 0.091707, l4: 0.086562, l5: 0.084119, l6: 0.093099

[epoch:  21/100000, batch:   114/  187, ite: 1937] train loss: 0.841914, tar: 0.123533 
l0: 0.062220, l1: 0.049561, l2: 0.073192, l3: 0.086186, l4: 0.076428, l5: 0.088313, l6: 0.084320

[epoch:  21/100000, batch:   116/  187, ite: 1938] train loss: 0.841748, tar: 0.123502 
l0: 0.086301, l1: 0.093172, l2: 0.087781, l3: 0.086806, l4: 0.093237, l5: 0.090642, l6: 0.079993

[epoch:  21/100000, batch:   118/  187, ite: 1939] train loss: 0.841633, tar: 0.123483 
l0: 0.056595, l1: 0.069935, l2: 0.075289, l3: 0.075002, l4: 0.056576, l5: 0.070699, l6: 0.053350

[epoch:  21/100000, batch:   120/  187, ite: 1940] train loss: 0.841435, tar: 0.123448 
l0: 0.075047, l1: 0.070679, l2: 0.066033, l3: 0.074489, l4: 0.088042, l5: 0.091957, l6: 0.098011

[epoch:  21/100000, batch:   122/  187, ite: 1941] train loss: 0.841292, tar: 0.123423 
l0: 0.116544, l1: 0.120734, l2: 0.099804, l3: 0.099343, l4: 0.110347, l5: 0.128327, l6: 0.118642

[epoch:  21/100000, batch:   124/  187, ite: 1942] train loss: 0.841267, tar: 0.123420 
l0: 0.121132, l1: 0.123682, l2: 0.169798, l3: 0.157248, l4: 0.133299, l5: 0.143726, l6: 0.137718

[epoch:  21/100000, batch:   126/  187, ite: 1943] train loss: 0.841342, tar: 0.123418 
l0: 0.075612, l1: 0.064838, l2: 0.085092, l3: 0.086223, l4: 0.120193, l5: 0.118652, l6: 0.100969

[epoch:  21/100000, batch:   128/  187, ite: 1944] train loss: 0.841244, tar: 0.123394 
l0: 0.063141, l1: 0.056667, l2: 0.077022, l3: 0.075424, l4: 0.099842, l5: 0.095836, l6: 0.079575

[epoch:  21/100000, batch:   130/  187, ite: 1945] train loss: 0.841093, tar: 0.123363 
l0: 0.131661, l1: 0.148480, l2: 0.123415, l3: 0.133026, l4: 0.135048, l5: 0.128309, l6: 0.130585

[epoch:  21/100000, batch:   132/  187, ite: 1946] train loss: 0.841139, tar: 0.123367 
l0: 0.083786, l1: 0.090519, l2: 0.084492, l3: 0.085167, l4: 0.087511, l5: 0.094601, l6: 0.078836

[epoch:  21/100000, batch:   134/  187, ite: 1947] train loss: 0.841018, tar: 0.123347 
l0: 0.074178, l1: 0.084550, l2: 0.080437, l3: 0.097974, l4: 0.084331, l5: 0.082632, l6: 0.081812

[epoch:  21/100000, batch:   136/  187, ite: 1948] train loss: 0.840887, tar: 0.123322 
l0: 0.120722, l1: 0.117226, l2: 0.134392, l3: 0.127280, l4: 0.125309, l5: 0.132059, l6: 0.143010

[epoch:  21/100000, batch:   138/  187, ite: 1949] train loss: 0.840917, tar: 0.123320 
l0: 0.076480, l1: 0.088701, l2: 0.080132, l3: 0.080669, l4: 0.078989, l5: 0.082763, l6: 0.088586

[epoch:  21/100000, batch:   140/  187, ite: 1950] train loss: 0.840782, tar: 0.123296 
l0: 0.086025, l1: 0.086597, l2: 0.089290, l3: 0.090610, l4: 0.093363, l5: 0.099216, l6: 0.103292

[epoch:  21/100000, batch:   142/  187, ite: 1951] train loss: 0.840683, tar: 0.123277 
l0: 0.087012, l1: 0.097056, l2: 0.074321, l3: 0.078692, l4: 0.087921, l5: 0.087216, l6: 0.094374

[epoch:  21/100000, batch:   144/  187, ite: 1952] train loss: 0.840563, tar: 0.123259 
l0: 0.107206, l1: 0.088862, l2: 0.107666, l3: 0.116065, l4: 0.143653, l5: 0.162759, l6: 0.139374

[epoch:  21/100000, batch:   146/  187, ite: 1953] train loss: 0.840576, tar: 0.123250 
l0: 0.054498, l1: 0.069715, l2: 0.067312, l3: 0.064668, l4: 0.048921, l5: 0.052282, l6: 0.052287

[epoch:  21/100000, batch:   148/  187, ite: 1954] train loss: 0.840355, tar: 0.123215 
l0: 0.080730, l1: 0.079663, l2: 0.084808, l3: 0.083208, l4: 0.103286, l5: 0.092556, l6: 0.087606

[epoch:  21/100000, batch:   150/  187, ite: 1955] train loss: 0.840239, tar: 0.123193 
l0: 0.069453, l1: 0.083743, l2: 0.086165, l3: 0.081227, l4: 0.055941, l5: 0.080146, l6: 0.065851

[epoch:  21/100000, batch:   152/  187, ite: 1956] train loss: 0.840076, tar: 0.123166 
l0: 0.129256, l1: 0.137530, l2: 0.146413, l3: 0.145929, l4: 0.117502, l5: 0.113603, l6: 0.123652

[epoch:  21/100000, batch:   154/  187, ite: 1957] train loss: 0.840114, tar: 0.123169 
l0: 0.068936, l1: 0.063677, l2: 0.073316, l3: 0.070247, l4: 0.096573, l5: 0.097889, l6: 0.098256

[epoch:  21/100000, batch:   156/  187, ite: 1958] train loss: 0.839975, tar: 0.123141 
l0: 0.069255, l1: 0.076709, l2: 0.079963, l3: 0.076970, l4: 0.060064, l5: 0.067542, l6: 0.064063

[epoch:  21/100000, batch:   158/  187, ite: 1959] train loss: 0.839799, tar: 0.123114 
l0: 0.060820, l1: 0.057257, l2: 0.066685, l3: 0.067013, l4: 0.085924, l5: 0.080414, l6: 0.087134

[epoch:  21/100000, batch:   160/  187, ite: 1960] train loss: 0.839628, tar: 0.123082 
l0: 0.101286, l1: 0.089614, l2: 0.115828, l3: 0.119129, l4: 0.131197, l5: 0.136307, l6: 0.144364

[epoch:  21/100000, batch:   162/  187, ite: 1961] train loss: 0.839627, tar: 0.123071 
l0: 0.129563, l1: 0.129508, l2: 0.128246, l3: 0.121675, l4: 0.153202, l5: 0.173481, l6: 0.181928

[epoch:  21/100000, batch:   164/  187, ite: 1962] train loss: 0.839718, tar: 0.123074 
l0: 0.115721, l1: 0.119454, l2: 0.135757, l3: 0.141134, l4: 0.120273, l5: 0.113250, l6: 0.126744

[epoch:  21/100000, batch:   166/  187, ite: 1963] train loss: 0.839735, tar: 0.123070 
l0: 0.065030, l1: 0.059275, l2: 0.069959, l3: 0.069164, l4: 0.092514, l5: 0.085566, l6: 0.073019

[epoch:  21/100000, batch:   168/  187, ite: 1964] train loss: 0.839569, tar: 0.123041 
l0: 0.111007, l1: 0.106245, l2: 0.112565, l3: 0.113279, l4: 0.121649, l5: 0.128464, l6: 0.114517

[epoch:  21/100000, batch:   170/  187, ite: 1965] train loss: 0.839553, tar: 0.123035 
l0: 0.118983, l1: 0.106656, l2: 0.140591, l3: 0.135347, l4: 0.157252, l5: 0.154017, l6: 0.151646

[epoch:  21/100000, batch:   172/  187, ite: 1966] train loss: 0.839616, tar: 0.123033 
l0: 0.080285, l1: 0.075202, l2: 0.085735, l3: 0.086675, l4: 0.093880, l5: 0.100250, l6: 0.095948

[epoch:  21/100000, batch:   174/  187, ite: 1967] train loss: 0.839504, tar: 0.123011 
l0: 0.108694, l1: 0.113758, l2: 0.105392, l3: 0.103639, l4: 0.100012, l5: 0.106463, l6: 0.100896

[epoch:  21/100000, batch:   176/  187, ite: 1968] train loss: 0.839453, tar: 0.123004 
l0: 0.108527, l1: 0.113545, l2: 0.110152, l3: 0.105945, l4: 0.098394, l5: 0.112865, l6: 0.089709

[epoch:  21/100000, batch:   178/  187, ite: 1969] train loss: 0.839402, tar: 0.122996 
l0: 0.071122, l1: 0.071070, l2: 0.075207, l3: 0.076206, l4: 0.080676, l5: 0.076453, l6: 0.074928

[epoch:  21/100000, batch:   180/  187, ite: 1970] train loss: 0.839242, tar: 0.122970 
l0: 0.087727, l1: 0.084968, l2: 0.096302, l3: 0.096821, l4: 0.113402, l5: 0.106440, l6: 0.108020

[epoch:  21/100000, batch:   182/  187, ite: 1971] train loss: 0.839169, tar: 0.122952 
l0: 0.091029, l1: 0.086827, l2: 0.107693, l3: 0.092092, l4: 0.098749, l5: 0.109599, l6: 0.097047

[epoch:  21/100000, batch:   184/  187, ite: 1972] train loss: 0.839089, tar: 0.122936 
l0: 0.106058, l1: 0.106858, l2: 0.103621, l3: 0.111074, l4: 0.120335, l5: 0.116330, l6: 0.125220

[epoch:  21/100000, batch:   186/  187, ite: 1973] train loss: 0.839064, tar: 0.122927 
l0: 0.074187, l1: 0.070897, l2: 0.085086, l3: 0.088070, l4: 0.100046, l5: 0.104071, l6: 0.113911

[epoch:  21/100000, batch:   188/  187, ite: 1974] train loss: 0.838962, tar: 0.122903 
l0: 0.105704, l1: 0.096899, l2: 0.108580, l3: 0.107851, l4: 0.114393, l5: 0.116252, l6: 0.117456

[epoch:  22/100000, batch:     2/  187, ite: 1975] train loss: 0.838925, tar: 0.122894 
l0: 0.079719, l1: 0.084494, l2: 0.086566, l3: 0.088205, l4: 0.089299, l5: 0.089926, l6: 0.083118

[epoch:  22/100000, batch:     4/  187, ite: 1976] train loss: 0.838805, tar: 0.122872 
l0: 0.123495, l1: 0.123532, l2: 0.136682, l3: 0.143134, l4: 0.182305, l5: 0.154139, l6: 0.178801

[epoch:  22/100000, batch:     6/  187, ite: 1977] train loss: 0.838908, tar: 0.122873 
l0: 0.094989, l1: 0.082875, l2: 0.109365, l3: 0.112877, l4: 0.115484, l5: 0.120407, l6: 0.128768

[epoch:  22/100000, batch:     8/  187, ite: 1978] train loss: 0.838870, tar: 0.122858 
l0: 0.114329, l1: 0.122872, l2: 0.125829, l3: 0.122341, l4: 0.120042, l5: 0.125299, l6: 0.128195

[epoch:  22/100000, batch:    10/  187, ite: 1979] train loss: 0.838880, tar: 0.122854 
l0: 0.116310, l1: 0.100828, l2: 0.117313, l3: 0.124845, l4: 0.176203, l5: 0.157427, l6: 0.156900

[epoch:  22/100000, batch:    12/  187, ite: 1980] train loss: 0.838936, tar: 0.122851 
l0: 0.059115, l1: 0.062676, l2: 0.061468, l3: 0.066135, l4: 0.072560, l5: 0.068211, l6: 0.059954

[epoch:  22/100000, batch:    14/  187, ite: 1981] train loss: 0.838740, tar: 0.122819 
l0: 0.070620, l1: 0.064757, l2: 0.073328, l3: 0.070016, l4: 0.079216, l5: 0.086568, l6: 0.106170

[epoch:  22/100000, batch:    16/  187, ite: 1982] train loss: 0.838595, tar: 0.122792 
l0: 0.104822, l1: 0.109204, l2: 0.096682, l3: 0.103354, l4: 0.110429, l5: 0.110805, l6: 0.108234

[epoch:  22/100000, batch:    18/  187, ite: 1983] train loss: 0.838547, tar: 0.122783 
l0: 0.091825, l1: 0.094772, l2: 0.092027, l3: 0.096187, l4: 0.104850, l5: 0.106922, l6: 0.105329

[epoch:  22/100000, batch:    20/  187, ite: 1984] train loss: 0.838473, tar: 0.122768 
l0: 0.105748, l1: 0.107378, l2: 0.120730, l3: 0.131015, l4: 0.145395, l5: 0.129584, l6: 0.115481

[epoch:  22/100000, batch:    22/  187, ite: 1985] train loss: 0.838481, tar: 0.122759 
l0: 0.081549, l1: 0.088594, l2: 0.085845, l3: 0.084897, l4: 0.093537, l5: 0.088699, l6: 0.090474

[epoch:  22/100000, batch:    24/  187, ite: 1986] train loss: 0.838368, tar: 0.122738 
l0: 0.070692, l1: 0.080812, l2: 0.076726, l3: 0.070875, l4: 0.078738, l5: 0.077933, l6: 0.091852

[epoch:  22/100000, batch:    26/  187, ite: 1987] train loss: 0.838222, tar: 0.122712 
l0: 0.074035, l1: 0.058437, l2: 0.072257, l3: 0.085845, l4: 0.093047, l5: 0.094104, l6: 0.107478

[epoch:  22/100000, batch:    28/  187, ite: 1988] train loss: 0.838095, tar: 0.122688 
l0: 0.077345, l1: 0.058086, l2: 0.073003, l3: 0.084234, l4: 0.113568, l5: 0.123014, l6: 0.113769

[epoch:  22/100000, batch:    30/  187, ite: 1989] train loss: 0.837997, tar: 0.122665 
l0: 0.085417, l1: 0.085423, l2: 0.092033, l3: 0.089729, l4: 0.100349, l5: 0.093658, l6: 0.098137

[epoch:  22/100000, batch:    32/  187, ite: 1990] train loss: 0.837899, tar: 0.122646 
l0: 0.069794, l1: 0.085608, l2: 0.086362, l3: 0.076594, l4: 0.069117, l5: 0.061860, l6: 0.066945

[epoch:  22/100000, batch:    34/  187, ite: 1991] train loss: 0.837738, tar: 0.122620 
l0: 0.100527, l1: 0.111151, l2: 0.104645, l3: 0.088945, l4: 0.107453, l5: 0.103074, l6: 0.124262

[epoch:  22/100000, batch:    36/  187, ite: 1992] train loss: 0.837689, tar: 0.122608 
l0: 0.068678, l1: 0.063389, l2: 0.082787, l3: 0.083751, l4: 0.098509, l5: 0.085961, l6: 0.099712

[epoch:  22/100000, batch:    38/  187, ite: 1993] train loss: 0.837561, tar: 0.122581 
l0: 0.061227, l1: 0.083520, l2: 0.070930, l3: 0.064146, l4: 0.063002, l5: 0.061981, l6: 0.059816

[epoch:  22/100000, batch:    40/  187, ite: 1994] train loss: 0.837374, tar: 0.122551 
l0: 0.061935, l1: 0.063566, l2: 0.069945, l3: 0.069345, l4: 0.072447, l5: 0.074132, l6: 0.066168

[epoch:  22/100000, batch:    42/  187, ite: 1995] train loss: 0.837194, tar: 0.122520 
l0: 0.077334, l1: 0.078292, l2: 0.087012, l3: 0.074544, l4: 0.092872, l5: 0.097243, l6: 0.079126

[epoch:  22/100000, batch:    44/  187, ite: 1996] train loss: 0.837068, tar: 0.122498 
l0: 0.064188, l1: 0.070725, l2: 0.061660, l3: 0.057781, l4: 0.078419, l5: 0.071016, l6: 0.066632

[epoch:  22/100000, batch:    46/  187, ite: 1997] train loss: 0.836884, tar: 0.122468 
l0: 0.051339, l1: 0.055301, l2: 0.059231, l3: 0.063581, l4: 0.058685, l5: 0.056899, l6: 0.058524

[epoch:  22/100000, batch:    48/  187, ite: 1998] train loss: 0.836667, tar: 0.122433 
l0: 0.074605, l1: 0.060715, l2: 0.081701, l3: 0.087245, l4: 0.116646, l5: 0.101345, l6: 0.112416

[epoch:  22/100000, batch:    50/  187, ite: 1999] train loss: 0.836566, tar: 0.122409 
l0: 0.052010, l1: 0.054217, l2: 0.052957, l3: 0.050970, l4: 0.055071, l5: 0.065201, l6: 0.056656

[epoch:  22/100000, batch:    52/  187, ite: 2000] train loss: 0.836342, tar: 0.122374 
l0: 0.064356, l1: 0.057075, l2: 0.061220, l3: 0.064616, l4: 0.090230, l5: 0.087430, l6: 0.091082

[epoch:  22/100000, batch:    54/  187, ite: 2001] train loss: 0.516008, tar: 0.064356 
l0: 0.030504, l1: 0.028879, l2: 0.031314, l3: 0.031119, l4: 0.038523, l5: 0.041840, l6: 0.031985

[epoch:  22/100000, batch:    56/  187, ite: 2002] train loss: 0.375086, tar: 0.047430 
l0: 0.037320, l1: 0.037272, l2: 0.036788, l3: 0.038339, l4: 0.045770, l5: 0.039196, l6: 0.044678

[epoch:  22/100000, batch:    58/  187, ite: 2003] train loss: 0.343178, tar: 0.044060 
l0: 0.123387, l1: 0.135082, l2: 0.124972, l3: 0.115725, l4: 0.128819, l5: 0.115047, l6: 0.119618

[epoch:  22/100000, batch:    60/  187, ite: 2004] train loss: 0.473046, tar: 0.063892 
l0: 0.058462, l1: 0.059170, l2: 0.059097, l3: 0.056802, l4: 0.069694, l5: 0.063960, l6: 0.066363

[epoch:  22/100000, batch:    62/  187, ite: 2005] train loss: 0.465146, tar: 0.062806 
l0: 0.062207, l1: 0.060929, l2: 0.062599, l3: 0.065129, l4: 0.065515, l5: 0.070538, l6: 0.070751

[epoch:  22/100000, batch:    64/  187, ite: 2006] train loss: 0.463900, tar: 0.062706 
l0: 0.050262, l1: 0.059544, l2: 0.066940, l3: 0.069665, l4: 0.045822, l5: 0.046473, l6: 0.048943

[epoch:  22/100000, batch:    66/  187, ite: 2007] train loss: 0.453007, tar: 0.060928 
l0: 0.127906, l1: 0.131510, l2: 0.131168, l3: 0.128629, l4: 0.121432, l5: 0.146407, l6: 0.146826

[epoch:  22/100000, batch:    68/  187, ite: 2008] train loss: 0.513116, tar: 0.069300 
l0: 0.124852, l1: 0.112495, l2: 0.160019, l3: 0.155086, l4: 0.151339, l5: 0.158628, l6: 0.168532

[epoch:  22/100000, batch:    70/  187, ite: 2009] train loss: 0.570653, tar: 0.075473 
l0: 0.118541, l1: 0.121793, l2: 0.124251, l3: 0.115889, l4: 0.111285, l5: 0.117774, l6: 0.129324

[epoch:  22/100000, batch:    72/  187, ite: 2010] train loss: 0.597473, tar: 0.079780 
l0: 0.072249, l1: 0.072935, l2: 0.079203, l3: 0.070565, l4: 0.076428, l5: 0.076721, l6: 0.075353

[epoch:  22/100000, batch:    74/  187, ite: 2011] train loss: 0.590744, tar: 0.079095 
l0: 0.080798, l1: 0.078985, l2: 0.084393, l3: 0.080816, l4: 0.108301, l5: 0.105396, l6: 0.109086

[epoch:  22/100000, batch:    76/  187, ite: 2012] train loss: 0.595497, tar: 0.079237 
l0: 0.088384, l1: 0.077780, l2: 0.097334, l3: 0.093979, l4: 0.128462, l5: 0.123674, l6: 0.139994

[epoch:  22/100000, batch:    78/  187, ite: 2013] train loss: 0.607351, tar: 0.079941 
l0: 0.067984, l1: 0.069354, l2: 0.061845, l3: 0.105382, l4: 0.102763, l5: 0.101411, l6: 0.117527

[epoch:  22/100000, batch:    80/  187, ite: 2014] train loss: 0.608702, tar: 0.079086 
l0: 0.068539, l1: 0.067002, l2: 0.076653, l3: 0.075995, l4: 0.083157, l5: 0.074257, l6: 0.074805

[epoch:  22/100000, batch:    82/  187, ite: 2015] train loss: 0.602816, tar: 0.078383 
l0: 0.086561, l1: 0.078092, l2: 0.093250, l3: 0.104723, l4: 0.130504, l5: 0.124542, l6: 0.129737

[epoch:  22/100000, batch:    84/  187, ite: 2016] train loss: 0.611853, tar: 0.078894 
l0: 0.089246, l1: 0.086940, l2: 0.081952, l3: 0.082894, l4: 0.098215, l5: 0.104240, l6: 0.099082

[epoch:  22/100000, batch:    86/  187, ite: 2017] train loss: 0.613660, tar: 0.079503 
l0: 0.054068, l1: 0.056550, l2: 0.071378, l3: 0.072852, l4: 0.066523, l5: 0.064929, l6: 0.052446

[epoch:  22/100000, batch:    88/  187, ite: 2018] train loss: 0.603943, tar: 0.078090 
l0: 0.078923, l1: 0.089307, l2: 0.090243, l3: 0.088857, l4: 0.076535, l5: 0.096242, l6: 0.078610

[epoch:  22/100000, batch:    90/  187, ite: 2019] train loss: 0.603668, tar: 0.078134 
l0: 0.075062, l1: 0.090630, l2: 0.078413, l3: 0.065651, l4: 0.076248, l5: 0.072521, l6: 0.074206

[epoch:  22/100000, batch:    92/  187, ite: 2020] train loss: 0.600121, tar: 0.077981 
l0: 0.063078, l1: 0.068815, l2: 0.070592, l3: 0.058361, l4: 0.079696, l5: 0.087327, l6: 0.088130

[epoch:  22/100000, batch:    94/  187, ite: 2021] train loss: 0.596115, tar: 0.077271 
l0: 0.091989, l1: 0.084168, l2: 0.104831, l3: 0.116748, l4: 0.116921, l5: 0.103743, l6: 0.126806

[epoch:  22/100000, batch:    96/  187, ite: 2022] train loss: 0.602892, tar: 0.077940 
l0: 0.100961, l1: 0.086866, l2: 0.106593, l3: 0.119157, l4: 0.123664, l5: 0.125836, l6: 0.148950

[epoch:  22/100000, batch:    98/  187, ite: 2023] train loss: 0.611985, tar: 0.078941 
l0: 0.083771, l1: 0.074605, l2: 0.091859, l3: 0.095567, l4: 0.108138, l5: 0.114932, l6: 0.117761

[epoch:  22/100000, batch:   100/  187, ite: 2024] train loss: 0.615095, tar: 0.079142 
l0: 0.075943, l1: 0.076133, l2: 0.087549, l3: 0.085286, l4: 0.089170, l5: 0.092240, l6: 0.097534

[epoch:  22/100000, batch:   102/  187, ite: 2025] train loss: 0.614646, tar: 0.079014 
l0: 0.082322, l1: 0.113157, l2: 0.084996, l3: 0.078845, l4: 0.079181, l5: 0.073560, l6: 0.062999

[epoch:  22/100000, batch:   104/  187, ite: 2026] train loss: 0.613123, tar: 0.079141 
l0: 0.055682, l1: 0.075608, l2: 0.054556, l3: 0.051591, l4: 0.055798, l5: 0.054517, l6: 0.047300

[epoch:  22/100000, batch:   106/  187, ite: 2027] train loss: 0.605046, tar: 0.078272 
l0: 0.062509, l1: 0.049276, l2: 0.069278, l3: 0.077024, l4: 0.078410, l5: 0.083359, l6: 0.083278

[epoch:  22/100000, batch:   108/  187, ite: 2028] train loss: 0.601407, tar: 0.077709 
l0: 0.102358, l1: 0.098012, l2: 0.128512, l3: 0.124888, l4: 0.117464, l5: 0.113425, l6: 0.106696

[epoch:  22/100000, batch:   110/  187, ite: 2029] train loss: 0.607957, tar: 0.078559 
l0: 0.076228, l1: 0.067212, l2: 0.080339, l3: 0.086847, l4: 0.099377, l5: 0.125109, l6: 0.092356

[epoch:  22/100000, batch:   112/  187, ite: 2030] train loss: 0.608607, tar: 0.078482 
l0: 0.060549, l1: 0.056807, l2: 0.066654, l3: 0.067111, l4: 0.069419, l5: 0.070426, l6: 0.068463

[epoch:  22/100000, batch:   114/  187, ite: 2031] train loss: 0.603795, tar: 0.077903 
l0: 0.092766, l1: 0.087102, l2: 0.099179, l3: 0.091875, l4: 0.100114, l5: 0.128262, l6: 0.105113

[epoch:  22/100000, batch:   116/  187, ite: 2032] train loss: 0.606939, tar: 0.078368 
l0: 0.065618, l1: 0.069837, l2: 0.062991, l3: 0.074477, l4: 0.069520, l5: 0.066380, l6: 0.068535

[epoch:  22/100000, batch:   118/  187, ite: 2033] train loss: 0.603012, tar: 0.077981 
l0: 0.072675, l1: 0.073306, l2: 0.070161, l3: 0.075674, l4: 0.100016, l5: 0.095788, l6: 0.081608

[epoch:  22/100000, batch:   120/  187, ite: 2034] train loss: 0.602019, tar: 0.077825 
l0: 0.076926, l1: 0.075094, l2: 0.073787, l3: 0.083218, l4: 0.079867, l5: 0.089467, l6: 0.092299

[epoch:  22/100000, batch:   122/  187, ite: 2035] train loss: 0.601123, tar: 0.077800 
l0: 0.081958, l1: 0.071389, l2: 0.075219, l3: 0.074563, l4: 0.072048, l5: 0.108395, l6: 0.101746

[epoch:  22/100000, batch:   124/  187, ite: 2036] train loss: 0.600684, tar: 0.077915 
l0: 0.066742, l1: 0.072902, l2: 0.075504, l3: 0.111774, l4: 0.088504, l5: 0.085253, l6: 0.072575

[epoch:  22/100000, batch:   126/  187, ite: 2037] train loss: 0.599942, tar: 0.077613 
l0: 0.079952, l1: 0.095111, l2: 0.089978, l3: 0.100999, l4: 0.090419, l5: 0.091817, l6: 0.104638

[epoch:  22/100000, batch:   128/  187, ite: 2038] train loss: 0.601336, tar: 0.077675 
l0: 0.053109, l1: 0.056178, l2: 0.051109, l3: 0.053903, l4: 0.053951, l5: 0.058803, l6: 0.061369

[epoch:  22/100000, batch:   130/  187, ite: 2039] train loss: 0.595877, tar: 0.077045 
l0: 0.045541, l1: 0.042854, l2: 0.054807, l3: 0.061746, l4: 0.073600, l5: 0.058869, l6: 0.055504

[epoch:  22/100000, batch:   132/  187, ite: 2040] train loss: 0.590803, tar: 0.076257 
l0: 0.094115, l1: 0.084372, l2: 0.079366, l3: 0.095316, l4: 0.079505, l5: 0.091257, l6: 0.118583

[epoch:  22/100000, batch:   134/  187, ite: 2041] train loss: 0.592064, tar: 0.076693 
l0: 0.063782, l1: 0.085973, l2: 0.069907, l3: 0.059994, l4: 0.047868, l5: 0.053769, l6: 0.045267

[epoch:  22/100000, batch:   136/  187, ite: 2042] train loss: 0.588124, tar: 0.076385 
l0: 0.091990, l1: 0.077738, l2: 0.077643, l3: 0.101173, l4: 0.103028, l5: 0.094526, l6: 0.108498

[epoch:  22/100000, batch:   138/  187, ite: 2043] train loss: 0.589669, tar: 0.076748 
l0: 0.092243, l1: 0.110386, l2: 0.110010, l3: 0.082973, l4: 0.087780, l5: 0.083730, l6: 0.082838

[epoch:  22/100000, batch:   140/  187, ite: 2044] train loss: 0.591040, tar: 0.077100 
l0: 0.088172, l1: 0.087243, l2: 0.096977, l3: 0.101834, l4: 0.104079, l5: 0.095574, l6: 0.097675

[epoch:  22/100000, batch:   142/  187, ite: 2045] train loss: 0.592829, tar: 0.077346 
l0: 0.066216, l1: 0.059738, l2: 0.067153, l3: 0.086047, l4: 0.089312, l5: 0.080218, l6: 0.078663

[epoch:  22/100000, batch:   144/  187, ite: 2046] train loss: 0.591405, tar: 0.077104 
l0: 0.087947, l1: 0.088889, l2: 0.100848, l3: 0.097131, l4: 0.088196, l5: 0.084588, l6: 0.082878

[epoch:  22/100000, batch:   146/  187, ite: 2047] train loss: 0.592237, tar: 0.077335 
l0: 0.098331, l1: 0.090115, l2: 0.115479, l3: 0.131461, l4: 0.109112, l5: 0.112993, l6: 0.126092

[epoch:  22/100000, batch:   148/  187, ite: 2048] train loss: 0.596223, tar: 0.077773 
l0: 0.106398, l1: 0.104793, l2: 0.106989, l3: 0.120224, l4: 0.117941, l5: 0.116573, l6: 0.099217

[epoch:  22/100000, batch:   150/  187, ite: 2049] train loss: 0.599813, tar: 0.078357 
l0: 0.060385, l1: 0.073924, l2: 0.074764, l3: 0.077022, l4: 0.078703, l5: 0.064914, l6: 0.072409

[epoch:  22/100000, batch:   152/  187, ite: 2050] train loss: 0.597859, tar: 0.077997 
l0: 0.058951, l1: 0.062114, l2: 0.064592, l3: 0.061386, l4: 0.066323, l5: 0.066653, l6: 0.067587

[epoch:  22/100000, batch:   154/  187, ite: 2051] train loss: 0.594913, tar: 0.077624 
l0: 0.078869, l1: 0.070060, l2: 0.077107, l3: 0.081757, l4: 0.100083, l5: 0.100006, l6: 0.101267

[epoch:  22/100000, batch:   156/  187, ite: 2052] train loss: 0.595187, tar: 0.077648 
l0: 0.080536, l1: 0.078474, l2: 0.095515, l3: 0.086067, l4: 0.099062, l5: 0.095710, l6: 0.101814

[epoch:  22/100000, batch:   158/  187, ite: 2053] train loss: 0.595979, tar: 0.077702 
l0: 0.149725, l1: 0.160286, l2: 0.139678, l3: 0.143216, l4: 0.203124, l5: 0.177998, l6: 0.217062

[epoch:  22/100000, batch:   160/  187, ite: 2054] train loss: 0.607000, tar: 0.079036 
l0: 0.095608, l1: 0.095228, l2: 0.100617, l3: 0.097704, l4: 0.115106, l5: 0.128466, l6: 0.156155

[epoch:  22/100000, batch:   162/  187, ite: 2055] train loss: 0.610307, tar: 0.079337 
l0: 0.048723, l1: 0.060341, l2: 0.049663, l3: 0.047599, l4: 0.051023, l5: 0.056180, l6: 0.053432

[epoch:  22/100000, batch:   164/  187, ite: 2056] train loss: 0.605961, tar: 0.078791 
l0: 0.088114, l1: 0.084443, l2: 0.097583, l3: 0.090214, l4: 0.086782, l5: 0.089306, l6: 0.109484

[epoch:  22/100000, batch:   166/  187, ite: 2057] train loss: 0.606662, tar: 0.078954 
l0: 0.097724, l1: 0.089764, l2: 0.100640, l3: 0.102363, l4: 0.107751, l5: 0.131293, l6: 0.131384

[epoch:  22/100000, batch:   168/  187, ite: 2058] train loss: 0.609322, tar: 0.079278 
l0: 0.139035, l1: 0.148486, l2: 0.149515, l3: 0.151718, l4: 0.149866, l5: 0.168631, l6: 0.139936

[epoch:  22/100000, batch:   170/  187, ite: 2059] train loss: 0.616743, tar: 0.080291 
l0: 0.051199, l1: 0.045074, l2: 0.060748, l3: 0.056936, l4: 0.067294, l5: 0.064534, l6: 0.056615

[epoch:  22/100000, batch:   172/  187, ite: 2060] train loss: 0.613171, tar: 0.079806 
l0: 0.079951, l1: 0.078040, l2: 0.086271, l3: 0.084556, l4: 0.085327, l5: 0.092876, l6: 0.093411

[epoch:  22/100000, batch:   174/  187, ite: 2061] train loss: 0.612962, tar: 0.079808 
l0: 0.062197, l1: 0.052397, l2: 0.071040, l3: 0.078630, l4: 0.074258, l5: 0.089270, l6: 0.086600

[epoch:  22/100000, batch:   176/  187, ite: 2062] train loss: 0.611372, tar: 0.079524 
l0: 0.079574, l1: 0.078391, l2: 0.083258, l3: 0.083334, l4: 0.087965, l5: 0.081157, l6: 0.082584

[epoch:  22/100000, batch:   178/  187, ite: 2063] train loss: 0.610815, tar: 0.079525 
l0: 0.072171, l1: 0.069375, l2: 0.075949, l3: 0.074929, l4: 0.082685, l5: 0.088285, l6: 0.079751

[epoch:  22/100000, batch:   180/  187, ite: 2064] train loss: 0.609758, tar: 0.079410 
l0: 0.047754, l1: 0.042328, l2: 0.051828, l3: 0.052963, l4: 0.057753, l5: 0.065699, l6: 0.066000

[epoch:  22/100000, batch:   182/  187, ite: 2065] train loss: 0.606290, tar: 0.078923 
l0: 0.062502, l1: 0.057384, l2: 0.060100, l3: 0.058980, l4: 0.066723, l5: 0.076028, l6: 0.065928

[epoch:  22/100000, batch:   184/  187, ite: 2066] train loss: 0.603886, tar: 0.078674 
l0: 0.109686, l1: 0.106223, l2: 0.119316, l3: 0.125762, l4: 0.164507, l5: 0.138535, l6: 0.120399

[epoch:  22/100000, batch:   186/  187, ite: 2067] train loss: 0.608073, tar: 0.079137 
l0: 0.047160, l1: 0.045144, l2: 0.064529, l3: 0.061931, l4: 0.067660, l5: 0.070994, l6: 0.056792

[epoch:  22/100000, batch:   188/  187, ite: 2068] train loss: 0.605222, tar: 0.078667 
l0: 0.103885, l1: 0.113924, l2: 0.108424, l3: 0.113441, l4: 0.106934, l5: 0.108613, l6: 0.103077

[epoch:  23/100000, batch:     2/  187, ite: 2069] train loss: 0.607441, tar: 0.079032 
l0: 0.091334, l1: 0.078645, l2: 0.100709, l3: 0.098342, l4: 0.106679, l5: 0.144108, l6: 0.133414

[epoch:  23/100000, batch:     4/  187, ite: 2070] train loss: 0.609523, tar: 0.079208 
l0: 0.104651, l1: 0.105553, l2: 0.094841, l3: 0.107680, l4: 0.101089, l5: 0.118097, l6: 0.120877

[epoch:  23/100000, batch:     6/  187, ite: 2071] train loss: 0.611541, tar: 0.079566 
l0: 0.081055, l1: 0.071418, l2: 0.084018, l3: 0.092727, l4: 0.094983, l5: 0.108764, l6: 0.123205

[epoch:  23/100000, batch:     8/  187, ite: 2072] train loss: 0.612161, tar: 0.079587 
l0: 0.072916, l1: 0.068723, l2: 0.084563, l3: 0.088796, l4: 0.092368, l5: 0.095878, l6: 0.097981

[epoch:  23/100000, batch:    10/  187, ite: 2073] train loss: 0.612011, tar: 0.079496 
l0: 0.059252, l1: 0.054321, l2: 0.060258, l3: 0.059636, l4: 0.070151, l5: 0.070900, l6: 0.073912

[epoch:  23/100000, batch:    12/  187, ite: 2074] train loss: 0.609801, tar: 0.079222 
l0: 0.063751, l1: 0.068624, l2: 0.068943, l3: 0.069146, l4: 0.082305, l5: 0.076720, l6: 0.066488

[epoch:  23/100000, batch:    14/  187, ite: 2075] train loss: 0.608283, tar: 0.079016 
l0: 0.095355, l1: 0.088636, l2: 0.095545, l3: 0.094476, l4: 0.126684, l5: 0.119439, l6: 0.112184

[epoch:  23/100000, batch:    16/  187, ite: 2076] train loss: 0.609915, tar: 0.079231 
l0: 0.087987, l1: 0.088329, l2: 0.082746, l3: 0.090266, l4: 0.096911, l5: 0.102312, l6: 0.105428

[epoch:  23/100000, batch:    18/  187, ite: 2077] train loss: 0.610487, tar: 0.079345 
l0: 0.076815, l1: 0.074929, l2: 0.080339, l3: 0.082658, l4: 0.103564, l5: 0.094983, l6: 0.084441

[epoch:  23/100000, batch:    20/  187, ite: 2078] train loss: 0.610324, tar: 0.079312 
l0: 0.075133, l1: 0.073736, l2: 0.068331, l3: 0.070869, l4: 0.074937, l5: 0.100420, l6: 0.089502

[epoch:  23/100000, batch:    22/  187, ite: 2079] train loss: 0.609597, tar: 0.079259 
l0: 0.087298, l1: 0.078993, l2: 0.101561, l3: 0.105924, l4: 0.098214, l5: 0.104668, l6: 0.118172

[epoch:  23/100000, batch:    24/  187, ite: 2080] train loss: 0.610663, tar: 0.079360 
l0: 0.054725, l1: 0.050062, l2: 0.054878, l3: 0.061356, l4: 0.068245, l5: 0.074695, l6: 0.076987

[epoch:  23/100000, batch:    26/  187, ite: 2081] train loss: 0.608567, tar: 0.079056 
l0: 0.070102, l1: 0.069232, l2: 0.081139, l3: 0.081588, l4: 0.094531, l5: 0.126119, l6: 0.142766

[epoch:  23/100000, batch:    28/  187, ite: 2082] train loss: 0.609261, tar: 0.078946 
l0: 0.109178, l1: 0.138919, l2: 0.139208, l3: 0.122136, l4: 0.091488, l5: 0.095069, l6: 0.100302

[epoch:  23/100000, batch:    30/  187, ite: 2083] train loss: 0.611515, tar: 0.079311 
l0: 0.054802, l1: 0.047777, l2: 0.066703, l3: 0.074587, l4: 0.072521, l5: 0.077393, l6: 0.078656

[epoch:  23/100000, batch:    32/  187, ite: 2084] train loss: 0.609859, tar: 0.079019 
l0: 0.059323, l1: 0.061953, l2: 0.069442, l3: 0.074244, l4: 0.070687, l5: 0.078770, l6: 0.076942

[epoch:  23/100000, batch:    34/  187, ite: 2085] train loss: 0.608465, tar: 0.078787 
l0: 0.053444, l1: 0.059935, l2: 0.061731, l3: 0.065921, l4: 0.056267, l5: 0.060515, l6: 0.054236

[epoch:  23/100000, batch:    36/  187, ite: 2086] train loss: 0.606181, tar: 0.078492 
l0: 0.058162, l1: 0.055902, l2: 0.064571, l3: 0.068002, l4: 0.097186, l5: 0.085612, l6: 0.080540

[epoch:  23/100000, batch:    38/  187, ite: 2087] train loss: 0.605075, tar: 0.078259 
l0: 0.071524, l1: 0.052251, l2: 0.080888, l3: 0.096029, l4: 0.106919, l5: 0.093739, l6: 0.114120

[epoch:  23/100000, batch:    40/  187, ite: 2088] train loss: 0.605194, tar: 0.078182 
l0: 0.073109, l1: 0.078779, l2: 0.093013, l3: 0.089694, l4: 0.086160, l5: 0.087739, l6: 0.087599

[epoch:  23/100000, batch:    42/  187, ite: 2089] train loss: 0.605091, tar: 0.078125 
l0: 0.111611, l1: 0.126274, l2: 0.115765, l3: 0.100898, l4: 0.160861, l5: 0.142216, l6: 0.159631

[epoch:  23/100000, batch:    44/  187, ite: 2090] train loss: 0.608560, tar: 0.078497 
l0: 0.124204, l1: 0.113589, l2: 0.111134, l3: 0.118404, l4: 0.176798, l5: 0.164250, l6: 0.166931

[epoch:  23/100000, batch:    46/  187, ite: 2091] train loss: 0.612590, tar: 0.079000 
l0: 0.075521, l1: 0.066374, l2: 0.076697, l3: 0.085514, l4: 0.123214, l5: 0.110592, l6: 0.102434

[epoch:  23/100000, batch:    48/  187, ite: 2092] train loss: 0.612892, tar: 0.078962 
l0: 0.038174, l1: 0.040205, l2: 0.043047, l3: 0.042829, l4: 0.048462, l5: 0.046945, l6: 0.045856

[epoch:  23/100000, batch:    50/  187, ite: 2093] train loss: 0.609587, tar: 0.078523 
l0: 0.066048, l1: 0.088953, l2: 0.070284, l3: 0.066546, l4: 0.072322, l5: 0.054991, l6: 0.048443

[epoch:  23/100000, batch:    52/  187, ite: 2094] train loss: 0.608076, tar: 0.078390 
l0: 0.119732, l1: 0.111672, l2: 0.141092, l3: 0.150872, l4: 0.148144, l5: 0.141888, l6: 0.143920

[epoch:  23/100000, batch:    54/  187, ite: 2095] train loss: 0.611752, tar: 0.078826 
l0: 0.077925, l1: 0.071782, l2: 0.079385, l3: 0.080765, l4: 0.090025, l5: 0.095433, l6: 0.090677

[epoch:  23/100000, batch:    56/  187, ite: 2096] train loss: 0.611484, tar: 0.078816 
l0: 0.090989, l1: 0.100312, l2: 0.085585, l3: 0.084586, l4: 0.092828, l5: 0.094417, l6: 0.098724

[epoch:  23/100000, batch:    58/  187, ite: 2097] train loss: 0.611855, tar: 0.078942 
l0: 0.049029, l1: 0.041542, l2: 0.053887, l3: 0.056910, l4: 0.070317, l5: 0.065988, l6: 0.058985

[epoch:  23/100000, batch:    60/  187, ite: 2098] train loss: 0.609659, tar: 0.078637 
l0: 0.092787, l1: 0.096861, l2: 0.120092, l3: 0.118256, l4: 0.119312, l5: 0.114299, l6: 0.116300

[epoch:  23/100000, batch:    62/  187, ite: 2099] train loss: 0.611358, tar: 0.078779 
l0: 0.070698, l1: 0.085816, l2: 0.085016, l3: 0.084745, l4: 0.080970, l5: 0.073333, l6: 0.076910

[epoch:  23/100000, batch:    64/  187, ite: 2100] train loss: 0.610819, tar: 0.078699 
l0: 0.088991, l1: 0.088537, l2: 0.080177, l3: 0.078472, l4: 0.105064, l5: 0.109980, l6: 0.122034

[epoch:  23/100000, batch:    66/  187, ite: 2101] train loss: 0.611438, tar: 0.078801 
l0: 0.069008, l1: 0.057906, l2: 0.072527, l3: 0.074340, l4: 0.091705, l5: 0.106511, l6: 0.105155

[epoch:  23/100000, batch:    68/  187, ite: 2102] train loss: 0.611102, tar: 0.078705 
l0: 0.071151, l1: 0.070584, l2: 0.084039, l3: 0.080719, l4: 0.085829, l5: 0.084578, l6: 0.086104

[epoch:  23/100000, batch:    70/  187, ite: 2103] train loss: 0.610635, tar: 0.078631 
l0: 0.069130, l1: 0.072207, l2: 0.088124, l3: 0.089785, l4: 0.083101, l5: 0.089952, l6: 0.079133

[epoch:  23/100000, batch:    72/  187, ite: 2104] train loss: 0.610258, tar: 0.078540 
l0: 0.048799, l1: 0.048908, l2: 0.048291, l3: 0.049585, l4: 0.051016, l5: 0.062624, l6: 0.058474

[epoch:  23/100000, batch:    74/  187, ite: 2105] train loss: 0.607948, tar: 0.078257 
l0: 0.080781, l1: 0.074464, l2: 0.106945, l3: 0.110390, l4: 0.105831, l5: 0.111812, l6: 0.123286

[epoch:  23/100000, batch:    76/  187, ite: 2106] train loss: 0.608943, tar: 0.078280 
l0: 0.041621, l1: 0.044439, l2: 0.043229, l3: 0.042428, l4: 0.045608, l5: 0.047998, l6: 0.046058

[epoch:  23/100000, batch:    78/  187, ite: 2107] train loss: 0.606162, tar: 0.077938 
l0: 0.104227, l1: 0.103639, l2: 0.106777, l3: 0.113867, l4: 0.112549, l5: 0.121962, l6: 0.119851

[epoch:  23/100000, batch:    80/  187, ite: 2108] train loss: 0.607799, tar: 0.078181 
l0: 0.073329, l1: 0.061630, l2: 0.088351, l3: 0.081250, l4: 0.103652, l5: 0.111630, l6: 0.107371

[epoch:  23/100000, batch:    82/  187, ite: 2109] train loss: 0.607977, tar: 0.078137 
l0: 0.064181, l1: 0.066924, l2: 0.078831, l3: 0.078791, l4: 0.084700, l5: 0.084022, l6: 0.081743

[epoch:  23/100000, batch:    84/  187, ite: 2110] train loss: 0.607351, tar: 0.078010 
l0: 0.056503, l1: 0.056083, l2: 0.062117, l3: 0.056069, l4: 0.072027, l5: 0.071292, l6: 0.083689

[epoch:  23/100000, batch:    86/  187, ite: 2111] train loss: 0.606004, tar: 0.077816 
l0: 0.064443, l1: 0.074927, l2: 0.075792, l3: 0.080747, l4: 0.071443, l5: 0.071590, l6: 0.070132

[epoch:  23/100000, batch:    88/  187, ite: 2112] train loss: 0.605138, tar: 0.077697 
l0: 0.053127, l1: 0.058167, l2: 0.053367, l3: 0.052237, l4: 0.064865, l5: 0.066757, l6: 0.066512

[epoch:  23/100000, batch:    90/  187, ite: 2113] train loss: 0.603456, tar: 0.077479 
l0: 0.059278, l1: 0.061842, l2: 0.055779, l3: 0.058120, l4: 0.069264, l5: 0.072805, l6: 0.077991

[epoch:  23/100000, batch:    92/  187, ite: 2114] train loss: 0.602155, tar: 0.077320 
l0: 0.076347, l1: 0.069116, l2: 0.092651, l3: 0.091526, l4: 0.088146, l5: 0.087057, l6: 0.090452

[epoch:  23/100000, batch:    94/  187, ite: 2115] train loss: 0.602095, tar: 0.077311 
l0: 0.085840, l1: 0.088474, l2: 0.083510, l3: 0.074990, l4: 0.096086, l5: 0.088718, l6: 0.087307

[epoch:  23/100000, batch:    96/  187, ite: 2116] train loss: 0.602119, tar: 0.077385 
l0: 0.086019, l1: 0.099063, l2: 0.078787, l3: 0.072700, l4: 0.082434, l5: 0.068478, l6: 0.083515

[epoch:  23/100000, batch:    98/  187, ite: 2117] train loss: 0.601853, tar: 0.077458 
l0: 0.068728, l1: 0.060962, l2: 0.061435, l3: 0.065209, l4: 0.083014, l5: 0.099568, l6: 0.093612

[epoch:  23/100000, batch:   100/  187, ite: 2118] train loss: 0.601266, tar: 0.077384 
l0: 0.043610, l1: 0.052788, l2: 0.046894, l3: 0.049157, l4: 0.045912, l5: 0.049957, l6: 0.054789

[epoch:  23/100000, batch:   102/  187, ite: 2119] train loss: 0.599096, tar: 0.077101 
l0: 0.114771, l1: 0.124517, l2: 0.117062, l3: 0.105753, l4: 0.123101, l5: 0.113265, l6: 0.110791

[epoch:  23/100000, batch:   104/  187, ite: 2120] train loss: 0.600848, tar: 0.077415 
l0: 0.087172, l1: 0.079380, l2: 0.098780, l3: 0.101549, l4: 0.117278, l5: 0.114317, l6: 0.118291

[epoch:  23/100000, batch:   106/  187, ite: 2121] train loss: 0.601806, tar: 0.077495 
l0: 0.106501, l1: 0.114540, l2: 0.097897, l3: 0.100754, l4: 0.120357, l5: 0.109073, l6: 0.118016

[epoch:  23/100000, batch:   108/  187, ite: 2122] train loss: 0.603161, tar: 0.077733 
l0: 0.105822, l1: 0.099624, l2: 0.119085, l3: 0.110374, l4: 0.132693, l5: 0.145924, l6: 0.133804

[epoch:  23/100000, batch:   110/  187, ite: 2123] train loss: 0.605146, tar: 0.077961 
l0: 0.074938, l1: 0.069149, l2: 0.114233, l3: 0.111383, l4: 0.126333, l5: 0.119896, l6: 0.126234

[epoch:  23/100000, batch:   112/  187, ite: 2124] train loss: 0.606251, tar: 0.077937 
l0: 0.063327, l1: 0.057616, l2: 0.059713, l3: 0.060662, l4: 0.080241, l5: 0.093545, l6: 0.088630

[epoch:  23/100000, batch:   114/  187, ite: 2125] train loss: 0.605431, tar: 0.077820 
l0: 0.062853, l1: 0.063864, l2: 0.070667, l3: 0.074338, l4: 0.075489, l5: 0.075682, l6: 0.078629

[epoch:  23/100000, batch:   116/  187, ite: 2126] train loss: 0.604606, tar: 0.077701 
l0: 0.067514, l1: 0.062838, l2: 0.075169, l3: 0.080427, l4: 0.079586, l5: 0.089909, l6: 0.079593

[epoch:  23/100000, batch:   118/  187, ite: 2127] train loss: 0.604058, tar: 0.077621 
l0: 0.084513, l1: 0.071858, l2: 0.083404, l3: 0.083578, l4: 0.123247, l5: 0.119861, l6: 0.099107

[epoch:  23/100000, batch:   120/  187, ite: 2128] train loss: 0.604539, tar: 0.077675 
l0: 0.090790, l1: 0.096538, l2: 0.100389, l3: 0.111947, l4: 0.094894, l5: 0.087624, l6: 0.088718

[epoch:  23/100000, batch:   122/  187, ite: 2129] train loss: 0.605053, tar: 0.077777 
l0: 0.072771, l1: 0.066576, l2: 0.077507, l3: 0.081186, l4: 0.092485, l5: 0.096929, l6: 0.087270

[epoch:  23/100000, batch:   124/  187, ite: 2130] train loss: 0.604820, tar: 0.077738 
l0: 0.053276, l1: 0.056571, l2: 0.067192, l3: 0.060235, l4: 0.062667, l5: 0.061906, l6: 0.057548

[epoch:  23/100000, batch:   126/  187, ite: 2131] train loss: 0.603405, tar: 0.077551 
l0: 0.072033, l1: 0.065660, l2: 0.078223, l3: 0.083411, l4: 0.102286, l5: 0.103445, l6: 0.101015

[epoch:  23/100000, batch:   128/  187, ite: 2132] train loss: 0.603425, tar: 0.077510 
l0: 0.059046, l1: 0.066611, l2: 0.072968, l3: 0.081048, l4: 0.079351, l5: 0.070422, l6: 0.061393

[epoch:  23/100000, batch:   130/  187, ite: 2133] train loss: 0.602578, tar: 0.077371 
l0: 0.046441, l1: 0.037347, l2: 0.061559, l3: 0.071419, l4: 0.078334, l5: 0.073026, l6: 0.067438

[epoch:  23/100000, batch:   132/  187, ite: 2134] train loss: 0.601332, tar: 0.077140 
l0: 0.056527, l1: 0.057815, l2: 0.064071, l3: 0.060244, l4: 0.065367, l5: 0.071572, l6: 0.074058

[epoch:  23/100000, batch:   134/  187, ite: 2135] train loss: 0.600208, tar: 0.076987 
l0: 0.058090, l1: 0.058339, l2: 0.057525, l3: 0.056892, l4: 0.080557, l5: 0.070043, l6: 0.063452

[epoch:  23/100000, batch:   136/  187, ite: 2136] train loss: 0.599066, tar: 0.076848 
l0: 0.108679, l1: 0.135127, l2: 0.097718, l3: 0.099372, l4: 0.088365, l5: 0.084222, l6: 0.085549

[epoch:  23/100000, batch:   138/  187, ite: 2137] train loss: 0.599796, tar: 0.077081 
l0: 0.064834, l1: 0.083201, l2: 0.077441, l3: 0.069978, l4: 0.064639, l5: 0.065942, l6: 0.067373

[epoch:  23/100000, batch:   140/  187, ite: 2138] train loss: 0.599025, tar: 0.076992 
l0: 0.069704, l1: 0.086824, l2: 0.069094, l3: 0.067847, l4: 0.077420, l5: 0.065806, l6: 0.058804

[epoch:  23/100000, batch:   142/  187, ite: 2139] train loss: 0.598280, tar: 0.076939 
l0: 0.109774, l1: 0.151418, l2: 0.089182, l3: 0.091273, l4: 0.084559, l5: 0.073236, l6: 0.076519

[epoch:  23/100000, batch:   144/  187, ite: 2140] train loss: 0.598835, tar: 0.077174 
l0: 0.067358, l1: 0.073911, l2: 0.054634, l3: 0.071311, l4: 0.081597, l5: 0.075927, l6: 0.063950

[epoch:  23/100000, batch:   146/  187, ite: 2141] train loss: 0.598054, tar: 0.077104 
l0: 0.067675, l1: 0.081309, l2: 0.060108, l3: 0.058468, l4: 0.076669, l5: 0.073109, l6: 0.069634

[epoch:  23/100000, batch:   148/  187, ite: 2142] train loss: 0.597272, tar: 0.077038 
l0: 0.049210, l1: 0.039802, l2: 0.063236, l3: 0.065810, l4: 0.077465, l5: 0.083212, l6: 0.071598

[epoch:  23/100000, batch:   150/  187, ite: 2143] train loss: 0.596244, tar: 0.076843 
l0: 0.072144, l1: 0.080669, l2: 0.063402, l3: 0.064670, l4: 0.070196, l5: 0.071905, l6: 0.066228

[epoch:  23/100000, batch:   152/  187, ite: 2144] train loss: 0.595501, tar: 0.076811 
l0: 0.067754, l1: 0.067989, l2: 0.066181, l3: 0.058361, l4: 0.090450, l5: 0.088624, l6: 0.085118

[epoch:  23/100000, batch:   154/  187, ite: 2145] train loss: 0.595011, tar: 0.076748 
l0: 0.123993, l1: 0.143327, l2: 0.136092, l3: 0.134545, l4: 0.113075, l5: 0.121539, l6: 0.131334

[epoch:  23/100000, batch:   156/  187, ite: 2146] train loss: 0.597127, tar: 0.077072 
l0: 0.064286, l1: 0.075098, l2: 0.072253, l3: 0.074468, l4: 0.070047, l5: 0.064228, l6: 0.068201

[epoch:  23/100000, batch:   158/  187, ite: 2147] train loss: 0.596388, tar: 0.076985 
l0: 0.076332, l1: 0.070156, l2: 0.087976, l3: 0.079161, l4: 0.091637, l5: 0.117598, l6: 0.097840

[epoch:  23/100000, batch:   160/  187, ite: 2148] train loss: 0.596553, tar: 0.076980 
l0: 0.069889, l1: 0.081635, l2: 0.073215, l3: 0.085383, l4: 0.067292, l5: 0.068642, l6: 0.066575

[epoch:  23/100000, batch:   162/  187, ite: 2149] train loss: 0.595990, tar: 0.076933 
l0: 0.094722, l1: 0.105187, l2: 0.121625, l3: 0.112477, l4: 0.093229, l5: 0.098552, l6: 0.095090

[epoch:  23/100000, batch:   164/  187, ite: 2150] train loss: 0.596822, tar: 0.077051 
l0: 0.072721, l1: 0.071125, l2: 0.083022, l3: 0.085948, l4: 0.085399, l5: 0.088699, l6: 0.103547

[epoch:  23/100000, batch:   166/  187, ite: 2151] train loss: 0.596780, tar: 0.077023 
l0: 0.071964, l1: 0.076978, l2: 0.079633, l3: 0.074624, l4: 0.080981, l5: 0.076275, l6: 0.084042

[epoch:  23/100000, batch:   168/  187, ite: 2152] train loss: 0.596436, tar: 0.076989 
l0: 0.075367, l1: 0.078879, l2: 0.074868, l3: 0.076905, l4: 0.078592, l5: 0.080583, l6: 0.073361

[epoch:  23/100000, batch:   170/  187, ite: 2153] train loss: 0.596058, tar: 0.076979 
l0: 0.090643, l1: 0.092191, l2: 0.110557, l3: 0.098998, l4: 0.099228, l5: 0.099965, l6: 0.088696

[epoch:  23/100000, batch:   172/  187, ite: 2154] train loss: 0.596605, tar: 0.077068 
l0: 0.097028, l1: 0.104612, l2: 0.106793, l3: 0.106466, l4: 0.093713, l5: 0.087014, l6: 0.090999

[epoch:  23/100000, batch:   174/  187, ite: 2155] train loss: 0.597185, tar: 0.077196 
l0: 0.043369, l1: 0.046599, l2: 0.053604, l3: 0.051011, l4: 0.045038, l5: 0.047201, l6: 0.044580

[epoch:  23/100000, batch:   176/  187, ite: 2156] train loss: 0.595482, tar: 0.076980 
l0: 0.100607, l1: 0.110911, l2: 0.102497, l3: 0.097575, l4: 0.092797, l5: 0.082918, l6: 0.084828

[epoch:  23/100000, batch:   178/  187, ite: 2157] train loss: 0.595970, tar: 0.077130 
l0: 0.090989, l1: 0.093471, l2: 0.090768, l3: 0.093663, l4: 0.077219, l5: 0.075789, l6: 0.077024

[epoch:  23/100000, batch:   180/  187, ite: 2158] train loss: 0.595989, tar: 0.077218 
l0: 0.047281, l1: 0.047905, l2: 0.053286, l3: 0.050711, l4: 0.061027, l5: 0.057407, l6: 0.048914

[epoch:  23/100000, batch:   182/  187, ite: 2159] train loss: 0.594545, tar: 0.077029 
l0: 0.053914, l1: 0.059515, l2: 0.070785, l3: 0.065400, l4: 0.068062, l5: 0.066536, l6: 0.063710

[epoch:  23/100000, batch:   184/  187, ite: 2160] train loss: 0.593629, tar: 0.076885 
l0: 0.076859, l1: 0.074936, l2: 0.078467, l3: 0.072791, l4: 0.085742, l5: 0.088321, l6: 0.094827

[epoch:  23/100000, batch:   186/  187, ite: 2161] train loss: 0.593494, tar: 0.076885 
l0: 0.087813, l1: 0.062796, l2: 0.082524, l3: 0.096286, l4: 0.137993, l5: 0.147153, l6: 0.167689

[epoch:  23/100000, batch:   188/  187, ite: 2162] train loss: 0.594660, tar: 0.076952 
l0: 0.064131, l1: 0.064827, l2: 0.081699, l3: 0.085433, l4: 0.073079, l5: 0.069581, l6: 0.065540

[epoch:  24/100000, batch:     2/  187, ite: 2163] train loss: 0.594105, tar: 0.076874 
l0: 0.087233, l1: 0.085754, l2: 0.089845, l3: 0.087407, l4: 0.096762, l5: 0.098272, l6: 0.094846

[epoch:  24/100000, batch:     4/  187, ite: 2164] train loss: 0.594386, tar: 0.076937 
l0: 0.108292, l1: 0.117168, l2: 0.106631, l3: 0.102879, l4: 0.109592, l5: 0.107658, l6: 0.105834

[epoch:  24/100000, batch:     6/  187, ite: 2165] train loss: 0.595378, tar: 0.077127 
l0: 0.081026, l1: 0.095278, l2: 0.076310, l3: 0.073710, l4: 0.076345, l5: 0.085503, l6: 0.081623

[epoch:  24/100000, batch:     8/  187, ite: 2166] train loss: 0.595223, tar: 0.077150 
l0: 0.093215, l1: 0.083537, l2: 0.101041, l3: 0.100175, l4: 0.116303, l5: 0.109590, l6: 0.106823

[epoch:  24/100000, batch:    10/  187, ite: 2167] train loss: 0.595915, tar: 0.077247 
l0: 0.060158, l1: 0.052690, l2: 0.066640, l3: 0.066958, l4: 0.080036, l5: 0.079885, l6: 0.068386

[epoch:  24/100000, batch:    12/  187, ite: 2168] train loss: 0.595194, tar: 0.077145 
l0: 0.060628, l1: 0.066175, l2: 0.057514, l3: 0.060742, l4: 0.068930, l5: 0.069796, l6: 0.075431

[epoch:  24/100000, batch:    14/  187, ite: 2169] train loss: 0.594389, tar: 0.077047 
l0: 0.060986, l1: 0.076141, l2: 0.056370, l3: 0.052321, l4: 0.058610, l5: 0.054552, l6: 0.052105

[epoch:  24/100000, batch:    16/  187, ite: 2170] train loss: 0.593311, tar: 0.076953 
l0: 0.069197, l1: 0.061736, l2: 0.071349, l3: 0.069043, l4: 0.081583, l5: 0.075707, l6: 0.072775

[epoch:  24/100000, batch:    18/  187, ite: 2171] train loss: 0.592773, tar: 0.076907 
l0: 0.054685, l1: 0.052680, l2: 0.063921, l3: 0.061783, l4: 0.066989, l5: 0.064638, l6: 0.062342

[epoch:  24/100000, batch:    20/  187, ite: 2172] train loss: 0.591810, tar: 0.076778 
l0: 0.056012, l1: 0.056046, l2: 0.059442, l3: 0.055843, l4: 0.072024, l5: 0.084596, l6: 0.080148

[epoch:  24/100000, batch:    22/  187, ite: 2173] train loss: 0.591072, tar: 0.076658 
l0: 0.102003, l1: 0.099679, l2: 0.094731, l3: 0.091102, l4: 0.114890, l5: 0.127998, l6: 0.126727

[epoch:  24/100000, batch:    24/  187, ite: 2174] train loss: 0.592026, tar: 0.076804 
l0: 0.068838, l1: 0.059211, l2: 0.079123, l3: 0.071559, l4: 0.080280, l5: 0.100654, l6: 0.081404

[epoch:  24/100000, batch:    26/  187, ite: 2175] train loss: 0.591735, tar: 0.076758 
l0: 0.069387, l1: 0.078295, l2: 0.084166, l3: 0.085153, l4: 0.088784, l5: 0.083740, l6: 0.083112

[epoch:  24/100000, batch:    28/  187, ite: 2176] train loss: 0.591626, tar: 0.076716 
l0: 0.078137, l1: 0.073779, l2: 0.082932, l3: 0.082776, l4: 0.089618, l5: 0.090223, l6: 0.084896

[epoch:  24/100000, batch:    30/  187, ite: 2177] train loss: 0.591574, tar: 0.076724 
l0: 0.086540, l1: 0.090733, l2: 0.090506, l3: 0.099298, l4: 0.109124, l5: 0.097509, l6: 0.102052

[epoch:  24/100000, batch:    32/  187, ite: 2178] train loss: 0.592047, tar: 0.076779 
l0: 0.055650, l1: 0.057971, l2: 0.057115, l3: 0.056052, l4: 0.066111, l5: 0.068512, l6: 0.061482

[epoch:  24/100000, batch:    34/  187, ite: 2179] train loss: 0.591102, tar: 0.076661 
l0: 0.075570, l1: 0.067241, l2: 0.070228, l3: 0.074272, l4: 0.075766, l5: 0.086085, l6: 0.082889

[epoch:  24/100000, batch:    36/  187, ite: 2180] train loss: 0.590774, tar: 0.076655 
l0: 0.045364, l1: 0.048048, l2: 0.051028, l3: 0.045820, l4: 0.055336, l5: 0.054628, l6: 0.053638

[epoch:  24/100000, batch:    38/  187, ite: 2181] train loss: 0.589465, tar: 0.076482 
l0: 0.063375, l1: 0.074465, l2: 0.063243, l3: 0.060021, l4: 0.071113, l5: 0.073227, l6: 0.059668

[epoch:  24/100000, batch:    40/  187, ite: 2182] train loss: 0.588782, tar: 0.076410 
l0: 0.111370, l1: 0.134248, l2: 0.118512, l3: 0.115225, l4: 0.083276, l5: 0.087004, l6: 0.074457

[epoch:  24/100000, batch:    42/  187, ite: 2183] train loss: 0.589521, tar: 0.076601 
l0: 0.093397, l1: 0.109457, l2: 0.117615, l3: 0.110221, l4: 0.079116, l5: 0.082472, l6: 0.086804

[epoch:  24/100000, batch:    44/  187, ite: 2184] train loss: 0.590008, tar: 0.076693 
l0: 0.212622, l1: 0.256448, l2: 0.212145, l3: 0.189323, l4: 0.181605, l5: 0.226694, l6: 0.214100

[epoch:  24/100000, batch:    46/  187, ite: 2185] train loss: 0.594888, tar: 0.077428 
l0: 0.067540, l1: 0.070810, l2: 0.077778, l3: 0.080890, l4: 0.086445, l5: 0.065899, l6: 0.069280

[epoch:  24/100000, batch:    48/  187, ite: 2186] train loss: 0.594479, tar: 0.077374 
l0: 0.131393, l1: 0.151096, l2: 0.142213, l3: 0.152366, l4: 0.161928, l5: 0.132707, l6: 0.132770

[epoch:  24/100000, batch:    50/  187, ite: 2187] train loss: 0.596671, tar: 0.077663 
l0: 0.084638, l1: 0.073725, l2: 0.094901, l3: 0.100336, l4: 0.101470, l5: 0.132487, l6: 0.114946

[epoch:  24/100000, batch:    52/  187, ite: 2188] train loss: 0.597234, tar: 0.077700 
l0: 0.067510, l1: 0.072192, l2: 0.073063, l3: 0.070524, l4: 0.073005, l5: 0.077055, l6: 0.081459

[epoch:  24/100000, batch:    54/  187, ite: 2189] train loss: 0.596798, tar: 0.077646 
l0: 0.042812, l1: 0.050870, l2: 0.040716, l3: 0.035013, l4: 0.037878, l5: 0.047801, l6: 0.052469

[epoch:  24/100000, batch:    56/  187, ite: 2190] train loss: 0.595275, tar: 0.077463 
l0: 0.103094, l1: 0.097421, l2: 0.110067, l3: 0.121121, l4: 0.126552, l5: 0.120087, l6: 0.115879

[epoch:  24/100000, batch:    58/  187, ite: 2191] train loss: 0.596317, tar: 0.077597 
l0: 0.095609, l1: 0.097425, l2: 0.093236, l3: 0.100496, l4: 0.117877, l5: 0.110789, l6: 0.115519

[epoch:  24/100000, batch:    60/  187, ite: 2192] train loss: 0.597018, tar: 0.077691 
l0: 0.098176, l1: 0.087699, l2: 0.110663, l3: 0.114143, l4: 0.107733, l5: 0.115876, l6: 0.097720

[epoch:  24/100000, batch:    62/  187, ite: 2193] train loss: 0.597718, tar: 0.077797 
l0: 0.121953, l1: 0.122435, l2: 0.123534, l3: 0.124183, l4: 0.116047, l5: 0.110423, l6: 0.117360

[epoch:  24/100000, batch:    64/  187, ite: 2194] train loss: 0.598946, tar: 0.078025 
l0: 0.072176, l1: 0.073011, l2: 0.069626, l3: 0.063625, l4: 0.070107, l5: 0.071074, l6: 0.075143

[epoch:  24/100000, batch:    66/  187, ite: 2195] train loss: 0.598411, tar: 0.077995 
l0: 0.119824, l1: 0.118860, l2: 0.104900, l3: 0.108072, l4: 0.121718, l5: 0.139113, l6: 0.139159

[epoch:  24/100000, batch:    68/  187, ite: 2196] train loss: 0.599703, tar: 0.078208 
l0: 0.076043, l1: 0.072485, l2: 0.081070, l3: 0.084178, l4: 0.086520, l5: 0.093384, l6: 0.086504

[epoch:  24/100000, batch:    70/  187, ite: 2197] train loss: 0.599604, tar: 0.078197 
l0: 0.120575, l1: 0.118638, l2: 0.126515, l3: 0.133556, l4: 0.135734, l5: 0.120886, l6: 0.172639

[epoch:  24/100000, batch:    72/  187, ite: 2198] train loss: 0.601266, tar: 0.078411 
l0: 0.085713, l1: 0.078485, l2: 0.093471, l3: 0.085545, l4: 0.100864, l5: 0.093219, l6: 0.093357

[epoch:  24/100000, batch:    74/  187, ite: 2199] train loss: 0.601413, tar: 0.078448 
l0: 0.067048, l1: 0.072836, l2: 0.064307, l3: 0.081596, l4: 0.093531, l5: 0.074821, l6: 0.091231

[epoch:  24/100000, batch:    76/  187, ite: 2200] train loss: 0.601133, tar: 0.078391 
l0: 0.102329, l1: 0.097916, l2: 0.107852, l3: 0.113996, l4: 0.112930, l5: 0.106177, l6: 0.110366

[epoch:  24/100000, batch:    78/  187, ite: 2201] train loss: 0.601882, tar: 0.078510 
l0: 0.066503, l1: 0.059661, l2: 0.081189, l3: 0.082328, l4: 0.096322, l5: 0.087465, l6: 0.081945

[epoch:  24/100000, batch:    80/  187, ite: 2202] train loss: 0.601651, tar: 0.078451 
l0: 0.077391, l1: 0.075884, l2: 0.083297, l3: 0.079496, l4: 0.081339, l5: 0.084136, l6: 0.084606

[epoch:  24/100000, batch:    82/  187, ite: 2203] train loss: 0.601477, tar: 0.078445 
l0: 0.087426, l1: 0.079934, l2: 0.095453, l3: 0.096115, l4: 0.087682, l5: 0.096532, l6: 0.093404

[epoch:  24/100000, batch:    84/  187, ite: 2204] train loss: 0.601648, tar: 0.078489 
l0: 0.067712, l1: 0.062236, l2: 0.077005, l3: 0.082775, l4: 0.080516, l5: 0.086093, l6: 0.093964

[epoch:  24/100000, batch:    86/  187, ite: 2205] train loss: 0.601398, tar: 0.078437 
l0: 0.075683, l1: 0.067333, l2: 0.083757, l3: 0.087525, l4: 0.093938, l5: 0.088800, l6: 0.088641

[epoch:  24/100000, batch:    88/  187, ite: 2206] train loss: 0.601322, tar: 0.078423 
l0: 0.067819, l1: 0.062905, l2: 0.075230, l3: 0.075730, l4: 0.081379, l5: 0.078533, l6: 0.075960

[epoch:  24/100000, batch:    90/  187, ite: 2207] train loss: 0.600917, tar: 0.078372 
l0: 0.105790, l1: 0.109275, l2: 0.123207, l3: 0.124379, l4: 0.129383, l5: 0.120289, l6: 0.128219

[epoch:  24/100000, batch:    92/  187, ite: 2208] train loss: 0.602069, tar: 0.078504 
l0: 0.080749, l1: 0.076338, l2: 0.096831, l3: 0.094235, l4: 0.093691, l5: 0.103595, l6: 0.109648

[epoch:  24/100000, batch:    94/  187, ite: 2209] train loss: 0.602323, tar: 0.078515 
l0: 0.093432, l1: 0.101707, l2: 0.101318, l3: 0.104025, l4: 0.101742, l5: 0.107612, l6: 0.095654

[epoch:  24/100000, batch:    96/  187, ite: 2210] train loss: 0.602814, tar: 0.078586 
l0: 0.056389, l1: 0.052993, l2: 0.057608, l3: 0.057668, l4: 0.061152, l5: 0.067551, l6: 0.065242

[epoch:  24/100000, batch:    98/  187, ite: 2211] train loss: 0.601941, tar: 0.078481 
l0: 0.062134, l1: 0.063026, l2: 0.070970, l3: 0.069476, l4: 0.073968, l5: 0.067084, l6: 0.065293

[epoch:  24/100000, batch:   100/  187, ite: 2212] train loss: 0.601328, tar: 0.078404 
l0: 0.047836, l1: 0.042670, l2: 0.071496, l3: 0.070043, l4: 0.063650, l5: 0.062119, l6: 0.073869

[epoch:  24/100000, batch:   102/  187, ite: 2213] train loss: 0.600531, tar: 0.078260 
l0: 0.059263, l1: 0.053086, l2: 0.082257, l3: 0.089468, l4: 0.080862, l5: 0.068841, l6: 0.083840

[epoch:  24/100000, batch:   104/  187, ite: 2214] train loss: 0.600144, tar: 0.078171 
l0: 0.111867, l1: 0.099674, l2: 0.131940, l3: 0.139492, l4: 0.137255, l5: 0.132386, l6: 0.149279

[epoch:  24/100000, batch:   106/  187, ite: 2215] train loss: 0.601547, tar: 0.078328 
l0: 0.082977, l1: 0.072706, l2: 0.103194, l3: 0.097744, l4: 0.085375, l5: 0.093394, l6: 0.094510

[epoch:  24/100000, batch:   108/  187, ite: 2216] train loss: 0.601679, tar: 0.078350 
l0: 0.063473, l1: 0.057285, l2: 0.075574, l3: 0.078808, l4: 0.068512, l5: 0.063490, l6: 0.071725

[epoch:  24/100000, batch:   110/  187, ite: 2217] train loss: 0.601113, tar: 0.078281 
l0: 0.036592, l1: 0.047939, l2: 0.036959, l3: 0.036376, l4: 0.042740, l5: 0.043050, l6: 0.040309

[epoch:  24/100000, batch:   112/  187, ite: 2218] train loss: 0.599658, tar: 0.078090 
l0: 0.100841, l1: 0.093512, l2: 0.099596, l3: 0.092580, l4: 0.113281, l5: 0.116523, l6: 0.116988

[epoch:  24/100000, batch:   114/  187, ite: 2219] train loss: 0.600268, tar: 0.078194 
l0: 0.062876, l1: 0.061012, l2: 0.062782, l3: 0.066353, l4: 0.076071, l5: 0.079353, l6: 0.085678

[epoch:  24/100000, batch:   116/  187, ite: 2220] train loss: 0.599786, tar: 0.078124 
l0: 0.067825, l1: 0.055191, l2: 0.070738, l3: 0.076142, l4: 0.079659, l5: 0.097257, l6: 0.100153

[epoch:  24/100000, batch:   118/  187, ite: 2221] train loss: 0.599547, tar: 0.078077 
l0: 0.071322, l1: 0.064864, l2: 0.071592, l3: 0.069890, l4: 0.082151, l5: 0.076494, l6: 0.095825

[epoch:  24/100000, batch:   120/  187, ite: 2222] train loss: 0.599243, tar: 0.078047 
l0: 0.064939, l1: 0.062647, l2: 0.071794, l3: 0.075420, l4: 0.087314, l5: 0.092697, l6: 0.072799

[epoch:  24/100000, batch:   122/  187, ite: 2223] train loss: 0.598922, tar: 0.077988 
l0: 0.055739, l1: 0.053120, l2: 0.070780, l3: 0.078575, l4: 0.093244, l5: 0.089339, l6: 0.075734

[epoch:  24/100000, batch:   124/  187, ite: 2224] train loss: 0.598554, tar: 0.077889 
l0: 0.045620, l1: 0.047347, l2: 0.053840, l3: 0.070088, l4: 0.064754, l5: 0.061117, l6: 0.055247

[epoch:  24/100000, batch:   126/  187, ite: 2225] train loss: 0.597663, tar: 0.077745 
l0: 0.077446, l1: 0.079717, l2: 0.102668, l3: 0.099873, l4: 0.076041, l5: 0.084426, l6: 0.080546

[epoch:  24/100000, batch:   128/  187, ite: 2226] train loss: 0.597676, tar: 0.077744 
l0: 0.063300, l1: 0.061942, l2: 0.071963, l3: 0.079483, l4: 0.062603, l5: 0.064959, l6: 0.068171

[epoch:  24/100000, batch:   130/  187, ite: 2227] train loss: 0.597125, tar: 0.077680 
l0: 0.105620, l1: 0.098020, l2: 0.129906, l3: 0.124830, l4: 0.152811, l5: 0.158264, l6: 0.127687

[epoch:  24/100000, batch:   132/  187, ite: 2228] train loss: 0.598440, tar: 0.077803 
l0: 0.079801, l1: 0.076965, l2: 0.080815, l3: 0.082642, l4: 0.100585, l5: 0.108334, l6: 0.121893

[epoch:  24/100000, batch:   134/  187, ite: 2229] train loss: 0.598670, tar: 0.077812 
l0: 0.089351, l1: 0.079683, l2: 0.101932, l3: 0.099409, l4: 0.123979, l5: 0.134071, l6: 0.125120

[epoch:  24/100000, batch:   136/  187, ite: 2230] train loss: 0.599343, tar: 0.077862 
l0: 0.086482, l1: 0.094206, l2: 0.087420, l3: 0.079413, l4: 0.135933, l5: 0.122108, l6: 0.088184

[epoch:  24/100000, batch:   138/  187, ite: 2231] train loss: 0.599752, tar: 0.077899 
l0: 0.080978, l1: 0.094035, l2: 0.102374, l3: 0.098842, l4: 0.090558, l5: 0.085641, l6: 0.091053

[epoch:  24/100000, batch:   140/  187, ite: 2232] train loss: 0.599941, tar: 0.077912 
l0: 0.045204, l1: 0.057106, l2: 0.054742, l3: 0.045009, l4: 0.056622, l5: 0.056511, l6: 0.061510

[epoch:  24/100000, batch:   142/  187, ite: 2233] train loss: 0.598982, tar: 0.077772 
l0: 0.064172, l1: 0.068696, l2: 0.056230, l3: 0.059386, l4: 0.086557, l5: 0.088946, l6: 0.090461

[epoch:  24/100000, batch:   144/  187, ite: 2234] train loss: 0.598621, tar: 0.077714 
l0: 0.062849, l1: 0.075556, l2: 0.054537, l3: 0.053845, l4: 0.072652, l5: 0.074036, l6: 0.066374

[epoch:  24/100000, batch:   146/  187, ite: 2235] train loss: 0.598031, tar: 0.077651 
l0: 0.121600, l1: 0.113028, l2: 0.097809, l3: 0.115161, l4: 0.160937, l5: 0.208135, l6: 0.197554

[epoch:  24/100000, batch:   148/  187, ite: 2236] train loss: 0.599794, tar: 0.077837 
l0: 0.103854, l1: 0.106214, l2: 0.097926, l3: 0.097066, l4: 0.102601, l5: 0.114426, l6: 0.108307

[epoch:  24/100000, batch:   150/  187, ite: 2237] train loss: 0.600345, tar: 0.077947 
l0: 0.058592, l1: 0.043376, l2: 0.065658, l3: 0.067844, l4: 0.094411, l5: 0.094223, l6: 0.113514

[epoch:  24/100000, batch:   152/  187, ite: 2238] train loss: 0.600082, tar: 0.077865 
l0: 0.089687, l1: 0.082063, l2: 0.093214, l3: 0.101253, l4: 0.118292, l5: 0.115899, l6: 0.101199

[epoch:  24/100000, batch:   154/  187, ite: 2239] train loss: 0.600506, tar: 0.077915 
l0: 0.106949, l1: 0.115595, l2: 0.112912, l3: 0.120626, l4: 0.132092, l5: 0.117778, l6: 0.131813

[epoch:  24/100000, batch:   156/  187, ite: 2240] train loss: 0.601495, tar: 0.078036 
l0: 0.050889, l1: 0.060589, l2: 0.050953, l3: 0.068336, l4: 0.068317, l5: 0.058097, l6: 0.056166

[epoch:  24/100000, batch:   158/  187, ite: 2241] train loss: 0.600714, tar: 0.077923 
l0: 0.048146, l1: 0.048780, l2: 0.044513, l3: 0.048402, l4: 0.065545, l5: 0.082583, l6: 0.090538

[epoch:  24/100000, batch:   160/  187, ite: 2242] train loss: 0.600003, tar: 0.077800 
l0: 0.070682, l1: 0.082667, l2: 0.066615, l3: 0.068228, l4: 0.064407, l5: 0.066877, l6: 0.063801

[epoch:  24/100000, batch:   162/  187, ite: 2243] train loss: 0.599522, tar: 0.077771 
l0: 0.059400, l1: 0.057976, l2: 0.060913, l3: 0.062050, l4: 0.067607, l5: 0.077344, l6: 0.068736

[epoch:  24/100000, batch:   164/  187, ite: 2244] train loss: 0.598926, tar: 0.077696 
l0: 0.060932, l1: 0.052076, l2: 0.076458, l3: 0.074390, l4: 0.083619, l5: 0.087622, l6: 0.083896

[epoch:  24/100000, batch:   166/  187, ite: 2245] train loss: 0.598600, tar: 0.077627 
l0: 0.050074, l1: 0.053194, l2: 0.050873, l3: 0.053584, l4: 0.056502, l5: 0.060216, l6: 0.068513

[epoch:  24/100000, batch:   168/  187, ite: 2246] train loss: 0.597764, tar: 0.077515 
l0: 0.073819, l1: 0.061254, l2: 0.086354, l3: 0.087597, l4: 0.104341, l5: 0.114377, l6: 0.100899

[epoch:  24/100000, batch:   170/  187, ite: 2247] train loss: 0.597889, tar: 0.077500 
l0: 0.117899, l1: 0.125586, l2: 0.110420, l3: 0.141292, l4: 0.134485, l5: 0.119340, l6: 0.110089

[epoch:  24/100000, batch:   172/  187, ite: 2248] train loss: 0.598942, tar: 0.077663 
l0: 0.074885, l1: 0.083413, l2: 0.072942, l3: 0.070529, l4: 0.072789, l5: 0.067574, l6: 0.073086

[epoch:  24/100000, batch:   174/  187, ite: 2249] train loss: 0.598606, tar: 0.077652 
l0: 0.073143, l1: 0.064065, l2: 0.068876, l3: 0.072944, l4: 0.121572, l5: 0.119036, l6: 0.112294

[epoch:  24/100000, batch:   176/  187, ite: 2250] train loss: 0.598739, tar: 0.077634 
l0: 0.058330, l1: 0.049457, l2: 0.055180, l3: 0.063521, l4: 0.082586, l5: 0.094300, l6: 0.071413

[epoch:  24/100000, batch:   178/  187, ite: 2251] train loss: 0.598245, tar: 0.077557 
l0: 0.070747, l1: 0.065323, l2: 0.062229, l3: 0.067496, l4: 0.089628, l5: 0.091992, l6: 0.080498

[epoch:  24/100000, batch:   180/  187, ite: 2252] train loss: 0.597966, tar: 0.077530 
l0: 0.074661, l1: 0.075874, l2: 0.073859, l3: 0.072818, l4: 0.097029, l5: 0.085544, l6: 0.090932

[epoch:  24/100000, batch:   182/  187, ite: 2253] train loss: 0.597859, tar: 0.077519 
l0: 0.089277, l1: 0.084987, l2: 0.090403, l3: 0.095101, l4: 0.093818, l5: 0.104245, l6: 0.103178

[epoch:  24/100000, batch:   184/  187, ite: 2254] train loss: 0.598107, tar: 0.077565 
l0: 0.059639, l1: 0.058024, l2: 0.072888, l3: 0.067240, l4: 0.092332, l5: 0.082496, l6: 0.081609

[epoch:  24/100000, batch:   186/  187, ite: 2255] train loss: 0.597778, tar: 0.077495 
l0: 0.152668, l1: 0.182023, l2: 0.165860, l3: 0.154237, l4: 0.126395, l5: 0.135709, l6: 0.140315

[epoch:  24/100000, batch:   188/  187, ite: 2256] train loss: 0.599573, tar: 0.077788 
l0: 0.077389, l1: 0.073468, l2: 0.077262, l3: 0.074359, l4: 0.096335, l5: 0.098300, l6: 0.095654

[epoch:  25/100000, batch:     2/  187, ite: 2257] train loss: 0.599546, tar: 0.077787 
l0: 0.084768, l1: 0.079828, l2: 0.079019, l3: 0.089995, l4: 0.099636, l5: 0.085355, l6: 0.075372

[epoch:  25/100000, batch:     4/  187, ite: 2258] train loss: 0.599525, tar: 0.077814 
l0: 0.089070, l1: 0.083126, l2: 0.089105, l3: 0.089344, l4: 0.107545, l5: 0.113954, l6: 0.116565

[epoch:  25/100000, batch:     6/  187, ite: 2259] train loss: 0.599869, tar: 0.077857 
l0: 0.071582, l1: 0.064920, l2: 0.069486, l3: 0.071559, l4: 0.084078, l5: 0.086235, l6: 0.089006

[epoch:  25/100000, batch:     8/  187, ite: 2260] train loss: 0.599627, tar: 0.077833 
l0: 0.074443, l1: 0.074250, l2: 0.061226, l3: 0.067611, l4: 0.090342, l5: 0.090345, l6: 0.092466

[epoch:  25/100000, batch:    10/  187, ite: 2261] train loss: 0.599439, tar: 0.077820 
l0: 0.066376, l1: 0.058534, l2: 0.060324, l3: 0.068335, l4: 0.088936, l5: 0.095170, l6: 0.089991

[epoch:  25/100000, batch:    12/  187, ite: 2262] train loss: 0.599165, tar: 0.077776 
l0: 0.066160, l1: 0.081912, l2: 0.080183, l3: 0.072949, l4: 0.069580, l5: 0.069904, l6: 0.065189

[epoch:  25/100000, batch:    14/  187, ite: 2263] train loss: 0.598811, tar: 0.077732 
l0: 0.068053, l1: 0.087699, l2: 0.085497, l3: 0.074932, l4: 0.066019, l5: 0.069624, l6: 0.059847

[epoch:  25/100000, batch:    16/  187, ite: 2264] train loss: 0.598481, tar: 0.077696 
l0: 0.064950, l1: 0.061647, l2: 0.056826, l3: 0.058897, l4: 0.065861, l5: 0.067152, l6: 0.063278

[epoch:  25/100000, batch:    18/  187, ite: 2265] train loss: 0.597877, tar: 0.077647 
l0: 0.087257, l1: 0.083327, l2: 0.091666, l3: 0.102182, l4: 0.107678, l5: 0.101025, l6: 0.097472

[epoch:  25/100000, batch:    20/  187, ite: 2266] train loss: 0.598151, tar: 0.077684 
l0: 0.105001, l1: 0.099705, l2: 0.141034, l3: 0.129473, l4: 0.096849, l5: 0.115035, l6: 0.118831

[epoch:  25/100000, batch:    22/  187, ite: 2267] train loss: 0.598929, tar: 0.077786 
l0: 0.041472, l1: 0.035349, l2: 0.040670, l3: 0.045958, l4: 0.071134, l5: 0.059422, l6: 0.059727

[epoch:  25/100000, batch:    24/  187, ite: 2268] train loss: 0.598014, tar: 0.077650 
l0: 0.086029, l1: 0.076135, l2: 0.100744, l3: 0.106341, l4: 0.103567, l5: 0.110489, l6: 0.101135

[epoch:  25/100000, batch:    26/  187, ite: 2269] train loss: 0.598335, tar: 0.077682 
l0: 0.082162, l1: 0.064195, l2: 0.092784, l3: 0.108054, l4: 0.086126, l5: 0.110946, l6: 0.098165

[epoch:  25/100000, batch:    28/  187, ite: 2270] train loss: 0.598499, tar: 0.077698 
l0: 0.079145, l1: 0.075985, l2: 0.100461, l3: 0.092995, l4: 0.111342, l5: 0.103756, l6: 0.099070

[epoch:  25/100000, batch:    30/  187, ite: 2271] train loss: 0.598736, tar: 0.077704 
l0: 0.076036, l1: 0.068727, l2: 0.079130, l3: 0.078402, l4: 0.087079, l5: 0.094428, l6: 0.088146

[epoch:  25/100000, batch:    32/  187, ite: 2272] train loss: 0.598637, tar: 0.077697 
l0: 0.078808, l1: 0.083384, l2: 0.074773, l3: 0.081121, l4: 0.096299, l5: 0.108396, l6: 0.100705

[epoch:  25/100000, batch:    34/  187, ite: 2273] train loss: 0.598728, tar: 0.077701 
l0: 0.070430, l1: 0.068139, l2: 0.072476, l3: 0.084806, l4: 0.110996, l5: 0.087791, l6: 0.092331

[epoch:  25/100000, batch:    36/  187, ite: 2274] train loss: 0.598685, tar: 0.077675 
l0: 0.086505, l1: 0.085263, l2: 0.108164, l3: 0.119357, l4: 0.120330, l5: 0.106312, l6: 0.108006

[epoch:  25/100000, batch:    38/  187, ite: 2275] train loss: 0.599177, tar: 0.077707 
l0: 0.045442, l1: 0.045035, l2: 0.047376, l3: 0.052215, l4: 0.050764, l5: 0.051183, l6: 0.051622

[epoch:  25/100000, batch:    40/  187, ite: 2276] train loss: 0.598251, tar: 0.077590 
l0: 0.057300, l1: 0.056447, l2: 0.070155, l3: 0.068157, l4: 0.073268, l5: 0.071116, l6: 0.064333

[epoch:  25/100000, batch:    42/  187, ite: 2277] train loss: 0.597755, tar: 0.077517 
l0: 0.064574, l1: 0.062152, l2: 0.074581, l3: 0.081704, l4: 0.076791, l5: 0.078921, l6: 0.085707

[epoch:  25/100000, batch:    44/  187, ite: 2278] train loss: 0.597491, tar: 0.077470 
l0: 0.075682, l1: 0.082589, l2: 0.071473, l3: 0.075985, l4: 0.064862, l5: 0.067078, l6: 0.058055

[epoch:  25/100000, batch:    46/  187, ite: 2279] train loss: 0.597127, tar: 0.077464 
l0: 0.060183, l1: 0.078089, l2: 0.067332, l3: 0.058664, l4: 0.066573, l5: 0.068618, l6: 0.057514

[epoch:  25/100000, batch:    48/  187, ite: 2280] train loss: 0.596626, tar: 0.077402 
l0: 0.083732, l1: 0.091616, l2: 0.074709, l3: 0.080047, l4: 0.081526, l5: 0.088896, l6: 0.111175

[epoch:  25/100000, batch:    50/  187, ite: 2281] train loss: 0.596680, tar: 0.077425 
l0: 0.053821, l1: 0.054667, l2: 0.051168, l3: 0.056022, l4: 0.061531, l5: 0.076569, l6: 0.069504

[epoch:  25/100000, batch:    52/  187, ite: 2282] train loss: 0.596065, tar: 0.077341 
l0: 0.077291, l1: 0.074372, l2: 0.071664, l3: 0.071445, l4: 0.101818, l5: 0.100756, l6: 0.109493

[epoch:  25/100000, batch:    54/  187, ite: 2283] train loss: 0.596103, tar: 0.077341 
l0: 0.074155, l1: 0.063413, l2: 0.082599, l3: 0.090361, l4: 0.103625, l5: 0.092752, l6: 0.129556

[epoch:  25/100000, batch:    56/  187, ite: 2284] train loss: 0.596245, tar: 0.077330 
l0: 0.232323, l1: 0.257828, l2: 0.217437, l3: 0.226386, l4: 0.278298, l5: 0.270826, l6: 0.269812

[epoch:  25/100000, batch:    58/  187, ite: 2285] train loss: 0.600303, tar: 0.077873 
l0: 0.047583, l1: 0.043833, l2: 0.053549, l3: 0.055298, l4: 0.051969, l5: 0.054592, l6: 0.054887

[epoch:  25/100000, batch:    60/  187, ite: 2286] train loss: 0.599469, tar: 0.077768 
l0: 0.075510, l1: 0.093075, l2: 0.073320, l3: 0.069756, l4: 0.080518, l5: 0.062996, l6: 0.069879

[epoch:  25/100000, batch:    62/  187, ite: 2287] train loss: 0.599210, tar: 0.077760 
l0: 0.082021, l1: 0.081044, l2: 0.088082, l3: 0.088859, l4: 0.094468, l5: 0.098578, l6: 0.090636

[epoch:  25/100000, batch:    64/  187, ite: 2288] train loss: 0.599295, tar: 0.077774 
l0: 0.050351, l1: 0.053065, l2: 0.046465, l3: 0.040356, l4: 0.044798, l5: 0.053254, l6: 0.060734

[epoch:  25/100000, batch:    66/  187, ite: 2289] train loss: 0.598429, tar: 0.077680 
l0: 0.069390, l1: 0.096879, l2: 0.075143, l3: 0.061790, l4: 0.051605, l5: 0.047929, l6: 0.055415

[epoch:  25/100000, batch:    68/  187, ite: 2290] train loss: 0.597945, tar: 0.077651 
l0: 0.139481, l1: 0.151803, l2: 0.125923, l3: 0.121794, l4: 0.125216, l5: 0.143651, l6: 0.165752

[epoch:  25/100000, batch:    70/  187, ite: 2291] train loss: 0.599236, tar: 0.077863 
l0: 0.087523, l1: 0.090762, l2: 0.102372, l3: 0.095894, l4: 0.099623, l5: 0.080335, l6: 0.098517

[epoch:  25/100000, batch:    72/  187, ite: 2292] train loss: 0.599427, tar: 0.077897 
l0: 0.069019, l1: 0.063862, l2: 0.074479, l3: 0.074724, l4: 0.075274, l5: 0.099487, l6: 0.112035

[epoch:  25/100000, batch:    74/  187, ite: 2293] train loss: 0.599323, tar: 0.077866 
l0: 0.220922, l1: 0.263088, l2: 0.257111, l3: 0.273106, l4: 0.254817, l5: 0.229597, l6: 0.206451

[epoch:  25/100000, batch:    76/  187, ite: 2294] train loss: 0.603084, tar: 0.078353 
l0: 0.093253, l1: 0.110842, l2: 0.100318, l3: 0.092104, l4: 0.100569, l5: 0.096351, l6: 0.097985

[epoch:  25/100000, batch:    78/  187, ite: 2295] train loss: 0.603383, tar: 0.078403 
l0: 0.072933, l1: 0.073242, l2: 0.077017, l3: 0.080129, l4: 0.081726, l5: 0.074727, l6: 0.082135

[epoch:  25/100000, batch:    80/  187, ite: 2296] train loss: 0.603176, tar: 0.078385 
l0: 0.130575, l1: 0.152253, l2: 0.129446, l3: 0.123730, l4: 0.130980, l5: 0.139575, l6: 0.149623

[epoch:  25/100000, batch:    82/  187, ite: 2297] train loss: 0.604364, tar: 0.078561 
l0: 0.047455, l1: 0.046221, l2: 0.051070, l3: 0.053935, l4: 0.061122, l5: 0.064729, l6: 0.057355

[epoch:  25/100000, batch:    84/  187, ite: 2298] train loss: 0.603618, tar: 0.078456 
l0: 0.051048, l1: 0.045644, l2: 0.056261, l3: 0.052862, l4: 0.072474, l5: 0.091653, l6: 0.081090

[epoch:  25/100000, batch:    86/  187, ite: 2299] train loss: 0.603107, tar: 0.078365 
l0: 0.067183, l1: 0.066831, l2: 0.072844, l3: 0.076309, l4: 0.084668, l5: 0.083052, l6: 0.078939

[epoch:  25/100000, batch:    88/  187, ite: 2300] train loss: 0.602863, tar: 0.078327 
l0: 0.060480, l1: 0.074291, l2: 0.069669, l3: 0.061146, l4: 0.077040, l5: 0.063249, l6: 0.056874

[epoch:  25/100000, batch:    90/  187, ite: 2301] train loss: 0.602398, tar: 0.078268 
l0: 0.133665, l1: 0.145458, l2: 0.148991, l3: 0.144576, l4: 0.146009, l5: 0.145986, l6: 0.157294

[epoch:  25/100000, batch:    92/  187, ite: 2302] train loss: 0.603787, tar: 0.078451 
l0: 0.085151, l1: 0.089085, l2: 0.092089, l3: 0.093824, l4: 0.097010, l5: 0.097517, l6: 0.091345

[epoch:  25/100000, batch:    94/  187, ite: 2303] train loss: 0.603926, tar: 0.078474 
l0: 0.051991, l1: 0.060572, l2: 0.064976, l3: 0.062003, l4: 0.053869, l5: 0.059904, l6: 0.054365

[epoch:  25/100000, batch:    96/  187, ite: 2304] train loss: 0.603281, tar: 0.078386 
l0: 0.118489, l1: 0.135745, l2: 0.117042, l3: 0.112962, l4: 0.098608, l5: 0.105553, l6: 0.122775

[epoch:  25/100000, batch:    98/  187, ite: 2305] train loss: 0.603963, tar: 0.078518 
l0: 0.133149, l1: 0.162876, l2: 0.142926, l3: 0.127800, l4: 0.098027, l5: 0.110721, l6: 0.113577

[epoch:  25/100000, batch:   100/  187, ite: 2306] train loss: 0.604894, tar: 0.078696 
l0: 0.056567, l1: 0.056862, l2: 0.055821, l3: 0.054970, l4: 0.068394, l5: 0.065883, l6: 0.060340

[epoch:  25/100000, batch:   102/  187, ite: 2307] train loss: 0.604288, tar: 0.078624 
l0: 0.089229, l1: 0.078640, l2: 0.089208, l3: 0.104704, l4: 0.104879, l5: 0.110133, l6: 0.114392

[epoch:  25/100000, batch:   104/  187, ite: 2308] train loss: 0.604570, tar: 0.078659 
l0: 0.123065, l1: 0.118700, l2: 0.150198, l3: 0.147626, l4: 0.161428, l5: 0.149360, l6: 0.141968

[epoch:  25/100000, batch:   106/  187, ite: 2309] train loss: 0.605825, tar: 0.078802 
l0: 0.106833, l1: 0.102629, l2: 0.119596, l3: 0.117900, l4: 0.115220, l5: 0.110948, l6: 0.104155

[epoch:  25/100000, batch:   108/  187, ite: 2310] train loss: 0.606378, tar: 0.078893 
l0: 0.069330, l1: 0.060969, l2: 0.074631, l3: 0.079226, l4: 0.087174, l5: 0.079584, l6: 0.083322

[epoch:  25/100000, batch:   110/  187, ite: 2311] train loss: 0.606146, tar: 0.078862 
l0: 0.066022, l1: 0.060953, l2: 0.068063, l3: 0.073450, l4: 0.065398, l5: 0.073909, l6: 0.077355

[epoch:  25/100000, batch:   112/  187, ite: 2312] train loss: 0.605759, tar: 0.078821 
l0: 0.079139, l1: 0.073604, l2: 0.084720, l3: 0.086407, l4: 0.094721, l5: 0.094034, l6: 0.100113

[epoch:  25/100000, batch:   114/  187, ite: 2313] train loss: 0.605781, tar: 0.078822 
l0: 0.077133, l1: 0.075955, l2: 0.085737, l3: 0.090673, l4: 0.087721, l5: 0.086699, l6: 0.088063

[epoch:  25/100000, batch:   116/  187, ite: 2314] train loss: 0.605737, tar: 0.078817 
l0: 0.073095, l1: 0.069115, l2: 0.076912, l3: 0.080549, l4: 0.086887, l5: 0.086050, l6: 0.094820

[epoch:  25/100000, batch:   118/  187, ite: 2315] train loss: 0.605615, tar: 0.078798 
l0: 0.090060, l1: 0.095469, l2: 0.094090, l3: 0.089818, l4: 0.080062, l5: 0.080157, l6: 0.069549

[epoch:  25/100000, batch:   120/  187, ite: 2316] train loss: 0.605595, tar: 0.078834 
l0: 0.105392, l1: 0.098942, l2: 0.117128, l3: 0.106745, l4: 0.112513, l5: 0.120601, l6: 0.110111

[epoch:  25/100000, batch:   122/  187, ite: 2317] train loss: 0.606118, tar: 0.078918 
l0: 0.091050, l1: 0.093983, l2: 0.091797, l3: 0.082136, l4: 0.088485, l5: 0.087957, l6: 0.084782

[epoch:  25/100000, batch:   124/  187, ite: 2318] train loss: 0.606162, tar: 0.078956 
l0: 0.098580, l1: 0.080993, l2: 0.101590, l3: 0.103239, l4: 0.125397, l5: 0.145094, l6: 0.155560

[epoch:  25/100000, batch:   126/  187, ite: 2319] train loss: 0.606803, tar: 0.079018 
l0: 0.057485, l1: 0.050208, l2: 0.065163, l3: 0.068268, l4: 0.065899, l5: 0.074582, l6: 0.062326

[epoch:  25/100000, batch:   128/  187, ite: 2320] train loss: 0.606294, tar: 0.078950 
l0: 0.079894, l1: 0.076693, l2: 0.088967, l3: 0.090683, l4: 0.088336, l5: 0.086596, l6: 0.077998

[epoch:  25/100000, batch:   130/  187, ite: 2321] train loss: 0.606241, tar: 0.078953 
l0: 0.118333, l1: 0.113167, l2: 0.111497, l3: 0.122149, l4: 0.122725, l5: 0.142539, l6: 0.148883

[epoch:  25/100000, batch:   132/  187, ite: 2322] train loss: 0.607089, tar: 0.079076 
l0: 0.061635, l1: 0.052146, l2: 0.068805, l3: 0.077412, l4: 0.069318, l5: 0.076763, l6: 0.067275

[epoch:  25/100000, batch:   134/  187, ite: 2323] train loss: 0.606674, tar: 0.079022 
l0: 0.095342, l1: 0.098668, l2: 0.098299, l3: 0.096192, l4: 0.102115, l5: 0.104517, l6: 0.112405

[epoch:  25/100000, batch:   136/  187, ite: 2324] train loss: 0.606986, tar: 0.079072 
l0: 0.068675, l1: 0.064487, l2: 0.069433, l3: 0.063928, l4: 0.092434, l5: 0.081950, l6: 0.081315

[epoch:  25/100000, batch:   138/  187, ite: 2325] train loss: 0.606725, tar: 0.079040 
l0: 0.079011, l1: 0.077482, l2: 0.081814, l3: 0.074396, l4: 0.081077, l5: 0.091703, l6: 0.093789

[epoch:  25/100000, batch:   140/  187, ite: 2326] train loss: 0.606641, tar: 0.079040 
l0: 0.066204, l1: 0.070020, l2: 0.074564, l3: 0.072315, l4: 0.087914, l5: 0.081435, l6: 0.101740

[epoch:  25/100000, batch:   142/  187, ite: 2327] train loss: 0.606480, tar: 0.079001 
l0: 0.110810, l1: 0.102728, l2: 0.134483, l3: 0.132606, l4: 0.147277, l5: 0.130873, l6: 0.128069

[epoch:  25/100000, batch:   144/  187, ite: 2328] train loss: 0.607335, tar: 0.079098 
l0: 0.078460, l1: 0.086858, l2: 0.082138, l3: 0.084014, l4: 0.081916, l5: 0.073437, l6: 0.082609

[epoch:  25/100000, batch:   146/  187, ite: 2329] train loss: 0.607220, tar: 0.079096 
l0: 0.095487, l1: 0.109769, l2: 0.112140, l3: 0.106308, l4: 0.103337, l5: 0.095336, l6: 0.114712

[epoch:  25/100000, batch:   148/  187, ite: 2330] train loss: 0.607613, tar: 0.079145 
l0: 0.080248, l1: 0.076750, l2: 0.091612, l3: 0.081773, l4: 0.094590, l5: 0.095403, l6: 0.092499

[epoch:  25/100000, batch:   150/  187, ite: 2331] train loss: 0.607629, tar: 0.079149 
l0: 0.074528, l1: 0.081752, l2: 0.071853, l3: 0.068229, l4: 0.095552, l5: 0.084478, l6: 0.080726

[epoch:  25/100000, batch:   152/  187, ite: 2332] train loss: 0.607477, tar: 0.079135 
l0: 0.089676, l1: 0.074844, l2: 0.110683, l3: 0.119131, l4: 0.101627, l5: 0.102987, l6: 0.107944

[epoch:  25/100000, batch:   154/  187, ite: 2333] train loss: 0.607776, tar: 0.079166 
l0: 0.062865, l1: 0.059185, l2: 0.072682, l3: 0.066503, l4: 0.074348, l5: 0.068166, l6: 0.080665

[epoch:  25/100000, batch:   156/  187, ite: 2334] train loss: 0.607406, tar: 0.079118 
l0: 0.085802, l1: 0.077854, l2: 0.089465, l3: 0.086468, l4: 0.112725, l5: 0.110614, l6: 0.112522

[epoch:  25/100000, batch:   158/  187, ite: 2335] train loss: 0.607610, tar: 0.079137 
l0: 0.134641, l1: 0.130577, l2: 0.140861, l3: 0.143685, l4: 0.146758, l5: 0.172123, l6: 0.156965

[epoch:  25/100000, batch:   160/  187, ite: 2336] train loss: 0.608854, tar: 0.079303 
l0: 0.120055, l1: 0.129056, l2: 0.108980, l3: 0.107346, l4: 0.105775, l5: 0.124371, l6: 0.130342

[epoch:  25/100000, batch:   162/  187, ite: 2337] train loss: 0.609498, tar: 0.079424 
l0: 0.092642, l1: 0.080476, l2: 0.097895, l3: 0.099020, l4: 0.109077, l5: 0.121336, l6: 0.121997

[epoch:  25/100000, batch:   164/  187, ite: 2338] train loss: 0.609832, tar: 0.079463 
l0: 0.072479, l1: 0.070018, l2: 0.099371, l3: 0.107549, l4: 0.096327, l5: 0.100855, l6: 0.101642

[epoch:  25/100000, batch:   166/  187, ite: 2339] train loss: 0.609945, tar: 0.079442 
l0: 0.042422, l1: 0.046717, l2: 0.047662, l3: 0.051021, l4: 0.042697, l5: 0.042769, l6: 0.043492

[epoch:  25/100000, batch:   168/  187, ite: 2340] train loss: 0.609083, tar: 0.079333 
l0: 0.083386, l1: 0.079103, l2: 0.086251, l3: 0.085721, l4: 0.095169, l5: 0.100132, l6: 0.102382

[epoch:  25/100000, batch:   170/  187, ite: 2341] train loss: 0.609151, tar: 0.079345 
l0: 0.055122, l1: 0.065283, l2: 0.059909, l3: 0.057410, l4: 0.055442, l5: 0.055666, l6: 0.058891

[epoch:  25/100000, batch:   172/  187, ite: 2342] train loss: 0.608562, tar: 0.079274 
l0: 0.094978, l1: 0.087030, l2: 0.108910, l3: 0.113532, l4: 0.120381, l5: 0.128614, l6: 0.113929

[epoch:  25/100000, batch:   174/  187, ite: 2343] train loss: 0.609025, tar: 0.079320 
l0: 0.081400, l1: 0.082277, l2: 0.092586, l3: 0.090507, l4: 0.083425, l5: 0.083998, l6: 0.086426

[epoch:  25/100000, batch:   176/  187, ite: 2344] train loss: 0.609000, tar: 0.079326 
l0: 0.056336, l1: 0.064408, l2: 0.055179, l3: 0.051480, l4: 0.056034, l5: 0.059573, l6: 0.062604

[epoch:  25/100000, batch:   178/  187, ite: 2345] train loss: 0.608411, tar: 0.079259 
l0: 0.044108, l1: 0.054095, l2: 0.047985, l3: 0.039184, l4: 0.045535, l5: 0.049997, l6: 0.051764

[epoch:  25/100000, batch:   180/  187, ite: 2346] train loss: 0.607614, tar: 0.079158 
l0: 0.093400, l1: 0.079871, l2: 0.119072, l3: 0.125265, l4: 0.103745, l5: 0.100728, l6: 0.121573

[epoch:  25/100000, batch:   182/  187, ite: 2347] train loss: 0.608006, tar: 0.079199 
l0: 0.062009, l1: 0.066762, l2: 0.060869, l3: 0.062709, l4: 0.067915, l5: 0.066606, l6: 0.066390

[epoch:  25/100000, batch:   184/  187, ite: 2348] train loss: 0.607561, tar: 0.079150 
l0: 0.045748, l1: 0.059069, l2: 0.056833, l3: 0.052440, l4: 0.047553, l5: 0.050938, l6: 0.036619

[epoch:  25/100000, batch:   186/  187, ite: 2349] train loss: 0.606821, tar: 0.079054 
l0: 0.019009, l1: 0.027521, l2: 0.021211, l3: 0.018866, l4: 0.021039, l5: 0.015308, l6: 0.019366

[epoch:  25/100000, batch:   188/  187, ite: 2350] train loss: 0.605494, tar: 0.078882 
l0: 0.034188, l1: 0.028172, l2: 0.044851, l3: 0.044853, l4: 0.050105, l5: 0.044037, l6: 0.052488

[epoch:  26/100000, batch:     2/  187, ite: 2351] train loss: 0.604620, tar: 0.078755 
l0: 0.117144, l1: 0.110988, l2: 0.121357, l3: 0.126353, l4: 0.126227, l5: 0.115325, l6: 0.130636

[epoch:  26/100000, batch:     4/  187, ite: 2352] train loss: 0.605311, tar: 0.078864 
l0: 0.071356, l1: 0.084790, l2: 0.056159, l3: 0.051817, l4: 0.059339, l5: 0.057238, l6: 0.063322

[epoch:  26/100000, batch:     6/  187, ite: 2353] train loss: 0.604854, tar: 0.078843 
l0: 0.077409, l1: 0.075026, l2: 0.078875, l3: 0.080238, l4: 0.088991, l5: 0.078939, l6: 0.081354

[epoch:  26/100000, batch:     8/  187, ite: 2354] train loss: 0.604730, tar: 0.078839 
l0: 0.066289, l1: 0.054037, l2: 0.083693, l3: 0.076427, l4: 0.087312, l5: 0.089146, l6: 0.093457

[epoch:  26/100000, batch:    10/  187, ite: 2355] train loss: 0.604577, tar: 0.078803 
l0: 0.035004, l1: 0.028885, l2: 0.049065, l3: 0.048728, l4: 0.055492, l5: 0.053276, l6: 0.054437

[epoch:  26/100000, batch:    12/  187, ite: 2356] train loss: 0.603791, tar: 0.078680 
l0: 0.072396, l1: 0.085191, l2: 0.070845, l3: 0.082826, l4: 0.089739, l5: 0.081586, l6: 0.085529

[epoch:  26/100000, batch:    14/  187, ite: 2357] train loss: 0.603691, tar: 0.078663 
l0: 0.083196, l1: 0.093370, l2: 0.077629, l3: 0.077987, l4: 0.075347, l5: 0.070908, l6: 0.081821

[epoch:  26/100000, batch:    16/  187, ite: 2358] train loss: 0.603570, tar: 0.078675 
l0: 0.054795, l1: 0.056490, l2: 0.067084, l3: 0.070133, l4: 0.073306, l5: 0.083169, l6: 0.070084

[epoch:  26/100000, batch:    18/  187, ite: 2359] train loss: 0.603212, tar: 0.078609 
l0: 0.032127, l1: 0.030559, l2: 0.046681, l3: 0.044423, l4: 0.048657, l5: 0.049400, l6: 0.044270

[epoch:  26/100000, batch:    20/  187, ite: 2360] train loss: 0.602359, tar: 0.078480 
l0: 0.065977, l1: 0.059635, l2: 0.069429, l3: 0.070890, l4: 0.080885, l5: 0.079556, l6: 0.087863

[epoch:  26/100000, batch:    22/  187, ite: 2361] train loss: 0.602115, tar: 0.078445 
l0: 0.085119, l1: 0.083694, l2: 0.091465, l3: 0.100554, l4: 0.106263, l5: 0.091220, l6: 0.099629

[epoch:  26/100000, batch:    24/  187, ite: 2362] train loss: 0.602269, tar: 0.078464 
l0: 0.061500, l1: 0.070953, l2: 0.075335, l3: 0.078415, l4: 0.093545, l5: 0.084729, l6: 0.058219

[epoch:  26/100000, batch:    26/  187, ite: 2363] train loss: 0.602050, tar: 0.078417 
l0: 0.077521, l1: 0.076812, l2: 0.084121, l3: 0.083425, l4: 0.091157, l5: 0.076054, l6: 0.087845

[epoch:  26/100000, batch:    28/  187, ite: 2364] train loss: 0.601981, tar: 0.078414 
l0: 0.070920, l1: 0.063856, l2: 0.081174, l3: 0.080382, l4: 0.101709, l5: 0.111012, l6: 0.113389

[epoch:  26/100000, batch:    30/  187, ite: 2365] train loss: 0.602037, tar: 0.078394 
l0: 0.059777, l1: 0.049114, l2: 0.068033, l3: 0.066450, l4: 0.068002, l5: 0.082755, l6: 0.088562

[epoch:  26/100000, batch:    32/  187, ite: 2366] train loss: 0.601711, tar: 0.078343 
l0: 0.065920, l1: 0.061414, l2: 0.081793, l3: 0.084705, l4: 0.121191, l5: 0.106729, l6: 0.110798

[epoch:  26/100000, batch:    34/  187, ite: 2367] train loss: 0.601795, tar: 0.078309 
l0: 0.073868, l1: 0.061132, l2: 0.071342, l3: 0.070243, l4: 0.092696, l5: 0.105433, l6: 0.130681

[epoch:  26/100000, batch:    36/  187, ite: 2368] train loss: 0.601804, tar: 0.078297 
l0: 0.085684, l1: 0.083544, l2: 0.085475, l3: 0.083323, l4: 0.095058, l5: 0.100538, l6: 0.109052

[epoch:  26/100000, batch:    38/  187, ite: 2369] train loss: 0.601915, tar: 0.078317 
l0: 0.094127, l1: 0.104354, l2: 0.094362, l3: 0.095473, l4: 0.099339, l5: 0.097230, l6: 0.102690

[epoch:  26/100000, batch:    40/  187, ite: 2370] train loss: 0.602147, tar: 0.078360 
l0: 0.050154, l1: 0.043049, l2: 0.056387, l3: 0.058270, l4: 0.068130, l5: 0.072268, l6: 0.073712

[epoch:  26/100000, batch:    42/  187, ite: 2371] train loss: 0.601661, tar: 0.078284 
l0: 0.062651, l1: 0.070100, l2: 0.065908, l3: 0.071873, l4: 0.067520, l5: 0.075085, l6: 0.067001

[epoch:  26/100000, batch:    44/  187, ite: 2372] train loss: 0.601334, tar: 0.078242 
l0: 0.062977, l1: 0.064315, l2: 0.071239, l3: 0.064360, l4: 0.081588, l5: 0.079144, l6: 0.084881

[epoch:  26/100000, batch:    46/  187, ite: 2373] train loss: 0.601086, tar: 0.078201 
l0: 0.067982, l1: 0.080234, l2: 0.058173, l3: 0.059240, l4: 0.069185, l5: 0.073791, l6: 0.063660

[epoch:  26/100000, batch:    48/  187, ite: 2374] train loss: 0.600741, tar: 0.078173 
l0: 0.046339, l1: 0.041664, l2: 0.041273, l3: 0.046832, l4: 0.077007, l5: 0.076720, l6: 0.071365

[epoch:  26/100000, batch:    50/  187, ite: 2375] train loss: 0.600209, tar: 0.078089 
l0: 0.057513, l1: 0.067810, l2: 0.069041, l3: 0.061499, l4: 0.052902, l5: 0.058692, l6: 0.058852

[epoch:  26/100000, batch:    52/  187, ite: 2376] train loss: 0.599746, tar: 0.078034 
l0: 0.050834, l1: 0.051953, l2: 0.070255, l3: 0.072054, l4: 0.076204, l5: 0.080437, l6: 0.063585

[epoch:  26/100000, batch:    54/  187, ite: 2377] train loss: 0.599390, tar: 0.077962 
l0: 0.052482, l1: 0.045285, l2: 0.063018, l3: 0.064976, l4: 0.070256, l5: 0.068360, l6: 0.079696

[epoch:  26/100000, batch:    56/  187, ite: 2378] train loss: 0.598979, tar: 0.077894 
l0: 0.084369, l1: 0.097184, l2: 0.099016, l3: 0.099150, l4: 0.086142, l5: 0.082858, l6: 0.089799

[epoch:  26/100000, batch:    58/  187, ite: 2379] train loss: 0.599083, tar: 0.077911 
l0: 0.056339, l1: 0.050447, l2: 0.061728, l3: 0.063666, l4: 0.074176, l5: 0.076723, l6: 0.096384

[epoch:  26/100000, batch:    60/  187, ite: 2380] train loss: 0.598769, tar: 0.077855 
l0: 0.030448, l1: 0.038712, l2: 0.034409, l3: 0.035160, l4: 0.033852, l5: 0.028881, l6: 0.032425

[epoch:  26/100000, batch:    62/  187, ite: 2381] train loss: 0.597811, tar: 0.077730 
l0: 0.125754, l1: 0.133204, l2: 0.147914, l3: 0.147218, l4: 0.105886, l5: 0.120195, l6: 0.106089

[epoch:  26/100000, batch:    64/  187, ite: 2382] train loss: 0.598566, tar: 0.077856 
l0: 0.054332, l1: 0.065665, l2: 0.063977, l3: 0.058225, l4: 0.067888, l5: 0.068524, l6: 0.066024

[epoch:  26/100000, batch:    66/  187, ite: 2383] train loss: 0.598164, tar: 0.077794 
l0: 0.040689, l1: 0.044994, l2: 0.058431, l3: 0.054458, l4: 0.043262, l5: 0.042764, l6: 0.038624

[epoch:  26/100000, batch:    68/  187, ite: 2384] train loss: 0.597448, tar: 0.077698 
l0: 0.069540, l1: 0.069760, l2: 0.074940, l3: 0.072055, l4: 0.069610, l5: 0.071034, l6: 0.078689

[epoch:  26/100000, batch:    70/  187, ite: 2385] train loss: 0.597210, tar: 0.077677 
l0: 0.053696, l1: 0.045607, l2: 0.050709, l3: 0.052523, l4: 0.058491, l5: 0.080168, l6: 0.069196

[epoch:  26/100000, batch:    72/  187, ite: 2386] train loss: 0.596726, tar: 0.077615 
l0: 0.142541, l1: 0.132125, l2: 0.144682, l3: 0.136570, l4: 0.202086, l5: 0.212925, l6: 0.180099

[epoch:  26/100000, batch:    74/  187, ite: 2387] train loss: 0.598158, tar: 0.077782 
l0: 0.069648, l1: 0.073258, l2: 0.069698, l3: 0.070484, l4: 0.097581, l5: 0.081477, l6: 0.090199

[epoch:  26/100000, batch:    76/  187, ite: 2388] train loss: 0.598040, tar: 0.077761 
l0: 0.096337, l1: 0.097420, l2: 0.095256, l3: 0.103142, l4: 0.100131, l5: 0.099750, l6: 0.111473

[epoch:  26/100000, batch:    78/  187, ite: 2389] train loss: 0.598311, tar: 0.077809 
l0: 0.065595, l1: 0.067343, l2: 0.072819, l3: 0.072728, l4: 0.066281, l5: 0.072580, l6: 0.068262

[epoch:  26/100000, batch:    80/  187, ite: 2390] train loss: 0.598022, tar: 0.077778 
l0: 0.028760, l1: 0.032527, l2: 0.031615, l3: 0.031607, l4: 0.030080, l5: 0.035885, l6: 0.029009

[epoch:  26/100000, batch:    82/  187, ite: 2391] train loss: 0.597054, tar: 0.077652 
l0: 0.051324, l1: 0.042750, l2: 0.058320, l3: 0.064545, l4: 0.068604, l5: 0.084919, l6: 0.097699

[epoch:  26/100000, batch:    84/  187, ite: 2392] train loss: 0.596725, tar: 0.077585 
l0: 0.098293, l1: 0.090007, l2: 0.093285, l3: 0.112554, l4: 0.134458, l5: 0.120564, l6: 0.115756

[epoch:  26/100000, batch:    86/  187, ite: 2393] train loss: 0.597153, tar: 0.077638 
l0: 0.105772, l1: 0.122030, l2: 0.121621, l3: 0.118109, l4: 0.103215, l5: 0.099204, l6: 0.088952

[epoch:  26/100000, batch:    88/  187, ite: 2394] train loss: 0.597564, tar: 0.077709 
l0: 0.053978, l1: 0.060119, l2: 0.051493, l3: 0.058251, l4: 0.074545, l5: 0.063259, l6: 0.061710

[epoch:  26/100000, batch:    90/  187, ite: 2395] train loss: 0.597122, tar: 0.077649 
l0: 0.056851, l1: 0.062396, l2: 0.065083, l3: 0.066100, l4: 0.076831, l5: 0.081744, l6: 0.076386

[epoch:  26/100000, batch:    92/  187, ite: 2396] train loss: 0.596840, tar: 0.077597 
l0: 0.062604, l1: 0.058389, l2: 0.070697, l3: 0.068985, l4: 0.079594, l5: 0.087234, l6: 0.087262

[epoch:  26/100000, batch:    94/  187, ite: 2397] train loss: 0.596634, tar: 0.077559 
l0: 0.063130, l1: 0.063669, l2: 0.075410, l3: 0.082114, l4: 0.064164, l5: 0.070685, l6: 0.069083

[epoch:  26/100000, batch:    96/  187, ite: 2398] train loss: 0.596361, tar: 0.077523 
l0: 0.041197, l1: 0.047062, l2: 0.039791, l3: 0.037337, l4: 0.045214, l5: 0.046967, l6: 0.048802

[epoch:  26/100000, batch:    98/  187, ite: 2399] train loss: 0.595634, tar: 0.077432 
l0: 0.065123, l1: 0.064031, l2: 0.067970, l3: 0.070621, l4: 0.090829, l5: 0.086140, l6: 0.085616

[epoch:  26/100000, batch:   100/  187, ite: 2400] train loss: 0.595471, tar: 0.077401 
l0: 0.072575, l1: 0.082234, l2: 0.071334, l3: 0.065804, l4: 0.085574, l5: 0.076861, l6: 0.094405

[epoch:  26/100000, batch:   102/  187, ite: 2401] train loss: 0.595355, tar: 0.077389 
l0: 0.082995, l1: 0.080776, l2: 0.096059, l3: 0.107580, l4: 0.114233, l5: 0.098442, l6: 0.075815

[epoch:  26/100000, batch:   104/  187, ite: 2402] train loss: 0.595505, tar: 0.077403 
l0: 0.054755, l1: 0.053958, l2: 0.052086, l3: 0.047917, l4: 0.081936, l5: 0.079095, l6: 0.093258

[epoch:  26/100000, batch:   106/  187, ite: 2403] train loss: 0.595177, tar: 0.077347 
l0: 0.082003, l1: 0.088585, l2: 0.102485, l3: 0.094828, l4: 0.135903, l5: 0.119187, l6: 0.106130

[epoch:  26/100000, batch:   108/  187, ite: 2404] train loss: 0.595508, tar: 0.077358 
l0: 0.080299, l1: 0.078046, l2: 0.093285, l3: 0.091564, l4: 0.080336, l5: 0.098634, l6: 0.088685

[epoch:  26/100000, batch:   110/  187, ite: 2405] train loss: 0.595546, tar: 0.077365 
l0: 0.052101, l1: 0.057736, l2: 0.062114, l3: 0.057283, l4: 0.049888, l5: 0.056670, l6: 0.055843

[epoch:  26/100000, batch:   112/  187, ite: 2406] train loss: 0.595044, tar: 0.077303 
l0: 0.074344, l1: 0.057956, l2: 0.078612, l3: 0.078814, l4: 0.080286, l5: 0.100402, l6: 0.126878

[epoch:  26/100000, batch:   114/  187, ite: 2407] train loss: 0.595049, tar: 0.077296 
l0: 0.058030, l1: 0.055238, l2: 0.073012, l3: 0.075234, l4: 0.059911, l5: 0.064798, l6: 0.072125

[epoch:  26/100000, batch:   116/  187, ite: 2408] train loss: 0.594714, tar: 0.077249 
l0: 0.088328, l1: 0.075703, l2: 0.109512, l3: 0.107163, l4: 0.114600, l5: 0.113908, l6: 0.130354

[epoch:  26/100000, batch:   118/  187, ite: 2409] train loss: 0.595068, tar: 0.077276 
l0: 0.040661, l1: 0.044484, l2: 0.046222, l3: 0.052891, l4: 0.061652, l5: 0.052904, l6: 0.048736

[epoch:  26/100000, batch:   120/  187, ite: 2410] train loss: 0.594465, tar: 0.077186 
l0: 0.081222, l1: 0.071212, l2: 0.087248, l3: 0.076331, l4: 0.087504, l5: 0.098183, l6: 0.127573

[epoch:  26/100000, batch:   122/  187, ite: 2411] train loss: 0.594549, tar: 0.077196 
l0: 0.073264, l1: 0.075845, l2: 0.083023, l3: 0.096258, l4: 0.096916, l5: 0.098326, l6: 0.087383

[epoch:  26/100000, batch:   124/  187, ite: 2412] train loss: 0.594589, tar: 0.077187 
l0: 0.089635, l1: 0.083638, l2: 0.084791, l3: 0.084971, l4: 0.115869, l5: 0.114841, l6: 0.125555

[epoch:  26/100000, batch:   126/  187, ite: 2413] train loss: 0.594843, tar: 0.077217 
l0: 0.083632, l1: 0.086054, l2: 0.078996, l3: 0.081887, l4: 0.090606, l5: 0.085334, l6: 0.088225

[epoch:  26/100000, batch:   128/  187, ite: 2414] train loss: 0.594843, tar: 0.077232 
l0: 0.141313, l1: 0.152042, l2: 0.150113, l3: 0.146515, l4: 0.138099, l5: 0.156026, l6: 0.153948

[epoch:  26/100000, batch:   130/  187, ite: 2415] train loss: 0.595911, tar: 0.077387 
l0: 0.085892, l1: 0.098177, l2: 0.094066, l3: 0.096329, l4: 0.078744, l5: 0.102120, l6: 0.092661

[epoch:  26/100000, batch:   132/  187, ite: 2416] train loss: 0.596036, tar: 0.077407 
l0: 0.087894, l1: 0.079687, l2: 0.087331, l3: 0.093245, l4: 0.098319, l5: 0.103299, l6: 0.119348

[epoch:  26/100000, batch:   134/  187, ite: 2417] train loss: 0.596211, tar: 0.077432 
l0: 0.060501, l1: 0.069973, l2: 0.070923, l3: 0.065474, l4: 0.063757, l5: 0.076938, l6: 0.078934

[epoch:  26/100000, batch:   136/  187, ite: 2418] train loss: 0.595949, tar: 0.077392 
l0: 0.125060, l1: 0.128673, l2: 0.152915, l3: 0.144384, l4: 0.158240, l5: 0.166327, l6: 0.165117

[epoch:  26/100000, batch:   138/  187, ite: 2419] train loss: 0.597010, tar: 0.077506 
l0: 0.150115, l1: 0.178374, l2: 0.133415, l3: 0.143720, l4: 0.105386, l5: 0.122667, l6: 0.127915

[epoch:  26/100000, batch:   140/  187, ite: 2420] train loss: 0.597878, tar: 0.077679 
l0: 0.091144, l1: 0.085435, l2: 0.111954, l3: 0.104844, l4: 0.120356, l5: 0.114985, l6: 0.125000

[epoch:  26/100000, batch:   142/  187, ite: 2421] train loss: 0.598248, tar: 0.077710 
l0: 0.072438, l1: 0.082262, l2: 0.062441, l3: 0.068717, l4: 0.068926, l5: 0.065397, l6: 0.060506

[epoch:  26/100000, batch:   144/  187, ite: 2422] train loss: 0.597970, tar: 0.077698 
l0: 0.069679, l1: 0.075275, l2: 0.082234, l3: 0.075884, l4: 0.079973, l5: 0.082195, l6: 0.090476

[epoch:  26/100000, batch:   146/  187, ite: 2423] train loss: 0.597870, tar: 0.077679 
l0: 0.044871, l1: 0.057538, l2: 0.044922, l3: 0.040956, l4: 0.046377, l5: 0.050326, l6: 0.054210

[epoch:  26/100000, batch:   148/  187, ite: 2424] train loss: 0.597260, tar: 0.077602 
l0: 0.088692, l1: 0.084348, l2: 0.100905, l3: 0.101229, l4: 0.117030, l5: 0.106388, l6: 0.095347

[epoch:  26/100000, batch:   150/  187, ite: 2425] train loss: 0.597487, tar: 0.077628 
l0: 0.112578, l1: 0.112918, l2: 0.126141, l3: 0.124185, l4: 0.127058, l5: 0.131783, l6: 0.130754

[epoch:  26/100000, batch:   152/  187, ite: 2426] train loss: 0.598116, tar: 0.077710 
l0: 0.076882, l1: 0.075376, l2: 0.082445, l3: 0.086074, l4: 0.086825, l5: 0.091596, l6: 0.083560

[epoch:  26/100000, batch:   154/  187, ite: 2427] train loss: 0.598080, tar: 0.077708 
l0: 0.054251, l1: 0.068637, l2: 0.048768, l3: 0.045139, l4: 0.047421, l5: 0.050470, l6: 0.050890

[epoch:  26/100000, batch:   156/  187, ite: 2428] train loss: 0.597537, tar: 0.077653 
l0: 0.069188, l1: 0.062695, l2: 0.076830, l3: 0.078846, l4: 0.088074, l5: 0.087262, l6: 0.102395

[epoch:  26/100000, batch:   158/  187, ite: 2429] train loss: 0.597462, tar: 0.077633 
l0: 0.073803, l1: 0.067904, l2: 0.082890, l3: 0.079747, l4: 0.084682, l5: 0.078523, l6: 0.083823

[epoch:  26/100000, batch:   160/  187, ite: 2430] train loss: 0.597355, tar: 0.077624 
l0: 0.078222, l1: 0.079611, l2: 0.079221, l3: 0.074568, l4: 0.077288, l5: 0.085798, l6: 0.088711

[epoch:  26/100000, batch:   162/  187, ite: 2431] train loss: 0.597276, tar: 0.077626 
l0: 0.119825, l1: 0.139836, l2: 0.099376, l3: 0.098158, l4: 0.102184, l5: 0.105075, l6: 0.110637

[epoch:  26/100000, batch:   164/  187, ite: 2432] train loss: 0.597688, tar: 0.077723 
l0: 0.081816, l1: 0.073308, l2: 0.086984, l3: 0.080975, l4: 0.090591, l5: 0.102639, l6: 0.097457

[epoch:  26/100000, batch:   166/  187, ite: 2433] train loss: 0.597725, tar: 0.077733 
l0: 0.086156, l1: 0.080245, l2: 0.091189, l3: 0.086097, l4: 0.095651, l5: 0.096332, l6: 0.089531

[epoch:  26/100000, batch:   168/  187, ite: 2434] train loss: 0.597788, tar: 0.077752 
l0: 0.081658, l1: 0.068096, l2: 0.093897, l3: 0.094626, l4: 0.114825, l5: 0.121557, l6: 0.116461

[epoch:  26/100000, batch:   170/  187, ite: 2435] train loss: 0.598003, tar: 0.077761 
l0: 0.092178, l1: 0.088032, l2: 0.097967, l3: 0.097047, l4: 0.094520, l5: 0.103476, l6: 0.108605

[epoch:  26/100000, batch:   172/  187, ite: 2436] train loss: 0.598195, tar: 0.077794 
l0: 0.069878, l1: 0.076010, l2: 0.078780, l3: 0.098493, l4: 0.090526, l5: 0.078691, l6: 0.075328

[epoch:  26/100000, batch:   174/  187, ite: 2437] train loss: 0.598125, tar: 0.077776 
l0: 0.088834, l1: 0.084590, l2: 0.095766, l3: 0.106178, l4: 0.107687, l5: 0.129718, l6: 0.118271

[epoch:  26/100000, batch:   176/  187, ite: 2438] train loss: 0.598429, tar: 0.077802 
l0: 0.050292, l1: 0.050224, l2: 0.058064, l3: 0.062796, l4: 0.069788, l5: 0.074360, l6: 0.061736

[epoch:  26/100000, batch:   178/  187, ite: 2439] train loss: 0.598039, tar: 0.077739 
l0: 0.077819, l1: 0.077419, l2: 0.080048, l3: 0.081915, l4: 0.109547, l5: 0.113938, l6: 0.107359

[epoch:  26/100000, batch:   180/  187, ite: 2440] train loss: 0.598152, tar: 0.077739 
l0: 0.071523, l1: 0.058783, l2: 0.086324, l3: 0.079298, l4: 0.085330, l5: 0.113497, l6: 0.109712

[epoch:  26/100000, batch:   182/  187, ite: 2441] train loss: 0.598167, tar: 0.077725 
l0: 0.118672, l1: 0.109487, l2: 0.125772, l3: 0.131467, l4: 0.148895, l5: 0.163180, l6: 0.162762

[epoch:  26/100000, batch:   184/  187, ite: 2442] train loss: 0.598986, tar: 0.077818 
l0: 0.088938, l1: 0.094310, l2: 0.089056, l3: 0.094685, l4: 0.114524, l5: 0.100938, l6: 0.099162

[epoch:  26/100000, batch:   186/  187, ite: 2443] train loss: 0.599172, tar: 0.077843 
l0: 0.080650, l1: 0.090286, l2: 0.107777, l3: 0.085067, l4: 0.101593, l5: 0.093985, l6: 0.091757

[epoch:  26/100000, batch:   188/  187, ite: 2444] train loss: 0.599289, tar: 0.077849 
l0: 0.068080, l1: 0.060713, l2: 0.063764, l3: 0.071490, l4: 0.096038, l5: 0.085557, l6: 0.074635

[epoch:  27/100000, batch:     2/  187, ite: 2445] train loss: 0.599112, tar: 0.077827 
l0: 0.050517, l1: 0.052163, l2: 0.053319, l3: 0.055180, l4: 0.060306, l5: 0.062790, l6: 0.062089

[epoch:  27/100000, batch:     4/  187, ite: 2446] train loss: 0.598657, tar: 0.077766 
l0: 0.080959, l1: 0.074108, l2: 0.087143, l3: 0.092278, l4: 0.092823, l5: 0.097972, l6: 0.086286

[epoch:  27/100000, batch:     6/  187, ite: 2447] train loss: 0.598686, tar: 0.077773 
l0: 0.055470, l1: 0.049588, l2: 0.054210, l3: 0.053999, l4: 0.068161, l5: 0.078011, l6: 0.079224

[epoch:  27/100000, batch:     8/  187, ite: 2448] train loss: 0.598329, tar: 0.077723 
l0: 0.086792, l1: 0.087388, l2: 0.075282, l3: 0.083065, l4: 0.092281, l5: 0.105733, l6: 0.092342

[epoch:  27/100000, batch:    10/  187, ite: 2449] train loss: 0.598383, tar: 0.077743 
l0: 0.055104, l1: 0.050809, l2: 0.056264, l3: 0.058079, l4: 0.065894, l5: 0.072594, l6: 0.069352

[epoch:  27/100000, batch:    12/  187, ite: 2450] train loss: 0.598005, tar: 0.077693 
l0: 0.088357, l1: 0.080521, l2: 0.094867, l3: 0.102409, l4: 0.117036, l5: 0.118874, l6: 0.125466

[epoch:  27/100000, batch:    14/  187, ite: 2451] train loss: 0.598292, tar: 0.077717 
l0: 0.088649, l1: 0.075483, l2: 0.113865, l3: 0.104142, l4: 0.114915, l5: 0.110052, l6: 0.128524

[epoch:  27/100000, batch:    16/  187, ite: 2452] train loss: 0.598596, tar: 0.077741 
l0: 0.042039, l1: 0.042263, l2: 0.057027, l3: 0.051743, l4: 0.062858, l5: 0.056452, l6: 0.054006

[epoch:  27/100000, batch:    18/  187, ite: 2453] train loss: 0.598083, tar: 0.077662 
l0: 0.085236, l1: 0.096800, l2: 0.091238, l3: 0.093435, l4: 0.099779, l5: 0.088657, l6: 0.084702

[epoch:  27/100000, batch:    20/  187, ite: 2454] train loss: 0.598175, tar: 0.077679 
l0: 0.094411, l1: 0.090210, l2: 0.100745, l3: 0.098529, l4: 0.100257, l5: 0.112203, l6: 0.105109

[epoch:  27/100000, batch:    22/  187, ite: 2455] train loss: 0.598402, tar: 0.077716 
l0: 0.045608, l1: 0.048572, l2: 0.048199, l3: 0.046491, l4: 0.068466, l5: 0.057777, l6: 0.061524

[epoch:  27/100000, batch:    24/  187, ite: 2456] train loss: 0.597916, tar: 0.077645 
l0: 0.054845, l1: 0.073708, l2: 0.046805, l3: 0.058226, l4: 0.055457, l5: 0.041509, l6: 0.038500

[epoch:  27/100000, batch:    26/  187, ite: 2457] train loss: 0.597415, tar: 0.077595 
l0: 0.083122, l1: 0.087390, l2: 0.083480, l3: 0.078669, l4: 0.087375, l5: 0.086813, l6: 0.083734

[epoch:  27/100000, batch:    28/  187, ite: 2458] train loss: 0.597400, tar: 0.077607 
l0: 0.057777, l1: 0.049719, l2: 0.062119, l3: 0.057749, l4: 0.069643, l5: 0.090487, l6: 0.076909

[epoch:  27/100000, batch:    30/  187, ite: 2459] train loss: 0.597111, tar: 0.077564 
l0: 0.056868, l1: 0.052924, l2: 0.076887, l3: 0.080995, l4: 0.082505, l5: 0.064468, l6: 0.067652

[epoch:  27/100000, batch:    32/  187, ite: 2460] train loss: 0.596861, tar: 0.077519 
l0: 0.045175, l1: 0.038891, l2: 0.058493, l3: 0.066309, l4: 0.075975, l5: 0.065119, l6: 0.065690

[epoch:  27/100000, batch:    34/  187, ite: 2461] train loss: 0.596468, tar: 0.077449 
l0: 0.052885, l1: 0.069411, l2: 0.048922, l3: 0.049678, l4: 0.050599, l5: 0.054341, l6: 0.051942

[epoch:  27/100000, batch:    36/  187, ite: 2462] train loss: 0.595995, tar: 0.077396 
l0: 0.040960, l1: 0.042061, l2: 0.042714, l3: 0.043852, l4: 0.056209, l5: 0.058202, l6: 0.058898

[epoch:  27/100000, batch:    38/  187, ite: 2463] train loss: 0.595448, tar: 0.077317 
l0: 0.090162, l1: 0.089851, l2: 0.123635, l3: 0.154157, l4: 0.107361, l5: 0.088899, l6: 0.091066

[epoch:  27/100000, batch:    40/  187, ite: 2464] train loss: 0.595771, tar: 0.077345 
l0: 0.073783, l1: 0.074893, l2: 0.089976, l3: 0.092744, l4: 0.092237, l5: 0.084076, l6: 0.083218

[epoch:  27/100000, batch:    42/  187, ite: 2465] train loss: 0.595760, tar: 0.077337 
l0: 0.057029, l1: 0.045807, l2: 0.065962, l3: 0.068794, l4: 0.089306, l5: 0.084528, l6: 0.078946

[epoch:  27/100000, batch:    44/  187, ite: 2466] train loss: 0.595534, tar: 0.077294 
l0: 0.117913, l1: 0.090721, l2: 0.118207, l3: 0.143224, l4: 0.225470, l5: 0.218392, l6: 0.221213

[epoch:  27/100000, batch:    46/  187, ite: 2467] train loss: 0.596690, tar: 0.077381 
l0: 0.065962, l1: 0.084000, l2: 0.082146, l3: 0.070794, l4: 0.081900, l5: 0.079427, l6: 0.085305

[epoch:  27/100000, batch:    48/  187, ite: 2468] train loss: 0.596589, tar: 0.077356 
l0: 0.101500, l1: 0.101728, l2: 0.120187, l3: 0.118747, l4: 0.109426, l5: 0.131441, l6: 0.143427

[epoch:  27/100000, batch:    50/  187, ite: 2469] train loss: 0.597079, tar: 0.077408 
l0: 0.091691, l1: 0.089845, l2: 0.102369, l3: 0.097406, l4: 0.114675, l5: 0.129653, l6: 0.110836

[epoch:  27/100000, batch:    52/  187, ite: 2470] train loss: 0.597375, tar: 0.077438 
l0: 0.105080, l1: 0.123035, l2: 0.103945, l3: 0.102498, l4: 0.096828, l5: 0.084325, l6: 0.081758

[epoch:  27/100000, batch:    54/  187, ite: 2471] train loss: 0.597588, tar: 0.077497 
l0: 0.070070, l1: 0.068697, l2: 0.079977, l3: 0.085893, l4: 0.082940, l5: 0.087553, l6: 0.088960

[epoch:  27/100000, batch:    56/  187, ite: 2472] train loss: 0.597517, tar: 0.077481 
l0: 0.055662, l1: 0.060826, l2: 0.053363, l3: 0.060857, l4: 0.054871, l5: 0.063491, l6: 0.070530

[epoch:  27/100000, batch:    58/  187, ite: 2473] train loss: 0.597141, tar: 0.077435 
l0: 0.105933, l1: 0.115479, l2: 0.112909, l3: 0.113425, l4: 0.120678, l5: 0.113213, l6: 0.110941

[epoch:  27/100000, batch:    60/  187, ite: 2474] train loss: 0.597553, tar: 0.077495 
l0: 0.057321, l1: 0.062000, l2: 0.069481, l3: 0.066713, l4: 0.077673, l5: 0.080193, l6: 0.074849

[epoch:  27/100000, batch:    62/  187, ite: 2475] train loss: 0.597323, tar: 0.077452 
l0: 0.048058, l1: 0.048456, l2: 0.059092, l3: 0.061800, l4: 0.064417, l5: 0.062181, l6: 0.051227

[epoch:  27/100000, batch:    64/  187, ite: 2476] train loss: 0.596898, tar: 0.077391 
l0: 0.049986, l1: 0.042161, l2: 0.053509, l3: 0.058007, l4: 0.068907, l5: 0.070686, l6: 0.076028

[epoch:  27/100000, batch:    66/  187, ite: 2477] train loss: 0.596526, tar: 0.077333 
l0: 0.078690, l1: 0.093788, l2: 0.071882, l3: 0.075648, l4: 0.094979, l5: 0.090259, l6: 0.065767

[epoch:  27/100000, batch:    68/  187, ite: 2478] train loss: 0.596473, tar: 0.077336 
l0: 0.078820, l1: 0.084216, l2: 0.078441, l3: 0.081196, l4: 0.093270, l5: 0.090517, l6: 0.085182

[epoch:  27/100000, batch:    70/  187, ite: 2479] train loss: 0.596463, tar: 0.077339 
l0: 0.105868, l1: 0.096146, l2: 0.142296, l3: 0.139265, l4: 0.123473, l5: 0.133848, l6: 0.148490

[epoch:  27/100000, batch:    72/  187, ite: 2480] train loss: 0.597073, tar: 0.077399 
l0: 0.115513, l1: 0.118377, l2: 0.124977, l3: 0.113857, l4: 0.113681, l5: 0.123290, l6: 0.118874

[epoch:  27/100000, batch:    74/  187, ite: 2481] train loss: 0.597554, tar: 0.077478 
l0: 0.074211, l1: 0.065895, l2: 0.090863, l3: 0.098405, l4: 0.090257, l5: 0.089326, l6: 0.087102

[epoch:  27/100000, batch:    76/  187, ite: 2482] train loss: 0.597551, tar: 0.077471 
l0: 0.056460, l1: 0.049734, l2: 0.063142, l3: 0.067868, l4: 0.068683, l5: 0.079931, l6: 0.089427

[epoch:  27/100000, batch:    78/  187, ite: 2483] train loss: 0.597298, tar: 0.077428 
l0: 0.053312, l1: 0.051094, l2: 0.065815, l3: 0.073637, l4: 0.058971, l5: 0.059344, l6: 0.056122

[epoch:  27/100000, batch:    80/  187, ite: 2484] train loss: 0.596928, tar: 0.077378 
l0: 0.053289, l1: 0.055039, l2: 0.064670, l3: 0.061551, l4: 0.061846, l5: 0.062169, l6: 0.055151

[epoch:  27/100000, batch:    82/  187, ite: 2485] train loss: 0.596550, tar: 0.077328 
l0: 0.088898, l1: 0.079096, l2: 0.119118, l3: 0.128386, l4: 0.096647, l5: 0.108697, l6: 0.120104

[epoch:  27/100000, batch:    84/  187, ite: 2486] train loss: 0.596847, tar: 0.077352 
l0: 0.080351, l1: 0.070592, l2: 0.083672, l3: 0.085416, l4: 0.116795, l5: 0.123570, l6: 0.117082

[epoch:  27/100000, batch:    86/  187, ite: 2487] train loss: 0.597013, tar: 0.077358 
l0: 0.078424, l1: 0.080486, l2: 0.093251, l3: 0.092464, l4: 0.104926, l5: 0.096482, l6: 0.091850

[epoch:  27/100000, batch:    88/  187, ite: 2488] train loss: 0.597097, tar: 0.077360 
l0: 0.094858, l1: 0.103958, l2: 0.084778, l3: 0.094470, l4: 0.085552, l5: 0.109014, l6: 0.103963

[epoch:  27/100000, batch:    90/  187, ite: 2489] train loss: 0.597259, tar: 0.077396 
l0: 0.130192, l1: 0.128767, l2: 0.156661, l3: 0.149759, l4: 0.166602, l5: 0.177163, l6: 0.167732

[epoch:  27/100000, batch:    92/  187, ite: 2490] train loss: 0.598238, tar: 0.077504 
l0: 0.068732, l1: 0.070585, l2: 0.077614, l3: 0.076062, l4: 0.077902, l5: 0.088222, l6: 0.104352

[epoch:  27/100000, batch:    94/  187, ite: 2491] train loss: 0.598167, tar: 0.077486 
l0: 0.066789, l1: 0.088445, l2: 0.078000, l3: 0.066797, l4: 0.074325, l5: 0.070433, l6: 0.071244

[epoch:  27/100000, batch:    96/  187, ite: 2492] train loss: 0.598000, tar: 0.077464 
l0: 0.059758, l1: 0.080344, l2: 0.059943, l3: 0.058742, l4: 0.052046, l5: 0.059154, l6: 0.060398

[epoch:  27/100000, batch:    98/  187, ite: 2493] train loss: 0.597660, tar: 0.077428 
l0: 0.071982, l1: 0.066554, l2: 0.081215, l3: 0.083237, l4: 0.089183, l5: 0.090216, l6: 0.090486

[epoch:  27/100000, batch:   100/  187, ite: 2494] train loss: 0.597610, tar: 0.077417 
l0: 0.086788, l1: 0.080267, l2: 0.094711, l3: 0.113881, l4: 0.103474, l5: 0.114559, l6: 0.134600

[epoch:  27/100000, batch:   102/  187, ite: 2495] train loss: 0.597874, tar: 0.077436 
l0: 0.058976, l1: 0.055355, l2: 0.076936, l3: 0.075456, l4: 0.082716, l5: 0.071698, l6: 0.080893

[epoch:  27/100000, batch:   104/  187, ite: 2496] train loss: 0.597681, tar: 0.077399 
l0: 0.089345, l1: 0.079265, l2: 0.091285, l3: 0.102863, l4: 0.142036, l5: 0.128382, l6: 0.120320

[epoch:  27/100000, batch:   106/  187, ite: 2497] train loss: 0.597994, tar: 0.077423 
l0: 0.075309, l1: 0.069390, l2: 0.088108, l3: 0.088022, l4: 0.103162, l5: 0.107496, l6: 0.097704

[epoch:  27/100000, batch:   108/  187, ite: 2498] train loss: 0.598057, tar: 0.077419 
l0: 0.082893, l1: 0.075047, l2: 0.096162, l3: 0.102848, l4: 0.105000, l5: 0.098159, l6: 0.095296

[epoch:  27/100000, batch:   110/  187, ite: 2499] train loss: 0.598172, tar: 0.077430 
l0: 0.147983, l1: 0.137415, l2: 0.158662, l3: 0.155516, l4: 0.185539, l5: 0.202358, l6: 0.163291

[epoch:  27/100000, batch:   112/  187, ite: 2500] train loss: 0.599277, tar: 0.077571 
l0: 0.100124, l1: 0.112568, l2: 0.089165, l3: 0.092000, l4: 0.082471, l5: 0.089146, l6: 0.084617

[epoch:  27/100000, batch:   114/  187, ite: 2501] train loss: 0.599379, tar: 0.077616 
l0: 0.052628, l1: 0.046910, l2: 0.063718, l3: 0.063959, l4: 0.082522, l5: 0.079533, l6: 0.078461

[epoch:  27/100000, batch:   116/  187, ite: 2502] train loss: 0.599116, tar: 0.077566 
l0: 0.074438, l1: 0.068955, l2: 0.082714, l3: 0.083175, l4: 0.081990, l5: 0.091985, l6: 0.082184

[epoch:  27/100000, batch:   118/  187, ite: 2503] train loss: 0.599049, tar: 0.077560 
l0: 0.046978, l1: 0.042986, l2: 0.072697, l3: 0.069883, l4: 0.065690, l5: 0.065516, l6: 0.057403

[epoch:  27/100000, batch:   120/  187, ite: 2504] train loss: 0.598696, tar: 0.077499 
l0: 0.065678, l1: 0.063788, l2: 0.080285, l3: 0.076087, l4: 0.087156, l5: 0.091822, l6: 0.080739

[epoch:  27/100000, batch:   122/  187, ite: 2505] train loss: 0.598591, tar: 0.077476 
l0: 0.075621, l1: 0.070615, l2: 0.079270, l3: 0.086477, l4: 0.101890, l5: 0.096734, l6: 0.100239

[epoch:  27/100000, batch:   124/  187, ite: 2506] train loss: 0.598615, tar: 0.077472 
l0: 0.046576, l1: 0.057290, l2: 0.047761, l3: 0.048600, l4: 0.058204, l5: 0.062441, l6: 0.043365

[epoch:  27/100000, batch:   126/  187, ite: 2507] train loss: 0.598153, tar: 0.077411 
l0: 0.068954, l1: 0.058202, l2: 0.077768, l3: 0.084672, l4: 0.111839, l5: 0.118912, l6: 0.117504

[epoch:  27/100000, batch:   128/  187, ite: 2508] train loss: 0.598231, tar: 0.077394 
l0: 0.062064, l1: 0.054482, l2: 0.068907, l3: 0.079373, l4: 0.084796, l5: 0.085007, l6: 0.080933

[epoch:  27/100000, batch:   130/  187, ite: 2509] train loss: 0.598069, tar: 0.077364 
l0: 0.068411, l1: 0.064669, l2: 0.072481, l3: 0.067312, l4: 0.087761, l5: 0.094700, l6: 0.097543

[epoch:  27/100000, batch:   132/  187, ite: 2510] train loss: 0.597980, tar: 0.077347 
l0: 0.058420, l1: 0.049048, l2: 0.063523, l3: 0.073913, l4: 0.079348, l5: 0.080120, l6: 0.074595

[epoch:  27/100000, batch:   134/  187, ite: 2511] train loss: 0.597747, tar: 0.077310 
l0: 0.067973, l1: 0.074325, l2: 0.083563, l3: 0.086289, l4: 0.082998, l5: 0.082954, l6: 0.073663

[epoch:  27/100000, batch:   136/  187, ite: 2512] train loss: 0.597658, tar: 0.077292 
l0: 0.072252, l1: 0.075717, l2: 0.092168, l3: 0.082124, l4: 0.084290, l5: 0.092198, l6: 0.090724

[epoch:  27/100000, batch:   138/  187, ite: 2513] train loss: 0.597642, tar: 0.077282 
l0: 0.080886, l1: 0.078101, l2: 0.100174, l3: 0.093408, l4: 0.107429, l5: 0.109316, l6: 0.103587

[epoch:  27/100000, batch:   140/  187, ite: 2514] train loss: 0.597788, tar: 0.077289 
l0: 0.093647, l1: 0.100309, l2: 0.089389, l3: 0.099397, l4: 0.095435, l5: 0.088643, l6: 0.089723

[epoch:  27/100000, batch:   142/  187, ite: 2515] train loss: 0.597902, tar: 0.077320 
l0: 0.041478, l1: 0.058121, l2: 0.057276, l3: 0.049441, l4: 0.051594, l5: 0.050044, l6: 0.046811

[epoch:  27/100000, batch:   144/  187, ite: 2516] train loss: 0.597431, tar: 0.077251 
l0: 0.045694, l1: 0.048763, l2: 0.052025, l3: 0.049405, l4: 0.058998, l5: 0.059514, l6: 0.061400

[epoch:  27/100000, batch:   146/  187, ite: 2517] train loss: 0.597002, tar: 0.077190 
l0: 0.053055, l1: 0.046462, l2: 0.097053, l3: 0.108524, l4: 0.063951, l5: 0.068091, l6: 0.063315

[epoch:  27/100000, batch:   148/  187, ite: 2518] train loss: 0.596816, tar: 0.077143 
l0: 0.105933, l1: 0.103259, l2: 0.107293, l3: 0.115975, l4: 0.130745, l5: 0.140397, l6: 0.119147

[epoch:  27/100000, batch:   150/  187, ite: 2519] train loss: 0.597251, tar: 0.077199 
l0: 0.070755, l1: 0.074754, l2: 0.067291, l3: 0.067686, l4: 0.071538, l5: 0.077345, l6: 0.073091

[epoch:  27/100000, batch:   152/  187, ite: 2520] train loss: 0.597069, tar: 0.077186 
l0: 0.082458, l1: 0.091513, l2: 0.067788, l3: 0.062287, l4: 0.082180, l5: 0.082637, l6: 0.089991

[epoch:  27/100000, batch:   154/  187, ite: 2521] train loss: 0.596995, tar: 0.077197 
l0: 0.051222, l1: 0.056161, l2: 0.056986, l3: 0.055503, l4: 0.068403, l5: 0.068691, l6: 0.072951

[epoch:  27/100000, batch:   156/  187, ite: 2522] train loss: 0.596675, tar: 0.077147 
l0: 0.062696, l1: 0.062417, l2: 0.064269, l3: 0.064982, l4: 0.072206, l5: 0.066298, l6: 0.077436

[epoch:  27/100000, batch:   158/  187, ite: 2523] train loss: 0.596434, tar: 0.077119 
l0: 0.065927, l1: 0.056071, l2: 0.080443, l3: 0.083148, l4: 0.077925, l5: 0.088499, l6: 0.093210

[epoch:  27/100000, batch:   160/  187, ite: 2524] train loss: 0.596336, tar: 0.077098 
l0: 0.070728, l1: 0.065052, l2: 0.066237, l3: 0.067546, l4: 0.086969, l5: 0.098025, l6: 0.100848

[epoch:  27/100000, batch:   162/  187, ite: 2525] train loss: 0.596258, tar: 0.077086 
l0: 0.041752, l1: 0.035011, l2: 0.053990, l3: 0.054572, l4: 0.072124, l5: 0.085312, l6: 0.080648

[epoch:  27/100000, batch:   164/  187, ite: 2526] train loss: 0.595929, tar: 0.077019 
l0: 0.086400, l1: 0.101312, l2: 0.087127, l3: 0.081250, l4: 0.080813, l5: 0.083950, l6: 0.087037

[epoch:  27/100000, batch:   166/  187, ite: 2527] train loss: 0.595952, tar: 0.077036 
l0: 0.061440, l1: 0.059764, l2: 0.065096, l3: 0.069772, l4: 0.070922, l5: 0.070726, l6: 0.068321

[epoch:  27/100000, batch:   168/  187, ite: 2528] train loss: 0.595706, tar: 0.077007 
l0: 0.042698, l1: 0.040430, l2: 0.072951, l3: 0.074339, l4: 0.074625, l5: 0.078719, l6: 0.053793

[epoch:  27/100000, batch:   170/  187, ite: 2529] train loss: 0.595407, tar: 0.076942 
l0: 0.122262, l1: 0.146794, l2: 0.112836, l3: 0.116029, l4: 0.119228, l5: 0.119337, l6: 0.121109

[epoch:  27/100000, batch:   172/  187, ite: 2530] train loss: 0.595902, tar: 0.077027 
l0: 0.037028, l1: 0.042715, l2: 0.044767, l3: 0.045485, l4: 0.052195, l5: 0.055097, l6: 0.044296

[epoch:  27/100000, batch:   174/  187, ite: 2531] train loss: 0.595385, tar: 0.076952 
l0: 0.060166, l1: 0.054994, l2: 0.066489, l3: 0.068484, l4: 0.081747, l5: 0.092119, l6: 0.082724

[epoch:  27/100000, batch:   176/  187, ite: 2532] train loss: 0.595219, tar: 0.076921 
l0: 0.061383, l1: 0.060576, l2: 0.057337, l3: 0.061224, l4: 0.083718, l5: 0.084481, l6: 0.087204

[epoch:  27/100000, batch:   178/  187, ite: 2533] train loss: 0.595032, tar: 0.076891 
l0: 0.064668, l1: 0.059001, l2: 0.062619, l3: 0.066459, l4: 0.079785, l5: 0.081944, l6: 0.086348

[epoch:  27/100000, batch:   180/  187, ite: 2534] train loss: 0.594856, tar: 0.076869 
l0: 0.045550, l1: 0.042775, l2: 0.060664, l3: 0.060314, l4: 0.058404, l5: 0.059329, l6: 0.059400

[epoch:  27/100000, batch:   182/  187, ite: 2535] train loss: 0.594466, tar: 0.076810 
l0: 0.064738, l1: 0.058813, l2: 0.074050, l3: 0.076979, l4: 0.091949, l5: 0.096303, l6: 0.086010

[epoch:  27/100000, batch:   184/  187, ite: 2536] train loss: 0.594381, tar: 0.076787 
l0: 0.066748, l1: 0.056297, l2: 0.072216, l3: 0.074780, l4: 0.088480, l5: 0.085950, l6: 0.097308

[epoch:  27/100000, batch:   186/  187, ite: 2537] train loss: 0.594283, tar: 0.076769 
l0: 0.061223, l1: 0.057219, l2: 0.085396, l3: 0.080556, l4: 0.085036, l5: 0.065359, l6: 0.069714

[epoch:  27/100000, batch:   188/  187, ite: 2538] train loss: 0.594116, tar: 0.076740 
l0: 0.054714, l1: 0.050439, l2: 0.056954, l3: 0.055265, l4: 0.061847, l5: 0.068742, l6: 0.062458

[epoch:  28/100000, batch:     2/  187, ite: 2539] train loss: 0.593776, tar: 0.076699 
l0: 0.044720, l1: 0.038646, l2: 0.065404, l3: 0.067823, l4: 0.062003, l5: 0.060462, l6: 0.065293

[epoch:  28/100000, batch:     4/  187, ite: 2540] train loss: 0.593425, tar: 0.076640 
l0: 0.058351, l1: 0.048556, l2: 0.066883, l3: 0.066078, l4: 0.075391, l5: 0.077221, l6: 0.080307

[epoch:  28/100000, batch:     6/  187, ite: 2541] train loss: 0.593202, tar: 0.076606 
l0: 0.055504, l1: 0.049091, l2: 0.066718, l3: 0.071507, l4: 0.072053, l5: 0.079875, l6: 0.073691

[epoch:  28/100000, batch:     8/  187, ite: 2542] train loss: 0.592972, tar: 0.076567 
l0: 0.052622, l1: 0.043963, l2: 0.065734, l3: 0.062936, l4: 0.075961, l5: 0.085544, l6: 0.084807

[epoch:  28/100000, batch:    10/  187, ite: 2543] train loss: 0.592748, tar: 0.076523 
l0: 0.058708, l1: 0.055219, l2: 0.081379, l3: 0.086505, l4: 0.090153, l5: 0.083754, l6: 0.082662

[epoch:  28/100000, batch:    12/  187, ite: 2544] train loss: 0.592648, tar: 0.076490 
l0: 0.041746, l1: 0.049780, l2: 0.046763, l3: 0.051095, l4: 0.063827, l5: 0.063988, l6: 0.053686

[epoch:  28/100000, batch:    14/  187, ite: 2545] train loss: 0.592241, tar: 0.076426 
l0: 0.053056, l1: 0.051298, l2: 0.067353, l3: 0.068899, l4: 0.058864, l5: 0.062704, l6: 0.062287

[epoch:  28/100000, batch:    16/  187, ite: 2546] train loss: 0.591934, tar: 0.076384 
l0: 0.045301, l1: 0.051940, l2: 0.041538, l3: 0.035130, l4: 0.064098, l5: 0.065382, l6: 0.062383

[epoch:  28/100000, batch:    18/  187, ite: 2547] train loss: 0.591520, tar: 0.076327 
l0: 0.064861, l1: 0.070994, l2: 0.082942, l3: 0.078958, l4: 0.071739, l5: 0.071013, l6: 0.069024

[epoch:  28/100000, batch:    20/  187, ite: 2548] train loss: 0.591371, tar: 0.076306 
l0: 0.075738, l1: 0.080219, l2: 0.077262, l3: 0.075660, l4: 0.082149, l5: 0.072900, l6: 0.081628

[epoch:  28/100000, batch:    22/  187, ite: 2549] train loss: 0.591287, tar: 0.076305 
l0: 0.071600, l1: 0.075262, l2: 0.087274, l3: 0.083035, l4: 0.093130, l5: 0.077581, l6: 0.078469

[epoch:  28/100000, batch:    24/  187, ite: 2550] train loss: 0.591242, tar: 0.076296 
l0: 0.048815, l1: 0.045133, l2: 0.061821, l3: 0.070060, l4: 0.080660, l5: 0.074111, l6: 0.072148

[epoch:  28/100000, batch:    26/  187, ite: 2551] train loss: 0.590991, tar: 0.076246 
l0: 0.048626, l1: 0.051375, l2: 0.048786, l3: 0.055640, l4: 0.063509, l5: 0.059377, l6: 0.061883

[epoch:  28/100000, batch:    28/  187, ite: 2552] train loss: 0.590625, tar: 0.076196 
l0: 0.073430, l1: 0.074351, l2: 0.072361, l3: 0.075857, l4: 0.099601, l5: 0.087665, l6: 0.074053

[epoch:  28/100000, batch:    30/  187, ite: 2553] train loss: 0.590565, tar: 0.076191 
l0: 0.063361, l1: 0.059323, l2: 0.067758, l3: 0.069789, l4: 0.084804, l5: 0.093375, l6: 0.088459

[epoch:  28/100000, batch:    32/  187, ite: 2554] train loss: 0.590450, tar: 0.076168 
l0: 0.060936, l1: 0.056379, l2: 0.066586, l3: 0.068390, l4: 0.067267, l5: 0.070202, l6: 0.075112

[epoch:  28/100000, batch:    34/  187, ite: 2555] train loss: 0.590224, tar: 0.076141 
l0: 0.072710, l1: 0.062381, l2: 0.074406, l3: 0.075519, l4: 0.081896, l5: 0.101676, l6: 0.098730

[epoch:  28/100000, batch:    36/  187, ite: 2556] train loss: 0.590182, tar: 0.076135 
l0: 0.060341, l1: 0.058383, l2: 0.062790, l3: 0.065478, l4: 0.072032, l5: 0.059465, l6: 0.064511

[epoch:  28/100000, batch:    38/  187, ite: 2557] train loss: 0.589918, tar: 0.076106 
l0: 0.058060, l1: 0.058736, l2: 0.065695, l3: 0.063432, l4: 0.062814, l5: 0.063903, l6: 0.069875

[epoch:  28/100000, batch:    40/  187, ite: 2558] train loss: 0.589654, tar: 0.076074 
l0: 0.050479, l1: 0.050727, l2: 0.060780, l3: 0.060182, l4: 0.066212, l5: 0.066814, l6: 0.062813

[epoch:  28/100000, batch:    42/  187, ite: 2559] train loss: 0.589347, tar: 0.076028 
l0: 0.054874, l1: 0.060419, l2: 0.049701, l3: 0.054713, l4: 0.044568, l5: 0.052896, l6: 0.055981

[epoch:  28/100000, batch:    44/  187, ite: 2560] train loss: 0.588961, tar: 0.075990 
l0: 0.089525, l1: 0.130198, l2: 0.096529, l3: 0.096310, l4: 0.070545, l5: 0.077435, l6: 0.080488

[epoch:  28/100000, batch:    46/  187, ite: 2561] train loss: 0.589054, tar: 0.076014 
l0: 0.102742, l1: 0.112118, l2: 0.101926, l3: 0.102164, l4: 0.117838, l5: 0.139211, l6: 0.129503

[epoch:  28/100000, batch:    48/  187, ite: 2562] train loss: 0.589439, tar: 0.076062 
l0: 0.056468, l1: 0.057259, l2: 0.059588, l3: 0.072299, l4: 0.107696, l5: 0.094974, l6: 0.080082

[epoch:  28/100000, batch:    50/  187, ite: 2563] train loss: 0.589330, tar: 0.076027 
l0: 0.069947, l1: 0.074279, l2: 0.079865, l3: 0.081744, l4: 0.083213, l5: 0.071646, l6: 0.076596

[epoch:  28/100000, batch:    52/  187, ite: 2564] train loss: 0.589238, tar: 0.076016 
l0: 0.074103, l1: 0.072843, l2: 0.074088, l3: 0.078079, l4: 0.100374, l5: 0.116503, l6: 0.086309

[epoch:  28/100000, batch:    54/  187, ite: 2565] train loss: 0.589261, tar: 0.076013 
l0: 0.089154, l1: 0.112053, l2: 0.090909, l3: 0.086254, l4: 0.066209, l5: 0.095273, l6: 0.079610

[epoch:  28/100000, batch:    56/  187, ite: 2566] train loss: 0.589315, tar: 0.076036 
l0: 0.085673, l1: 0.080168, l2: 0.098561, l3: 0.091760, l4: 0.116665, l5: 0.117458, l6: 0.104555

[epoch:  28/100000, batch:    58/  187, ite: 2567] train loss: 0.589501, tar: 0.076053 
l0: 0.039810, l1: 0.050203, l2: 0.051358, l3: 0.041373, l4: 0.042092, l5: 0.041428, l6: 0.042781

[epoch:  28/100000, batch:    60/  187, ite: 2568] train loss: 0.589007, tar: 0.075989 
l0: 0.040896, l1: 0.053085, l2: 0.044623, l3: 0.043088, l4: 0.043374, l5: 0.045853, l6: 0.038952

[epoch:  28/100000, batch:    62/  187, ite: 2569] train loss: 0.588516, tar: 0.075928 
l0: 0.062763, l1: 0.057897, l2: 0.068417, l3: 0.058995, l4: 0.069494, l5: 0.082457, l6: 0.100419

[epoch:  28/100000, batch:    64/  187, ite: 2570] train loss: 0.588362, tar: 0.075905 
l0: 0.083781, l1: 0.095568, l2: 0.073936, l3: 0.079455, l4: 0.083750, l5: 0.090898, l6: 0.089991

[epoch:  28/100000, batch:    66/  187, ite: 2571] train loss: 0.588378, tar: 0.075919 
l0: 0.028371, l1: 0.034326, l2: 0.029032, l3: 0.032823, l4: 0.043067, l5: 0.053296, l6: 0.041741

[epoch:  28/100000, batch:    68/  187, ite: 2572] train loss: 0.587808, tar: 0.075835 
l0: 0.050408, l1: 0.042561, l2: 0.060924, l3: 0.065289, l4: 0.066843, l5: 0.073016, l6: 0.071699

[epoch:  28/100000, batch:    70/  187, ite: 2573] train loss: 0.587534, tar: 0.075791 
l0: 0.048795, l1: 0.049340, l2: 0.051612, l3: 0.059521, l4: 0.071081, l5: 0.059973, l6: 0.072833

[epoch:  28/100000, batch:    72/  187, ite: 2574] train loss: 0.587230, tar: 0.075744 
l0: 0.050031, l1: 0.051188, l2: 0.052778, l3: 0.060127, l4: 0.045455, l5: 0.047277, l6: 0.040720

[epoch:  28/100000, batch:    74/  187, ite: 2575] train loss: 0.586813, tar: 0.075699 
l0: 0.042637, l1: 0.046429, l2: 0.051586, l3: 0.047038, l4: 0.041697, l5: 0.048170, l6: 0.046674

[epoch:  28/100000, batch:    76/  187, ite: 2576] train loss: 0.586358, tar: 0.075642 
l0: 0.085807, l1: 0.087435, l2: 0.085002, l3: 0.105440, l4: 0.094827, l5: 0.091304, l6: 0.088856

[epoch:  28/100000, batch:    78/  187, ite: 2577] train loss: 0.586448, tar: 0.075659 
l0: 0.128073, l1: 0.125141, l2: 0.136897, l3: 0.138778, l4: 0.140553, l5: 0.141095, l6: 0.145832

[epoch:  28/100000, batch:    80/  187, ite: 2578] train loss: 0.587088, tar: 0.075750 
l0: 0.093545, l1: 0.093582, l2: 0.097709, l3: 0.108651, l4: 0.102406, l5: 0.106685, l6: 0.125289

[epoch:  28/100000, batch:    82/  187, ite: 2579] train loss: 0.587331, tar: 0.075781 
l0: 0.073820, l1: 0.073803, l2: 0.079230, l3: 0.078408, l4: 0.097253, l5: 0.086302, l6: 0.087138

[epoch:  28/100000, batch:    84/  187, ite: 2580] train loss: 0.587312, tar: 0.075778 
l0: 0.069306, l1: 0.073786, l2: 0.063664, l3: 0.085277, l4: 0.077319, l5: 0.081253, l6: 0.061538

[epoch:  28/100000, batch:    86/  187, ite: 2581] train loss: 0.587182, tar: 0.075766 
l0: 0.089407, l1: 0.087970, l2: 0.083357, l3: 0.089471, l4: 0.082998, l5: 0.094831, l6: 0.091727

[epoch:  28/100000, batch:    88/  187, ite: 2582] train loss: 0.587238, tar: 0.075790 
l0: 0.038185, l1: 0.039935, l2: 0.044959, l3: 0.044726, l4: 0.043850, l5: 0.049193, l6: 0.052505

[epoch:  28/100000, batch:    90/  187, ite: 2583] train loss: 0.586769, tar: 0.075725 
l0: 0.042307, l1: 0.036258, l2: 0.039556, l3: 0.044128, l4: 0.067318, l5: 0.089949, l6: 0.088096

[epoch:  28/100000, batch:    92/  187, ite: 2584] train loss: 0.586462, tar: 0.075668 
l0: 0.071274, l1: 0.067454, l2: 0.086889, l3: 0.095726, l4: 0.081748, l5: 0.094058, l6: 0.097275

[epoch:  28/100000, batch:    94/  187, ite: 2585] train loss: 0.586475, tar: 0.075661 
l0: 0.087822, l1: 0.097589, l2: 0.108852, l3: 0.094433, l4: 0.114413, l5: 0.084767, l6: 0.088151

[epoch:  28/100000, batch:    96/  187, ite: 2586] train loss: 0.586628, tar: 0.075681 
l0: 0.070768, l1: 0.075162, l2: 0.079651, l3: 0.075066, l4: 0.073550, l5: 0.068415, l6: 0.075124

[epoch:  28/100000, batch:    98/  187, ite: 2587] train loss: 0.586511, tar: 0.075673 
l0: 0.083142, l1: 0.076796, l2: 0.085085, l3: 0.090192, l4: 0.096839, l5: 0.105956, l6: 0.098897

[epoch:  28/100000, batch:   100/  187, ite: 2588] train loss: 0.586597, tar: 0.075686 
l0: 0.087132, l1: 0.093947, l2: 0.090383, l3: 0.100362, l4: 0.102410, l5: 0.085903, l6: 0.076302

[epoch:  28/100000, batch:   102/  187, ite: 2589] train loss: 0.586681, tar: 0.075705 
l0: 0.058753, l1: 0.077841, l2: 0.064627, l3: 0.070873, l4: 0.068518, l5: 0.059527, l6: 0.062083

[epoch:  28/100000, batch:   104/  187, ite: 2590] train loss: 0.586470, tar: 0.075676 
l0: 0.061273, l1: 0.067452, l2: 0.086113, l3: 0.072860, l4: 0.081873, l5: 0.079645, l6: 0.083112

[epoch:  28/100000, batch:   106/  187, ite: 2591] train loss: 0.586379, tar: 0.075652 
l0: 0.042907, l1: 0.053608, l2: 0.051840, l3: 0.044244, l4: 0.037634, l5: 0.036073, l6: 0.047185

[epoch:  28/100000, batch:   108/  187, ite: 2592] train loss: 0.585918, tar: 0.075597 
l0: 0.069392, l1: 0.067006, l2: 0.065550, l3: 0.075511, l4: 0.101180, l5: 0.089054, l6: 0.087728

[epoch:  28/100000, batch:   110/  187, ite: 2593] train loss: 0.585866, tar: 0.075586 
l0: 0.054011, l1: 0.049123, l2: 0.056892, l3: 0.069685, l4: 0.065825, l5: 0.068580, l6: 0.054943

[epoch:  28/100000, batch:   112/  187, ite: 2594] train loss: 0.585585, tar: 0.075550 
l0: 0.076253, l1: 0.098777, l2: 0.074774, l3: 0.074040, l4: 0.079110, l5: 0.076034, l6: 0.066418

[epoch:  28/100000, batch:   114/  187, ite: 2595] train loss: 0.585518, tar: 0.075551 
l0: 0.047448, l1: 0.046358, l2: 0.047693, l3: 0.054340, l4: 0.065039, l5: 0.053920, l6: 0.055941

[epoch:  28/100000, batch:   116/  187, ite: 2596] train loss: 0.585158, tar: 0.075504 
l0: 0.063976, l1: 0.056009, l2: 0.064517, l3: 0.071940, l4: 0.079768, l5: 0.096546, l6: 0.103987

[epoch:  28/100000, batch:   118/  187, ite: 2597] train loss: 0.585076, tar: 0.075485 
l0: 0.129629, l1: 0.130749, l2: 0.134237, l3: 0.134555, l4: 0.137636, l5: 0.138193, l6: 0.129678

[epoch:  28/100000, batch:   120/  187, ite: 2598] train loss: 0.585661, tar: 0.075575 
l0: 0.095062, l1: 0.087221, l2: 0.096030, l3: 0.099347, l4: 0.116386, l5: 0.112733, l6: 0.107350

[epoch:  28/100000, batch:   122/  187, ite: 2599] train loss: 0.585876, tar: 0.075608 
l0: 0.038137, l1: 0.044549, l2: 0.044985, l3: 0.041726, l4: 0.047236, l5: 0.055290, l6: 0.039893

[epoch:  28/100000, batch:   124/  187, ite: 2600] train loss: 0.585419, tar: 0.075545 
l0: 0.100337, l1: 0.094547, l2: 0.103473, l3: 0.107923, l4: 0.123544, l5: 0.110808, l6: 0.129846

[epoch:  28/100000, batch:   126/  187, ite: 2601] train loss: 0.585727, tar: 0.075586 
l0: 0.074301, l1: 0.067658, l2: 0.084973, l3: 0.075401, l4: 0.092162, l5: 0.108805, l6: 0.100258

[epoch:  28/100000, batch:   128/  187, ite: 2602] train loss: 0.585756, tar: 0.075584 
l0: 0.059447, l1: 0.056657, l2: 0.057051, l3: 0.057680, l4: 0.058689, l5: 0.071732, l6: 0.061030

[epoch:  28/100000, batch:   130/  187, ite: 2603] train loss: 0.585485, tar: 0.075558 
l0: 0.071916, l1: 0.068687, l2: 0.077685, l3: 0.080716, l4: 0.104447, l5: 0.109768, l6: 0.085702

[epoch:  28/100000, batch:   132/  187, ite: 2604] train loss: 0.585507, tar: 0.075552 
l0: 0.051283, l1: 0.052211, l2: 0.058656, l3: 0.064062, l4: 0.074627, l5: 0.069814, l6: 0.066571

[epoch:  28/100000, batch:   134/  187, ite: 2605] train loss: 0.585262, tar: 0.075511 
l0: 0.062945, l1: 0.060765, l2: 0.069325, l3: 0.070811, l4: 0.100934, l5: 0.093071, l6: 0.099198

[epoch:  28/100000, batch:   136/  187, ite: 2606] train loss: 0.585216, tar: 0.075491 
l0: 0.081633, l1: 0.084072, l2: 0.086880, l3: 0.089825, l4: 0.097756, l5: 0.100416, l6: 0.090362

[epoch:  28/100000, batch:   138/  187, ite: 2607] train loss: 0.585291, tar: 0.075501 
l0: 0.063306, l1: 0.064158, l2: 0.068312, l3: 0.074766, l4: 0.087028, l5: 0.095886, l6: 0.097299

[epoch:  28/100000, batch:   140/  187, ite: 2608] train loss: 0.585234, tar: 0.075481 
l0: 0.075875, l1: 0.081433, l2: 0.083244, l3: 0.092911, l4: 0.079792, l5: 0.089173, l6: 0.078513

[epoch:  28/100000, batch:   142/  187, ite: 2609] train loss: 0.585227, tar: 0.075481 
l0: 0.078160, l1: 0.082957, l2: 0.083697, l3: 0.085898, l4: 0.086530, l5: 0.079264, l6: 0.081090

[epoch:  28/100000, batch:   144/  187, ite: 2610] train loss: 0.585215, tar: 0.075486 
l0: 0.067753, l1: 0.068517, l2: 0.089700, l3: 0.090682, l4: 0.094876, l5: 0.082555, l6: 0.066045

[epoch:  28/100000, batch:   146/  187, ite: 2611] train loss: 0.585174, tar: 0.075473 
l0: 0.035757, l1: 0.044619, l2: 0.043349, l3: 0.036855, l4: 0.033529, l5: 0.031618, l6: 0.044965

[epoch:  28/100000, batch:   148/  187, ite: 2612] train loss: 0.584660, tar: 0.075408 
l0: 0.153276, l1: 0.157716, l2: 0.168239, l3: 0.169266, l4: 0.220068, l5: 0.210948, l6: 0.209186

[epoch:  28/100000, batch:   150/  187, ite: 2613] train loss: 0.585808, tar: 0.075535 
l0: 0.055514, l1: 0.049329, l2: 0.066953, l3: 0.066707, l4: 0.078126, l5: 0.075457, l6: 0.097280

[epoch:  28/100000, batch:   152/  187, ite: 2614] train loss: 0.585651, tar: 0.075503 
l0: 0.073198, l1: 0.060597, l2: 0.090827, l3: 0.092708, l4: 0.104411, l5: 0.103342, l6: 0.096921

[epoch:  28/100000, batch:   154/  187, ite: 2615] train loss: 0.585710, tar: 0.075499 
l0: 0.051688, l1: 0.045745, l2: 0.046584, l3: 0.053487, l4: 0.090749, l5: 0.093949, l6: 0.096804

[epoch:  28/100000, batch:   156/  187, ite: 2616] train loss: 0.585537, tar: 0.075460 
l0: 0.062327, l1: 0.056229, l2: 0.072344, l3: 0.070366, l4: 0.080193, l5: 0.072477, l6: 0.089560

[epoch:  28/100000, batch:   158/  187, ite: 2617] train loss: 0.585404, tar: 0.075439 
l0: 0.087240, l1: 0.074807, l2: 0.095745, l3: 0.095800, l4: 0.103730, l5: 0.125222, l6: 0.106995

[epoch:  28/100000, batch:   160/  187, ite: 2618] train loss: 0.585573, tar: 0.075458 
l0: 0.068471, l1: 0.083134, l2: 0.066744, l3: 0.065169, l4: 0.071662, l5: 0.063295, l6: 0.062582

[epoch:  28/100000, batch:   162/  187, ite: 2619] train loss: 0.585404, tar: 0.075447 
l0: 0.071807, l1: 0.064168, l2: 0.076185, l3: 0.075994, l4: 0.103228, l5: 0.105482, l6: 0.119919

[epoch:  28/100000, batch:   164/  187, ite: 2620] train loss: 0.585454, tar: 0.075441 
l0: 0.048994, l1: 0.044152, l2: 0.057129, l3: 0.062342, l4: 0.083284, l5: 0.082295, l6: 0.082309

[epoch:  28/100000, batch:   166/  187, ite: 2621] train loss: 0.585253, tar: 0.075398 
l0: 0.084596, l1: 0.079973, l2: 0.092397, l3: 0.090834, l4: 0.117388, l5: 0.125713, l6: 0.116251

[epoch:  28/100000, batch:   168/  187, ite: 2622] train loss: 0.585449, tar: 0.075413 
l0: 0.067593, l1: 0.063872, l2: 0.095939, l3: 0.086685, l4: 0.086717, l5: 0.088914, l6: 0.086647

[epoch:  28/100000, batch:   170/  187, ite: 2623] train loss: 0.585435, tar: 0.075401 
l0: 0.079407, l1: 0.073187, l2: 0.096323, l3: 0.112348, l4: 0.105033, l5: 0.126089, l6: 0.106119

[epoch:  28/100000, batch:   172/  187, ite: 2624] train loss: 0.585616, tar: 0.075407 
l0: 0.082766, l1: 0.071174, l2: 0.104721, l3: 0.111520, l4: 0.104881, l5: 0.108699, l6: 0.119950

[epoch:  28/100000, batch:   174/  187, ite: 2625] train loss: 0.585805, tar: 0.075419 
l0: 0.082928, l1: 0.082870, l2: 0.097123, l3: 0.093986, l4: 0.105040, l5: 0.104816, l6: 0.094756

[epoch:  28/100000, batch:   176/  187, ite: 2626] train loss: 0.585926, tar: 0.075431 
l0: 0.060832, l1: 0.055074, l2: 0.068890, l3: 0.064748, l4: 0.092065, l5: 0.084494, l6: 0.100006

[epoch:  28/100000, batch:   178/  187, ite: 2627] train loss: 0.585830, tar: 0.075407 
l0: 0.090689, l1: 0.099117, l2: 0.109203, l3: 0.097575, l4: 0.092458, l5: 0.094608, l6: 0.098892

[epoch:  28/100000, batch:   180/  187, ite: 2628] train loss: 0.585984, tar: 0.075432 
l0: 0.033303, l1: 0.034808, l2: 0.047628, l3: 0.047238, l4: 0.049203, l5: 0.047864, l6: 0.045354

[epoch:  28/100000, batch:   182/  187, ite: 2629] train loss: 0.585538, tar: 0.075365 
l0: 0.091628, l1: 0.077547, l2: 0.106006, l3: 0.126028, l4: 0.134392, l5: 0.159110, l6: 0.203463

[epoch:  28/100000, batch:   184/  187, ite: 2630] train loss: 0.586035, tar: 0.075391 
l0: 0.081191, l1: 0.081136, l2: 0.090183, l3: 0.097892, l4: 0.080661, l5: 0.094664, l6: 0.102717

[epoch:  28/100000, batch:   186/  187, ite: 2631] train loss: 0.586102, tar: 0.075400 
l0: 0.067362, l1: 0.060797, l2: 0.073526, l3: 0.076402, l4: 0.098265, l5: 0.106279, l6: 0.089814

[epoch:  28/100000, batch:   188/  187, ite: 2632] train loss: 0.586080, tar: 0.075387 
l0: 0.051395, l1: 0.055704, l2: 0.061199, l3: 0.060095, l4: 0.063256, l5: 0.060300, l6: 0.064584

[epoch:  29/100000, batch:     2/  187, ite: 2633] train loss: 0.585812, tar: 0.075349 
l0: 0.058810, l1: 0.051729, l2: 0.063839, l3: 0.062006, l4: 0.083042, l5: 0.085302, l6: 0.092502

[epoch:  29/100000, batch:     4/  187, ite: 2634] train loss: 0.585673, tar: 0.075323 
l0: 0.095219, l1: 0.079010, l2: 0.139098, l3: 0.157147, l4: 0.126782, l5: 0.134850, l6: 0.131922

[epoch:  29/100000, batch:     6/  187, ite: 2635] train loss: 0.586111, tar: 0.075354 
l0: 0.068394, l1: 0.066086, l2: 0.065729, l3: 0.070491, l4: 0.107402, l5: 0.107617, l6: 0.110878

[epoch:  29/100000, batch:     8/  187, ite: 2636] train loss: 0.586127, tar: 0.075344 
l0: 0.053209, l1: 0.046375, l2: 0.060943, l3: 0.061560, l4: 0.096578, l5: 0.099488, l6: 0.094517

[epoch:  29/100000, batch:    10/  187, ite: 2637] train loss: 0.586012, tar: 0.075309 
l0: 0.083275, l1: 0.078809, l2: 0.095112, l3: 0.087272, l4: 0.106140, l5: 0.101846, l6: 0.109929

[epoch:  29/100000, batch:    12/  187, ite: 2638] train loss: 0.586132, tar: 0.075321 
l0: 0.094698, l1: 0.103648, l2: 0.079877, l3: 0.079694, l4: 0.106612, l5: 0.103308, l6: 0.119914

[epoch:  29/100000, batch:    14/  187, ite: 2639] train loss: 0.586291, tar: 0.075352 
l0: 0.061400, l1: 0.077066, l2: 0.066271, l3: 0.065722, l4: 0.070945, l5: 0.067019, l6: 0.059480

[epoch:  29/100000, batch:    16/  187, ite: 2640] train loss: 0.586106, tar: 0.075330 
l0: 0.056453, l1: 0.061998, l2: 0.073897, l3: 0.075852, l4: 0.078871, l5: 0.075659, l6: 0.071504

[epoch:  29/100000, batch:    18/  187, ite: 2641] train loss: 0.585963, tar: 0.075300 
l0: 0.050949, l1: 0.048822, l2: 0.057630, l3: 0.056928, l4: 0.066840, l5: 0.069344, l6: 0.070398

[epoch:  29/100000, batch:    20/  187, ite: 2642] train loss: 0.585705, tar: 0.075262 
l0: 0.049451, l1: 0.048956, l2: 0.060980, l3: 0.061395, l4: 0.103762, l5: 0.081696, l6: 0.071279

[epoch:  29/100000, batch:    22/  187, ite: 2643] train loss: 0.585537, tar: 0.075222 
l0: 0.078157, l1: 0.073094, l2: 0.106111, l3: 0.106046, l4: 0.108331, l5: 0.107790, l6: 0.102676

[epoch:  29/100000, batch:    24/  187, ite: 2644] train loss: 0.585687, tar: 0.075227 
l0: 0.034222, l1: 0.028445, l2: 0.046592, l3: 0.047541, l4: 0.067306, l5: 0.074409, l6: 0.070818

[epoch:  29/100000, batch:    26/  187, ite: 2645] train loss: 0.585352, tar: 0.075163 
l0: 0.043469, l1: 0.039592, l2: 0.072359, l3: 0.074506, l4: 0.062978, l5: 0.068946, l6: 0.057208

[epoch:  29/100000, batch:    28/  187, ite: 2646] train loss: 0.585094, tar: 0.075114 
l0: 0.079058, l1: 0.087497, l2: 0.077341, l3: 0.080515, l4: 0.073026, l5: 0.073559, l6: 0.074929

[epoch:  29/100000, batch:    30/  187, ite: 2647] train loss: 0.585034, tar: 0.075120 
l0: 0.041770, l1: 0.042307, l2: 0.043636, l3: 0.043373, l4: 0.054367, l5: 0.057903, l6: 0.055409

[epoch:  29/100000, batch:    32/  187, ite: 2648] train loss: 0.584654, tar: 0.075069 
l0: 0.059324, l1: 0.074774, l2: 0.075674, l3: 0.074910, l4: 0.063987, l5: 0.063305, l6: 0.060187

[epoch:  29/100000, batch:    34/  187, ite: 2649] train loss: 0.584481, tar: 0.075045 
l0: 0.051620, l1: 0.055475, l2: 0.061315, l3: 0.063831, l4: 0.054494, l5: 0.051535, l6: 0.056428

[epoch:  29/100000, batch:    36/  187, ite: 2650] train loss: 0.584189, tar: 0.075009 
l0: 0.025873, l1: 0.039748, l2: 0.032272, l3: 0.030776, l4: 0.036125, l5: 0.031844, l6: 0.029951

[epoch:  29/100000, batch:    38/  187, ite: 2651] train loss: 0.583639, tar: 0.074933 
l0: 0.097181, l1: 0.111552, l2: 0.113695, l3: 0.119894, l4: 0.136833, l5: 0.108049, l6: 0.106474

[epoch:  29/100000, batch:    40/  187, ite: 2652] train loss: 0.583961, tar: 0.074967 
l0: 0.039078, l1: 0.031050, l2: 0.050206, l3: 0.053542, l4: 0.078673, l5: 0.086598, l6: 0.076818

[epoch:  29/100000, batch:    42/  187, ite: 2653] train loss: 0.583704, tar: 0.074912 
l0: 0.062654, l1: 0.064948, l2: 0.066226, l3: 0.064946, l4: 0.081750, l5: 0.072556, l6: 0.068025

[epoch:  29/100000, batch:    44/  187, ite: 2654] train loss: 0.583547, tar: 0.074893 
l0: 0.044258, l1: 0.034081, l2: 0.069171, l3: 0.065051, l4: 0.063859, l5: 0.069625, l6: 0.056674

[epoch:  29/100000, batch:    46/  187, ite: 2655] train loss: 0.583271, tar: 0.074847 
l0: 0.047965, l1: 0.042386, l2: 0.060591, l3: 0.062917, l4: 0.067439, l5: 0.070250, l6: 0.060327

[epoch:  29/100000, batch:    48/  187, ite: 2656] train loss: 0.583010, tar: 0.074806 
l0: 0.064992, l1: 0.053064, l2: 0.084929, l3: 0.094829, l4: 0.105412, l5: 0.107709, l6: 0.095269

[epoch:  29/100000, batch:    50/  187, ite: 2657] train loss: 0.583045, tar: 0.074791 
l0: 0.037125, l1: 0.035212, l2: 0.054101, l3: 0.053115, l4: 0.063361, l5: 0.056297, l6: 0.062029

[epoch:  29/100000, batch:    52/  187, ite: 2658] train loss: 0.582708, tar: 0.074734 
l0: 0.059783, l1: 0.057747, l2: 0.079857, l3: 0.079765, l4: 0.077867, l5: 0.076259, l6: 0.061975

[epoch:  29/100000, batch:    54/  187, ite: 2659] train loss: 0.582572, tar: 0.074711 
l0: 0.115031, l1: 0.128452, l2: 0.108170, l3: 0.109025, l4: 0.131331, l5: 0.111790, l6: 0.115472

[epoch:  29/100000, batch:    56/  187, ite: 2660] train loss: 0.582931, tar: 0.074772 
l0: 0.044288, l1: 0.056986, l2: 0.044153, l3: 0.042404, l4: 0.041631, l5: 0.042847, l6: 0.053574

[epoch:  29/100000, batch:    58/  187, ite: 2661] train loss: 0.582542, tar: 0.074726 
l0: 0.112223, l1: 0.130002, l2: 0.117020, l3: 0.123444, l4: 0.124241, l5: 0.110045, l6: 0.116045

[epoch:  29/100000, batch:    60/  187, ite: 2662] train loss: 0.582920, tar: 0.074782 
l0: 0.108314, l1: 0.111862, l2: 0.113029, l3: 0.109151, l4: 0.121532, l5: 0.118543, l6: 0.138204

[epoch:  29/100000, batch:    62/  187, ite: 2663] train loss: 0.583279, tar: 0.074833 
l0: 0.077787, l1: 0.078333, l2: 0.096308, l3: 0.089164, l4: 0.099993, l5: 0.090024, l6: 0.090790

[epoch:  29/100000, batch:    64/  187, ite: 2664] train loss: 0.583338, tar: 0.074837 
l0: 0.040929, l1: 0.043721, l2: 0.059796, l3: 0.058146, l4: 0.054881, l5: 0.052235, l6: 0.044115

[epoch:  29/100000, batch:    66/  187, ite: 2665] train loss: 0.582993, tar: 0.074786 
l0: 0.084332, l1: 0.092053, l2: 0.103366, l3: 0.098229, l4: 0.087593, l5: 0.089276, l6: 0.094304

[epoch:  29/100000, batch:    68/  187, ite: 2666] train loss: 0.583092, tar: 0.074801 
l0: 0.073754, l1: 0.073017, l2: 0.071766, l3: 0.073141, l4: 0.078345, l5: 0.083146, l6: 0.078143

[epoch:  29/100000, batch:    70/  187, ite: 2667] train loss: 0.583015, tar: 0.074799 
l0: 0.126533, l1: 0.143798, l2: 0.140381, l3: 0.136498, l4: 0.133596, l5: 0.118461, l6: 0.114731

[epoch:  29/100000, batch:    72/  187, ite: 2668] train loss: 0.583510, tar: 0.074877 
l0: 0.091672, l1: 0.088671, l2: 0.102038, l3: 0.109307, l4: 0.125053, l5: 0.130573, l6: 0.125681

[epoch:  29/100000, batch:    74/  187, ite: 2669] train loss: 0.583793, tar: 0.074902 
l0: 0.053033, l1: 0.050092, l2: 0.064738, l3: 0.066754, l4: 0.073697, l5: 0.072078, l6: 0.066556

[epoch:  29/100000, batch:    76/  187, ite: 2670] train loss: 0.583589, tar: 0.074869 
l0: 0.103922, l1: 0.094066, l2: 0.119726, l3: 0.127459, l4: 0.119886, l5: 0.120255, l6: 0.147933

[epoch:  29/100000, batch:    78/  187, ite: 2671] train loss: 0.583961, tar: 0.074912 
l0: 0.073421, l1: 0.083781, l2: 0.085056, l3: 0.080658, l4: 0.075649, l5: 0.066525, l6: 0.065173

[epoch:  29/100000, batch:    80/  187, ite: 2672] train loss: 0.583881, tar: 0.074910 
l0: 0.066184, l1: 0.057496, l2: 0.076642, l3: 0.078008, l4: 0.088518, l5: 0.086382, l6: 0.083716

[epoch:  29/100000, batch:    82/  187, ite: 2673] train loss: 0.583811, tar: 0.074897 
l0: 0.058132, l1: 0.057758, l2: 0.059961, l3: 0.064576, l4: 0.073293, l5: 0.063415, l6: 0.069275

[epoch:  29/100000, batch:    84/  187, ite: 2674] train loss: 0.583608, tar: 0.074872 
l0: 0.085706, l1: 0.082147, l2: 0.087646, l3: 0.093176, l4: 0.078916, l5: 0.084888, l6: 0.094370

[epoch:  29/100000, batch:    86/  187, ite: 2675] train loss: 0.583642, tar: 0.074888 
l0: 0.067179, l1: 0.058958, l2: 0.096584, l3: 0.097651, l4: 0.080067, l5: 0.089509, l6: 0.090622

[epoch:  29/100000, batch:    88/  187, ite: 2676] train loss: 0.583637, tar: 0.074877 
l0: 0.078853, l1: 0.085815, l2: 0.085546, l3: 0.079896, l4: 0.081989, l5: 0.094689, l6: 0.092683

[epoch:  29/100000, batch:    90/  187, ite: 2677] train loss: 0.583661, tar: 0.074883 
l0: 0.045517, l1: 0.048850, l2: 0.055533, l3: 0.056211, l4: 0.068981, l5: 0.062852, l6: 0.051749

[epoch:  29/100000, batch:    92/  187, ite: 2678] train loss: 0.583375, tar: 0.074840 
l0: 0.074683, l1: 0.064757, l2: 0.082302, l3: 0.086153, l4: 0.102686, l5: 0.119688, l6: 0.098941

[epoch:  29/100000, batch:    94/  187, ite: 2679] train loss: 0.583442, tar: 0.074839 
l0: 0.076981, l1: 0.077199, l2: 0.076683, l3: 0.078013, l4: 0.087595, l5: 0.097624, l6: 0.098267

[epoch:  29/100000, batch:    96/  187, ite: 2680] train loss: 0.583455, tar: 0.074843 
l0: 0.134308, l1: 0.122075, l2: 0.192286, l3: 0.202285, l4: 0.221867, l5: 0.212354, l6: 0.260439

[epoch:  29/100000, batch:    98/  187, ite: 2681] train loss: 0.584575, tar: 0.074930 
l0: 0.060932, l1: 0.052371, l2: 0.063755, l3: 0.070194, l4: 0.077600, l5: 0.091240, l6: 0.097714

[epoch:  29/100000, batch:   100/  187, ite: 2682] train loss: 0.584471, tar: 0.074909 
l0: 0.052855, l1: 0.054346, l2: 0.050303, l3: 0.052251, l4: 0.065950, l5: 0.069270, l6: 0.072205

[epoch:  29/100000, batch:   102/  187, ite: 2683] train loss: 0.584226, tar: 0.074877 
l0: 0.042924, l1: 0.059935, l2: 0.047656, l3: 0.042577, l4: 0.039197, l5: 0.037808, l6: 0.033532

[epoch:  29/100000, batch:   104/  187, ite: 2684] train loss: 0.583816, tar: 0.074830 
l0: 0.049231, l1: 0.057687, l2: 0.048509, l3: 0.044945, l4: 0.055625, l5: 0.056906, l6: 0.063689

[epoch:  29/100000, batch:   106/  187, ite: 2685] train loss: 0.583513, tar: 0.074793 
l0: 0.029713, l1: 0.029776, l2: 0.036072, l3: 0.038138, l4: 0.038718, l5: 0.038264, l6: 0.036741

[epoch:  29/100000, batch:   108/  187, ite: 2686] train loss: 0.583023, tar: 0.074727 
l0: 0.087014, l1: 0.075460, l2: 0.107375, l3: 0.127491, l4: 0.117128, l5: 0.112430, l6: 0.114239

[epoch:  29/100000, batch:   110/  187, ite: 2687] train loss: 0.583253, tar: 0.074745 
l0: 0.037152, l1: 0.032839, l2: 0.053045, l3: 0.057000, l4: 0.039411, l5: 0.040891, l6: 0.042577

[epoch:  29/100000, batch:   112/  187, ite: 2688] train loss: 0.582846, tar: 0.074690 
l0: 0.066509, l1: 0.065332, l2: 0.085529, l3: 0.080261, l4: 0.081284, l5: 0.083173, l6: 0.078029

[epoch:  29/100000, batch:   114/  187, ite: 2689] train loss: 0.582784, tar: 0.074679 
l0: 0.076111, l1: 0.087256, l2: 0.073732, l3: 0.070289, l4: 0.078156, l5: 0.082214, l6: 0.078416

[epoch:  29/100000, batch:   116/  187, ite: 2690] train loss: 0.582731, tar: 0.074681 
l0: 0.066118, l1: 0.056708, l2: 0.071006, l3: 0.082795, l4: 0.071943, l5: 0.086240, l6: 0.100936

[epoch:  29/100000, batch:   118/  187, ite: 2691] train loss: 0.582663, tar: 0.074668 
l0: 0.054073, l1: 0.057351, l2: 0.059748, l3: 0.071619, l4: 0.075933, l5: 0.070785, l6: 0.066494

[epoch:  29/100000, batch:   120/  187, ite: 2692] train loss: 0.582480, tar: 0.074639 
l0: 0.022599, l1: 0.019979, l2: 0.034166, l3: 0.034054, l4: 0.045274, l5: 0.038430, l6: 0.040572

[epoch:  29/100000, batch:   122/  187, ite: 2693] train loss: 0.581978, tar: 0.074563 
l0: 0.080455, l1: 0.100610, l2: 0.070456, l3: 0.070389, l4: 0.065227, l5: 0.070039, l6: 0.067913

[epoch:  29/100000, batch:   124/  187, ite: 2694] train loss: 0.581896, tar: 0.074572 
l0: 0.054679, l1: 0.066243, l2: 0.056997, l3: 0.059264, l4: 0.076339, l5: 0.079121, l6: 0.066568

[epoch:  29/100000, batch:   126/  187, ite: 2695] train loss: 0.581720, tar: 0.074543 
l0: 0.063907, l1: 0.058323, l2: 0.080994, l3: 0.070816, l4: 0.083615, l5: 0.105672, l6: 0.084955

[epoch:  29/100000, batch:   128/  187, ite: 2696] train loss: 0.581672, tar: 0.074528 
l0: 0.054056, l1: 0.049319, l2: 0.067571, l3: 0.074745, l4: 0.076635, l5: 0.079096, l6: 0.076090

[epoch:  29/100000, batch:   130/  187, ite: 2697] train loss: 0.581522, tar: 0.074499 
l0: 0.063496, l1: 0.054386, l2: 0.060349, l3: 0.065597, l4: 0.086997, l5: 0.091024, l6: 0.125617

[epoch:  29/100000, batch:   132/  187, ite: 2698] train loss: 0.581474, tar: 0.074483 
l0: 0.098443, l1: 0.094965, l2: 0.101697, l3: 0.094365, l4: 0.105173, l5: 0.133217, l6: 0.149176

[epoch:  29/100000, batch:   134/  187, ite: 2699] train loss: 0.581753, tar: 0.074517 
l0: 0.059953, l1: 0.064380, l2: 0.064345, l3: 0.070616, l4: 0.071142, l5: 0.077720, l6: 0.109607

[epoch:  29/100000, batch:   136/  187, ite: 2700] train loss: 0.581662, tar: 0.074496 
l0: 0.058346, l1: 0.053519, l2: 0.062400, l3: 0.071126, l4: 0.088793, l5: 0.078183, l6: 0.081691

[epoch:  29/100000, batch:   138/  187, ite: 2701] train loss: 0.581537, tar: 0.074473 
l0: 0.040303, l1: 0.031673, l2: 0.041695, l3: 0.051201, l4: 0.087899, l5: 0.092158, l6: 0.081633

[epoch:  29/100000, batch:   140/  187, ite: 2702] train loss: 0.581316, tar: 0.074425 
l0: 0.050806, l1: 0.051494, l2: 0.049070, l3: 0.055321, l4: 0.066106, l5: 0.071367, l6: 0.073817

[epoch:  29/100000, batch:   142/  187, ite: 2703] train loss: 0.581084, tar: 0.074391 
l0: 0.080583, l1: 0.085555, l2: 0.100939, l3: 0.111617, l4: 0.130272, l5: 0.124608, l6: 0.075946

[epoch:  29/100000, batch:   144/  187, ite: 2704] train loss: 0.581266, tar: 0.074400 
l0: 0.076206, l1: 0.075643, l2: 0.089193, l3: 0.094561, l4: 0.109835, l5: 0.109356, l6: 0.123235

[epoch:  29/100000, batch:   146/  187, ite: 2705] train loss: 0.581404, tar: 0.074402 
l0: 0.107755, l1: 0.116089, l2: 0.139687, l3: 0.117451, l4: 0.130863, l5: 0.120233, l6: 0.125624

[epoch:  29/100000, batch:   148/  187, ite: 2706] train loss: 0.581795, tar: 0.074450 
l0: 0.110572, l1: 0.128089, l2: 0.153263, l3: 0.113900, l4: 0.133409, l5: 0.122055, l6: 0.136463

[epoch:  29/100000, batch:   150/  187, ite: 2707] train loss: 0.582242, tar: 0.074501 
l0: 0.131286, l1: 0.169579, l2: 0.150024, l3: 0.144511, l4: 0.114523, l5: 0.094120, l6: 0.118748

[epoch:  29/100000, batch:   152/  187, ite: 2708] train loss: 0.582723, tar: 0.074581 
l0: 0.052960, l1: 0.052839, l2: 0.050719, l3: 0.059869, l4: 0.070956, l5: 0.076918, l6: 0.085683

[epoch:  29/100000, batch:   154/  187, ite: 2709] train loss: 0.582536, tar: 0.074550 
l0: 0.049576, l1: 0.039952, l2: 0.062527, l3: 0.076784, l4: 0.111617, l5: 0.103496, l6: 0.104186

[epoch:  29/100000, batch:   156/  187, ite: 2710] train loss: 0.582487, tar: 0.074515 
l0: 0.107009, l1: 0.109584, l2: 0.115595, l3: 0.113128, l4: 0.105097, l5: 0.128968, l6: 0.170661

[epoch:  29/100000, batch:   158/  187, ite: 2711] train loss: 0.582863, tar: 0.074561 
l0: 0.053352, l1: 0.055749, l2: 0.052745, l3: 0.053437, l4: 0.081265, l5: 0.074772, l6: 0.065228

[epoch:  29/100000, batch:   160/  187, ite: 2712] train loss: 0.582658, tar: 0.074531 
l0: 0.052691, l1: 0.070761, l2: 0.077199, l3: 0.071668, l4: 0.074004, l5: 0.061285, l6: 0.062435

[epoch:  29/100000, batch:   162/  187, ite: 2713] train loss: 0.582500, tar: 0.074501 
l0: 0.057693, l1: 0.053361, l2: 0.066044, l3: 0.061648, l4: 0.071213, l5: 0.072656, l6: 0.082562

[epoch:  29/100000, batch:   164/  187, ite: 2714] train loss: 0.582336, tar: 0.074477 
l0: 0.051953, l1: 0.054370, l2: 0.066748, l3: 0.064967, l4: 0.080475, l5: 0.074638, l6: 0.067818

[epoch:  29/100000, batch:   166/  187, ite: 2715] train loss: 0.582166, tar: 0.074446 
l0: 0.080378, l1: 0.078248, l2: 0.094074, l3: 0.088880, l4: 0.096900, l5: 0.121167, l6: 0.094371

[epoch:  29/100000, batch:   168/  187, ite: 2716] train loss: 0.582266, tar: 0.074454 
l0: 0.052716, l1: 0.054313, l2: 0.055986, l3: 0.054319, l4: 0.064031, l5: 0.067334, l6: 0.068075

[epoch:  29/100000, batch:   170/  187, ite: 2717] train loss: 0.582036, tar: 0.074423 
l0: 0.055701, l1: 0.059883, l2: 0.058882, l3: 0.063494, l4: 0.069835, l5: 0.072119, l6: 0.075027

[epoch:  29/100000, batch:   172/  187, ite: 2718] train loss: 0.581859, tar: 0.074397 
l0: 0.053494, l1: 0.048798, l2: 0.079440, l3: 0.068945, l4: 0.072747, l5: 0.077914, l6: 0.082097

[epoch:  29/100000, batch:   174/  187, ite: 2719] train loss: 0.581722, tar: 0.074368 
l0: 0.040647, l1: 0.047349, l2: 0.044970, l3: 0.043804, l4: 0.043061, l5: 0.042749, l6: 0.044207

[epoch:  29/100000, batch:   176/  187, ite: 2720] train loss: 0.581340, tar: 0.074321 
l0: 0.038995, l1: 0.034044, l2: 0.046928, l3: 0.050155, l4: 0.061972, l5: 0.061240, l6: 0.051271

[epoch:  29/100000, batch:   178/  187, ite: 2721] train loss: 0.581011, tar: 0.074273 
l0: 0.157549, l1: 0.146278, l2: 0.185890, l3: 0.218300, l4: 0.202035, l5: 0.223700, l6: 0.205143

[epoch:  29/100000, batch:   180/  187, ite: 2722] train loss: 0.582061, tar: 0.074388 
l0: 0.088494, l1: 0.079312, l2: 0.113461, l3: 0.117682, l4: 0.127596, l5: 0.121885, l6: 0.137639

[epoch:  29/100000, batch:   182/  187, ite: 2723] train loss: 0.582343, tar: 0.074407 
l0: 0.088505, l1: 0.094757, l2: 0.096604, l3: 0.092095, l4: 0.102005, l5: 0.101614, l6: 0.099607

[epoch:  29/100000, batch:   184/  187, ite: 2724] train loss: 0.582472, tar: 0.074427 
l0: 0.038537, l1: 0.040904, l2: 0.044105, l3: 0.046898, l4: 0.058692, l5: 0.055579, l6: 0.053029

[epoch:  29/100000, batch:   186/  187, ite: 2725] train loss: 0.582134, tar: 0.074377 
l0: 0.117216, l1: 0.122456, l2: 0.117178, l3: 0.106696, l4: 0.107097, l5: 0.123676, l6: 0.157066

[epoch:  29/100000, batch:   188/  187, ite: 2726] train loss: 0.582505, tar: 0.074436 
l0: 0.067168, l1: 0.063252, l2: 0.078798, l3: 0.073150, l4: 0.097622, l5: 0.086857, l6: 0.078388

[epoch:  30/100000, batch:     2/  187, ite: 2727] train loss: 0.582454, tar: 0.074426 
l0: 0.040801, l1: 0.042466, l2: 0.043918, l3: 0.044178, l4: 0.058909, l5: 0.065579, l6: 0.056346

[epoch:  30/100000, batch:     4/  187, ite: 2728] train loss: 0.582137, tar: 0.074380 
l0: 0.071326, l1: 0.061623, l2: 0.079102, l3: 0.082437, l4: 0.117892, l5: 0.114812, l6: 0.096498

[epoch:  30/100000, batch:     6/  187, ite: 2729] train loss: 0.582194, tar: 0.074376 
l0: 0.056269, l1: 0.050437, l2: 0.076108, l3: 0.078001, l4: 0.079522, l5: 0.081152, l6: 0.071707

[epoch:  30/100000, batch:     8/  187, ite: 2730] train loss: 0.582072, tar: 0.074351 
l0: 0.059342, l1: 0.047503, l2: 0.069806, l3: 0.073992, l4: 0.115062, l5: 0.139203, l6: 0.118507

[epoch:  30/100000, batch:    10/  187, ite: 2731] train loss: 0.582129, tar: 0.074331 
l0: 0.086342, l1: 0.086781, l2: 0.091438, l3: 0.121586, l4: 0.109199, l5: 0.135216, l6: 0.117484

[epoch:  30/100000, batch:    12/  187, ite: 2732] train loss: 0.582356, tar: 0.074347 
l0: 0.070242, l1: 0.058851, l2: 0.070900, l3: 0.075449, l4: 0.110823, l5: 0.114883, l6: 0.109841

[epoch:  30/100000, batch:    14/  187, ite: 2733] train loss: 0.582395, tar: 0.074341 
l0: 0.069065, l1: 0.085033, l2: 0.088929, l3: 0.085513, l4: 0.077133, l5: 0.068224, l6: 0.074570

[epoch:  30/100000, batch:    16/  187, ite: 2734] train loss: 0.582348, tar: 0.074334 
l0: 0.060669, l1: 0.059689, l2: 0.071059, l3: 0.073001, l4: 0.074309, l5: 0.078870, l6: 0.078002

[epoch:  30/100000, batch:    18/  187, ite: 2735] train loss: 0.582230, tar: 0.074316 
l0: 0.160677, l1: 0.146476, l2: 0.205499, l3: 0.224126, l4: 0.214772, l5: 0.236794, l6: 0.232716

[epoch:  30/100000, batch:    20/  187, ite: 2736] train loss: 0.583370, tar: 0.074433 
l0: 0.085766, l1: 0.081358, l2: 0.088071, l3: 0.089012, l4: 0.096888, l5: 0.093421, l6: 0.097200

[epoch:  30/100000, batch:    22/  187, ite: 2737] train loss: 0.583436, tar: 0.074448 
l0: 0.104411, l1: 0.102930, l2: 0.114263, l3: 0.131579, l4: 0.106693, l5: 0.117243, l6: 0.126335

[epoch:  30/100000, batch:    24/  187, ite: 2738] train loss: 0.583734, tar: 0.074489 
l0: 0.097341, l1: 0.095539, l2: 0.097769, l3: 0.105266, l4: 0.112173, l5: 0.115156, l6: 0.102736

[epoch:  30/100000, batch:    26/  187, ite: 2739] train loss: 0.583926, tar: 0.074520 
l0: 0.046102, l1: 0.046295, l2: 0.058551, l3: 0.058712, l4: 0.062985, l5: 0.056625, l6: 0.049885

[epoch:  30/100000, batch:    28/  187, ite: 2740] train loss: 0.583650, tar: 0.074481 
l0: 0.081273, l1: 0.084942, l2: 0.091132, l3: 0.093758, l4: 0.087212, l5: 0.090669, l6: 0.088192

[epoch:  30/100000, batch:    30/  187, ite: 2741] train loss: 0.583695, tar: 0.074491 
l0: 0.113100, l1: 0.122066, l2: 0.120098, l3: 0.119486, l4: 0.136694, l5: 0.121706, l6: 0.101951

[epoch:  30/100000, batch:    32/  187, ite: 2742] train loss: 0.584034, tar: 0.074543 
l0: 0.060937, l1: 0.067492, l2: 0.059668, l3: 0.060866, l4: 0.072828, l5: 0.068838, l6: 0.058565

[epoch:  30/100000, batch:    34/  187, ite: 2743] train loss: 0.583852, tar: 0.074524 
l0: 0.048465, l1: 0.054992, l2: 0.052695, l3: 0.048729, l4: 0.052454, l5: 0.051238, l6: 0.049433

[epoch:  30/100000, batch:    36/  187, ite: 2744] train loss: 0.583549, tar: 0.074489 
l0: 0.062377, l1: 0.057825, l2: 0.081498, l3: 0.074109, l4: 0.087284, l5: 0.086321, l6: 0.086578

[epoch:  30/100000, batch:    38/  187, ite: 2745] train loss: 0.583485, tar: 0.074473 
l0: 0.059899, l1: 0.065732, l2: 0.060741, l3: 0.064840, l4: 0.090942, l5: 0.083483, l6: 0.074809

[epoch:  30/100000, batch:    40/  187, ite: 2746] train loss: 0.583373, tar: 0.074454 
l0: 0.074965, l1: 0.075975, l2: 0.074202, l3: 0.069437, l4: 0.091815, l5: 0.101541, l6: 0.103903

[epoch:  30/100000, batch:    42/  187, ite: 2747] train loss: 0.583385, tar: 0.074454 
l0: 0.043146, l1: 0.048425, l2: 0.045108, l3: 0.042963, l4: 0.064884, l5: 0.063748, l6: 0.060295

[epoch:  30/100000, batch:    44/  187, ite: 2748] train loss: 0.583098, tar: 0.074412 
l0: 0.036204, l1: 0.041642, l2: 0.040824, l3: 0.044368, l4: 0.043145, l5: 0.044736, l6: 0.040851

[epoch:  30/100000, batch:    46/  187, ite: 2749] train loss: 0.582709, tar: 0.074361 
l0: 0.040927, l1: 0.046137, l2: 0.044170, l3: 0.047602, l4: 0.052520, l5: 0.047365, l6: 0.052520

[epoch:  30/100000, batch:    48/  187, ite: 2750] train loss: 0.582373, tar: 0.074317 
l0: 0.066648, l1: 0.058031, l2: 0.076383, l3: 0.072940, l4: 0.095352, l5: 0.091731, l6: 0.091789

[epoch:  30/100000, batch:    50/  187, ite: 2751] train loss: 0.582334, tar: 0.074307 
l0: 0.052951, l1: 0.050908, l2: 0.071257, l3: 0.059460, l4: 0.067210, l5: 0.067053, l6: 0.074462

[epoch:  30/100000, batch:    52/  187, ite: 2752] train loss: 0.582149, tar: 0.074278 
l0: 0.062081, l1: 0.058758, l2: 0.085390, l3: 0.085307, l4: 0.090415, l5: 0.090044, l6: 0.080072

[epoch:  30/100000, batch:    54/  187, ite: 2753] train loss: 0.582109, tar: 0.074262 
l0: 0.051265, l1: 0.054214, l2: 0.059013, l3: 0.055511, l4: 0.068415, l5: 0.060571, l6: 0.058342

[epoch:  30/100000, batch:    56/  187, ite: 2754] train loss: 0.581877, tar: 0.074231 
l0: 0.056264, l1: 0.072569, l2: 0.053961, l3: 0.051060, l4: 0.052431, l5: 0.051431, l6: 0.059950

[epoch:  30/100000, batch:    58/  187, ite: 2755] train loss: 0.581633, tar: 0.074208 
l0: 0.047347, l1: 0.044681, l2: 0.063710, l3: 0.052653, l4: 0.056416, l5: 0.051944, l6: 0.054508

[epoch:  30/100000, batch:    60/  187, ite: 2756] train loss: 0.581355, tar: 0.074172 
l0: 0.071231, l1: 0.077619, l2: 0.079229, l3: 0.070575, l4: 0.069670, l5: 0.059523, l6: 0.071121

[epoch:  30/100000, batch:    62/  187, ite: 2757] train loss: 0.581246, tar: 0.074168 
l0: 0.059130, l1: 0.047593, l2: 0.077141, l3: 0.082620, l4: 0.099339, l5: 0.106748, l6: 0.091094

[epoch:  30/100000, batch:    64/  187, ite: 2758] train loss: 0.581223, tar: 0.074148 
l0: 0.082950, l1: 0.099566, l2: 0.069618, l3: 0.074868, l4: 0.076620, l5: 0.073716, l6: 0.090806

[epoch:  30/100000, batch:    66/  187, ite: 2759] train loss: 0.581206, tar: 0.074160 
l0: 0.071553, l1: 0.073715, l2: 0.093585, l3: 0.093418, l4: 0.075944, l5: 0.074630, l6: 0.088000

[epoch:  30/100000, batch:    68/  187, ite: 2760] train loss: 0.581192, tar: 0.074157 
l0: 0.067105, l1: 0.061117, l2: 0.088448, l3: 0.086189, l4: 0.087452, l5: 0.090741, l6: 0.099441

[epoch:  30/100000, batch:    70/  187, ite: 2761] train loss: 0.581191, tar: 0.074147 
l0: 0.100682, l1: 0.100206, l2: 0.105401, l3: 0.104912, l4: 0.101845, l5: 0.112476, l6: 0.114891

[epoch:  30/100000, batch:    72/  187, ite: 2762] train loss: 0.581400, tar: 0.074182 
l0: 0.044812, l1: 0.034038, l2: 0.057512, l3: 0.054968, l4: 0.069256, l5: 0.080496, l6: 0.110652

[epoch:  30/100000, batch:    74/  187, ite: 2763] train loss: 0.581230, tar: 0.074144 
l0: 0.076421, l1: 0.072100, l2: 0.071573, l3: 0.073054, l4: 0.088582, l5: 0.120401, l6: 0.108368

[epoch:  30/100000, batch:    76/  187, ite: 2764] train loss: 0.581269, tar: 0.074147 
l0: 0.071738, l1: 0.071405, l2: 0.066795, l3: 0.071269, l4: 0.091997, l5: 0.080899, l6: 0.082074

[epoch:  30/100000, batch:    78/  187, ite: 2765] train loss: 0.581210, tar: 0.074143 
l0: 0.047138, l1: 0.050356, l2: 0.051462, l3: 0.045974, l4: 0.064102, l5: 0.061376, l6: 0.059336

[epoch:  30/100000, batch:    80/  187, ite: 2766] train loss: 0.580947, tar: 0.074108 
l0: 0.052917, l1: 0.055037, l2: 0.057909, l3: 0.052149, l4: 0.085347, l5: 0.089915, l6: 0.094956

[epoch:  30/100000, batch:    82/  187, ite: 2767] train loss: 0.580826, tar: 0.074081 
l0: 0.064822, l1: 0.060256, l2: 0.063349, l3: 0.066446, l4: 0.080143, l5: 0.086415, l6: 0.075334

[epoch:  30/100000, batch:    84/  187, ite: 2768] train loss: 0.580716, tar: 0.074069 
l0: 0.088724, l1: 0.082325, l2: 0.095224, l3: 0.101309, l4: 0.105932, l5: 0.107839, l6: 0.115826

[epoch:  30/100000, batch:    86/  187, ite: 2769] train loss: 0.580868, tar: 0.074088 
l0: 0.067503, l1: 0.057483, l2: 0.072569, l3: 0.075709, l4: 0.109869, l5: 0.132303, l6: 0.082382

[epoch:  30/100000, batch:    88/  187, ite: 2770] train loss: 0.580890, tar: 0.074079 
l0: 0.058451, l1: 0.049401, l2: 0.062501, l3: 0.064234, l4: 0.071133, l5: 0.072146, l6: 0.086241

[epoch:  30/100000, batch:    90/  187, ite: 2771] train loss: 0.580738, tar: 0.074059 
l0: 0.091410, l1: 0.101339, l2: 0.108573, l3: 0.090424, l4: 0.095107, l5: 0.085777, l6: 0.093730

[epoch:  30/100000, batch:    92/  187, ite: 2772] train loss: 0.580849, tar: 0.074081 
l0: 0.064599, l1: 0.077155, l2: 0.085226, l3: 0.072106, l4: 0.063069, l5: 0.057082, l6: 0.093781

[epoch:  30/100000, batch:    94/  187, ite: 2773] train loss: 0.580762, tar: 0.074069 
l0: 0.070043, l1: 0.086605, l2: 0.086337, l3: 0.078916, l4: 0.061247, l5: 0.062605, l6: 0.057920

[epoch:  30/100000, batch:    96/  187, ite: 2774] train loss: 0.580662, tar: 0.074064 
l0: 0.083478, l1: 0.100491, l2: 0.088136, l3: 0.091141, l4: 0.094429, l5: 0.087347, l6: 0.080928

[epoch:  30/100000, batch:    98/  187, ite: 2775] train loss: 0.580720, tar: 0.074076 
l0: 0.036677, l1: 0.033273, l2: 0.050370, l3: 0.052943, l4: 0.050861, l5: 0.058694, l6: 0.047942

[epoch:  30/100000, batch:   100/  187, ite: 2776] train loss: 0.580398, tar: 0.074028 
l0: 0.058411, l1: 0.053400, l2: 0.071349, l3: 0.060841, l4: 0.082477, l5: 0.075642, l6: 0.077925

[epoch:  30/100000, batch:   102/  187, ite: 2777] train loss: 0.580269, tar: 0.074008 
l0: 0.041032, l1: 0.046732, l2: 0.055015, l3: 0.048658, l4: 0.048518, l5: 0.046305, l6: 0.051747

[epoch:  30/100000, batch:   104/  187, ite: 2778] train loss: 0.579958, tar: 0.073965 
l0: 0.066861, l1: 0.064617, l2: 0.069928, l3: 0.065996, l4: 0.088937, l5: 0.099248, l6: 0.102801

[epoch:  30/100000, batch:   106/  187, ite: 2779] train loss: 0.579930, tar: 0.073956 
l0: 0.040732, l1: 0.035756, l2: 0.039485, l3: 0.042552, l4: 0.056345, l5: 0.055117, l6: 0.061801

[epoch:  30/100000, batch:   108/  187, ite: 2780] train loss: 0.579612, tar: 0.073914 
l0: 0.041560, l1: 0.037266, l2: 0.051640, l3: 0.056091, l4: 0.064622, l5: 0.069080, l6: 0.066472

[epoch:  30/100000, batch:   110/  187, ite: 2781] train loss: 0.579365, tar: 0.073872 
l0: 0.138689, l1: 0.168153, l2: 0.152543, l3: 0.134660, l4: 0.153889, l5: 0.130239, l6: 0.142585

[epoch:  30/100000, batch:   112/  187, ite: 2782] train loss: 0.579929, tar: 0.073955 
l0: 0.031014, l1: 0.031756, l2: 0.037037, l3: 0.033818, l4: 0.037027, l5: 0.039753, l6: 0.035056

[epoch:  30/100000, batch:   114/  187, ite: 2783] train loss: 0.579502, tar: 0.073900 
l0: 0.034642, l1: 0.037819, l2: 0.031271, l3: 0.031760, l4: 0.051997, l5: 0.061086, l6: 0.056113

[epoch:  30/100000, batch:   116/  187, ite: 2784] train loss: 0.579152, tar: 0.073850 
l0: 0.043248, l1: 0.044436, l2: 0.050439, l3: 0.044453, l4: 0.048645, l5: 0.050363, l6: 0.045659

[epoch:  30/100000, batch:   118/  187, ite: 2785] train loss: 0.578831, tar: 0.073811 
l0: 0.085320, l1: 0.071465, l2: 0.108215, l3: 0.098287, l4: 0.126022, l5: 0.127496, l6: 0.140063

[epoch:  30/100000, batch:   120/  187, ite: 2786] train loss: 0.579057, tar: 0.073826 
l0: 0.074116, l1: 0.068486, l2: 0.084238, l3: 0.079393, l4: 0.097827, l5: 0.098573, l6: 0.096195

[epoch:  30/100000, batch:   122/  187, ite: 2787] train loss: 0.579082, tar: 0.073826 
l0: 0.059193, l1: 0.054724, l2: 0.066954, l3: 0.062730, l4: 0.080063, l5: 0.073221, l6: 0.082392

[epoch:  30/100000, batch:   124/  187, ite: 2788] train loss: 0.578956, tar: 0.073808 
l0: 0.069370, l1: 0.069244, l2: 0.066765, l3: 0.069446, l4: 0.103131, l5: 0.089730, l6: 0.093061

[epoch:  30/100000, batch:   126/  187, ite: 2789] train loss: 0.578933, tar: 0.073802 
l0: 0.061654, l1: 0.051580, l2: 0.071210, l3: 0.077483, l4: 0.091281, l5: 0.105033, l6: 0.112820

[epoch:  30/100000, batch:   128/  187, ite: 2790] train loss: 0.578923, tar: 0.073787 
l0: 0.086922, l1: 0.077160, l2: 0.105120, l3: 0.104101, l4: 0.110554, l5: 0.124690, l6: 0.129171

[epoch:  30/100000, batch:   130/  187, ite: 2791] train loss: 0.579124, tar: 0.073803 
l0: 0.065793, l1: 0.063103, l2: 0.069324, l3: 0.073705, l4: 0.104678, l5: 0.102692, l6: 0.103868

[epoch:  30/100000, batch:   132/  187, ite: 2792] train loss: 0.579129, tar: 0.073793 
l0: 0.060853, l1: 0.053401, l2: 0.072734, l3: 0.073943, l4: 0.087983, l5: 0.100149, l6: 0.101380

[epoch:  30/100000, batch:   134/  187, ite: 2793] train loss: 0.579092, tar: 0.073777 
l0: 0.064128, l1: 0.069469, l2: 0.066763, l3: 0.074494, l4: 0.082076, l5: 0.101537, l6: 0.091330

[epoch:  30/100000, batch:   136/  187, ite: 2794] train loss: 0.579056, tar: 0.073765 
l0: 0.094883, l1: 0.097432, l2: 0.117762, l3: 0.125998, l4: 0.129273, l5: 0.136954, l6: 0.122000

[epoch:  30/100000, batch:   138/  187, ite: 2795] train loss: 0.579364, tar: 0.073791 
l0: 0.057167, l1: 0.059489, l2: 0.066935, l3: 0.067757, l4: 0.089109, l5: 0.090348, l6: 0.099628

[epoch:  30/100000, batch:   140/  187, ite: 2796] train loss: 0.579303, tar: 0.073770 
l0: 0.066535, l1: 0.059039, l2: 0.065807, l3: 0.063597, l4: 0.088877, l5: 0.099482, l6: 0.093467

[epoch:  30/100000, batch:   142/  187, ite: 2797] train loss: 0.579249, tar: 0.073761 
l0: 0.056333, l1: 0.056335, l2: 0.067621, l3: 0.067953, l4: 0.072506, l5: 0.075200, l6: 0.080262

[epoch:  30/100000, batch:   144/  187, ite: 2798] train loss: 0.579120, tar: 0.073739 
l0: 0.053872, l1: 0.049322, l2: 0.058186, l3: 0.065516, l4: 0.077098, l5: 0.087660, l6: 0.084806

[epoch:  30/100000, batch:   146/  187, ite: 2799] train loss: 0.578992, tar: 0.073714 
l0: 0.071409, l1: 0.076330, l2: 0.103217, l3: 0.094451, l4: 0.076459, l5: 0.084097, l6: 0.088417

[epoch:  30/100000, batch:   148/  187, ite: 2800] train loss: 0.579011, tar: 0.073712 
l0: 0.095102, l1: 0.085399, l2: 0.115498, l3: 0.119697, l4: 0.123647, l5: 0.135707, l6: 0.127685

[epoch:  30/100000, batch:   150/  187, ite: 2801] train loss: 0.579290, tar: 0.073738 
l0: 0.040504, l1: 0.048202, l2: 0.051150, l3: 0.045448, l4: 0.042813, l5: 0.054382, l6: 0.047068

[epoch:  30/100000, batch:   152/  187, ite: 2802] train loss: 0.578979, tar: 0.073697 
l0: 0.061633, l1: 0.057264, l2: 0.058878, l3: 0.062676, l4: 0.092642, l5: 0.091872, l6: 0.098800

[epoch:  30/100000, batch:   154/  187, ite: 2803] train loss: 0.578910, tar: 0.073682 
l0: 0.087167, l1: 0.085673, l2: 0.092461, l3: 0.089295, l4: 0.092872, l5: 0.109480, l6: 0.094779

[epoch:  30/100000, batch:   156/  187, ite: 2804] train loss: 0.579001, tar: 0.073699 
l0: 0.071422, l1: 0.079648, l2: 0.091101, l3: 0.091164, l4: 0.085002, l5: 0.081717, l6: 0.081946

[epoch:  30/100000, batch:   158/  187, ite: 2805] train loss: 0.579004, tar: 0.073696 
l0: 0.046304, l1: 0.038477, l2: 0.059895, l3: 0.058673, l4: 0.075283, l5: 0.085897, l6: 0.081083

[epoch:  30/100000, batch:   160/  187, ite: 2806] train loss: 0.578839, tar: 0.073662 
l0: 0.067504, l1: 0.056247, l2: 0.072791, l3: 0.070976, l4: 0.091298, l5: 0.120610, l6: 0.112524

[epoch:  30/100000, batch:   162/  187, ite: 2807] train loss: 0.578855, tar: 0.073654 
l0: 0.069143, l1: 0.071349, l2: 0.069941, l3: 0.074466, l4: 0.103074, l5: 0.105068, l6: 0.101155

[epoch:  30/100000, batch:   164/  187, ite: 2808] train loss: 0.578874, tar: 0.073649 
l0: 0.067870, l1: 0.060126, l2: 0.067416, l3: 0.071933, l4: 0.092183, l5: 0.093762, l6: 0.092688

[epoch:  30/100000, batch:   166/  187, ite: 2809] train loss: 0.578833, tar: 0.073641 
l0: 0.108663, l1: 0.097045, l2: 0.146719, l3: 0.153327, l4: 0.137403, l5: 0.142046, l6: 0.155196

[epoch:  30/100000, batch:   168/  187, ite: 2810] train loss: 0.579280, tar: 0.073685 
l0: 0.049083, l1: 0.055276, l2: 0.050278, l3: 0.048634, l4: 0.065500, l5: 0.063709, l6: 0.069121

[epoch:  30/100000, batch:   170/  187, ite: 2811] train loss: 0.579061, tar: 0.073654 
l0: 0.068578, l1: 0.075541, l2: 0.069859, l3: 0.080675, l4: 0.080086, l5: 0.082681, l6: 0.076288

[epoch:  30/100000, batch:   172/  187, ite: 2812] train loss: 0.579005, tar: 0.073648 
l0: 0.065787, l1: 0.054710, l2: 0.077732, l3: 0.066573, l4: 0.099043, l5: 0.118036, l6: 0.111599

[epoch:  30/100000, batch:   174/  187, ite: 2813] train loss: 0.579023, tar: 0.073638 
l0: 0.083645, l1: 0.084169, l2: 0.090593, l3: 0.092903, l4: 0.105308, l5: 0.131829, l6: 0.126893

[epoch:  30/100000, batch:   176/  187, ite: 2814] train loss: 0.579190, tar: 0.073651 
l0: 0.053395, l1: 0.049523, l2: 0.055880, l3: 0.054864, l4: 0.063546, l5: 0.068691, l6: 0.073145

[epoch:  30/100000, batch:   178/  187, ite: 2815] train loss: 0.578994, tar: 0.073626 
l0: 0.119583, l1: 0.120510, l2: 0.170777, l3: 0.175718, l4: 0.169703, l5: 0.152351, l6: 0.130080

[epoch:  30/100000, batch:   180/  187, ite: 2816] train loss: 0.579557, tar: 0.073682 
l0: 0.083646, l1: 0.081863, l2: 0.121231, l3: 0.113843, l4: 0.098650, l5: 0.107025, l6: 0.099364

[epoch:  30/100000, batch:   182/  187, ite: 2817] train loss: 0.579711, tar: 0.073694 
l0: 0.041095, l1: 0.036202, l2: 0.048321, l3: 0.048933, l4: 0.057897, l5: 0.068910, l6: 0.061804

[epoch:  30/100000, batch:   184/  187, ite: 2818] train loss: 0.579447, tar: 0.073655 
l0: 0.055071, l1: 0.053670, l2: 0.056455, l3: 0.056232, l4: 0.064880, l5: 0.070790, l6: 0.066509

[epoch:  30/100000, batch:   186/  187, ite: 2819] train loss: 0.579256, tar: 0.073632 
l0: 0.131536, l1: 0.158081, l2: 0.112188, l3: 0.114191, l4: 0.113425, l5: 0.115892, l6: 0.126404

[epoch:  30/100000, batch:   188/  187, ite: 2820] train loss: 0.579613, tar: 0.073702 
l0: 0.042053, l1: 0.055008, l2: 0.072436, l3: 0.064441, l4: 0.049642, l5: 0.044467, l6: 0.042827

[epoch:  31/100000, batch:     2/  187, ite: 2821] train loss: 0.579359, tar: 0.073664 
l0: 0.093083, l1: 0.092656, l2: 0.106328, l3: 0.114866, l4: 0.130162, l5: 0.118808, l6: 0.114694

[epoch:  31/100000, batch:     4/  187, ite: 2822] train loss: 0.579591, tar: 0.073688 
l0: 0.088959, l1: 0.107689, l2: 0.085168, l3: 0.097926, l4: 0.073320, l5: 0.075451, l6: 0.070209

[epoch:  31/100000, batch:     6/  187, ite: 2823] train loss: 0.579615, tar: 0.073706 
l0: 0.056903, l1: 0.052548, l2: 0.063972, l3: 0.066175, l4: 0.070796, l5: 0.080214, l6: 0.074289

[epoch:  31/100000, batch:     8/  187, ite: 2824] train loss: 0.579475, tar: 0.073686 
l0: 0.049767, l1: 0.051676, l2: 0.059358, l3: 0.059491, l4: 0.057584, l5: 0.059224, l6: 0.060842

[epoch:  31/100000, batch:    10/  187, ite: 2825] train loss: 0.579255, tar: 0.073657 
l0: 0.043279, l1: 0.040195, l2: 0.055011, l3: 0.054665, l4: 0.067462, l5: 0.069250, l6: 0.068028

[epoch:  31/100000, batch:    12/  187, ite: 2826] train loss: 0.579036, tar: 0.073620 
l0: 0.073679, l1: 0.085133, l2: 0.074034, l3: 0.082970, l4: 0.075080, l5: 0.082162, l6: 0.080934

[epoch:  31/100000, batch:    14/  187, ite: 2827] train loss: 0.579005, tar: 0.073620 
l0: 0.069885, l1: 0.067484, l2: 0.083918, l3: 0.083879, l4: 0.077819, l5: 0.091837, l6: 0.076822

[epoch:  31/100000, batch:    16/  187, ite: 2828] train loss: 0.578972, tar: 0.073615 
l0: 0.068974, l1: 0.078631, l2: 0.075549, l3: 0.083075, l4: 0.089521, l5: 0.085917, l6: 0.095626

[epoch:  31/100000, batch:    18/  187, ite: 2829] train loss: 0.578970, tar: 0.073610 
l0: 0.047069, l1: 0.049655, l2: 0.056454, l3: 0.057545, l4: 0.052775, l5: 0.052475, l6: 0.056865

[epoch:  31/100000, batch:    20/  187, ite: 2830] train loss: 0.578722, tar: 0.073578 
l0: 0.056911, l1: 0.061010, l2: 0.056653, l3: 0.055981, l4: 0.073982, l5: 0.070982, l6: 0.070127

[epoch:  31/100000, batch:    22/  187, ite: 2831] train loss: 0.578562, tar: 0.073558 
l0: 0.112864, l1: 0.123857, l2: 0.097088, l3: 0.092800, l4: 0.099995, l5: 0.118285, l6: 0.132384

[epoch:  31/100000, batch:    24/  187, ite: 2832] train loss: 0.578801, tar: 0.073605 
l0: 0.080247, l1: 0.076689, l2: 0.097285, l3: 0.093126, l4: 0.093128, l5: 0.087600, l6: 0.094592

[epoch:  31/100000, batch:    26/  187, ite: 2833] train loss: 0.578853, tar: 0.073613 
l0: 0.056577, l1: 0.048562, l2: 0.068453, l3: 0.067905, l4: 0.068767, l5: 0.071279, l6: 0.089365

[epoch:  31/100000, batch:    28/  187, ite: 2834] train loss: 0.578724, tar: 0.073593 
l0: 0.069089, l1: 0.061984, l2: 0.092548, l3: 0.108891, l4: 0.090405, l5: 0.081272, l6: 0.095767

[epoch:  31/100000, batch:    30/  187, ite: 2835] train loss: 0.578749, tar: 0.073587 
l0: 0.051512, l1: 0.041641, l2: 0.075668, l3: 0.079188, l4: 0.097549, l5: 0.088193, l6: 0.085445

[epoch:  31/100000, batch:    32/  187, ite: 2836] train loss: 0.578678, tar: 0.073561 
l0: 0.056442, l1: 0.050620, l2: 0.065481, l3: 0.061156, l4: 0.059966, l5: 0.065301, l6: 0.061716

[epoch:  31/100000, batch:    34/  187, ite: 2837] train loss: 0.578489, tar: 0.073540 
l0: 0.070932, l1: 0.067602, l2: 0.083648, l3: 0.080645, l4: 0.081185, l5: 0.098769, l6: 0.087792

[epoch:  31/100000, batch:    36/  187, ite: 2838] train loss: 0.578480, tar: 0.073537 
l0: 0.049237, l1: 0.052693, l2: 0.050077, l3: 0.052269, l4: 0.064821, l5: 0.064459, l6: 0.059063

[epoch:  31/100000, batch:    38/  187, ite: 2839] train loss: 0.578258, tar: 0.073508 
l0: 0.046908, l1: 0.042184, l2: 0.048382, l3: 0.050079, l4: 0.082273, l5: 0.085428, l6: 0.089977

[epoch:  31/100000, batch:    40/  187, ite: 2840] train loss: 0.578100, tar: 0.073477 
l0: 0.056516, l1: 0.059760, l2: 0.057394, l3: 0.054761, l4: 0.088051, l5: 0.086334, l6: 0.092956

[epoch:  31/100000, batch:    42/  187, ite: 2841] train loss: 0.578002, tar: 0.073456 
l0: 0.081522, l1: 0.080912, l2: 0.088411, l3: 0.090852, l4: 0.083079, l5: 0.089644, l6: 0.085432

[epoch:  31/100000, batch:    44/  187, ite: 2842] train loss: 0.578028, tar: 0.073466 
l0: 0.031202, l1: 0.032156, l2: 0.038203, l3: 0.038896, l4: 0.046961, l5: 0.037864, l6: 0.049292

[epoch:  31/100000, batch:    46/  187, ite: 2843] train loss: 0.577668, tar: 0.073416 
l0: 0.049392, l1: 0.063254, l2: 0.069606, l3: 0.060394, l4: 0.053976, l5: 0.056194, l6: 0.061255

[epoch:  31/100000, batch:    48/  187, ite: 2844] train loss: 0.577474, tar: 0.073387 
l0: 0.075727, l1: 0.083663, l2: 0.074417, l3: 0.076322, l4: 0.110274, l5: 0.092503, l6: 0.091163

[epoch:  31/100000, batch:    50/  187, ite: 2845] train loss: 0.577506, tar: 0.073390 
l0: 0.051988, l1: 0.072894, l2: 0.050781, l3: 0.045111, l4: 0.041153, l5: 0.035727, l6: 0.040034

[epoch:  31/100000, batch:    52/  187, ite: 2846] train loss: 0.577222, tar: 0.073365 
l0: 0.074409, l1: 0.074407, l2: 0.061405, l3: 0.068891, l4: 0.089823, l5: 0.101637, l6: 0.094753

[epoch:  31/100000, batch:    54/  187, ite: 2847] train loss: 0.577208, tar: 0.073366 
l0: 0.050302, l1: 0.046416, l2: 0.048070, l3: 0.056819, l4: 0.068604, l5: 0.074634, l6: 0.072504

[epoch:  31/100000, batch:    56/  187, ite: 2848] train loss: 0.577020, tar: 0.073339 
l0: 0.038946, l1: 0.054136, l2: 0.050613, l3: 0.045161, l4: 0.037247, l5: 0.039247, l6: 0.041102

[epoch:  31/100000, batch:    58/  187, ite: 2849] train loss: 0.576701, tar: 0.073298 
l0: 0.053443, l1: 0.050813, l2: 0.056755, l3: 0.060067, l4: 0.065509, l5: 0.064480, l6: 0.069851

[epoch:  31/100000, batch:    60/  187, ite: 2850] train loss: 0.576518, tar: 0.073275 
l0: 0.024787, l1: 0.025277, l2: 0.033613, l3: 0.030711, l4: 0.049349, l5: 0.050547, l6: 0.053388

[epoch:  31/100000, batch:    62/  187, ite: 2851] train loss: 0.576155, tar: 0.073218 
l0: 0.082887, l1: 0.087157, l2: 0.083173, l3: 0.083439, l4: 0.077190, l5: 0.073717, l6: 0.094264

[epoch:  31/100000, batch:    64/  187, ite: 2852] train loss: 0.576162, tar: 0.073229 
l0: 0.038286, l1: 0.028987, l2: 0.044362, l3: 0.048325, l4: 0.061197, l5: 0.066886, l6: 0.071071

[epoch:  31/100000, batch:    66/  187, ite: 2853] train loss: 0.575907, tar: 0.073188 
l0: 0.057759, l1: 0.051651, l2: 0.071290, l3: 0.070055, l4: 0.073814, l5: 0.082963, l6: 0.076541

[epoch:  31/100000, batch:    68/  187, ite: 2854] train loss: 0.575800, tar: 0.073170 
l0: 0.051112, l1: 0.054511, l2: 0.049453, l3: 0.051357, l4: 0.056637, l5: 0.059270, l6: 0.066526

[epoch:  31/100000, batch:    70/  187, ite: 2855] train loss: 0.575581, tar: 0.073145 
l0: 0.082890, l1: 0.092822, l2: 0.074112, l3: 0.085894, l4: 0.099335, l5: 0.096550, l6: 0.074895

[epoch:  31/100000, batch:    72/  187, ite: 2856] train loss: 0.575617, tar: 0.073156 
l0: 0.074731, l1: 0.083848, l2: 0.078146, l3: 0.087053, l4: 0.081792, l5: 0.096776, l6: 0.077892

[epoch:  31/100000, batch:    74/  187, ite: 2857] train loss: 0.575622, tar: 0.073158 
l0: 0.089012, l1: 0.098197, l2: 0.097727, l3: 0.090743, l4: 0.087449, l5: 0.090621, l6: 0.105176

[epoch:  31/100000, batch:    76/  187, ite: 2858] train loss: 0.575720, tar: 0.073176 
l0: 0.084712, l1: 0.083753, l2: 0.104274, l3: 0.104423, l4: 0.104592, l5: 0.103930, l6: 0.092570

[epoch:  31/100000, batch:    78/  187, ite: 2859] train loss: 0.575839, tar: 0.073190 
l0: 0.060191, l1: 0.069415, l2: 0.069811, l3: 0.070645, l4: 0.077455, l5: 0.081935, l6: 0.083005

[epoch:  31/100000, batch:    80/  187, ite: 2860] train loss: 0.575765, tar: 0.073175 
l0: 0.052306, l1: 0.041688, l2: 0.057680, l3: 0.061067, l4: 0.111888, l5: 0.106058, l6: 0.120919

[epoch:  31/100000, batch:    82/  187, ite: 2861] train loss: 0.575737, tar: 0.073150 
l0: 0.032043, l1: 0.032411, l2: 0.040796, l3: 0.038272, l4: 0.054388, l5: 0.053923, l6: 0.049590

[epoch:  31/100000, batch:    84/  187, ite: 2862] train loss: 0.575419, tar: 0.073103 
l0: 0.039949, l1: 0.046539, l2: 0.046800, l3: 0.050421, l4: 0.051195, l5: 0.043718, l6: 0.038360

[epoch:  31/100000, batch:    86/  187, ite: 2863] train loss: 0.575119, tar: 0.073064 
l0: 0.048340, l1: 0.062597, l2: 0.046734, l3: 0.047607, l4: 0.045728, l5: 0.043197, l6: 0.039771

[epoch:  31/100000, batch:    88/  187, ite: 2864] train loss: 0.574840, tar: 0.073036 
l0: 0.060734, l1: 0.068446, l2: 0.067969, l3: 0.062402, l4: 0.062741, l5: 0.083965, l6: 0.071952

[epoch:  31/100000, batch:    90/  187, ite: 2865] train loss: 0.574729, tar: 0.073021 
l0: 0.088209, l1: 0.083755, l2: 0.105283, l3: 0.098351, l4: 0.136330, l5: 0.109779, l6: 0.096314

[epoch:  31/100000, batch:    92/  187, ite: 2866] train loss: 0.574894, tar: 0.073039 
l0: 0.154781, l1: 0.197722, l2: 0.165226, l3: 0.171836, l4: 0.123041, l5: 0.107327, l6: 0.114780

[epoch:  31/100000, batch:    94/  187, ite: 2867] train loss: 0.575424, tar: 0.073133 
l0: 0.079992, l1: 0.079909, l2: 0.094336, l3: 0.083488, l4: 0.088855, l5: 0.097786, l6: 0.089160

[epoch:  31/100000, batch:    96/  187, ite: 2868] train loss: 0.575468, tar: 0.073141 
l0: 0.051835, l1: 0.055676, l2: 0.050919, l3: 0.051067, l4: 0.066377, l5: 0.071682, l6: 0.076979

[epoch:  31/100000, batch:    98/  187, ite: 2869] train loss: 0.575295, tar: 0.073117 
l0: 0.066153, l1: 0.066912, l2: 0.088562, l3: 0.081641, l4: 0.081520, l5: 0.077522, l6: 0.079358

[epoch:  31/100000, batch:   100/  187, ite: 2870] train loss: 0.575256, tar: 0.073109 
l0: 0.043567, l1: 0.043951, l2: 0.052255, l3: 0.059757, l4: 0.053601, l5: 0.049396, l6: 0.056849

[epoch:  31/100000, batch:   102/  187, ite: 2871] train loss: 0.575008, tar: 0.073075 
l0: 0.055801, l1: 0.051297, l2: 0.058506, l3: 0.065964, l4: 0.088761, l5: 0.090770, l6: 0.070052

[epoch:  31/100000, batch:   104/  187, ite: 2872] train loss: 0.574901, tar: 0.073055 
l0: 0.057417, l1: 0.057178, l2: 0.064764, l3: 0.064627, l4: 0.065045, l5: 0.061860, l6: 0.061340

[epoch:  31/100000, batch:   106/  187, ite: 2873] train loss: 0.574737, tar: 0.073037 
l0: 0.073052, l1: 0.072916, l2: 0.075100, l3: 0.076463, l4: 0.081516, l5: 0.078959, l6: 0.062197

[epoch:  31/100000, batch:   108/  187, ite: 2874] train loss: 0.574675, tar: 0.073037 
l0: 0.091868, l1: 0.084840, l2: 0.087479, l3: 0.090957, l4: 0.101989, l5: 0.119887, l6: 0.101510

[epoch:  31/100000, batch:   110/  187, ite: 2875] train loss: 0.574793, tar: 0.073059 
l0: 0.063927, l1: 0.062895, l2: 0.071453, l3: 0.064898, l4: 0.091740, l5: 0.091572, l6: 0.074034

[epoch:  31/100000, batch:   112/  187, ite: 2876] train loss: 0.574731, tar: 0.073048 
l0: 0.089548, l1: 0.094170, l2: 0.091541, l3: 0.086310, l4: 0.073661, l5: 0.085876, l6: 0.089865

[epoch:  31/100000, batch:   114/  187, ite: 2877] train loss: 0.574773, tar: 0.073067 
l0: 0.035898, l1: 0.032630, l2: 0.041650, l3: 0.042667, l4: 0.052024, l5: 0.052219, l6: 0.048419

[epoch:  31/100000, batch:   116/  187, ite: 2878] train loss: 0.574466, tar: 0.073025 
l0: 0.065152, l1: 0.064594, l2: 0.071216, l3: 0.063654, l4: 0.084684, l5: 0.090738, l6: 0.075175

[epoch:  31/100000, batch:   118/  187, ite: 2879] train loss: 0.574399, tar: 0.073016 
l0: 0.090187, l1: 0.096028, l2: 0.097223, l3: 0.110975, l4: 0.106744, l5: 0.097931, l6: 0.091875

[epoch:  31/100000, batch:   120/  187, ite: 2880] train loss: 0.574531, tar: 0.073035 
l0: 0.069257, l1: 0.065311, l2: 0.070903, l3: 0.074676, l4: 0.090309, l5: 0.097098, l6: 0.099591

[epoch:  31/100000, batch:   122/  187, ite: 2881] train loss: 0.574523, tar: 0.073031 
l0: 0.053595, l1: 0.048729, l2: 0.062302, l3: 0.067155, l4: 0.069156, l5: 0.068909, l6: 0.072991

[epoch:  31/100000, batch:   124/  187, ite: 2882] train loss: 0.574373, tar: 0.073009 
l0: 0.073215, l1: 0.083496, l2: 0.069241, l3: 0.074374, l4: 0.067525, l5: 0.077895, l6: 0.075191

[epoch:  31/100000, batch:   126/  187, ite: 2883] train loss: 0.574313, tar: 0.073009 
l0: 0.061558, l1: 0.057346, l2: 0.065369, l3: 0.079470, l4: 0.091064, l5: 0.098484, l6: 0.109170

[epoch:  31/100000, batch:   128/  187, ite: 2884] train loss: 0.574299, tar: 0.072996 
l0: 0.080059, l1: 0.076093, l2: 0.070907, l3: 0.067956, l4: 0.089677, l5: 0.121181, l6: 0.102751

[epoch:  31/100000, batch:   130/  187, ite: 2885] train loss: 0.574338, tar: 0.073004 
l0: 0.060034, l1: 0.064623, l2: 0.072963, l3: 0.064058, l4: 0.081379, l5: 0.073932, l6: 0.067891

[epoch:  31/100000, batch:   132/  187, ite: 2886] train loss: 0.574237, tar: 0.072989 
l0: 0.069471, l1: 0.066294, l2: 0.071428, l3: 0.075047, l4: 0.084130, l5: 0.090099, l6: 0.080385

[epoch:  31/100000, batch:   134/  187, ite: 2887] train loss: 0.574195, tar: 0.072985 
l0: 0.061657, l1: 0.060745, l2: 0.060859, l3: 0.064190, l4: 0.086781, l5: 0.088698, l6: 0.091036

[epoch:  31/100000, batch:   136/  187, ite: 2888] train loss: 0.574127, tar: 0.072973 
l0: 0.052172, l1: 0.047333, l2: 0.072845, l3: 0.075602, l4: 0.089662, l5: 0.084485, l6: 0.075340

[epoch:  31/100000, batch:   138/  187, ite: 2889] train loss: 0.574041, tar: 0.072949 
l0: 0.055922, l1: 0.047336, l2: 0.056851, l3: 0.076213, l4: 0.105549, l5: 0.083512, l6: 0.080877

[epoch:  31/100000, batch:   140/  187, ite: 2890] train loss: 0.573965, tar: 0.072930 
l0: 0.067698, l1: 0.064920, l2: 0.089009, l3: 0.085062, l4: 0.084744, l5: 0.072211, l6: 0.082307

[epoch:  31/100000, batch:   142/  187, ite: 2891] train loss: 0.573933, tar: 0.072924 
l0: 0.063959, l1: 0.069010, l2: 0.074216, l3: 0.071384, l4: 0.080108, l5: 0.074437, l6: 0.082141

[epoch:  31/100000, batch:   144/  187, ite: 2892] train loss: 0.573868, tar: 0.072914 
l0: 0.085127, l1: 0.079551, l2: 0.094136, l3: 0.111740, l4: 0.104267, l5: 0.089963, l6: 0.096026

[epoch:  31/100000, batch:   146/  187, ite: 2893] train loss: 0.573965, tar: 0.072928 
l0: 0.101013, l1: 0.116273, l2: 0.095930, l3: 0.100183, l4: 0.084583, l5: 0.086470, l6: 0.091808

[epoch:  31/100000, batch:   148/  187, ite: 2894] train loss: 0.574079, tar: 0.072959 
l0: 0.055027, l1: 0.046405, l2: 0.059731, l3: 0.061209, l4: 0.085670, l5: 0.093467, l6: 0.077268

[epoch:  31/100000, batch:   150/  187, ite: 2895] train loss: 0.573973, tar: 0.072939 
l0: 0.053090, l1: 0.061380, l2: 0.065367, l3: 0.063080, l4: 0.073244, l5: 0.074871, l6: 0.063109

[epoch:  31/100000, batch:   152/  187, ite: 2896] train loss: 0.573839, tar: 0.072917 
l0: 0.050000, l1: 0.046808, l2: 0.054940, l3: 0.060228, l4: 0.084254, l5: 0.078156, l6: 0.080787

[epoch:  31/100000, batch:   154/  187, ite: 2897] train loss: 0.573707, tar: 0.072892 
l0: 0.041204, l1: 0.043560, l2: 0.042272, l3: 0.042393, l4: 0.060913, l5: 0.057232, l6: 0.054473

[epoch:  31/100000, batch:   156/  187, ite: 2898] train loss: 0.573449, tar: 0.072856 
l0: 0.070523, l1: 0.072730, l2: 0.078259, l3: 0.085513, l4: 0.065197, l5: 0.061628, l6: 0.064126

[epoch:  31/100000, batch:   158/  187, ite: 2899] train loss: 0.573365, tar: 0.072854 
l0: 0.043267, l1: 0.040102, l2: 0.041084, l3: 0.047090, l4: 0.069358, l5: 0.064185, l6: 0.061157

[epoch:  31/100000, batch:   160/  187, ite: 2900] train loss: 0.573135, tar: 0.072821 
l0: 0.044373, l1: 0.048316, l2: 0.049472, l3: 0.052111, l4: 0.060244, l5: 0.052428, l6: 0.047039

[epoch:  31/100000, batch:   162/  187, ite: 2901] train loss: 0.572892, tar: 0.072789 
l0: 0.070554, l1: 0.068879, l2: 0.090846, l3: 0.094615, l4: 0.073490, l5: 0.074400, l6: 0.077455

[epoch:  31/100000, batch:   164/  187, ite: 2902] train loss: 0.572867, tar: 0.072787 
l0: 0.063251, l1: 0.071715, l2: 0.061162, l3: 0.055613, l4: 0.055141, l5: 0.056839, l6: 0.068687

[epoch:  31/100000, batch:   166/  187, ite: 2903] train loss: 0.572711, tar: 0.072776 
l0: 0.037083, l1: 0.037086, l2: 0.046646, l3: 0.041442, l4: 0.046044, l5: 0.044936, l6: 0.049490

[epoch:  31/100000, batch:   168/  187, ite: 2904] train loss: 0.572412, tar: 0.072737 
l0: 0.048681, l1: 0.047076, l2: 0.075720, l3: 0.081001, l4: 0.063140, l5: 0.058761, l6: 0.055337

[epoch:  31/100000, batch:   170/  187, ite: 2905] train loss: 0.572255, tar: 0.072710 
l0: 0.059932, l1: 0.052456, l2: 0.069877, l3: 0.070436, l4: 0.074820, l5: 0.073196, l6: 0.084477

[epoch:  31/100000, batch:   172/  187, ite: 2906] train loss: 0.572159, tar: 0.072696 
l0: 0.069039, l1: 0.069745, l2: 0.082637, l3: 0.078962, l4: 0.121451, l5: 0.097310, l6: 0.073477

[epoch:  31/100000, batch:   174/  187, ite: 2907] train loss: 0.572181, tar: 0.072692 
l0: 0.064932, l1: 0.052743, l2: 0.076431, l3: 0.082258, l4: 0.085892, l5: 0.130568, l6: 0.112194

[epoch:  31/100000, batch:   176/  187, ite: 2908] train loss: 0.572217, tar: 0.072684 
l0: 0.044139, l1: 0.043416, l2: 0.042246, l3: 0.041294, l4: 0.048312, l5: 0.052343, l6: 0.046058

[epoch:  31/100000, batch:   178/  187, ite: 2909] train loss: 0.571937, tar: 0.072652 
l0: 0.052692, l1: 0.051487, l2: 0.051761, l3: 0.052882, l4: 0.064133, l5: 0.066574, l6: 0.067226

[epoch:  31/100000, batch:   180/  187, ite: 2910] train loss: 0.571756, tar: 0.072630 
l0: 0.025830, l1: 0.021671, l2: 0.040625, l3: 0.049201, l4: 0.046162, l5: 0.049431, l6: 0.042414

[epoch:  31/100000, batch:   182/  187, ite: 2911] train loss: 0.571431, tar: 0.072579 
l0: 0.051497, l1: 0.053732, l2: 0.053355, l3: 0.053563, l4: 0.053961, l5: 0.045028, l6: 0.046027

[epoch:  31/100000, batch:   184/  187, ite: 2912] train loss: 0.571196, tar: 0.072556 
l0: 0.099422, l1: 0.122110, l2: 0.118385, l3: 0.107497, l4: 0.105312, l5: 0.106091, l6: 0.117775

[epoch:  31/100000, batch:   186/  187, ite: 2913] train loss: 0.571421, tar: 0.072585 
l0: 0.046969, l1: 0.036662, l2: 0.082679, l3: 0.093615, l4: 0.092070, l5: 0.103167, l6: 0.088747

[epoch:  31/100000, batch:   188/  187, ite: 2914] train loss: 0.571390, tar: 0.072557 
l0: 0.050619, l1: 0.057954, l2: 0.051388, l3: 0.046769, l4: 0.047469, l5: 0.055387, l6: 0.048195

[epoch:  32/100000, batch:     2/  187, ite: 2915] train loss: 0.571157, tar: 0.072533 
l0: 0.044169, l1: 0.045932, l2: 0.048030, l3: 0.050988, l4: 0.052749, l5: 0.049894, l6: 0.049500

[epoch:  32/100000, batch:     4/  187, ite: 2916] train loss: 0.570906, tar: 0.072502 
l0: 0.092346, l1: 0.084775, l2: 0.102957, l3: 0.109301, l4: 0.105511, l5: 0.116156, l6: 0.134180

[epoch:  32/100000, batch:     6/  187, ite: 2917] train loss: 0.571096, tar: 0.072524 
l0: 0.051040, l1: 0.045314, l2: 0.055219, l3: 0.058584, l4: 0.060761, l5: 0.065091, l6: 0.067627

[epoch:  32/100000, batch:     8/  187, ite: 2918] train loss: 0.570914, tar: 0.072500 
l0: 0.064524, l1: 0.058177, l2: 0.066541, l3: 0.069393, l4: 0.094147, l5: 0.106391, l6: 0.105136

[epoch:  32/100000, batch:    10/  187, ite: 2919] train loss: 0.570907, tar: 0.072492 
l0: 0.085003, l1: 0.066727, l2: 0.106298, l3: 0.117587, l4: 0.123295, l5: 0.149449, l6: 0.138864

[epoch:  32/100000, batch:    12/  187, ite: 2920] train loss: 0.571142, tar: 0.072505 
l0: 0.039993, l1: 0.042738, l2: 0.036839, l3: 0.036442, l4: 0.047174, l5: 0.049412, l6: 0.046902

[epoch:  32/100000, batch:    14/  187, ite: 2921] train loss: 0.570847, tar: 0.072470 
l0: 0.057206, l1: 0.052030, l2: 0.062978, l3: 0.069281, l4: 0.073605, l5: 0.080153, l6: 0.081997

[epoch:  32/100000, batch:    16/  187, ite: 2922] train loss: 0.570745, tar: 0.072453 
l0: 0.045938, l1: 0.046240, l2: 0.054659, l3: 0.056587, l4: 0.052918, l5: 0.066093, l6: 0.057610

[epoch:  32/100000, batch:    18/  187, ite: 2923] train loss: 0.570539, tar: 0.072425 
l0: 0.062437, l1: 0.068311, l2: 0.061079, l3: 0.061610, l4: 0.067964, l5: 0.072683, l6: 0.073914

[epoch:  32/100000, batch:    20/  187, ite: 2924] train loss: 0.570428, tar: 0.072414 
l0: 0.023192, l1: 0.021826, l2: 0.026670, l3: 0.027656, l4: 0.031775, l5: 0.032066, l6: 0.034424

[epoch:  32/100000, batch:    22/  187, ite: 2925] train loss: 0.570025, tar: 0.072361 
l0: 0.046558, l1: 0.038308, l2: 0.053293, l3: 0.071555, l4: 0.073609, l5: 0.071096, l6: 0.077556

[epoch:  32/100000, batch:    24/  187, ite: 2926] train loss: 0.569875, tar: 0.072333 
l0: 0.051850, l1: 0.044448, l2: 0.055623, l3: 0.057686, l4: 0.074398, l5: 0.077727, l6: 0.074675

[epoch:  32/100000, batch:    26/  187, ite: 2927] train loss: 0.569731, tar: 0.072311 
l0: 0.076250, l1: 0.079411, l2: 0.085073, l3: 0.080879, l4: 0.080673, l5: 0.073368, l6: 0.080298

[epoch:  32/100000, batch:    28/  187, ite: 2928] train loss: 0.569717, tar: 0.072315 
l0: 0.040909, l1: 0.043257, l2: 0.049698, l3: 0.046744, l4: 0.055030, l5: 0.064607, l6: 0.063633

[epoch:  32/100000, batch:    30/  187, ite: 2929] train loss: 0.569495, tar: 0.072281 
l0: 0.080586, l1: 0.106614, l2: 0.077662, l3: 0.081074, l4: 0.081354, l5: 0.065982, l6: 0.074397

[epoch:  32/100000, batch:    32/  187, ite: 2930] train loss: 0.569493, tar: 0.072290 
l0: 0.064328, l1: 0.063227, l2: 0.064285, l3: 0.075311, l4: 0.102655, l5: 0.105865, l6: 0.094538

[epoch:  32/100000, batch:    34/  187, ite: 2931] train loss: 0.569494, tar: 0.072282 
l0: 0.059046, l1: 0.055912, l2: 0.064741, l3: 0.071981, l4: 0.073848, l5: 0.074055, l6: 0.066291

[epoch:  32/100000, batch:    36/  187, ite: 2932] train loss: 0.569383, tar: 0.072267 
l0: 0.075771, l1: 0.067339, l2: 0.085863, l3: 0.094680, l4: 0.085806, l5: 0.099033, l6: 0.090595

[epoch:  32/100000, batch:    38/  187, ite: 2933] train loss: 0.569415, tar: 0.072271 
l0: 0.045281, l1: 0.041652, l2: 0.044835, l3: 0.049038, l4: 0.044693, l5: 0.057114, l6: 0.071980

[epoch:  32/100000, batch:    40/  187, ite: 2934] train loss: 0.569185, tar: 0.072242 
l0: 0.059983, l1: 0.060652, l2: 0.056521, l3: 0.061493, l4: 0.081968, l5: 0.085325, l6: 0.074691

[epoch:  32/100000, batch:    42/  187, ite: 2935] train loss: 0.569090, tar: 0.072229 
l0: 0.068172, l1: 0.062402, l2: 0.088624, l3: 0.088269, l4: 0.074713, l5: 0.086085, l6: 0.097295

[epoch:  32/100000, batch:    44/  187, ite: 2936] train loss: 0.569086, tar: 0.072225 
l0: 0.037901, l1: 0.047754, l2: 0.054406, l3: 0.050202, l4: 0.060475, l5: 0.045694, l6: 0.041999

[epoch:  32/100000, batch:    46/  187, ite: 2937] train loss: 0.568840, tar: 0.072188 
l0: 0.069685, l1: 0.072344, l2: 0.084050, l3: 0.077273, l4: 0.087481, l5: 0.082139, l6: 0.087050

[epoch:  32/100000, batch:    48/  187, ite: 2938] train loss: 0.568830, tar: 0.072185 
l0: 0.073683, l1: 0.080496, l2: 0.083535, l3: 0.078476, l4: 0.086972, l5: 0.093104, l6: 0.071811

[epoch:  32/100000, batch:    50/  187, ite: 2939] train loss: 0.568830, tar: 0.072187 
l0: 0.038261, l1: 0.031680, l2: 0.046160, l3: 0.053350, l4: 0.084487, l5: 0.061023, l6: 0.063258

[epoch:  32/100000, batch:    52/  187, ite: 2940] train loss: 0.568627, tar: 0.072151 
l0: 0.047592, l1: 0.041403, l2: 0.048166, l3: 0.049423, l4: 0.051506, l5: 0.062343, l6: 0.081962

[epoch:  32/100000, batch:    54/  187, ite: 2941] train loss: 0.568429, tar: 0.072125 
l0: 0.056807, l1: 0.047555, l2: 0.057273, l3: 0.062189, l4: 0.072496, l5: 0.073145, l6: 0.083277

[epoch:  32/100000, batch:    56/  187, ite: 2942] train loss: 0.568306, tar: 0.072109 
l0: 0.041827, l1: 0.037199, l2: 0.045585, l3: 0.052561, l4: 0.064874, l5: 0.070258, l6: 0.070247

[epoch:  32/100000, batch:    58/  187, ite: 2943] train loss: 0.568109, tar: 0.072076 
l0: 0.067183, l1: 0.065051, l2: 0.074891, l3: 0.073649, l4: 0.085008, l5: 0.085362, l6: 0.087564

[epoch:  32/100000, batch:    60/  187, ite: 2944] train loss: 0.568078, tar: 0.072071 
l0: 0.042466, l1: 0.050497, l2: 0.036704, l3: 0.037653, l4: 0.047120, l5: 0.050148, l6: 0.042966

[epoch:  32/100000, batch:    62/  187, ite: 2945] train loss: 0.567802, tar: 0.072040 
l0: 0.075109, l1: 0.077071, l2: 0.076897, l3: 0.068724, l4: 0.080269, l5: 0.081973, l6: 0.092505

[epoch:  32/100000, batch:    64/  187, ite: 2946] train loss: 0.567786, tar: 0.072043 
l0: 0.077370, l1: 0.085901, l2: 0.067649, l3: 0.070764, l4: 0.086065, l5: 0.081340, l6: 0.091584

[epoch:  32/100000, batch:    66/  187, ite: 2947] train loss: 0.567779, tar: 0.072049 
l0: 0.098466, l1: 0.112478, l2: 0.087078, l3: 0.092918, l4: 0.089704, l5: 0.090372, l6: 0.118707

[epoch:  32/100000, batch:    68/  187, ite: 2948] train loss: 0.567907, tar: 0.072077 
l0: 0.029705, l1: 0.027133, l2: 0.035857, l3: 0.048531, l4: 0.051491, l5: 0.048684, l6: 0.048117

[epoch:  32/100000, batch:    70/  187, ite: 2949] train loss: 0.567614, tar: 0.072032 
l0: 0.084499, l1: 0.090190, l2: 0.103869, l3: 0.092664, l4: 0.083371, l5: 0.084450, l6: 0.081589

[epoch:  32/100000, batch:    72/  187, ite: 2950] train loss: 0.567670, tar: 0.072045 
l0: 0.045939, l1: 0.040248, l2: 0.050340, l3: 0.050744, l4: 0.052443, l5: 0.057069, l6: 0.059652

[epoch:  32/100000, batch:    74/  187, ite: 2951] train loss: 0.567448, tar: 0.072018 
l0: 0.066031, l1: 0.062376, l2: 0.061058, l3: 0.060616, l4: 0.071341, l5: 0.090251, l6: 0.102570

[epoch:  32/100000, batch:    76/  187, ite: 2952] train loss: 0.567392, tar: 0.072011 
l0: 0.064471, l1: 0.063180, l2: 0.079546, l3: 0.068529, l4: 0.091127, l5: 0.103624, l6: 0.090128

[epoch:  32/100000, batch:    78/  187, ite: 2953] train loss: 0.567385, tar: 0.072004 
l0: 0.042898, l1: 0.042951, l2: 0.050434, l3: 0.049468, l4: 0.063294, l5: 0.068614, l6: 0.065982

[epoch:  32/100000, batch:    80/  187, ite: 2954] train loss: 0.567192, tar: 0.071973 
l0: 0.039821, l1: 0.041893, l2: 0.057641, l3: 0.053337, l4: 0.057135, l5: 0.059018, l6: 0.058321

[epoch:  32/100000, batch:    82/  187, ite: 2955] train loss: 0.566983, tar: 0.071939 
l0: 0.068041, l1: 0.065082, l2: 0.081492, l3: 0.083470, l4: 0.071831, l5: 0.083642, l6: 0.075316

[epoch:  32/100000, batch:    84/  187, ite: 2956] train loss: 0.566943, tar: 0.071935 
l0: 0.078825, l1: 0.074639, l2: 0.090399, l3: 0.089355, l4: 0.094051, l5: 0.098274, l6: 0.098207

[epoch:  32/100000, batch:    86/  187, ite: 2957] train loss: 0.567002, tar: 0.071942 
l0: 0.117737, l1: 0.128158, l2: 0.134364, l3: 0.142542, l4: 0.135858, l5: 0.139527, l6: 0.117401

[epoch:  32/100000, batch:    88/  187, ite: 2958] train loss: 0.567366, tar: 0.071990 
l0: 0.047064, l1: 0.049335, l2: 0.058909, l3: 0.058603, l4: 0.049979, l5: 0.059337, l6: 0.054428

[epoch:  32/100000, batch:    90/  187, ite: 2959] train loss: 0.567168, tar: 0.071964 
l0: 0.058582, l1: 0.059328, l2: 0.067849, l3: 0.073126, l4: 0.057668, l5: 0.056647, l6: 0.064766

[epoch:  32/100000, batch:    92/  187, ite: 2960] train loss: 0.567034, tar: 0.071950 
l0: 0.072315, l1: 0.062671, l2: 0.085402, l3: 0.094626, l4: 0.099389, l5: 0.102282, l6: 0.107227

[epoch:  32/100000, batch:    94/  187, ite: 2961] train loss: 0.567093, tar: 0.071951 
l0: 0.060361, l1: 0.054451, l2: 0.065480, l3: 0.068854, l4: 0.082917, l5: 0.089469, l6: 0.070726

[epoch:  32/100000, batch:    96/  187, ite: 2962] train loss: 0.567015, tar: 0.071939 
l0: 0.071918, l1: 0.076750, l2: 0.059673, l3: 0.063664, l4: 0.073173, l5: 0.067705, l6: 0.086259

[epoch:  32/100000, batch:    98/  187, ite: 2963] train loss: 0.566945, tar: 0.071939 
l0: 0.077743, l1: 0.093550, l2: 0.088765, l3: 0.080631, l4: 0.078346, l5: 0.064101, l6: 0.067574

[epoch:  32/100000, batch:   100/  187, ite: 2964] train loss: 0.566928, tar: 0.071945 
l0: 0.058000, l1: 0.055781, l2: 0.062580, l3: 0.065073, l4: 0.070789, l5: 0.065671, l6: 0.071864

[epoch:  32/100000, batch:   102/  187, ite: 2965] train loss: 0.566806, tar: 0.071930 
l0: 0.090386, l1: 0.096068, l2: 0.086586, l3: 0.091425, l4: 0.113253, l5: 0.115111, l6: 0.118340

[epoch:  32/100000, batch:   104/  187, ite: 2966] train loss: 0.566956, tar: 0.071949 
l0: 0.070133, l1: 0.064532, l2: 0.073714, l3: 0.071364, l4: 0.080579, l5: 0.085696, l6: 0.079982

[epoch:  32/100000, batch:   106/  187, ite: 2967] train loss: 0.566913, tar: 0.071947 
l0: 0.044545, l1: 0.042823, l2: 0.047182, l3: 0.050046, l4: 0.055601, l5: 0.060165, l6: 0.056774

[epoch:  32/100000, batch:   108/  187, ite: 2968] train loss: 0.566697, tar: 0.071919 
l0: 0.056840, l1: 0.056244, l2: 0.071710, l3: 0.066478, l4: 0.064955, l5: 0.075584, l6: 0.086168

[epoch:  32/100000, batch:   110/  187, ite: 2969] train loss: 0.566605, tar: 0.071904 
l0: 0.064515, l1: 0.063328, l2: 0.063132, l3: 0.069430, l4: 0.102531, l5: 0.089193, l6: 0.099657

[epoch:  32/100000, batch:   112/  187, ite: 2970] train loss: 0.566590, tar: 0.071896 
l0: 0.059796, l1: 0.054361, l2: 0.074305, l3: 0.073823, l4: 0.106708, l5: 0.104271, l6: 0.085861

[epoch:  32/100000, batch:   114/  187, ite: 2971] train loss: 0.566582, tar: 0.071884 
l0: 0.057278, l1: 0.056524, l2: 0.052539, l3: 0.055207, l4: 0.053335, l5: 0.062646, l6: 0.059830

[epoch:  32/100000, batch:   116/  187, ite: 2972] train loss: 0.566408, tar: 0.071868 
l0: 0.052406, l1: 0.055725, l2: 0.055859, l3: 0.062857, l4: 0.051866, l5: 0.062211, l6: 0.054868

[epoch:  32/100000, batch:   118/  187, ite: 2973] train loss: 0.566233, tar: 0.071848 
l0: 0.049241, l1: 0.043164, l2: 0.048587, l3: 0.056562, l4: 0.070433, l5: 0.078223, l6: 0.088489

[epoch:  32/100000, batch:   120/  187, ite: 2974] train loss: 0.566098, tar: 0.071825 
l0: 0.068180, l1: 0.059665, l2: 0.084877, l3: 0.102892, l4: 0.079139, l5: 0.096199, l6: 0.074192

[epoch:  32/100000, batch:   122/  187, ite: 2975] train loss: 0.566097, tar: 0.071822 
l0: 0.052305, l1: 0.055516, l2: 0.057389, l3: 0.060545, l4: 0.063814, l5: 0.059293, l6: 0.054130

[epoch:  32/100000, batch:   124/  187, ite: 2976] train loss: 0.565930, tar: 0.071802 
l0: 0.037767, l1: 0.047290, l2: 0.046519, l3: 0.048623, l4: 0.060617, l5: 0.051426, l6: 0.054429

[epoch:  32/100000, batch:   126/  187, ite: 2977] train loss: 0.565705, tar: 0.071767 
l0: 0.061645, l1: 0.060030, l2: 0.070340, l3: 0.075149, l4: 0.081415, l5: 0.086393, l6: 0.075816

[epoch:  32/100000, batch:   128/  187, ite: 2978] train loss: 0.565649, tar: 0.071756 
l0: 0.064598, l1: 0.068996, l2: 0.075966, l3: 0.066331, l4: 0.076569, l5: 0.083201, l6: 0.081190

[epoch:  32/100000, batch:   130/  187, ite: 2979] train loss: 0.565599, tar: 0.071749 
l0: 0.072861, l1: 0.081049, l2: 0.068240, l3: 0.065485, l4: 0.089709, l5: 0.074555, l6: 0.082256

[epoch:  32/100000, batch:   132/  187, ite: 2980] train loss: 0.565567, tar: 0.071750 
l0: 0.030341, l1: 0.034420, l2: 0.033302, l3: 0.033043, l4: 0.033673, l5: 0.035065, l6: 0.036006

[epoch:  32/100000, batch:   134/  187, ite: 2981] train loss: 0.565231, tar: 0.071708 
l0: 0.070965, l1: 0.083433, l2: 0.081996, l3: 0.080751, l4: 0.079224, l5: 0.077688, l6: 0.079006

[epoch:  32/100000, batch:   136/  187, ite: 2982] train loss: 0.565219, tar: 0.071707 
l0: 0.073750, l1: 0.085900, l2: 0.079999, l3: 0.070655, l4: 0.096399, l5: 0.084879, l6: 0.104784

[epoch:  32/100000, batch:   138/  187, ite: 2983] train loss: 0.565250, tar: 0.071709 
l0: 0.043701, l1: 0.035891, l2: 0.064105, l3: 0.069250, l4: 0.066977, l5: 0.066840, l6: 0.068842

[epoch:  32/100000, batch:   140/  187, ite: 2984] train loss: 0.565098, tar: 0.071681 
l0: 0.042877, l1: 0.036901, l2: 0.050576, l3: 0.054984, l4: 0.064707, l5: 0.076143, l6: 0.067122

[epoch:  32/100000, batch:   142/  187, ite: 2985] train loss: 0.564924, tar: 0.071652 
l0: 0.043691, l1: 0.040058, l2: 0.037723, l3: 0.039503, l4: 0.063103, l5: 0.066970, l6: 0.070045

[epoch:  32/100000, batch:   144/  187, ite: 2986] train loss: 0.564717, tar: 0.071623 
l0: 0.087411, l1: 0.076146, l2: 0.085040, l3: 0.081370, l4: 0.111165, l5: 0.129506, l6: 0.165618

[epoch:  32/100000, batch:   146/  187, ite: 2987] train loss: 0.564891, tar: 0.071639 
l0: 0.053488, l1: 0.046741, l2: 0.045752, l3: 0.055869, l4: 0.077803, l5: 0.067839, l6: 0.083242

[epoch:  32/100000, batch:   148/  187, ite: 2988] train loss: 0.564755, tar: 0.071621 
l0: 0.062331, l1: 0.067232, l2: 0.070744, l3: 0.058440, l4: 0.067952, l5: 0.085177, l6: 0.076181

[epoch:  32/100000, batch:   150/  187, ite: 2989] train loss: 0.564677, tar: 0.071611 
l0: 0.040063, l1: 0.038441, l2: 0.043531, l3: 0.043242, l4: 0.047640, l5: 0.055568, l6: 0.058585

[epoch:  32/100000, batch:   152/  187, ite: 2990] train loss: 0.564437, tar: 0.071580 
l0: 0.057326, l1: 0.057631, l2: 0.056450, l3: 0.058720, l4: 0.064606, l5: 0.063816, l6: 0.064589

[epoch:  32/100000, batch:   154/  187, ite: 2991] train loss: 0.564295, tar: 0.071565 
l0: 0.049441, l1: 0.046974, l2: 0.048526, l3: 0.050146, l4: 0.064140, l5: 0.059240, l6: 0.059740

[epoch:  32/100000, batch:   156/  187, ite: 2992] train loss: 0.564107, tar: 0.071543 
l0: 0.062965, l1: 0.061784, l2: 0.073349, l3: 0.069748, l4: 0.088918, l5: 0.088759, l6: 0.088468

[epoch:  32/100000, batch:   158/  187, ite: 2993] train loss: 0.564077, tar: 0.071534 
l0: 0.053051, l1: 0.044020, l2: 0.075148, l3: 0.083960, l4: 0.072022, l5: 0.084655, l6: 0.108175

[epoch:  32/100000, batch:   160/  187, ite: 2994] train loss: 0.564034, tar: 0.071516 
l0: 0.027067, l1: 0.027104, l2: 0.027695, l3: 0.034252, l4: 0.039671, l5: 0.041258, l6: 0.035630

[epoch:  32/100000, batch:   162/  187, ite: 2995] train loss: 0.563701, tar: 0.071471 
l0: 0.031115, l1: 0.030327, l2: 0.041808, l3: 0.042023, l4: 0.042456, l5: 0.035768, l6: 0.033001

[epoch:  32/100000, batch:   164/  187, ite: 2996] train loss: 0.563392, tar: 0.071430 
l0: 0.065435, l1: 0.054895, l2: 0.072695, l3: 0.067493, l4: 0.073423, l5: 0.103755, l6: 0.105376

[epoch:  32/100000, batch:   166/  187, ite: 2997] train loss: 0.563372, tar: 0.071424 
l0: 0.039194, l1: 0.037779, l2: 0.042351, l3: 0.042500, l4: 0.051175, l5: 0.059496, l6: 0.055467

[epoch:  32/100000, batch:   168/  187, ite: 2998] train loss: 0.563136, tar: 0.071392 
l0: 0.040704, l1: 0.035261, l2: 0.045495, l3: 0.053621, l4: 0.075641, l5: 0.072623, l6: 0.067760

[epoch:  32/100000, batch:   170/  187, ite: 2999] train loss: 0.562964, tar: 0.071361 
l0: 0.069572, l1: 0.076269, l2: 0.063898, l3: 0.065799, l4: 0.087256, l5: 0.088125, l6: 0.097382

[epoch:  32/100000, batch:   172/  187, ite: 3000] train loss: 0.562949, tar: 0.071360 
l0: 0.042265, l1: 0.045578, l2: 0.052521, l3: 0.059386, l4: 0.058798, l5: 0.052794, l6: 0.069703

[epoch:  32/100000, batch:   174/  187, ite: 3001] train loss: 0.562767, tar: 0.071331 
l0: 0.065305, l1: 0.060507, l2: 0.078770, l3: 0.081170, l4: 0.110289, l5: 0.109395, l6: 0.096834

[epoch:  32/100000, batch:   176/  187, ite: 3002] train loss: 0.562807, tar: 0.071325 
l0: 0.078559, l1: 0.091771, l2: 0.080526, l3: 0.088687, l4: 0.108742, l5: 0.099278, l6: 0.099122

[epoch:  32/100000, batch:   178/  187, ite: 3003] train loss: 0.562890, tar: 0.071332 
l0: 0.047905, l1: 0.045486, l2: 0.057154, l3: 0.057291, l4: 0.083814, l5: 0.101394, l6: 0.088413

[epoch:  32/100000, batch:   180/  187, ite: 3004] train loss: 0.562809, tar: 0.071308 
l0: 0.060803, l1: 0.049171, l2: 0.084271, l3: 0.091818, l4: 0.119760, l5: 0.106207, l6: 0.088242

[epoch:  32/100000, batch:   182/  187, ite: 3005] train loss: 0.562847, tar: 0.071298 
l0: 0.038326, l1: 0.042825, l2: 0.049866, l3: 0.048495, l4: 0.055158, l5: 0.047079, l6: 0.045760

[epoch:  32/100000, batch:   184/  187, ite: 3006] train loss: 0.562613, tar: 0.071265 
l0: 0.035870, l1: 0.034632, l2: 0.051597, l3: 0.051708, l4: 0.059647, l5: 0.060532, l6: 0.058026

[epoch:  32/100000, batch:   186/  187, ite: 3007] train loss: 0.562404, tar: 0.071230 
l0: 0.025607, l1: 0.027340, l2: 0.051157, l3: 0.046764, l4: 0.065825, l5: 0.063917, l6: 0.045666

[epoch:  32/100000, batch:   188/  187, ite: 3008] train loss: 0.562169, tar: 0.071185 
l0: 0.052369, l1: 0.046334, l2: 0.060845, l3: 0.068706, l4: 0.111630, l5: 0.102930, l6: 0.112208

[epoch:  33/100000, batch:     2/  187, ite: 3009] train loss: 0.562162, tar: 0.071166 
l0: 0.071900, l1: 0.063671, l2: 0.061619, l3: 0.068297, l4: 0.084503, l5: 0.116376, l6: 0.124159

[epoch:  33/100000, batch:     4/  187, ite: 3010] train loss: 0.562190, tar: 0.071167 
l0: 0.050017, l1: 0.045114, l2: 0.052517, l3: 0.052563, l4: 0.097102, l5: 0.099453, l6: 0.082787

[epoch:  33/100000, batch:     6/  187, ite: 3011] train loss: 0.562109, tar: 0.071146 
l0: 0.064682, l1: 0.057114, l2: 0.098486, l3: 0.104030, l4: 0.090381, l5: 0.094527, l6: 0.089927

[epoch:  33/100000, batch:     8/  187, ite: 3012] train loss: 0.562145, tar: 0.071140 
l0: 0.046381, l1: 0.048362, l2: 0.050825, l3: 0.046819, l4: 0.056590, l5: 0.060556, l6: 0.053637

[epoch:  33/100000, batch:    10/  187, ite: 3013] train loss: 0.561949, tar: 0.071115 
l0: 0.059193, l1: 0.060054, l2: 0.065433, l3: 0.069905, l4: 0.079685, l5: 0.083594, l6: 0.073522

[epoch:  33/100000, batch:    12/  187, ite: 3014] train loss: 0.561879, tar: 0.071103 
l0: 0.029703, l1: 0.032890, l2: 0.031407, l3: 0.033642, l4: 0.054324, l5: 0.062127, l6: 0.067395

[epoch:  33/100000, batch:    14/  187, ite: 3015] train loss: 0.561632, tar: 0.071063 
l0: 0.033284, l1: 0.038499, l2: 0.035743, l3: 0.039675, l4: 0.038296, l5: 0.050249, l6: 0.080835

[epoch:  33/100000, batch:    16/  187, ite: 3016] train loss: 0.561391, tar: 0.071025 
l0: 0.043662, l1: 0.045693, l2: 0.040980, l3: 0.047043, l4: 0.056721, l5: 0.066049, l6: 0.066012

[epoch:  33/100000, batch:    18/  187, ite: 3017] train loss: 0.561199, tar: 0.070999 
l0: 0.054430, l1: 0.055935, l2: 0.060849, l3: 0.062842, l4: 0.071192, l5: 0.070267, l6: 0.068004

[epoch:  33/100000, batch:    20/  187, ite: 3018] train loss: 0.561084, tar: 0.070982 
l0: 0.041547, l1: 0.040466, l2: 0.047308, l3: 0.049191, l4: 0.085820, l5: 0.086656, l6: 0.089944

[epoch:  33/100000, batch:    22/  187, ite: 3019] train loss: 0.560966, tar: 0.070953 
l0: 0.050851, l1: 0.051003, l2: 0.046090, l3: 0.042243, l4: 0.066839, l5: 0.079092, l6: 0.076935

[epoch:  33/100000, batch:    24/  187, ite: 3020] train loss: 0.560821, tar: 0.070934 
l0: 0.061826, l1: 0.064884, l2: 0.083143, l3: 0.077045, l4: 0.081302, l5: 0.074109, l6: 0.076226

[epoch:  33/100000, batch:    26/  187, ite: 3021] train loss: 0.560779, tar: 0.070925 
l0: 0.077040, l1: 0.080009, l2: 0.086305, l3: 0.094145, l4: 0.096117, l5: 0.101366, l6: 0.112048

[epoch:  33/100000, batch:    28/  187, ite: 3022] train loss: 0.560864, tar: 0.070931 
l0: 0.031933, l1: 0.037359, l2: 0.027375, l3: 0.033120, l4: 0.036926, l5: 0.039337, l6: 0.031286

[epoch:  33/100000, batch:    30/  187, ite: 3023] train loss: 0.560547, tar: 0.070893 
l0: 0.049257, l1: 0.046364, l2: 0.054721, l3: 0.064906, l4: 0.057515, l5: 0.057510, l6: 0.066627

[epoch:  33/100000, batch:    32/  187, ite: 3024] train loss: 0.560388, tar: 0.070871 
l0: 0.129082, l1: 0.145182, l2: 0.168773, l3: 0.127348, l4: 0.113326, l5: 0.119959, l6: 0.126916

[epoch:  33/100000, batch:    34/  187, ite: 3025] train loss: 0.560749, tar: 0.070928 
l0: 0.032352, l1: 0.034534, l2: 0.032309, l3: 0.036270, l4: 0.052974, l5: 0.051973, l6: 0.051617

[epoch:  33/100000, batch:    36/  187, ite: 3026] train loss: 0.560487, tar: 0.070891 
l0: 0.071061, l1: 0.075087, l2: 0.066162, l3: 0.069968, l4: 0.090254, l5: 0.072805, l6: 0.073416

[epoch:  33/100000, batch:    38/  187, ite: 3027] train loss: 0.560446, tar: 0.070891 
l0: 0.058026, l1: 0.054923, l2: 0.056327, l3: 0.060596, l4: 0.080176, l5: 0.077316, l6: 0.074753

[epoch:  33/100000, batch:    40/  187, ite: 3028] train loss: 0.560351, tar: 0.070878 
l0: 0.072008, l1: 0.074753, l2: 0.062373, l3: 0.065924, l4: 0.099082, l5: 0.082230, l6: 0.089993

[epoch:  33/100000, batch:    42/  187, ite: 3029] train loss: 0.560337, tar: 0.070879 
l0: 0.043236, l1: 0.054406, l2: 0.046680, l3: 0.048204, l4: 0.045803, l5: 0.055109, l6: 0.050063

[epoch:  33/100000, batch:    44/  187, ite: 3030] train loss: 0.560126, tar: 0.070853 
l0: 0.065749, l1: 0.086399, l2: 0.073357, l3: 0.073748, l4: 0.055807, l5: 0.054253, l6: 0.051943

[epoch:  33/100000, batch:    46/  187, ite: 3031] train loss: 0.560031, tar: 0.070848 
l0: 0.089274, l1: 0.100156, l2: 0.092906, l3: 0.100363, l4: 0.081889, l5: 0.077467, l6: 0.073898

[epoch:  33/100000, batch:    48/  187, ite: 3032] train loss: 0.560085, tar: 0.070865 
l0: 0.107255, l1: 0.118775, l2: 0.110935, l3: 0.106250, l4: 0.096560, l5: 0.103913, l6: 0.128845

[epoch:  33/100000, batch:    50/  187, ite: 3033] train loss: 0.560290, tar: 0.070901 
l0: 0.048512, l1: 0.055072, l2: 0.049490, l3: 0.051267, l4: 0.068128, l5: 0.071648, l6: 0.078059

[epoch:  33/100000, batch:    52/  187, ite: 3034] train loss: 0.560157, tar: 0.070879 
l0: 0.065304, l1: 0.064507, l2: 0.074819, l3: 0.076726, l4: 0.093516, l5: 0.085140, l6: 0.099336

[epoch:  33/100000, batch:    54/  187, ite: 3035] train loss: 0.560156, tar: 0.070874 
l0: 0.324875, l1: 0.330151, l2: 0.312909, l3: 0.344061, l4: 0.331867, l5: 0.474136, l6: 0.324570

[epoch:  33/100000, batch:    56/  187, ite: 3036] train loss: 0.561973, tar: 0.071119 
l0: 0.057443, l1: 0.054350, l2: 0.071847, l3: 0.070529, l4: 0.074794, l5: 0.082479, l6: 0.084609

[epoch:  33/100000, batch:    58/  187, ite: 3037] train loss: 0.561910, tar: 0.071106 
l0: 0.072666, l1: 0.074157, l2: 0.089754, l3: 0.078993, l4: 0.075588, l5: 0.085031, l6: 0.126350

[epoch:  33/100000, batch:    60/  187, ite: 3038] train loss: 0.561949, tar: 0.071107 
l0: 0.068148, l1: 0.077857, l2: 0.056929, l3: 0.062249, l4: 0.068540, l5: 0.065587, l6: 0.074775

[epoch:  33/100000, batch:    62/  187, ite: 3039] train loss: 0.561864, tar: 0.071104 
l0: 0.055956, l1: 0.065682, l2: 0.056488, l3: 0.043756, l4: 0.045273, l5: 0.050084, l6: 0.060686

[epoch:  33/100000, batch:    64/  187, ite: 3040] train loss: 0.561687, tar: 0.071090 
l0: 0.048336, l1: 0.052211, l2: 0.064488, l3: 0.060364, l4: 0.070949, l5: 0.060318, l6: 0.061103

[epoch:  33/100000, batch:    66/  187, ite: 3041] train loss: 0.561549, tar: 0.071068 
l0: 0.039517, l1: 0.039892, l2: 0.051101, l3: 0.049115, l4: 0.051098, l5: 0.043227, l6: 0.044648

[epoch:  33/100000, batch:    68/  187, ite: 3042] train loss: 0.561316, tar: 0.071038 
l0: 0.060043, l1: 0.064978, l2: 0.052802, l3: 0.058496, l4: 0.065366, l5: 0.064749, l6: 0.060569

[epoch:  33/100000, batch:    70/  187, ite: 3043] train loss: 0.561187, tar: 0.071027 
l0: 0.059094, l1: 0.066321, l2: 0.066162, l3: 0.066553, l4: 0.078130, l5: 0.072574, l6: 0.077332

[epoch:  33/100000, batch:    72/  187, ite: 3044] train loss: 0.561115, tar: 0.071016 
l0: 0.047556, l1: 0.048842, l2: 0.048955, l3: 0.054586, l4: 0.059581, l5: 0.061712, l6: 0.050085

[epoch:  33/100000, batch:    74/  187, ite: 3045] train loss: 0.560934, tar: 0.070993 
l0: 0.096570, l1: 0.102233, l2: 0.082220, l3: 0.085707, l4: 0.103769, l5: 0.110635, l6: 0.102000

[epoch:  33/100000, batch:    76/  187, ite: 3046] train loss: 0.561050, tar: 0.071018 
l0: 0.089822, l1: 0.082272, l2: 0.100333, l3: 0.107404, l4: 0.136225, l5: 0.129270, l6: 0.102112

[epoch:  33/100000, batch:    78/  187, ite: 3047] train loss: 0.561228, tar: 0.071036 
l0: 0.072258, l1: 0.076370, l2: 0.081746, l3: 0.071663, l4: 0.075566, l5: 0.085416, l6: 0.100062

[epoch:  33/100000, batch:    80/  187, ite: 3048] train loss: 0.561230, tar: 0.071037 
l0: 0.106316, l1: 0.111915, l2: 0.103364, l3: 0.106474, l4: 0.089321, l5: 0.097159, l6: 0.121129

[epoch:  33/100000, batch:    82/  187, ite: 3049] train loss: 0.561396, tar: 0.071070 
l0: 0.065051, l1: 0.055537, l2: 0.070280, l3: 0.080603, l4: 0.092900, l5: 0.089950, l6: 0.081965

[epoch:  33/100000, batch:    84/  187, ite: 3050] train loss: 0.561373, tar: 0.071065 
l0: 0.059968, l1: 0.055390, l2: 0.065522, l3: 0.071355, l4: 0.071897, l5: 0.066127, l6: 0.065353

[epoch:  33/100000, batch:    86/  187, ite: 3051] train loss: 0.561272, tar: 0.071054 
l0: 0.044390, l1: 0.044937, l2: 0.047825, l3: 0.051594, l4: 0.047664, l5: 0.054358, l6: 0.052500

[epoch:  33/100000, batch:    88/  187, ite: 3052] train loss: 0.561065, tar: 0.071029 
l0: 0.058447, l1: 0.052953, l2: 0.064560, l3: 0.064856, l4: 0.066722, l5: 0.080388, l6: 0.079914

[epoch:  33/100000, batch:    90/  187, ite: 3053] train loss: 0.560976, tar: 0.071017 
l0: 0.068418, l1: 0.072235, l2: 0.074465, l3: 0.073809, l4: 0.090435, l5: 0.070257, l6: 0.081677

[epoch:  33/100000, batch:    92/  187, ite: 3054] train loss: 0.560948, tar: 0.071014 
l0: 0.056296, l1: 0.056453, l2: 0.062001, l3: 0.060550, l4: 0.078045, l5: 0.073753, l6: 0.069701

[epoch:  33/100000, batch:    94/  187, ite: 3055] train loss: 0.560849, tar: 0.071000 
l0: 0.056410, l1: 0.055437, l2: 0.055854, l3: 0.064360, l4: 0.056390, l5: 0.064168, l6: 0.081936

[epoch:  33/100000, batch:    96/  187, ite: 3056] train loss: 0.560730, tar: 0.070987 
l0: 0.060302, l1: 0.058485, l2: 0.060257, l3: 0.067234, l4: 0.084945, l5: 0.092503, l6: 0.095826

[epoch:  33/100000, batch:    98/  187, ite: 3057] train loss: 0.560691, tar: 0.070976 
l0: 0.060576, l1: 0.067493, l2: 0.066366, l3: 0.070685, l4: 0.071418, l5: 0.066727, l6: 0.070139

[epoch:  33/100000, batch:   100/  187, ite: 3058] train loss: 0.560608, tar: 0.070967 
l0: 0.047733, l1: 0.043994, l2: 0.051050, l3: 0.051356, l4: 0.061475, l5: 0.064700, l6: 0.068666

[epoch:  33/100000, batch:   102/  187, ite: 3059] train loss: 0.560446, tar: 0.070945 
l0: 0.066155, l1: 0.062819, l2: 0.076819, l3: 0.077950, l4: 0.078617, l5: 0.080487, l6: 0.078380

[epoch:  33/100000, batch:   104/  187, ite: 3060] train loss: 0.560409, tar: 0.070940 
l0: 0.059639, l1: 0.049962, l2: 0.064111, l3: 0.064766, l4: 0.066584, l5: 0.072839, l6: 0.088745

[epoch:  33/100000, batch:   106/  187, ite: 3061] train loss: 0.560321, tar: 0.070930 
l0: 0.063816, l1: 0.063902, l2: 0.075397, l3: 0.067616, l4: 0.066820, l5: 0.073060, l6: 0.060322

[epoch:  33/100000, batch:   108/  187, ite: 3062] train loss: 0.560237, tar: 0.070923 
l0: 0.044156, l1: 0.046519, l2: 0.049391, l3: 0.058679, l4: 0.072446, l5: 0.075568, l6: 0.072746

[epoch:  33/100000, batch:   110/  187, ite: 3063] train loss: 0.560104, tar: 0.070898 
l0: 0.070818, l1: 0.069381, l2: 0.081426, l3: 0.081257, l4: 0.093310, l5: 0.110276, l6: 0.095041

[epoch:  33/100000, batch:   112/  187, ite: 3064] train loss: 0.560143, tar: 0.070898 
l0: 0.098655, l1: 0.095689, l2: 0.116858, l3: 0.112323, l4: 0.149606, l5: 0.150962, l6: 0.111014

[epoch:  33/100000, batch:   114/  187, ite: 3065] train loss: 0.560401, tar: 0.070924 
l0: 0.051922, l1: 0.043635, l2: 0.050854, l3: 0.063432, l4: 0.072284, l5: 0.073287, l6: 0.072235

[epoch:  33/100000, batch:   116/  187, ite: 3066] train loss: 0.560277, tar: 0.070906 
l0: 0.060440, l1: 0.054443, l2: 0.068208, l3: 0.068456, l4: 0.092864, l5: 0.103530, l6: 0.096959

[epoch:  33/100000, batch:   118/  187, ite: 3067] train loss: 0.560262, tar: 0.070896 
l0: 0.071562, l1: 0.066279, l2: 0.077799, l3: 0.100124, l4: 0.091924, l5: 0.064971, l6: 0.077318

[epoch:  33/100000, batch:   120/  187, ite: 3068] train loss: 0.560253, tar: 0.070897 
l0: 0.034722, l1: 0.031726, l2: 0.061147, l3: 0.048286, l4: 0.067554, l5: 0.083628, l6: 0.072492

[epoch:  33/100000, batch:   122/  187, ite: 3069] train loss: 0.560102, tar: 0.070863 
l0: 0.048987, l1: 0.048283, l2: 0.059270, l3: 0.065920, l4: 0.084333, l5: 0.068792, l6: 0.069843

[epoch:  33/100000, batch:   124/  187, ite: 3070] train loss: 0.559995, tar: 0.070842 
l0: 0.062046, l1: 0.064145, l2: 0.066615, l3: 0.065640, l4: 0.062933, l5: 0.066688, l6: 0.063661

[epoch:  33/100000, batch:   126/  187, ite: 3071] train loss: 0.559894, tar: 0.070834 
l0: 0.042639, l1: 0.049942, l2: 0.043169, l3: 0.035388, l4: 0.049115, l5: 0.050611, l6: 0.046337

[epoch:  33/100000, batch:   128/  187, ite: 3072] train loss: 0.559668, tar: 0.070808 
l0: 0.106040, l1: 0.114589, l2: 0.110539, l3: 0.099751, l4: 0.126243, l5: 0.126439, l6: 0.133959

[epoch:  33/100000, batch:   130/  187, ite: 3073] train loss: 0.559908, tar: 0.070841 
l0: 0.062483, l1: 0.073770, l2: 0.055757, l3: 0.056263, l4: 0.065194, l5: 0.073106, l6: 0.080033

[epoch:  33/100000, batch:   132/  187, ite: 3074] train loss: 0.559821, tar: 0.070833 
l0: 0.052547, l1: 0.056607, l2: 0.052333, l3: 0.059897, l4: 0.098434, l5: 0.082311, l6: 0.091126

[epoch:  33/100000, batch:   134/  187, ite: 3075] train loss: 0.559759, tar: 0.070816 
l0: 0.060194, l1: 0.073107, l2: 0.069390, l3: 0.066683, l4: 0.062588, l5: 0.060947, l6: 0.060554

[epoch:  33/100000, batch:   136/  187, ite: 3076] train loss: 0.559661, tar: 0.070806 
l0: 0.048418, l1: 0.047848, l2: 0.049120, l3: 0.047486, l4: 0.089820, l5: 0.086010, l6: 0.090544

[epoch:  33/100000, batch:   138/  187, ite: 3077] train loss: 0.559567, tar: 0.070785 
l0: 0.103348, l1: 0.113953, l2: 0.125274, l3: 0.110361, l4: 0.115669, l5: 0.101649, l6: 0.115705

[epoch:  33/100000, batch:   140/  187, ite: 3078] train loss: 0.559777, tar: 0.070815 
l0: 0.072144, l1: 0.066602, l2: 0.088326, l3: 0.092202, l4: 0.099302, l5: 0.105277, l6: 0.092629

[epoch:  33/100000, batch:   142/  187, ite: 3079] train loss: 0.559830, tar: 0.070817 
l0: 0.061390, l1: 0.057398, l2: 0.065139, l3: 0.065889, l4: 0.094037, l5: 0.096152, l6: 0.107667

[epoch:  33/100000, batch:   144/  187, ite: 3080] train loss: 0.559819, tar: 0.070808 
l0: 0.055511, l1: 0.045466, l2: 0.057230, l3: 0.070485, l4: 0.077918, l5: 0.099006, l6: 0.091620

[epoch:  33/100000, batch:   146/  187, ite: 3081] train loss: 0.559761, tar: 0.070794 
l0: 0.044550, l1: 0.050290, l2: 0.044315, l3: 0.049401, l4: 0.056264, l5: 0.056055, l6: 0.064385

[epoch:  33/100000, batch:   148/  187, ite: 3082] train loss: 0.559581, tar: 0.070770 
l0: 0.053332, l1: 0.055969, l2: 0.050015, l3: 0.060582, l4: 0.069395, l5: 0.066832, l6: 0.063908

[epoch:  33/100000, batch:   150/  187, ite: 3083] train loss: 0.559452, tar: 0.070753 
l0: 0.041953, l1: 0.042951, l2: 0.054390, l3: 0.059636, l4: 0.069943, l5: 0.058674, l6: 0.063513

[epoch:  33/100000, batch:   152/  187, ite: 3084] train loss: 0.559297, tar: 0.070727 
l0: 0.039529, l1: 0.050373, l2: 0.038308, l3: 0.033893, l4: 0.058620, l5: 0.062885, l6: 0.060423

[epoch:  33/100000, batch:   154/  187, ite: 3085] train loss: 0.559098, tar: 0.070698 
l0: 0.027921, l1: 0.030025, l2: 0.044204, l3: 0.040286, l4: 0.057052, l5: 0.057770, l6: 0.060161

[epoch:  33/100000, batch:   156/  187, ite: 3086] train loss: 0.558876, tar: 0.070659 
l0: 0.042126, l1: 0.043410, l2: 0.053103, l3: 0.051212, l4: 0.056979, l5: 0.055479, l6: 0.052738

[epoch:  33/100000, batch:   158/  187, ite: 3087] train loss: 0.558688, tar: 0.070632 
l0: 0.047536, l1: 0.043766, l2: 0.068502, l3: 0.079411, l4: 0.087685, l5: 0.083267, l6: 0.079994

[epoch:  33/100000, batch:   160/  187, ite: 3088] train loss: 0.558625, tar: 0.070611 
l0: 0.068118, l1: 0.067977, l2: 0.069540, l3: 0.071958, l4: 0.081527, l5: 0.091468, l6: 0.097255

[epoch:  33/100000, batch:   162/  187, ite: 3089] train loss: 0.558615, tar: 0.070609 
l0: 0.059646, l1: 0.067243, l2: 0.068434, l3: 0.063302, l4: 0.058727, l5: 0.060024, l6: 0.063278

[epoch:  33/100000, batch:   164/  187, ite: 3090] train loss: 0.558507, tar: 0.070599 
l0: 0.062538, l1: 0.058954, l2: 0.071828, l3: 0.071925, l4: 0.067125, l5: 0.066944, l6: 0.086297

[epoch:  33/100000, batch:   166/  187, ite: 3091] train loss: 0.558440, tar: 0.070591 
l0: 0.046888, l1: 0.042928, l2: 0.047786, l3: 0.049201, l4: 0.072688, l5: 0.074091, l6: 0.069349

[epoch:  33/100000, batch:   168/  187, ite: 3092] train loss: 0.558298, tar: 0.070570 
l0: 0.028539, l1: 0.027021, l2: 0.042372, l3: 0.041747, l4: 0.048511, l5: 0.041969, l6: 0.042082

[epoch:  33/100000, batch:   170/  187, ite: 3093] train loss: 0.558036, tar: 0.070531 
l0: 0.059152, l1: 0.055276, l2: 0.055586, l3: 0.052609, l4: 0.073101, l5: 0.101005, l6: 0.076710

[epoch:  33/100000, batch:   172/  187, ite: 3094] train loss: 0.557959, tar: 0.070521 
l0: 0.026080, l1: 0.023505, l2: 0.030394, l3: 0.030631, l4: 0.041978, l5: 0.053762, l6: 0.043210

[epoch:  33/100000, batch:   174/  187, ite: 3095] train loss: 0.557677, tar: 0.070480 
l0: 0.102073, l1: 0.115309, l2: 0.097950, l3: 0.092227, l4: 0.098135, l5: 0.101157, l6: 0.109485

[epoch:  33/100000, batch:   176/  187, ite: 3096] train loss: 0.557822, tar: 0.070509 
l0: 0.065527, l1: 0.070434, l2: 0.071362, l3: 0.064447, l4: 0.084957, l5: 0.084758, l6: 0.092101

[epoch:  33/100000, batch:   178/  187, ite: 3097] train loss: 0.557800, tar: 0.070505 
l0: 0.055855, l1: 0.059010, l2: 0.058136, l3: 0.054035, l4: 0.077239, l5: 0.079223, l6: 0.066809

[epoch:  33/100000, batch:   180/  187, ite: 3098] train loss: 0.557702, tar: 0.070491 
l0: 0.066287, l1: 0.062484, l2: 0.090769, l3: 0.079005, l4: 0.080102, l5: 0.078397, l6: 0.072998

[epoch:  33/100000, batch:   182/  187, ite: 3099] train loss: 0.557677, tar: 0.070487 
l0: 0.099233, l1: 0.107415, l2: 0.118501, l3: 0.116626, l4: 0.107213, l5: 0.093992, l6: 0.104386

[epoch:  33/100000, batch:   184/  187, ite: 3100] train loss: 0.557849, tar: 0.070514 
l0: 0.059556, l1: 0.048432, l2: 0.075864, l3: 0.073619, l4: 0.081886, l5: 0.091469, l6: 0.102908

[epoch:  33/100000, batch:   186/  187, ite: 3101] train loss: 0.557827, tar: 0.070504 
l0: 0.052405, l1: 0.046967, l2: 0.059528, l3: 0.049279, l4: 0.087451, l5: 0.092355, l6: 0.095591

[epoch:  33/100000, batch:   188/  187, ite: 3102] train loss: 0.557760, tar: 0.070487 
l0: 0.059621, l1: 0.077157, l2: 0.050764, l3: 0.052966, l4: 0.044511, l5: 0.042212, l6: 0.041961

[epoch:  34/100000, batch:     2/  187, ite: 3103] train loss: 0.557589, tar: 0.070477 
l0: 0.071594, l1: 0.066663, l2: 0.069113, l3: 0.073506, l4: 0.083381, l5: 0.089422, l6: 0.092633

[epoch:  34/100000, batch:     4/  187, ite: 3104] train loss: 0.557579, tar: 0.070478 
l0: 0.047162, l1: 0.042602, l2: 0.058772, l3: 0.059658, l4: 0.058671, l5: 0.060092, l6: 0.073782

[epoch:  34/100000, batch:     6/  187, ite: 3105] train loss: 0.557437, tar: 0.070457 
l0: 0.061032, l1: 0.060253, l2: 0.057729, l3: 0.068784, l4: 0.100079, l5: 0.115035, l6: 0.117282

[epoch:  34/100000, batch:     8/  187, ite: 3106] train loss: 0.557458, tar: 0.070449 
l0: 0.053481, l1: 0.052192, l2: 0.065765, l3: 0.075370, l4: 0.084497, l5: 0.081928, l6: 0.091206

[epoch:  34/100000, batch:    10/  187, ite: 3107] train loss: 0.557410, tar: 0.070433 
l0: 0.049600, l1: 0.046479, l2: 0.058212, l3: 0.063535, l4: 0.056491, l5: 0.066354, l6: 0.067435

[epoch:  34/100000, batch:    12/  187, ite: 3108] train loss: 0.557275, tar: 0.070415 
l0: 0.083338, l1: 0.087291, l2: 0.088773, l3: 0.092270, l4: 0.083497, l5: 0.095272, l6: 0.114704

[epoch:  34/100000, batch:    14/  187, ite: 3109] train loss: 0.557354, tar: 0.070426 
l0: 0.052728, l1: 0.051225, l2: 0.051082, l3: 0.054750, l4: 0.109469, l5: 0.085317, l6: 0.084812

[epoch:  34/100000, batch:    16/  187, ite: 3110] train loss: 0.557293, tar: 0.070410 
l0: 0.041799, l1: 0.045760, l2: 0.060119, l3: 0.052327, l4: 0.069191, l5: 0.058600, l6: 0.063756

[epoch:  34/100000, batch:    18/  187, ite: 3111] train loss: 0.557144, tar: 0.070385 
l0: 0.053970, l1: 0.059169, l2: 0.060601, l3: 0.059415, l4: 0.065209, l5: 0.067831, l6: 0.069949

[epoch:  34/100000, batch:    20/  187, ite: 3112] train loss: 0.557035, tar: 0.070370 
l0: 0.047033, l1: 0.045568, l2: 0.047769, l3: 0.047335, l4: 0.057547, l5: 0.059429, l6: 0.056665

[epoch:  34/100000, batch:    22/  187, ite: 3113] train loss: 0.556859, tar: 0.070349 
l0: 0.042135, l1: 0.048984, l2: 0.044664, l3: 0.040598, l4: 0.067068, l5: 0.069384, l6: 0.061504

[epoch:  34/100000, batch:    24/  187, ite: 3114] train loss: 0.556695, tar: 0.070324 
l0: 0.050622, l1: 0.053219, l2: 0.053775, l3: 0.054142, l4: 0.081200, l5: 0.076830, l6: 0.062327

[epoch:  34/100000, batch:    26/  187, ite: 3115] train loss: 0.556583, tar: 0.070306 
l0: 0.045569, l1: 0.049595, l2: 0.048056, l3: 0.046089, l4: 0.054114, l5: 0.052389, l6: 0.055537

[epoch:  34/100000, batch:    28/  187, ite: 3116] train loss: 0.556400, tar: 0.070284 
l0: 0.042749, l1: 0.041146, l2: 0.043529, l3: 0.055926, l4: 0.058334, l5: 0.072648, l6: 0.058562

[epoch:  34/100000, batch:    30/  187, ite: 3117] train loss: 0.556235, tar: 0.070259 
l0: 0.037445, l1: 0.032037, l2: 0.065419, l3: 0.077935, l4: 0.066706, l5: 0.077552, l6: 0.081841

[epoch:  34/100000, batch:    32/  187, ite: 3118] train loss: 0.556130, tar: 0.070230 
l0: 0.055326, l1: 0.052924, l2: 0.053893, l3: 0.056812, l4: 0.094735, l5: 0.115640, l6: 0.086273

[epoch:  34/100000, batch:    34/  187, ite: 3119] train loss: 0.556094, tar: 0.070216 
l0: 0.038287, l1: 0.046475, l2: 0.032040, l3: 0.028228, l4: 0.047740, l5: 0.050224, l6: 0.062465

[epoch:  34/100000, batch:    36/  187, ite: 3120] train loss: 0.555870, tar: 0.070188 
l0: 0.044055, l1: 0.046566, l2: 0.054341, l3: 0.047750, l4: 0.051185, l5: 0.062014, l6: 0.066996

[epoch:  34/100000, batch:    38/  187, ite: 3121] train loss: 0.555707, tar: 0.070165 
l0: 0.029829, l1: 0.030933, l2: 0.034828, l3: 0.032172, l4: 0.042594, l5: 0.039903, l6: 0.049928

[epoch:  34/100000, batch:    40/  187, ite: 3122] train loss: 0.555444, tar: 0.070129 
l0: 0.118831, l1: 0.118065, l2: 0.140019, l3: 0.141353, l4: 0.171345, l5: 0.144623, l6: 0.163048

[epoch:  34/100000, batch:    42/  187, ite: 3123] train loss: 0.555837, tar: 0.070172 
l0: 0.035205, l1: 0.032010, l2: 0.045019, l3: 0.044524, l4: 0.068234, l5: 0.076021, l6: 0.050358

[epoch:  34/100000, batch:    44/  187, ite: 3124] train loss: 0.555655, tar: 0.070141 
l0: 0.079267, l1: 0.081743, l2: 0.079660, l3: 0.083719, l4: 0.111027, l5: 0.111056, l6: 0.090870

[epoch:  34/100000, batch:    46/  187, ite: 3125] train loss: 0.555728, tar: 0.070149 
l0: 0.052917, l1: 0.049610, l2: 0.081914, l3: 0.081554, l4: 0.095085, l5: 0.087339, l6: 0.089977

[epoch:  34/100000, batch:    48/  187, ite: 3126] train loss: 0.555713, tar: 0.070134 
l0: 0.029929, l1: 0.038146, l2: 0.034254, l3: 0.029195, l4: 0.032592, l5: 0.029437, l6: 0.030332

[epoch:  34/100000, batch:    50/  187, ite: 3127] train loss: 0.555418, tar: 0.070098 
l0: 0.028635, l1: 0.023653, l2: 0.028734, l3: 0.032602, l4: 0.073311, l5: 0.077123, l6: 0.077187

[epoch:  34/100000, batch:    52/  187, ite: 3128] train loss: 0.555228, tar: 0.070061 
l0: 0.062144, l1: 0.060182, l2: 0.058604, l3: 0.062556, l4: 0.086108, l5: 0.088145, l6: 0.099250

[epoch:  34/100000, batch:    54/  187, ite: 3129] train loss: 0.555194, tar: 0.070054 
l0: 0.047834, l1: 0.051403, l2: 0.053455, l3: 0.049012, l4: 0.064664, l5: 0.074607, l6: 0.055753

[epoch:  34/100000, batch:    56/  187, ite: 3130] train loss: 0.555054, tar: 0.070035 
l0: 0.105509, l1: 0.116719, l2: 0.114387, l3: 0.101375, l4: 0.078813, l5: 0.083409, l6: 0.101415

[epoch:  34/100000, batch:    58/  187, ite: 3131] train loss: 0.555184, tar: 0.070066 
l0: 0.067942, l1: 0.066241, l2: 0.068756, l3: 0.076141, l4: 0.077232, l5: 0.089275, l6: 0.092497

[epoch:  34/100000, batch:    60/  187, ite: 3132] train loss: 0.555169, tar: 0.070064 
l0: 0.049696, l1: 0.052547, l2: 0.043767, l3: 0.050177, l4: 0.067222, l5: 0.072568, l6: 0.073403

[epoch:  34/100000, batch:    62/  187, ite: 3133] train loss: 0.555040, tar: 0.070046 
l0: 0.049657, l1: 0.051092, l2: 0.051281, l3: 0.055010, l4: 0.070859, l5: 0.071656, l6: 0.052364

[epoch:  34/100000, batch:    64/  187, ite: 3134] train loss: 0.554905, tar: 0.070028 
l0: 0.047658, l1: 0.067539, l2: 0.055013, l3: 0.046827, l4: 0.056951, l5: 0.045318, l6: 0.059592

[epoch:  34/100000, batch:    66/  187, ite: 3135] train loss: 0.554750, tar: 0.070008 
l0: 0.074331, l1: 0.090316, l2: 0.082577, l3: 0.083982, l4: 0.068802, l5: 0.077877, l6: 0.082279

[epoch:  34/100000, batch:    68/  187, ite: 3136] train loss: 0.554755, tar: 0.070012 
l0: 0.053347, l1: 0.053060, l2: 0.065837, l3: 0.062856, l4: 0.063132, l5: 0.072969, l6: 0.073403

[epoch:  34/100000, batch:    70/  187, ite: 3137] train loss: 0.554658, tar: 0.069998 
l0: 0.056940, l1: 0.058831, l2: 0.072825, l3: 0.076646, l4: 0.078627, l5: 0.072647, l6: 0.060583

[epoch:  34/100000, batch:    72/  187, ite: 3138] train loss: 0.554590, tar: 0.069986 
l0: 0.079337, l1: 0.080601, l2: 0.086448, l3: 0.080059, l4: 0.093538, l5: 0.101319, l6: 0.109402

[epoch:  34/100000, batch:    74/  187, ite: 3139] train loss: 0.554656, tar: 0.069994 
l0: 0.056657, l1: 0.058614, l2: 0.085765, l3: 0.086481, l4: 0.051248, l5: 0.050059, l6: 0.054008

[epoch:  34/100000, batch:    76/  187, ite: 3140] train loss: 0.554558, tar: 0.069983 
l0: 0.058840, l1: 0.062170, l2: 0.062188, l3: 0.065676, l4: 0.099139, l5: 0.093269, l6: 0.084261

[epoch:  34/100000, batch:    78/  187, ite: 3141] train loss: 0.554533, tar: 0.069973 
l0: 0.067002, l1: 0.064053, l2: 0.068166, l3: 0.062406, l4: 0.096783, l5: 0.080308, l6: 0.112625

[epoch:  34/100000, batch:    80/  187, ite: 3142] train loss: 0.554530, tar: 0.069970 
l0: 0.073449, l1: 0.074512, l2: 0.077984, l3: 0.078274, l4: 0.075782, l5: 0.074906, l6: 0.076759

[epoch:  34/100000, batch:    82/  187, ite: 3143] train loss: 0.554510, tar: 0.069973 
l0: 0.026135, l1: 0.034492, l2: 0.031169, l3: 0.027283, l4: 0.027662, l5: 0.033388, l6: 0.026328

[epoch:  34/100000, batch:    84/  187, ite: 3144] train loss: 0.554206, tar: 0.069935 
l0: 0.065806, l1: 0.061983, l2: 0.071229, l3: 0.075565, l4: 0.100158, l5: 0.096664, l6: 0.115417

[epoch:  34/100000, batch:    86/  187, ite: 3145] train loss: 0.554234, tar: 0.069931 
l0: 0.063596, l1: 0.065035, l2: 0.062224, l3: 0.061790, l4: 0.079464, l5: 0.067612, l6: 0.066854

[epoch:  34/100000, batch:    88/  187, ite: 3146] train loss: 0.554158, tar: 0.069926 
l0: 0.087319, l1: 0.079439, l2: 0.111995, l3: 0.127618, l4: 0.111925, l5: 0.105137, l6: 0.111832

[epoch:  34/100000, batch:    90/  187, ite: 3147] train loss: 0.554316, tar: 0.069941 
l0: 0.040005, l1: 0.040659, l2: 0.043729, l3: 0.040018, l4: 0.044687, l5: 0.047784, l6: 0.042880

[epoch:  34/100000, batch:    92/  187, ite: 3148] train loss: 0.554094, tar: 0.069915 
l0: 0.069782, l1: 0.071673, l2: 0.072220, l3: 0.075803, l4: 0.098621, l5: 0.093802, l6: 0.110926

[epoch:  34/100000, batch:    94/  187, ite: 3149] train loss: 0.554128, tar: 0.069915 
l0: 0.060197, l1: 0.065957, l2: 0.062841, l3: 0.062248, l4: 0.068158, l5: 0.073177, l6: 0.072705

[epoch:  34/100000, batch:    96/  187, ite: 3150] train loss: 0.554050, tar: 0.069906 
l0: 0.046135, l1: 0.049078, l2: 0.050462, l3: 0.063467, l4: 0.076466, l5: 0.072178, l6: 0.059573

[epoch:  34/100000, batch:    98/  187, ite: 3151] train loss: 0.553932, tar: 0.069886 
l0: 0.075096, l1: 0.070323, l2: 0.071753, l3: 0.067557, l4: 0.074115, l5: 0.098252, l6: 0.125021

[epoch:  34/100000, batch:   100/  187, ite: 3152] train loss: 0.553956, tar: 0.069890 
l0: 0.044369, l1: 0.054049, l2: 0.050530, l3: 0.043875, l4: 0.056031, l5: 0.052575, l6: 0.071753

[epoch:  34/100000, batch:   102/  187, ite: 3153] train loss: 0.553799, tar: 0.069868 
l0: 0.076717, l1: 0.084241, l2: 0.083335, l3: 0.081077, l4: 0.077934, l5: 0.075119, l6: 0.069705

[epoch:  34/100000, batch:   104/  187, ite: 3154] train loss: 0.553794, tar: 0.069874 
l0: 0.046612, l1: 0.047617, l2: 0.050547, l3: 0.050415, l4: 0.067718, l5: 0.062016, l6: 0.056900

[epoch:  34/100000, batch:   106/  187, ite: 3155] train loss: 0.553646, tar: 0.069854 
l0: 0.078267, l1: 0.070987, l2: 0.083747, l3: 0.084219, l4: 0.085867, l5: 0.092345, l6: 0.123611

[epoch:  34/100000, batch:   108/  187, ite: 3156] train loss: 0.553702, tar: 0.069861 
l0: 0.030044, l1: 0.027082, l2: 0.034747, l3: 0.034399, l4: 0.055341, l5: 0.050980, l6: 0.059627

[epoch:  34/100000, batch:   110/  187, ite: 3157] train loss: 0.553476, tar: 0.069827 
l0: 0.074037, l1: 0.067177, l2: 0.084994, l3: 0.092560, l4: 0.087074, l5: 0.112984, l6: 0.071400

[epoch:  34/100000, batch:   112/  187, ite: 3158] train loss: 0.553508, tar: 0.069830 
l0: 0.046652, l1: 0.055862, l2: 0.052295, l3: 0.048033, l4: 0.058559, l5: 0.052374, l6: 0.067040

[epoch:  34/100000, batch:   114/  187, ite: 3159] train loss: 0.553359, tar: 0.069810 
l0: 0.029191, l1: 0.031103, l2: 0.038036, l3: 0.031717, l4: 0.029670, l5: 0.031885, l6: 0.041706

[epoch:  34/100000, batch:   116/  187, ite: 3160] train loss: 0.553083, tar: 0.069775 
l0: 0.098236, l1: 0.086805, l2: 0.107612, l3: 0.114837, l4: 0.130262, l5: 0.129797, l6: 0.134710

[epoch:  34/100000, batch:   118/  187, ite: 3161] train loss: 0.553298, tar: 0.069800 
l0: 0.024028, l1: 0.028282, l2: 0.025557, l3: 0.023173, l4: 0.033675, l5: 0.037958, l6: 0.032535

[epoch:  34/100000, batch:   120/  187, ite: 3162] train loss: 0.552998, tar: 0.069760 
l0: 0.045544, l1: 0.046128, l2: 0.052272, l3: 0.049889, l4: 0.052956, l5: 0.066150, l6: 0.046920

[epoch:  34/100000, batch:   122/  187, ite: 3163] train loss: 0.552832, tar: 0.069740 
l0: 0.063779, l1: 0.065107, l2: 0.068753, l3: 0.069873, l4: 0.086594, l5: 0.073829, l6: 0.074291

[epoch:  34/100000, batch:   124/  187, ite: 3164] train loss: 0.552788, tar: 0.069734 
l0: 0.049225, l1: 0.064817, l2: 0.055328, l3: 0.049971, l4: 0.037679, l5: 0.039235, l6: 0.041537

[epoch:  34/100000, batch:   126/  187, ite: 3165] train loss: 0.552604, tar: 0.069717 
l0: 0.066858, l1: 0.063212, l2: 0.071325, l3: 0.064762, l4: 0.088188, l5: 0.079379, l6: 0.092323

[epoch:  34/100000, batch:   128/  187, ite: 3166] train loss: 0.552581, tar: 0.069714 
l0: 0.067082, l1: 0.069632, l2: 0.086317, l3: 0.077206, l4: 0.082212, l5: 0.058774, l6: 0.075635

[epoch:  34/100000, batch:   130/  187, ite: 3167] train loss: 0.552551, tar: 0.069712 
l0: 0.146552, l1: 0.162179, l2: 0.166662, l3: 0.152621, l4: 0.172021, l5: 0.161550, l6: 0.154585

[epoch:  34/100000, batch:   132/  187, ite: 3168] train loss: 0.553033, tar: 0.069778 
l0: 0.078967, l1: 0.077367, l2: 0.082522, l3: 0.078478, l4: 0.101569, l5: 0.112335, l6: 0.109846

[epoch:  34/100000, batch:   134/  187, ite: 3169] train loss: 0.553108, tar: 0.069786 
l0: 0.061587, l1: 0.061072, l2: 0.072278, l3: 0.069130, l4: 0.076719, l5: 0.068448, l6: 0.067153

[epoch:  34/100000, batch:   136/  187, ite: 3170] train loss: 0.553043, tar: 0.069779 
l0: 0.048904, l1: 0.053165, l2: 0.054332, l3: 0.057616, l4: 0.063362, l5: 0.056946, l6: 0.056873

[epoch:  34/100000, batch:   138/  187, ite: 3171] train loss: 0.552905, tar: 0.069761 
l0: 0.055919, l1: 0.050459, l2: 0.061485, l3: 0.071017, l4: 0.087671, l5: 0.090492, l6: 0.075830

[epoch:  34/100000, batch:   140/  187, ite: 3172] train loss: 0.552853, tar: 0.069749 
l0: 0.096578, l1: 0.103971, l2: 0.108470, l3: 0.105784, l4: 0.105848, l5: 0.090502, l6: 0.097583

[epoch:  34/100000, batch:   142/  187, ite: 3173] train loss: 0.552986, tar: 0.069772 
l0: 0.077058, l1: 0.080670, l2: 0.089968, l3: 0.085671, l4: 0.126646, l5: 0.117273, l6: 0.101911

[epoch:  34/100000, batch:   144/  187, ite: 3174] train loss: 0.553094, tar: 0.069778 
l0: 0.039874, l1: 0.036171, l2: 0.043860, l3: 0.045077, l4: 0.059073, l5: 0.057966, l6: 0.063009

[epoch:  34/100000, batch:   146/  187, ite: 3175] train loss: 0.552917, tar: 0.069753 
l0: 0.043747, l1: 0.041095, l2: 0.052404, l3: 0.051834, l4: 0.096405, l5: 0.075900, l6: 0.059844

[epoch:  34/100000, batch:   148/  187, ite: 3176] train loss: 0.552805, tar: 0.069731 
l0: 0.038196, l1: 0.033430, l2: 0.050367, l3: 0.054464, l4: 0.058283, l5: 0.065414, l6: 0.057928

[epoch:  34/100000, batch:   150/  187, ite: 3177] train loss: 0.552639, tar: 0.069704 
l0: 0.050791, l1: 0.051475, l2: 0.054645, l3: 0.052950, l4: 0.063015, l5: 0.067028, l6: 0.085623

[epoch:  34/100000, batch:   152/  187, ite: 3178] train loss: 0.552531, tar: 0.069688 
l0: 0.053637, l1: 0.048973, l2: 0.055852, l3: 0.057610, l4: 0.090222, l5: 0.094974, l6: 0.090916

[epoch:  34/100000, batch:   154/  187, ite: 3179] train loss: 0.552480, tar: 0.069674 
l0: 0.050512, l1: 0.047596, l2: 0.054206, l3: 0.051242, l4: 0.069643, l5: 0.075150, l6: 0.085930

[epoch:  34/100000, batch:   156/  187, ite: 3180] train loss: 0.552380, tar: 0.069658 
l0: 0.049246, l1: 0.044861, l2: 0.051038, l3: 0.052863, l4: 0.080363, l5: 0.073860, l6: 0.076845

[epoch:  34/100000, batch:   158/  187, ite: 3181] train loss: 0.552276, tar: 0.069641 
l0: 0.065074, l1: 0.059407, l2: 0.068297, l3: 0.072499, l4: 0.102662, l5: 0.098278, l6: 0.099247

[epoch:  34/100000, batch:   160/  187, ite: 3182] train loss: 0.552287, tar: 0.069637 
l0: 0.077043, l1: 0.068188, l2: 0.085556, l3: 0.086946, l4: 0.119249, l5: 0.126231, l6: 0.115971

[epoch:  34/100000, batch:   162/  187, ite: 3183] train loss: 0.552394, tar: 0.069643 
l0: 0.051624, l1: 0.045027, l2: 0.063911, l3: 0.067952, l4: 0.077376, l5: 0.080691, l6: 0.084556

[epoch:  34/100000, batch:   164/  187, ite: 3184] train loss: 0.552325, tar: 0.069628 
l0: 0.054319, l1: 0.063595, l2: 0.067434, l3: 0.071316, l4: 0.068974, l5: 0.074234, l6: 0.069776

[epoch:  34/100000, batch:   166/  187, ite: 3185] train loss: 0.552256, tar: 0.069615 
l0: 0.072949, l1: 0.062463, l2: 0.079128, l3: 0.095487, l4: 0.113638, l5: 0.114151, l6: 0.110501

[epoch:  34/100000, batch:   168/  187, ite: 3186] train loss: 0.552337, tar: 0.069618 
l0: 0.082443, l1: 0.085875, l2: 0.085302, l3: 0.091990, l4: 0.087919, l5: 0.075267, l6: 0.076191

[epoch:  34/100000, batch:   170/  187, ite: 3187] train loss: 0.552364, tar: 0.069629 
l0: 0.077866, l1: 0.074457, l2: 0.103385, l3: 0.111541, l4: 0.127882, l5: 0.119373, l6: 0.095026

[epoch:  34/100000, batch:   172/  187, ite: 3188] train loss: 0.552496, tar: 0.069636 
l0: 0.097144, l1: 0.094575, l2: 0.116982, l3: 0.131153, l4: 0.122114, l5: 0.131721, l6: 0.128522

[epoch:  34/100000, batch:   174/  187, ite: 3189] train loss: 0.552723, tar: 0.069659 
l0: 0.036490, l1: 0.037551, l2: 0.039921, l3: 0.041709, l4: 0.071676, l5: 0.069328, l6: 0.062222

[epoch:  34/100000, batch:   176/  187, ite: 3190] train loss: 0.552560, tar: 0.069631 
l0: 0.054472, l1: 0.052565, l2: 0.073687, l3: 0.077023, l4: 0.089162, l5: 0.087385, l6: 0.075372

[epoch:  34/100000, batch:   178/  187, ite: 3191] train loss: 0.552524, tar: 0.069618 
l0: 0.052136, l1: 0.049153, l2: 0.068204, l3: 0.071944, l4: 0.070415, l5: 0.072744, l6: 0.069097

[epoch:  34/100000, batch:   180/  187, ite: 3192] train loss: 0.552441, tar: 0.069603 
l0: 0.043496, l1: 0.042503, l2: 0.039982, l3: 0.040932, l4: 0.068477, l5: 0.073076, l6: 0.070297

[epoch:  34/100000, batch:   182/  187, ite: 3193] train loss: 0.552296, tar: 0.069582 
l0: 0.040847, l1: 0.039858, l2: 0.048032, l3: 0.051453, l4: 0.069914, l5: 0.071512, l6: 0.069787

[epoch:  34/100000, batch:   184/  187, ite: 3194] train loss: 0.552161, tar: 0.069557 
l0: 0.064285, l1: 0.061303, l2: 0.074305, l3: 0.077117, l4: 0.087699, l5: 0.099205, l6: 0.098814

[epoch:  34/100000, batch:   186/  187, ite: 3195] train loss: 0.552170, tar: 0.069553 
l0: 0.054610, l1: 0.057862, l2: 0.054719, l3: 0.051291, l4: 0.080948, l5: 0.069823, l6: 0.063377

[epoch:  34/100000, batch:   188/  187, ite: 3196] train loss: 0.552070, tar: 0.069541 
l0: 0.041409, l1: 0.041973, l2: 0.039075, l3: 0.042935, l4: 0.052476, l5: 0.054966, l6: 0.056159

[epoch:  35/100000, batch:     2/  187, ite: 3197] train loss: 0.551884, tar: 0.069517 
l0: 0.067156, l1: 0.071300, l2: 0.064376, l3: 0.082133, l4: 0.114565, l5: 0.091330, l6: 0.100397

[epoch:  35/100000, batch:     4/  187, ite: 3198] train loss: 0.551917, tar: 0.069515 
l0: 0.074375, l1: 0.076045, l2: 0.080922, l3: 0.078591, l4: 0.091672, l5: 0.101119, l6: 0.102247

[epoch:  35/100000, batch:     6/  187, ite: 3199] train loss: 0.551961, tar: 0.069519 
l0: 0.048936, l1: 0.047643, l2: 0.059631, l3: 0.063016, l4: 0.060494, l5: 0.075212, l6: 0.061966

[epoch:  35/100000, batch:     8/  187, ite: 3200] train loss: 0.551848, tar: 0.069502 
l0: 0.052571, l1: 0.059445, l2: 0.058268, l3: 0.053240, l4: 0.077234, l5: 0.088749, l6: 0.083218

[epoch:  35/100000, batch:    10/  187, ite: 3201] train loss: 0.551782, tar: 0.069488 
l0: 0.099539, l1: 0.109154, l2: 0.110216, l3: 0.107749, l4: 0.127898, l5: 0.121319, l6: 0.115365

[epoch:  35/100000, batch:    12/  187, ite: 3202] train loss: 0.551982, tar: 0.069513 
l0: 0.030828, l1: 0.032925, l2: 0.052966, l3: 0.042385, l4: 0.049536, l5: 0.050140, l6: 0.045156

[epoch:  35/100000, batch:    14/  187, ite: 3203] train loss: 0.551775, tar: 0.069481 
l0: 0.059062, l1: 0.064424, l2: 0.054256, l3: 0.058248, l4: 0.071508, l5: 0.063760, l6: 0.057201

[epoch:  35/100000, batch:    16/  187, ite: 3204] train loss: 0.551673, tar: 0.069472 
l0: 0.049280, l1: 0.049849, l2: 0.058399, l3: 0.063876, l4: 0.089545, l5: 0.067274, l6: 0.059100

[epoch:  35/100000, batch:    18/  187, ite: 3205] train loss: 0.551578, tar: 0.069455 
l0: 0.078485, l1: 0.071851, l2: 0.091268, l3: 0.091598, l4: 0.108543, l5: 0.116079, l6: 0.108116

[epoch:  35/100000, batch:    20/  187, ite: 3206] train loss: 0.551673, tar: 0.069463 
l0: 0.021200, l1: 0.022290, l2: 0.014035, l3: 0.016487, l4: 0.036872, l5: 0.035387, l6: 0.038606

[epoch:  35/100000, batch:    22/  187, ite: 3207] train loss: 0.551369, tar: 0.069423 
l0: 0.057225, l1: 0.071675, l2: 0.060610, l3: 0.062805, l4: 0.056885, l5: 0.049780, l6: 0.055425

[epoch:  35/100000, batch:    24/  187, ite: 3208] train loss: 0.551256, tar: 0.069413 
l0: 0.053969, l1: 0.053079, l2: 0.046466, l3: 0.051739, l4: 0.075925, l5: 0.086887, l6: 0.082757

[epoch:  35/100000, batch:    26/  187, ite: 3209] train loss: 0.551173, tar: 0.069400 
l0: 0.064489, l1: 0.063026, l2: 0.083040, l3: 0.084376, l4: 0.064487, l5: 0.077366, l6: 0.063973

[epoch:  35/100000, batch:    28/  187, ite: 3210] train loss: 0.551131, tar: 0.069396 
l0: 0.077149, l1: 0.073228, l2: 0.098229, l3: 0.083766, l4: 0.096873, l5: 0.109048, l6: 0.088960

[epoch:  35/100000, batch:    30/  187, ite: 3211] train loss: 0.551194, tar: 0.069402 
l0: 0.038272, l1: 0.030937, l2: 0.039394, l3: 0.047122, l4: 0.069625, l5: 0.074801, l6: 0.069371

[epoch:  35/100000, batch:    32/  187, ite: 3212] train loss: 0.551044, tar: 0.069377 
l0: 0.084551, l1: 0.090417, l2: 0.079800, l3: 0.082391, l4: 0.089623, l5: 0.086252, l6: 0.078168

[epoch:  35/100000, batch:    34/  187, ite: 3213] train loss: 0.551077, tar: 0.069389 
l0: 0.062336, l1: 0.061735, l2: 0.049294, l3: 0.051147, l4: 0.061398, l5: 0.075227, l6: 0.076606

[epoch:  35/100000, batch:    36/  187, ite: 3214] train loss: 0.550984, tar: 0.069383 
l0: 0.064096, l1: 0.060056, l2: 0.067783, l3: 0.062467, l4: 0.074592, l5: 0.085524, l6: 0.100123

[epoch:  35/100000, batch:    38/  187, ite: 3215] train loss: 0.550954, tar: 0.069379 
l0: 0.053783, l1: 0.053624, l2: 0.049878, l3: 0.059439, l4: 0.068002, l5: 0.077293, l6: 0.068055

[epoch:  35/100000, batch:    40/  187, ite: 3216] train loss: 0.550854, tar: 0.069366 
l0: 0.053327, l1: 0.050009, l2: 0.065411, l3: 0.068283, l4: 0.111812, l5: 0.108271, l6: 0.103127

[epoch:  35/100000, batch:    42/  187, ite: 3217] train loss: 0.550862, tar: 0.069353 
l0: 0.076268, l1: 0.075104, l2: 0.074390, l3: 0.073314, l4: 0.082856, l5: 0.131953, l6: 0.109065

[epoch:  35/100000, batch:    44/  187, ite: 3218] train loss: 0.550921, tar: 0.069359 
l0: 0.042565, l1: 0.043217, l2: 0.046742, l3: 0.054903, l4: 0.053078, l5: 0.052833, l6: 0.053375

[epoch:  35/100000, batch:    46/  187, ite: 3219] train loss: 0.550754, tar: 0.069337 
l0: 0.033055, l1: 0.034833, l2: 0.054624, l3: 0.050182, l4: 0.097064, l5: 0.081377, l6: 0.070281

[epoch:  35/100000, batch:    48/  187, ite: 3220] train loss: 0.550648, tar: 0.069307 
l0: 0.069260, l1: 0.069299, l2: 0.078575, l3: 0.082020, l4: 0.078945, l5: 0.081325, l6: 0.087414

[epoch:  35/100000, batch:    50/  187, ite: 3221] train loss: 0.550645, tar: 0.069307 
l0: 0.065516, l1: 0.063906, l2: 0.075531, l3: 0.082793, l4: 0.094097, l5: 0.093052, l6: 0.096494

[epoch:  35/100000, batch:    52/  187, ite: 3222] train loss: 0.550661, tar: 0.069304 
l0: 0.064773, l1: 0.077509, l2: 0.070245, l3: 0.077900, l4: 0.064623, l5: 0.062303, l6: 0.082513

[epoch:  35/100000, batch:    54/  187, ite: 3223] train loss: 0.550620, tar: 0.069300 
l0: 0.116545, l1: 0.125387, l2: 0.125776, l3: 0.138463, l4: 0.107383, l5: 0.140683, l6: 0.131936

[epoch:  35/100000, batch:    56/  187, ite: 3224] train loss: 0.550894, tar: 0.069339 
l0: 0.052606, l1: 0.079750, l2: 0.062134, l3: 0.051463, l4: 0.073673, l5: 0.074508, l6: 0.077424

[epoch:  35/100000, batch:    58/  187, ite: 3225] train loss: 0.550829, tar: 0.069325 
l0: 0.057069, l1: 0.067605, l2: 0.053371, l3: 0.056240, l4: 0.067051, l5: 0.058162, l6: 0.060345

[epoch:  35/100000, batch:    60/  187, ite: 3226] train loss: 0.550723, tar: 0.069315 
l0: 0.055470, l1: 0.067591, l2: 0.060411, l3: 0.046957, l4: 0.090918, l5: 0.063953, l6: 0.057316

[epoch:  35/100000, batch:    62/  187, ite: 3227] train loss: 0.550634, tar: 0.069304 
l0: 0.058180, l1: 0.052064, l2: 0.066324, l3: 0.077653, l4: 0.111361, l5: 0.088132, l6: 0.076400

[epoch:  35/100000, batch:    64/  187, ite: 3228] train loss: 0.550618, tar: 0.069295 
l0: 0.071554, l1: 0.063381, l2: 0.090964, l3: 0.101353, l4: 0.077026, l5: 0.091295, l6: 0.085789

[epoch:  35/100000, batch:    66/  187, ite: 3229] train loss: 0.550643, tar: 0.069296 
l0: 0.065144, l1: 0.061623, l2: 0.063521, l3: 0.071579, l4: 0.078878, l5: 0.082412, l6: 0.080457

[epoch:  35/100000, batch:    68/  187, ite: 3230] train loss: 0.550604, tar: 0.069293 
l0: 0.073030, l1: 0.068510, l2: 0.073882, l3: 0.080124, l4: 0.072008, l5: 0.085403, l6: 0.079827

[epoch:  35/100000, batch:    70/  187, ite: 3231] train loss: 0.550590, tar: 0.069296 
l0: 0.049670, l1: 0.051478, l2: 0.066845, l3: 0.059703, l4: 0.049117, l5: 0.060002, l6: 0.052610

[epoch:  35/100000, batch:    72/  187, ite: 3232] train loss: 0.550459, tar: 0.069280 
l0: 0.051791, l1: 0.046189, l2: 0.061375, l3: 0.075113, l4: 0.071478, l5: 0.066483, l6: 0.064755

[epoch:  35/100000, batch:    74/  187, ite: 3233] train loss: 0.550367, tar: 0.069266 
l0: 0.062778, l1: 0.053411, l2: 0.082301, l3: 0.077194, l4: 0.073021, l5: 0.085167, l6: 0.080491

[epoch:  35/100000, batch:    76/  187, ite: 3234] train loss: 0.550338, tar: 0.069261 
l0: 0.069723, l1: 0.059070, l2: 0.073846, l3: 0.079595, l4: 0.093264, l5: 0.099054, l6: 0.111346

[epoch:  35/100000, batch:    78/  187, ite: 3235] train loss: 0.550367, tar: 0.069261 
l0: 0.031835, l1: 0.030303, l2: 0.036344, l3: 0.037947, l4: 0.079115, l5: 0.056860, l6: 0.060804

[epoch:  35/100000, batch:    80/  187, ite: 3236] train loss: 0.550191, tar: 0.069231 
l0: 0.043437, l1: 0.045330, l2: 0.045782, l3: 0.045114, l4: 0.058635, l5: 0.051883, l6: 0.047268

[epoch:  35/100000, batch:    82/  187, ite: 3237] train loss: 0.550019, tar: 0.069210 
l0: 0.046069, l1: 0.053168, l2: 0.061351, l3: 0.062114, l4: 0.076174, l5: 0.064844, l6: 0.050976

[epoch:  35/100000, batch:    84/  187, ite: 3238] train loss: 0.549910, tar: 0.069191 
l0: 0.048347, l1: 0.048375, l2: 0.054869, l3: 0.057636, l4: 0.065849, l5: 0.060921, l6: 0.054317

[epoch:  35/100000, batch:    86/  187, ite: 3239] train loss: 0.549781, tar: 0.069175 
l0: 0.054257, l1: 0.055298, l2: 0.069920, l3: 0.065066, l4: 0.069956, l5: 0.074816, l6: 0.061302

[epoch:  35/100000, batch:    88/  187, ite: 3240] train loss: 0.549701, tar: 0.069162 
l0: 0.051653, l1: 0.050639, l2: 0.067313, l3: 0.060798, l4: 0.065151, l5: 0.056338, l6: 0.057953

[epoch:  35/100000, batch:    90/  187, ite: 3241] train loss: 0.549588, tar: 0.069148 
l0: 0.064518, l1: 0.062149, l2: 0.079852, l3: 0.077436, l4: 0.084787, l5: 0.071577, l6: 0.071100

[epoch:  35/100000, batch:    92/  187, ite: 3242] train loss: 0.549558, tar: 0.069145 
l0: 0.081642, l1: 0.087297, l2: 0.084427, l3: 0.080373, l4: 0.092685, l5: 0.081025, l6: 0.072720

[epoch:  35/100000, batch:    94/  187, ite: 3243] train loss: 0.549582, tar: 0.069155 
l0: 0.074152, l1: 0.074331, l2: 0.079321, l3: 0.088837, l4: 0.083506, l5: 0.097189, l6: 0.093455

[epoch:  35/100000, batch:    96/  187, ite: 3244] train loss: 0.549615, tar: 0.069159 
l0: 0.041096, l1: 0.044797, l2: 0.050978, l3: 0.046763, l4: 0.049971, l5: 0.054681, l6: 0.049280

[epoch:  35/100000, batch:    98/  187, ite: 3245] train loss: 0.549445, tar: 0.069136 
l0: 0.050497, l1: 0.051030, l2: 0.060106, l3: 0.058588, l4: 0.066198, l5: 0.081442, l6: 0.088336

[epoch:  35/100000, batch:   100/  187, ite: 3246] train loss: 0.549370, tar: 0.069121 
l0: 0.052030, l1: 0.044905, l2: 0.068468, l3: 0.068912, l4: 0.086789, l5: 0.078894, l6: 0.088063

[epoch:  35/100000, batch:   102/  187, ite: 3247] train loss: 0.549321, tar: 0.069107 
l0: 0.068914, l1: 0.078054, l2: 0.075322, l3: 0.066618, l4: 0.078654, l5: 0.080120, l6: 0.067230

[epoch:  35/100000, batch:   104/  187, ite: 3248] train loss: 0.549294, tar: 0.069107 
l0: 0.049574, l1: 0.045838, l2: 0.056150, l3: 0.060289, l4: 0.080206, l5: 0.075057, l6: 0.075704

[epoch:  35/100000, batch:   106/  187, ite: 3249] train loss: 0.549208, tar: 0.069092 
l0: 0.060276, l1: 0.057877, l2: 0.082159, l3: 0.073604, l4: 0.094606, l5: 0.093012, l6: 0.093034

[epoch:  35/100000, batch:   108/  187, ite: 3250] train loss: 0.549213, tar: 0.069085 
l0: 0.043863, l1: 0.036919, l2: 0.053804, l3: 0.056041, l4: 0.058648, l5: 0.065155, l6: 0.071190

[epoch:  35/100000, batch:   110/  187, ite: 3251] train loss: 0.549082, tar: 0.069064 
l0: 0.079600, l1: 0.070043, l2: 0.081546, l3: 0.099579, l4: 0.113672, l5: 0.115383, l6: 0.098619

[epoch:  35/100000, batch:   112/  187, ite: 3252] train loss: 0.549169, tar: 0.069073 
l0: 0.060060, l1: 0.053011, l2: 0.080114, l3: 0.074760, l4: 0.061543, l5: 0.074130, l6: 0.066919

[epoch:  35/100000, batch:   114/  187, ite: 3253] train loss: 0.549106, tar: 0.069066 
l0: 0.048583, l1: 0.047409, l2: 0.060150, l3: 0.059514, l4: 0.067307, l5: 0.068576, l6: 0.070394

[epoch:  35/100000, batch:   116/  187, ite: 3254] train loss: 0.549005, tar: 0.069049 
l0: 0.046269, l1: 0.066971, l2: 0.053324, l3: 0.046218, l4: 0.044049, l5: 0.034529, l6: 0.036433

[epoch:  35/100000, batch:   118/  187, ite: 3255] train loss: 0.548829, tar: 0.069031 
l0: 0.041227, l1: 0.061841, l2: 0.048261, l3: 0.034288, l4: 0.032276, l5: 0.033201, l6: 0.032135

[epoch:  35/100000, batch:   120/  187, ite: 3256] train loss: 0.548617, tar: 0.069009 
l0: 0.072016, l1: 0.085971, l2: 0.053667, l3: 0.056323, l4: 0.073933, l5: 0.073817, l6: 0.067232

[epoch:  35/100000, batch:   122/  187, ite: 3257] train loss: 0.548565, tar: 0.069011 
l0: 0.036659, l1: 0.035085, l2: 0.051258, l3: 0.050522, l4: 0.060623, l5: 0.053507, l6: 0.048794

[epoch:  35/100000, batch:   124/  187, ite: 3258] train loss: 0.548396, tar: 0.068986 
l0: 0.075660, l1: 0.066883, l2: 0.101031, l3: 0.110195, l4: 0.077787, l5: 0.083168, l6: 0.080177

[epoch:  35/100000, batch:   126/  187, ite: 3259] train loss: 0.548433, tar: 0.068991 
l0: 0.073429, l1: 0.070987, l2: 0.084504, l3: 0.083778, l4: 0.076609, l5: 0.077931, l6: 0.076859

[epoch:  35/100000, batch:   128/  187, ite: 3260] train loss: 0.548430, tar: 0.068995 
l0: 0.033192, l1: 0.028209, l2: 0.038313, l3: 0.041424, l4: 0.042396, l5: 0.059099, l6: 0.053184

[epoch:  35/100000, batch:   130/  187, ite: 3261] train loss: 0.548230, tar: 0.068966 
l0: 0.033365, l1: 0.036316, l2: 0.037516, l3: 0.032251, l4: 0.052187, l5: 0.043420, l6: 0.044266

[epoch:  35/100000, batch:   132/  187, ite: 3262] train loss: 0.548017, tar: 0.068938 
l0: 0.023339, l1: 0.024177, l2: 0.037534, l3: 0.028312, l4: 0.037768, l5: 0.033445, l6: 0.027876

[epoch:  35/100000, batch:   134/  187, ite: 3263] train loss: 0.547751, tar: 0.068902 
l0: 0.051467, l1: 0.050730, l2: 0.051571, l3: 0.062006, l4: 0.073913, l5: 0.067184, l6: 0.071008

[epoch:  35/100000, batch:   136/  187, ite: 3264] train loss: 0.547656, tar: 0.068888 
l0: 0.051277, l1: 0.056961, l2: 0.058845, l3: 0.053748, l4: 0.065781, l5: 0.063909, l6: 0.072952

[epoch:  35/100000, batch:   138/  187, ite: 3265] train loss: 0.547558, tar: 0.068874 
l0: 0.051466, l1: 0.050513, l2: 0.056661, l3: 0.063090, l4: 0.048112, l5: 0.051612, l6: 0.048119

[epoch:  35/100000, batch:   140/  187, ite: 3266] train loss: 0.547417, tar: 0.068860 
l0: 0.082663, l1: 0.099750, l2: 0.099165, l3: 0.101108, l4: 0.105753, l5: 0.100074, l6: 0.088292

[epoch:  35/100000, batch:   142/  187, ite: 3267] train loss: 0.547519, tar: 0.068871 
l0: 0.074661, l1: 0.085732, l2: 0.079940, l3: 0.087046, l4: 0.085040, l5: 0.086237, l6: 0.076977

[epoch:  35/100000, batch:   144/  187, ite: 3268] train loss: 0.547542, tar: 0.068876 
l0: 0.045717, l1: 0.044966, l2: 0.053688, l3: 0.059948, l4: 0.062909, l5: 0.074475, l6: 0.067298

[epoch:  35/100000, batch:   146/  187, ite: 3269] train loss: 0.547432, tar: 0.068858 
l0: 0.083372, l1: 0.088170, l2: 0.084299, l3: 0.091951, l4: 0.082992, l5: 0.087883, l6: 0.093321

[epoch:  35/100000, batch:   148/  187, ite: 3270] train loss: 0.547483, tar: 0.068869 
l0: 0.032474, l1: 0.036774, l2: 0.041984, l3: 0.043805, l4: 0.067290, l5: 0.054148, l6: 0.049139

[epoch:  35/100000, batch:   150/  187, ite: 3271] train loss: 0.547309, tar: 0.068840 
l0: 0.057354, l1: 0.056301, l2: 0.064638, l3: 0.075873, l4: 0.117242, l5: 0.097439, l6: 0.071958

[epoch:  35/100000, batch:   152/  187, ite: 3272] train loss: 0.547304, tar: 0.068831 
l0: 0.059860, l1: 0.065048, l2: 0.064995, l3: 0.060127, l4: 0.064600, l5: 0.071920, l6: 0.070183

[epoch:  35/100000, batch:   154/  187, ite: 3273] train loss: 0.547232, tar: 0.068824 
l0: 0.044934, l1: 0.039842, l2: 0.046305, l3: 0.051255, l4: 0.076310, l5: 0.076284, l6: 0.090297

[epoch:  35/100000, batch:   156/  187, ite: 3274] train loss: 0.547137, tar: 0.068806 
l0: 0.031881, l1: 0.031659, l2: 0.040618, l3: 0.038599, l4: 0.040457, l5: 0.039834, l6: 0.039504

[epoch:  35/100000, batch:   158/  187, ite: 3275] train loss: 0.546913, tar: 0.068777 
l0: 0.049824, l1: 0.050160, l2: 0.072429, l3: 0.070092, l4: 0.068677, l5: 0.057327, l6: 0.052541

[epoch:  35/100000, batch:   160/  187, ite: 3276] train loss: 0.546815, tar: 0.068762 
l0: 0.078934, l1: 0.078838, l2: 0.078288, l3: 0.094718, l4: 0.103377, l5: 0.094299, l6: 0.089881

[epoch:  35/100000, batch:   162/  187, ite: 3277] train loss: 0.546871, tar: 0.068770 
l0: 0.032497, l1: 0.033442, l2: 0.036397, l3: 0.043810, l4: 0.036731, l5: 0.032633, l6: 0.037782

[epoch:  35/100000, batch:   164/  187, ite: 3278] train loss: 0.546641, tar: 0.068741 
l0: 0.038163, l1: 0.033811, l2: 0.041739, l3: 0.046905, l4: 0.050300, l5: 0.062748, l6: 0.047720

[epoch:  35/100000, batch:   166/  187, ite: 3279] train loss: 0.546465, tar: 0.068717 
l0: 0.065884, l1: 0.052573, l2: 0.073536, l3: 0.085732, l4: 0.089253, l5: 0.117063, l6: 0.122352

[epoch:  35/100000, batch:   168/  187, ite: 3280] train loss: 0.546512, tar: 0.068715 
l0: 0.074463, l1: 0.069265, l2: 0.077844, l3: 0.091950, l4: 0.101308, l5: 0.107535, l6: 0.107285

[epoch:  35/100000, batch:   170/  187, ite: 3281] train loss: 0.546577, tar: 0.068720 
l0: 0.053862, l1: 0.056039, l2: 0.065642, l3: 0.063112, l4: 0.057487, l5: 0.057475, l6: 0.057783

[epoch:  35/100000, batch:   172/  187, ite: 3282] train loss: 0.546471, tar: 0.068708 
l0: 0.065543, l1: 0.063038, l2: 0.074031, l3: 0.068313, l4: 0.073017, l5: 0.080310, l6: 0.090986

[epoch:  35/100000, batch:   174/  187, ite: 3283] train loss: 0.546447, tar: 0.068706 
l0: 0.049902, l1: 0.063390, l2: 0.045068, l3: 0.047792, l4: 0.051559, l5: 0.057077, l6: 0.058610

[epoch:  35/100000, batch:   176/  187, ite: 3284] train loss: 0.546312, tar: 0.068691 
l0: 0.051695, l1: 0.051741, l2: 0.060342, l3: 0.065410, l4: 0.060473, l5: 0.058949, l6: 0.074145

[epoch:  35/100000, batch:   178/  187, ite: 3285] train loss: 0.546216, tar: 0.068678 
l0: 0.056859, l1: 0.057718, l2: 0.050066, l3: 0.056660, l4: 0.065612, l5: 0.070932, l6: 0.094563

[epoch:  35/100000, batch:   180/  187, ite: 3286] train loss: 0.546143, tar: 0.068669 
l0: 0.064868, l1: 0.069877, l2: 0.065697, l3: 0.080807, l4: 0.075808, l5: 0.063136, l6: 0.069235

[epoch:  35/100000, batch:   182/  187, ite: 3287] train loss: 0.546099, tar: 0.068666 
l0: 0.049687, l1: 0.045304, l2: 0.059230, l3: 0.067962, l4: 0.096936, l5: 0.092240, l6: 0.075781

[epoch:  35/100000, batch:   184/  187, ite: 3288] train loss: 0.546053, tar: 0.068651 
l0: 0.051233, l1: 0.044294, l2: 0.062781, l3: 0.078663, l4: 0.121437, l5: 0.110235, l6: 0.106148

[epoch:  35/100000, batch:   186/  187, ite: 3289] train loss: 0.546075, tar: 0.068637 
l0: 0.050669, l1: 0.071239, l2: 0.070953, l3: 0.070184, l4: 0.052786, l5: 0.038697, l6: 0.031781

[epoch:  35/100000, batch:   188/  187, ite: 3290] train loss: 0.545952, tar: 0.068623 
l0: 0.076554, l1: 0.072629, l2: 0.070744, l3: 0.074503, l4: 0.084429, l5: 0.099432, l6: 0.096120

[epoch:  36/100000, batch:     2/  187, ite: 3291] train loss: 0.545974, tar: 0.068630 
l0: 0.025722, l1: 0.038912, l2: 0.033853, l3: 0.021140, l4: 0.027665, l5: 0.020551, l6: 0.011392

[epoch:  36/100000, batch:     4/  187, ite: 3292] train loss: 0.545690, tar: 0.068596 
l0: 0.061999, l1: 0.055500, l2: 0.075080, l3: 0.079406, l4: 0.097583, l5: 0.097567, l6: 0.106305

[epoch:  36/100000, batch:     6/  187, ite: 3293] train loss: 0.545711, tar: 0.068591 
l0: 0.064635, l1: 0.069844, l2: 0.062162, l3: 0.057725, l4: 0.069259, l5: 0.091071, l6: 0.096004

[epoch:  36/100000, batch:     8/  187, ite: 3294] train loss: 0.545684, tar: 0.068588 
l0: 0.040079, l1: 0.034563, l2: 0.041193, l3: 0.046869, l4: 0.073623, l5: 0.066409, l6: 0.062042

[epoch:  36/100000, batch:    10/  187, ite: 3295] train loss: 0.545545, tar: 0.068566 
l0: 0.043555, l1: 0.053029, l2: 0.042349, l3: 0.041146, l4: 0.047468, l5: 0.044337, l6: 0.050924

[epoch:  36/100000, batch:    12/  187, ite: 3296] train loss: 0.545373, tar: 0.068547 
l0: 0.070025, l1: 0.073299, l2: 0.081020, l3: 0.084201, l4: 0.083054, l5: 0.068270, l6: 0.076022

[epoch:  36/100000, batch:    14/  187, ite: 3297] train loss: 0.545365, tar: 0.068548 
l0: 0.047811, l1: 0.035404, l2: 0.050757, l3: 0.066344, l4: 0.112327, l5: 0.094523, l6: 0.081577

[epoch:  36/100000, batch:    16/  187, ite: 3298] train loss: 0.545322, tar: 0.068532 
l0: 0.050291, l1: 0.045734, l2: 0.048902, l3: 0.059807, l4: 0.068240, l5: 0.064997, l6: 0.050214

[epoch:  36/100000, batch:    18/  187, ite: 3299] train loss: 0.545201, tar: 0.068518 
l0: 0.090432, l1: 0.094797, l2: 0.092508, l3: 0.085772, l4: 0.125901, l5: 0.127816, l6: 0.097563

[epoch:  36/100000, batch:    20/  187, ite: 3300] train loss: 0.545331, tar: 0.068535 
l0: 0.082315, l1: 0.088483, l2: 0.106939, l3: 0.086697, l4: 0.097403, l5: 0.098402, l6: 0.092989

[epoch:  36/100000, batch:    22/  187, ite: 3301] train loss: 0.545414, tar: 0.068546 
l0: 0.068759, l1: 0.075580, l2: 0.055117, l3: 0.059437, l4: 0.069573, l5: 0.066699, l6: 0.065452

[epoch:  36/100000, batch:    24/  187, ite: 3302] train loss: 0.545349, tar: 0.068546 
l0: 0.046733, l1: 0.047103, l2: 0.060208, l3: 0.053290, l4: 0.063726, l5: 0.060000, l6: 0.051170

[epoch:  36/100000, batch:    26/  187, ite: 3303] train loss: 0.545224, tar: 0.068529 
l0: 0.066537, l1: 0.082175, l2: 0.062612, l3: 0.064453, l4: 0.093559, l5: 0.082978, l6: 0.094985

[epoch:  36/100000, batch:    28/  187, ite: 3304] train loss: 0.545225, tar: 0.068527 
l0: 0.050973, l1: 0.053397, l2: 0.045420, l3: 0.045600, l4: 0.060853, l5: 0.064003, l6: 0.060928

[epoch:  36/100000, batch:    30/  187, ite: 3305] train loss: 0.545100, tar: 0.068514 
l0: 0.035459, l1: 0.032537, l2: 0.041484, l3: 0.040856, l4: 0.066103, l5: 0.072501, l6: 0.057980

[epoch:  36/100000, batch:    32/  187, ite: 3306] train loss: 0.544948, tar: 0.068489 
l0: 0.055543, l1: 0.056405, l2: 0.076154, l3: 0.072221, l4: 0.102044, l5: 0.100942, l6: 0.088772

[epoch:  36/100000, batch:    34/  187, ite: 3307] train loss: 0.544953, tar: 0.068479 
l0: 0.035375, l1: 0.031069, l2: 0.040102, l3: 0.044532, l4: 0.057591, l5: 0.063067, l6: 0.061112

[epoch:  36/100000, batch:    36/  187, ite: 3308] train loss: 0.544791, tar: 0.068453 
l0: 0.076636, l1: 0.081739, l2: 0.070251, l3: 0.076119, l4: 0.101849, l5: 0.097422, l6: 0.100237

[epoch:  36/100000, batch:    38/  187, ite: 3309] train loss: 0.544837, tar: 0.068460 
l0: 0.050762, l1: 0.067658, l2: 0.041290, l3: 0.045178, l4: 0.052346, l5: 0.057757, l6: 0.043470

[epoch:  36/100000, batch:    40/  187, ite: 3310] train loss: 0.544694, tar: 0.068446 
l0: 0.040417, l1: 0.038426, l2: 0.044206, l3: 0.049437, l4: 0.064130, l5: 0.062468, l6: 0.053910

[epoch:  36/100000, batch:    42/  187, ite: 3311] train loss: 0.544548, tar: 0.068425 
l0: 0.060453, l1: 0.055450, l2: 0.049906, l3: 0.061889, l4: 0.096067, l5: 0.098459, l6: 0.131289

[epoch:  36/100000, batch:    44/  187, ite: 3312] train loss: 0.544555, tar: 0.068419 
l0: 0.045814, l1: 0.046319, l2: 0.045580, l3: 0.056163, l4: 0.059633, l5: 0.060025, l6: 0.066021

[epoch:  36/100000, batch:    46/  187, ite: 3313] train loss: 0.544429, tar: 0.068401 
l0: 0.051370, l1: 0.044281, l2: 0.054506, l3: 0.060040, l4: 0.073911, l5: 0.076156, l6: 0.099985

[epoch:  36/100000, batch:    48/  187, ite: 3314] train loss: 0.544365, tar: 0.068389 
l0: 0.036953, l1: 0.039943, l2: 0.053865, l3: 0.053122, l4: 0.050793, l5: 0.048134, l6: 0.046252

[epoch:  36/100000, batch:    50/  187, ite: 3315] train loss: 0.544202, tar: 0.068365 
l0: 0.024756, l1: 0.020790, l2: 0.033734, l3: 0.035623, l4: 0.050019, l5: 0.047660, l6: 0.063753

[epoch:  36/100000, batch:    52/  187, ite: 3316] train loss: 0.543998, tar: 0.068331 
l0: 0.049887, l1: 0.044805, l2: 0.059649, l3: 0.069860, l4: 0.067172, l5: 0.068358, l6: 0.068993

[epoch:  36/100000, batch:    54/  187, ite: 3317] train loss: 0.543910, tar: 0.068317 
l0: 0.034184, l1: 0.033233, l2: 0.040761, l3: 0.043752, l4: 0.055026, l5: 0.058257, l6: 0.056346

[epoch:  36/100000, batch:    56/  187, ite: 3318] train loss: 0.543742, tar: 0.068292 
l0: 0.038655, l1: 0.034406, l2: 0.044008, l3: 0.042547, l4: 0.063274, l5: 0.081875, l6: 0.076494

[epoch:  36/100000, batch:    58/  187, ite: 3319] train loss: 0.543619, tar: 0.068269 
l0: 0.066245, l1: 0.061015, l2: 0.073617, l3: 0.091530, l4: 0.082021, l5: 0.085717, l6: 0.074699

[epoch:  36/100000, batch:    60/  187, ite: 3320] train loss: 0.543612, tar: 0.068268 
l0: 0.059269, l1: 0.062211, l2: 0.059620, l3: 0.067702, l4: 0.065062, l5: 0.071462, l6: 0.075548

[epoch:  36/100000, batch:    62/  187, ite: 3321] train loss: 0.543549, tar: 0.068261 
l0: 0.058747, l1: 0.057737, l2: 0.063887, l3: 0.063362, l4: 0.069824, l5: 0.068711, l6: 0.079076

[epoch:  36/100000, batch:    64/  187, ite: 3322] train loss: 0.543487, tar: 0.068254 
l0: 0.047042, l1: 0.043412, l2: 0.056100, l3: 0.062748, l4: 0.077375, l5: 0.068826, l6: 0.067838

[epoch:  36/100000, batch:    66/  187, ite: 3323] train loss: 0.543396, tar: 0.068238 
l0: 0.070731, l1: 0.071569, l2: 0.102396, l3: 0.092024, l4: 0.076369, l5: 0.079483, l6: 0.067663

[epoch:  36/100000, batch:    68/  187, ite: 3324] train loss: 0.543409, tar: 0.068239 
l0: 0.057379, l1: 0.058037, l2: 0.051495, l3: 0.055647, l4: 0.060291, l5: 0.062774, l6: 0.071833

[epoch:  36/100000, batch:    70/  187, ite: 3325] train loss: 0.543314, tar: 0.068231 
l0: 0.036607, l1: 0.035176, l2: 0.040078, l3: 0.044834, l4: 0.051462, l5: 0.050965, l6: 0.050249

[epoch:  36/100000, batch:    72/  187, ite: 3326] train loss: 0.543138, tar: 0.068207 
l0: 0.042181, l1: 0.039972, l2: 0.043178, l3: 0.041323, l4: 0.052248, l5: 0.062511, l6: 0.061764

[epoch:  36/100000, batch:    74/  187, ite: 3327] train loss: 0.542987, tar: 0.068188 
l0: 0.027229, l1: 0.029059, l2: 0.034864, l3: 0.036394, l4: 0.049511, l5: 0.047419, l6: 0.048404

[epoch:  36/100000, batch:    76/  187, ite: 3328] train loss: 0.542783, tar: 0.068157 
l0: 0.084839, l1: 0.092914, l2: 0.134866, l3: 0.134956, l4: 0.123244, l5: 0.089744, l6: 0.066500

[epoch:  36/100000, batch:    78/  187, ite: 3329] train loss: 0.542922, tar: 0.068169 
l0: 0.086477, l1: 0.094278, l2: 0.095588, l3: 0.069861, l4: 0.085372, l5: 0.095681, l6: 0.122759

[epoch:  36/100000, batch:    80/  187, ite: 3330] train loss: 0.543003, tar: 0.068183 
l0: 0.051226, l1: 0.051362, l2: 0.056297, l3: 0.067051, l4: 0.056640, l5: 0.065602, l6: 0.064914

[epoch:  36/100000, batch:    82/  187, ite: 3331] train loss: 0.542905, tar: 0.068171 
l0: 0.082671, l1: 0.084695, l2: 0.091126, l3: 0.102084, l4: 0.089209, l5: 0.098836, l6: 0.081224

[epoch:  36/100000, batch:    84/  187, ite: 3332] train loss: 0.542970, tar: 0.068181 
l0: 0.054476, l1: 0.056967, l2: 0.063305, l3: 0.065925, l4: 0.061454, l5: 0.071708, l6: 0.075645

[epoch:  36/100000, batch:    86/  187, ite: 3333] train loss: 0.542900, tar: 0.068171 
l0: 0.045631, l1: 0.041760, l2: 0.048355, l3: 0.053484, l4: 0.064724, l5: 0.076544, l6: 0.069244

[epoch:  36/100000, batch:    88/  187, ite: 3334] train loss: 0.542793, tar: 0.068154 
l0: 0.059510, l1: 0.059907, l2: 0.058038, l3: 0.071953, l4: 0.096840, l5: 0.117443, l6: 0.114582

[epoch:  36/100000, batch:    90/  187, ite: 3335] train loss: 0.542819, tar: 0.068148 
l0: 0.048454, l1: 0.042749, l2: 0.069720, l3: 0.068346, l4: 0.078992, l5: 0.067860, l6: 0.071753

[epoch:  36/100000, batch:    92/  187, ite: 3336] train loss: 0.542748, tar: 0.068133 
l0: 0.061188, l1: 0.058781, l2: 0.088935, l3: 0.094184, l4: 0.077204, l5: 0.079226, l6: 0.084415

[epoch:  36/100000, batch:    94/  187, ite: 3337] train loss: 0.542749, tar: 0.068128 
l0: 0.030257, l1: 0.032289, l2: 0.037603, l3: 0.033663, l4: 0.044546, l5: 0.041669, l6: 0.036766

[epoch:  36/100000, batch:    96/  187, ite: 3338] train loss: 0.542536, tar: 0.068099 
l0: 0.049317, l1: 0.052441, l2: 0.080332, l3: 0.070446, l4: 0.063353, l5: 0.073073, l6: 0.074717

[epoch:  36/100000, batch:    98/  187, ite: 3339] train loss: 0.542477, tar: 0.068085 
l0: 0.083012, l1: 0.080454, l2: 0.099030, l3: 0.092671, l4: 0.085168, l5: 0.100423, l6: 0.110392

[epoch:  36/100000, batch:   100/  187, ite: 3340] train loss: 0.542558, tar: 0.068097 
l0: 0.071543, l1: 0.062774, l2: 0.082732, l3: 0.097658, l4: 0.138781, l5: 0.120354, l6: 0.113468

[epoch:  36/100000, batch:   102/  187, ite: 3341] train loss: 0.542666, tar: 0.068099 
l0: 0.072786, l1: 0.070726, l2: 0.112287, l3: 0.112327, l4: 0.210844, l5: 0.147390, l6: 0.166650

[epoch:  36/100000, batch:   104/  187, ite: 3342] train loss: 0.542927, tar: 0.068103 
l0: 0.067899, l1: 0.050077, l2: 0.081928, l3: 0.097248, l4: 0.138013, l5: 0.154813, l6: 0.146776

[epoch:  36/100000, batch:   106/  187, ite: 3343] train loss: 0.543071, tar: 0.068103 
l0: 0.032060, l1: 0.029509, l2: 0.043873, l3: 0.042232, l4: 0.057900, l5: 0.055288, l6: 0.045253

[epoch:  36/100000, batch:   108/  187, ite: 3344] train loss: 0.542895, tar: 0.068076 
l0: 0.026883, l1: 0.029942, l2: 0.039384, l3: 0.038714, l4: 0.037776, l5: 0.047387, l6: 0.043290

[epoch:  36/100000, batch:   110/  187, ite: 3345] train loss: 0.542687, tar: 0.068045 
l0: 0.039762, l1: 0.043335, l2: 0.049809, l3: 0.043733, l4: 0.047327, l5: 0.061465, l6: 0.054394

[epoch:  36/100000, batch:   112/  187, ite: 3346] train loss: 0.542536, tar: 0.068024 
l0: 0.045390, l1: 0.058089, l2: 0.046406, l3: 0.039201, l4: 0.062094, l5: 0.065768, l6: 0.055553

[epoch:  36/100000, batch:   114/  187, ite: 3347] train loss: 0.542410, tar: 0.068007 
l0: 0.054808, l1: 0.057901, l2: 0.057583, l3: 0.059384, l4: 0.066356, l5: 0.076765, l6: 0.070038

[epoch:  36/100000, batch:   116/  187, ite: 3348] train loss: 0.542336, tar: 0.067997 
l0: 0.052917, l1: 0.046765, l2: 0.067019, l3: 0.070206, l4: 0.118547, l5: 0.110874, l6: 0.085546

[epoch:  36/100000, batch:   118/  187, ite: 3349] train loss: 0.542343, tar: 0.067986 
l0: 0.041660, l1: 0.043739, l2: 0.053501, l3: 0.055138, l4: 0.063586, l5: 0.060212, l6: 0.062792

[epoch:  36/100000, batch:   120/  187, ite: 3350] train loss: 0.542223, tar: 0.067967 
l0: 0.127672, l1: 0.144310, l2: 0.127737, l3: 0.138466, l4: 0.148555, l5: 0.123597, l6: 0.131692

[epoch:  36/100000, batch:   122/  187, ite: 3351] train loss: 0.542519, tar: 0.068011 
l0: 0.050789, l1: 0.039275, l2: 0.074648, l3: 0.072777, l4: 0.072915, l5: 0.084696, l6: 0.091689

[epoch:  36/100000, batch:   124/  187, ite: 3352] train loss: 0.542478, tar: 0.067998 
l0: 0.067076, l1: 0.067941, l2: 0.086841, l3: 0.089368, l4: 0.105370, l5: 0.091142, l6: 0.081770

[epoch:  36/100000, batch:   126/  187, ite: 3353] train loss: 0.542513, tar: 0.067998 
l0: 0.071924, l1: 0.060943, l2: 0.087225, l3: 0.090018, l4: 0.133487, l5: 0.152096, l6: 0.153120

[epoch:  36/100000, batch:   128/  187, ite: 3354] train loss: 0.542665, tar: 0.068000 
l0: 0.044856, l1: 0.059726, l2: 0.042210, l3: 0.045991, l4: 0.056340, l5: 0.052850, l6: 0.052866

[epoch:  36/100000, batch:   130/  187, ite: 3355] train loss: 0.542527, tar: 0.067983 
l0: 0.039365, l1: 0.040734, l2: 0.039558, l3: 0.050958, l4: 0.065657, l5: 0.077238, l6: 0.068634

[epoch:  36/100000, batch:   132/  187, ite: 3356] train loss: 0.542408, tar: 0.067962 
l0: 0.061187, l1: 0.056622, l2: 0.079384, l3: 0.089624, l4: 0.096304, l5: 0.098137, l6: 0.081086

[epoch:  36/100000, batch:   134/  187, ite: 3357] train loss: 0.542423, tar: 0.067957 
l0: 0.044510, l1: 0.041535, l2: 0.046308, l3: 0.048684, l4: 0.071486, l5: 0.080103, l6: 0.078316

[epoch:  36/100000, batch:   136/  187, ite: 3358] train loss: 0.542326, tar: 0.067940 
l0: 0.065726, l1: 0.054694, l2: 0.086177, l3: 0.093979, l4: 0.126940, l5: 0.125879, l6: 0.145738

[epoch:  36/100000, batch:   138/  187, ite: 3359] train loss: 0.542442, tar: 0.067938 
l0: 0.041586, l1: 0.051906, l2: 0.058070, l3: 0.047461, l4: 0.051400, l5: 0.060236, l6: 0.054387

[epoch:  36/100000, batch:   140/  187, ite: 3360] train loss: 0.542311, tar: 0.067919 
l0: 0.074984, l1: 0.080138, l2: 0.107054, l3: 0.108998, l4: 0.085555, l5: 0.075067, l6: 0.068259

[epoch:  36/100000, batch:   142/  187, ite: 3361] train loss: 0.542354, tar: 0.067924 
l0: 0.063087, l1: 0.068330, l2: 0.072595, l3: 0.069286, l4: 0.080026, l5: 0.093047, l6: 0.093001

[epoch:  36/100000, batch:   144/  187, ite: 3362] train loss: 0.542351, tar: 0.067921 
l0: 0.060307, l1: 0.067331, l2: 0.063642, l3: 0.062213, l4: 0.075676, l5: 0.062217, l6: 0.073329

[epoch:  36/100000, batch:   146/  187, ite: 3363] train loss: 0.542294, tar: 0.067915 
l0: 0.056280, l1: 0.052360, l2: 0.072608, l3: 0.072173, l4: 0.078660, l5: 0.077170, l6: 0.087985

[epoch:  36/100000, batch:   148/  187, ite: 3364] train loss: 0.542261, tar: 0.067907 
l0: 0.043961, l1: 0.058704, l2: 0.056654, l3: 0.051428, l4: 0.050524, l5: 0.055426, l6: 0.043179

[epoch:  36/100000, batch:   150/  187, ite: 3365] train loss: 0.542128, tar: 0.067889 
l0: 0.064696, l1: 0.080869, l2: 0.091766, l3: 0.071207, l4: 0.060858, l5: 0.076513, l6: 0.058493

[epoch:  36/100000, batch:   152/  187, ite: 3366] train loss: 0.542100, tar: 0.067887 
l0: 0.065148, l1: 0.061181, l2: 0.069297, l3: 0.066775, l4: 0.090890, l5: 0.093855, l6: 0.096252

[epoch:  36/100000, batch:   154/  187, ite: 3367] train loss: 0.542101, tar: 0.067885 
l0: 0.069037, l1: 0.063407, l2: 0.055914, l3: 0.065799, l4: 0.114647, l5: 0.127212, l6: 0.177982

[epoch:  36/100000, batch:   156/  187, ite: 3368] train loss: 0.542198, tar: 0.067885 
l0: 0.038841, l1: 0.043624, l2: 0.043017, l3: 0.042155, l4: 0.058086, l5: 0.049529, l6: 0.050901

[epoch:  36/100000, batch:   158/  187, ite: 3369] train loss: 0.542040, tar: 0.067864 
l0: 0.067431, l1: 0.078830, l2: 0.067233, l3: 0.069802, l4: 0.092569, l5: 0.068400, l6: 0.072380

[epoch:  36/100000, batch:   160/  187, ite: 3370] train loss: 0.542021, tar: 0.067864 
l0: 0.072545, l1: 0.064734, l2: 0.079199, l3: 0.096197, l4: 0.120220, l5: 0.116566, l6: 0.100648

[epoch:  36/100000, batch:   162/  187, ite: 3371] train loss: 0.542100, tar: 0.067867 
l0: 0.073704, l1: 0.072230, l2: 0.073991, l3: 0.084127, l4: 0.101729, l5: 0.105385, l6: 0.089165

[epoch:  36/100000, batch:   164/  187, ite: 3372] train loss: 0.542142, tar: 0.067872 
l0: 0.056750, l1: 0.054734, l2: 0.054465, l3: 0.061259, l4: 0.078586, l5: 0.083196, l6: 0.075453

[epoch:  36/100000, batch:   166/  187, ite: 3373] train loss: 0.542086, tar: 0.067864 
l0: 0.030589, l1: 0.036714, l2: 0.033609, l3: 0.034138, l4: 0.051009, l5: 0.050314, l6: 0.043812

[epoch:  36/100000, batch:   168/  187, ite: 3374] train loss: 0.541895, tar: 0.067836 
l0: 0.070289, l1: 0.071640, l2: 0.095426, l3: 0.091264, l4: 0.091550, l5: 0.084594, l6: 0.093939

[epoch:  36/100000, batch:   170/  187, ite: 3375] train loss: 0.541937, tar: 0.067838 
l0: 0.081197, l1: 0.087207, l2: 0.077421, l3: 0.081348, l4: 0.094070, l5: 0.104021, l6: 0.099695

[epoch:  36/100000, batch:   172/  187, ite: 3376] train loss: 0.541997, tar: 0.067848 
l0: 0.082944, l1: 0.072277, l2: 0.113330, l3: 0.122058, l4: 0.131559, l5: 0.151406, l6: 0.157144

[epoch:  36/100000, batch:   174/  187, ite: 3377] train loss: 0.542207, tar: 0.067859 
l0: 0.054900, l1: 0.060747, l2: 0.057887, l3: 0.057270, l4: 0.062097, l5: 0.059455, l6: 0.068182

[epoch:  36/100000, batch:   176/  187, ite: 3378] train loss: 0.542118, tar: 0.067849 
l0: 0.076930, l1: 0.087161, l2: 0.076499, l3: 0.073061, l4: 0.080610, l5: 0.074051, l6: 0.090077

[epoch:  36/100000, batch:   178/  187, ite: 3379] train loss: 0.542130, tar: 0.067856 
l0: 0.051771, l1: 0.050001, l2: 0.053897, l3: 0.054734, l4: 0.054857, l5: 0.060672, l6: 0.069730

[epoch:  36/100000, batch:   180/  187, ite: 3380] train loss: 0.542024, tar: 0.067844 
l0: 0.067748, l1: 0.061304, l2: 0.080961, l3: 0.082632, l4: 0.116023, l5: 0.118250, l6: 0.130369

[epoch:  36/100000, batch:   182/  187, ite: 3381] train loss: 0.542107, tar: 0.067844 
l0: 0.051404, l1: 0.053596, l2: 0.051151, l3: 0.053941, l4: 0.056579, l5: 0.061613, l6: 0.072345

[epoch:  36/100000, batch:   184/  187, ite: 3382] train loss: 0.542005, tar: 0.067832 
l0: 0.106252, l1: 0.122111, l2: 0.093021, l3: 0.102057, l4: 0.125262, l5: 0.127116, l6: 0.100740

[epoch:  36/100000, batch:   186/  187, ite: 3383] train loss: 0.542175, tar: 0.067860 
l0: 0.052009, l1: 0.045468, l2: 0.054619, l3: 0.051913, l4: 0.080502, l5: 0.086748, l6: 0.085584

[epoch:  36/100000, batch:   188/  187, ite: 3384] train loss: 0.542113, tar: 0.067849 
l0: 0.055735, l1: 0.074415, l2: 0.061851, l3: 0.059825, l4: 0.077054, l5: 0.066647, l6: 0.044435

[epoch:  37/100000, batch:     2/  187, ite: 3385] train loss: 0.542039, tar: 0.067840 
l0: 0.044328, l1: 0.043652, l2: 0.054754, l3: 0.058014, l4: 0.044152, l5: 0.052919, l6: 0.064182

[epoch:  37/100000, batch:     4/  187, ite: 3386] train loss: 0.541909, tar: 0.067823 
l0: 0.043172, l1: 0.034900, l2: 0.046781, l3: 0.047411, l4: 0.067027, l5: 0.071941, l6: 0.082786

[epoch:  37/100000, batch:     6/  187, ite: 3387] train loss: 0.541803, tar: 0.067805 
l0: 0.035419, l1: 0.032633, l2: 0.041471, l3: 0.041286, l4: 0.058351, l5: 0.057687, l6: 0.055358

[epoch:  37/100000, batch:     8/  187, ite: 3388] train loss: 0.541645, tar: 0.067782 
l0: 0.052210, l1: 0.047252, l2: 0.059009, l3: 0.057528, l4: 0.060172, l5: 0.060152, l6: 0.071174

[epoch:  37/100000, batch:    10/  187, ite: 3389] train loss: 0.541548, tar: 0.067771 
l0: 0.054475, l1: 0.046237, l2: 0.052096, l3: 0.056941, l4: 0.082468, l5: 0.095516, l6: 0.114935

[epoch:  37/100000, batch:    12/  187, ite: 3390] train loss: 0.541520, tar: 0.067761 
l0: 0.050405, l1: 0.048823, l2: 0.055937, l3: 0.057569, l4: 0.053189, l5: 0.064657, l6: 0.057835

[epoch:  37/100000, batch:    14/  187, ite: 3391] train loss: 0.541410, tar: 0.067749 
l0: 0.054426, l1: 0.055563, l2: 0.052130, l3: 0.053852, l4: 0.054808, l5: 0.062763, l6: 0.056118

[epoch:  37/100000, batch:    16/  187, ite: 3392] train loss: 0.541301, tar: 0.067739 
l0: 0.054568, l1: 0.044647, l2: 0.060534, l3: 0.070691, l4: 0.073954, l5: 0.086625, l6: 0.087166

[epoch:  37/100000, batch:    18/  187, ite: 3393] train loss: 0.541256, tar: 0.067730 
l0: 0.073258, l1: 0.063707, l2: 0.089386, l3: 0.109310, l4: 0.090779, l5: 0.091637, l6: 0.100933

[epoch:  37/100000, batch:    20/  187, ite: 3394] train loss: 0.541311, tar: 0.067734 
l0: 0.043112, l1: 0.034108, l2: 0.064928, l3: 0.070791, l4: 0.047691, l5: 0.063462, l6: 0.070276

[epoch:  37/100000, batch:    22/  187, ite: 3395] train loss: 0.541206, tar: 0.067716 
l0: 0.052350, l1: 0.049352, l2: 0.061664, l3: 0.060820, l4: 0.087706, l5: 0.093405, l6: 0.083759

[epoch:  37/100000, batch:    24/  187, ite: 3396] train loss: 0.541169, tar: 0.067705 
l0: 0.035084, l1: 0.045596, l2: 0.046480, l3: 0.037365, l4: 0.045041, l5: 0.037161, l6: 0.042217

[epoch:  37/100000, batch:    26/  187, ite: 3397] train loss: 0.540988, tar: 0.067682 
l0: 0.045687, l1: 0.041151, l2: 0.045971, l3: 0.054868, l4: 0.101530, l5: 0.097456, l6: 0.086436

[epoch:  37/100000, batch:    28/  187, ite: 3398] train loss: 0.540940, tar: 0.067666 
l0: 0.045813, l1: 0.046039, l2: 0.047591, l3: 0.043997, l4: 0.065264, l5: 0.062786, l6: 0.073194

[epoch:  37/100000, batch:    30/  187, ite: 3399] train loss: 0.540828, tar: 0.067650 
l0: 0.052287, l1: 0.055469, l2: 0.063966, l3: 0.066570, l4: 0.076877, l5: 0.065551, l6: 0.076614

[epoch:  37/100000, batch:    32/  187, ite: 3400] train loss: 0.540768, tar: 0.067639 
l0: 0.041644, l1: 0.040155, l2: 0.048760, l3: 0.054489, l4: 0.061163, l5: 0.060448, l6: 0.051698

[epoch:  37/100000, batch:    34/  187, ite: 3401] train loss: 0.540638, tar: 0.067621 
l0: 0.032703, l1: 0.031795, l2: 0.029065, l3: 0.030047, l4: 0.042331, l5: 0.050031, l6: 0.044057

[epoch:  37/100000, batch:    36/  187, ite: 3402] train loss: 0.540438, tar: 0.067596 
l0: 0.044824, l1: 0.043000, l2: 0.050486, l3: 0.065439, l4: 0.060520, l5: 0.054716, l6: 0.052235

[epoch:  37/100000, batch:    38/  187, ite: 3403] train loss: 0.540317, tar: 0.067580 
l0: 0.042423, l1: 0.035819, l2: 0.037481, l3: 0.048220, l4: 0.076345, l5: 0.094658, l6: 0.087148

[epoch:  37/100000, batch:    40/  187, ite: 3404] train loss: 0.540233, tar: 0.067562 
l0: 0.065730, l1: 0.061410, l2: 0.079143, l3: 0.095472, l4: 0.119228, l5: 0.101836, l6: 0.100657

[epoch:  37/100000, batch:    42/  187, ite: 3405] train loss: 0.540292, tar: 0.067560 
l0: 0.140528, l1: 0.168135, l2: 0.151741, l3: 0.138746, l4: 0.152714, l5: 0.132011, l6: 0.146684

[epoch:  37/100000, batch:    44/  187, ite: 3406] train loss: 0.540641, tar: 0.067612 
l0: 0.046399, l1: 0.046957, l2: 0.060718, l3: 0.059184, l4: 0.066286, l5: 0.073197, l6: 0.081995

[epoch:  37/100000, batch:    46/  187, ite: 3407] train loss: 0.540566, tar: 0.067597 
l0: 0.054257, l1: 0.039063, l2: 0.062036, l3: 0.089980, l4: 0.085248, l5: 0.106065, l6: 0.117861

[epoch:  37/100000, batch:    48/  187, ite: 3408] train loss: 0.540576, tar: 0.067588 
l0: 0.060796, l1: 0.059726, l2: 0.064635, l3: 0.062273, l4: 0.073832, l5: 0.073005, l6: 0.076596

[epoch:  37/100000, batch:    50/  187, ite: 3409] train loss: 0.540526, tar: 0.067583 
l0: 0.022744, l1: 0.026624, l2: 0.033273, l3: 0.033102, l4: 0.037902, l5: 0.037862, l6: 0.036737

[epoch:  37/100000, batch:    52/  187, ite: 3410] train loss: 0.540305, tar: 0.067551 
l0: 0.091954, l1: 0.095917, l2: 0.127544, l3: 0.109191, l4: 0.107139, l5: 0.115595, l6: 0.104487

[epoch:  37/100000, batch:    54/  187, ite: 3411] train loss: 0.540455, tar: 0.067568 
l0: 0.130372, l1: 0.134177, l2: 0.111624, l3: 0.109247, l4: 0.126420, l5: 0.157485, l6: 0.216291

[epoch:  37/100000, batch:    56/  187, ite: 3412] train loss: 0.540770, tar: 0.067613 
l0: 0.035663, l1: 0.028310, l2: 0.057834, l3: 0.062265, l4: 0.094858, l5: 0.107829, l6: 0.093356

[epoch:  37/100000, batch:    58/  187, ite: 3413] train loss: 0.540727, tar: 0.067590 
l0: 0.071996, l1: 0.072921, l2: 0.088924, l3: 0.096352, l4: 0.068726, l5: 0.069892, l6: 0.075486

[epoch:  37/100000, batch:    60/  187, ite: 3414] train loss: 0.540729, tar: 0.067593 
l0: 0.083208, l1: 0.083804, l2: 0.077086, l3: 0.081337, l4: 0.096348, l5: 0.125373, l6: 0.121312

[epoch:  37/100000, batch:    62/  187, ite: 3415] train loss: 0.540820, tar: 0.067604 
l0: 0.099713, l1: 0.046634, l2: 0.048246, l3: 0.077505, l4: 0.230657, l5: 0.495608, l6: 0.186014

[epoch:  37/100000, batch:    64/  187, ite: 3416] train loss: 0.541274, tar: 0.067627 
l0: 0.051024, l1: 0.051932, l2: 0.060256, l3: 0.060768, l4: 0.056832, l5: 0.063053, l6: 0.059759

[epoch:  37/100000, batch:    66/  187, ite: 3417] train loss: 0.541177, tar: 0.067615 
l0: 0.061696, l1: 0.069250, l2: 0.090791, l3: 0.078741, l4: 0.076585, l5: 0.073384, l6: 0.079063

[epoch:  37/100000, batch:    68/  187, ite: 3418] train loss: 0.541169, tar: 0.067611 
l0: 0.067450, l1: 0.073423, l2: 0.070177, l3: 0.070897, l4: 0.079137, l5: 0.080992, l6: 0.089894

[epoch:  37/100000, batch:    70/  187, ite: 3419] train loss: 0.541162, tar: 0.067611 
l0: 0.059497, l1: 0.057833, l2: 0.046737, l3: 0.057159, l4: 0.074264, l5: 0.083457, l6: 0.117593

[epoch:  37/100000, batch:    72/  187, ite: 3420] train loss: 0.541131, tar: 0.067605 
l0: 0.071604, l1: 0.073131, l2: 0.101919, l3: 0.102496, l4: 0.080098, l5: 0.069860, l6: 0.090457

[epoch:  37/100000, batch:    74/  187, ite: 3421] train loss: 0.541165, tar: 0.067608 
l0: 0.040461, l1: 0.044734, l2: 0.044909, l3: 0.042122, l4: 0.052578, l5: 0.053895, l6: 0.061755

[epoch:  37/100000, batch:    76/  187, ite: 3422] train loss: 0.541024, tar: 0.067589 
l0: 0.050297, l1: 0.049614, l2: 0.049884, l3: 0.054027, l4: 0.062622, l5: 0.070265, l6: 0.076119

[epoch:  37/100000, batch:    78/  187, ite: 3423] train loss: 0.540934, tar: 0.067577 
l0: 0.052507, l1: 0.041369, l2: 0.067156, l3: 0.078605, l4: 0.093295, l5: 0.100924, l6: 0.104661

[epoch:  37/100000, batch:    80/  187, ite: 3424] train loss: 0.540932, tar: 0.067566 
l0: 0.072440, l1: 0.069411, l2: 0.104888, l3: 0.111244, l4: 0.115096, l5: 0.099257, l6: 0.087517

[epoch:  37/100000, batch:    82/  187, ite: 3425] train loss: 0.541016, tar: 0.067570 
l0: 0.077594, l1: 0.082588, l2: 0.094740, l3: 0.109871, l4: 0.116726, l5: 0.107978, l6: 0.135687

[epoch:  37/100000, batch:    84/  187, ite: 3426] train loss: 0.541145, tar: 0.067577 
l0: 0.195734, l1: 0.189878, l2: 0.226989, l3: 0.233435, l4: 0.220136, l5: 0.228247, l6: 0.309045

[epoch:  37/100000, batch:    86/  187, ite: 3427] train loss: 0.541889, tar: 0.067667 
l0: 0.050544, l1: 0.043945, l2: 0.056369, l3: 0.060899, l4: 0.084723, l5: 0.087228, l6: 0.115424

[epoch:  37/100000, batch:    88/  187, ite: 3428] train loss: 0.541859, tar: 0.067655 
l0: 0.113730, l1: 0.102538, l2: 0.145645, l3: 0.166293, l4: 0.202781, l5: 0.175628, l6: 0.198908

[epoch:  37/100000, batch:    90/  187, ite: 3429] train loss: 0.542254, tar: 0.067687 
l0: 0.046790, l1: 0.043910, l2: 0.050144, l3: 0.053688, l4: 0.084749, l5: 0.078612, l6: 0.081650

[epoch:  37/100000, batch:    92/  187, ite: 3430] train loss: 0.542182, tar: 0.067672 
l0: 0.044828, l1: 0.039025, l2: 0.043445, l3: 0.049567, l4: 0.073725, l5: 0.089901, l6: 0.084761

[epoch:  37/100000, batch:    94/  187, ite: 3431] train loss: 0.542100, tar: 0.067656 
l0: 0.077385, l1: 0.070957, l2: 0.112904, l3: 0.109842, l4: 0.125376, l5: 0.114213, l6: 0.140583

[epoch:  37/100000, batch:    96/  187, ite: 3432] train loss: 0.542246, tar: 0.067663 
l0: 0.078849, l1: 0.071833, l2: 0.105124, l3: 0.099860, l4: 0.109322, l5: 0.119545, l6: 0.090468

[epoch:  37/100000, batch:    98/  187, ite: 3433] train loss: 0.542339, tar: 0.067671 
l0: 0.049842, l1: 0.046501, l2: 0.064754, l3: 0.069811, l4: 0.080190, l5: 0.077516, l6: 0.097665

[epoch:  37/100000, batch:   100/  187, ite: 3434] train loss: 0.542300, tar: 0.067658 
l0: 0.083619, l1: 0.085194, l2: 0.116151, l3: 0.114173, l4: 0.118386, l5: 0.108487, l6: 0.102224

[epoch:  37/100000, batch:   102/  187, ite: 3435] train loss: 0.542429, tar: 0.067670 
l0: 0.046309, l1: 0.043443, l2: 0.061693, l3: 0.059771, l4: 0.097235, l5: 0.095269, l6: 0.117571

[epoch:  37/100000, batch:   104/  187, ite: 3436] train loss: 0.542415, tar: 0.067655 
l0: 0.073070, l1: 0.072319, l2: 0.061877, l3: 0.067144, l4: 0.100983, l5: 0.105807, l6: 0.106035

[epoch:  37/100000, batch:   106/  187, ite: 3437] train loss: 0.542446, tar: 0.067658 
l0: 0.056856, l1: 0.044454, l2: 0.078525, l3: 0.079970, l4: 0.114990, l5: 0.125134, l6: 0.124086

[epoch:  37/100000, batch:   108/  187, ite: 3438] train loss: 0.542502, tar: 0.067651 
l0: 0.055197, l1: 0.053809, l2: 0.075463, l3: 0.068437, l4: 0.082469, l5: 0.090648, l6: 0.070040

[epoch:  37/100000, batch:   110/  187, ite: 3439] train loss: 0.542470, tar: 0.067642 
l0: 0.034088, l1: 0.034279, l2: 0.056983, l3: 0.054629, l4: 0.075331, l5: 0.074486, l6: 0.087212

[epoch:  37/100000, batch:   112/  187, ite: 3440] train loss: 0.542383, tar: 0.067619 
l0: 0.061495, l1: 0.055919, l2: 0.069061, l3: 0.068640, l4: 0.093433, l5: 0.104916, l6: 0.130387

[epoch:  37/100000, batch:   114/  187, ite: 3441] train loss: 0.542412, tar: 0.067615 
l0: 0.078475, l1: 0.084631, l2: 0.092851, l3: 0.100576, l4: 0.095422, l5: 0.100600, l6: 0.116627

[epoch:  37/100000, batch:   116/  187, ite: 3442] train loss: 0.542500, tar: 0.067622 
l0: 0.046505, l1: 0.043998, l2: 0.057259, l3: 0.061353, l4: 0.069167, l5: 0.070784, l6: 0.076152

[epoch:  37/100000, batch:   118/  187, ite: 3443] train loss: 0.542419, tar: 0.067608 
l0: 0.077667, l1: 0.070206, l2: 0.099072, l3: 0.105571, l4: 0.106295, l5: 0.102886, l6: 0.146168

[epoch:  37/100000, batch:   120/  187, ite: 3444] train loss: 0.542533, tar: 0.067615 
l0: 0.071465, l1: 0.082773, l2: 0.072107, l3: 0.069374, l4: 0.071572, l5: 0.085803, l6: 0.085710

[epoch:  37/100000, batch:   122/  187, ite: 3445] train loss: 0.542530, tar: 0.067617 
l0: 0.053358, l1: 0.066351, l2: 0.050869, l3: 0.048580, l4: 0.048540, l5: 0.062214, l6: 0.044977

[epoch:  37/100000, batch:   124/  187, ite: 3446] train loss: 0.542415, tar: 0.067607 
l0: 0.053367, l1: 0.046442, l2: 0.070990, l3: 0.072284, l4: 0.104156, l5: 0.117016, l6: 0.107397

[epoch:  37/100000, batch:   126/  187, ite: 3447] train loss: 0.542435, tar: 0.067598 
l0: 0.087160, l1: 0.086704, l2: 0.104365, l3: 0.103276, l4: 0.114115, l5: 0.102045, l6: 0.116367

[epoch:  37/100000, batch:   128/  187, ite: 3448] train loss: 0.542553, tar: 0.067611 
l0: 0.065501, l1: 0.058535, l2: 0.091642, l3: 0.100906, l4: 0.086337, l5: 0.077109, l6: 0.079549

[epoch:  37/100000, batch:   130/  187, ite: 3449] train loss: 0.542565, tar: 0.067610 
l0: 0.056468, l1: 0.054403, l2: 0.062427, l3: 0.066638, l4: 0.085592, l5: 0.091466, l6: 0.103024

[epoch:  37/100000, batch:   132/  187, ite: 3450] train loss: 0.542549, tar: 0.067602 
l0: 0.056882, l1: 0.070776, l2: 0.057263, l3: 0.059514, l4: 0.056340, l5: 0.053226, l6: 0.057453

[epoch:  37/100000, batch:   134/  187, ite: 3451] train loss: 0.542459, tar: 0.067595 
l0: 0.050149, l1: 0.072526, l2: 0.041242, l3: 0.032390, l4: 0.044344, l5: 0.046350, l6: 0.042861

[epoch:  37/100000, batch:   136/  187, ite: 3452] train loss: 0.542313, tar: 0.067583 
l0: 0.080876, l1: 0.086297, l2: 0.093904, l3: 0.098311, l4: 0.106799, l5: 0.115888, l6: 0.120970

[epoch:  37/100000, batch:   138/  187, ite: 3453] train loss: 0.542423, tar: 0.067592 
l0: 0.070015, l1: 0.076747, l2: 0.068833, l3: 0.078719, l4: 0.088902, l5: 0.085958, l6: 0.105275

[epoch:  37/100000, batch:   140/  187, ite: 3454] train loss: 0.542445, tar: 0.067593 
l0: 0.053208, l1: 0.050846, l2: 0.063232, l3: 0.067946, l4: 0.083858, l5: 0.088992, l6: 0.092092

[epoch:  37/100000, batch:   142/  187, ite: 3455] train loss: 0.542416, tar: 0.067583 
l0: 0.045776, l1: 0.036415, l2: 0.067819, l3: 0.076814, l4: 0.074058, l5: 0.086591, l6: 0.080122

[epoch:  37/100000, batch:   144/  187, ite: 3456] train loss: 0.542365, tar: 0.067568 
l0: 0.059238, l1: 0.047623, l2: 0.089938, l3: 0.096469, l4: 0.104669, l5: 0.117323, l6: 0.115907

[epoch:  37/100000, batch:   146/  187, ite: 3457] train loss: 0.542426, tar: 0.067563 
l0: 0.065219, l1: 0.067297, l2: 0.060654, l3: 0.066846, l4: 0.082904, l5: 0.092714, l6: 0.080925

[epoch:  37/100000, batch:   148/  187, ite: 3458] train loss: 0.542408, tar: 0.067561 
l0: 0.060974, l1: 0.065966, l2: 0.070535, l3: 0.068669, l4: 0.064723, l5: 0.068309, l6: 0.088440

[epoch:  37/100000, batch:   150/  187, ite: 3459] train loss: 0.542371, tar: 0.067557 
l0: 0.048061, l1: 0.049739, l2: 0.058309, l3: 0.056628, l4: 0.061810, l5: 0.064980, l6: 0.069782

[epoch:  37/100000, batch:   152/  187, ite: 3460] train loss: 0.542279, tar: 0.067543 
l0: 0.091085, l1: 0.093970, l2: 0.128044, l3: 0.102124, l4: 0.125739, l5: 0.145912, l6: 0.121127

[epoch:  37/100000, batch:   154/  187, ite: 3461] train loss: 0.542461, tar: 0.067559 
l0: 0.077578, l1: 0.094757, l2: 0.072364, l3: 0.065095, l4: 0.052436, l5: 0.070672, l6: 0.065115

[epoch:  37/100000, batch:   156/  187, ite: 3462] train loss: 0.542431, tar: 0.067566 
l0: 0.053753, l1: 0.056265, l2: 0.074880, l3: 0.086486, l4: 0.071247, l5: 0.062683, l6: 0.062910

[epoch:  37/100000, batch:   158/  187, ite: 3463] train loss: 0.542380, tar: 0.067557 
l0: 0.096975, l1: 0.114734, l2: 0.089572, l3: 0.094755, l4: 0.083948, l5: 0.097725, l6: 0.096546

[epoch:  37/100000, batch:   160/  187, ite: 3464] train loss: 0.542470, tar: 0.067577 
l0: 0.037125, l1: 0.041301, l2: 0.054791, l3: 0.051932, l4: 0.040813, l5: 0.051353, l6: 0.040482

[epoch:  37/100000, batch:   162/  187, ite: 3465] train loss: 0.542317, tar: 0.067556 
l0: 0.058108, l1: 0.054921, l2: 0.068578, l3: 0.075128, l4: 0.077596, l5: 0.090289, l6: 0.090189

[epoch:  37/100000, batch:   164/  187, ite: 3466] train loss: 0.542298, tar: 0.067550 
l0: 0.049263, l1: 0.046512, l2: 0.061662, l3: 0.073468, l4: 0.079841, l5: 0.079697, l6: 0.085993

[epoch:  37/100000, batch:   166/  187, ite: 3467] train loss: 0.542253, tar: 0.067537 
l0: 0.061887, l1: 0.058257, l2: 0.083549, l3: 0.081678, l4: 0.101182, l5: 0.094358, l6: 0.088090

[epoch:  37/100000, batch:   168/  187, ite: 3468] train loss: 0.542271, tar: 0.067533 
l0: 0.060410, l1: 0.055524, l2: 0.071640, l3: 0.073682, l4: 0.110073, l5: 0.106718, l6: 0.112212

[epoch:  37/100000, batch:   170/  187, ite: 3469] train loss: 0.542304, tar: 0.067529 
l0: 0.047213, l1: 0.048283, l2: 0.057600, l3: 0.056181, l4: 0.074545, l5: 0.083846, l6: 0.070930

[epoch:  37/100000, batch:   172/  187, ite: 3470] train loss: 0.542234, tar: 0.067515 
l0: 0.047599, l1: 0.047826, l2: 0.047365, l3: 0.057784, l4: 0.071922, l5: 0.075450, l6: 0.072473

[epoch:  37/100000, batch:   174/  187, ite: 3471] train loss: 0.542151, tar: 0.067501 
l0: 0.038733, l1: 0.034568, l2: 0.044638, l3: 0.046835, l4: 0.085789, l5: 0.074814, l6: 0.080967

[epoch:  37/100000, batch:   176/  187, ite: 3472] train loss: 0.542059, tar: 0.067482 
l0: 0.058011, l1: 0.060826, l2: 0.053145, l3: 0.055314, l4: 0.065810, l5: 0.074856, l6: 0.091457

[epoch:  37/100000, batch:   178/  187, ite: 3473] train loss: 0.542002, tar: 0.067475 
l0: 0.044663, l1: 0.038361, l2: 0.057190, l3: 0.061250, l4: 0.065943, l5: 0.077068, l6: 0.062901

[epoch:  37/100000, batch:   180/  187, ite: 3474] train loss: 0.541911, tar: 0.067460 
l0: 0.050570, l1: 0.050087, l2: 0.053606, l3: 0.063592, l4: 0.085154, l5: 0.071765, l6: 0.070268

[epoch:  37/100000, batch:   182/  187, ite: 3475] train loss: 0.541845, tar: 0.067448 
l0: 0.055163, l1: 0.052087, l2: 0.070897, l3: 0.077815, l4: 0.083760, l5: 0.083281, l6: 0.066080

[epoch:  37/100000, batch:   184/  187, ite: 3476] train loss: 0.541810, tar: 0.067440 
l0: 0.061745, l1: 0.054363, l2: 0.094171, l3: 0.108393, l4: 0.096822, l5: 0.080939, l6: 0.078321

[epoch:  37/100000, batch:   186/  187, ite: 3477] train loss: 0.541832, tar: 0.067436 
l0: 0.044444, l1: 0.037841, l2: 0.057092, l3: 0.069413, l4: 0.061921, l5: 0.065418, l6: 0.065193

[epoch:  37/100000, batch:   188/  187, ite: 3478] train loss: 0.541737, tar: 0.067421 
l0: 0.064247, l1: 0.063460, l2: 0.077294, l3: 0.083683, l4: 0.090250, l5: 0.086670, l6: 0.072585

[epoch:  38/100000, batch:     2/  187, ite: 3479] train loss: 0.541734, tar: 0.067418 
l0: 0.035377, l1: 0.037413, l2: 0.045107, l3: 0.047278, l4: 0.052412, l5: 0.057048, l6: 0.060402

[epoch:  38/100000, batch:     4/  187, ite: 3480] train loss: 0.541595, tar: 0.067397 
l0: 0.035293, l1: 0.040837, l2: 0.038368, l3: 0.037713, l4: 0.051912, l5: 0.051530, l6: 0.044590

[epoch:  38/100000, batch:     6/  187, ite: 3481] train loss: 0.541432, tar: 0.067375 
l0: 0.059318, l1: 0.055463, l2: 0.063634, l3: 0.064877, l4: 0.103467, l5: 0.107388, l6: 0.094695

[epoch:  38/100000, batch:     8/  187, ite: 3482] train loss: 0.541437, tar: 0.067370 
l0: 0.027880, l1: 0.026436, l2: 0.049153, l3: 0.058780, l4: 0.079525, l5: 0.073946, l6: 0.064855

[epoch:  38/100000, batch:    10/  187, ite: 3483] train loss: 0.541328, tar: 0.067343 
l0: 0.050326, l1: 0.047656, l2: 0.058523, l3: 0.062382, l4: 0.064387, l5: 0.069533, l6: 0.063615

[epoch:  38/100000, batch:    12/  187, ite: 3484] train loss: 0.541244, tar: 0.067332 
l0: 0.036073, l1: 0.036504, l2: 0.044925, l3: 0.037821, l4: 0.054954, l5: 0.064153, l6: 0.076465

[epoch:  38/100000, batch:    14/  187, ite: 3485] train loss: 0.541116, tar: 0.067310 
l0: 0.040758, l1: 0.042828, l2: 0.040281, l3: 0.047362, l4: 0.060884, l5: 0.060399, l6: 0.063461

[epoch:  38/100000, batch:    16/  187, ite: 3486] train loss: 0.540991, tar: 0.067293 
l0: 0.046132, l1: 0.044800, l2: 0.049460, l3: 0.052093, l4: 0.075160, l5: 0.066603, l6: 0.059415

[epoch:  38/100000, batch:    18/  187, ite: 3487] train loss: 0.540892, tar: 0.067278 
l0: 0.073959, l1: 0.088826, l2: 0.054005, l3: 0.066947, l4: 0.084065, l5: 0.090582, l6: 0.093354

[epoch:  38/100000, batch:    20/  187, ite: 3488] train loss: 0.540900, tar: 0.067283 
l0: 0.059770, l1: 0.049222, l2: 0.060635, l3: 0.066534, l4: 0.125421, l5: 0.129369, l6: 0.156769

[epoch:  38/100000, batch:    22/  187, ite: 3489] train loss: 0.540971, tar: 0.067278 
l0: 0.042075, l1: 0.035687, l2: 0.070899, l3: 0.073388, l4: 0.084594, l5: 0.088359, l6: 0.095639

[epoch:  38/100000, batch:    24/  187, ite: 3490] train loss: 0.540938, tar: 0.067261 
l0: 0.048579, l1: 0.045859, l2: 0.045339, l3: 0.060297, l4: 0.069108, l5: 0.076479, l6: 0.083873

[epoch:  38/100000, batch:    26/  187, ite: 3491] train loss: 0.540863, tar: 0.067248 
l0: 0.047421, l1: 0.053409, l2: 0.058781, l3: 0.068934, l4: 0.064948, l5: 0.068060, l6: 0.070005

[epoch:  38/100000, batch:    28/  187, ite: 3492] train loss: 0.540790, tar: 0.067235 
l0: 0.049116, l1: 0.060270, l2: 0.045170, l3: 0.048650, l4: 0.054794, l5: 0.048370, l6: 0.049045

[epoch:  38/100000, batch:    30/  187, ite: 3493] train loss: 0.540665, tar: 0.067223 
l0: 0.035002, l1: 0.036783, l2: 0.045996, l3: 0.052532, l4: 0.059864, l5: 0.051152, l6: 0.061857

[epoch:  38/100000, batch:    32/  187, ite: 3494] train loss: 0.540533, tar: 0.067201 
l0: 0.033149, l1: 0.028444, l2: 0.035355, l3: 0.044384, l4: 0.063336, l5: 0.066049, l6: 0.067020

[epoch:  38/100000, batch:    34/  187, ite: 3495] train loss: 0.540398, tar: 0.067179 
l0: 0.044253, l1: 0.042144, l2: 0.039525, l3: 0.052210, l4: 0.071480, l5: 0.093323, l6: 0.082645

[epoch:  38/100000, batch:    36/  187, ite: 3496] train loss: 0.540321, tar: 0.067163 
l0: 0.062928, l1: 0.063071, l2: 0.058376, l3: 0.067236, l4: 0.096788, l5: 0.102458, l6: 0.100216

[epoch:  38/100000, batch:    38/  187, ite: 3497] train loss: 0.540328, tar: 0.067160 
l0: 0.042831, l1: 0.041205, l2: 0.046365, l3: 0.052642, l4: 0.063989, l5: 0.068345, l6: 0.068141

[epoch:  38/100000, batch:    40/  187, ite: 3498] train loss: 0.540223, tar: 0.067144 
l0: 0.059109, l1: 0.053896, l2: 0.078335, l3: 0.086553, l4: 0.073702, l5: 0.073988, l6: 0.082654

[epoch:  38/100000, batch:    42/  187, ite: 3499] train loss: 0.540202, tar: 0.067139 
l0: 0.030276, l1: 0.028075, l2: 0.043515, l3: 0.039105, l4: 0.038626, l5: 0.046089, l6: 0.042089

[epoch:  38/100000, batch:    44/  187, ite: 3500] train loss: 0.540020, tar: 0.067114 
l0: 0.035637, l1: 0.034302, l2: 0.028158, l3: 0.046192, l4: 0.064064, l5: 0.074381, l6: 0.082850

[epoch:  38/100000, batch:    46/  187, ite: 3501] train loss: 0.539904, tar: 0.067093 
l0: 0.039319, l1: 0.038194, l2: 0.043863, l3: 0.054062, l4: 0.081687, l5: 0.067239, l6: 0.064120

[epoch:  38/100000, batch:    48/  187, ite: 3502] train loss: 0.539803, tar: 0.067075 
l0: 0.022486, l1: 0.030094, l2: 0.036840, l3: 0.031170, l4: 0.027845, l5: 0.030959, l6: 0.030001

[epoch:  38/100000, batch:    50/  187, ite: 3503] train loss: 0.539584, tar: 0.067045 
l0: 0.036887, l1: 0.035229, l2: 0.041781, l3: 0.044998, l4: 0.059361, l5: 0.064164, l6: 0.072954

[epoch:  38/100000, batch:    52/  187, ite: 3504] train loss: 0.539461, tar: 0.067025 
l0: 0.033878, l1: 0.040169, l2: 0.037497, l3: 0.033102, l4: 0.050535, l5: 0.055677, l6: 0.047923

[epoch:  38/100000, batch:    54/  187, ite: 3505] train loss: 0.539301, tar: 0.067003 
l0: 0.049452, l1: 0.054140, l2: 0.046581, l3: 0.047992, l4: 0.061131, l5: 0.070719, l6: 0.067810

[epoch:  38/100000, batch:    56/  187, ite: 3506] train loss: 0.539207, tar: 0.066991 
l0: 0.034902, l1: 0.038428, l2: 0.046996, l3: 0.038438, l4: 0.065453, l5: 0.062229, l6: 0.065006

[epoch:  38/100000, batch:    58/  187, ite: 3507] train loss: 0.539083, tar: 0.066970 
l0: 0.087418, l1: 0.093516, l2: 0.101474, l3: 0.083690, l4: 0.087526, l5: 0.088967, l6: 0.102573

[epoch:  38/100000, batch:    60/  187, ite: 3508] train loss: 0.539153, tar: 0.066984 
l0: 0.060081, l1: 0.049989, l2: 0.076121, l3: 0.088428, l4: 0.072551, l5: 0.087244, l6: 0.110958

[epoch:  38/100000, batch:    62/  187, ite: 3509] train loss: 0.539157, tar: 0.066979 
l0: 0.051609, l1: 0.053522, l2: 0.069386, l3: 0.061607, l4: 0.054439, l5: 0.057972, l6: 0.065380

[epoch:  38/100000, batch:    64/  187, ite: 3510] train loss: 0.539074, tar: 0.066969 
l0: 0.105400, l1: 0.109369, l2: 0.120539, l3: 0.141149, l4: 0.116391, l5: 0.116799, l6: 0.129899

[epoch:  38/100000, batch:    66/  187, ite: 3511] train loss: 0.539273, tar: 0.066994 
l0: 0.061684, l1: 0.063615, l2: 0.060353, l3: 0.066418, l4: 0.092276, l5: 0.090731, l6: 0.123014

[epoch:  38/100000, batch:    68/  187, ite: 3512] train loss: 0.539285, tar: 0.066991 
l0: 0.045384, l1: 0.036326, l2: 0.047022, l3: 0.060733, l4: 0.075411, l5: 0.091308, l6: 0.100649

[epoch:  38/100000, batch:    70/  187, ite: 3513] train loss: 0.539231, tar: 0.066977 
l0: 0.052176, l1: 0.046764, l2: 0.068388, l3: 0.062438, l4: 0.072307, l5: 0.084170, l6: 0.083125

[epoch:  38/100000, batch:    72/  187, ite: 3514] train loss: 0.539185, tar: 0.066967 
l0: 0.050700, l1: 0.046361, l2: 0.067234, l3: 0.068728, l4: 0.080368, l5: 0.086564, l6: 0.080391

[epoch:  38/100000, batch:    74/  187, ite: 3515] train loss: 0.539146, tar: 0.066956 
l0: 0.088378, l1: 0.094262, l2: 0.103070, l3: 0.107288, l4: 0.126309, l5: 0.117043, l6: 0.110766

[epoch:  38/100000, batch:    76/  187, ite: 3516] train loss: 0.539283, tar: 0.066970 
l0: 0.075133, l1: 0.086326, l2: 0.099121, l3: 0.093095, l4: 0.073176, l5: 0.079005, l6: 0.100135

[epoch:  38/100000, batch:    78/  187, ite: 3517] train loss: 0.539327, tar: 0.066976 
l0: 0.052050, l1: 0.045401, l2: 0.065613, l3: 0.070549, l4: 0.078587, l5: 0.093122, l6: 0.068387

[epoch:  38/100000, batch:    80/  187, ite: 3518] train loss: 0.539284, tar: 0.066966 
l0: 0.063513, l1: 0.057263, l2: 0.083573, l3: 0.075521, l4: 0.083184, l5: 0.095693, l6: 0.090500

[epoch:  38/100000, batch:    82/  187, ite: 3519] train loss: 0.539290, tar: 0.066963 
l0: 0.045201, l1: 0.038635, l2: 0.055192, l3: 0.060326, l4: 0.070150, l5: 0.084467, l6: 0.074195

[epoch:  38/100000, batch:    84/  187, ite: 3520] train loss: 0.539217, tar: 0.066949 
l0: 0.041541, l1: 0.039680, l2: 0.053481, l3: 0.068841, l4: 0.051836, l5: 0.059823, l6: 0.052621

[epoch:  38/100000, batch:    86/  187, ite: 3521] train loss: 0.539105, tar: 0.066932 
l0: 0.060079, l1: 0.055370, l2: 0.069664, l3: 0.072572, l4: 0.070767, l5: 0.080541, l6: 0.085807

[epoch:  38/100000, batch:    88/  187, ite: 3522] train loss: 0.539076, tar: 0.066928 
l0: 0.060806, l1: 0.066253, l2: 0.079305, l3: 0.071529, l4: 0.075760, l5: 0.075274, l6: 0.089555

[epoch:  38/100000, batch:    90/  187, ite: 3523] train loss: 0.539062, tar: 0.066924 
l0: 0.046942, l1: 0.037303, l2: 0.053026, l3: 0.058372, l4: 0.070584, l5: 0.095648, l6: 0.096907

[epoch:  38/100000, batch:    92/  187, ite: 3524] train loss: 0.539009, tar: 0.066911 
l0: 0.045945, l1: 0.041515, l2: 0.050764, l3: 0.051359, l4: 0.084447, l5: 0.095738, l6: 0.081944

[epoch:  38/100000, batch:    94/  187, ite: 3525] train loss: 0.538952, tar: 0.066897 
l0: 0.038496, l1: 0.040163, l2: 0.050981, l3: 0.059484, l4: 0.092633, l5: 0.078814, l6: 0.067891

[epoch:  38/100000, batch:    96/  187, ite: 3526] train loss: 0.538880, tar: 0.066878 
l0: 0.037934, l1: 0.039198, l2: 0.047318, l3: 0.049680, l4: 0.045741, l5: 0.048357, l6: 0.048439

[epoch:  38/100000, batch:    98/  187, ite: 3527] train loss: 0.538734, tar: 0.066859 
l0: 0.036857, l1: 0.032039, l2: 0.042952, l3: 0.044888, l4: 0.076082, l5: 0.077370, l6: 0.073972

[epoch:  38/100000, batch:   100/  187, ite: 3528] train loss: 0.538633, tar: 0.066840 
l0: 0.031503, l1: 0.030865, l2: 0.036854, l3: 0.036063, l4: 0.042961, l5: 0.042629, l6: 0.055075

[epoch:  38/100000, batch:   102/  187, ite: 3529] train loss: 0.538461, tar: 0.066817 
l0: 0.040637, l1: 0.037830, l2: 0.052641, l3: 0.057703, l4: 0.083741, l5: 0.081861, l6: 0.085868

[epoch:  38/100000, batch:   104/  187, ite: 3530] train loss: 0.538397, tar: 0.066800 
l0: 0.066898, l1: 0.063733, l2: 0.072691, l3: 0.075269, l4: 0.090591, l5: 0.098417, l6: 0.090291

[epoch:  38/100000, batch:   106/  187, ite: 3531] train loss: 0.538410, tar: 0.066800 
l0: 0.040296, l1: 0.036506, l2: 0.060135, l3: 0.067772, l4: 0.089087, l5: 0.082261, l6: 0.062590

[epoch:  38/100000, batch:   108/  187, ite: 3532] train loss: 0.538345, tar: 0.066782 
l0: 0.064488, l1: 0.071558, l2: 0.067013, l3: 0.063572, l4: 0.056207, l5: 0.060023, l6: 0.055221

[epoch:  38/100000, batch:   110/  187, ite: 3533] train loss: 0.538279, tar: 0.066781 
l0: 0.085853, l1: 0.083006, l2: 0.082774, l3: 0.087250, l4: 0.118036, l5: 0.138071, l6: 0.127626

[epoch:  38/100000, batch:   112/  187, ite: 3534] train loss: 0.538399, tar: 0.066793 
l0: 0.048419, l1: 0.054463, l2: 0.074162, l3: 0.059291, l4: 0.050166, l5: 0.058395, l6: 0.053824

[epoch:  38/100000, batch:   114/  187, ite: 3535] train loss: 0.538308, tar: 0.066781 
l0: 0.069095, l1: 0.071354, l2: 0.086858, l3: 0.077181, l4: 0.071011, l5: 0.068695, l6: 0.068734

[epoch:  38/100000, batch:   116/  187, ite: 3536] train loss: 0.538292, tar: 0.066783 
l0: 0.060279, l1: 0.059099, l2: 0.076453, l3: 0.074472, l4: 0.085836, l5: 0.090161, l6: 0.095405

[epoch:  38/100000, batch:   118/  187, ite: 3537] train loss: 0.538294, tar: 0.066779 
l0: 0.035091, l1: 0.034142, l2: 0.041634, l3: 0.042688, l4: 0.048660, l5: 0.056545, l6: 0.052457

[epoch:  38/100000, batch:   120/  187, ite: 3538] train loss: 0.538147, tar: 0.066758 
l0: 0.039995, l1: 0.038462, l2: 0.051203, l3: 0.054730, l4: 0.069789, l5: 0.069514, l6: 0.060458

[epoch:  38/100000, batch:   122/  187, ite: 3539] train loss: 0.538046, tar: 0.066741 
l0: 0.052997, l1: 0.060319, l2: 0.059223, l3: 0.059200, l4: 0.055020, l5: 0.060517, l6: 0.055487

[epoch:  38/100000, batch:   124/  187, ite: 3540] train loss: 0.537959, tar: 0.066732 
l0: 0.037349, l1: 0.033015, l2: 0.049929, l3: 0.050742, l4: 0.070295, l5: 0.074433, l6: 0.067785

[epoch:  38/100000, batch:   126/  187, ite: 3541] train loss: 0.537858, tar: 0.066713 
l0: 0.042716, l1: 0.043062, l2: 0.061386, l3: 0.061942, l4: 0.060388, l5: 0.064565, l6: 0.069413

[epoch:  38/100000, batch:   128/  187, ite: 3542] train loss: 0.537771, tar: 0.066697 
l0: 0.052920, l1: 0.054367, l2: 0.057799, l3: 0.058600, l4: 0.067070, l5: 0.070118, l6: 0.069270

[epoch:  38/100000, batch:   130/  187, ite: 3543] train loss: 0.537702, tar: 0.066688 
l0: 0.078055, l1: 0.096695, l2: 0.068814, l3: 0.058473, l4: 0.062710, l5: 0.068747, l6: 0.082691

[epoch:  38/100000, batch:   132/  187, ite: 3544] train loss: 0.537688, tar: 0.066696 
l0: 0.039022, l1: 0.037779, l2: 0.044663, l3: 0.058256, l4: 0.067302, l5: 0.066924, l6: 0.073158

[epoch:  38/100000, batch:   134/  187, ite: 3545] train loss: 0.537590, tar: 0.066678 
l0: 0.045769, l1: 0.041580, l2: 0.043403, l3: 0.045429, l4: 0.080590, l5: 0.075856, l6: 0.094631

[epoch:  38/100000, batch:   136/  187, ite: 3546] train loss: 0.537519, tar: 0.066664 
l0: 0.049584, l1: 0.045321, l2: 0.057330, l3: 0.057774, l4: 0.074804, l5: 0.068061, l6: 0.079706

[epoch:  38/100000, batch:   138/  187, ite: 3547] train loss: 0.537451, tar: 0.066653 
l0: 0.046110, l1: 0.036804, l2: 0.050954, l3: 0.051141, l4: 0.084875, l5: 0.111768, l6: 0.102345

[epoch:  38/100000, batch:   140/  187, ite: 3548] train loss: 0.537416, tar: 0.066640 
l0: 0.037920, l1: 0.032930, l2: 0.040878, l3: 0.049460, l4: 0.062429, l5: 0.066193, l6: 0.073022

[epoch:  38/100000, batch:   142/  187, ite: 3549] train loss: 0.537304, tar: 0.066621 
l0: 0.059382, l1: 0.059210, l2: 0.053956, l3: 0.058615, l4: 0.073306, l5: 0.084169, l6: 0.085836

[epoch:  38/100000, batch:   144/  187, ite: 3550] train loss: 0.537263, tar: 0.066617 
l0: 0.040776, l1: 0.049489, l2: 0.049705, l3: 0.042030, l4: 0.061159, l5: 0.075405, l6: 0.086071

[epoch:  38/100000, batch:   146/  187, ite: 3551] train loss: 0.537178, tar: 0.066600 
l0: 0.055392, l1: 0.061533, l2: 0.064732, l3: 0.070623, l4: 0.054931, l5: 0.049763, l6: 0.060197

[epoch:  38/100000, batch:   148/  187, ite: 3552] train loss: 0.537100, tar: 0.066593 
l0: 0.066477, l1: 0.069197, l2: 0.076871, l3: 0.084819, l4: 0.072800, l5: 0.075454, l6: 0.070516

[epoch:  38/100000, batch:   150/  187, ite: 3553] train loss: 0.537087, tar: 0.066593 
l0: 0.041932, l1: 0.042307, l2: 0.051034, l3: 0.049572, l4: 0.071205, l5: 0.058394, l6: 0.068200

[epoch:  38/100000, batch:   152/  187, ite: 3554] train loss: 0.536987, tar: 0.066577 
l0: 0.078310, l1: 0.093597, l2: 0.051046, l3: 0.054285, l4: 0.081341, l5: 0.084262, l6: 0.096075

[epoch:  38/100000, batch:   154/  187, ite: 3555] train loss: 0.536989, tar: 0.066584 
l0: 0.036639, l1: 0.034914, l2: 0.050993, l3: 0.049059, l4: 0.056970, l5: 0.058877, l6: 0.070102

[epoch:  38/100000, batch:   156/  187, ite: 3556] train loss: 0.536873, tar: 0.066565 
l0: 0.053920, l1: 0.053930, l2: 0.059821, l3: 0.066262, l4: 0.128567, l5: 0.118773, l6: 0.101096

[epoch:  38/100000, batch:   158/  187, ite: 3557] train loss: 0.536903, tar: 0.066557 
l0: 0.057194, l1: 0.058793, l2: 0.075615, l3: 0.080881, l4: 0.089539, l5: 0.074570, l6: 0.063231

[epoch:  38/100000, batch:   160/  187, ite: 3558] train loss: 0.536879, tar: 0.066551 
l0: 0.050578, l1: 0.042552, l2: 0.056599, l3: 0.066481, l4: 0.137902, l5: 0.122344, l6: 0.133432

[epoch:  38/100000, batch:   162/  187, ite: 3559] train loss: 0.536926, tar: 0.066541 
l0: 0.031443, l1: 0.038068, l2: 0.043901, l3: 0.038127, l4: 0.054411, l5: 0.049386, l6: 0.034976

[epoch:  38/100000, batch:   164/  187, ite: 3560] train loss: 0.536768, tar: 0.066518 
l0: 0.035699, l1: 0.034141, l2: 0.046572, l3: 0.056564, l4: 0.064384, l5: 0.062204, l6: 0.063645

[epoch:  38/100000, batch:   166/  187, ite: 3561] train loss: 0.536656, tar: 0.066498 
l0: 0.106127, l1: 0.130339, l2: 0.095445, l3: 0.090497, l4: 0.088756, l5: 0.073778, l6: 0.080517

[epoch:  38/100000, batch:   168/  187, ite: 3562] train loss: 0.536739, tar: 0.066524 
l0: 0.039448, l1: 0.039153, l2: 0.041911, l3: 0.039583, l4: 0.058673, l5: 0.059792, l6: 0.065154

[epoch:  38/100000, batch:   170/  187, ite: 3563] train loss: 0.536615, tar: 0.066506 
l0: 0.050801, l1: 0.060418, l2: 0.049376, l3: 0.049972, l4: 0.068079, l5: 0.057100, l6: 0.049997

[epoch:  38/100000, batch:   172/  187, ite: 3564] train loss: 0.536519, tar: 0.066496 
l0: 0.064004, l1: 0.066805, l2: 0.063839, l3: 0.067455, l4: 0.072650, l5: 0.059364, l6: 0.066365

[epoch:  38/100000, batch:   174/  187, ite: 3565] train loss: 0.536470, tar: 0.066495 
l0: 0.047873, l1: 0.050501, l2: 0.050408, l3: 0.057270, l4: 0.051998, l5: 0.056512, l6: 0.050431

[epoch:  38/100000, batch:   176/  187, ite: 3566] train loss: 0.536361, tar: 0.066483 
l0: 0.032500, l1: 0.037001, l2: 0.033516, l3: 0.038564, l4: 0.036125, l5: 0.030458, l6: 0.032889

[epoch:  38/100000, batch:   178/  187, ite: 3567] train loss: 0.536172, tar: 0.066461 
l0: 0.053984, l1: 0.055210, l2: 0.061706, l3: 0.065283, l4: 0.070715, l5: 0.069526, l6: 0.077375

[epoch:  38/100000, batch:   180/  187, ite: 3568] train loss: 0.536120, tar: 0.066453 
l0: 0.057186, l1: 0.065593, l2: 0.059409, l3: 0.056572, l4: 0.070775, l5: 0.072795, l6: 0.072102

[epoch:  38/100000, batch:   182/  187, ite: 3569] train loss: 0.536068, tar: 0.066447 
l0: 0.048655, l1: 0.046428, l2: 0.048703, l3: 0.051009, l4: 0.083448, l5: 0.080552, l6: 0.090822

[epoch:  38/100000, batch:   184/  187, ite: 3570] train loss: 0.536013, tar: 0.066436 
l0: 0.059123, l1: 0.058974, l2: 0.071481, l3: 0.069199, l4: 0.110347, l5: 0.090020, l6: 0.099825

[epoch:  38/100000, batch:   186/  187, ite: 3571] train loss: 0.536027, tar: 0.066431 
l0: 0.127002, l1: 0.128220, l2: 0.138083, l3: 0.148149, l4: 0.099363, l5: 0.119389, l6: 0.132040

[epoch:  38/100000, batch:   188/  187, ite: 3572] train loss: 0.536254, tar: 0.066470 
l0: 0.082210, l1: 0.079136, l2: 0.083072, l3: 0.086221, l4: 0.099545, l5: 0.122403, l6: 0.074671

[epoch:  39/100000, batch:     2/  187, ite: 3573] train loss: 0.536312, tar: 0.066480 
l0: 0.037585, l1: 0.035432, l2: 0.036161, l3: 0.041696, l4: 0.052447, l5: 0.052099, l6: 0.061025

[epoch:  39/100000, batch:     4/  187, ite: 3574] train loss: 0.536172, tar: 0.066462 
l0: 0.027989, l1: 0.027320, l2: 0.025723, l3: 0.027280, l4: 0.054434, l5: 0.049338, l6: 0.051307

[epoch:  39/100000, batch:     6/  187, ite: 3575] train loss: 0.535999, tar: 0.066437 
l0: 0.041785, l1: 0.040925, l2: 0.055894, l3: 0.053834, l4: 0.053355, l5: 0.054713, l6: 0.062307

[epoch:  39/100000, batch:     8/  187, ite: 3576] train loss: 0.535889, tar: 0.066422 
l0: 0.048624, l1: 0.050190, l2: 0.047305, l3: 0.050948, l4: 0.078123, l5: 0.070150, l6: 0.072996

[epoch:  39/100000, batch:    10/  187, ite: 3577] train loss: 0.535814, tar: 0.066410 
l0: 0.065747, l1: 0.065129, l2: 0.072804, l3: 0.072802, l4: 0.082156, l5: 0.083726, l6: 0.105496

[epoch:  39/100000, batch:    12/  187, ite: 3578] train loss: 0.535822, tar: 0.066410 
l0: 0.052591, l1: 0.050847, l2: 0.050464, l3: 0.065533, l4: 0.066528, l5: 0.072357, l6: 0.092859

[epoch:  39/100000, batch:    14/  187, ite: 3579] train loss: 0.535768, tar: 0.066401 
l0: 0.037533, l1: 0.039609, l2: 0.037479, l3: 0.035815, l4: 0.053760, l5: 0.048530, l6: 0.061945

[epoch:  39/100000, batch:    16/  187, ite: 3580] train loss: 0.535628, tar: 0.066383 
l0: 0.070796, l1: 0.063478, l2: 0.083587, l3: 0.082758, l4: 0.109830, l5: 0.127931, l6: 0.120952

[epoch:  39/100000, batch:    18/  187, ite: 3581] train loss: 0.535707, tar: 0.066386 
l0: 0.048148, l1: 0.047362, l2: 0.055385, l3: 0.059161, l4: 0.083900, l5: 0.071006, l6: 0.064215

[epoch:  39/100000, batch:    20/  187, ite: 3582] train loss: 0.535639, tar: 0.066374 
l0: 0.041824, l1: 0.041862, l2: 0.047249, l3: 0.049627, l4: 0.057984, l5: 0.062552, l6: 0.053918

[epoch:  39/100000, batch:    22/  187, ite: 3583] train loss: 0.535525, tar: 0.066359 
l0: 0.052863, l1: 0.055113, l2: 0.078265, l3: 0.067057, l4: 0.071315, l5: 0.070096, l6: 0.062360

[epoch:  39/100000, batch:    24/  187, ite: 3584] train loss: 0.535476, tar: 0.066350 
l0: 0.105457, l1: 0.101811, l2: 0.164905, l3: 0.174064, l4: 0.148173, l5: 0.123386, l6: 0.127720

[epoch:  39/100000, batch:    26/  187, ite: 3585] train loss: 0.535734, tar: 0.066375 
l0: 0.035018, l1: 0.034523, l2: 0.046834, l3: 0.049714, l4: 0.043678, l5: 0.044126, l6: 0.039064

[epoch:  39/100000, batch:    28/  187, ite: 3586] train loss: 0.535581, tar: 0.066355 
l0: 0.033386, l1: 0.027893, l2: 0.045967, l3: 0.044014, l4: 0.068856, l5: 0.089717, l6: 0.079004

[epoch:  39/100000, batch:    30/  187, ite: 3587] train loss: 0.535489, tar: 0.066334 
l0: 0.054300, l1: 0.043283, l2: 0.069647, l3: 0.082812, l4: 0.107662, l5: 0.116902, l6: 0.139750

[epoch:  39/100000, batch:    32/  187, ite: 3588] train loss: 0.535539, tar: 0.066327 
l0: 0.024377, l1: 0.027450, l2: 0.046453, l3: 0.036007, l4: 0.038860, l5: 0.039607, l6: 0.041017

[epoch:  39/100000, batch:    34/  187, ite: 3589] train loss: 0.535361, tar: 0.066300 
l0: 0.083399, l1: 0.074039, l2: 0.123494, l3: 0.124779, l4: 0.077290, l5: 0.097475, l6: 0.116189

[epoch:  39/100000, batch:    36/  187, ite: 3590] train loss: 0.535463, tar: 0.066311 
l0: 0.078665, l1: 0.070980, l2: 0.093145, l3: 0.094218, l4: 0.091145, l5: 0.109721, l6: 0.104010

[epoch:  39/100000, batch:    38/  187, ite: 3591] train loss: 0.535530, tar: 0.066319 
l0: 0.054493, l1: 0.053015, l2: 0.053497, l3: 0.059026, l4: 0.077762, l5: 0.084372, l6: 0.080318

[epoch:  39/100000, batch:    40/  187, ite: 3592] train loss: 0.535484, tar: 0.066311 
l0: 0.049449, l1: 0.048400, l2: 0.054631, l3: 0.054115, l4: 0.064986, l5: 0.068432, l6: 0.063749

[epoch:  39/100000, batch:    42/  187, ite: 3593] train loss: 0.535401, tar: 0.066301 
l0: 0.024400, l1: 0.024661, l2: 0.029731, l3: 0.034910, l4: 0.050964, l5: 0.051433, l6: 0.052188

[epoch:  39/100000, batch:    44/  187, ite: 3594] train loss: 0.535233, tar: 0.066274 
l0: 0.049394, l1: 0.044780, l2: 0.067250, l3: 0.069771, l4: 0.072616, l5: 0.062150, l6: 0.067904

[epoch:  39/100000, batch:    46/  187, ite: 3595] train loss: 0.535170, tar: 0.066264 
l0: 0.047742, l1: 0.049336, l2: 0.054381, l3: 0.052818, l4: 0.083647, l5: 0.080800, l6: 0.089202

[epoch:  39/100000, batch:    48/  187, ite: 3596] train loss: 0.535121, tar: 0.066252 
l0: 0.061324, l1: 0.063760, l2: 0.073336, l3: 0.080736, l4: 0.086469, l5: 0.074514, l6: 0.092200

[epoch:  39/100000, batch:    50/  187, ite: 3597] train loss: 0.535120, tar: 0.066249 
l0: 0.040570, l1: 0.036664, l2: 0.058350, l3: 0.058121, l4: 0.071017, l5: 0.064283, l6: 0.062180

[epoch:  39/100000, batch:    52/  187, ite: 3598] train loss: 0.535030, tar: 0.066233 
l0: 0.035711, l1: 0.032219, l2: 0.042031, l3: 0.045371, l4: 0.064985, l5: 0.061363, l6: 0.072824

[epoch:  39/100000, batch:    54/  187, ite: 3599] train loss: 0.534917, tar: 0.066214 
l0: 0.053856, l1: 0.054976, l2: 0.065157, l3: 0.061363, l4: 0.057350, l5: 0.057289, l6: 0.069898

[epoch:  39/100000, batch:    56/  187, ite: 3600] train loss: 0.534845, tar: 0.066206 
l0: 0.039911, l1: 0.034656, l2: 0.062948, l3: 0.068922, l4: 0.066181, l5: 0.061042, l6: 0.071078

[epoch:  39/100000, batch:    58/  187, ite: 3601] train loss: 0.534764, tar: 0.066190 
l0: 0.031002, l1: 0.027388, l2: 0.049611, l3: 0.052942, l4: 0.061280, l5: 0.052491, l6: 0.063955

[epoch:  39/100000, batch:    60/  187, ite: 3602] train loss: 0.534641, tar: 0.066168 
l0: 0.033254, l1: 0.026347, l2: 0.058689, l3: 0.066544, l4: 0.064464, l5: 0.063667, l6: 0.067820

[epoch:  39/100000, batch:    62/  187, ite: 3603] train loss: 0.534545, tar: 0.066147 
l0: 0.027503, l1: 0.031164, l2: 0.034704, l3: 0.037962, l4: 0.043615, l5: 0.033177, l6: 0.033688

[epoch:  39/100000, batch:    64/  187, ite: 3604] train loss: 0.534363, tar: 0.066123 
l0: 0.067409, l1: 0.060056, l2: 0.098283, l3: 0.100682, l4: 0.086043, l5: 0.082655, l6: 0.083121

[epoch:  39/100000, batch:    66/  187, ite: 3605] train loss: 0.534390, tar: 0.066124 
l0: 0.035134, l1: 0.029597, l2: 0.045166, l3: 0.060711, l4: 0.075978, l5: 0.077042, l6: 0.076120

[epoch:  39/100000, batch:    68/  187, ite: 3606] train loss: 0.534306, tar: 0.066105 
l0: 0.061552, l1: 0.077491, l2: 0.061408, l3: 0.062320, l4: 0.067226, l5: 0.062117, l6: 0.063157

[epoch:  39/100000, batch:    70/  187, ite: 3607] train loss: 0.534257, tar: 0.066102 
l0: 0.058028, l1: 0.061018, l2: 0.067182, l3: 0.074356, l4: 0.075666, l5: 0.079239, l6: 0.075256

[epoch:  39/100000, batch:    72/  187, ite: 3608] train loss: 0.534230, tar: 0.066097 
l0: 0.050201, l1: 0.047456, l2: 0.061533, l3: 0.066960, l4: 0.119075, l5: 0.107144, l6: 0.101980

[epoch:  39/100000, batch:    74/  187, ite: 3609] train loss: 0.534242, tar: 0.066087 
l0: 0.030443, l1: 0.030062, l2: 0.036502, l3: 0.037831, l4: 0.040972, l5: 0.041606, l6: 0.043925

[epoch:  39/100000, batch:    76/  187, ite: 3610] train loss: 0.534073, tar: 0.066065 
l0: 0.028368, l1: 0.036555, l2: 0.033394, l3: 0.038302, l4: 0.044209, l5: 0.034794, l6: 0.032601

[epoch:  39/100000, batch:    78/  187, ite: 3611] train loss: 0.533896, tar: 0.066041 
l0: 0.052587, l1: 0.048115, l2: 0.069159, l3: 0.083052, l4: 0.066515, l5: 0.067673, l6: 0.075569

[epoch:  39/100000, batch:    80/  187, ite: 3612] train loss: 0.533851, tar: 0.066033 
l0: 0.039984, l1: 0.040290, l2: 0.042340, l3: 0.043477, l4: 0.053946, l5: 0.055033, l6: 0.050862

[epoch:  39/100000, batch:    82/  187, ite: 3613] train loss: 0.533722, tar: 0.066017 
l0: 0.035111, l1: 0.036050, l2: 0.040167, l3: 0.047156, l4: 0.071599, l5: 0.060447, l6: 0.049776

[epoch:  39/100000, batch:    84/  187, ite: 3614] train loss: 0.533603, tar: 0.065998 
l0: 0.045292, l1: 0.041413, l2: 0.071382, l3: 0.073082, l4: 0.065247, l5: 0.066832, l6: 0.069245

[epoch:  39/100000, batch:    86/  187, ite: 3615] train loss: 0.533540, tar: 0.065985 
l0: 0.020299, l1: 0.015936, l2: 0.038285, l3: 0.033005, l4: 0.070940, l5: 0.061891, l6: 0.074532

[epoch:  39/100000, batch:    88/  187, ite: 3616] train loss: 0.533405, tar: 0.065957 
l0: 0.033890, l1: 0.044166, l2: 0.042507, l3: 0.044428, l4: 0.046299, l5: 0.042148, l6: 0.043030

[epoch:  39/100000, batch:    90/  187, ite: 3617] train loss: 0.533258, tar: 0.065937 
l0: 0.066160, l1: 0.075003, l2: 0.055664, l3: 0.065327, l4: 0.083099, l5: 0.089917, l6: 0.072638

[epoch:  39/100000, batch:    92/  187, ite: 3618] train loss: 0.533242, tar: 0.065937 
l0: 0.040101, l1: 0.042101, l2: 0.042358, l3: 0.046336, l4: 0.062761, l5: 0.051439, l6: 0.054522

[epoch:  39/100000, batch:    94/  187, ite: 3619] train loss: 0.533123, tar: 0.065921 
l0: 0.033253, l1: 0.028961, l2: 0.047388, l3: 0.052872, l4: 0.055994, l5: 0.051039, l6: 0.053477

[epoch:  39/100000, batch:    96/  187, ite: 3620] train loss: 0.532993, tar: 0.065901 
l0: 0.042626, l1: 0.042640, l2: 0.066814, l3: 0.063304, l4: 0.093510, l5: 0.090039, l6: 0.076087

[epoch:  39/100000, batch:    98/  187, ite: 3621] train loss: 0.532957, tar: 0.065887 
l0: 0.056659, l1: 0.075548, l2: 0.050328, l3: 0.047403, l4: 0.054543, l5: 0.044163, l6: 0.047127

[epoch:  39/100000, batch:   100/  187, ite: 3622] train loss: 0.532860, tar: 0.065881 
l0: 0.068153, l1: 0.068696, l2: 0.059994, l3: 0.060581, l4: 0.135582, l5: 0.137418, l6: 0.142480

[epoch:  39/100000, batch:   102/  187, ite: 3623] train loss: 0.532947, tar: 0.065882 
l0: 0.042149, l1: 0.046505, l2: 0.042002, l3: 0.044427, l4: 0.058951, l5: 0.056239, l6: 0.044963

[epoch:  39/100000, batch:   104/  187, ite: 3624] train loss: 0.532825, tar: 0.065868 
l0: 0.041261, l1: 0.041882, l2: 0.055429, l3: 0.054691, l4: 0.054905, l5: 0.054536, l6: 0.047480

[epoch:  39/100000, batch:   106/  187, ite: 3625] train loss: 0.532713, tar: 0.065852 
l0: 0.028883, l1: 0.027254, l2: 0.037790, l3: 0.041145, l4: 0.069345, l5: 0.050410, l6: 0.049593

[epoch:  39/100000, batch:   108/  187, ite: 3626] train loss: 0.532572, tar: 0.065830 
l0: 0.051513, l1: 0.064979, l2: 0.036696, l3: 0.045449, l4: 0.049870, l5: 0.038450, l6: 0.036004

[epoch:  39/100000, batch:   110/  187, ite: 3627] train loss: 0.532443, tar: 0.065821 
l0: 0.018433, l1: 0.018299, l2: 0.026618, l3: 0.032459, l4: 0.046725, l5: 0.057115, l6: 0.050981

[epoch:  39/100000, batch:   112/  187, ite: 3628] train loss: 0.532270, tar: 0.065792 
l0: 0.078655, l1: 0.088136, l2: 0.073915, l3: 0.081018, l4: 0.079752, l5: 0.076524, l6: 0.076939

[epoch:  39/100000, batch:   114/  187, ite: 3629] train loss: 0.532284, tar: 0.065800 
l0: 0.078670, l1: 0.080371, l2: 0.096137, l3: 0.087466, l4: 0.104865, l5: 0.096486, l6: 0.091374

[epoch:  39/100000, batch:   116/  187, ite: 3630] train loss: 0.532347, tar: 0.065808 
l0: 0.042367, l1: 0.036352, l2: 0.058876, l3: 0.072798, l4: 0.068404, l5: 0.068468, l6: 0.072237

[epoch:  39/100000, batch:   118/  187, ite: 3631] train loss: 0.532278, tar: 0.065793 
l0: 0.063982, l1: 0.067487, l2: 0.055208, l3: 0.065165, l4: 0.064803, l5: 0.062043, l6: 0.061882

[epoch:  39/100000, batch:   120/  187, ite: 3632] train loss: 0.532222, tar: 0.065792 
l0: 0.076149, l1: 0.090308, l2: 0.076395, l3: 0.081795, l4: 0.086334, l5: 0.083068, l6: 0.083183

[epoch:  39/100000, batch:   122/  187, ite: 3633] train loss: 0.532250, tar: 0.065799 
l0: 0.120613, l1: 0.116567, l2: 0.134340, l3: 0.134368, l4: 0.220450, l5: 0.205576, l6: 0.220329

[epoch:  39/100000, batch:   124/  187, ite: 3634] train loss: 0.532629, tar: 0.065832 
l0: 0.051775, l1: 0.051119, l2: 0.067554, l3: 0.070910, l4: 0.080863, l5: 0.076273, l6: 0.079806

[epoch:  39/100000, batch:   126/  187, ite: 3635] train loss: 0.532596, tar: 0.065823 
l0: 0.051508, l1: 0.053742, l2: 0.054396, l3: 0.055597, l4: 0.062784, l5: 0.060298, l6: 0.058369

[epoch:  39/100000, batch:   128/  187, ite: 3636] train loss: 0.532513, tar: 0.065815 
l0: 0.080371, l1: 0.081999, l2: 0.094887, l3: 0.078931, l4: 0.087802, l5: 0.099035, l6: 0.113259

[epoch:  39/100000, batch:   130/  187, ite: 3637] train loss: 0.532576, tar: 0.065824 
l0: 0.036245, l1: 0.039456, l2: 0.048080, l3: 0.042638, l4: 0.045951, l5: 0.046240, l6: 0.044087

[epoch:  39/100000, batch:   132/  187, ite: 3638] train loss: 0.532436, tar: 0.065806 
l0: 0.062086, l1: 0.067311, l2: 0.070716, l3: 0.078572, l4: 0.084503, l5: 0.081652, l6: 0.073288

[epoch:  39/100000, batch:   134/  187, ite: 3639] train loss: 0.532427, tar: 0.065803 
l0: 0.039697, l1: 0.042453, l2: 0.043795, l3: 0.038291, l4: 0.060242, l5: 0.055332, l6: 0.058723

[epoch:  39/100000, batch:   136/  187, ite: 3640] train loss: 0.532309, tar: 0.065787 
l0: 0.049511, l1: 0.057837, l2: 0.052523, l3: 0.044790, l4: 0.076813, l5: 0.071599, l6: 0.077004

[epoch:  39/100000, batch:   138/  187, ite: 3641] train loss: 0.532247, tar: 0.065777 
l0: 0.087949, l1: 0.122777, l2: 0.090619, l3: 0.068134, l4: 0.070129, l5: 0.076264, l6: 0.072940

[epoch:  39/100000, batch:   140/  187, ite: 3642] train loss: 0.532281, tar: 0.065791 
l0: 0.039506, l1: 0.041418, l2: 0.042633, l3: 0.042597, l4: 0.063442, l5: 0.056170, l6: 0.057072

[epoch:  39/100000, batch:   142/  187, ite: 3643] train loss: 0.532166, tar: 0.065775 
l0: 0.046274, l1: 0.043331, l2: 0.060255, l3: 0.064934, l4: 0.073232, l5: 0.071655, l6: 0.063569

[epoch:  39/100000, batch:   144/  187, ite: 3644] train loss: 0.532099, tar: 0.065763 
l0: 0.062744, l1: 0.063338, l2: 0.065787, l3: 0.068546, l4: 0.080717, l5: 0.069611, l6: 0.067939

[epoch:  39/100000, batch:   146/  187, ite: 3645] train loss: 0.532067, tar: 0.065761 
l0: 0.076639, l1: 0.085753, l2: 0.081705, l3: 0.084392, l4: 0.077428, l5: 0.073220, l6: 0.070933

[epoch:  39/100000, batch:   148/  187, ite: 3646] train loss: 0.532078, tar: 0.065768 
l0: 0.046257, l1: 0.045916, l2: 0.055744, l3: 0.063821, l4: 0.058965, l5: 0.048511, l6: 0.046128

[epoch:  39/100000, batch:   150/  187, ite: 3647] train loss: 0.531977, tar: 0.065756 
l0: 0.042038, l1: 0.042433, l2: 0.043830, l3: 0.045281, l4: 0.057249, l5: 0.050071, l6: 0.046647

[epoch:  39/100000, batch:   152/  187, ite: 3648] train loss: 0.531853, tar: 0.065742 
l0: 0.051184, l1: 0.060817, l2: 0.040656, l3: 0.039802, l4: 0.063876, l5: 0.068582, l6: 0.053373

[epoch:  39/100000, batch:   154/  187, ite: 3649] train loss: 0.531760, tar: 0.065733 
l0: 0.039987, l1: 0.035142, l2: 0.049991, l3: 0.053160, l4: 0.072472, l5: 0.068219, l6: 0.068627

[epoch:  39/100000, batch:   156/  187, ite: 3650] train loss: 0.531672, tar: 0.065717 
l0: 0.062534, l1: 0.061902, l2: 0.067018, l3: 0.071060, l4: 0.105328, l5: 0.099131, l6: 0.119370

[epoch:  39/100000, batch:   158/  187, ite: 3651] train loss: 0.531705, tar: 0.065715 
l0: 0.083271, l1: 0.080998, l2: 0.083509, l3: 0.093341, l4: 0.098233, l5: 0.102471, l6: 0.118215

[epoch:  39/100000, batch:   160/  187, ite: 3652] train loss: 0.531783, tar: 0.065726 
l0: 0.063872, l1: 0.057684, l2: 0.074438, l3: 0.066214, l4: 0.118915, l5: 0.114365, l6: 0.119435

[epoch:  39/100000, batch:   162/  187, ite: 3653] train loss: 0.531833, tar: 0.065725 
l0: 0.056274, l1: 0.058399, l2: 0.062560, l3: 0.056292, l4: 0.056860, l5: 0.064730, l6: 0.062015

[epoch:  39/100000, batch:   164/  187, ite: 3654] train loss: 0.531764, tar: 0.065719 
l0: 0.067660, l1: 0.065755, l2: 0.086894, l3: 0.089327, l4: 0.073332, l5: 0.077381, l6: 0.080242

[epoch:  39/100000, batch:   166/  187, ite: 3655] train loss: 0.531769, tar: 0.065720 
l0: 0.090507, l1: 0.092830, l2: 0.114590, l3: 0.093472, l4: 0.080134, l5: 0.088221, l6: 0.078314

[epoch:  39/100000, batch:   168/  187, ite: 3656] train loss: 0.531833, tar: 0.065735 
l0: 0.041164, l1: 0.038499, l2: 0.047641, l3: 0.042843, l4: 0.059479, l5: 0.065778, l6: 0.072508

[epoch:  39/100000, batch:   170/  187, ite: 3657] train loss: 0.531734, tar: 0.065720 
l0: 0.048615, l1: 0.042134, l2: 0.054389, l3: 0.060650, l4: 0.093131, l5: 0.105562, l6: 0.082532

[epoch:  39/100000, batch:   172/  187, ite: 3658] train loss: 0.531708, tar: 0.065710 
l0: 0.043107, l1: 0.041415, l2: 0.054996, l3: 0.058342, l4: 0.065744, l5: 0.064122, l6: 0.073348

[epoch:  39/100000, batch:   174/  187, ite: 3659] train loss: 0.531629, tar: 0.065696 
l0: 0.039490, l1: 0.037480, l2: 0.041590, l3: 0.049421, l4: 0.060024, l5: 0.062036, l6: 0.064497

[epoch:  39/100000, batch:   176/  187, ite: 3660] train loss: 0.531522, tar: 0.065681 
l0: 0.035342, l1: 0.033559, l2: 0.035107, l3: 0.043476, l4: 0.077770, l5: 0.076923, l6: 0.076866

[epoch:  39/100000, batch:   178/  187, ite: 3661] train loss: 0.531430, tar: 0.065662 
l0: 0.047288, l1: 0.050509, l2: 0.060519, l3: 0.061503, l4: 0.078597, l5: 0.083035, l6: 0.079733

[epoch:  39/100000, batch:   180/  187, ite: 3662] train loss: 0.531388, tar: 0.065651 
l0: 0.056292, l1: 0.056754, l2: 0.060873, l3: 0.071451, l4: 0.067177, l5: 0.064332, l6: 0.066408

[epoch:  39/100000, batch:   182/  187, ite: 3663] train loss: 0.531335, tar: 0.065646 
l0: 0.076210, l1: 0.079908, l2: 0.085138, l3: 0.106884, l4: 0.079686, l5: 0.084518, l6: 0.081586

[epoch:  39/100000, batch:   184/  187, ite: 3664] train loss: 0.531373, tar: 0.065652 
l0: 0.050240, l1: 0.053351, l2: 0.054487, l3: 0.053187, l4: 0.051749, l5: 0.054650, l6: 0.055300

[epoch:  39/100000, batch:   186/  187, ite: 3665] train loss: 0.531278, tar: 0.065643 
l0: 0.032343, l1: 0.030585, l2: 0.043914, l3: 0.044292, l4: 0.049531, l5: 0.057650, l6: 0.055564

[epoch:  39/100000, batch:   188/  187, ite: 3666] train loss: 0.531147, tar: 0.065623 
l0: 0.047822, l1: 0.041430, l2: 0.061950, l3: 0.058531, l4: 0.080114, l5: 0.072052, l6: 0.089195

[epoch:  40/100000, batch:     2/  187, ite: 3667] train loss: 0.531099, tar: 0.065612 
l0: 0.066022, l1: 0.059094, l2: 0.061537, l3: 0.067657, l4: 0.104747, l5: 0.121625, l6: 0.146009

[epoch:  40/100000, batch:     4/  187, ite: 3668] train loss: 0.531156, tar: 0.065612 
l0: 0.052734, l1: 0.057903, l2: 0.074613, l3: 0.060669, l4: 0.078996, l5: 0.070340, l6: 0.066629

[epoch:  40/100000, batch:     6/  187, ite: 3669] train loss: 0.531115, tar: 0.065605 
l0: 0.040508, l1: 0.029819, l2: 0.049527, l3: 0.065416, l4: 0.083622, l5: 0.090120, l6: 0.100965

[epoch:  40/100000, batch:     8/  187, ite: 3670] train loss: 0.531072, tar: 0.065590 
l0: 0.065950, l1: 0.080197, l2: 0.073480, l3: 0.068936, l4: 0.077681, l5: 0.063548, l6: 0.054871

[epoch:  40/100000, batch:    10/  187, ite: 3671] train loss: 0.531044, tar: 0.065590 
l0: 0.079913, l1: 0.075829, l2: 0.105866, l3: 0.107738, l4: 0.079693, l5: 0.075537, l6: 0.086094

[epoch:  40/100000, batch:    12/  187, ite: 3672] train loss: 0.531092, tar: 0.065598 
l0: 0.036662, l1: 0.044785, l2: 0.052647, l3: 0.043483, l4: 0.036205, l5: 0.038338, l6: 0.036257

[epoch:  40/100000, batch:    14/  187, ite: 3673] train loss: 0.530947, tar: 0.065581 
l0: 0.048002, l1: 0.040809, l2: 0.054843, l3: 0.065206, l4: 0.085924, l5: 0.093332, l6: 0.086682

[epoch:  40/100000, batch:    16/  187, ite: 3674] train loss: 0.530913, tar: 0.065571 
l0: 0.050824, l1: 0.043613, l2: 0.085472, l3: 0.077095, l4: 0.062951, l5: 0.070534, l6: 0.080140

[epoch:  40/100000, batch:    18/  187, ite: 3675] train loss: 0.530877, tar: 0.065562 
l0: 0.035363, l1: 0.034878, l2: 0.044086, l3: 0.040049, l4: 0.063065, l5: 0.058809, l6: 0.055787

[epoch:  40/100000, batch:    20/  187, ite: 3676] train loss: 0.530759, tar: 0.065544 
l0: 0.050719, l1: 0.052893, l2: 0.047382, l3: 0.056621, l4: 0.067758, l5: 0.071334, l6: 0.072632

[epoch:  40/100000, batch:    22/  187, ite: 3677] train loss: 0.530692, tar: 0.065535 
l0: 0.028795, l1: 0.026975, l2: 0.038941, l3: 0.034922, l4: 0.065396, l5: 0.066378, l6: 0.064029

[epoch:  40/100000, batch:    24/  187, ite: 3678] train loss: 0.530570, tar: 0.065513 
l0: 0.035399, l1: 0.036152, l2: 0.043315, l3: 0.040037, l4: 0.057277, l5: 0.053552, l6: 0.050881

[epoch:  40/100000, batch:    26/  187, ite: 3679] train loss: 0.530443, tar: 0.065495 
l0: 0.056624, l1: 0.062816, l2: 0.056833, l3: 0.053936, l4: 0.050307, l5: 0.052961, l6: 0.054664

[epoch:  40/100000, batch:    28/  187, ite: 3680] train loss: 0.530358, tar: 0.065490 
l0: 0.038005, l1: 0.041365, l2: 0.047227, l3: 0.044721, l4: 0.048936, l5: 0.045732, l6: 0.049672

[epoch:  40/100000, batch:    30/  187, ite: 3681] train loss: 0.530230, tar: 0.065473 
l0: 0.039839, l1: 0.037442, l2: 0.049993, l3: 0.045235, l4: 0.049063, l5: 0.050233, l6: 0.049359

[epoch:  40/100000, batch:    32/  187, ite: 3682] train loss: 0.530106, tar: 0.065458 
l0: 0.023938, l1: 0.022372, l2: 0.029928, l3: 0.027915, l4: 0.049322, l5: 0.045160, l6: 0.048857

[epoch:  40/100000, batch:    34/  187, ite: 3683] train loss: 0.529938, tar: 0.065434 
l0: 0.034416, l1: 0.032821, l2: 0.046769, l3: 0.045529, l4: 0.056060, l5: 0.050159, l6: 0.048866

[epoch:  40/100000, batch:    36/  187, ite: 3684] train loss: 0.529810, tar: 0.065415 
l0: 0.055277, l1: 0.054589, l2: 0.058835, l3: 0.053134, l4: 0.071495, l5: 0.072814, l6: 0.069955

[epoch:  40/100000, batch:    38/  187, ite: 3685] train loss: 0.529754, tar: 0.065409 
l0: 0.032417, l1: 0.034880, l2: 0.037160, l3: 0.039317, l4: 0.041008, l5: 0.041795, l6: 0.039743

[epoch:  40/100000, batch:    40/  187, ite: 3686] train loss: 0.529598, tar: 0.065390 
l0: 0.088980, l1: 0.089868, l2: 0.114056, l3: 0.132690, l4: 0.090961, l5: 0.092524, l6: 0.096950

[epoch:  40/100000, batch:    42/  187, ite: 3687] train loss: 0.529703, tar: 0.065404 
l0: 0.041345, l1: 0.038156, l2: 0.049510, l3: 0.054822, l4: 0.063195, l5: 0.066390, l6: 0.064365

[epoch:  40/100000, batch:    44/  187, ite: 3688] train loss: 0.529613, tar: 0.065389 
l0: 0.071467, l1: 0.082034, l2: 0.063354, l3: 0.078484, l4: 0.084514, l5: 0.069311, l6: 0.079319

[epoch:  40/100000, batch:    46/  187, ite: 3689] train loss: 0.529612, tar: 0.065393 
l0: 0.046541, l1: 0.050020, l2: 0.047915, l3: 0.048324, l4: 0.052455, l5: 0.051846, l6: 0.054877

[epoch:  40/100000, batch:    48/  187, ite: 3690] train loss: 0.529507, tar: 0.065382 
l0: 0.051488, l1: 0.048596, l2: 0.053338, l3: 0.049291, l4: 0.064481, l5: 0.095187, l6: 0.113722

[epoch:  40/100000, batch:    50/  187, ite: 3691] train loss: 0.529475, tar: 0.065374 
l0: 0.042191, l1: 0.042926, l2: 0.044748, l3: 0.041227, l4: 0.053607, l5: 0.058090, l6: 0.054338

[epoch:  40/100000, batch:    52/  187, ite: 3692] train loss: 0.529362, tar: 0.065360 
l0: 0.051868, l1: 0.047102, l2: 0.049103, l3: 0.052222, l4: 0.079687, l5: 0.091041, l6: 0.108065

[epoch:  40/100000, batch:    54/  187, ite: 3693] train loss: 0.529332, tar: 0.065352 
l0: 0.049205, l1: 0.042832, l2: 0.046887, l3: 0.056382, l4: 0.093429, l5: 0.100317, l6: 0.114564

[epoch:  40/100000, batch:    56/  187, ite: 3694] train loss: 0.529317, tar: 0.065342 
l0: 0.036651, l1: 0.035286, l2: 0.040425, l3: 0.039100, l4: 0.061755, l5: 0.059098, l6: 0.059597

[epoch:  40/100000, batch:    58/  187, ite: 3695] train loss: 0.529200, tar: 0.065325 
l0: 0.060752, l1: 0.058240, l2: 0.069073, l3: 0.067391, l4: 0.117135, l5: 0.108858, l6: 0.099365

[epoch:  40/100000, batch:    60/  187, ite: 3696] train loss: 0.529231, tar: 0.065323 
l0: 0.035013, l1: 0.042319, l2: 0.051596, l3: 0.040287, l4: 0.052126, l5: 0.058390, l6: 0.051720

[epoch:  40/100000, batch:    62/  187, ite: 3697] train loss: 0.529114, tar: 0.065305 
l0: 0.040692, l1: 0.044592, l2: 0.052074, l3: 0.051437, l4: 0.046410, l5: 0.038745, l6: 0.041934

[epoch:  40/100000, batch:    64/  187, ite: 3698] train loss: 0.528989, tar: 0.065290 
l0: 0.036890, l1: 0.042577, l2: 0.045943, l3: 0.041557, l4: 0.047462, l5: 0.059944, l6: 0.050153

[epoch:  40/100000, batch:    66/  187, ite: 3699] train loss: 0.528868, tar: 0.065274 
l0: 0.047951, l1: 0.047052, l2: 0.046680, l3: 0.052639, l4: 0.072439, l5: 0.074067, l6: 0.074314

[epoch:  40/100000, batch:    68/  187, ite: 3700] train loss: 0.528802, tar: 0.065263 
l0: 0.030511, l1: 0.033436, l2: 0.033723, l3: 0.037238, l4: 0.052749, l5: 0.068632, l6: 0.052004

[epoch:  40/100000, batch:    70/  187, ite: 3701] train loss: 0.528672, tar: 0.065243 
l0: 0.033525, l1: 0.033248, l2: 0.038714, l3: 0.037468, l4: 0.048030, l5: 0.043257, l6: 0.043380

[epoch:  40/100000, batch:    72/  187, ite: 3702] train loss: 0.528524, tar: 0.065224 
l0: 0.064996, l1: 0.069429, l2: 0.056879, l3: 0.058957, l4: 0.057724, l5: 0.061151, l6: 0.070933

[epoch:  40/100000, batch:    74/  187, ite: 3703] train loss: 0.528472, tar: 0.065224 
l0: 0.026923, l1: 0.029683, l2: 0.039287, l3: 0.039608, l4: 0.035247, l5: 0.036964, l6: 0.026635

[epoch:  40/100000, batch:    76/  187, ite: 3704] train loss: 0.528300, tar: 0.065202 
l0: 0.028013, l1: 0.027153, l2: 0.029902, l3: 0.035771, l4: 0.045229, l5: 0.048569, l6: 0.052567

[epoch:  40/100000, batch:    78/  187, ite: 3705] train loss: 0.528147, tar: 0.065180 
l0: 0.033539, l1: 0.033274, l2: 0.048749, l3: 0.047510, l4: 0.064865, l5: 0.074308, l6: 0.078442

[epoch:  40/100000, batch:    80/  187, ite: 3706] train loss: 0.528060, tar: 0.065161 
l0: 0.032515, l1: 0.029462, l2: 0.035655, l3: 0.038272, l4: 0.046507, l5: 0.055632, l6: 0.050745

[epoch:  40/100000, batch:    82/  187, ite: 3707] train loss: 0.527920, tar: 0.065142 
l0: 0.030233, l1: 0.032015, l2: 0.028707, l3: 0.029544, l4: 0.041481, l5: 0.040860, l6: 0.037778

[epoch:  40/100000, batch:    84/  187, ite: 3708] train loss: 0.527752, tar: 0.065122 
l0: 0.044530, l1: 0.055038, l2: 0.067455, l3: 0.063188, l4: 0.045322, l5: 0.040819, l6: 0.038958

[epoch:  40/100000, batch:    86/  187, ite: 3709] train loss: 0.527651, tar: 0.065110 
l0: 0.055143, l1: 0.054419, l2: 0.072519, l3: 0.068023, l4: 0.088628, l5: 0.102414, l6: 0.113817

[epoch:  40/100000, batch:    88/  187, ite: 3710] train loss: 0.527667, tar: 0.065104 
l0: 0.046595, l1: 0.050016, l2: 0.054775, l3: 0.053158, l4: 0.064048, l5: 0.061750, l6: 0.065067

[epoch:  40/100000, batch:    90/  187, ite: 3711] train loss: 0.527590, tar: 0.065093 
l0: 0.056262, l1: 0.057486, l2: 0.060593, l3: 0.061618, l4: 0.064536, l5: 0.061309, l6: 0.060512

[epoch:  40/100000, batch:    92/  187, ite: 3712] train loss: 0.527528, tar: 0.065088 
l0: 0.041549, l1: 0.041995, l2: 0.040753, l3: 0.041694, l4: 0.047389, l5: 0.054269, l6: 0.045894

[epoch:  40/100000, batch:    94/  187, ite: 3713] train loss: 0.527403, tar: 0.065074 
l0: 0.034961, l1: 0.032024, l2: 0.040680, l3: 0.045734, l4: 0.057104, l5: 0.073268, l6: 0.080234

[epoch:  40/100000, batch:    96/  187, ite: 3714] train loss: 0.527308, tar: 0.065057 
l0: 0.027939, l1: 0.029153, l2: 0.034982, l3: 0.033704, l4: 0.043829, l5: 0.051534, l6: 0.048301

[epoch:  40/100000, batch:    98/  187, ite: 3715] train loss: 0.527158, tar: 0.065035 
l0: 0.015158, l1: 0.014854, l2: 0.018802, l3: 0.020734, l4: 0.030425, l5: 0.035756, l6: 0.035609

[epoch:  40/100000, batch:   100/  187, ite: 3716] train loss: 0.526950, tar: 0.065006 
l0: 0.028824, l1: 0.026180, l2: 0.043299, l3: 0.047610, l4: 0.051680, l5: 0.056331, l6: 0.051384

[epoch:  40/100000, batch:   102/  187, ite: 3717] train loss: 0.526821, tar: 0.064985 
l0: 0.023689, l1: 0.022761, l2: 0.024022, l3: 0.025054, l4: 0.041101, l5: 0.048046, l6: 0.043509

[epoch:  40/100000, batch:   104/  187, ite: 3718] train loss: 0.526647, tar: 0.064961 
l0: 0.041646, l1: 0.040915, l2: 0.039136, l3: 0.040397, l4: 0.065328, l5: 0.068350, l6: 0.069872

[epoch:  40/100000, batch:   106/  187, ite: 3719] train loss: 0.526554, tar: 0.064947 
l0: 0.090937, l1: 0.108421, l2: 0.090749, l3: 0.094603, l4: 0.080783, l5: 0.071978, l6: 0.072499

[epoch:  40/100000, batch:   108/  187, ite: 3720] train loss: 0.526602, tar: 0.064962 
l0: 0.043528, l1: 0.046079, l2: 0.050138, l3: 0.047027, l4: 0.061550, l5: 0.060021, l6: 0.061103

[epoch:  40/100000, batch:   110/  187, ite: 3721] train loss: 0.526511, tar: 0.064950 
l0: 0.025846, l1: 0.029869, l2: 0.029829, l3: 0.028859, l4: 0.040522, l5: 0.032367, l6: 0.036823

[epoch:  40/100000, batch:   112/  187, ite: 3722] train loss: 0.526335, tar: 0.064927 
l0: 0.016617, l1: 0.015263, l2: 0.019552, l3: 0.019290, l4: 0.024963, l5: 0.028719, l6: 0.028892

[epoch:  40/100000, batch:   114/  187, ite: 3723] train loss: 0.526119, tar: 0.064899 
l0: 0.274474, l1: 0.290500, l2: 0.230961, l3: 0.210391, l4: 0.254696, l5: 0.297601, l6: 0.345416

[epoch:  40/100000, batch:   116/  187, ite: 3724] train loss: 0.526918, tar: 0.065021 
l0: 0.030118, l1: 0.027589, l2: 0.035808, l3: 0.044599, l4: 0.050287, l5: 0.048920, l6: 0.050576

[epoch:  40/100000, batch:   118/  187, ite: 3725] train loss: 0.526779, tar: 0.065001 
l0: 0.037008, l1: 0.041091, l2: 0.033722, l3: 0.036903, l4: 0.048293, l5: 0.047872, l6: 0.043562

[epoch:  40/100000, batch:   120/  187, ite: 3726] train loss: 0.526641, tar: 0.064984 
l0: 0.046900, l1: 0.047392, l2: 0.046127, l3: 0.045233, l4: 0.076270, l5: 0.070075, l6: 0.071345

[epoch:  40/100000, batch:   122/  187, ite: 3727] train loss: 0.526570, tar: 0.064974 
l0: 0.059939, l1: 0.064204, l2: 0.075625, l3: 0.067955, l4: 0.076208, l5: 0.079262, l6: 0.085402

[epoch:  40/100000, batch:   124/  187, ite: 3728] train loss: 0.526560, tar: 0.064971 
l0: 0.055405, l1: 0.053591, l2: 0.068337, l3: 0.076802, l4: 0.070794, l5: 0.073490, l6: 0.084511

[epoch:  40/100000, batch:   126/  187, ite: 3729] train loss: 0.526534, tar: 0.064965 
l0: 0.049023, l1: 0.049193, l2: 0.076574, l3: 0.065242, l4: 0.089313, l5: 0.082304, l6: 0.059449

[epoch:  40/100000, batch:   128/  187, ite: 3730] train loss: 0.526502, tar: 0.064956 
l0: 0.078011, l1: 0.086331, l2: 0.065843, l3: 0.075329, l4: 0.077211, l5: 0.070720, l6: 0.071814

[epoch:  40/100000, batch:   130/  187, ite: 3731] train loss: 0.526502, tar: 0.064964 
l0: 0.106391, l1: 0.115686, l2: 0.134852, l3: 0.117547, l4: 0.126764, l5: 0.106396, l6: 0.114709

[epoch:  40/100000, batch:   132/  187, ite: 3732] train loss: 0.526672, tar: 0.064988 
l0: 0.102707, l1: 0.103306, l2: 0.142826, l3: 0.137786, l4: 0.127241, l5: 0.128507, l6: 0.111147

[epoch:  40/100000, batch:   134/  187, ite: 3733] train loss: 0.526861, tar: 0.065009 
l0: 0.031970, l1: 0.034326, l2: 0.045464, l3: 0.045814, l4: 0.048529, l5: 0.042910, l6: 0.043725

[epoch:  40/100000, batch:   136/  187, ite: 3734] train loss: 0.526726, tar: 0.064990 
l0: 0.052939, l1: 0.048058, l2: 0.060567, l3: 0.075124, l4: 0.101341, l5: 0.092005, l6: 0.092443

[epoch:  40/100000, batch:   138/  187, ite: 3735] train loss: 0.526723, tar: 0.064983 
l0: 0.052193, l1: 0.055381, l2: 0.063712, l3: 0.066531, l4: 0.087649, l5: 0.076103, l6: 0.060145

[epoch:  40/100000, batch:   140/  187, ite: 3736] train loss: 0.526686, tar: 0.064976 
l0: 0.060687, l1: 0.066824, l2: 0.055823, l3: 0.069298, l4: 0.071843, l5: 0.083673, l6: 0.084807

[epoch:  40/100000, batch:   142/  187, ite: 3737] train loss: 0.526667, tar: 0.064974 
l0: 0.046176, l1: 0.066428, l2: 0.053992, l3: 0.040481, l4: 0.024858, l5: 0.033945, l6: 0.034545

[epoch:  40/100000, batch:   144/  187, ite: 3738] train loss: 0.526536, tar: 0.064963 
l0: 0.049396, l1: 0.072974, l2: 0.064793, l3: 0.045297, l4: 0.023072, l5: 0.032889, l6: 0.024808

[epoch:  40/100000, batch:   146/  187, ite: 3739] train loss: 0.526414, tar: 0.064954 
l0: 0.064824, l1: 0.084700, l2: 0.063353, l3: 0.063844, l4: 0.068295, l5: 0.069423, l6: 0.072988

[epoch:  40/100000, batch:   148/  187, ite: 3740] train loss: 0.526391, tar: 0.064954 
l0: 0.064121, l1: 0.065590, l2: 0.062426, l3: 0.061725, l4: 0.073978, l5: 0.088200, l6: 0.092776

[epoch:  40/100000, batch:   150/  187, ite: 3741] train loss: 0.526381, tar: 0.064953 
l0: 0.059160, l1: 0.064571, l2: 0.065001, l3: 0.071007, l4: 0.099326, l5: 0.097898, l6: 0.109216

[epoch:  40/100000, batch:   152/  187, ite: 3742] train loss: 0.526404, tar: 0.064950 
l0: 0.032167, l1: 0.026472, l2: 0.038548, l3: 0.050568, l4: 0.085587, l5: 0.058157, l6: 0.066421

[epoch:  40/100000, batch:   154/  187, ite: 3743] train loss: 0.526307, tar: 0.064931 
l0: 0.029526, l1: 0.037870, l2: 0.030409, l3: 0.028003, l4: 0.048243, l5: 0.049771, l6: 0.040019

[epoch:  40/100000, batch:   156/  187, ite: 3744] train loss: 0.526157, tar: 0.064911 
l0: 0.054031, l1: 0.050866, l2: 0.066825, l3: 0.067835, l4: 0.070205, l5: 0.066161, l6: 0.063654

[epoch:  40/100000, batch:   158/  187, ite: 3745] train loss: 0.526107, tar: 0.064905 
l0: 0.046609, l1: 0.044097, l2: 0.053552, l3: 0.051530, l4: 0.052175, l5: 0.048316, l6: 0.062972

[epoch:  40/100000, batch:   160/  187, ite: 3746] train loss: 0.526012, tar: 0.064894 
l0: 0.058650, l1: 0.051342, l2: 0.078448, l3: 0.066576, l4: 0.089845, l5: 0.108928, l6: 0.106702

[epoch:  40/100000, batch:   162/  187, ite: 3747] train loss: 0.526031, tar: 0.064891 
l0: 0.059134, l1: 0.061411, l2: 0.072792, l3: 0.064665, l4: 0.061055, l5: 0.050664, l6: 0.056046

[epoch:  40/100000, batch:   164/  187, ite: 3748] train loss: 0.525974, tar: 0.064887 
l0: 0.041516, l1: 0.042062, l2: 0.039509, l3: 0.034644, l4: 0.055143, l5: 0.067818, l6: 0.061589

[epoch:  40/100000, batch:   166/  187, ite: 3749] train loss: 0.525869, tar: 0.064874 
l0: 0.081651, l1: 0.081167, l2: 0.097683, l3: 0.117925, l4: 0.095675, l5: 0.081064, l6: 0.088629

[epoch:  40/100000, batch:   168/  187, ite: 3750] train loss: 0.525936, tar: 0.064883 
l0: 0.046934, l1: 0.034450, l2: 0.054406, l3: 0.066360, l4: 0.126889, l5: 0.143612, l6: 0.147035

[epoch:  40/100000, batch:   170/  187, ite: 3751] train loss: 0.525990, tar: 0.064873 
l0: 0.039265, l1: 0.040333, l2: 0.042888, l3: 0.040019, l4: 0.057826, l5: 0.059263, l6: 0.061205

[epoch:  40/100000, batch:   172/  187, ite: 3752] train loss: 0.525884, tar: 0.064859 
l0: 0.051322, l1: 0.052836, l2: 0.053471, l3: 0.060015, l4: 0.076493, l5: 0.075550, l6: 0.063157

[epoch:  40/100000, batch:   174/  187, ite: 3753] train loss: 0.525831, tar: 0.064851 
l0: 0.044124, l1: 0.042667, l2: 0.058654, l3: 0.054936, l4: 0.082033, l5: 0.062260, l6: 0.066884

[epoch:  40/100000, batch:   176/  187, ite: 3754] train loss: 0.525766, tar: 0.064839 
l0: 0.051581, l1: 0.048221, l2: 0.069187, l3: 0.067479, l4: 0.067234, l5: 0.061970, l6: 0.084313

[epoch:  40/100000, batch:   178/  187, ite: 3755] train loss: 0.525723, tar: 0.064831 
l0: 0.027797, l1: 0.032201, l2: 0.032957, l3: 0.032559, l4: 0.036912, l5: 0.037839, l6: 0.057756

[epoch:  40/100000, batch:   180/  187, ite: 3756] train loss: 0.525570, tar: 0.064810 
l0: 0.072258, l1: 0.084290, l2: 0.065568, l3: 0.069722, l4: 0.067541, l5: 0.066557, l6: 0.059315

[epoch:  40/100000, batch:   182/  187, ite: 3757] train loss: 0.525548, tar: 0.064815 
l0: 0.043128, l1: 0.045281, l2: 0.048077, l3: 0.042613, l4: 0.044153, l5: 0.042390, l6: 0.052615

[epoch:  40/100000, batch:   184/  187, ite: 3758] train loss: 0.525430, tar: 0.064802 
l0: 0.047378, l1: 0.045705, l2: 0.057580, l3: 0.054064, l4: 0.075288, l5: 0.072586, l6: 0.070770

[epoch:  40/100000, batch:   186/  187, ite: 3759] train loss: 0.525372, tar: 0.064792 
l0: 0.057833, l1: 0.054814, l2: 0.068118, l3: 0.078033, l4: 0.093882, l5: 0.088073, l6: 0.076648

[epoch:  40/100000, batch:   188/  187, ite: 3760] train loss: 0.525367, tar: 0.064788 
l0: 0.035174, l1: 0.039136, l2: 0.043513, l3: 0.038569, l4: 0.038830, l5: 0.041656, l6: 0.038762

[epoch:  41/100000, batch:     2/  187, ite: 3761] train loss: 0.525225, tar: 0.064772 
l0: 0.026117, l1: 0.024808, l2: 0.032754, l3: 0.030477, l4: 0.044910, l5: 0.043344, l6: 0.049333

[epoch:  41/100000, batch:     4/  187, ite: 3762] train loss: 0.525070, tar: 0.064750 
l0: 0.052620, l1: 0.050114, l2: 0.058143, l3: 0.063687, l4: 0.068086, l5: 0.057199, l6: 0.063829

[epoch:  41/100000, batch:     6/  187, ite: 3763] train loss: 0.525007, tar: 0.064743 
l0: 0.079666, l1: 0.083009, l2: 0.074155, l3: 0.075904, l4: 0.099359, l5: 0.098597, l6: 0.083810

[epoch:  41/100000, batch:     8/  187, ite: 3764] train loss: 0.525046, tar: 0.064751 
l0: 0.052077, l1: 0.046044, l2: 0.062242, l3: 0.078036, l4: 0.084378, l5: 0.076448, l6: 0.072368

[epoch:  41/100000, batch:    10/  187, ite: 3765] train loss: 0.525016, tar: 0.064744 
l0: 0.029364, l1: 0.027519, l2: 0.031936, l3: 0.035971, l4: 0.048618, l5: 0.047127, l6: 0.053997

[epoch:  41/100000, batch:    12/  187, ite: 3766] train loss: 0.524874, tar: 0.064724 
l0: 0.050855, l1: 0.042803, l2: 0.063939, l3: 0.076297, l4: 0.072289, l5: 0.081669, l6: 0.063648

[epoch:  41/100000, batch:    14/  187, ite: 3767] train loss: 0.524833, tar: 0.064716 
l0: 0.059236, l1: 0.056372, l2: 0.081150, l3: 0.076889, l4: 0.086042, l5: 0.092131, l6: 0.092375

[epoch:  41/100000, batch:    16/  187, ite: 3768] train loss: 0.524844, tar: 0.064713 
l0: 0.027872, l1: 0.027529, l2: 0.034946, l3: 0.037898, l4: 0.041723, l5: 0.041372, l6: 0.035398

[epoch:  41/100000, batch:    18/  187, ite: 3769] train loss: 0.524686, tar: 0.064692 
l0: 0.065646, l1: 0.065261, l2: 0.062673, l3: 0.074318, l4: 0.080237, l5: 0.091307, l6: 0.088965

[epoch:  41/100000, batch:    20/  187, ite: 3770] train loss: 0.524688, tar: 0.064693 
l0: 0.058481, l1: 0.049902, l2: 0.067723, l3: 0.077250, l4: 0.076989, l5: 0.090940, l6: 0.091305

[epoch:  41/100000, batch:    22/  187, ite: 3771] train loss: 0.524682, tar: 0.064689 
l0: 0.035065, l1: 0.032365, l2: 0.039268, l3: 0.044700, l4: 0.053819, l5: 0.057445, l6: 0.047363

[epoch:  41/100000, batch:    24/  187, ite: 3772] train loss: 0.524560, tar: 0.064673 
l0: 0.053568, l1: 0.054213, l2: 0.062759, l3: 0.063955, l4: 0.061310, l5: 0.068391, l6: 0.066742

[epoch:  41/100000, batch:    26/  187, ite: 3773] train loss: 0.524508, tar: 0.064666 
l0: 0.060770, l1: 0.061742, l2: 0.072123, l3: 0.080832, l4: 0.074115, l5: 0.083337, l6: 0.081988

[epoch:  41/100000, batch:    28/  187, ite: 3774] train loss: 0.524502, tar: 0.064664 
l0: 0.052671, l1: 0.057451, l2: 0.054893, l3: 0.056625, l4: 0.074475, l5: 0.073961, l6: 0.062961

[epoch:  41/100000, batch:    30/  187, ite: 3775] train loss: 0.524451, tar: 0.064657 
l0: 0.041836, l1: 0.039750, l2: 0.066324, l3: 0.055480, l4: 0.062426, l5: 0.063240, l6: 0.063067

[epoch:  41/100000, batch:    32/  187, ite: 3776] train loss: 0.524376, tar: 0.064645 
l0: 0.047477, l1: 0.044548, l2: 0.059083, l3: 0.064913, l4: 0.084222, l5: 0.076936, l6: 0.071443

[epoch:  41/100000, batch:    34/  187, ite: 3777] train loss: 0.524334, tar: 0.064635 
l0: 0.052430, l1: 0.064347, l2: 0.054340, l3: 0.051378, l4: 0.048768, l5: 0.051297, l6: 0.049999

[epoch:  41/100000, batch:    36/  187, ite: 3778] train loss: 0.524248, tar: 0.064628 
l0: 0.245427, l1: 0.285565, l2: 0.265163, l3: 0.222146, l4: 0.237212, l5: 0.260759, l6: 0.191344

[epoch:  41/100000, batch:    38/  187, ite: 3779] train loss: 0.524913, tar: 0.064730 
l0: 0.052634, l1: 0.049782, l2: 0.069930, l3: 0.075623, l4: 0.099307, l5: 0.092206, l6: 0.077040

[epoch:  41/100000, batch:    40/  187, ite: 3780] train loss: 0.524909, tar: 0.064723 
l0: 0.057645, l1: 0.065866, l2: 0.075074, l3: 0.069600, l4: 0.073181, l5: 0.062548, l6: 0.062280

[epoch:  41/100000, batch:    42/  187, ite: 3781] train loss: 0.524876, tar: 0.064719 
l0: 0.062731, l1: 0.075864, l2: 0.057565, l3: 0.054522, l4: 0.061649, l5: 0.071314, l6: 0.061758

[epoch:  41/100000, batch:    44/  187, ite: 3782] train loss: 0.524831, tar: 0.064718 
l0: 0.076327, l1: 0.071290, l2: 0.089184, l3: 0.104884, l4: 0.109285, l5: 0.102855, l6: 0.114080

[epoch:  41/100000, batch:    46/  187, ite: 3783] train loss: 0.524911, tar: 0.064724 
l0: 0.075679, l1: 0.083143, l2: 0.087205, l3: 0.085071, l4: 0.108879, l5: 0.088348, l6: 0.105220

[epoch:  41/100000, batch:    48/  187, ite: 3784] train loss: 0.524972, tar: 0.064730 
l0: 0.043490, l1: 0.038548, l2: 0.047571, l3: 0.052225, l4: 0.067778, l5: 0.076382, l6: 0.085370

[epoch:  41/100000, batch:    50/  187, ite: 3785] train loss: 0.524909, tar: 0.064718 
l0: 0.045535, l1: 0.047410, l2: 0.039558, l3: 0.048207, l4: 0.052583, l5: 0.053411, l6: 0.062732

[epoch:  41/100000, batch:    52/  187, ite: 3786] train loss: 0.524810, tar: 0.064708 
l0: 0.090818, l1: 0.091030, l2: 0.082409, l3: 0.089956, l4: 0.102979, l5: 0.113141, l6: 0.104611

[epoch:  41/100000, batch:    54/  187, ite: 3787] train loss: 0.524894, tar: 0.064722 
l0: 0.035958, l1: 0.039836, l2: 0.046691, l3: 0.041903, l4: 0.049075, l5: 0.047970, l6: 0.039301

[epoch:  41/100000, batch:    56/  187, ite: 3788] train loss: 0.524769, tar: 0.064706 
l0: 0.054298, l1: 0.054282, l2: 0.065762, l3: 0.069710, l4: 0.073485, l5: 0.071779, l6: 0.068882

[epoch:  41/100000, batch:    58/  187, ite: 3789] train loss: 0.524732, tar: 0.064700 
l0: 0.046285, l1: 0.044229, l2: 0.062080, l3: 0.060444, l4: 0.084713, l5: 0.094011, l6: 0.083865

[epoch:  41/100000, batch:    60/  187, ite: 3790] train loss: 0.524704, tar: 0.064690 
l0: 0.104534, l1: 0.103171, l2: 0.124833, l3: 0.099161, l4: 0.135446, l5: 0.163313, l6: 0.184669

[epoch:  41/100000, batch:    62/  187, ite: 3791] train loss: 0.524922, tar: 0.064712 
l0: 0.041235, l1: 0.044115, l2: 0.053804, l3: 0.051061, l4: 0.048255, l5: 0.047917, l6: 0.038974

[epoch:  41/100000, batch:    64/  187, ite: 3792] train loss: 0.524811, tar: 0.064699 
l0: 0.043383, l1: 0.039568, l2: 0.065112, l3: 0.062223, l4: 0.062567, l5: 0.068783, l6: 0.068791

[epoch:  41/100000, batch:    66/  187, ite: 3793] train loss: 0.524747, tar: 0.064687 
l0: 0.063807, l1: 0.061775, l2: 0.072229, l3: 0.074549, l4: 0.094751, l5: 0.097273, l6: 0.096549

[epoch:  41/100000, batch:    68/  187, ite: 3794] train loss: 0.524767, tar: 0.064687 
l0: 0.054529, l1: 0.058870, l2: 0.058522, l3: 0.058299, l4: 0.077975, l5: 0.078517, l6: 0.077057

[epoch:  41/100000, batch:    70/  187, ite: 3795] train loss: 0.524733, tar: 0.064681 
l0: 0.054651, l1: 0.054110, l2: 0.054674, l3: 0.056945, l4: 0.063400, l5: 0.072408, l6: 0.073835

[epoch:  41/100000, batch:    72/  187, ite: 3796] train loss: 0.524681, tar: 0.064676 
l0: 0.042630, l1: 0.044442, l2: 0.050864, l3: 0.048232, l4: 0.046628, l5: 0.051934, l6: 0.052969

[epoch:  41/100000, batch:    74/  187, ite: 3797] train loss: 0.524577, tar: 0.064663 
l0: 0.184494, l1: 0.218346, l2: 0.218795, l3: 0.204130, l4: 0.245845, l5: 0.205304, l6: 0.188310

[epoch:  41/100000, batch:    76/  187, ite: 3798] train loss: 0.525100, tar: 0.064730 
l0: 0.054067, l1: 0.053482, l2: 0.054481, l3: 0.053748, l4: 0.064908, l5: 0.064666, l6: 0.072230

[epoch:  41/100000, batch:    78/  187, ite: 3799] train loss: 0.525040, tar: 0.064724 
l0: 0.032538, l1: 0.031524, l2: 0.034162, l3: 0.034952, l4: 0.045562, l5: 0.047591, l6: 0.046552

[epoch:  41/100000, batch:    80/  187, ite: 3800] train loss: 0.524900, tar: 0.064706 
l0: 0.042522, l1: 0.040969, l2: 0.041937, l3: 0.050619, l4: 0.061541, l5: 0.058122, l6: 0.068044

[epoch:  41/100000, batch:    82/  187, ite: 3801] train loss: 0.524810, tar: 0.064694 
l0: 0.044948, l1: 0.048536, l2: 0.048871, l3: 0.047313, l4: 0.051219, l5: 0.052502, l6: 0.046768

[epoch:  41/100000, batch:    84/  187, ite: 3802] train loss: 0.524708, tar: 0.064683 
l0: 0.033946, l1: 0.034951, l2: 0.037243, l3: 0.042995, l4: 0.048150, l5: 0.043225, l6: 0.039781

[epoch:  41/100000, batch:    86/  187, ite: 3803] train loss: 0.524572, tar: 0.064666 
l0: 0.045194, l1: 0.042539, l2: 0.045809, l3: 0.055346, l4: 0.092330, l5: 0.089685, l6: 0.080666

[epoch:  41/100000, batch:    88/  187, ite: 3804] train loss: 0.524532, tar: 0.064655 
l0: 0.059121, l1: 0.052114, l2: 0.055526, l3: 0.065419, l4: 0.109341, l5: 0.107730, l6: 0.107779

[epoch:  41/100000, batch:    90/  187, ite: 3805] train loss: 0.524550, tar: 0.064652 
l0: 0.042610, l1: 0.037822, l2: 0.042545, l3: 0.043794, l4: 0.067926, l5: 0.076960, l6: 0.068806

[epoch:  41/100000, batch:    92/  187, ite: 3806] train loss: 0.524470, tar: 0.064640 
l0: 0.031519, l1: 0.029142, l2: 0.035731, l3: 0.038697, l4: 0.062570, l5: 0.068458, l6: 0.058178

[epoch:  41/100000, batch:    94/  187, ite: 3807] train loss: 0.524359, tar: 0.064622 
l0: 0.034976, l1: 0.028171, l2: 0.035743, l3: 0.042775, l4: 0.067024, l5: 0.079468, l6: 0.083906

[epoch:  41/100000, batch:    96/  187, ite: 3808] train loss: 0.524275, tar: 0.064605 
l0: 0.040152, l1: 0.037145, l2: 0.040832, l3: 0.056048, l4: 0.072670, l5: 0.075759, l6: 0.066175

[epoch:  41/100000, batch:    98/  187, ite: 3809] train loss: 0.524200, tar: 0.064592 
l0: 0.037537, l1: 0.036690, l2: 0.056116, l3: 0.048852, l4: 0.038756, l5: 0.044148, l6: 0.035438

[epoch:  41/100000, batch:   100/  187, ite: 3810] train loss: 0.524075, tar: 0.064577 
l0: 0.039118, l1: 0.033895, l2: 0.044689, l3: 0.044839, l4: 0.066514, l5: 0.067467, l6: 0.074799

[epoch:  41/100000, batch:   102/  187, ite: 3811] train loss: 0.523991, tar: 0.064563 
l0: 0.051735, l1: 0.054333, l2: 0.067726, l3: 0.073646, l4: 0.056855, l5: 0.055820, l6: 0.061521

[epoch:  41/100000, batch:   104/  187, ite: 3812] train loss: 0.523934, tar: 0.064556 
l0: 0.055008, l1: 0.054636, l2: 0.070059, l3: 0.066177, l4: 0.062198, l5: 0.065677, l6: 0.063296

[epoch:  41/100000, batch:   106/  187, ite: 3813] train loss: 0.523886, tar: 0.064550 
l0: 0.051745, l1: 0.049315, l2: 0.063753, l3: 0.073945, l4: 0.079473, l5: 0.072731, l6: 0.093417

[epoch:  41/100000, batch:   108/  187, ite: 3814] train loss: 0.523864, tar: 0.064543 
l0: 0.036553, l1: 0.041054, l2: 0.038067, l3: 0.047242, l4: 0.055815, l5: 0.058148, l6: 0.059438

[epoch:  41/100000, batch:   110/  187, ite: 3815] train loss: 0.523761, tar: 0.064528 
l0: 0.085206, l1: 0.082587, l2: 0.126642, l3: 0.136135, l4: 0.135350, l5: 0.123976, l6: 0.152938

[epoch:  41/100000, batch:   112/  187, ite: 3816] train loss: 0.523937, tar: 0.064539 
l0: 0.066467, l1: 0.063378, l2: 0.077534, l3: 0.074353, l4: 0.092389, l5: 0.099355, l6: 0.108643

[epoch:  41/100000, batch:   114/  187, ite: 3817] train loss: 0.523969, tar: 0.064540 
l0: 0.039004, l1: 0.037146, l2: 0.043591, l3: 0.044939, l4: 0.068684, l5: 0.071073, l6: 0.071115

[epoch:  41/100000, batch:   116/  187, ite: 3818] train loss: 0.523887, tar: 0.064526 
l0: 0.027964, l1: 0.026155, l2: 0.033166, l3: 0.036287, l4: 0.052650, l5: 0.044294, l6: 0.046030

[epoch:  41/100000, batch:   118/  187, ite: 3819] train loss: 0.523746, tar: 0.064506 
l0: 0.040256, l1: 0.040112, l2: 0.042674, l3: 0.039843, l4: 0.057496, l5: 0.060057, l6: 0.070661

[epoch:  41/100000, batch:   120/  187, ite: 3820] train loss: 0.523651, tar: 0.064493 
l0: 0.069804, l1: 0.073246, l2: 0.091525, l3: 0.084935, l4: 0.064557, l5: 0.069240, l6: 0.079941

[epoch:  41/100000, batch:   122/  187, ite: 3821] train loss: 0.523656, tar: 0.064496 
l0: 0.053507, l1: 0.051850, l2: 0.060535, l3: 0.063797, l4: 0.069469, l5: 0.070789, l6: 0.078874

[epoch:  41/100000, batch:   124/  187, ite: 3822] train loss: 0.523615, tar: 0.064490 
l0: 0.049108, l1: 0.052427, l2: 0.051031, l3: 0.051645, l4: 0.087459, l5: 0.095858, l6: 0.109616

[epoch:  41/100000, batch:   126/  187, ite: 3823] train loss: 0.523601, tar: 0.064481 
l0: 0.060246, l1: 0.058042, l2: 0.073430, l3: 0.074151, l4: 0.081954, l5: 0.083622, l6: 0.082448

[epoch:  41/100000, batch:   128/  187, ite: 3824] train loss: 0.523595, tar: 0.064479 
l0: 0.039465, l1: 0.034164, l2: 0.047261, l3: 0.050513, l4: 0.071136, l5: 0.062996, l6: 0.066394

[epoch:  41/100000, batch:   130/  187, ite: 3825] train loss: 0.523512, tar: 0.064465 
l0: 0.044396, l1: 0.053460, l2: 0.057219, l3: 0.054407, l4: 0.038558, l5: 0.035244, l6: 0.037616

[epoch:  41/100000, batch:   132/  187, ite: 3826] train loss: 0.523401, tar: 0.064454 
l0: 0.038987, l1: 0.043270, l2: 0.047098, l3: 0.050099, l4: 0.056938, l5: 0.060685, l6: 0.065013

[epoch:  41/100000, batch:   134/  187, ite: 3827] train loss: 0.523313, tar: 0.064440 
l0: 0.036478, l1: 0.033977, l2: 0.046950, l3: 0.049946, l4: 0.059489, l5: 0.057713, l6: 0.059247

[epoch:  41/100000, batch:   136/  187, ite: 3828] train loss: 0.523215, tar: 0.064425 
l0: 0.052596, l1: 0.051027, l2: 0.068753, l3: 0.077787, l4: 0.072429, l5: 0.074876, l6: 0.065545

[epoch:  41/100000, batch:   138/  187, ite: 3829] train loss: 0.523182, tar: 0.064418 
l0: 0.061945, l1: 0.063065, l2: 0.074280, l3: 0.080932, l4: 0.093310, l5: 0.099857, l6: 0.096599

[epoch:  41/100000, batch:   140/  187, ite: 3830] train loss: 0.523207, tar: 0.064417 
l0: 0.047258, l1: 0.041565, l2: 0.061117, l3: 0.071283, l4: 0.091681, l5: 0.095593, l6: 0.101726

[epoch:  41/100000, batch:   142/  187, ite: 3831] train loss: 0.523200, tar: 0.064408 
l0: 0.057926, l1: 0.063477, l2: 0.053378, l3: 0.054028, l4: 0.061490, l5: 0.060954, l6: 0.061417

[epoch:  41/100000, batch:   144/  187, ite: 3832] train loss: 0.523140, tar: 0.064404 
l0: 0.026674, l1: 0.025163, l2: 0.027224, l3: 0.032151, l4: 0.046980, l5: 0.051841, l6: 0.046066

[epoch:  41/100000, batch:   146/  187, ite: 3833] train loss: 0.522994, tar: 0.064384 
l0: 0.041045, l1: 0.039790, l2: 0.041109, l3: 0.049186, l4: 0.065307, l5: 0.055141, l6: 0.066719

[epoch:  41/100000, batch:   148/  187, ite: 3834] train loss: 0.522904, tar: 0.064371 
l0: 0.049044, l1: 0.046907, l2: 0.066411, l3: 0.059910, l4: 0.058838, l5: 0.056967, l6: 0.063898

[epoch:  41/100000, batch:   150/  187, ite: 3835] train loss: 0.522839, tar: 0.064363 
l0: 0.034058, l1: 0.031537, l2: 0.043175, l3: 0.040903, l4: 0.064367, l5: 0.065257, l6: 0.064331

[epoch:  41/100000, batch:   152/  187, ite: 3836] train loss: 0.522741, tar: 0.064346 
l0: 0.051739, l1: 0.058668, l2: 0.063468, l3: 0.052553, l4: 0.078315, l5: 0.072112, l6: 0.067753

[epoch:  41/100000, batch:   154/  187, ite: 3837] train loss: 0.522698, tar: 0.064339 
l0: 0.067330, l1: 0.066423, l2: 0.096520, l3: 0.082501, l4: 0.088880, l5: 0.078298, l6: 0.083982

[epoch:  41/100000, batch:   156/  187, ite: 3838] train loss: 0.522721, tar: 0.064341 
l0: 0.035554, l1: 0.038261, l2: 0.042220, l3: 0.040302, l4: 0.043536, l5: 0.050449, l6: 0.052673

[epoch:  41/100000, batch:   158/  187, ite: 3839] train loss: 0.522601, tar: 0.064325 
l0: 0.031771, l1: 0.030889, l2: 0.036915, l3: 0.034789, l4: 0.049875, l5: 0.058709, l6: 0.055856

[epoch:  41/100000, batch:   160/  187, ite: 3840] train loss: 0.522480, tar: 0.064307 
l0: 0.038484, l1: 0.048321, l2: 0.048326, l3: 0.036002, l4: 0.053759, l5: 0.053170, l6: 0.040783

[epoch:  41/100000, batch:   162/  187, ite: 3841] train loss: 0.522369, tar: 0.064293 
l0: 0.048241, l1: 0.056590, l2: 0.049551, l3: 0.042956, l4: 0.044765, l5: 0.039246, l6: 0.035843

[epoch:  41/100000, batch:   164/  187, ite: 3842] train loss: 0.522258, tar: 0.064285 
l0: 0.038157, l1: 0.035637, l2: 0.043354, l3: 0.049371, l4: 0.062458, l5: 0.056877, l6: 0.059603

[epoch:  41/100000, batch:   166/  187, ite: 3843] train loss: 0.522162, tar: 0.064271 
l0: 0.024293, l1: 0.025150, l2: 0.028709, l3: 0.029190, l4: 0.043404, l5: 0.043712, l6: 0.045878

[epoch:  41/100000, batch:   168/  187, ite: 3844] train loss: 0.522009, tar: 0.064249 
l0: 0.051221, l1: 0.053569, l2: 0.060224, l3: 0.054698, l4: 0.074032, l5: 0.071210, l6: 0.061407

[epoch:  41/100000, batch:   170/  187, ite: 3845] train loss: 0.521957, tar: 0.064242 
l0: 0.030794, l1: 0.025313, l2: 0.044345, l3: 0.049473, l4: 0.066842, l5: 0.069253, l6: 0.079460

[epoch:  41/100000, batch:   172/  187, ite: 3846] train loss: 0.521872, tar: 0.064224 
l0: 0.054237, l1: 0.056803, l2: 0.064846, l3: 0.066947, l4: 0.075272, l5: 0.071994, l6: 0.084149

[epoch:  41/100000, batch:   174/  187, ite: 3847] train loss: 0.521847, tar: 0.064218 
l0: 0.102289, l1: 0.108149, l2: 0.130090, l3: 0.112759, l4: 0.126365, l5: 0.118546, l6: 0.104647

[epoch:  41/100000, batch:   176/  187, ite: 3848] train loss: 0.521999, tar: 0.064239 
l0: 0.039823, l1: 0.046824, l2: 0.059000, l3: 0.056138, l4: 0.071371, l5: 0.080562, l6: 0.081284

[epoch:  41/100000, batch:   178/  187, ite: 3849] train loss: 0.521952, tar: 0.064226 
l0: 0.041246, l1: 0.044916, l2: 0.060797, l3: 0.055244, l4: 0.063095, l5: 0.070071, l6: 0.055390

[epoch:  41/100000, batch:   180/  187, ite: 3850] train loss: 0.521881, tar: 0.064213 
l0: 0.040342, l1: 0.035278, l2: 0.045105, l3: 0.054776, l4: 0.085301, l5: 0.093498, l6: 0.087376

[epoch:  41/100000, batch:   182/  187, ite: 3851] train loss: 0.521837, tar: 0.064200 
l0: 0.052274, l1: 0.055040, l2: 0.058035, l3: 0.058713, l4: 0.068460, l5: 0.066659, l6: 0.065749

[epoch:  41/100000, batch:   184/  187, ite: 3852] train loss: 0.521785, tar: 0.064194 
l0: 0.036640, l1: 0.039823, l2: 0.055961, l3: 0.050150, l4: 0.037807, l5: 0.034603, l6: 0.033662

[epoch:  41/100000, batch:   186/  187, ite: 3853] train loss: 0.521659, tar: 0.064179 
l0: 0.068605, l1: 0.070886, l2: 0.067559, l3: 0.072383, l4: 0.080839, l5: 0.069226, l6: 0.074322

[epoch:  41/100000, batch:   188/  187, ite: 3854] train loss: 0.521650, tar: 0.064181 
l0: 0.027325, l1: 0.027407, l2: 0.030271, l3: 0.032391, l4: 0.057371, l5: 0.065593, l6: 0.075564

[epoch:  42/100000, batch:     2/  187, ite: 3855] train loss: 0.521539, tar: 0.064162 
l0: 0.058924, l1: 0.052822, l2: 0.083807, l3: 0.087513, l4: 0.076272, l5: 0.075169, l6: 0.092300

[epoch:  42/100000, batch:     4/  187, ite: 3856] train loss: 0.521542, tar: 0.064159 
l0: 0.023661, l1: 0.026934, l2: 0.033759, l3: 0.028111, l4: 0.040293, l5: 0.040610, l6: 0.036661

[epoch:  42/100000, batch:     6/  187, ite: 3857] train loss: 0.521385, tar: 0.064137 
l0: 0.051459, l1: 0.047649, l2: 0.060500, l3: 0.058733, l4: 0.071496, l5: 0.084302, l6: 0.086010

[epoch:  42/100000, batch:     8/  187, ite: 3858] train loss: 0.521352, tar: 0.064130 
l0: 0.043229, l1: 0.047104, l2: 0.047731, l3: 0.055988, l4: 0.073317, l5: 0.057366, l6: 0.068002

[epoch:  42/100000, batch:    10/  187, ite: 3859] train loss: 0.521282, tar: 0.064119 
l0: 0.038423, l1: 0.034877, l2: 0.047471, l3: 0.052118, l4: 0.054761, l5: 0.057941, l6: 0.063005

[epoch:  42/100000, batch:    12/  187, ite: 3860] train loss: 0.521190, tar: 0.064105 
l0: 0.030777, l1: 0.025864, l2: 0.042800, l3: 0.046686, l4: 0.067174, l5: 0.070434, l6: 0.073230

[epoch:  42/100000, batch:    14/  187, ite: 3861] train loss: 0.521101, tar: 0.064087 
l0: 0.051065, l1: 0.050840, l2: 0.056362, l3: 0.065443, l4: 0.071984, l5: 0.076933, l6: 0.069740

[epoch:  42/100000, batch:    16/  187, ite: 3862] train loss: 0.521059, tar: 0.064080 
l0: 0.037892, l1: 0.036450, l2: 0.045822, l3: 0.050851, l4: 0.071836, l5: 0.078115, l6: 0.080366

[epoch:  42/100000, batch:    18/  187, ite: 3863] train loss: 0.520995, tar: 0.064066 
l0: 0.075951, l1: 0.084033, l2: 0.087620, l3: 0.078389, l4: 0.107445, l5: 0.092491, l6: 0.084243

[epoch:  42/100000, batch:    20/  187, ite: 3864] train loss: 0.521043, tar: 0.064072 
l0: 0.052138, l1: 0.063542, l2: 0.062788, l3: 0.066075, l4: 0.077626, l5: 0.065227, l6: 0.070009

[epoch:  42/100000, batch:    22/  187, ite: 3865] train loss: 0.521008, tar: 0.064066 
l0: 0.040938, l1: 0.031806, l2: 0.056536, l3: 0.059929, l4: 0.098260, l5: 0.109886, l6: 0.142807

[epoch:  42/100000, batch:    24/  187, ite: 3866] train loss: 0.521019, tar: 0.064054 
l0: 0.040081, l1: 0.037925, l2: 0.044407, l3: 0.046544, l4: 0.059227, l5: 0.062086, l6: 0.071211

[epoch:  42/100000, batch:    26/  187, ite: 3867] train loss: 0.520933, tar: 0.064041 
l0: 0.052157, l1: 0.055782, l2: 0.051805, l3: 0.055055, l4: 0.064571, l5: 0.065108, l6: 0.071265

[epoch:  42/100000, batch:    28/  187, ite: 3868] train loss: 0.520877, tar: 0.064034 
l0: 0.055014, l1: 0.063112, l2: 0.058527, l3: 0.060140, l4: 0.068091, l5: 0.063050, l6: 0.064421

[epoch:  42/100000, batch:    30/  187, ite: 3869] train loss: 0.520830, tar: 0.064030 
l0: 0.082532, l1: 0.085451, l2: 0.076932, l3: 0.082279, l4: 0.091634, l5: 0.094931, l6: 0.098182

[epoch:  42/100000, batch:    32/  187, ite: 3870] train loss: 0.520878, tar: 0.064040 
l0: 0.042275, l1: 0.039862, l2: 0.064579, l3: 0.057657, l4: 0.055522, l5: 0.064670, l6: 0.057395

[epoch:  42/100000, batch:    34/  187, ite: 3871] train loss: 0.520804, tar: 0.064028 
l0: 0.035215, l1: 0.026789, l2: 0.053300, l3: 0.062221, l4: 0.096909, l5: 0.106698, l6: 0.122645

[epoch:  42/100000, batch:    36/  187, ite: 3872] train loss: 0.520795, tar: 0.064013 
l0: 0.038559, l1: 0.034076, l2: 0.041713, l3: 0.046540, l4: 0.072818, l5: 0.077822, l6: 0.080825

[epoch:  42/100000, batch:    38/  187, ite: 3873] train loss: 0.520726, tar: 0.063999 
l0: 0.047761, l1: 0.044999, l2: 0.052147, l3: 0.059264, l4: 0.073973, l5: 0.082425, l6: 0.077264

[epoch:  42/100000, batch:    40/  187, ite: 3874] train loss: 0.520682, tar: 0.063990 
l0: 0.022971, l1: 0.020029, l2: 0.027550, l3: 0.027551, l4: 0.036923, l5: 0.034196, l6: 0.041670

[epoch:  42/100000, batch:    42/  187, ite: 3875] train loss: 0.520517, tar: 0.063968 
l0: 0.030620, l1: 0.031933, l2: 0.031107, l3: 0.039860, l4: 0.043598, l5: 0.041553, l6: 0.042958

[epoch:  42/100000, batch:    44/  187, ite: 3876] train loss: 0.520379, tar: 0.063951 
l0: 0.070175, l1: 0.067167, l2: 0.073581, l3: 0.089956, l4: 0.092110, l5: 0.084586, l6: 0.083015

[epoch:  42/100000, batch:    46/  187, ite: 3877] train loss: 0.520400, tar: 0.063954 
l0: 0.050076, l1: 0.051845, l2: 0.053737, l3: 0.056376, l4: 0.061807, l5: 0.070372, l6: 0.072295

[epoch:  42/100000, batch:    48/  187, ite: 3878] train loss: 0.520345, tar: 0.063947 
l0: 0.017515, l1: 0.016256, l2: 0.018391, l3: 0.020567, l4: 0.032580, l5: 0.040046, l6: 0.054481

[epoch:  42/100000, batch:    50/  187, ite: 3879] train loss: 0.520174, tar: 0.063922 
l0: 0.031664, l1: 0.035167, l2: 0.040722, l3: 0.037329, l4: 0.039568, l5: 0.036967, l6: 0.033702

[epoch:  42/100000, batch:    52/  187, ite: 3880] train loss: 0.520033, tar: 0.063905 
l0: 0.036488, l1: 0.040735, l2: 0.044959, l3: 0.050481, l4: 0.050046, l5: 0.043461, l6: 0.052628

[epoch:  42/100000, batch:    54/  187, ite: 3881] train loss: 0.519927, tar: 0.063890 
l0: 0.043187, l1: 0.039720, l2: 0.046550, l3: 0.067686, l4: 0.074420, l5: 0.069719, l6: 0.072103

[epoch:  42/100000, batch:    56/  187, ite: 3882] train loss: 0.519870, tar: 0.063879 
l0: 0.045535, l1: 0.057914, l2: 0.048996, l3: 0.036523, l4: 0.049954, l5: 0.047040, l6: 0.049051

[epoch:  42/100000, batch:    58/  187, ite: 3883] train loss: 0.519772, tar: 0.063869 
l0: 0.062687, l1: 0.068776, l2: 0.072743, l3: 0.083766, l4: 0.087585, l5: 0.077895, l6: 0.083184

[epoch:  42/100000, batch:    60/  187, ite: 3884] train loss: 0.519781, tar: 0.063869 
l0: 0.035090, l1: 0.034033, l2: 0.033601, l3: 0.039137, l4: 0.053933, l5: 0.048859, l6: 0.060852

[epoch:  42/100000, batch:    62/  187, ite: 3885] train loss: 0.519667, tar: 0.063853 
l0: 0.033484, l1: 0.046979, l2: 0.037982, l3: 0.032686, l4: 0.038736, l5: 0.036357, l6: 0.038802

[epoch:  42/100000, batch:    64/  187, ite: 3886] train loss: 0.519532, tar: 0.063837 
l0: 0.058945, l1: 0.058091, l2: 0.081539, l3: 0.079588, l4: 0.096594, l5: 0.095613, l6: 0.094226

[epoch:  42/100000, batch:    66/  187, ite: 3887] train loss: 0.519556, tar: 0.063835 
l0: 0.044695, l1: 0.051583, l2: 0.062789, l3: 0.065237, l4: 0.062234, l5: 0.053105, l6: 0.046908

[epoch:  42/100000, batch:    68/  187, ite: 3888] train loss: 0.519485, tar: 0.063825 
l0: 0.031873, l1: 0.038992, l2: 0.028471, l3: 0.033432, l4: 0.046323, l5: 0.048745, l6: 0.046626

[epoch:  42/100000, batch:    70/  187, ite: 3889] train loss: 0.519356, tar: 0.063808 
l0: 0.036527, l1: 0.036007, l2: 0.042533, l3: 0.052967, l4: 0.042673, l5: 0.043561, l6: 0.040842

[epoch:  42/100000, batch:    72/  187, ite: 3890] train loss: 0.519237, tar: 0.063793 
l0: 0.020592, l1: 0.017347, l2: 0.020439, l3: 0.024466, l4: 0.053054, l5: 0.064970, l6: 0.071376

[epoch:  42/100000, batch:    74/  187, ite: 3891] train loss: 0.519106, tar: 0.063770 
l0: 0.033180, l1: 0.029224, l2: 0.049221, l3: 0.043166, l4: 0.058975, l5: 0.056458, l6: 0.059641

[epoch:  42/100000, batch:    76/  187, ite: 3892] train loss: 0.519006, tar: 0.063754 
l0: 0.041965, l1: 0.039440, l2: 0.057095, l3: 0.046061, l4: 0.063104, l5: 0.062104, l6: 0.061524

[epoch:  42/100000, batch:    78/  187, ite: 3893] train loss: 0.518928, tar: 0.063743 
l0: 0.033571, l1: 0.036750, l2: 0.033403, l3: 0.037023, l4: 0.066674, l5: 0.065562, l6: 0.059705

[epoch:  42/100000, batch:    80/  187, ite: 3894] train loss: 0.518830, tar: 0.063727 
l0: 0.045162, l1: 0.044237, l2: 0.055538, l3: 0.059912, l4: 0.103609, l5: 0.081794, l6: 0.063688

[epoch:  42/100000, batch:    82/  187, ite: 3895] train loss: 0.518796, tar: 0.063717 
l0: 0.034927, l1: 0.038984, l2: 0.044802, l3: 0.040796, l4: 0.060062, l5: 0.058810, l6: 0.070071

[epoch:  42/100000, batch:    84/  187, ite: 3896] train loss: 0.518706, tar: 0.063702 
l0: 0.048097, l1: 0.049754, l2: 0.054734, l3: 0.058854, l4: 0.053868, l5: 0.060519, l6: 0.071674

[epoch:  42/100000, batch:    86/  187, ite: 3897] train loss: 0.518642, tar: 0.063694 
l0: 0.035180, l1: 0.039829, l2: 0.048879, l3: 0.040816, l4: 0.029794, l5: 0.029948, l6: 0.030164

[epoch:  42/100000, batch:    88/  187, ite: 3898] train loss: 0.518503, tar: 0.063679 
l0: 0.034303, l1: 0.032186, l2: 0.034371, l3: 0.044053, l4: 0.064206, l5: 0.068874, l6: 0.067819

[epoch:  42/100000, batch:    90/  187, ite: 3899] train loss: 0.518412, tar: 0.063663 
l0: 0.031684, l1: 0.032337, l2: 0.037502, l3: 0.033688, l4: 0.041176, l5: 0.041166, l6: 0.037567

[epoch:  42/100000, batch:    92/  187, ite: 3900] train loss: 0.518273, tar: 0.063646 
l0: 0.049748, l1: 0.055073, l2: 0.055224, l3: 0.052740, l4: 0.053036, l5: 0.045001, l6: 0.044978

[epoch:  42/100000, batch:    94/  187, ite: 3901] train loss: 0.518188, tar: 0.063639 
l0: 0.041661, l1: 0.036249, l2: 0.065409, l3: 0.062981, l4: 0.056010, l5: 0.061011, l6: 0.069882

[epoch:  42/100000, batch:    96/  187, ite: 3902] train loss: 0.518122, tar: 0.063627 
l0: 0.039717, l1: 0.037642, l2: 0.069364, l3: 0.069757, l4: 0.075034, l5: 0.062496, l6: 0.057054

[epoch:  42/100000, batch:    98/  187, ite: 3903] train loss: 0.518066, tar: 0.063615 
l0: 0.034266, l1: 0.031974, l2: 0.040528, l3: 0.046713, l4: 0.053933, l5: 0.051871, l6: 0.053304

[epoch:  42/100000, batch:   100/  187, ite: 3904] train loss: 0.517958, tar: 0.063599 
l0: 0.058149, l1: 0.065024, l2: 0.048081, l3: 0.050834, l4: 0.058091, l5: 0.073504, l6: 0.087067

[epoch:  42/100000, batch:   102/  187, ite: 3905] train loss: 0.517918, tar: 0.063597 
l0: 0.072864, l1: 0.067218, l2: 0.086597, l3: 0.087083, l4: 0.095664, l5: 0.128475, l6: 0.140018

[epoch:  42/100000, batch:   104/  187, ite: 3906] train loss: 0.518002, tar: 0.063601 
l0: 0.058638, l1: 0.059587, l2: 0.059002, l3: 0.059692, l4: 0.081765, l5: 0.083270, l6: 0.087670

[epoch:  42/100000, batch:   106/  187, ite: 3907] train loss: 0.517987, tar: 0.063599 
l0: 0.036221, l1: 0.034209, l2: 0.047608, l3: 0.056085, l4: 0.098826, l5: 0.092635, l6: 0.077373

[epoch:  42/100000, batch:   108/  187, ite: 3908] train loss: 0.517947, tar: 0.063585 
l0: 0.071155, l1: 0.078415, l2: 0.064456, l3: 0.067722, l4: 0.090106, l5: 0.094545, l6: 0.088702

[epoch:  42/100000, batch:   110/  187, ite: 3909] train loss: 0.517967, tar: 0.063588 
l0: 0.069177, l1: 0.086750, l2: 0.074338, l3: 0.056705, l4: 0.063103, l5: 0.064390, l6: 0.055245

[epoch:  42/100000, batch:   112/  187, ite: 3910] train loss: 0.517942, tar: 0.063591 
l0: 0.043078, l1: 0.042598, l2: 0.061475, l3: 0.065143, l4: 0.052421, l5: 0.054748, l6: 0.058995

[epoch:  42/100000, batch:   114/  187, ite: 3911] train loss: 0.517869, tar: 0.063581 
l0: 0.034235, l1: 0.036355, l2: 0.041205, l3: 0.039532, l4: 0.045514, l5: 0.045167, l6: 0.043868

[epoch:  42/100000, batch:   116/  187, ite: 3912] train loss: 0.517747, tar: 0.063565 
l0: 0.034613, l1: 0.033980, l2: 0.047827, l3: 0.035644, l4: 0.059784, l5: 0.050298, l6: 0.047168

[epoch:  42/100000, batch:   118/  187, ite: 3913] train loss: 0.517638, tar: 0.063550 
l0: 0.025764, l1: 0.029375, l2: 0.032903, l3: 0.029802, l4: 0.029991, l5: 0.033406, l6: 0.030833

[epoch:  42/100000, batch:   120/  187, ite: 3914] train loss: 0.517479, tar: 0.063530 
l0: 0.035196, l1: 0.032568, l2: 0.042178, l3: 0.039839, l4: 0.052858, l5: 0.051810, l6: 0.057037

[epoch:  42/100000, batch:   122/  187, ite: 3915] train loss: 0.517371, tar: 0.063516 
l0: 0.040444, l1: 0.037999, l2: 0.039105, l3: 0.040754, l4: 0.053387, l5: 0.058462, l6: 0.063646

[epoch:  42/100000, batch:   124/  187, ite: 3916] train loss: 0.517275, tar: 0.063504 
l0: 0.069413, l1: 0.068676, l2: 0.077979, l3: 0.078686, l4: 0.070985, l5: 0.077064, l6: 0.082875

[epoch:  42/100000, batch:   126/  187, ite: 3917] train loss: 0.517280, tar: 0.063507 
l0: 0.034449, l1: 0.038366, l2: 0.031943, l3: 0.029116, l4: 0.039413, l5: 0.039755, l6: 0.037106

[epoch:  42/100000, batch:   128/  187, ite: 3918] train loss: 0.517140, tar: 0.063492 
l0: 0.027394, l1: 0.028147, l2: 0.030825, l3: 0.027220, l4: 0.045287, l5: 0.040875, l6: 0.042240

[epoch:  42/100000, batch:   130/  187, ite: 3919] train loss: 0.516997, tar: 0.063473 
l0: 0.050550, l1: 0.045719, l2: 0.057069, l3: 0.060728, l4: 0.069879, l5: 0.081197, l6: 0.093861

[epoch:  42/100000, batch:   132/  187, ite: 3920] train loss: 0.516967, tar: 0.063466 
l0: 0.035616, l1: 0.036287, l2: 0.039227, l3: 0.039395, l4: 0.059911, l5: 0.052080, l6: 0.046862

[epoch:  42/100000, batch:   134/  187, ite: 3921] train loss: 0.516859, tar: 0.063452 
l0: 0.029814, l1: 0.029602, l2: 0.033676, l3: 0.033628, l4: 0.056154, l5: 0.058357, l6: 0.067293

[epoch:  42/100000, batch:   136/  187, ite: 3922] train loss: 0.516750, tar: 0.063434 
l0: 0.026707, l1: 0.023103, l2: 0.039801, l3: 0.038684, l4: 0.041721, l5: 0.068716, l6: 0.075614

[epoch:  42/100000, batch:   138/  187, ite: 3923] train loss: 0.516645, tar: 0.063415 
l0: 0.033835, l1: 0.037436, l2: 0.046672, l3: 0.048387, l4: 0.065102, l5: 0.051315, l6: 0.048725

[epoch:  42/100000, batch:   140/  187, ite: 3924] train loss: 0.516549, tar: 0.063400 
l0: 0.058127, l1: 0.056675, l2: 0.059084, l3: 0.066531, l4: 0.082475, l5: 0.093819, l6: 0.097161

[epoch:  42/100000, batch:   142/  187, ite: 3925] train loss: 0.516547, tar: 0.063397 
l0: 0.020136, l1: 0.020998, l2: 0.029117, l3: 0.026295, l4: 0.033551, l5: 0.027245, l6: 0.023345

[epoch:  42/100000, batch:   144/  187, ite: 3926] train loss: 0.516373, tar: 0.063374 
l0: 0.036203, l1: 0.038630, l2: 0.039306, l3: 0.039142, l4: 0.041681, l5: 0.043155, l6: 0.046189

[epoch:  42/100000, batch:   146/  187, ite: 3927] train loss: 0.516253, tar: 0.063360 
l0: 0.080933, l1: 0.089449, l2: 0.101828, l3: 0.079727, l4: 0.080739, l5: 0.081349, l6: 0.082353

[epoch:  42/100000, batch:   148/  187, ite: 3928] train loss: 0.516294, tar: 0.063369 
l0: 0.046191, l1: 0.043590, l2: 0.056451, l3: 0.059893, l4: 0.078155, l5: 0.080214, l6: 0.076417

[epoch:  42/100000, batch:   150/  187, ite: 3929] train loss: 0.516255, tar: 0.063360 
l0: 0.028331, l1: 0.030589, l2: 0.032783, l3: 0.032881, l4: 0.035992, l5: 0.031824, l6: 0.031456

[epoch:  42/100000, batch:   152/  187, ite: 3930] train loss: 0.516104, tar: 0.063342 
l0: 0.021495, l1: 0.019734, l2: 0.032214, l3: 0.033161, l4: 0.044495, l5: 0.045021, l6: 0.043868

[epoch:  42/100000, batch:   154/  187, ite: 3931] train loss: 0.515961, tar: 0.063321 
l0: 0.057777, l1: 0.066559, l2: 0.055667, l3: 0.052822, l4: 0.067426, l5: 0.071264, l6: 0.084288

[epoch:  42/100000, batch:   156/  187, ite: 3932] train loss: 0.515929, tar: 0.063318 
l0: 0.037935, l1: 0.037705, l2: 0.052833, l3: 0.043207, l4: 0.049086, l5: 0.045058, l6: 0.046179

[epoch:  42/100000, batch:   158/  187, ite: 3933] train loss: 0.515824, tar: 0.063305 
l0: 0.058011, l1: 0.058748, l2: 0.067930, l3: 0.073224, l4: 0.047781, l5: 0.051116, l6: 0.064006

[epoch:  42/100000, batch:   160/  187, ite: 3934] train loss: 0.515775, tar: 0.063302 
l0: 0.041630, l1: 0.043776, l2: 0.057353, l3: 0.049899, l4: 0.061091, l5: 0.061069, l6: 0.051656

[epoch:  42/100000, batch:   162/  187, ite: 3935] train loss: 0.515698, tar: 0.063291 
l0: 0.046451, l1: 0.046337, l2: 0.048550, l3: 0.046800, l4: 0.055099, l5: 0.059887, l6: 0.058627

[epoch:  42/100000, batch:   164/  187, ite: 3936] train loss: 0.515618, tar: 0.063282 
l0: 0.048428, l1: 0.052595, l2: 0.051045, l3: 0.049391, l4: 0.063026, l5: 0.066881, l6: 0.061722

[epoch:  42/100000, batch:   166/  187, ite: 3937] train loss: 0.515555, tar: 0.063274 
l0: 0.043624, l1: 0.042343, l2: 0.065230, l3: 0.067723, l4: 0.056358, l5: 0.045877, l6: 0.061694

[epoch:  42/100000, batch:   168/  187, ite: 3938] train loss: 0.515486, tar: 0.063264 
l0: 0.050054, l1: 0.042259, l2: 0.054553, l3: 0.070100, l4: 0.077742, l5: 0.078214, l6: 0.077579

[epoch:  42/100000, batch:   170/  187, ite: 3939] train loss: 0.515453, tar: 0.063257 
l0: 0.029264, l1: 0.029501, l2: 0.035987, l3: 0.040812, l4: 0.061293, l5: 0.052259, l6: 0.041982

[epoch:  42/100000, batch:   172/  187, ite: 3940] train loss: 0.515337, tar: 0.063240 
l0: 0.048896, l1: 0.056184, l2: 0.063091, l3: 0.055218, l4: 0.059939, l5: 0.060460, l6: 0.057119

[epoch:  42/100000, batch:   174/  187, ite: 3941] train loss: 0.515278, tar: 0.063232 
l0: 0.033042, l1: 0.031696, l2: 0.054406, l3: 0.058303, l4: 0.058827, l5: 0.057764, l6: 0.051150

[epoch:  42/100000, batch:   176/  187, ite: 3942] train loss: 0.515191, tar: 0.063217 
l0: 0.050429, l1: 0.054853, l2: 0.043482, l3: 0.051425, l4: 0.055834, l5: 0.056512, l6: 0.056548

[epoch:  42/100000, batch:   178/  187, ite: 3943] train loss: 0.515115, tar: 0.063210 
l0: 0.032231, l1: 0.033456, l2: 0.039279, l3: 0.040788, l4: 0.052764, l5: 0.039721, l6: 0.043374

[epoch:  42/100000, batch:   180/  187, ite: 3944] train loss: 0.514995, tar: 0.063194 
l0: 0.040656, l1: 0.041549, l2: 0.080460, l3: 0.065067, l4: 0.082744, l5: 0.068256, l6: 0.100244

[epoch:  42/100000, batch:   182/  187, ite: 3945] train loss: 0.514977, tar: 0.063183 
l0: 0.043058, l1: 0.040892, l2: 0.044246, l3: 0.049606, l4: 0.101521, l5: 0.091005, l6: 0.084184

[epoch:  42/100000, batch:   184/  187, ite: 3946] train loss: 0.514946, tar: 0.063172 
l0: 0.052896, l1: 0.059052, l2: 0.060393, l3: 0.054093, l4: 0.052791, l5: 0.063666, l6: 0.053281

[epoch:  42/100000, batch:   186/  187, ite: 3947] train loss: 0.514885, tar: 0.063167 
l0: 0.011724, l1: 0.016365, l2: 0.021778, l3: 0.015354, l4: 0.035756, l5: 0.033266, l6: 0.016051

[epoch:  42/100000, batch:   188/  187, ite: 3948] train loss: 0.514698, tar: 0.063141 
l0: 0.016048, l1: 0.017242, l2: 0.015760, l3: 0.016488, l4: 0.018151, l5: 0.018759, l6: 0.031732

[epoch:  43/100000, batch:     2/  187, ite: 3949] train loss: 0.514502, tar: 0.063117 
l0: 0.027838, l1: 0.027429, l2: 0.035660, l3: 0.037525, l4: 0.037815, l5: 0.038789, l6: 0.029907

[epoch:  43/100000, batch:     4/  187, ite: 3950] train loss: 0.514359, tar: 0.063099 
l0: 0.043121, l1: 0.041613, l2: 0.054125, l3: 0.060675, l4: 0.059897, l5: 0.060123, l6: 0.042602

[epoch:  43/100000, batch:     6/  187, ite: 3951] train loss: 0.514281, tar: 0.063088 
l0: 0.094521, l1: 0.105652, l2: 0.112272, l3: 0.106202, l4: 0.102283, l5: 0.086557, l6: 0.070956

[epoch:  43/100000, batch:     8/  187, ite: 3952] train loss: 0.514365, tar: 0.063104 
l0: 0.059619, l1: 0.061192, l2: 0.071928, l3: 0.063564, l4: 0.065704, l5: 0.055093, l6: 0.061853

[epoch:  43/100000, batch:    10/  187, ite: 3953] train loss: 0.514326, tar: 0.063103 
l0: 0.048956, l1: 0.052057, l2: 0.060590, l3: 0.054548, l4: 0.057982, l5: 0.046177, l6: 0.056439

[epoch:  43/100000, batch:    12/  187, ite: 3954] train loss: 0.514256, tar: 0.063095 
l0: 0.046275, l1: 0.049919, l2: 0.054602, l3: 0.047171, l4: 0.068907, l5: 0.057627, l6: 0.051068

[epoch:  43/100000, batch:    14/  187, ite: 3955] train loss: 0.514185, tar: 0.063087 
l0: 0.061058, l1: 0.060668, l2: 0.074712, l3: 0.085095, l4: 0.094612, l5: 0.096951, l6: 0.079219

[epoch:  43/100000, batch:    16/  187, ite: 3956] train loss: 0.514205, tar: 0.063086 
l0: 0.030520, l1: 0.032813, l2: 0.026338, l3: 0.028366, l4: 0.038083, l5: 0.048243, l6: 0.044887

[epoch:  43/100000, batch:    18/  187, ite: 3957] train loss: 0.514069, tar: 0.063069 
l0: 0.030829, l1: 0.029295, l2: 0.037368, l3: 0.045013, l4: 0.066669, l5: 0.057403, l6: 0.064719

[epoch:  43/100000, batch:    20/  187, ite: 3958] train loss: 0.513976, tar: 0.063053 
l0: 0.067720, l1: 0.058161, l2: 0.082214, l3: 0.094931, l4: 0.116421, l5: 0.148627, l6: 0.139871

[epoch:  43/100000, batch:    22/  187, ite: 3959] train loss: 0.514075, tar: 0.063055 
l0: 0.026505, l1: 0.028000, l2: 0.026857, l3: 0.033906, l4: 0.034196, l5: 0.035893, l6: 0.035068

[epoch:  43/100000, batch:    24/  187, ite: 3960] train loss: 0.513925, tar: 0.063036 
l0: 0.035634, l1: 0.031545, l2: 0.041858, l3: 0.045827, l4: 0.056503, l5: 0.065506, l6: 0.064733

[epoch:  43/100000, batch:    26/  187, ite: 3961] train loss: 0.513837, tar: 0.063022 
l0: 0.057469, l1: 0.062501, l2: 0.061919, l3: 0.068975, l4: 0.083317, l5: 0.079775, l6: 0.074723

[epoch:  43/100000, batch:    28/  187, ite: 3962] train loss: 0.513824, tar: 0.063020 
l0: 0.050337, l1: 0.058273, l2: 0.055806, l3: 0.056264, l4: 0.070149, l5: 0.067130, l6: 0.063188

[epoch:  43/100000, batch:    30/  187, ite: 3963] train loss: 0.513777, tar: 0.063013 
l0: 0.048869, l1: 0.054191, l2: 0.042401, l3: 0.043996, l4: 0.083934, l5: 0.082645, l6: 0.077640

[epoch:  43/100000, batch:    32/  187, ite: 3964] train loss: 0.513736, tar: 0.063006 
l0: 0.037825, l1: 0.035894, l2: 0.038053, l3: 0.043441, l4: 0.058634, l5: 0.066711, l6: 0.065297

[epoch:  43/100000, batch:    34/  187, ite: 3965] train loss: 0.513651, tar: 0.062993 
l0: 0.061655, l1: 0.047693, l2: 0.062597, l3: 0.087643, l4: 0.195415, l5: 0.172242, l6: 0.168187

[epoch:  43/100000, batch:    36/  187, ite: 3966] train loss: 0.513794, tar: 0.062992 
l0: 0.022026, l1: 0.022156, l2: 0.026517, l3: 0.024488, l4: 0.037890, l5: 0.043096, l6: 0.042762

[epoch:  43/100000, batch:    38/  187, ite: 3967] train loss: 0.513644, tar: 0.062972 
l0: 0.042263, l1: 0.050731, l2: 0.052812, l3: 0.045239, l4: 0.039757, l5: 0.043476, l6: 0.061070

[epoch:  43/100000, batch:    40/  187, ite: 3968] train loss: 0.513554, tar: 0.062961 
l0: 0.021559, l1: 0.022920, l2: 0.025021, l3: 0.022988, l4: 0.043176, l5: 0.050418, l6: 0.059709

[epoch:  43/100000, batch:    42/  187, ite: 3969] train loss: 0.513418, tar: 0.062940 
l0: 0.023076, l1: 0.031389, l2: 0.029142, l3: 0.030942, l4: 0.026211, l5: 0.030142, l6: 0.036273

[epoch:  43/100000, batch:    44/  187, ite: 3970] train loss: 0.513262, tar: 0.062920 
l0: 0.048971, l1: 0.047385, l2: 0.050063, l3: 0.071042, l4: 0.049143, l5: 0.053800, l6: 0.048551

[epoch:  43/100000, batch:    46/  187, ite: 3971] train loss: 0.513189, tar: 0.062913 
l0: 0.029037, l1: 0.032987, l2: 0.035768, l3: 0.035819, l4: 0.047918, l5: 0.050249, l6: 0.045867

[epoch:  43/100000, batch:    48/  187, ite: 3972] train loss: 0.513070, tar: 0.062896 
l0: 0.162809, l1: 0.165872, l2: 0.179975, l3: 0.226814, l4: 0.138785, l5: 0.148750, l6: 0.134811

[epoch:  43/100000, batch:    50/  187, ite: 3973] train loss: 0.513396, tar: 0.062946 
l0: 0.046407, l1: 0.043161, l2: 0.046105, l3: 0.052083, l4: 0.073569, l5: 0.079414, l6: 0.059995

[epoch:  43/100000, batch:    52/  187, ite: 3974] train loss: 0.513339, tar: 0.062938 
l0: 0.026908, l1: 0.023601, l2: 0.031833, l3: 0.034507, l4: 0.055294, l5: 0.061750, l6: 0.044132

[epoch:  43/100000, batch:    54/  187, ite: 3975] train loss: 0.513220, tar: 0.062920 
l0: 0.057137, l1: 0.057957, l2: 0.055351, l3: 0.050053, l4: 0.079638, l5: 0.090286, l6: 0.086522

[epoch:  43/100000, batch:    56/  187, ite: 3976] train loss: 0.513202, tar: 0.062917 
l0: 0.052543, l1: 0.054363, l2: 0.059973, l3: 0.069955, l4: 0.070636, l5: 0.069990, l6: 0.066944

[epoch:  43/100000, batch:    58/  187, ite: 3977] train loss: 0.513167, tar: 0.062911 
l0: 0.048002, l1: 0.047928, l2: 0.048170, l3: 0.049541, l4: 0.061695, l5: 0.063721, l6: 0.068778

[epoch:  43/100000, batch:    60/  187, ite: 3978] train loss: 0.513104, tar: 0.062904 
l0: 0.033819, l1: 0.027772, l2: 0.040186, l3: 0.060900, l4: 0.082877, l5: 0.099970, l6: 0.101095

[epoch:  43/100000, batch:    62/  187, ite: 3979] train loss: 0.513070, tar: 0.062889 
l0: 0.034077, l1: 0.043884, l2: 0.059309, l3: 0.063705, l4: 0.046415, l5: 0.036485, l6: 0.031528

[epoch:  43/100000, batch:    64/  187, ite: 3980] train loss: 0.512970, tar: 0.062875 
l0: 0.044872, l1: 0.044513, l2: 0.061458, l3: 0.077804, l4: 0.069433, l5: 0.067153, l6: 0.063587

[epoch:  43/100000, batch:    66/  187, ite: 3981] train loss: 0.512928, tar: 0.062865 
l0: 0.047721, l1: 0.049253, l2: 0.057937, l3: 0.054377, l4: 0.055795, l5: 0.067540, l6: 0.060451

[epoch:  43/100000, batch:    68/  187, ite: 3982] train loss: 0.512867, tar: 0.062858 
l0: 0.037430, l1: 0.033736, l2: 0.045506, l3: 0.054987, l4: 0.066944, l5: 0.067293, l6: 0.063453

[epoch:  43/100000, batch:    70/  187, ite: 3983] train loss: 0.512795, tar: 0.062845 
l0: 0.039810, l1: 0.041166, l2: 0.042616, l3: 0.047444, l4: 0.055254, l5: 0.066472, l6: 0.064478

[epoch:  43/100000, batch:    72/  187, ite: 3984] train loss: 0.512717, tar: 0.062833 
l0: 0.038805, l1: 0.037474, l2: 0.044271, l3: 0.054656, l4: 0.064794, l5: 0.064540, l6: 0.069019

[epoch:  43/100000, batch:    74/  187, ite: 3985] train loss: 0.512646, tar: 0.062821 
l0: 0.055964, l1: 0.056064, l2: 0.084408, l3: 0.076606, l4: 0.081730, l5: 0.079093, l6: 0.103852

[epoch:  43/100000, batch:    76/  187, ite: 3986] train loss: 0.512659, tar: 0.062818 
l0: 0.033234, l1: 0.033537, l2: 0.041137, l3: 0.041289, l4: 0.041761, l5: 0.048697, l6: 0.052041

[epoch:  43/100000, batch:    78/  187, ite: 3987] train loss: 0.512548, tar: 0.062803 
l0: 0.037883, l1: 0.047439, l2: 0.038326, l3: 0.035213, l4: 0.053418, l5: 0.047855, l6: 0.048639

[epoch:  43/100000, batch:    80/  187, ite: 3988] train loss: 0.512445, tar: 0.062790 
l0: 0.034820, l1: 0.039990, l2: 0.037356, l3: 0.033112, l4: 0.037397, l5: 0.040186, l6: 0.040241

[epoch:  43/100000, batch:    82/  187, ite: 3989] train loss: 0.512320, tar: 0.062776 
l0: 0.040713, l1: 0.035022, l2: 0.052826, l3: 0.059283, l4: 0.080214, l5: 0.078869, l6: 0.072580

[epoch:  43/100000, batch:    84/  187, ite: 3990] train loss: 0.512273, tar: 0.062765 
l0: 0.031291, l1: 0.037136, l2: 0.039015, l3: 0.040327, l4: 0.033963, l5: 0.041511, l6: 0.046998

[epoch:  43/100000, batch:    86/  187, ite: 3991] train loss: 0.512152, tar: 0.062749 
l0: 0.046660, l1: 0.038275, l2: 0.045998, l3: 0.059332, l4: 0.098219, l5: 0.118765, l6: 0.084417

[epoch:  43/100000, batch:    88/  187, ite: 3992] train loss: 0.512142, tar: 0.062741 
l0: 0.058836, l1: 0.056220, l2: 0.086077, l3: 0.090831, l4: 0.066516, l5: 0.084858, l6: 0.050012

[epoch:  43/100000, batch:    90/  187, ite: 3993] train loss: 0.512132, tar: 0.062739 
l0: 0.034473, l1: 0.030486, l2: 0.037055, l3: 0.044712, l4: 0.063451, l5: 0.070373, l6: 0.075714

[epoch:  43/100000, batch:    92/  187, ite: 3994] train loss: 0.512054, tar: 0.062725 
l0: 0.031024, l1: 0.031859, l2: 0.036220, l3: 0.037680, l4: 0.041389, l5: 0.043948, l6: 0.037941

[epoch:  43/100000, batch:    94/  187, ite: 3995] train loss: 0.511928, tar: 0.062709 
l0: 0.072542, l1: 0.068631, l2: 0.093887, l3: 0.093954, l4: 0.080077, l5: 0.079612, l6: 0.077265

[epoch:  43/100000, batch:    96/  187, ite: 3996] train loss: 0.511955, tar: 0.062714 
l0: 0.040122, l1: 0.041048, l2: 0.052487, l3: 0.053669, l4: 0.074304, l5: 0.084151, l6: 0.080095

[epoch:  43/100000, batch:    98/  187, ite: 3997] train loss: 0.511912, tar: 0.062703 
l0: 0.029326, l1: 0.030659, l2: 0.049219, l3: 0.053809, l4: 0.038101, l5: 0.034915, l6: 0.032151

[epoch:  43/100000, batch:   100/  187, ite: 3998] train loss: 0.511790, tar: 0.062686 
l0: 0.041610, l1: 0.040825, l2: 0.056528, l3: 0.052883, l4: 0.047127, l5: 0.051240, l6: 0.053902

[epoch:  43/100000, batch:   102/  187, ite: 3999] train loss: 0.511706, tar: 0.062676 
l0: 0.043204, l1: 0.041096, l2: 0.054606, l3: 0.056836, l4: 0.073975, l5: 0.073268, l6: 0.074455

[epoch:  43/100000, batch:   104/  187, ite: 4000] train loss: 0.511659, tar: 0.062666 
l0: 0.029845, l1: 0.028256, l2: 0.036226, l3: 0.040761, l4: 0.046442, l5: 0.051968, l6: 0.053782

[epoch:  43/100000, batch:   106/  187, ite: 4001] train loss: 0.287279, tar: 0.029845 
l0: 0.042405, l1: 0.044740, l2: 0.062703, l3: 0.070262, l4: 0.067301, l5: 0.077554, l6: 0.055615

[epoch:  43/100000, batch:   108/  187, ite: 4002] train loss: 0.353929, tar: 0.036125 
l0: 0.050135, l1: 0.054739, l2: 0.067830, l3: 0.065484, l4: 0.084275, l5: 0.087172, l6: 0.081800

[epoch:  43/100000, batch:   110/  187, ite: 4003] train loss: 0.399764, tar: 0.040795 
l0: 0.032720, l1: 0.031904, l2: 0.046754, l3: 0.045893, l4: 0.040688, l5: 0.042748, l6: 0.037918

[epoch:  43/100000, batch:   112/  187, ite: 4004] train loss: 0.369480, tar: 0.038776 
l0: 0.054564, l1: 0.049544, l2: 0.069448, l3: 0.077786, l4: 0.109618, l5: 0.098187, l6: 0.091606

[epoch:  43/100000, batch:   114/  187, ite: 4005] train loss: 0.405734, tar: 0.041934 
l0: 0.043527, l1: 0.045173, l2: 0.041671, l3: 0.048983, l4: 0.062960, l5: 0.063665, l6: 0.073325

[epoch:  43/100000, batch:   116/  187, ite: 4006] train loss: 0.401329, tar: 0.042199 
l0: 0.035671, l1: 0.032517, l2: 0.049052, l3: 0.047366, l4: 0.062293, l5: 0.069863, l6: 0.066967

[epoch:  43/100000, batch:   118/  187, ite: 4007] train loss: 0.395958, tar: 0.041267 
l0: 0.053304, l1: 0.054463, l2: 0.054759, l3: 0.053330, l4: 0.061331, l5: 0.064548, l6: 0.062959

[epoch:  43/100000, batch:   120/  187, ite: 4008] train loss: 0.397050, tar: 0.042771 
l0: 0.036691, l1: 0.037653, l2: 0.056587, l3: 0.063135, l4: 0.071906, l5: 0.072223, l6: 0.082855

[epoch:  43/100000, batch:   122/  187, ite: 4009] train loss: 0.399716, tar: 0.042096 
l0: 0.064718, l1: 0.074214, l2: 0.064806, l3: 0.059958, l4: 0.059508, l5: 0.064500, l6: 0.066730

[epoch:  43/100000, batch:   124/  187, ite: 4010] train loss: 0.405188, tar: 0.044358 
l0: 0.060138, l1: 0.060572, l2: 0.091282, l3: 0.087220, l4: 0.075212, l5: 0.066316, l6: 0.069518

[epoch:  43/100000, batch:   126/  187, ite: 4011] train loss: 0.414740, tar: 0.045792 
l0: 0.032939, l1: 0.031316, l2: 0.038218, l3: 0.043907, l4: 0.052353, l5: 0.053388, l6: 0.051392

[epoch:  43/100000, batch:   128/  187, ite: 4012] train loss: 0.405471, tar: 0.044721 
l0: 0.040815, l1: 0.034803, l2: 0.047024, l3: 0.050743, l4: 0.074483, l5: 0.090863, l6: 0.088194

[epoch:  43/100000, batch:   130/  187, ite: 4013] train loss: 0.407121, tar: 0.044421 
l0: 0.024560, l1: 0.021866, l2: 0.028755, l3: 0.039222, l4: 0.039699, l5: 0.043053, l6: 0.047692

[epoch:  43/100000, batch:   132/  187, ite: 4014] train loss: 0.395530, tar: 0.043002 
l0: 0.057154, l1: 0.053637, l2: 0.069179, l3: 0.064019, l4: 0.090935, l5: 0.107469, l6: 0.081419

[epoch:  43/100000, batch:   134/  187, ite: 4015] train loss: 0.404082, tar: 0.043946 
l0: 0.051392, l1: 0.054281, l2: 0.051216, l3: 0.053371, l4: 0.074105, l5: 0.081705, l6: 0.089179

[epoch:  43/100000, batch:   136/  187, ite: 4016] train loss: 0.407280, tar: 0.044411 
l0: 0.082413, l1: 0.087085, l2: 0.072756, l3: 0.088816, l4: 0.105541, l5: 0.127785, l6: 0.127186

[epoch:  43/100000, batch:   138/  187, ite: 4017] train loss: 0.424004, tar: 0.046646 
l0: 0.033452, l1: 0.033295, l2: 0.035580, l3: 0.034737, l4: 0.043791, l5: 0.044953, l6: 0.051695

[epoch:  43/100000, batch:   140/  187, ite: 4018] train loss: 0.415865, tar: 0.045913 
l0: 0.046035, l1: 0.046792, l2: 0.041765, l3: 0.058065, l4: 0.065290, l5: 0.060755, l6: 0.064419

[epoch:  43/100000, batch:   142/  187, ite: 4019] train loss: 0.414142, tar: 0.045920 
l0: 0.036713, l1: 0.031236, l2: 0.056911, l3: 0.055362, l4: 0.076821, l5: 0.078524, l6: 0.082202

[epoch:  43/100000, batch:   144/  187, ite: 4020] train loss: 0.414323, tar: 0.045459 
l0: 0.038260, l1: 0.053083, l2: 0.031233, l3: 0.030422, l4: 0.029872, l5: 0.030979, l6: 0.029064

[epoch:  43/100000, batch:   146/  187, ite: 4021] train loss: 0.406161, tar: 0.045117 
l0: 0.201559, l1: 0.222723, l2: 0.198969, l3: 0.196028, l4: 0.168711, l5: 0.178630, l6: 0.204895

[epoch:  43/100000, batch:   148/  187, ite: 4022] train loss: 0.450040, tar: 0.052228 
l0: 0.052867, l1: 0.054534, l2: 0.061397, l3: 0.064564, l4: 0.076143, l5: 0.075447, l6: 0.073914

[epoch:  43/100000, batch:   150/  187, ite: 4023] train loss: 0.450424, tar: 0.052255 
l0: 0.030659, l1: 0.029576, l2: 0.050388, l3: 0.056794, l4: 0.051486, l5: 0.053240, l6: 0.054787

[epoch:  43/100000, batch:   152/  187, ite: 4024] train loss: 0.445278, tar: 0.051356 
l0: 0.100068, l1: 0.108569, l2: 0.116322, l3: 0.099714, l4: 0.127509, l5: 0.110275, l6: 0.109437

[epoch:  43/100000, batch:   154/  187, ite: 4025] train loss: 0.458343, tar: 0.053304 
l0: 0.061813, l1: 0.063103, l2: 0.061321, l3: 0.064847, l4: 0.062756, l5: 0.078828, l6: 0.069631

[epoch:  43/100000, batch:   156/  187, ite: 4026] train loss: 0.458495, tar: 0.053631 
l0: 0.030660, l1: 0.027015, l2: 0.037701, l3: 0.042861, l4: 0.058520, l5: 0.063631, l6: 0.061818

[epoch:  43/100000, batch:   158/  187, ite: 4027] train loss: 0.453447, tar: 0.052781 
l0: 0.075512, l1: 0.079799, l2: 0.103416, l3: 0.103652, l4: 0.079812, l5: 0.081221, l6: 0.077275

[epoch:  43/100000, batch:   160/  187, ite: 4028] train loss: 0.458706, tar: 0.053592 
l0: 0.040734, l1: 0.040661, l2: 0.054476, l3: 0.055244, l4: 0.067262, l5: 0.078041, l6: 0.080870

[epoch:  43/100000, batch:   162/  187, ite: 4029] train loss: 0.457278, tar: 0.053149 
l0: 0.050132, l1: 0.057542, l2: 0.044961, l3: 0.045011, l4: 0.057393, l5: 0.060309, l6: 0.051218

[epoch:  43/100000, batch:   164/  187, ite: 4030] train loss: 0.454254, tar: 0.053049 
l0: 0.042352, l1: 0.039400, l2: 0.046871, l3: 0.046947, l4: 0.079420, l5: 0.083960, l6: 0.085254

[epoch:  43/100000, batch:   166/  187, ite: 4031] train loss: 0.453285, tar: 0.052703 
l0: 0.049964, l1: 0.045178, l2: 0.076863, l3: 0.070648, l4: 0.071675, l5: 0.083233, l6: 0.079689

[epoch:  43/100000, batch:   168/  187, ite: 4032] train loss: 0.454034, tar: 0.052618 
l0: 0.034601, l1: 0.029558, l2: 0.043691, l3: 0.051514, l4: 0.068164, l5: 0.071259, l6: 0.069745

[epoch:  43/100000, batch:   170/  187, ite: 4033] train loss: 0.451443, tar: 0.052072 
l0: 0.047412, l1: 0.049420, l2: 0.051089, l3: 0.058198, l4: 0.065526, l5: 0.065022, l6: 0.069955

[epoch:  43/100000, batch:   172/  187, ite: 4034] train loss: 0.450124, tar: 0.051935 
l0: 0.037418, l1: 0.037742, l2: 0.040746, l3: 0.047253, l4: 0.059484, l5: 0.059072, l6: 0.056560

[epoch:  43/100000, batch:   174/  187, ite: 4035] train loss: 0.446929, tar: 0.051520 
l0: 0.054520, l1: 0.062848, l2: 0.055491, l3: 0.056718, l4: 0.059904, l5: 0.067130, l6: 0.062104

[epoch:  43/100000, batch:   176/  187, ite: 4036] train loss: 0.446145, tar: 0.051603 
l0: 0.071902, l1: 0.100571, l2: 0.077003, l3: 0.072573, l4: 0.033703, l5: 0.038288, l6: 0.030913

[epoch:  43/100000, batch:   178/  187, ite: 4037] train loss: 0.445572, tar: 0.052152 
l0: 0.047665, l1: 0.049746, l2: 0.055801, l3: 0.052913, l4: 0.053002, l5: 0.054772, l6: 0.056597

[epoch:  43/100000, batch:   180/  187, ite: 4038] train loss: 0.443596, tar: 0.052034 
l0: 0.044612, l1: 0.067924, l2: 0.050499, l3: 0.049567, l4: 0.043613, l5: 0.033244, l6: 0.032894

[epoch:  43/100000, batch:   182/  187, ite: 4039] train loss: 0.440488, tar: 0.051844 
l0: 0.053277, l1: 0.066997, l2: 0.054428, l3: 0.051986, l4: 0.044326, l5: 0.049267, l6: 0.049198

[epoch:  43/100000, batch:   184/  187, ite: 4040] train loss: 0.438712, tar: 0.051879 
l0: 0.025546, l1: 0.030332, l2: 0.032219, l3: 0.026030, l4: 0.023632, l5: 0.026769, l6: 0.031389

[epoch:  43/100000, batch:   186/  187, ite: 4041] train loss: 0.432791, tar: 0.051237 
l0: 0.051438, l1: 0.047495, l2: 0.054567, l3: 0.051663, l4: 0.051151, l5: 0.064492, l6: 0.078188

[epoch:  43/100000, batch:   188/  187, ite: 4042] train loss: 0.431986, tar: 0.051242 
l0: 0.028903, l1: 0.030034, l2: 0.029282, l3: 0.027014, l4: 0.038044, l5: 0.033137, l6: 0.041220

[epoch:  44/100000, batch:     2/  187, ite: 4043] train loss: 0.427234, tar: 0.050722 
l0: 0.033643, l1: 0.031786, l2: 0.041148, l3: 0.036001, l4: 0.043714, l5: 0.042386, l6: 0.050579

[epoch:  44/100000, batch:     4/  187, ite: 4044] train loss: 0.423870, tar: 0.050334 
l0: 0.026281, l1: 0.022226, l2: 0.037327, l3: 0.042543, l4: 0.045059, l5: 0.044662, l6: 0.049195

[epoch:  44/100000, batch:     6/  187, ite: 4045] train loss: 0.420391, tar: 0.049800 
l0: 0.025609, l1: 0.023848, l2: 0.031740, l3: 0.037053, l4: 0.042481, l5: 0.036458, l6: 0.042492

[epoch:  44/100000, batch:     8/  187, ite: 4046] train loss: 0.416462, tar: 0.049274 
l0: 0.064190, l1: 0.065009, l2: 0.070365, l3: 0.080611, l4: 0.070812, l5: 0.073861, l6: 0.054040

[epoch:  44/100000, batch:    10/  187, ite: 4047] train loss: 0.417791, tar: 0.049591 
l0: 0.065545, l1: 0.064596, l2: 0.072946, l3: 0.077016, l4: 0.067925, l5: 0.082616, l6: 0.059688

[epoch:  44/100000, batch:    12/  187, ite: 4048] train loss: 0.419302, tar: 0.049924 
l0: 0.054200, l1: 0.051186, l2: 0.062823, l3: 0.064845, l4: 0.061797, l5: 0.065166, l6: 0.068873

[epoch:  44/100000, batch:    14/  187, ite: 4049] train loss: 0.419498, tar: 0.050011 
l0: 0.020966, l1: 0.020119, l2: 0.028036, l3: 0.025054, l4: 0.032791, l5: 0.044799, l6: 0.053384

[epoch:  44/100000, batch:    16/  187, ite: 4050] train loss: 0.415611, tar: 0.049430 
l0: 0.031729, l1: 0.031570, l2: 0.035546, l3: 0.036139, l4: 0.047620, l5: 0.056474, l6: 0.064289

[epoch:  44/100000, batch:    18/  187, ite: 4051] train loss: 0.413410, tar: 0.049083 
l0: 0.031592, l1: 0.031278, l2: 0.031917, l3: 0.032219, l4: 0.047012, l5: 0.045430, l6: 0.053320

[epoch:  44/100000, batch:    20/  187, ite: 4052] train loss: 0.410705, tar: 0.048747 
l0: 0.024608, l1: 0.024343, l2: 0.031143, l3: 0.031631, l4: 0.048110, l5: 0.043502, l6: 0.042834

[epoch:  44/100000, batch:    22/  187, ite: 4053] train loss: 0.407601, tar: 0.048291 
l0: 0.061335, l1: 0.057830, l2: 0.083107, l3: 0.106604, l4: 0.101186, l5: 0.090237, l6: 0.090240

[epoch:  44/100000, batch:    24/  187, ite: 4054] train loss: 0.410988, tar: 0.048533 
l0: 0.041434, l1: 0.039157, l2: 0.049169, l3: 0.044690, l4: 0.064282, l5: 0.069034, l6: 0.073282

[epoch:  44/100000, batch:    26/  187, ite: 4055] train loss: 0.410444, tar: 0.048404 
l0: 0.037880, l1: 0.034060, l2: 0.047284, l3: 0.056911, l4: 0.086398, l5: 0.080248, l6: 0.072578

[epoch:  44/100000, batch:    28/  187, ite: 4056] train loss: 0.410532, tar: 0.048216 
l0: 0.050614, l1: 0.053482, l2: 0.059585, l3: 0.051502, l4: 0.060120, l5: 0.060961, l6: 0.085927

[epoch:  44/100000, batch:    30/  187, ite: 4057] train loss: 0.410736, tar: 0.048258 
l0: 0.045259, l1: 0.042266, l2: 0.055511, l3: 0.056372, l4: 0.065884, l5: 0.073759, l6: 0.067529

[epoch:  44/100000, batch:    32/  187, ite: 4058] train loss: 0.410665, tar: 0.048206 
l0: 0.031042, l1: 0.029660, l2: 0.034168, l3: 0.036871, l4: 0.057331, l5: 0.060943, l6: 0.055006

[epoch:  44/100000, batch:    34/  187, ite: 4059] train loss: 0.408874, tar: 0.047915 
l0: 0.021369, l1: 0.024427, l2: 0.022232, l3: 0.022240, l4: 0.035400, l5: 0.034588, l6: 0.036432

[epoch:  44/100000, batch:    36/  187, ite: 4060] train loss: 0.405338, tar: 0.047473 
l0: 0.037274, l1: 0.032350, l2: 0.040433, l3: 0.043708, l4: 0.067468, l5: 0.073241, l6: 0.109428

[epoch:  44/100000, batch:    38/  187, ite: 4061] train loss: 0.405314, tar: 0.047306 
l0: 0.025090, l1: 0.025389, l2: 0.024716, l3: 0.027834, l4: 0.029056, l5: 0.029903, l6: 0.032653

[epoch:  44/100000, batch:    40/  187, ite: 4062] train loss: 0.401916, tar: 0.046947 
l0: 0.043378, l1: 0.043019, l2: 0.040854, l3: 0.043645, l4: 0.047926, l5: 0.060018, l6: 0.061467

[epoch:  44/100000, batch:    42/  187, ite: 4063] train loss: 0.400938, tar: 0.046891 
l0: 0.035728, l1: 0.034503, l2: 0.037530, l3: 0.039314, l4: 0.052965, l5: 0.058341, l6: 0.054484

[epoch:  44/100000, batch:    44/  187, ite: 4064] train loss: 0.399562, tar: 0.046716 
l0: 0.022743, l1: 0.022784, l2: 0.026930, l3: 0.036333, l4: 0.053217, l5: 0.036750, l6: 0.039920

[epoch:  44/100000, batch:    46/  187, ite: 4065] train loss: 0.397087, tar: 0.046347 
l0: 0.042845, l1: 0.047155, l2: 0.040302, l3: 0.038931, l4: 0.066798, l5: 0.060465, l6: 0.050305

[epoch:  44/100000, batch:    48/  187, ite: 4066] train loss: 0.396325, tar: 0.046294 
l0: 0.055913, l1: 0.060177, l2: 0.049891, l3: 0.046971, l4: 0.057781, l5: 0.057261, l6: 0.080703

[epoch:  44/100000, batch:    50/  187, ite: 4067] train loss: 0.396510, tar: 0.046438 
l0: 0.032966, l1: 0.030090, l2: 0.041349, l3: 0.042034, l4: 0.101432, l5: 0.104742, l6: 0.110311

[epoch:  44/100000, batch:    52/  187, ite: 4068] train loss: 0.397486, tar: 0.046240 
l0: 0.043193, l1: 0.048368, l2: 0.055639, l3: 0.055050, l4: 0.051867, l5: 0.043351, l6: 0.053412

[epoch:  44/100000, batch:    54/  187, ite: 4069] train loss: 0.396811, tar: 0.046196 
l0: 0.039612, l1: 0.040672, l2: 0.043933, l3: 0.041226, l4: 0.050441, l5: 0.053413, l6: 0.055898

[epoch:  44/100000, batch:    56/  187, ite: 4070] train loss: 0.395788, tar: 0.046101 
l0: 0.024245, l1: 0.022863, l2: 0.031480, l3: 0.034686, l4: 0.038564, l5: 0.040850, l6: 0.037331

[epoch:  44/100000, batch:    58/  187, ite: 4071] train loss: 0.393453, tar: 0.045794 
l0: 0.027316, l1: 0.025613, l2: 0.032464, l3: 0.028976, l4: 0.033201, l5: 0.045366, l6: 0.048791

[epoch:  44/100000, batch:    60/  187, ite: 4072] train loss: 0.391346, tar: 0.045537 
l0: 0.071951, l1: 0.073507, l2: 0.094918, l3: 0.106664, l4: 0.089195, l5: 0.087688, l6: 0.067925

[epoch:  44/100000, batch:    62/  187, ite: 4073] train loss: 0.394092, tar: 0.045899 
l0: 0.030001, l1: 0.036809, l2: 0.026497, l3: 0.027534, l4: 0.039802, l5: 0.037573, l6: 0.040234

[epoch:  44/100000, batch:    64/  187, ite: 4074] train loss: 0.391989, tar: 0.045684 
l0: 0.022000, l1: 0.025536, l2: 0.026344, l3: 0.024765, l4: 0.023937, l5: 0.021959, l6: 0.024482

[epoch:  44/100000, batch:    66/  187, ite: 4075] train loss: 0.389016, tar: 0.045368 
l0: 0.044915, l1: 0.043990, l2: 0.048776, l3: 0.049338, l4: 0.051542, l5: 0.053023, l6: 0.055638

[epoch:  44/100000, batch:    68/  187, ite: 4076] train loss: 0.388466, tar: 0.045362 
l0: 0.034925, l1: 0.032588, l2: 0.038780, l3: 0.042735, l4: 0.068436, l5: 0.069550, l6: 0.065042

[epoch:  44/100000, batch:    70/  187, ite: 4077] train loss: 0.387993, tar: 0.045227 
l0: 0.035253, l1: 0.041289, l2: 0.035228, l3: 0.038324, l4: 0.053650, l5: 0.042229, l6: 0.039880

[epoch:  44/100000, batch:    72/  187, ite: 4078] train loss: 0.386684, tar: 0.045099 
l0: 0.048203, l1: 0.052651, l2: 0.046162, l3: 0.058621, l4: 0.083951, l5: 0.058159, l6: 0.073011

[epoch:  44/100000, batch:    74/  187, ite: 4079] train loss: 0.387115, tar: 0.045138 
l0: 0.041046, l1: 0.038531, l2: 0.057607, l3: 0.056137, l4: 0.058696, l5: 0.065524, l6: 0.071175

[epoch:  44/100000, batch:    76/  187, ite: 4080] train loss: 0.387135, tar: 0.045087 
l0: 0.039996, l1: 0.039903, l2: 0.043755, l3: 0.051895, l4: 0.078575, l5: 0.082670, l6: 0.065414

[epoch:  44/100000, batch:    78/  187, ite: 4081] train loss: 0.387321, tar: 0.045024 
l0: 0.035564, l1: 0.037087, l2: 0.050085, l3: 0.058804, l4: 0.050060, l5: 0.050895, l6: 0.057048

[epoch:  44/100000, batch:    80/  187, ite: 4082] train loss: 0.386739, tar: 0.044909 
l0: 0.048316, l1: 0.046826, l2: 0.075238, l3: 0.085023, l4: 0.087717, l5: 0.078277, l6: 0.062595

[epoch:  44/100000, batch:    82/  187, ite: 4083] train loss: 0.387910, tar: 0.044950 
l0: 0.026770, l1: 0.025418, l2: 0.030944, l3: 0.038570, l4: 0.054250, l5: 0.050627, l6: 0.049135

[epoch:  44/100000, batch:    84/  187, ite: 4084] train loss: 0.386575, tar: 0.044733 
l0: 0.031466, l1: 0.026001, l2: 0.034200, l3: 0.042229, l4: 0.060729, l5: 0.080967, l6: 0.084908

[epoch:  44/100000, batch:    86/  187, ite: 4085] train loss: 0.386268, tar: 0.044577 
l0: 0.021312, l1: 0.042343, l2: 0.023073, l3: 0.018955, l4: 0.021160, l5: 0.018542, l6: 0.015988

[epoch:  44/100000, batch:    88/  187, ite: 4086] train loss: 0.383653, tar: 0.044307 
l0: 0.056913, l1: 0.051698, l2: 0.059802, l3: 0.071843, l4: 0.081571, l5: 0.094542, l6: 0.106228

[epoch:  44/100000, batch:    90/  187, ite: 4087] train loss: 0.385250, tar: 0.044452 
l0: 0.027464, l1: 0.022821, l2: 0.027291, l3: 0.031602, l4: 0.050254, l5: 0.079320, l6: 0.076877

[epoch:  44/100000, batch:    92/  187, ite: 4088] train loss: 0.384459, tar: 0.044259 
l0: 0.047194, l1: 0.043022, l2: 0.062104, l3: 0.065223, l4: 0.081552, l5: 0.102060, l6: 0.107239

[epoch:  44/100000, batch:    94/  187, ite: 4089] train loss: 0.385851, tar: 0.044292 
l0: 0.036696, l1: 0.031335, l2: 0.048740, l3: 0.050938, l4: 0.078612, l5: 0.074545, l6: 0.067130

[epoch:  44/100000, batch:    96/  187, ite: 4090] train loss: 0.385875, tar: 0.044207 
l0: 0.045671, l1: 0.046786, l2: 0.044515, l3: 0.052055, l4: 0.048244, l5: 0.054080, l6: 0.063173

[epoch:  44/100000, batch:    98/  187, ite: 4091] train loss: 0.385531, tar: 0.044223 
l0: 0.035371, l1: 0.039086, l2: 0.037167, l3: 0.039492, l4: 0.050264, l5: 0.048580, l6: 0.040547

[epoch:  44/100000, batch:   100/  187, ite: 4092] train loss: 0.384498, tar: 0.044127 
l0: 0.028146, l1: 0.042813, l2: 0.028968, l3: 0.025955, l4: 0.033676, l5: 0.031049, l6: 0.037862

[epoch:  44/100000, batch:   102/  187, ite: 4093] train loss: 0.382820, tar: 0.043955 
l0: 0.031560, l1: 0.030868, l2: 0.036737, l3: 0.039096, l4: 0.061061, l5: 0.066777, l6: 0.071247

[epoch:  44/100000, batch:   104/  187, ite: 4094] train loss: 0.382336, tar: 0.043823 
l0: 0.034716, l1: 0.035887, l2: 0.045323, l3: 0.041845, l4: 0.066406, l5: 0.054500, l6: 0.062420

[epoch:  44/100000, batch:   106/  187, ite: 4095] train loss: 0.381902, tar: 0.043727 
l0: 0.016861, l1: 0.015413, l2: 0.024382, l3: 0.024783, l4: 0.031572, l5: 0.033129, l6: 0.032208

[epoch:  44/100000, batch:   108/  187, ite: 4096] train loss: 0.379782, tar: 0.043448 
l0: 0.032786, l1: 0.030372, l2: 0.042727, l3: 0.040449, l4: 0.047616, l5: 0.053623, l6: 0.056449

[epoch:  44/100000, batch:   110/  187, ite: 4097] train loss: 0.379001, tar: 0.043338 
l0: 0.022707, l1: 0.026099, l2: 0.027443, l3: 0.034850, l4: 0.038091, l5: 0.040309, l6: 0.033985

[epoch:  44/100000, batch:   112/  187, ite: 4098] train loss: 0.377414, tar: 0.043127 
l0: 0.031033, l1: 0.032552, l2: 0.031536, l3: 0.031591, l4: 0.045801, l5: 0.048026, l6: 0.058350

[epoch:  44/100000, batch:   114/  187, ite: 4099] train loss: 0.376419, tar: 0.043005 
l0: 0.045565, l1: 0.047920, l2: 0.046723, l3: 0.045427, l4: 0.062349, l5: 0.060919, l6: 0.064211

[epoch:  44/100000, batch:   116/  187, ite: 4100] train loss: 0.376386, tar: 0.043031 
l0: 0.032372, l1: 0.032614, l2: 0.047858, l3: 0.039940, l4: 0.053392, l5: 0.047608, l6: 0.041792

[epoch:  44/100000, batch:   118/  187, ite: 4101] train loss: 0.375586, tar: 0.042925 
l0: 0.015662, l1: 0.015143, l2: 0.017645, l3: 0.017727, l4: 0.031500, l5: 0.038040, l6: 0.029087

[epoch:  44/100000, batch:   120/  187, ite: 4102] train loss: 0.373519, tar: 0.042658 
l0: 0.018900, l1: 0.016314, l2: 0.025167, l3: 0.030566, l4: 0.038688, l5: 0.035745, l6: 0.037399

[epoch:  44/100000, batch:   122/  187, ite: 4103] train loss: 0.371861, tar: 0.042427 
l0: 0.039053, l1: 0.042284, l2: 0.055611, l3: 0.039125, l4: 0.047636, l5: 0.052501, l6: 0.066527

[epoch:  44/100000, batch:   124/  187, ite: 4104] train loss: 0.371581, tar: 0.042395 
l0: 0.064983, l1: 0.067474, l2: 0.070746, l3: 0.075298, l4: 0.086090, l5: 0.084892, l6: 0.075791

[epoch:  44/100000, batch:   126/  187, ite: 4105] train loss: 0.373045, tar: 0.042610 
l0: 0.026901, l1: 0.038166, l2: 0.035902, l3: 0.026156, l4: 0.026852, l5: 0.025465, l6: 0.018013

[epoch:  44/100000, batch:   128/  187, ite: 4106] train loss: 0.371389, tar: 0.042462 
l0: 0.065270, l1: 0.064426, l2: 0.056315, l3: 0.075824, l4: 0.076143, l5: 0.076648, l6: 0.083390

[epoch:  44/100000, batch:   130/  187, ite: 4107] train loss: 0.372572, tar: 0.042675 
l0: 0.029329, l1: 0.027826, l2: 0.034040, l3: 0.038651, l4: 0.045909, l5: 0.040806, l6: 0.043397

[epoch:  44/100000, batch:   132/  187, ite: 4108] train loss: 0.371529, tar: 0.042551 
l0: 0.035660, l1: 0.037060, l2: 0.049104, l3: 0.044361, l4: 0.055311, l5: 0.044723, l6: 0.041466

[epoch:  44/100000, batch:   134/  187, ite: 4109] train loss: 0.370944, tar: 0.042488 
l0: 0.019756, l1: 0.020860, l2: 0.024616, l3: 0.024803, l4: 0.026539, l5: 0.025245, l6: 0.026566

[epoch:  44/100000, batch:   136/  187, ite: 4110] train loss: 0.369102, tar: 0.042281 
l0: 0.027944, l1: 0.026657, l2: 0.036210, l3: 0.041901, l4: 0.067726, l5: 0.053893, l6: 0.046266

[epoch:  44/100000, batch:   138/  187, ite: 4111] train loss: 0.368485, tar: 0.042152 
l0: 0.063247, l1: 0.066595, l2: 0.061980, l3: 0.067156, l4: 0.061790, l5: 0.064816, l6: 0.068890

[epoch:  44/100000, batch:   140/  187, ite: 4112] train loss: 0.369253, tar: 0.042341 
l0: 0.075839, l1: 0.086770, l2: 0.082368, l3: 0.088360, l4: 0.059838, l5: 0.053055, l6: 0.058166

[epoch:  44/100000, batch:   142/  187, ite: 4113] train loss: 0.370449, tar: 0.042637 
l0: 0.036144, l1: 0.044344, l2: 0.050072, l3: 0.058152, l4: 0.046666, l5: 0.040475, l6: 0.039689

[epoch:  44/100000, batch:   144/  187, ite: 4114] train loss: 0.369967, tar: 0.042580 
l0: 0.036960, l1: 0.030824, l2: 0.054903, l3: 0.067732, l4: 0.101700, l5: 0.081818, l6: 0.085119

[epoch:  44/100000, batch:   146/  187, ite: 4115] train loss: 0.370742, tar: 0.042531 
l0: 0.028828, l1: 0.027286, l2: 0.034365, l3: 0.035124, l4: 0.046130, l5: 0.047788, l6: 0.057630

[epoch:  44/100000, batch:   148/  187, ite: 4116] train loss: 0.369935, tar: 0.042413 
l0: 0.037893, l1: 0.038867, l2: 0.039371, l3: 0.042694, l4: 0.044369, l5: 0.047857, l6: 0.044039

[epoch:  44/100000, batch:   150/  187, ite: 4117] train loss: 0.369295, tar: 0.042374 
l0: 0.036417, l1: 0.046140, l2: 0.035670, l3: 0.037272, l4: 0.040715, l5: 0.040193, l6: 0.038095

[epoch:  44/100000, batch:   152/  187, ite: 4118] train loss: 0.368492, tar: 0.042324 
l0: 0.048682, l1: 0.045708, l2: 0.051579, l3: 0.057340, l4: 0.068567, l5: 0.067306, l6: 0.089803

[epoch:  44/100000, batch:   154/  187, ite: 4119] train loss: 0.369000, tar: 0.042377 
l0: 0.040159, l1: 0.038181, l2: 0.043130, l3: 0.051843, l4: 0.055357, l5: 0.051179, l6: 0.062532

[epoch:  44/100000, batch:   156/  187, ite: 4120] train loss: 0.368778, tar: 0.042359 
l0: 0.034119, l1: 0.032880, l2: 0.045237, l3: 0.042585, l4: 0.063750, l5: 0.062357, l6: 0.067737

[epoch:  44/100000, batch:   158/  187, ite: 4121] train loss: 0.368612, tar: 0.042291 
l0: 0.053249, l1: 0.049643, l2: 0.065282, l3: 0.059160, l4: 0.065978, l5: 0.076353, l6: 0.072909

[epoch:  44/100000, batch:   160/  187, ite: 4122] train loss: 0.369218, tar: 0.042381 
l0: 0.052103, l1: 0.045695, l2: 0.054947, l3: 0.065188, l4: 0.077188, l5: 0.085929, l6: 0.105115

[epoch:  44/100000, batch:   162/  187, ite: 4123] train loss: 0.370169, tar: 0.042460 
l0: 0.053296, l1: 0.058712, l2: 0.071008, l3: 0.063138, l4: 0.063528, l5: 0.068111, l6: 0.054968

[epoch:  44/100000, batch:   164/  187, ite: 4124] train loss: 0.370674, tar: 0.042547 
l0: 0.047611, l1: 0.053930, l2: 0.045375, l3: 0.039386, l4: 0.061650, l5: 0.058849, l6: 0.060015

[epoch:  44/100000, batch:   166/  187, ite: 4125] train loss: 0.370643, tar: 0.042588 
l0: 0.032486, l1: 0.033649, l2: 0.037571, l3: 0.036175, l4: 0.054012, l5: 0.052707, l6: 0.050675

[epoch:  44/100000, batch:   168/  187, ite: 4126] train loss: 0.370061, tar: 0.042507 
l0: 0.030712, l1: 0.029740, l2: 0.035317, l3: 0.037675, l4: 0.066373, l5: 0.063439, l6: 0.047420

[epoch:  44/100000, batch:   170/  187, ite: 4127] train loss: 0.369593, tar: 0.042414 
l0: 0.055938, l1: 0.046934, l2: 0.060805, l3: 0.075677, l4: 0.107276, l5: 0.105327, l6: 0.126582

[epoch:  44/100000, batch:   172/  187, ite: 4128] train loss: 0.371226, tar: 0.042520 
l0: 0.047614, l1: 0.049429, l2: 0.058339, l3: 0.058344, l4: 0.071944, l5: 0.068181, l6: 0.056051

[epoch:  44/100000, batch:   174/  187, ite: 4129] train loss: 0.371525, tar: 0.042560 
l0: 0.039850, l1: 0.038980, l2: 0.047575, l3: 0.045841, l4: 0.082269, l5: 0.083208, l6: 0.077072

[epoch:  44/100000, batch:   176/  187, ite: 4130] train loss: 0.371858, tar: 0.042539 
l0: 0.031999, l1: 0.031462, l2: 0.034324, l3: 0.039745, l4: 0.046156, l5: 0.038536, l6: 0.039991

[epoch:  44/100000, batch:   178/  187, ite: 4131] train loss: 0.371021, tar: 0.042458 
l0: 0.053100, l1: 0.054627, l2: 0.056414, l3: 0.053611, l4: 0.063216, l5: 0.062775, l6: 0.059419

[epoch:  44/100000, batch:   180/  187, ite: 4132] train loss: 0.371265, tar: 0.042539 
l0: 0.053226, l1: 0.052867, l2: 0.066361, l3: 0.064330, l4: 0.067776, l5: 0.067499, l6: 0.070649

[epoch:  44/100000, batch:   182/  187, ite: 4133] train loss: 0.371802, tar: 0.042619 
l0: 0.037132, l1: 0.033162, l2: 0.054933, l3: 0.056461, l4: 0.060295, l5: 0.061707, l6: 0.044708

[epoch:  44/100000, batch:   184/  187, ite: 4134] train loss: 0.371627, tar: 0.042578 
l0: 0.032930, l1: 0.034698, l2: 0.038288, l3: 0.037474, l4: 0.044548, l5: 0.046812, l6: 0.054637

[epoch:  44/100000, batch:   186/  187, ite: 4135] train loss: 0.371018, tar: 0.042507 
l0: 0.053541, l1: 0.057094, l2: 0.048592, l3: 0.053483, l4: 0.063492, l5: 0.056192, l6: 0.053142

[epoch:  44/100000, batch:   188/  187, ite: 4136] train loss: 0.371125, tar: 0.042588 
l0: 0.013963, l1: 0.012810, l2: 0.016906, l3: 0.016710, l4: 0.023738, l5: 0.025139, l6: 0.026320

[epoch:  45/100000, batch:     2/  187, ite: 4137] train loss: 0.369406, tar: 0.042379 
l0: 0.039859, l1: 0.037649, l2: 0.050440, l3: 0.043757, l4: 0.070355, l5: 0.083478, l6: 0.097185

[epoch:  45/100000, batch:     4/  187, ite: 4138] train loss: 0.369792, tar: 0.042361 
l0: 0.033372, l1: 0.046780, l2: 0.033414, l3: 0.026633, l4: 0.041927, l5: 0.046529, l6: 0.049076

[epoch:  45/100000, batch:     6/  187, ite: 4139] train loss: 0.369130, tar: 0.042296 
l0: 0.036528, l1: 0.036055, l2: 0.039268, l3: 0.041484, l4: 0.050947, l5: 0.055294, l6: 0.057026

[epoch:  45/100000, batch:     8/  187, ite: 4140] train loss: 0.368754, tar: 0.042255 
l0: 0.024526, l1: 0.026659, l2: 0.027262, l3: 0.026771, l4: 0.043718, l5: 0.051483, l6: 0.057406

[epoch:  45/100000, batch:    10/  187, ite: 4141] train loss: 0.367968, tar: 0.042129 
l0: 0.019820, l1: 0.021204, l2: 0.029059, l3: 0.030317, l4: 0.044453, l5: 0.042331, l6: 0.032676

[epoch:  45/100000, batch:    12/  187, ite: 4142] train loss: 0.366925, tar: 0.041972 
l0: 0.031698, l1: 0.038960, l2: 0.036219, l3: 0.036396, l4: 0.034049, l5: 0.037695, l6: 0.038026

[epoch:  45/100000, batch:    14/  187, ite: 4143] train loss: 0.366128, tar: 0.041900 
l0: 0.032656, l1: 0.034825, l2: 0.044547, l3: 0.051265, l4: 0.066557, l5: 0.064358, l6: 0.060500

[epoch:  45/100000, batch:    16/  187, ite: 4144] train loss: 0.366049, tar: 0.041836 
l0: 0.037949, l1: 0.041172, l2: 0.051329, l3: 0.052006, l4: 0.051077, l5: 0.053700, l6: 0.064849

[epoch:  45/100000, batch:    18/  187, ite: 4145] train loss: 0.365953, tar: 0.041809 
l0: 0.026289, l1: 0.025607, l2: 0.033907, l3: 0.035091, l4: 0.041289, l5: 0.042820, l6: 0.050779

[epoch:  45/100000, batch:    20/  187, ite: 4146] train loss: 0.365198, tar: 0.041703 
l0: 0.037615, l1: 0.044148, l2: 0.042936, l3: 0.043331, l4: 0.073552, l5: 0.071392, l6: 0.084813

[epoch:  45/100000, batch:    22/  187, ite: 4147] train loss: 0.365420, tar: 0.041675 
l0: 0.052769, l1: 0.052334, l2: 0.050857, l3: 0.054696, l4: 0.057221, l5: 0.065485, l6: 0.051059

[epoch:  45/100000, batch:    24/  187, ite: 4148] train loss: 0.365548, tar: 0.041750 
l0: 0.034943, l1: 0.033946, l2: 0.043648, l3: 0.043128, l4: 0.040082, l5: 0.042391, l6: 0.037769

[epoch:  45/100000, batch:    26/  187, ite: 4149] train loss: 0.364947, tar: 0.041704 
l0: 0.048245, l1: 0.055104, l2: 0.044735, l3: 0.044119, l4: 0.060475, l5: 0.064664, l6: 0.064688

[epoch:  45/100000, batch:    28/  187, ite: 4150] train loss: 0.365060, tar: 0.041748 
l0: 0.054813, l1: 0.053563, l2: 0.069612, l3: 0.059726, l4: 0.082493, l5: 0.082544, l6: 0.068139

[epoch:  45/100000, batch:    30/  187, ite: 4151] train loss: 0.365761, tar: 0.041835 
l0: 0.058578, l1: 0.061923, l2: 0.062368, l3: 0.059726, l4: 0.066126, l5: 0.063576, l6: 0.063763

[epoch:  45/100000, batch:    32/  187, ite: 4152] train loss: 0.366224, tar: 0.041945 
l0: 0.018809, l1: 0.017532, l2: 0.021728, l3: 0.022976, l4: 0.042379, l5: 0.043578, l6: 0.043557

[epoch:  45/100000, batch:    34/  187, ite: 4153] train loss: 0.365206, tar: 0.041793 
l0: 0.039107, l1: 0.039596, l2: 0.041070, l3: 0.047151, l4: 0.058135, l5: 0.065484, l6: 0.067397

[epoch:  45/100000, batch:    36/  187, ite: 4154] train loss: 0.365159, tar: 0.041776 
l0: 0.056922, l1: 0.051237, l2: 0.080607, l3: 0.084263, l4: 0.071037, l5: 0.078406, l6: 0.105434

[epoch:  45/100000, batch:    38/  187, ite: 4155] train loss: 0.366209, tar: 0.041874 
l0: 0.030957, l1: 0.039778, l2: 0.027669, l3: 0.025746, l4: 0.054375, l5: 0.055825, l6: 0.047235

[epoch:  45/100000, batch:    40/  187, ite: 4156] train loss: 0.365667, tar: 0.041804 
l0: 0.019663, l1: 0.019644, l2: 0.023115, l3: 0.025592, l4: 0.028903, l5: 0.031107, l6: 0.029808

[epoch:  45/100000, batch:    42/  187, ite: 4157] train loss: 0.364470, tar: 0.041663 
l0: 0.034238, l1: 0.031895, l2: 0.042292, l3: 0.046141, l4: 0.065180, l5: 0.063817, l6: 0.059274

[epoch:  45/100000, batch:    44/  187, ite: 4158] train loss: 0.364333, tar: 0.041616 
l0: 0.044671, l1: 0.044736, l2: 0.055788, l3: 0.058579, l4: 0.047894, l5: 0.051974, l6: 0.048726

[epoch:  45/100000, batch:    46/  187, ite: 4159] train loss: 0.364258, tar: 0.041635 
l0: 0.020477, l1: 0.020045, l2: 0.022235, l3: 0.025462, l4: 0.043270, l5: 0.043146, l6: 0.050151

[epoch:  45/100000, batch:    48/  187, ite: 4160] train loss: 0.363386, tar: 0.041503 
l0: 0.029419, l1: 0.031650, l2: 0.034953, l3: 0.039549, l4: 0.055086, l5: 0.052029, l6: 0.050464

[epoch:  45/100000, batch:    50/  187, ite: 4161] train loss: 0.362950, tar: 0.041428 
l0: 0.029738, l1: 0.030172, l2: 0.036955, l3: 0.036624, l4: 0.064382, l5: 0.063988, l6: 0.047241

[epoch:  45/100000, batch:    52/  187, ite: 4162] train loss: 0.362618, tar: 0.041356 
l0: 0.055596, l1: 0.045339, l2: 0.062353, l3: 0.070127, l4: 0.107103, l5: 0.133703, l6: 0.118794

[epoch:  45/100000, batch:    54/  187, ite: 4163] train loss: 0.364031, tar: 0.041443 
l0: 0.042147, l1: 0.043478, l2: 0.051117, l3: 0.059119, l4: 0.073408, l5: 0.080355, l6: 0.058781

[epoch:  45/100000, batch:    56/  187, ite: 4164] train loss: 0.364302, tar: 0.041447 
l0: 0.030208, l1: 0.028868, l2: 0.027913, l3: 0.034772, l4: 0.065324, l5: 0.079805, l6: 0.081076

[epoch:  45/100000, batch:    58/  187, ite: 4165] train loss: 0.364203, tar: 0.041379 
l0: 0.030122, l1: 0.028976, l2: 0.034813, l3: 0.036421, l4: 0.060081, l5: 0.064748, l6: 0.067093

[epoch:  45/100000, batch:    60/  187, ite: 4166] train loss: 0.363950, tar: 0.041311 
l0: 0.045250, l1: 0.041022, l2: 0.053340, l3: 0.056523, l4: 0.071787, l5: 0.072274, l6: 0.074974

[epoch:  45/100000, batch:    62/  187, ite: 4167] train loss: 0.364257, tar: 0.041335 
l0: 0.039504, l1: 0.035431, l2: 0.054886, l3: 0.058246, l4: 0.058015, l5: 0.067599, l6: 0.051715

[epoch:  45/100000, batch:    64/  187, ite: 4168] train loss: 0.364264, tar: 0.041324 
l0: 0.024568, l1: 0.020575, l2: 0.046254, l3: 0.045432, l4: 0.045753, l5: 0.053164, l6: 0.047428

[epoch:  45/100000, batch:    66/  187, ite: 4169] train loss: 0.363784, tar: 0.041225 
l0: 0.030780, l1: 0.034268, l2: 0.040418, l3: 0.045343, l4: 0.053393, l5: 0.058738, l6: 0.053737

[epoch:  45/100000, batch:    68/  187, ite: 4170] train loss: 0.363507, tar: 0.041163 
l0: 0.021524, l1: 0.018588, l2: 0.035510, l3: 0.037201, l4: 0.055570, l5: 0.055203, l6: 0.049856

[epoch:  45/100000, batch:    70/  187, ite: 4171] train loss: 0.362980, tar: 0.041049 
l0: 0.022224, l1: 0.023694, l2: 0.029987, l3: 0.028462, l4: 0.037152, l5: 0.046402, l6: 0.046689

[epoch:  45/100000, batch:    72/  187, ite: 4172] train loss: 0.362234, tar: 0.040939 
l0: 0.034964, l1: 0.032536, l2: 0.055957, l3: 0.060182, l4: 0.071953, l5: 0.069482, l6: 0.061138

[epoch:  45/100000, batch:    74/  187, ite: 4173] train loss: 0.362372, tar: 0.040905 
l0: 0.035768, l1: 0.035755, l2: 0.047465, l3: 0.048230, l4: 0.056350, l5: 0.052108, l6: 0.049087

[epoch:  45/100000, batch:    76/  187, ite: 4174] train loss: 0.362156, tar: 0.040875 
l0: 0.039165, l1: 0.038883, l2: 0.045330, l3: 0.050104, l4: 0.057129, l5: 0.063406, l6: 0.063630

[epoch:  45/100000, batch:    78/  187, ite: 4175] train loss: 0.362130, tar: 0.040865 
l0: 0.041837, l1: 0.040506, l2: 0.072370, l3: 0.065466, l4: 0.056911, l5: 0.064652, l6: 0.067260

[epoch:  45/100000, batch:    80/  187, ite: 4176] train loss: 0.362397, tar: 0.040871 
l0: 0.029560, l1: 0.029588, l2: 0.048054, l3: 0.052468, l4: 0.045443, l5: 0.042363, l6: 0.039380

[epoch:  45/100000, batch:    82/  187, ite: 4177] train loss: 0.361970, tar: 0.040807 
l0: 0.019561, l1: 0.017599, l2: 0.034973, l3: 0.038608, l4: 0.059430, l5: 0.056448, l6: 0.057980

[epoch:  45/100000, batch:    84/  187, ite: 4178] train loss: 0.361535, tar: 0.040687 
l0: 0.024724, l1: 0.024919, l2: 0.033976, l3: 0.036789, l4: 0.055267, l5: 0.053216, l6: 0.050817

[epoch:  45/100000, batch:    86/  187, ite: 4179] train loss: 0.361078, tar: 0.040598 
l0: 0.032241, l1: 0.033685, l2: 0.038776, l3: 0.045681, l4: 0.047468, l5: 0.052016, l6: 0.053381

[epoch:  45/100000, batch:    88/  187, ite: 4180] train loss: 0.360757, tar: 0.040552 
l0: 0.039631, l1: 0.043069, l2: 0.041197, l3: 0.043984, l4: 0.054007, l5: 0.049249, l6: 0.051234

[epoch:  45/100000, batch:    90/  187, ite: 4181] train loss: 0.360545, tar: 0.040547 
l0: 0.025514, l1: 0.027386, l2: 0.032426, l3: 0.033819, l4: 0.039859, l5: 0.038530, l6: 0.034207

[epoch:  45/100000, batch:    92/  187, ite: 4182] train loss: 0.359837, tar: 0.040464 
l0: 0.043769, l1: 0.049074, l2: 0.055623, l3: 0.052274, l4: 0.052546, l5: 0.046021, l6: 0.047264

[epoch:  45/100000, batch:    94/  187, ite: 4183] train loss: 0.359765, tar: 0.040482 
l0: 0.050354, l1: 0.053508, l2: 0.050339, l3: 0.049339, l4: 0.052587, l5: 0.053109, l6: 0.057819

[epoch:  45/100000, batch:    96/  187, ite: 4184] train loss: 0.359804, tar: 0.040536 
l0: 0.025264, l1: 0.023289, l2: 0.030113, l3: 0.032694, l4: 0.037338, l5: 0.046025, l6: 0.048046

[epoch:  45/100000, batch:    98/  187, ite: 4185] train loss: 0.359172, tar: 0.040453 
l0: 0.030267, l1: 0.031690, l2: 0.036863, l3: 0.043206, l4: 0.073171, l5: 0.045381, l6: 0.051198

[epoch:  45/100000, batch:   100/  187, ite: 4186] train loss: 0.358917, tar: 0.040399 
l0: 0.049939, l1: 0.048641, l2: 0.054715, l3: 0.061998, l4: 0.066011, l5: 0.069857, l6: 0.070162

[epoch:  45/100000, batch:   102/  187, ite: 4187] train loss: 0.359250, tar: 0.040450 
l0: 0.044505, l1: 0.046455, l2: 0.042031, l3: 0.042013, l4: 0.051275, l5: 0.055207, l6: 0.054014

[epoch:  45/100000, batch:   104/  187, ite: 4188] train loss: 0.359124, tar: 0.040471 
l0: 0.036130, l1: 0.037102, l2: 0.040846, l3: 0.043061, l4: 0.050547, l5: 0.055684, l6: 0.053635

[epoch:  45/100000, batch:   106/  187, ite: 4189] train loss: 0.358901, tar: 0.040448 
l0: 0.021025, l1: 0.026485, l2: 0.021674, l3: 0.023472, l4: 0.037116, l5: 0.043793, l6: 0.044152

[epoch:  45/100000, batch:   108/  187, ite: 4190] train loss: 0.358158, tar: 0.040346 
l0: 0.024620, l1: 0.021999, l2: 0.028523, l3: 0.034315, l4: 0.055594, l5: 0.050422, l6: 0.054626

[epoch:  45/100000, batch:   110/  187, ite: 4191] train loss: 0.357697, tar: 0.040264 
l0: 0.028927, l1: 0.027191, l2: 0.039600, l3: 0.050109, l4: 0.048494, l5: 0.045940, l6: 0.050320

[epoch:  45/100000, batch:   112/  187, ite: 4192] train loss: 0.357348, tar: 0.040205 
l0: 0.031041, l1: 0.030682, l2: 0.035130, l3: 0.039363, l4: 0.053992, l5: 0.049311, l6: 0.056712

[epoch:  45/100000, batch:   114/  187, ite: 4193] train loss: 0.357031, tar: 0.040157 
l0: 0.045687, l1: 0.042363, l2: 0.056945, l3: 0.060228, l4: 0.072177, l5: 0.074281, l6: 0.065539

[epoch:  45/100000, batch:   116/  187, ite: 4194] train loss: 0.357341, tar: 0.040186 
l0: 0.028703, l1: 0.025975, l2: 0.042094, l3: 0.048206, l4: 0.044828, l5: 0.043298, l6: 0.050668

[epoch:  45/100000, batch:   118/  187, ite: 4195] train loss: 0.356964, tar: 0.040127 
l0: 0.030358, l1: 0.029924, l2: 0.040019, l3: 0.039308, l4: 0.044607, l5: 0.046074, l6: 0.058743

[epoch:  45/100000, batch:   120/  187, ite: 4196] train loss: 0.356617, tar: 0.040077 
l0: 0.023550, l1: 0.021854, l2: 0.041514, l3: 0.043905, l4: 0.062628, l5: 0.060922, l6: 0.069807

[epoch:  45/100000, batch:   122/  187, ite: 4197] train loss: 0.356453, tar: 0.039993 
l0: 0.020209, l1: 0.019686, l2: 0.027412, l3: 0.027888, l4: 0.043368, l5: 0.038463, l6: 0.043055

[epoch:  45/100000, batch:   124/  187, ite: 4198] train loss: 0.355764, tar: 0.039893 
l0: 0.058063, l1: 0.069941, l2: 0.077426, l3: 0.074544, l4: 0.072105, l5: 0.074668, l6: 0.057640

[epoch:  45/100000, batch:   126/  187, ite: 4199] train loss: 0.356410, tar: 0.039984 
l0: 0.053733, l1: 0.054310, l2: 0.069202, l3: 0.065501, l4: 0.059557, l5: 0.058731, l6: 0.066365

[epoch:  45/100000, batch:   128/  187, ite: 4200] train loss: 0.356765, tar: 0.040053 
l0: 0.027679, l1: 0.026008, l2: 0.055633, l3: 0.049423, l4: 0.058319, l5: 0.066814, l6: 0.046765

[epoch:  45/100000, batch:   130/  187, ite: 4201] train loss: 0.356635, tar: 0.039992 
l0: 0.055998, l1: 0.055179, l2: 0.055993, l3: 0.053724, l4: 0.073822, l5: 0.066309, l6: 0.092185

[epoch:  45/100000, batch:   132/  187, ite: 4202] train loss: 0.357113, tar: 0.040071 
l0: 0.038959, l1: 0.041309, l2: 0.040866, l3: 0.043387, l4: 0.052559, l5: 0.049905, l6: 0.045167

[epoch:  45/100000, batch:   134/  187, ite: 4203] train loss: 0.356892, tar: 0.040065 
l0: 0.047167, l1: 0.041982, l2: 0.045068, l3: 0.063291, l4: 0.087602, l5: 0.073174, l6: 0.078302

[epoch:  45/100000, batch:   136/  187, ite: 4204] train loss: 0.357283, tar: 0.040100 
l0: 0.031200, l1: 0.030816, l2: 0.037721, l3: 0.036865, l4: 0.047602, l5: 0.048331, l6: 0.043916

[epoch:  45/100000, batch:   138/  187, ite: 4205] train loss: 0.356888, tar: 0.040057 
l0: 0.082199, l1: 0.083602, l2: 0.060475, l3: 0.091938, l4: 0.158025, l5: 0.123399, l6: 0.142332

[epoch:  45/100000, batch:   140/  187, ite: 4206] train loss: 0.358758, tar: 0.040261 
l0: 0.040793, l1: 0.039783, l2: 0.049159, l3: 0.046444, l4: 0.057464, l5: 0.052574, l6: 0.073791

[epoch:  45/100000, batch:   142/  187, ite: 4207] train loss: 0.358764, tar: 0.040264 
l0: 0.052109, l1: 0.051396, l2: 0.048429, l3: 0.063115, l4: 0.087616, l5: 0.087551, l6: 0.083816

[epoch:  45/100000, batch:   144/  187, ite: 4208] train loss: 0.359318, tar: 0.040321 
l0: 0.021595, l1: 0.021852, l2: 0.020929, l3: 0.021683, l4: 0.048262, l5: 0.043914, l6: 0.039536

[epoch:  45/100000, batch:   146/  187, ite: 4209] train loss: 0.358640, tar: 0.040231 
l0: 0.029154, l1: 0.037899, l2: 0.032910, l3: 0.029004, l4: 0.048336, l5: 0.056547, l6: 0.052099

[epoch:  45/100000, batch:   148/  187, ite: 4210] train loss: 0.358294, tar: 0.040178 
l0: 0.058317, l1: 0.055397, l2: 0.063668, l3: 0.066528, l4: 0.102207, l5: 0.101164, l6: 0.090155

[epoch:  45/100000, batch:   150/  187, ite: 4211] train loss: 0.359143, tar: 0.040264 
l0: 0.045158, l1: 0.049303, l2: 0.043569, l3: 0.049749, l4: 0.066505, l5: 0.066622, l6: 0.063521

[epoch:  45/100000, batch:   152/  187, ite: 4212] train loss: 0.359263, tar: 0.040288 
l0: 0.061854, l1: 0.072198, l2: 0.071325, l3: 0.067842, l4: 0.073146, l5: 0.066272, l6: 0.078780

[epoch:  45/100000, batch:   154/  187, ite: 4213] train loss: 0.359883, tar: 0.040389 
l0: 0.050578, l1: 0.047922, l2: 0.056245, l3: 0.054883, l4: 0.062484, l5: 0.083053, l6: 0.088108

[epoch:  45/100000, batch:   156/  187, ite: 4214] train loss: 0.360273, tar: 0.040436 
l0: 0.046282, l1: 0.049304, l2: 0.055456, l3: 0.050709, l4: 0.053613, l5: 0.048315, l6: 0.048195

[epoch:  45/100000, batch:   158/  187, ite: 4215] train loss: 0.360234, tar: 0.040464 
l0: 0.031214, l1: 0.030105, l2: 0.032161, l3: 0.037065, l4: 0.052031, l5: 0.055332, l6: 0.067930

[epoch:  45/100000, batch:   160/  187, ite: 4216] train loss: 0.359982, tar: 0.040421 
l0: 0.029252, l1: 0.030863, l2: 0.034973, l3: 0.036565, l4: 0.042540, l5: 0.040261, l6: 0.042340

[epoch:  45/100000, batch:   162/  187, ite: 4217] train loss: 0.359506, tar: 0.040369 
l0: 0.056716, l1: 0.060305, l2: 0.059563, l3: 0.059593, l4: 0.063623, l5: 0.063290, l6: 0.062979

[epoch:  45/100000, batch:   164/  187, ite: 4218] train loss: 0.359812, tar: 0.040444 
l0: 0.039622, l1: 0.045114, l2: 0.043458, l3: 0.050716, l4: 0.042273, l5: 0.042045, l6: 0.043315

[epoch:  45/100000, batch:   166/  187, ite: 4219] train loss: 0.359568, tar: 0.040441 
l0: 0.047897, l1: 0.051935, l2: 0.052933, l3: 0.057111, l4: 0.050130, l5: 0.051914, l6: 0.048191

[epoch:  45/100000, batch:   168/  187, ite: 4220] train loss: 0.359571, tar: 0.040474 
l0: 0.034156, l1: 0.036027, l2: 0.042385, l3: 0.045741, l4: 0.054873, l5: 0.057222, l6: 0.054365

[epoch:  45/100000, batch:   170/  187, ite: 4221] train loss: 0.359413, tar: 0.040446 
l0: 0.032054, l1: 0.033812, l2: 0.033577, l3: 0.031264, l4: 0.049023, l5: 0.057236, l6: 0.048580

[epoch:  45/100000, batch:   172/  187, ite: 4222] train loss: 0.359081, tar: 0.040408 
l0: 0.051215, l1: 0.048189, l2: 0.050834, l3: 0.061323, l4: 0.100498, l5: 0.105155, l6: 0.098610

[epoch:  45/100000, batch:   174/  187, ite: 4223] train loss: 0.359784, tar: 0.040456 
l0: 0.065098, l1: 0.063658, l2: 0.071610, l3: 0.074845, l4: 0.093865, l5: 0.084219, l6: 0.087997

[epoch:  45/100000, batch:   176/  187, ite: 4224] train loss: 0.360594, tar: 0.040567 
l0: 0.036055, l1: 0.035852, l2: 0.050125, l3: 0.048042, l4: 0.063884, l5: 0.059403, l6: 0.057342

[epoch:  45/100000, batch:   178/  187, ite: 4225] train loss: 0.360550, tar: 0.040546 
l0: 0.032721, l1: 0.030603, l2: 0.045231, l3: 0.044635, l4: 0.053278, l5: 0.053947, l6: 0.047104

[epoch:  45/100000, batch:   180/  187, ite: 4226] train loss: 0.360315, tar: 0.040512 
l0: 0.039890, l1: 0.041036, l2: 0.035969, l3: 0.038030, l4: 0.048836, l5: 0.045455, l6: 0.063030

[epoch:  45/100000, batch:   182/  187, ite: 4227] train loss: 0.360103, tar: 0.040509 
l0: 0.049080, l1: 0.058599, l2: 0.054034, l3: 0.046801, l4: 0.045585, l5: 0.046849, l6: 0.040434

[epoch:  45/100000, batch:   184/  187, ite: 4228] train loss: 0.360021, tar: 0.040547 
l0: 0.044935, l1: 0.052355, l2: 0.037408, l3: 0.039869, l4: 0.038365, l5: 0.041197, l6: 0.051376

[epoch:  45/100000, batch:   186/  187, ite: 4229] train loss: 0.359783, tar: 0.040566 
l0: 0.034795, l1: 0.036843, l2: 0.041646, l3: 0.040509, l4: 0.056713, l5: 0.049275, l6: 0.041662

[epoch:  45/100000, batch:   188/  187, ite: 4230] train loss: 0.359530, tar: 0.040541 
l0: 0.023963, l1: 0.024722, l2: 0.038075, l3: 0.030545, l4: 0.041199, l5: 0.042560, l6: 0.037748

[epoch:  46/100000, batch:     2/  187, ite: 4231] train loss: 0.359007, tar: 0.040469 
l0: 0.023475, l1: 0.024227, l2: 0.027533, l3: 0.028960, l4: 0.051908, l5: 0.049142, l6: 0.046204

[epoch:  46/100000, batch:     4/  187, ite: 4232] train loss: 0.358543, tar: 0.040396 
l0: 0.030584, l1: 0.030345, l2: 0.036881, l3: 0.033702, l4: 0.036424, l5: 0.040343, l6: 0.047617

[epoch:  46/100000, batch:     6/  187, ite: 4233] train loss: 0.358103, tar: 0.040354 
l0: 0.039737, l1: 0.036303, l2: 0.042435, l3: 0.046218, l4: 0.091472, l5: 0.088238, l6: 0.086975

[epoch:  46/100000, batch:     8/  187, ite: 4234] train loss: 0.358416, tar: 0.040351 
l0: 0.028043, l1: 0.025986, l2: 0.033901, l3: 0.032290, l4: 0.047490, l5: 0.045718, l6: 0.044317

[epoch:  46/100000, batch:    10/  187, ite: 4235] train loss: 0.357988, tar: 0.040299 
l0: 0.028950, l1: 0.046352, l2: 0.050198, l3: 0.036481, l4: 0.023146, l5: 0.017352, l6: 0.016624

[epoch:  46/100000, batch:    12/  187, ite: 4236] train loss: 0.357399, tar: 0.040251 
l0: 0.210884, l1: 0.178301, l2: 0.204490, l3: 0.212075, l4: 0.232801, l5: 0.373153, l6: 0.307751

[epoch:  46/100000, batch:    14/  187, ite: 4237] train loss: 0.363146, tar: 0.040970 
l0: 0.039976, l1: 0.036220, l2: 0.046505, l3: 0.045652, l4: 0.068641, l5: 0.070993, l6: 0.065085

[epoch:  46/100000, batch:    16/  187, ite: 4238] train loss: 0.363188, tar: 0.040966 
l0: 0.032672, l1: 0.031630, l2: 0.046815, l3: 0.052118, l4: 0.084396, l5: 0.073404, l6: 0.077302

[epoch:  46/100000, batch:    18/  187, ite: 4239] train loss: 0.363335, tar: 0.040932 
l0: 0.026696, l1: 0.026855, l2: 0.033078, l3: 0.030434, l4: 0.040362, l5: 0.041055, l6: 0.035711

[epoch:  46/100000, batch:    20/  187, ite: 4240] train loss: 0.362797, tar: 0.040872 
l0: 0.028558, l1: 0.024779, l2: 0.031962, l3: 0.037891, l4: 0.062726, l5: 0.058643, l6: 0.061102

[epoch:  46/100000, batch:    22/  187, ite: 4241] train loss: 0.362560, tar: 0.040821 
l0: 0.073639, l1: 0.076829, l2: 0.075955, l3: 0.073935, l4: 0.096809, l5: 0.111239, l6: 0.087404

[epoch:  46/100000, batch:    24/  187, ite: 4242] train loss: 0.363524, tar: 0.040957 
l0: 0.029950, l1: 0.029498, l2: 0.038687, l3: 0.042204, l4: 0.055471, l5: 0.052573, l6: 0.058492

[epoch:  46/100000, batch:    26/  187, ite: 4243] train loss: 0.363291, tar: 0.040912 
l0: 0.033085, l1: 0.029105, l2: 0.046349, l3: 0.053662, l4: 0.047200, l5: 0.047840, l6: 0.056221

[epoch:  46/100000, batch:    28/  187, ite: 4244] train loss: 0.363086, tar: 0.040879 
l0: 0.032154, l1: 0.028595, l2: 0.039530, l3: 0.045157, l4: 0.050309, l5: 0.053250, l6: 0.051261

[epoch:  46/100000, batch:    30/  187, ite: 4245] train loss: 0.362830, tar: 0.040844 
l0: 0.027970, l1: 0.025107, l2: 0.037885, l3: 0.044341, l4: 0.054543, l5: 0.057577, l6: 0.065055

[epoch:  46/100000, batch:    32/  187, ite: 4246] train loss: 0.362625, tar: 0.040791 
l0: 0.046709, l1: 0.045566, l2: 0.044482, l3: 0.057654, l4: 0.068779, l5: 0.071051, l6: 0.075595

[epoch:  46/100000, batch:    34/  187, ite: 4247] train loss: 0.362816, tar: 0.040815 
l0: 0.039324, l1: 0.041593, l2: 0.058780, l3: 0.058414, l4: 0.073686, l5: 0.054450, l6: 0.062169

[epoch:  46/100000, batch:    36/  187, ite: 4248] train loss: 0.362920, tar: 0.040809 
l0: 0.025246, l1: 0.023907, l2: 0.030556, l3: 0.033323, l4: 0.034791, l5: 0.036959, l6: 0.042962

[epoch:  46/100000, batch:    38/  187, ite: 4249] train loss: 0.362377, tar: 0.040747 
l0: 0.043640, l1: 0.038670, l2: 0.049806, l3: 0.053954, l4: 0.091876, l5: 0.094742, l6: 0.087619

[epoch:  46/100000, batch:    40/  187, ite: 4250] train loss: 0.362768, tar: 0.040759 
l0: 0.042964, l1: 0.048238, l2: 0.041264, l3: 0.043342, l4: 0.063589, l5: 0.066098, l6: 0.047403

[epoch:  46/100000, batch:    42/  187, ite: 4251] train loss: 0.362729, tar: 0.040767 
l0: 0.038266, l1: 0.036451, l2: 0.038367, l3: 0.034594, l4: 0.040844, l5: 0.046095, l6: 0.069672

[epoch:  46/100000, batch:    44/  187, ite: 4252] train loss: 0.362497, tar: 0.040757 
l0: 0.044263, l1: 0.045174, l2: 0.053956, l3: 0.056124, l4: 0.116571, l5: 0.093366, l6: 0.077696

[epoch:  46/100000, batch:    46/  187, ite: 4253] train loss: 0.362990, tar: 0.040771 
l0: 0.043756, l1: 0.045486, l2: 0.042820, l3: 0.045520, l4: 0.076174, l5: 0.082967, l6: 0.050148

[epoch:  46/100000, batch:    48/  187, ite: 4254] train loss: 0.363084, tar: 0.040783 
l0: 0.051274, l1: 0.044086, l2: 0.061810, l3: 0.066337, l4: 0.079099, l5: 0.109354, l6: 0.125536

[epoch:  46/100000, batch:    50/  187, ite: 4255] train loss: 0.363768, tar: 0.040824 
l0: 0.032590, l1: 0.036313, l2: 0.036418, l3: 0.044216, l4: 0.042226, l5: 0.040897, l6: 0.038209

[epoch:  46/100000, batch:    52/  187, ite: 4256] train loss: 0.363405, tar: 0.040792 
l0: 0.031296, l1: 0.031940, l2: 0.037225, l3: 0.042984, l4: 0.074407, l5: 0.076311, l6: 0.057648

[epoch:  46/100000, batch:    54/  187, ite: 4257] train loss: 0.363360, tar: 0.040755 
l0: 0.024590, l1: 0.026628, l2: 0.026083, l3: 0.025386, l4: 0.036540, l5: 0.035783, l6: 0.047232

[epoch:  46/100000, batch:    56/  187, ite: 4258] train loss: 0.362813, tar: 0.040692 
l0: 0.020992, l1: 0.019316, l2: 0.026630, l3: 0.032984, l4: 0.045193, l5: 0.044209, l6: 0.041190

[epoch:  46/100000, batch:    58/  187, ite: 4259] train loss: 0.362302, tar: 0.040616 
l0: 0.030216, l1: 0.028090, l2: 0.037939, l3: 0.038391, l4: 0.042639, l5: 0.041695, l6: 0.055550

[epoch:  46/100000, batch:    60/  187, ite: 4260] train loss: 0.361964, tar: 0.040576 
l0: 0.047918, l1: 0.051791, l2: 0.045789, l3: 0.048669, l4: 0.068013, l5: 0.058914, l6: 0.063211

[epoch:  46/100000, batch:    62/  187, ite: 4261] train loss: 0.362050, tar: 0.040604 
l0: 0.040031, l1: 0.039537, l2: 0.044234, l3: 0.048356, l4: 0.046419, l5: 0.048266, l6: 0.056874

[epoch:  46/100000, batch:    64/  187, ite: 4262] train loss: 0.361904, tar: 0.040602 
l0: 0.047425, l1: 0.051816, l2: 0.051998, l3: 0.048648, l4: 0.069564, l5: 0.061873, l6: 0.066946

[epoch:  46/100000, batch:    66/  187, ite: 4263] train loss: 0.362042, tar: 0.040628 
l0: 0.067842, l1: 0.072442, l2: 0.087531, l3: 0.099583, l4: 0.150373, l5: 0.121483, l6: 0.086119

[epoch:  46/100000, batch:    68/  187, ite: 4264] train loss: 0.363267, tar: 0.040731 
l0: 0.027021, l1: 0.027194, l2: 0.031659, l3: 0.035686, l4: 0.054283, l5: 0.049542, l6: 0.062383

[epoch:  46/100000, batch:    70/  187, ite: 4265] train loss: 0.362982, tar: 0.040680 
l0: 0.026447, l1: 0.027440, l2: 0.043313, l3: 0.045684, l4: 0.055772, l5: 0.056923, l6: 0.047019

[epoch:  46/100000, batch:    72/  187, ite: 4266] train loss: 0.362755, tar: 0.040626 
l0: 0.028918, l1: 0.028781, l2: 0.038640, l3: 0.041043, l4: 0.050472, l5: 0.061215, l6: 0.070272

[epoch:  46/100000, batch:    74/  187, ite: 4267] train loss: 0.362592, tar: 0.040582 
l0: 0.030417, l1: 0.027977, l2: 0.043335, l3: 0.052191, l4: 0.081728, l5: 0.083889, l6: 0.080600

[epoch:  46/100000, batch:    76/  187, ite: 4268] train loss: 0.362732, tar: 0.040544 
l0: 0.034096, l1: 0.033672, l2: 0.041547, l3: 0.040830, l4: 0.049389, l5: 0.041681, l6: 0.046736

[epoch:  46/100000, batch:    78/  187, ite: 4269] train loss: 0.362454, tar: 0.040520 
l0: 0.022805, l1: 0.032512, l2: 0.023954, l3: 0.021213, l4: 0.047168, l5: 0.052766, l6: 0.038454

[epoch:  46/100000, batch:    80/  187, ite: 4270] train loss: 0.361997, tar: 0.040455 
l0: 0.024238, l1: 0.025198, l2: 0.034385, l3: 0.035205, l4: 0.043233, l5: 0.036655, l6: 0.035741

[epoch:  46/100000, batch:    82/  187, ite: 4271] train loss: 0.361527, tar: 0.040395 
l0: 0.026328, l1: 0.027243, l2: 0.034246, l3: 0.035252, l4: 0.059460, l5: 0.061029, l6: 0.052093

[epoch:  46/100000, batch:    84/  187, ite: 4272] train loss: 0.361285, tar: 0.040343 
l0: 0.023966, l1: 0.022804, l2: 0.029977, l3: 0.034410, l4: 0.058717, l5: 0.052259, l6: 0.064838

[epoch:  46/100000, batch:    86/  187, ite: 4273] train loss: 0.361012, tar: 0.040283 
l0: 0.106137, l1: 0.132171, l2: 0.112964, l3: 0.092965, l4: 0.088688, l5: 0.087382, l6: 0.082697

[epoch:  46/100000, batch:    88/  187, ite: 4274] train loss: 0.362260, tar: 0.040523 
l0: 0.022498, l1: 0.020816, l2: 0.028983, l3: 0.052697, l4: 0.109500, l5: 0.092084, l6: 0.106796

[epoch:  46/100000, batch:    90/  187, ite: 4275] train loss: 0.362519, tar: 0.040458 
l0: 0.037736, l1: 0.030616, l2: 0.046250, l3: 0.049946, l4: 0.086073, l5: 0.094451, l6: 0.136069

[epoch:  46/100000, batch:    92/  187, ite: 4276] train loss: 0.362949, tar: 0.040448 
l0: 0.042982, l1: 0.057072, l2: 0.043270, l3: 0.038007, l4: 0.041811, l5: 0.034065, l6: 0.030651

[epoch:  46/100000, batch:    94/  187, ite: 4277] train loss: 0.362678, tar: 0.040457 
l0: 0.041046, l1: 0.036166, l2: 0.048178, l3: 0.058082, l4: 0.075231, l5: 0.084248, l6: 0.088953

[epoch:  46/100000, batch:    96/  187, ite: 4278] train loss: 0.362927, tar: 0.040459 
l0: 0.028076, l1: 0.034729, l2: 0.028345, l3: 0.028926, l4: 0.034386, l5: 0.040284, l6: 0.041313

[epoch:  46/100000, batch:    98/  187, ite: 4279] train loss: 0.362472, tar: 0.040415 
l0: 0.042343, l1: 0.038860, l2: 0.041323, l3: 0.048688, l4: 0.054062, l5: 0.067946, l6: 0.083845

[epoch:  46/100000, batch:   100/  187, ite: 4280] train loss: 0.362524, tar: 0.040422 
l0: 0.051422, l1: 0.049017, l2: 0.073726, l3: 0.076517, l4: 0.066959, l5: 0.064314, l6: 0.065944

[epoch:  46/100000, batch:   102/  187, ite: 4281] train loss: 0.362828, tar: 0.040461 
l0: 0.052704, l1: 0.053556, l2: 0.066452, l3: 0.063182, l4: 0.051918, l5: 0.054354, l6: 0.049926

[epoch:  46/100000, batch:   104/  187, ite: 4282] train loss: 0.362932, tar: 0.040504 
l0: 0.079388, l1: 0.092789, l2: 0.081362, l3: 0.064623, l4: 0.083220, l5: 0.077751, l6: 0.073100

[epoch:  46/100000, batch:   106/  187, ite: 4283] train loss: 0.363601, tar: 0.040642 
l0: 0.048722, l1: 0.044159, l2: 0.058218, l3: 0.063243, l4: 0.097823, l5: 0.096875, l6: 0.083798

[epoch:  46/100000, batch:   108/  187, ite: 4284] train loss: 0.364056, tar: 0.040670 
l0: 0.034424, l1: 0.036859, l2: 0.037380, l3: 0.039652, l4: 0.053237, l5: 0.052862, l6: 0.058587

[epoch:  46/100000, batch:   110/  187, ite: 4285] train loss: 0.363877, tar: 0.040648 
l0: 0.023221, l1: 0.020131, l2: 0.036555, l3: 0.039164, l4: 0.062992, l5: 0.053162, l6: 0.060823

[epoch:  46/100000, batch:   112/  187, ite: 4286] train loss: 0.363639, tar: 0.040587 
l0: 0.033793, l1: 0.030470, l2: 0.042913, l3: 0.046018, l4: 0.074213, l5: 0.074420, l6: 0.086878

[epoch:  46/100000, batch:   114/  187, ite: 4287] train loss: 0.363727, tar: 0.040564 
l0: 0.039084, l1: 0.035093, l2: 0.048434, l3: 0.060481, l4: 0.078252, l5: 0.082842, l6: 0.088587

[epoch:  46/100000, batch:   116/  187, ite: 4288] train loss: 0.363967, tar: 0.040559 
l0: 0.042537, l1: 0.041804, l2: 0.049321, l3: 0.051575, l4: 0.056341, l5: 0.059988, l6: 0.056392

[epoch:  46/100000, batch:   118/  187, ite: 4289] train loss: 0.363946, tar: 0.040565 
l0: 0.032486, l1: 0.031588, l2: 0.038488, l3: 0.039176, l4: 0.051588, l5: 0.055114, l6: 0.050151

[epoch:  46/100000, batch:   120/  187, ite: 4290] train loss: 0.363720, tar: 0.040538 
l0: 0.023243, l1: 0.026489, l2: 0.028113, l3: 0.020608, l4: 0.038898, l5: 0.038321, l6: 0.036199

[epoch:  46/100000, batch:   122/  187, ite: 4291] train loss: 0.363199, tar: 0.040478 
l0: 0.034187, l1: 0.041727, l2: 0.053086, l3: 0.036546, l4: 0.077476, l5: 0.061933, l6: 0.038176

[epoch:  46/100000, batch:   124/  187, ite: 4292] train loss: 0.363130, tar: 0.040457 
l0: 0.048065, l1: 0.054040, l2: 0.066999, l3: 0.062965, l4: 0.050854, l5: 0.048737, l6: 0.039826

[epoch:  46/100000, batch:   126/  187, ite: 4293] train loss: 0.363158, tar: 0.040483 
l0: 0.058376, l1: 0.056675, l2: 0.077730, l3: 0.083977, l4: 0.063559, l5: 0.062845, l6: 0.069207

[epoch:  46/100000, batch:   128/  187, ite: 4294] train loss: 0.363530, tar: 0.040543 
l0: 0.031864, l1: 0.034537, l2: 0.040252, l3: 0.034328, l4: 0.072467, l5: 0.068996, l6: 0.081500

[epoch:  46/100000, batch:   130/  187, ite: 4295] train loss: 0.363531, tar: 0.040514 
l0: 0.046260, l1: 0.047502, l2: 0.059743, l3: 0.056783, l4: 0.050205, l5: 0.054957, l6: 0.061442

[epoch:  46/100000, batch:   132/  187, ite: 4296] train loss: 0.363576, tar: 0.040533 
l0: 0.041127, l1: 0.040149, l2: 0.051168, l3: 0.053955, l4: 0.041805, l5: 0.047994, l6: 0.057839

[epoch:  46/100000, batch:   134/  187, ite: 4297] train loss: 0.363477, tar: 0.040535 
l0: 0.024661, l1: 0.031411, l2: 0.028341, l3: 0.025116, l4: 0.031887, l5: 0.037253, l6: 0.025767

[epoch:  46/100000, batch:   136/  187, ite: 4298] train loss: 0.362943, tar: 0.040482 
l0: 0.057547, l1: 0.063516, l2: 0.077425, l3: 0.074618, l4: 0.081000, l5: 0.060462, l6: 0.063593

[epoch:  46/100000, batch:   138/  187, ite: 4299] train loss: 0.363329, tar: 0.040539 
l0: 0.033749, l1: 0.032740, l2: 0.039908, l3: 0.051314, l4: 0.049359, l5: 0.043021, l6: 0.045801

[epoch:  46/100000, batch:   140/  187, ite: 4300] train loss: 0.363104, tar: 0.040517 
l0: 0.071150, l1: 0.068668, l2: 0.089280, l3: 0.099917, l4: 0.092577, l5: 0.080782, l6: 0.103259

[epoch:  46/100000, batch:   142/  187, ite: 4301] train loss: 0.363910, tar: 0.040618 
l0: 0.027036, l1: 0.027762, l2: 0.030781, l3: 0.032005, l4: 0.031036, l5: 0.029803, l6: 0.027107

[epoch:  46/100000, batch:   144/  187, ite: 4302] train loss: 0.363385, tar: 0.040573 
l0: 0.038098, l1: 0.036215, l2: 0.047038, l3: 0.054382, l4: 0.081347, l5: 0.064315, l6: 0.061716

[epoch:  46/100000, batch:   146/  187, ite: 4303] train loss: 0.363450, tar: 0.040565 
l0: 0.040406, l1: 0.036432, l2: 0.049689, l3: 0.051527, l4: 0.075639, l5: 0.066764, l6: 0.069421

[epoch:  46/100000, batch:   148/  187, ite: 4304] train loss: 0.363537, tar: 0.040565 
l0: 0.044190, l1: 0.045234, l2: 0.049346, l3: 0.049178, l4: 0.056185, l5: 0.049930, l6: 0.050484

[epoch:  46/100000, batch:   150/  187, ite: 4305] train loss: 0.363475, tar: 0.040577 
l0: 0.030808, l1: 0.026791, l2: 0.047420, l3: 0.047631, l4: 0.045868, l5: 0.051613, l6: 0.043340

[epoch:  46/100000, batch:   152/  187, ite: 4306] train loss: 0.363246, tar: 0.040545 
l0: 0.034218, l1: 0.033832, l2: 0.040005, l3: 0.035801, l4: 0.046166, l5: 0.047666, l6: 0.055248

[epoch:  46/100000, batch:   154/  187, ite: 4307] train loss: 0.363017, tar: 0.040524 
l0: 0.029608, l1: 0.027330, l2: 0.038820, l3: 0.038940, l4: 0.039648, l5: 0.038342, l6: 0.042069

[epoch:  46/100000, batch:   156/  187, ite: 4308] train loss: 0.362666, tar: 0.040489 
l0: 0.052327, l1: 0.050481, l2: 0.068710, l3: 0.072815, l4: 0.084918, l5: 0.079510, l6: 0.079703

[epoch:  46/100000, batch:   158/  187, ite: 4309] train loss: 0.363073, tar: 0.040527 
l0: 0.024574, l1: 0.021912, l2: 0.033993, l3: 0.040574, l4: 0.058557, l5: 0.059437, l6: 0.064518

[epoch:  46/100000, batch:   160/  187, ite: 4310] train loss: 0.362881, tar: 0.040475 
l0: 0.055745, l1: 0.052256, l2: 0.066400, l3: 0.082557, l4: 0.085739, l5: 0.085555, l6: 0.094896

[epoch:  46/100000, batch:   162/  187, ite: 4311] train loss: 0.363396, tar: 0.040525 
l0: 0.037374, l1: 0.033564, l2: 0.066088, l3: 0.066954, l4: 0.078042, l5: 0.086988, l6: 0.100355

[epoch:  46/100000, batch:   164/  187, ite: 4312] train loss: 0.363736, tar: 0.040514 
l0: 0.035754, l1: 0.039542, l2: 0.033801, l3: 0.032512, l4: 0.046547, l5: 0.043016, l6: 0.046401

[epoch:  46/100000, batch:   166/  187, ite: 4313] train loss: 0.363460, tar: 0.040499 
l0: 0.028528, l1: 0.021036, l2: 0.034894, l3: 0.051487, l4: 0.089106, l5: 0.102155, l6: 0.098206

[epoch:  46/100000, batch:   168/  187, ite: 4314] train loss: 0.363658, tar: 0.040461 
l0: 0.055040, l1: 0.057179, l2: 0.075860, l3: 0.068106, l4: 0.073459, l5: 0.076416, l6: 0.074976

[epoch:  46/100000, batch:   170/  187, ite: 4315] train loss: 0.364030, tar: 0.040507 
l0: 0.041655, l1: 0.044237, l2: 0.052063, l3: 0.048417, l4: 0.059184, l5: 0.052790, l6: 0.048379

[epoch:  46/100000, batch:   172/  187, ite: 4316] train loss: 0.363976, tar: 0.040511 
l0: 0.040910, l1: 0.041848, l2: 0.045526, l3: 0.042324, l4: 0.049548, l5: 0.062402, l6: 0.068860

[epoch:  46/100000, batch:   174/  187, ite: 4317] train loss: 0.363936, tar: 0.040512 
l0: 0.047720, l1: 0.045363, l2: 0.056324, l3: 0.059028, l4: 0.064617, l5: 0.069043, l6: 0.072382

[epoch:  46/100000, batch:   176/  187, ite: 4318] train loss: 0.364095, tar: 0.040535 
l0: 0.043744, l1: 0.043039, l2: 0.055129, l3: 0.057000, l4: 0.083351, l5: 0.075060, l6: 0.071605

[epoch:  46/100000, batch:   178/  187, ite: 4319] train loss: 0.364298, tar: 0.040545 
l0: 0.060636, l1: 0.048793, l2: 0.068694, l3: 0.090882, l4: 0.162115, l5: 0.157966, l6: 0.186054

[epoch:  46/100000, batch:   180/  187, ite: 4320] train loss: 0.365582, tar: 0.040608 
l0: 0.033553, l1: 0.035384, l2: 0.041736, l3: 0.042053, l4: 0.034980, l5: 0.037277, l6: 0.037011

[epoch:  46/100000, batch:   182/  187, ite: 4321] train loss: 0.365259, tar: 0.040586 
l0: 0.036525, l1: 0.035954, l2: 0.037630, l3: 0.048980, l4: 0.067889, l5: 0.051198, l6: 0.065134

[epoch:  46/100000, batch:   184/  187, ite: 4322] train loss: 0.365191, tar: 0.040573 
l0: 0.121425, l1: 0.135288, l2: 0.162005, l3: 0.125341, l4: 0.151920, l5: 0.125753, l6: 0.116489

[epoch:  46/100000, batch:   186/  187, ite: 4323] train loss: 0.366965, tar: 0.040823 
l0: 0.030040, l1: 0.030746, l2: 0.041260, l3: 0.036195, l4: 0.040643, l5: 0.043377, l6: 0.039136

[epoch:  46/100000, batch:   188/  187, ite: 4324] train loss: 0.366639, tar: 0.040790 
l0: 0.025016, l1: 0.021984, l2: 0.037831, l3: 0.043129, l4: 0.040592, l5: 0.045426, l6: 0.042886

[epoch:  47/100000, batch:     2/  187, ite: 4325] train loss: 0.366302, tar: 0.040742 
l0: 0.023509, l1: 0.022307, l2: 0.035608, l3: 0.036313, l4: 0.047235, l5: 0.046823, l6: 0.050163

[epoch:  47/100000, batch:     4/  187, ite: 4326] train loss: 0.365982, tar: 0.040689 
l0: 0.039298, l1: 0.036419, l2: 0.052679, l3: 0.053118, l4: 0.074001, l5: 0.074099, l6: 0.068764

[epoch:  47/100000, batch:     6/  187, ite: 4327] train loss: 0.366081, tar: 0.040685 
l0: 0.027819, l1: 0.028397, l2: 0.028768, l3: 0.034033, l4: 0.045238, l5: 0.042855, l6: 0.039641

[epoch:  47/100000, batch:     8/  187, ite: 4328] train loss: 0.365717, tar: 0.040645 
l0: 0.037542, l1: 0.036058, l2: 0.047819, l3: 0.047975, l4: 0.066605, l5: 0.080754, l6: 0.077896

[epoch:  47/100000, batch:    10/  187, ite: 4329] train loss: 0.365805, tar: 0.040636 
l0: 0.029824, l1: 0.030703, l2: 0.036479, l3: 0.040944, l4: 0.051175, l5: 0.054045, l6: 0.046029

[epoch:  47/100000, batch:    12/  187, ite: 4330] train loss: 0.365573, tar: 0.040603 
l0: 0.034160, l1: 0.032996, l2: 0.037236, l3: 0.040083, l4: 0.058607, l5: 0.060196, l6: 0.054532

[epoch:  47/100000, batch:    14/  187, ite: 4331] train loss: 0.365428, tar: 0.040584 
l0: 0.029983, l1: 0.030298, l2: 0.033263, l3: 0.037646, l4: 0.049697, l5: 0.047670, l6: 0.041713

[epoch:  47/100000, batch:    16/  187, ite: 4332] train loss: 0.365142, tar: 0.040552 
l0: 0.022850, l1: 0.022888, l2: 0.026183, l3: 0.033053, l4: 0.048438, l5: 0.043990, l6: 0.050559

[epoch:  47/100000, batch:    18/  187, ite: 4333] train loss: 0.364790, tar: 0.040499 
l0: 0.033717, l1: 0.032769, l2: 0.042629, l3: 0.045829, l4: 0.071014, l5: 0.062354, l6: 0.063075

[epoch:  47/100000, batch:    20/  187, ite: 4334] train loss: 0.364750, tar: 0.040478 
l0: 0.031094, l1: 0.033627, l2: 0.029995, l3: 0.031230, l4: 0.046010, l5: 0.044044, l6: 0.046621

[epoch:  47/100000, batch:    22/  187, ite: 4335] train loss: 0.364445, tar: 0.040450 
l0: 0.023266, l1: 0.019914, l2: 0.035455, l3: 0.035465, l4: 0.060645, l5: 0.065220, l6: 0.055228

[epoch:  47/100000, batch:    24/  187, ite: 4336] train loss: 0.364239, tar: 0.040399 
l0: 0.033107, l1: 0.037990, l2: 0.046492, l3: 0.043151, l4: 0.036468, l5: 0.032000, l6: 0.030272

[epoch:  47/100000, batch:    26/  187, ite: 4337] train loss: 0.363928, tar: 0.040377 
l0: 0.031632, l1: 0.037715, l2: 0.041323, l3: 0.037514, l4: 0.034205, l5: 0.037822, l6: 0.047228

[epoch:  47/100000, batch:    28/  187, ite: 4338] train loss: 0.363642, tar: 0.040352 
l0: 0.034520, l1: 0.047380, l2: 0.040234, l3: 0.037256, l4: 0.042250, l5: 0.049291, l6: 0.044667

[epoch:  47/100000, batch:    30/  187, ite: 4339] train loss: 0.363442, tar: 0.040334 
l0: 0.021584, l1: 0.025869, l2: 0.025628, l3: 0.019744, l4: 0.057215, l5: 0.057513, l6: 0.050015

[epoch:  47/100000, batch:    32/  187, ite: 4340] train loss: 0.363130, tar: 0.040279 
l0: 0.055425, l1: 0.057463, l2: 0.063948, l3: 0.063815, l4: 0.071396, l5: 0.071482, l6: 0.070631

[epoch:  47/100000, batch:    34/  187, ite: 4341] train loss: 0.363397, tar: 0.040324 
l0: 0.029432, l1: 0.027151, l2: 0.030114, l3: 0.032063, l4: 0.047343, l5: 0.060287, l6: 0.064201

[epoch:  47/100000, batch:    36/  187, ite: 4342] train loss: 0.363184, tar: 0.040292 
l0: 0.048945, l1: 0.044031, l2: 0.059455, l3: 0.068491, l4: 0.074277, l5: 0.082963, l6: 0.086523

[epoch:  47/100000, batch:    38/  187, ite: 4343] train loss: 0.363480, tar: 0.040317 
l0: 0.023498, l1: 0.023889, l2: 0.020141, l3: 0.023100, l4: 0.043957, l5: 0.050833, l6: 0.057771

[epoch:  47/100000, batch:    40/  187, ite: 4344] train loss: 0.363131, tar: 0.040268 
l0: 0.028413, l1: 0.028893, l2: 0.029990, l3: 0.031921, l4: 0.047971, l5: 0.050251, l6: 0.057102

[epoch:  47/100000, batch:    42/  187, ite: 4345] train loss: 0.362874, tar: 0.040234 
l0: 0.023750, l1: 0.027072, l2: 0.026498, l3: 0.026507, l4: 0.039881, l5: 0.044412, l6: 0.046474

[epoch:  47/100000, batch:    44/  187, ite: 4346] train loss: 0.362503, tar: 0.040186 
l0: 0.057207, l1: 0.074627, l2: 0.028333, l3: 0.026176, l4: 0.050853, l5: 0.050322, l6: 0.040248

[epoch:  47/100000, batch:    46/  187, ite: 4347] train loss: 0.362403, tar: 0.040235 
l0: 0.018743, l1: 0.019054, l2: 0.026309, l3: 0.028286, l4: 0.047738, l5: 0.042526, l6: 0.041457

[epoch:  47/100000, batch:    48/  187, ite: 4348] train loss: 0.362006, tar: 0.040173 
l0: 0.026725, l1: 0.024751, l2: 0.041894, l3: 0.034061, l4: 0.049433, l5: 0.043753, l6: 0.048581

[epoch:  47/100000, batch:    50/  187, ite: 4349] train loss: 0.361740, tar: 0.040135 
l0: 0.121385, l1: 0.131533, l2: 0.149395, l3: 0.146613, l4: 0.144787, l5: 0.123139, l6: 0.095126

[epoch:  47/100000, batch:    52/  187, ite: 4350] train loss: 0.363312, tar: 0.040367 
l0: 0.020115, l1: 0.019565, l2: 0.023139, l3: 0.025358, l4: 0.034668, l5: 0.030568, l6: 0.029908

[epoch:  47/100000, batch:    54/  187, ite: 4351] train loss: 0.362799, tar: 0.040309 
l0: 0.027705, l1: 0.028090, l2: 0.031008, l3: 0.031896, l4: 0.056016, l5: 0.054390, l6: 0.051622

[epoch:  47/100000, batch:    56/  187, ite: 4352] train loss: 0.362566, tar: 0.040274 
l0: 0.032646, l1: 0.030789, l2: 0.042917, l3: 0.041105, l4: 0.057182, l5: 0.062404, l6: 0.066917

[epoch:  47/100000, batch:    58/  187, ite: 4353] train loss: 0.362485, tar: 0.040252 
l0: 0.048131, l1: 0.046332, l2: 0.061629, l3: 0.058253, l4: 0.070724, l5: 0.070509, l6: 0.078328

[epoch:  47/100000, batch:    60/  187, ite: 4354] train loss: 0.362687, tar: 0.040274 
l0: 0.019252, l1: 0.020079, l2: 0.019166, l3: 0.023796, l4: 0.034784, l5: 0.041984, l6: 0.041642

[epoch:  47/100000, batch:    62/  187, ite: 4355] train loss: 0.362230, tar: 0.040215 
l0: 0.041320, l1: 0.039707, l2: 0.044350, l3: 0.048321, l4: 0.046144, l5: 0.058828, l6: 0.067401

[epoch:  47/100000, batch:    64/  187, ite: 4356] train loss: 0.362185, tar: 0.040218 
l0: 0.025798, l1: 0.024857, l2: 0.026115, l3: 0.027995, l4: 0.041630, l5: 0.040891, l6: 0.048007

[epoch:  47/100000, batch:    66/  187, ite: 4357] train loss: 0.361829, tar: 0.040178 
l0: 0.040528, l1: 0.039875, l2: 0.045728, l3: 0.047446, l4: 0.053980, l5: 0.055647, l6: 0.057259

[epoch:  47/100000, batch:    68/  187, ite: 4358] train loss: 0.361770, tar: 0.040179 
l0: 0.018647, l1: 0.020348, l2: 0.018967, l3: 0.023783, l4: 0.034310, l5: 0.029499, l6: 0.024396

[epoch:  47/100000, batch:    70/  187, ite: 4359] train loss: 0.361235, tar: 0.040119 
l0: 0.035057, l1: 0.035489, l2: 0.032664, l3: 0.036138, l4: 0.043343, l5: 0.046963, l6: 0.043591

[epoch:  47/100000, batch:    72/  187, ite: 4360] train loss: 0.360991, tar: 0.040105 
l0: 0.049741, l1: 0.050637, l2: 0.062396, l3: 0.060516, l4: 0.073834, l5: 0.065312, l6: 0.067797

[epoch:  47/100000, batch:    74/  187, ite: 4361] train loss: 0.361183, tar: 0.040131 
l0: 0.036002, l1: 0.032710, l2: 0.050239, l3: 0.051836, l4: 0.071276, l5: 0.060560, l6: 0.068203

[epoch:  47/100000, batch:    76/  187, ite: 4362] train loss: 0.361209, tar: 0.040120 
l0: 0.032022, l1: 0.030945, l2: 0.040059, l3: 0.050274, l4: 0.064390, l5: 0.054539, l6: 0.066266

[epoch:  47/100000, batch:    78/  187, ite: 4363] train loss: 0.361147, tar: 0.040098 
l0: 0.036911, l1: 0.034781, l2: 0.047841, l3: 0.041024, l4: 0.053506, l5: 0.060094, l6: 0.061390

[epoch:  47/100000, batch:    80/  187, ite: 4364] train loss: 0.361077, tar: 0.040089 
l0: 0.042488, l1: 0.046604, l2: 0.046651, l3: 0.042958, l4: 0.076094, l5: 0.075776, l6: 0.076871

[epoch:  47/100000, batch:    82/  187, ite: 4365] train loss: 0.361204, tar: 0.040095 
l0: 0.025695, l1: 0.023946, l2: 0.030836, l3: 0.036104, l4: 0.063922, l5: 0.074764, l6: 0.077309

[epoch:  47/100000, batch:    84/  187, ite: 4366] train loss: 0.361125, tar: 0.040056 
l0: 0.036863, l1: 0.037656, l2: 0.037684, l3: 0.038125, l4: 0.065531, l5: 0.054623, l6: 0.055274

[epoch:  47/100000, batch:    86/  187, ite: 4367] train loss: 0.361029, tar: 0.040047 
l0: 0.027621, l1: 0.033794, l2: 0.031648, l3: 0.028126, l4: 0.023555, l5: 0.028530, l6: 0.026921

[epoch:  47/100000, batch:    88/  187, ite: 4368] train loss: 0.360592, tar: 0.040014 
l0: 0.066361, l1: 0.074218, l2: 0.054515, l3: 0.061389, l4: 0.086927, l5: 0.091446, l6: 0.086778

[epoch:  47/100000, batch:    90/  187, ite: 4369] train loss: 0.361028, tar: 0.040085 
l0: 0.060552, l1: 0.062641, l2: 0.052203, l3: 0.070555, l4: 0.064913, l5: 0.050205, l6: 0.061624

[epoch:  47/100000, batch:    92/  187, ite: 4370] train loss: 0.361195, tar: 0.040140 
l0: 0.030635, l1: 0.030408, l2: 0.034322, l3: 0.038279, l4: 0.046060, l5: 0.044932, l6: 0.046176

[epoch:  47/100000, batch:    94/  187, ite: 4371] train loss: 0.360951, tar: 0.040115 
l0: 0.030543, l1: 0.027754, l2: 0.036034, l3: 0.042357, l4: 0.053205, l5: 0.059257, l6: 0.056964

[epoch:  47/100000, batch:    96/  187, ite: 4372] train loss: 0.360804, tar: 0.040089 
l0: 0.026865, l1: 0.029163, l2: 0.032922, l3: 0.029345, l4: 0.048994, l5: 0.051727, l6: 0.043023

[epoch:  47/100000, batch:    98/  187, ite: 4373] train loss: 0.360539, tar: 0.040054 
l0: 0.037700, l1: 0.038395, l2: 0.036032, l3: 0.046483, l4: 0.069596, l5: 0.055565, l6: 0.063932

[epoch:  47/100000, batch:   100/  187, ite: 4374] train loss: 0.360505, tar: 0.040047 
l0: 0.026014, l1: 0.025264, l2: 0.030344, l3: 0.029271, l4: 0.056877, l5: 0.055528, l6: 0.044598

[epoch:  47/100000, batch:   102/  187, ite: 4375] train loss: 0.360258, tar: 0.040010 
l0: 0.033688, l1: 0.038686, l2: 0.032857, l3: 0.032292, l4: 0.041225, l5: 0.047116, l6: 0.046590

[epoch:  47/100000, batch:   104/  187, ite: 4376] train loss: 0.360024, tar: 0.039993 
l0: 0.043680, l1: 0.053207, l2: 0.044679, l3: 0.046626, l4: 0.053112, l5: 0.052522, l6: 0.044856

[epoch:  47/100000, batch:   106/  187, ite: 4377] train loss: 0.359968, tar: 0.040003 
l0: 0.027367, l1: 0.027295, l2: 0.031015, l3: 0.039703, l4: 0.040808, l5: 0.037970, l6: 0.036285

[epoch:  47/100000, batch:   108/  187, ite: 4378] train loss: 0.359652, tar: 0.039969 
l0: 0.045455, l1: 0.043692, l2: 0.070175, l3: 0.068119, l4: 0.072407, l5: 0.068799, l6: 0.086305

[epoch:  47/100000, batch:   110/  187, ite: 4379] train loss: 0.359903, tar: 0.039984 
l0: 0.026651, l1: 0.025817, l2: 0.028711, l3: 0.028788, l4: 0.034918, l5: 0.039149, l6: 0.042461

[epoch:  47/100000, batch:   112/  187, ite: 4380] train loss: 0.359552, tar: 0.039949 
l0: 0.022691, l1: 0.020906, l2: 0.026065, l3: 0.033342, l4: 0.048805, l5: 0.055299, l6: 0.048149

[epoch:  47/100000, batch:   114/  187, ite: 4381] train loss: 0.359278, tar: 0.039903 
l0: 0.058509, l1: 0.074096, l2: 0.065482, l3: 0.051751, l4: 0.045142, l5: 0.052244, l6: 0.059524

[epoch:  47/100000, batch:   116/  187, ite: 4382] train loss: 0.359402, tar: 0.039952 
l0: 0.034328, l1: 0.033201, l2: 0.047681, l3: 0.040675, l4: 0.048485, l5: 0.057130, l6: 0.049512

[epoch:  47/100000, batch:   118/  187, ite: 4383] train loss: 0.359276, tar: 0.039937 
l0: 0.020781, l1: 0.020712, l2: 0.023653, l3: 0.024237, l4: 0.041294, l5: 0.050683, l6: 0.053962

[epoch:  47/100000, batch:   120/  187, ite: 4384] train loss: 0.358953, tar: 0.039888 
l0: 0.022292, l1: 0.020331, l2: 0.031175, l3: 0.039486, l4: 0.043169, l5: 0.053386, l6: 0.052065

[epoch:  47/100000, batch:   122/  187, ite: 4385] train loss: 0.358701, tar: 0.039842 
l0: 0.031473, l1: 0.035776, l2: 0.040600, l3: 0.035745, l4: 0.042250, l5: 0.039552, l6: 0.057576

[epoch:  47/100000, batch:   124/  187, ite: 4386] train loss: 0.358505, tar: 0.039820 
l0: 0.047549, l1: 0.046852, l2: 0.046489, l3: 0.046163, l4: 0.058640, l5: 0.071143, l6: 0.072512

[epoch:  47/100000, batch:   126/  187, ite: 4387] train loss: 0.358585, tar: 0.039840 
l0: 0.017088, l1: 0.018069, l2: 0.028107, l3: 0.024874, l4: 0.027911, l5: 0.036327, l6: 0.027077

[epoch:  47/100000, batch:   128/  187, ite: 4388] train loss: 0.358123, tar: 0.039782 
l0: 0.040362, l1: 0.037551, l2: 0.042520, l3: 0.047941, l4: 0.075579, l5: 0.078434, l6: 0.068250

[epoch:  47/100000, batch:   130/  187, ite: 4389] train loss: 0.358207, tar: 0.039783 
l0: 0.070494, l1: 0.079361, l2: 0.075017, l3: 0.063212, l4: 0.070281, l5: 0.067693, l6: 0.058886

[epoch:  47/100000, batch:   132/  187, ite: 4390] train loss: 0.358532, tar: 0.039862 
l0: 0.053745, l1: 0.057844, l2: 0.062218, l3: 0.060860, l4: 0.064832, l5: 0.055076, l6: 0.058534

[epoch:  47/100000, batch:   134/  187, ite: 4391] train loss: 0.358671, tar: 0.039897 
l0: 0.035439, l1: 0.038713, l2: 0.038388, l3: 0.032960, l4: 0.035633, l5: 0.038406, l6: 0.038914

[epoch:  47/100000, batch:   136/  187, ite: 4392] train loss: 0.358416, tar: 0.039886 
l0: 0.048545, l1: 0.047088, l2: 0.062506, l3: 0.051661, l4: 0.072201, l5: 0.079248, l6: 0.076311

[epoch:  47/100000, batch:   138/  187, ite: 4393] train loss: 0.358617, tar: 0.039908 
l0: 0.029597, l1: 0.025516, l2: 0.040492, l3: 0.045983, l4: 0.059356, l5: 0.068772, l6: 0.062343

[epoch:  47/100000, batch:   140/  187, ite: 4394] train loss: 0.358550, tar: 0.039882 
l0: 0.023679, l1: 0.021674, l2: 0.026891, l3: 0.029224, l4: 0.050524, l5: 0.046042, l6: 0.047100

[epoch:  47/100000, batch:   142/  187, ite: 4395] train loss: 0.358262, tar: 0.039841 
l0: 0.135189, l1: 0.156518, l2: 0.166530, l3: 0.150778, l4: 0.163466, l5: 0.115852, l6: 0.104265

[epoch:  47/100000, batch:   144/  187, ite: 4396] train loss: 0.359864, tar: 0.040082 
l0: 0.059855, l1: 0.065888, l2: 0.062512, l3: 0.067247, l4: 0.060120, l5: 0.061669, l6: 0.068674

[epoch:  47/100000, batch:   146/  187, ite: 4397] train loss: 0.360081, tar: 0.040131 
l0: 0.061135, l1: 0.063698, l2: 0.083511, l3: 0.087971, l4: 0.064925, l5: 0.077257, l6: 0.051207

[epoch:  47/100000, batch:   148/  187, ite: 4398] train loss: 0.360407, tar: 0.040184 
l0: 0.036196, l1: 0.033504, l2: 0.046074, l3: 0.048884, l4: 0.044953, l5: 0.062097, l6: 0.049956

[epoch:  47/100000, batch:   150/  187, ite: 4399] train loss: 0.360310, tar: 0.040174 
l0: 0.037173, l1: 0.038077, l2: 0.039595, l3: 0.041048, l4: 0.043174, l5: 0.044525, l6: 0.038447

[epoch:  47/100000, batch:   152/  187, ite: 4400] train loss: 0.360114, tar: 0.040167 
l0: 0.041819, l1: 0.035947, l2: 0.055324, l3: 0.056384, l4: 0.087272, l5: 0.111284, l6: 0.104116

[epoch:  47/100000, batch:   154/  187, ite: 4401] train loss: 0.360443, tar: 0.040171 
l0: 0.061769, l1: 0.069646, l2: 0.074643, l3: 0.078942, l4: 0.055564, l5: 0.065765, l6: 0.052515

[epoch:  47/100000, batch:   156/  187, ite: 4402] train loss: 0.360688, tar: 0.040224 
l0: 0.042945, l1: 0.047525, l2: 0.049277, l3: 0.043555, l4: 0.112695, l5: 0.123919, l6: 0.153666

[epoch:  47/100000, batch:   158/  187, ite: 4403] train loss: 0.361216, tar: 0.040231 
l0: 0.053400, l1: 0.055516, l2: 0.060735, l3: 0.056586, l4: 0.098933, l5: 0.082365, l6: 0.093821

[epoch:  47/100000, batch:   160/  187, ite: 4404] train loss: 0.361563, tar: 0.040264 
l0: 0.032246, l1: 0.028723, l2: 0.039876, l3: 0.050221, l4: 0.062288, l5: 0.068472, l6: 0.064056

[epoch:  47/100000, batch:   162/  187, ite: 4405] train loss: 0.361525, tar: 0.040244 
l0: 0.019624, l1: 0.022292, l2: 0.026859, l3: 0.027988, l4: 0.039205, l5: 0.032945, l6: 0.041042

[epoch:  47/100000, batch:   164/  187, ite: 4406] train loss: 0.361151, tar: 0.040193 
l0: 0.030052, l1: 0.031450, l2: 0.035542, l3: 0.035337, l4: 0.065160, l5: 0.071975, l6: 0.071184

[epoch:  47/100000, batch:   166/  187, ite: 4407] train loss: 0.361101, tar: 0.040168 
l0: 0.051306, l1: 0.043827, l2: 0.065311, l3: 0.074656, l4: 0.067786, l5: 0.086196, l6: 0.077349

[epoch:  47/100000, batch:   168/  187, ite: 4408] train loss: 0.361359, tar: 0.040196 
l0: 0.038653, l1: 0.039263, l2: 0.056268, l3: 0.060681, l4: 0.046248, l5: 0.043378, l6: 0.047505

[epoch:  47/100000, batch:   170/  187, ite: 4409] train loss: 0.361287, tar: 0.040192 
l0: 0.028564, l1: 0.026148, l2: 0.031558, l3: 0.034392, l4: 0.052740, l5: 0.065937, l6: 0.061681

[epoch:  47/100000, batch:   172/  187, ite: 4410] train loss: 0.361140, tar: 0.040163 
l0: 0.036093, l1: 0.035244, l2: 0.066801, l3: 0.074292, l4: 0.051303, l5: 0.052627, l6: 0.041572

[epoch:  47/100000, batch:   174/  187, ite: 4411] train loss: 0.361133, tar: 0.040154 
l0: 0.049313, l1: 0.054110, l2: 0.042522, l3: 0.050126, l4: 0.066284, l5: 0.068560, l6: 0.061097

[epoch:  47/100000, batch:   176/  187, ite: 4412] train loss: 0.361207, tar: 0.040176 
l0: 0.036471, l1: 0.033825, l2: 0.056190, l3: 0.053334, l4: 0.074319, l5: 0.062617, l6: 0.064818

[epoch:  47/100000, batch:   178/  187, ite: 4413] train loss: 0.361257, tar: 0.040167 
l0: 0.055985, l1: 0.054015, l2: 0.064895, l3: 0.061728, l4: 0.074398, l5: 0.096251, l6: 0.101229

[epoch:  47/100000, batch:   180/  187, ite: 4414] train loss: 0.361612, tar: 0.040205 
l0: 0.037287, l1: 0.034411, l2: 0.050870, l3: 0.060973, l4: 0.067536, l5: 0.059400, l6: 0.048371

[epoch:  47/100000, batch:   182/  187, ite: 4415] train loss: 0.361606, tar: 0.040198 
l0: 0.045051, l1: 0.048664, l2: 0.045192, l3: 0.046964, l4: 0.052787, l5: 0.049683, l6: 0.056250

[epoch:  47/100000, batch:   184/  187, ite: 4416] train loss: 0.361565, tar: 0.040210 
l0: 0.045466, l1: 0.053694, l2: 0.044508, l3: 0.038727, l4: 0.040421, l5: 0.052328, l6: 0.040749

[epoch:  47/100000, batch:   186/  187, ite: 4417] train loss: 0.361455, tar: 0.040222 
l0: 0.017724, l1: 0.017238, l2: 0.036358, l3: 0.038486, l4: 0.041418, l5: 0.034976, l6: 0.030894

[epoch:  47/100000, batch:   188/  187, ite: 4418] train loss: 0.361110, tar: 0.040168 
l0: 0.029216, l1: 0.030771, l2: 0.031518, l3: 0.030606, l4: 0.056223, l5: 0.050059, l6: 0.043660

[epoch:  48/100000, batch:     2/  187, ite: 4419] train loss: 0.360897, tar: 0.040142 
l0: 0.039782, l1: 0.037583, l2: 0.057268, l3: 0.058973, l4: 0.052397, l5: 0.054827, l6: 0.051102

[epoch:  48/100000, batch:     4/  187, ite: 4420] train loss: 0.360876, tar: 0.040141 
l0: 0.035373, l1: 0.037539, l2: 0.029938, l3: 0.035485, l4: 0.047825, l5: 0.046673, l6: 0.050916

[epoch:  48/100000, batch:     6/  187, ite: 4421] train loss: 0.360693, tar: 0.040130 
l0: 0.023871, l1: 0.028963, l2: 0.019406, l3: 0.021350, l4: 0.033567, l5: 0.038399, l6: 0.046861

[epoch:  48/100000, batch:     8/  187, ite: 4422] train loss: 0.360342, tar: 0.040092 
l0: 0.021717, l1: 0.026061, l2: 0.024279, l3: 0.026448, l4: 0.033178, l5: 0.036143, l6: 0.041106

[epoch:  48/100000, batch:    10/  187, ite: 4423] train loss: 0.359984, tar: 0.040048 
l0: 0.024951, l1: 0.024631, l2: 0.040239, l3: 0.035665, l4: 0.046588, l5: 0.051364, l6: 0.050971

[epoch:  48/100000, batch:    12/  187, ite: 4424] train loss: 0.359782, tar: 0.040013 
l0: 0.053108, l1: 0.050153, l2: 0.063450, l3: 0.060984, l4: 0.080867, l5: 0.075626, l6: 0.082909

[epoch:  48/100000, batch:    14/  187, ite: 4425] train loss: 0.360034, tar: 0.040043 
l0: 0.054293, l1: 0.040603, l2: 0.082382, l3: 0.082208, l4: 0.165433, l5: 0.168367, l6: 0.147761

[epoch:  48/100000, batch:    16/  187, ite: 4426] train loss: 0.360929, tar: 0.040077 
l0: 0.015435, l1: 0.014267, l2: 0.026676, l3: 0.029335, l4: 0.028289, l5: 0.031948, l6: 0.045633

[epoch:  48/100000, batch:    18/  187, ite: 4427] train loss: 0.360532, tar: 0.040019 
l0: 0.027024, l1: 0.023569, l2: 0.030298, l3: 0.034249, l4: 0.053064, l5: 0.061242, l6: 0.069204

[epoch:  48/100000, batch:    20/  187, ite: 4428] train loss: 0.360387, tar: 0.039989 
l0: 0.017623, l1: 0.019410, l2: 0.021102, l3: 0.020984, l4: 0.032362, l5: 0.029850, l6: 0.030883

[epoch:  48/100000, batch:    22/  187, ite: 4429] train loss: 0.359949, tar: 0.039937 
l0: 0.017823, l1: 0.018106, l2: 0.019887, l3: 0.019076, l4: 0.037271, l5: 0.036659, l6: 0.034144

[epoch:  48/100000, batch:    24/  187, ite: 4430] train loss: 0.359537, tar: 0.039885 
l0: 0.038052, l1: 0.037866, l2: 0.033812, l3: 0.039943, l4: 0.059840, l5: 0.060553, l6: 0.055667

[epoch:  48/100000, batch:    26/  187, ite: 4431] train loss: 0.359459, tar: 0.039881 
l0: 0.060605, l1: 0.064011, l2: 0.063710, l3: 0.057059, l4: 0.078543, l5: 0.084459, l6: 0.113273

[epoch:  48/100000, batch:    28/  187, ite: 4432] train loss: 0.359834, tar: 0.039929 
l0: 0.028595, l1: 0.028442, l2: 0.029713, l3: 0.033359, l4: 0.049085, l5: 0.044534, l6: 0.054876

[epoch:  48/100000, batch:    30/  187, ite: 4433] train loss: 0.359624, tar: 0.039903 
l0: 0.036106, l1: 0.034705, l2: 0.045040, l3: 0.045098, l4: 0.052916, l5: 0.054056, l6: 0.075358

[epoch:  48/100000, batch:    32/  187, ite: 4434] train loss: 0.359586, tar: 0.039894 
l0: 0.053190, l1: 0.069268, l2: 0.045479, l3: 0.038978, l4: 0.053098, l5: 0.062558, l6: 0.087453

[epoch:  48/100000, batch:    34/  187, ite: 4435] train loss: 0.359702, tar: 0.039925 
l0: 0.029098, l1: 0.031086, l2: 0.029957, l3: 0.031590, l4: 0.034919, l5: 0.035219, l6: 0.045368

[epoch:  48/100000, batch:    36/  187, ite: 4436] train loss: 0.359421, tar: 0.039900 
l0: 0.032463, l1: 0.040847, l2: 0.042934, l3: 0.032464, l4: 0.035922, l5: 0.041022, l6: 0.036929

[epoch:  48/100000, batch:    38/  187, ite: 4437] train loss: 0.359199, tar: 0.039883 
l0: 0.029985, l1: 0.024580, l2: 0.055122, l3: 0.062322, l4: 0.066785, l5: 0.058529, l6: 0.056003

[epoch:  48/100000, batch:    40/  187, ite: 4438] train loss: 0.359186, tar: 0.039860 
l0: 0.037616, l1: 0.039649, l2: 0.038024, l3: 0.037261, l4: 0.048453, l5: 0.049134, l6: 0.049635

[epoch:  48/100000, batch:    42/  187, ite: 4439] train loss: 0.359051, tar: 0.039855 
l0: 0.055039, l1: 0.062840, l2: 0.040396, l3: 0.051807, l4: 0.087965, l5: 0.066082, l6: 0.069379

[epoch:  48/100000, batch:    44/  187, ite: 4440] train loss: 0.359220, tar: 0.039889 
l0: 0.042959, l1: 0.047291, l2: 0.045059, l3: 0.045769, l4: 0.074932, l5: 0.084307, l6: 0.076780

[epoch:  48/100000, batch:    46/  187, ite: 4441] train loss: 0.359351, tar: 0.039896 
l0: 0.040031, l1: 0.041161, l2: 0.060171, l3: 0.061938, l4: 0.056173, l5: 0.058155, l6: 0.058547

[epoch:  48/100000, batch:    48/  187, ite: 4442] train loss: 0.359389, tar: 0.039897 
l0: 0.072946, l1: 0.070875, l2: 0.088464, l3: 0.078748, l4: 0.081287, l5: 0.086069, l6: 0.106051

[epoch:  48/100000, batch:    50/  187, ite: 4443] train loss: 0.359897, tar: 0.039971 
l0: 0.034510, l1: 0.036650, l2: 0.028890, l3: 0.033966, l4: 0.046117, l5: 0.056409, l6: 0.054211

[epoch:  48/100000, batch:    52/  187, ite: 4444] train loss: 0.359741, tar: 0.039959 
l0: 0.027931, l1: 0.021693, l2: 0.033529, l3: 0.039587, l4: 0.061649, l5: 0.068747, l6: 0.075403

[epoch:  48/100000, batch:    54/  187, ite: 4445] train loss: 0.359671, tar: 0.039932 
l0: 0.030438, l1: 0.030126, l2: 0.034544, l3: 0.035209, l4: 0.046731, l5: 0.047398, l6: 0.051228

[epoch:  48/100000, batch:    56/  187, ite: 4446] train loss: 0.359483, tar: 0.039911 
l0: 0.076703, l1: 0.080144, l2: 0.084645, l3: 0.079977, l4: 0.085095, l5: 0.079052, l6: 0.090872

[epoch:  48/100000, batch:    58/  187, ite: 4447] train loss: 0.359968, tar: 0.039993 
l0: 0.027139, l1: 0.026806, l2: 0.038314, l3: 0.043422, l4: 0.051807, l5: 0.047602, l6: 0.043963

[epoch:  48/100000, batch:    60/  187, ite: 4448] train loss: 0.359788, tar: 0.039964 
l0: 0.028318, l1: 0.028972, l2: 0.036987, l3: 0.038298, l4: 0.038459, l5: 0.039553, l6: 0.038898

[epoch:  48/100000, batch:    62/  187, ite: 4449] train loss: 0.359542, tar: 0.039938 
l0: 0.011937, l1: 0.011535, l2: 0.019319, l3: 0.021026, l4: 0.028424, l5: 0.027201, l6: 0.030058

[epoch:  48/100000, batch:    64/  187, ite: 4450] train loss: 0.359075, tar: 0.039876 
l0: 0.047919, l1: 0.049357, l2: 0.053337, l3: 0.056444, l4: 0.050106, l5: 0.048979, l6: 0.049130

[epoch:  48/100000, batch:    66/  187, ite: 4451] train loss: 0.359067, tar: 0.039894 
l0: 0.027785, l1: 0.026040, l2: 0.041778, l3: 0.039869, l4: 0.045315, l5: 0.058126, l6: 0.052878

[epoch:  48/100000, batch:    68/  187, ite: 4452] train loss: 0.358918, tar: 0.039867 
l0: 0.042095, l1: 0.041466, l2: 0.062575, l3: 0.069883, l4: 0.056573, l5: 0.054162, l6: 0.049021

[epoch:  48/100000, batch:    70/  187, ite: 4453] train loss: 0.358955, tar: 0.039872 
l0: 0.038711, l1: 0.032797, l2: 0.052456, l3: 0.059298, l4: 0.092926, l5: 0.097384, l6: 0.090040

[epoch:  48/100000, batch:    72/  187, ite: 4454] train loss: 0.359186, tar: 0.039870 
l0: 0.021806, l1: 0.024342, l2: 0.023845, l3: 0.026661, l4: 0.029959, l5: 0.035352, l6: 0.037311

[epoch:  48/100000, batch:    74/  187, ite: 4455] train loss: 0.358834, tar: 0.039830 
l0: 0.036500, l1: 0.037662, l2: 0.035145, l3: 0.041601, l4: 0.050870, l5: 0.044403, l6: 0.047816

[epoch:  48/100000, batch:    76/  187, ite: 4456] train loss: 0.358692, tar: 0.039823 
l0: 0.039625, l1: 0.044356, l2: 0.057502, l3: 0.054378, l4: 0.046678, l5: 0.045126, l6: 0.040354

[epoch:  48/100000, batch:    78/  187, ite: 4457] train loss: 0.358625, tar: 0.039822 
l0: 0.024955, l1: 0.026040, l2: 0.035968, l3: 0.032239, l4: 0.044414, l5: 0.045858, l6: 0.040362

[epoch:  48/100000, batch:    80/  187, ite: 4458] train loss: 0.358388, tar: 0.039790 
l0: 0.034023, l1: 0.033721, l2: 0.034388, l3: 0.034241, l4: 0.078728, l5: 0.087833, l6: 0.067492

[epoch:  48/100000, batch:    82/  187, ite: 4459] train loss: 0.358414, tar: 0.039777 
l0: 0.050774, l1: 0.059297, l2: 0.037837, l3: 0.036353, l4: 0.052055, l5: 0.057414, l6: 0.059900

[epoch:  48/100000, batch:    84/  187, ite: 4460] train loss: 0.358403, tar: 0.039801 
l0: 0.034121, l1: 0.039250, l2: 0.034699, l3: 0.033687, l4: 0.036111, l5: 0.039759, l6: 0.044676

[epoch:  48/100000, batch:    86/  187, ite: 4461] train loss: 0.358195, tar: 0.039789 
l0: 0.035185, l1: 0.036849, l2: 0.041092, l3: 0.045025, l4: 0.061792, l5: 0.055113, l6: 0.055929

[epoch:  48/100000, batch:    88/  187, ite: 4462] train loss: 0.358136, tar: 0.039779 
l0: 0.024629, l1: 0.022179, l2: 0.031263, l3: 0.035622, l4: 0.034154, l5: 0.040070, l6: 0.044420

[epoch:  48/100000, batch:    90/  187, ite: 4463] train loss: 0.357864, tar: 0.039746 
l0: 0.030420, l1: 0.028821, l2: 0.033466, l3: 0.036350, l4: 0.048562, l5: 0.051441, l6: 0.056388

[epoch:  48/100000, batch:    92/  187, ite: 4464] train loss: 0.357708, tar: 0.039726 
l0: 0.045901, l1: 0.040614, l2: 0.072039, l3: 0.076532, l4: 0.086464, l5: 0.081940, l6: 0.052188

[epoch:  48/100000, batch:    94/  187, ite: 4465] train loss: 0.357919, tar: 0.039739 
l0: 0.042087, l1: 0.041676, l2: 0.040044, l3: 0.041998, l4: 0.043460, l5: 0.052879, l6: 0.062126

[epoch:  48/100000, batch:    96/  187, ite: 4466] train loss: 0.357847, tar: 0.039744 
l0: 0.054062, l1: 0.056108, l2: 0.062253, l3: 0.061661, l4: 0.062617, l5: 0.057805, l6: 0.047113

[epoch:  48/100000, batch:    98/  187, ite: 4467] train loss: 0.357941, tar: 0.039775 
l0: 0.035407, l1: 0.035232, l2: 0.035216, l3: 0.039017, l4: 0.046903, l5: 0.053010, l6: 0.048244

[epoch:  48/100000, batch:   100/  187, ite: 4468] train loss: 0.357802, tar: 0.039766 
l0: 0.030075, l1: 0.035498, l2: 0.033457, l3: 0.032723, l4: 0.032977, l5: 0.032335, l6: 0.025748

[epoch:  48/100000, batch:   102/  187, ite: 4469] train loss: 0.357514, tar: 0.039745 
l0: 0.035211, l1: 0.034440, l2: 0.039381, l3: 0.040281, l4: 0.040738, l5: 0.053252, l6: 0.052971

[epoch:  48/100000, batch:   104/  187, ite: 4470] train loss: 0.357384, tar: 0.039735 
l0: 0.033379, l1: 0.037951, l2: 0.031480, l3: 0.039214, l4: 0.054481, l5: 0.049588, l6: 0.042478

[epoch:  48/100000, batch:   106/  187, ite: 4471] train loss: 0.357238, tar: 0.039722 
l0: 0.030066, l1: 0.028002, l2: 0.046943, l3: 0.049581, l4: 0.063942, l5: 0.057183, l6: 0.059486

[epoch:  48/100000, batch:   108/  187, ite: 4472] train loss: 0.357191, tar: 0.039701 
l0: 0.027260, l1: 0.028104, l2: 0.027977, l3: 0.032203, l4: 0.045560, l5: 0.056565, l6: 0.048563

[epoch:  48/100000, batch:   110/  187, ite: 4473] train loss: 0.356999, tar: 0.039675 
l0: 0.038616, l1: 0.043906, l2: 0.042591, l3: 0.046887, l4: 0.035480, l5: 0.039995, l6: 0.036756

[epoch:  48/100000, batch:   112/  187, ite: 4474] train loss: 0.356845, tar: 0.039673 
l0: 0.031104, l1: 0.028199, l2: 0.036497, l3: 0.039546, l4: 0.052344, l5: 0.061054, l6: 0.067450

[epoch:  48/100000, batch:   114/  187, ite: 4475] train loss: 0.356760, tar: 0.039655 
l0: 0.022970, l1: 0.022584, l2: 0.027021, l3: 0.031379, l4: 0.048571, l5: 0.048865, l6: 0.042602

[epoch:  48/100000, batch:   116/  187, ite: 4476] train loss: 0.356523, tar: 0.039620 
l0: 0.031477, l1: 0.031755, l2: 0.041116, l3: 0.035213, l4: 0.036475, l5: 0.042106, l6: 0.035577

[epoch:  48/100000, batch:   118/  187, ite: 4477] train loss: 0.356307, tar: 0.039603 
l0: 0.048858, l1: 0.047166, l2: 0.063086, l3: 0.066570, l4: 0.081381, l5: 0.080116, l6: 0.084697

[epoch:  48/100000, batch:   120/  187, ite: 4478] train loss: 0.356549, tar: 0.039622 
l0: 0.027393, l1: 0.026543, l2: 0.036125, l3: 0.041121, l4: 0.037310, l5: 0.042018, l6: 0.040454

[epoch:  48/100000, batch:   122/  187, ite: 4479] train loss: 0.356328, tar: 0.039596 
l0: 0.018664, l1: 0.021668, l2: 0.018531, l3: 0.017819, l4: 0.022927, l5: 0.022237, l6: 0.024798

[epoch:  48/100000, batch:   124/  187, ite: 4480] train loss: 0.355892, tar: 0.039553 
l0: 0.024467, l1: 0.034174, l2: 0.027625, l3: 0.024107, l4: 0.039145, l5: 0.039609, l6: 0.039365

[epoch:  48/100000, batch:   126/  187, ite: 4481] train loss: 0.355627, tar: 0.039521 
l0: 0.038786, l1: 0.044957, l2: 0.051648, l3: 0.035524, l4: 0.039016, l5: 0.039611, l6: 0.036947

[epoch:  48/100000, batch:   128/  187, ite: 4482] train loss: 0.355483, tar: 0.039520 
l0: 0.045305, l1: 0.048631, l2: 0.046760, l3: 0.048099, l4: 0.066988, l5: 0.063971, l6: 0.075049

[epoch:  48/100000, batch:   130/  187, ite: 4483] train loss: 0.355565, tar: 0.039532 
l0: 0.046447, l1: 0.044089, l2: 0.065688, l3: 0.055697, l4: 0.051812, l5: 0.066020, l6: 0.078773

[epoch:  48/100000, batch:   132/  187, ite: 4484] train loss: 0.355674, tar: 0.039546 
l0: 0.024504, l1: 0.023918, l2: 0.026848, l3: 0.026686, l4: 0.047851, l5: 0.056712, l6: 0.047514

[epoch:  48/100000, batch:   134/  187, ite: 4485] train loss: 0.355465, tar: 0.039515 
l0: 0.029422, l1: 0.027322, l2: 0.038937, l3: 0.038730, l4: 0.045253, l5: 0.040223, l6: 0.041550

[epoch:  48/100000, batch:   136/  187, ite: 4486] train loss: 0.355271, tar: 0.039494 
l0: 0.041766, l1: 0.042945, l2: 0.050114, l3: 0.046180, l4: 0.064060, l5: 0.056778, l6: 0.046982

[epoch:  48/100000, batch:   138/  187, ite: 4487] train loss: 0.355258, tar: 0.039499 
l0: 0.032977, l1: 0.031766, l2: 0.032461, l3: 0.035099, l4: 0.054913, l5: 0.059620, l6: 0.061103

[epoch:  48/100000, batch:   140/  187, ite: 4488] train loss: 0.355161, tar: 0.039486 
l0: 0.033433, l1: 0.036458, l2: 0.026963, l3: 0.033148, l4: 0.047062, l5: 0.050538, l6: 0.044914

[epoch:  48/100000, batch:   142/  187, ite: 4489] train loss: 0.354992, tar: 0.039473 
l0: 0.040243, l1: 0.043692, l2: 0.051325, l3: 0.043002, l4: 0.030363, l5: 0.029135, l6: 0.056065

[epoch:  48/100000, batch:   144/  187, ite: 4490] train loss: 0.354867, tar: 0.039475 
l0: 0.020901, l1: 0.018774, l2: 0.027564, l3: 0.029219, l4: 0.043692, l5: 0.049116, l6: 0.052751

[epoch:  48/100000, batch:   146/  187, ite: 4491] train loss: 0.354637, tar: 0.039437 
l0: 0.027256, l1: 0.033512, l2: 0.045781, l3: 0.030301, l4: 0.046010, l5: 0.043428, l6: 0.035735

[epoch:  48/100000, batch:   148/  187, ite: 4492] train loss: 0.354449, tar: 0.039412 
l0: 0.048700, l1: 0.053249, l2: 0.050654, l3: 0.046317, l4: 0.061181, l5: 0.070180, l6: 0.075508

[epoch:  48/100000, batch:   150/  187, ite: 4493] train loss: 0.354553, tar: 0.039431 
l0: 0.030432, l1: 0.029365, l2: 0.034688, l3: 0.034873, l4: 0.049560, l5: 0.046048, l6: 0.051444

[epoch:  48/100000, batch:   152/  187, ite: 4494] train loss: 0.354395, tar: 0.039413 
l0: 0.028159, l1: 0.027382, l2: 0.032456, l3: 0.036900, l4: 0.045309, l5: 0.041055, l6: 0.048319

[epoch:  48/100000, batch:   154/  187, ite: 4495] train loss: 0.354203, tar: 0.039390 
l0: 0.043958, l1: 0.046099, l2: 0.046714, l3: 0.050798, l4: 0.049355, l5: 0.049860, l6: 0.046273

[epoch:  48/100000, batch:   156/  187, ite: 4496] train loss: 0.354161, tar: 0.039399 
l0: 0.033169, l1: 0.031697, l2: 0.044175, l3: 0.044167, l4: 0.049861, l5: 0.048318, l6: 0.045127

[epoch:  48/100000, batch:   158/  187, ite: 4497] train loss: 0.354045, tar: 0.039387 
l0: 0.025499, l1: 0.026350, l2: 0.024372, l3: 0.025429, l4: 0.041861, l5: 0.036944, l6: 0.039504

[epoch:  48/100000, batch:   160/  187, ite: 4498] train loss: 0.353775, tar: 0.039359 
l0: 0.027736, l1: 0.024673, l2: 0.036345, l3: 0.036475, l4: 0.045040, l5: 0.044779, l6: 0.055226

[epoch:  48/100000, batch:   162/  187, ite: 4499] train loss: 0.353608, tar: 0.039336 
l0: 0.017760, l1: 0.016299, l2: 0.023007, l3: 0.022697, l4: 0.029789, l5: 0.030656, l6: 0.040491

[epoch:  48/100000, batch:   164/  187, ite: 4500] train loss: 0.353262, tar: 0.039293 
l0: 0.023577, l1: 0.026242, l2: 0.020448, l3: 0.024820, l4: 0.065568, l5: 0.061958, l6: 0.056447

[epoch:  48/100000, batch:   166/  187, ite: 4501] train loss: 0.353114, tar: 0.039261 
l0: 0.035246, l1: 0.030173, l2: 0.046832, l3: 0.062698, l4: 0.054691, l5: 0.050473, l6: 0.064073

[epoch:  48/100000, batch:   168/  187, ite: 4502] train loss: 0.353096, tar: 0.039253 
l0: 0.034889, l1: 0.035792, l2: 0.035547, l3: 0.039787, l4: 0.047673, l5: 0.046287, l6: 0.048675

[epoch:  48/100000, batch:   170/  187, ite: 4503] train loss: 0.352968, tar: 0.039245 
l0: 0.033449, l1: 0.027246, l2: 0.032891, l3: 0.048725, l4: 0.074379, l5: 0.081665, l6: 0.077840

[epoch:  48/100000, batch:   172/  187, ite: 4504] train loss: 0.353014, tar: 0.039233 
l0: 0.025391, l1: 0.028557, l2: 0.034251, l3: 0.035329, l4: 0.039081, l5: 0.054027, l6: 0.032468

[epoch:  48/100000, batch:   174/  187, ite: 4505] train loss: 0.352809, tar: 0.039206 
l0: 0.046536, l1: 0.050871, l2: 0.050339, l3: 0.051102, l4: 0.048032, l5: 0.048226, l6: 0.052248

[epoch:  48/100000, batch:   176/  187, ite: 4506] train loss: 0.352798, tar: 0.039220 
l0: 0.024287, l1: 0.025323, l2: 0.030794, l3: 0.031719, l4: 0.021453, l5: 0.024728, l6: 0.027450

[epoch:  48/100000, batch:   178/  187, ite: 4507] train loss: 0.352468, tar: 0.039191 
l0: 0.041072, l1: 0.033061, l2: 0.060722, l3: 0.058296, l4: 0.098182, l5: 0.097912, l6: 0.106218

[epoch:  48/100000, batch:   180/  187, ite: 4508] train loss: 0.352750, tar: 0.039194 
l0: 0.019539, l1: 0.021667, l2: 0.025699, l3: 0.024328, l4: 0.037792, l5: 0.041793, l6: 0.024483

[epoch:  48/100000, batch:   182/  187, ite: 4509] train loss: 0.352441, tar: 0.039156 
l0: 0.021741, l1: 0.019463, l2: 0.029041, l3: 0.028994, l4: 0.065706, l5: 0.061936, l6: 0.057600

[epoch:  48/100000, batch:   184/  187, ite: 4510] train loss: 0.352307, tar: 0.039122 
l0: 0.052806, l1: 0.059027, l2: 0.056069, l3: 0.068811, l4: 0.113650, l5: 0.119441, l6: 0.103944

[epoch:  48/100000, batch:   186/  187, ite: 4511] train loss: 0.352741, tar: 0.039148 
l0: 0.044104, l1: 0.045177, l2: 0.056669, l3: 0.070344, l4: 0.078642, l5: 0.093403, l6: 0.079984

[epoch:  48/100000, batch:   188/  187, ite: 4512] train loss: 0.352966, tar: 0.039158 
l0: 0.024956, l1: 0.027528, l2: 0.023594, l3: 0.022409, l4: 0.042436, l5: 0.030534, l6: 0.034581

[epoch:  49/100000, batch:     2/  187, ite: 4513] train loss: 0.352680, tar: 0.039130 
l0: 0.022901, l1: 0.024694, l2: 0.023142, l3: 0.023593, l4: 0.038238, l5: 0.037660, l6: 0.035766

[epoch:  49/100000, batch:     4/  187, ite: 4514] train loss: 0.352395, tar: 0.039099 
l0: 0.019723, l1: 0.018821, l2: 0.027376, l3: 0.027746, l4: 0.035322, l5: 0.034245, l6: 0.032477

[epoch:  49/100000, batch:     6/  187, ite: 4515] train loss: 0.352090, tar: 0.039061 
l0: 0.022951, l1: 0.020135, l2: 0.027674, l3: 0.033460, l4: 0.046847, l5: 0.048700, l6: 0.053073

[epoch:  49/100000, batch:     8/  187, ite: 4516] train loss: 0.351898, tar: 0.039030 
l0: 0.034823, l1: 0.042344, l2: 0.031422, l3: 0.028374, l4: 0.040012, l5: 0.040167, l6: 0.041125

[epoch:  49/100000, batch:    10/  187, ite: 4517] train loss: 0.351717, tar: 0.039022 
l0: 0.017427, l1: 0.020976, l2: 0.027306, l3: 0.024779, l4: 0.022022, l5: 0.018401, l6: 0.019859

[epoch:  49/100000, batch:    12/  187, ite: 4518] train loss: 0.351329, tar: 0.038980 
l0: 0.035109, l1: 0.035553, l2: 0.034877, l3: 0.038272, l4: 0.054087, l5: 0.058047, l6: 0.056503

[epoch:  49/100000, batch:    14/  187, ite: 4519] train loss: 0.351254, tar: 0.038973 
l0: 0.034101, l1: 0.032936, l2: 0.038211, l3: 0.041199, l4: 0.057213, l5: 0.056892, l6: 0.046611

[epoch:  49/100000, batch:    16/  187, ite: 4520] train loss: 0.351169, tar: 0.038963 
l0: 0.019903, l1: 0.016855, l2: 0.025978, l3: 0.031484, l4: 0.044796, l5: 0.033803, l6: 0.053061

[epoch:  49/100000, batch:    18/  187, ite: 4521] train loss: 0.350929, tar: 0.038927 
l0: 0.068110, l1: 0.068344, l2: 0.108136, l3: 0.090989, l4: 0.065767, l5: 0.053139, l6: 0.073822

[epoch:  49/100000, batch:    20/  187, ite: 4522] train loss: 0.351269, tar: 0.038983 
l0: 0.031251, l1: 0.035803, l2: 0.034342, l3: 0.032505, l4: 0.037711, l5: 0.039077, l6: 0.046255

[epoch:  49/100000, batch:    22/  187, ite: 4523] train loss: 0.351088, tar: 0.038968 
l0: 0.036466, l1: 0.036941, l2: 0.044370, l3: 0.042861, l4: 0.052447, l5: 0.054324, l6: 0.044558

[epoch:  49/100000, batch:    24/  187, ite: 4524] train loss: 0.351014, tar: 0.038963 
l0: 0.085350, l1: 0.090035, l2: 0.083844, l3: 0.076130, l4: 0.116593, l5: 0.102528, l6: 0.105188

[epoch:  49/100000, batch:    26/  187, ite: 4525] train loss: 0.351602, tar: 0.039051 
l0: 0.024894, l1: 0.023713, l2: 0.028263, l3: 0.033153, l4: 0.049596, l5: 0.045098, l6: 0.043170

[epoch:  49/100000, batch:    28/  187, ite: 4526] train loss: 0.351404, tar: 0.039024 
l0: 0.044148, l1: 0.039572, l2: 0.059412, l3: 0.069765, l4: 0.066076, l5: 0.066866, l6: 0.070835

[epoch:  49/100000, batch:    30/  187, ite: 4527] train loss: 0.351528, tar: 0.039034 
l0: 0.050421, l1: 0.047580, l2: 0.065278, l3: 0.073336, l4: 0.053714, l5: 0.059024, l6: 0.057875

[epoch:  49/100000, batch:    32/  187, ite: 4528] train loss: 0.351634, tar: 0.039056 
l0: 0.026107, l1: 0.025816, l2: 0.032350, l3: 0.032364, l4: 0.043903, l5: 0.039808, l6: 0.041833

[epoch:  49/100000, batch:    34/  187, ite: 4529] train loss: 0.351427, tar: 0.039031 
l0: 0.052410, l1: 0.050897, l2: 0.055363, l3: 0.059239, l4: 0.067819, l5: 0.069156, l6: 0.072687

[epoch:  49/100000, batch:    36/  187, ite: 4530] train loss: 0.351570, tar: 0.039057 
l0: 0.021906, l1: 0.021271, l2: 0.027874, l3: 0.039046, l4: 0.043984, l5: 0.038037, l6: 0.041458

[epoch:  49/100000, batch:    38/  187, ite: 4531] train loss: 0.351348, tar: 0.039024 
l0: 0.038868, l1: 0.038175, l2: 0.043429, l3: 0.051971, l4: 0.052747, l5: 0.052759, l6: 0.050895

[epoch:  49/100000, batch:    40/  187, ite: 4532] train loss: 0.351306, tar: 0.039024 
l0: 0.025948, l1: 0.025491, l2: 0.034337, l3: 0.034570, l4: 0.038764, l5: 0.038961, l6: 0.040354

[epoch:  49/100000, batch:    42/  187, ite: 4533] train loss: 0.351094, tar: 0.038999 
l0: 0.031783, l1: 0.030931, l2: 0.045182, l3: 0.052954, l4: 0.043658, l5: 0.040323, l6: 0.038872

[epoch:  49/100000, batch:    44/  187, ite: 4534] train loss: 0.350968, tar: 0.038986 
l0: 0.029454, l1: 0.028359, l2: 0.032279, l3: 0.039299, l4: 0.048412, l5: 0.049748, l6: 0.058481

[epoch:  49/100000, batch:    46/  187, ite: 4535] train loss: 0.350847, tar: 0.038968 
l0: 0.033998, l1: 0.034920, l2: 0.044971, l3: 0.045923, l4: 0.042804, l5: 0.037020, l6: 0.032859

[epoch:  49/100000, batch:    48/  187, ite: 4536] train loss: 0.350700, tar: 0.038959 
l0: 0.033216, l1: 0.037556, l2: 0.054580, l3: 0.046055, l4: 0.036829, l5: 0.035576, l6: 0.030507

[epoch:  49/100000, batch:    50/  187, ite: 4537] train loss: 0.350558, tar: 0.038948 
l0: 0.030071, l1: 0.030762, l2: 0.034823, l3: 0.037946, l4: 0.055009, l5: 0.058986, l6: 0.051120

[epoch:  49/100000, batch:    52/  187, ite: 4538] train loss: 0.350462, tar: 0.038932 
l0: 0.036461, l1: 0.039538, l2: 0.042116, l3: 0.039044, l4: 0.041757, l5: 0.041982, l6: 0.041248

[epoch:  49/100000, batch:    54/  187, ite: 4539] train loss: 0.350335, tar: 0.038927 
l0: 0.027540, l1: 0.030349, l2: 0.031080, l3: 0.030007, l4: 0.048605, l5: 0.049762, l6: 0.041969

[epoch:  49/100000, batch:    56/  187, ite: 4540] train loss: 0.350166, tar: 0.038906 
l0: 0.046500, l1: 0.046297, l2: 0.056758, l3: 0.055968, l4: 0.072988, l5: 0.058815, l6: 0.052499

[epoch:  49/100000, batch:    58/  187, ite: 4541] train loss: 0.350240, tar: 0.038920 
l0: 0.059315, l1: 0.061795, l2: 0.058079, l3: 0.067044, l4: 0.087025, l5: 0.069345, l6: 0.086175

[epoch:  49/100000, batch:    60/  187, ite: 4542] train loss: 0.350495, tar: 0.038958 
l0: 0.028498, l1: 0.028231, l2: 0.028947, l3: 0.030542, l4: 0.039160, l5: 0.039861, l6: 0.037987

[epoch:  49/100000, batch:    62/  187, ite: 4543] train loss: 0.350279, tar: 0.038938 
l0: 0.027446, l1: 0.031650, l2: 0.026927, l3: 0.026826, l4: 0.050485, l5: 0.052475, l6: 0.051456

[epoch:  49/100000, batch:    64/  187, ite: 4544] train loss: 0.350127, tar: 0.038917 
l0: 0.024454, l1: 0.024568, l2: 0.030354, l3: 0.030403, l4: 0.041504, l5: 0.039060, l6: 0.037265

[epoch:  49/100000, batch:    66/  187, ite: 4545] train loss: 0.349902, tar: 0.038891 
l0: 0.026422, l1: 0.027480, l2: 0.029987, l3: 0.031462, l4: 0.027434, l5: 0.029572, l6: 0.031416

[epoch:  49/100000, batch:    68/  187, ite: 4546] train loss: 0.349634, tar: 0.038868 
l0: 0.026943, l1: 0.026738, l2: 0.031994, l3: 0.028285, l4: 0.042674, l5: 0.047247, l6: 0.041724

[epoch:  49/100000, batch:    70/  187, ite: 4547] train loss: 0.349444, tar: 0.038846 
l0: 0.022109, l1: 0.036532, l2: 0.041909, l3: 0.025859, l4: 0.046502, l5: 0.042871, l6: 0.038922

[epoch:  49/100000, batch:    72/  187, ite: 4548] train loss: 0.349271, tar: 0.038816 
l0: 0.036532, l1: 0.040383, l2: 0.036958, l3: 0.039074, l4: 0.035480, l5: 0.034604, l6: 0.040294

[epoch:  49/100000, batch:    74/  187, ite: 4549] train loss: 0.349115, tar: 0.038811 
l0: 0.052447, l1: 0.052145, l2: 0.052246, l3: 0.057268, l4: 0.055477, l5: 0.060466, l6: 0.055616

[epoch:  49/100000, batch:    76/  187, ite: 4550] train loss: 0.349181, tar: 0.038836 
l0: 0.018410, l1: 0.018273, l2: 0.026844, l3: 0.027893, l4: 0.025292, l5: 0.028879, l6: 0.030934

[epoch:  49/100000, batch:    78/  187, ite: 4551] train loss: 0.348868, tar: 0.038799 
l0: 0.033453, l1: 0.026609, l2: 0.034043, l3: 0.043059, l4: 0.075653, l5: 0.094452, l6: 0.083258

[epoch:  49/100000, batch:    80/  187, ite: 4552] train loss: 0.348943, tar: 0.038789 
l0: 0.022865, l1: 0.019287, l2: 0.028344, l3: 0.029939, l4: 0.045957, l5: 0.051610, l6: 0.060911

[epoch:  49/100000, batch:    82/  187, ite: 4553] train loss: 0.348781, tar: 0.038761 
l0: 0.049725, l1: 0.046955, l2: 0.042022, l3: 0.048134, l4: 0.079602, l5: 0.091851, l6: 0.090818

[epoch:  49/100000, batch:    84/  187, ite: 4554] train loss: 0.348962, tar: 0.038780 
l0: 0.032384, l1: 0.025910, l2: 0.032261, l3: 0.033419, l4: 0.064365, l5: 0.086484, l6: 0.117042

[epoch:  49/100000, batch:    86/  187, ite: 4555] train loss: 0.349039, tar: 0.038769 
l0: 0.030970, l1: 0.024932, l2: 0.033005, l3: 0.037162, l4: 0.059310, l5: 0.075743, l6: 0.090948

[epoch:  49/100000, batch:    88/  187, ite: 4556] train loss: 0.349044, tar: 0.038755 
l0: 0.049336, l1: 0.048349, l2: 0.056829, l3: 0.050239, l4: 0.056720, l5: 0.057963, l6: 0.063124

[epoch:  49/100000, batch:    90/  187, ite: 4557] train loss: 0.349105, tar: 0.038774 
l0: 0.021198, l1: 0.020892, l2: 0.022917, l3: 0.025205, l4: 0.055710, l5: 0.048434, l6: 0.045603

[epoch:  49/100000, batch:    92/  187, ite: 4558] train loss: 0.348909, tar: 0.038742 
l0: 0.036043, l1: 0.052867, l2: 0.032048, l3: 0.023984, l4: 0.034307, l5: 0.028631, l6: 0.039211

[epoch:  49/100000, batch:    94/  187, ite: 4559] train loss: 0.348727, tar: 0.038738 
l0: 0.031437, l1: 0.030066, l2: 0.036019, l3: 0.040551, l4: 0.049113, l5: 0.042848, l6: 0.050401

[epoch:  49/100000, batch:    96/  187, ite: 4560] train loss: 0.348605, tar: 0.038724 
l0: 0.053773, l1: 0.056585, l2: 0.084865, l3: 0.085051, l4: 0.094486, l5: 0.086003, l6: 0.101374

[epoch:  49/100000, batch:    98/  187, ite: 4561] train loss: 0.348986, tar: 0.038751 
l0: 0.030419, l1: 0.025922, l2: 0.045103, l3: 0.051732, l4: 0.073353, l5: 0.079300, l6: 0.088902

[epoch:  49/100000, batch:   100/  187, ite: 4562] train loss: 0.349067, tar: 0.038736 
l0: 0.028905, l1: 0.026576, l2: 0.036748, l3: 0.041732, l4: 0.058895, l5: 0.065598, l6: 0.065711

[epoch:  49/100000, batch:   102/  187, ite: 4563] train loss: 0.349023, tar: 0.038719 
l0: 0.051968, l1: 0.055983, l2: 0.054966, l3: 0.058820, l4: 0.070613, l5: 0.057284, l6: 0.052292

[epoch:  49/100000, batch:   104/  187, ite: 4564] train loss: 0.349116, tar: 0.038742 
l0: 0.016705, l1: 0.018033, l2: 0.020623, l3: 0.019647, l4: 0.023547, l5: 0.024337, l6: 0.020230

[epoch:  49/100000, batch:   106/  187, ite: 4565] train loss: 0.348752, tar: 0.038703 
l0: 0.026853, l1: 0.029114, l2: 0.030621, l3: 0.029281, l4: 0.033204, l5: 0.036076, l6: 0.037872

[epoch:  49/100000, batch:   108/  187, ite: 4566] train loss: 0.348530, tar: 0.038683 
l0: 0.021517, l1: 0.024194, l2: 0.025823, l3: 0.028151, l4: 0.042164, l5: 0.040445, l6: 0.036016

[epoch:  49/100000, batch:   110/  187, ite: 4567] train loss: 0.348300, tar: 0.038652 
l0: 0.029301, l1: 0.029439, l2: 0.034325, l3: 0.039562, l4: 0.053633, l5: 0.047041, l6: 0.053536

[epoch:  49/100000, batch:   112/  187, ite: 4568] train loss: 0.348192, tar: 0.038636 
l0: 0.035575, l1: 0.043610, l2: 0.026779, l3: 0.025471, l4: 0.040513, l5: 0.040653, l6: 0.040958

[epoch:  49/100000, batch:   114/  187, ite: 4569] train loss: 0.348026, tar: 0.038630 
l0: 0.021435, l1: 0.022122, l2: 0.029984, l3: 0.028361, l4: 0.044999, l5: 0.051220, l6: 0.048163

[epoch:  49/100000, batch:   116/  187, ite: 4570] train loss: 0.347847, tar: 0.038600 
l0: 0.028384, l1: 0.030783, l2: 0.032224, l3: 0.032455, l4: 0.036596, l5: 0.032118, l6: 0.038842

[epoch:  49/100000, batch:   118/  187, ite: 4571] train loss: 0.347643, tar: 0.038582 
l0: 0.026073, l1: 0.024948, l2: 0.026596, l3: 0.030467, l4: 0.056250, l5: 0.048546, l6: 0.045987

[epoch:  49/100000, batch:   120/  187, ite: 4572] train loss: 0.347488, tar: 0.038561 
l0: 0.049995, l1: 0.049306, l2: 0.040260, l3: 0.054289, l4: 0.070698, l5: 0.071519, l6: 0.083934

[epoch:  49/100000, batch:   122/  187, ite: 4573] train loss: 0.347614, tar: 0.038580 
l0: 0.072589, l1: 0.091773, l2: 0.051328, l3: 0.061624, l4: 0.072289, l5: 0.049832, l6: 0.047231

[epoch:  49/100000, batch:   124/  187, ite: 4574] train loss: 0.347787, tar: 0.038640 
l0: 0.029695, l1: 0.028777, l2: 0.039940, l3: 0.041042, l4: 0.059706, l5: 0.055524, l6: 0.057862

[epoch:  49/100000, batch:   126/  187, ite: 4575] train loss: 0.347726, tar: 0.038624 
l0: 0.016262, l1: 0.016147, l2: 0.026873, l3: 0.021310, l4: 0.024889, l5: 0.020044, l6: 0.018989

[epoch:  49/100000, batch:   128/  187, ite: 4576] train loss: 0.347373, tar: 0.038585 
l0: 0.054599, l1: 0.049504, l2: 0.064480, l3: 0.065522, l4: 0.088374, l5: 0.092747, l6: 0.096730

[epoch:  49/100000, batch:   130/  187, ite: 4577] train loss: 0.347658, tar: 0.038613 
l0: 0.034863, l1: 0.037895, l2: 0.040106, l3: 0.035789, l4: 0.045433, l5: 0.043626, l6: 0.039870

[epoch:  49/100000, batch:   132/  187, ite: 4578] train loss: 0.347537, tar: 0.038607 
l0: 0.026401, l1: 0.026091, l2: 0.028381, l3: 0.029068, l4: 0.048773, l5: 0.045982, l6: 0.051187

[epoch:  49/100000, batch:   134/  187, ite: 4579] train loss: 0.347379, tar: 0.038586 
l0: 0.028767, l1: 0.027632, l2: 0.029426, l3: 0.033155, l4: 0.047640, l5: 0.047009, l6: 0.047355

[epoch:  49/100000, batch:   136/  187, ite: 4580] train loss: 0.347230, tar: 0.038569 
l0: 0.030009, l1: 0.028420, l2: 0.035183, l3: 0.033395, l4: 0.058126, l5: 0.051187, l6: 0.053835

[epoch:  49/100000, batch:   138/  187, ite: 4581] train loss: 0.347131, tar: 0.038554 
l0: 0.027854, l1: 0.026555, l2: 0.040076, l3: 0.038866, l4: 0.045414, l5: 0.057671, l6: 0.052001

[epoch:  49/100000, batch:   140/  187, ite: 4582] train loss: 0.347031, tar: 0.038535 
l0: 0.065344, l1: 0.067599, l2: 0.060103, l3: 0.077857, l4: 0.105804, l5: 0.085560, l6: 0.091392

[epoch:  49/100000, batch:   142/  187, ite: 4583] train loss: 0.347385, tar: 0.038581 
l0: 0.071846, l1: 0.073211, l2: 0.080120, l3: 0.083977, l4: 0.089230, l5: 0.079738, l6: 0.081717

[epoch:  49/100000, batch:   144/  187, ite: 4584] train loss: 0.347749, tar: 0.038638 
l0: 0.030947, l1: 0.032644, l2: 0.047165, l3: 0.044490, l4: 0.051383, l5: 0.044339, l6: 0.052404

[epoch:  49/100000, batch:   146/  187, ite: 4585] train loss: 0.347673, tar: 0.038625 
l0: 0.144823, l1: 0.166818, l2: 0.176672, l3: 0.160462, l4: 0.140858, l5: 0.127391, l6: 0.120796

[epoch:  49/100000, batch:   148/  187, ite: 4586] train loss: 0.348851, tar: 0.038806 
l0: 0.038040, l1: 0.047044, l2: 0.038007, l3: 0.039454, l4: 0.040202, l5: 0.045988, l6: 0.053245

[epoch:  49/100000, batch:   150/  187, ite: 4587] train loss: 0.348771, tar: 0.038805 
l0: 0.038410, l1: 0.040733, l2: 0.044981, l3: 0.043384, l4: 0.050531, l5: 0.051279, l6: 0.057313

[epoch:  49/100000, batch:   152/  187, ite: 4588] train loss: 0.348733, tar: 0.038805 
l0: 0.041359, l1: 0.048254, l2: 0.041130, l3: 0.039314, l4: 0.037038, l5: 0.032982, l6: 0.030023

[epoch:  49/100000, batch:   154/  187, ite: 4589] train loss: 0.348600, tar: 0.038809 
l0: 0.055706, l1: 0.064561, l2: 0.065892, l3: 0.062615, l4: 0.043764, l5: 0.041863, l6: 0.043999

[epoch:  49/100000, batch:   156/  187, ite: 4590] train loss: 0.348650, tar: 0.038837 
l0: 0.036952, l1: 0.037341, l2: 0.043458, l3: 0.047620, l4: 0.054398, l5: 0.051595, l6: 0.053488

[epoch:  49/100000, batch:   158/  187, ite: 4591] train loss: 0.348610, tar: 0.038834 
l0: 0.084729, l1: 0.095343, l2: 0.101291, l3: 0.090687, l4: 0.068105, l5: 0.064734, l6: 0.057981

[epoch:  49/100000, batch:   160/  187, ite: 4592] train loss: 0.348972, tar: 0.038912 
l0: 0.028332, l1: 0.027217, l2: 0.035440, l3: 0.035589, l4: 0.055495, l5: 0.050283, l6: 0.050953

[epoch:  49/100000, batch:   162/  187, ite: 4593] train loss: 0.348861, tar: 0.038894 
l0: 0.055881, l1: 0.062138, l2: 0.054491, l3: 0.062410, l4: 0.042542, l5: 0.042772, l6: 0.048375

[epoch:  49/100000, batch:   164/  187, ite: 4594] train loss: 0.348894, tar: 0.038923 
l0: 0.031882, l1: 0.030940, l2: 0.032240, l3: 0.036340, l4: 0.058899, l5: 0.061580, l6: 0.050775

[epoch:  49/100000, batch:   166/  187, ite: 4595] train loss: 0.348817, tar: 0.038911 
l0: 0.020953, l1: 0.021006, l2: 0.024442, l3: 0.023781, l4: 0.039295, l5: 0.038414, l6: 0.039057

[epoch:  49/100000, batch:   168/  187, ite: 4596] train loss: 0.348579, tar: 0.038881 
l0: 0.033633, l1: 0.035312, l2: 0.032993, l3: 0.045119, l4: 0.047014, l5: 0.047464, l6: 0.049206

[epoch:  49/100000, batch:   170/  187, ite: 4597] train loss: 0.348482, tar: 0.038872 
l0: 0.034427, l1: 0.031059, l2: 0.048649, l3: 0.046260, l4: 0.048105, l5: 0.052055, l6: 0.057683

[epoch:  49/100000, batch:   172/  187, ite: 4598] train loss: 0.348431, tar: 0.038864 
l0: 0.045250, l1: 0.040452, l2: 0.058169, l3: 0.060933, l4: 0.069607, l5: 0.071466, l6: 0.067695

[epoch:  49/100000, batch:   174/  187, ite: 4599] train loss: 0.348540, tar: 0.038875 
l0: 0.049525, l1: 0.047785, l2: 0.058269, l3: 0.055094, l4: 0.083263, l5: 0.077061, l6: 0.074912

[epoch:  49/100000, batch:   176/  187, ite: 4600] train loss: 0.348702, tar: 0.038893 
l0: 0.056351, l1: 0.053313, l2: 0.074303, l3: 0.077830, l4: 0.059514, l5: 0.064272, l6: 0.060805

[epoch:  49/100000, batch:   178/  187, ite: 4601] train loss: 0.348865, tar: 0.038922 
l0: 0.049448, l1: 0.047018, l2: 0.058149, l3: 0.058274, l4: 0.077067, l5: 0.080473, l6: 0.062051

[epoch:  49/100000, batch:   180/  187, ite: 4602] train loss: 0.349004, tar: 0.038939 
l0: 0.031162, l1: 0.027300, l2: 0.033316, l3: 0.042448, l4: 0.060497, l5: 0.058381, l6: 0.063693

[epoch:  49/100000, batch:   182/  187, ite: 4603] train loss: 0.348950, tar: 0.038926 
l0: 0.031599, l1: 0.025931, l2: 0.038734, l3: 0.040943, l4: 0.056172, l5: 0.070435, l6: 0.066469

[epoch:  49/100000, batch:   184/  187, ite: 4604] train loss: 0.348919, tar: 0.038914 
l0: 0.030610, l1: 0.033029, l2: 0.023281, l3: 0.026799, l4: 0.049168, l5: 0.051850, l6: 0.047412

[epoch:  49/100000, batch:   186/  187, ite: 4605] train loss: 0.348776, tar: 0.038901 
l0: 0.049637, l1: 0.046177, l2: 0.057584, l3: 0.063590, l4: 0.102073, l5: 0.100712, l6: 0.099662

[epoch:  49/100000, batch:   188/  187, ite: 4606] train loss: 0.349058, tar: 0.038918 
l0: 0.022221, l1: 0.023496, l2: 0.023951, l3: 0.025859, l4: 0.060285, l5: 0.061652, l6: 0.057196

[epoch:  50/100000, batch:     2/  187, ite: 4607] train loss: 0.348935, tar: 0.038891 
l0: 0.017238, l1: 0.019977, l2: 0.025924, l3: 0.022323, l4: 0.055393, l5: 0.062370, l6: 0.079853

[epoch:  50/100000, batch:     4/  187, ite: 4608] train loss: 0.348827, tar: 0.038855 
l0: 0.029730, l1: 0.028994, l2: 0.031768, l3: 0.033159, l4: 0.044537, l5: 0.052035, l6: 0.055571

[epoch:  50/100000, batch:     6/  187, ite: 4609] train loss: 0.348707, tar: 0.038840 
l0: 0.040475, l1: 0.039365, l2: 0.037595, l3: 0.045183, l4: 0.065282, l5: 0.070154, l6: 0.089669

[epoch:  50/100000, batch:     8/  187, ite: 4610] train loss: 0.348771, tar: 0.038843 
l0: 0.026752, l1: 0.024712, l2: 0.030499, l3: 0.037029, l4: 0.058960, l5: 0.059949, l6: 0.061986

[epoch:  50/100000, batch:    10/  187, ite: 4611] train loss: 0.348691, tar: 0.038823 
l0: 0.038209, l1: 0.035320, l2: 0.040670, l3: 0.045728, l4: 0.075534, l5: 0.077773, l6: 0.076874

[epoch:  50/100000, batch:    12/  187, ite: 4612] train loss: 0.348758, tar: 0.038822 
l0: 0.059902, l1: 0.055487, l2: 0.067713, l3: 0.088838, l4: 0.086728, l5: 0.098062, l6: 0.101261

[epoch:  50/100000, batch:    14/  187, ite: 4613] train loss: 0.349100, tar: 0.038856 
l0: 0.036909, l1: 0.039423, l2: 0.046551, l3: 0.040489, l4: 0.044283, l5: 0.043814, l6: 0.047733

[epoch:  50/100000, batch:    16/  187, ite: 4614] train loss: 0.349018, tar: 0.038853 
l0: 0.017999, l1: 0.020963, l2: 0.026902, l3: 0.031438, l4: 0.018889, l5: 0.018366, l6: 0.019549

[epoch:  50/100000, batch:    18/  187, ite: 4615] train loss: 0.348701, tar: 0.038819 
l0: 0.039229, l1: 0.031873, l2: 0.043990, l3: 0.046632, l4: 0.083113, l5: 0.094942, l6: 0.102905

[epoch:  50/100000, batch:    20/  187, ite: 4616] train loss: 0.348854, tar: 0.038820 
l0: 0.028583, l1: 0.028327, l2: 0.049146, l3: 0.041737, l4: 0.046902, l5: 0.036618, l6: 0.035294

[epoch:  50/100000, batch:    22/  187, ite: 4617] train loss: 0.348721, tar: 0.038803 
l0: 0.066715, l1: 0.066404, l2: 0.064929, l3: 0.067365, l4: 0.089702, l5: 0.097288, l6: 0.120880

[epoch:  50/100000, batch:    24/  187, ite: 4618] train loss: 0.349084, tar: 0.038849 
l0: 0.055267, l1: 0.056471, l2: 0.062542, l3: 0.063843, l4: 0.050768, l5: 0.062483, l6: 0.059370

[epoch:  50/100000, batch:    26/  187, ite: 4619] train loss: 0.349184, tar: 0.038875 
l0: 0.030059, l1: 0.030981, l2: 0.038837, l3: 0.035848, l4: 0.031858, l5: 0.032690, l6: 0.037436

[epoch:  50/100000, batch:    28/  187, ite: 4620] train loss: 0.349004, tar: 0.038861 
l0: 0.022653, l1: 0.021817, l2: 0.029045, l3: 0.026629, l4: 0.040833, l5: 0.039506, l6: 0.042790

[epoch:  50/100000, batch:    30/  187, ite: 4621] train loss: 0.348801, tar: 0.038835 
l0: 0.032477, l1: 0.027716, l2: 0.049572, l3: 0.055236, l4: 0.042641, l5: 0.048591, l6: 0.053292

[epoch:  50/100000, batch:    32/  187, ite: 4622] train loss: 0.348738, tar: 0.038825 
l0: 0.042940, l1: 0.045874, l2: 0.052825, l3: 0.044932, l4: 0.069955, l5: 0.061201, l6: 0.066369

[epoch:  50/100000, batch:    34/  187, ite: 4623] train loss: 0.348795, tar: 0.038831 
l0: 0.022541, l1: 0.021522, l2: 0.032219, l3: 0.036540, l4: 0.045529, l5: 0.050780, l6: 0.048500

[epoch:  50/100000, batch:    36/  187, ite: 4624] train loss: 0.348649, tar: 0.038805 
l0: 0.055904, l1: 0.054655, l2: 0.070075, l3: 0.061800, l4: 0.073182, l5: 0.093086, l6: 0.100047

[epoch:  50/100000, batch:    38/  187, ite: 4625] train loss: 0.348905, tar: 0.038832 
l0: 0.048231, l1: 0.045978, l2: 0.062649, l3: 0.053990, l4: 0.052773, l5: 0.063967, l6: 0.071199

[epoch:  50/100000, batch:    40/  187, ite: 4626] train loss: 0.348985, tar: 0.038847 
l0: 0.024965, l1: 0.023138, l2: 0.028720, l3: 0.031614, l4: 0.056793, l5: 0.047311, l6: 0.047163

[epoch:  50/100000, batch:    42/  187, ite: 4627] train loss: 0.348842, tar: 0.038825 
l0: 0.032550, l1: 0.030421, l2: 0.049689, l3: 0.054728, l4: 0.051882, l5: 0.051165, l6: 0.052429

[epoch:  50/100000, batch:    44/  187, ite: 4628] train loss: 0.348801, tar: 0.038815 
l0: 0.019806, l1: 0.018093, l2: 0.028987, l3: 0.031295, l4: 0.046607, l5: 0.046171, l6: 0.036333

[epoch:  50/100000, batch:    46/  187, ite: 4629] train loss: 0.348608, tar: 0.038785 
l0: 0.028737, l1: 0.027554, l2: 0.031177, l3: 0.038993, l4: 0.062297, l5: 0.067540, l6: 0.037861

[epoch:  50/100000, batch:    48/  187, ite: 4630] train loss: 0.348521, tar: 0.038769 
l0: 0.031905, l1: 0.028956, l2: 0.035910, l3: 0.040369, l4: 0.063370, l5: 0.065721, l6: 0.059811

[epoch:  50/100000, batch:    50/  187, ite: 4631] train loss: 0.348486, tar: 0.038758 
l0: 0.024706, l1: 0.028776, l2: 0.035511, l3: 0.035252, l4: 0.047520, l5: 0.041870, l6: 0.041414

[epoch:  50/100000, batch:    52/  187, ite: 4632] train loss: 0.348338, tar: 0.038736 
l0: 0.039583, l1: 0.038531, l2: 0.045421, l3: 0.051737, l4: 0.078268, l5: 0.063495, l6: 0.083429

[epoch:  50/100000, batch:    54/  187, ite: 4633] train loss: 0.348420, tar: 0.038737 
l0: 0.037309, l1: 0.037164, l2: 0.049407, l3: 0.044686, l4: 0.046756, l5: 0.050448, l6: 0.046353

[epoch:  50/100000, batch:    56/  187, ite: 4634] train loss: 0.348363, tar: 0.038735 
l0: 0.033780, l1: 0.030655, l2: 0.038116, l3: 0.045820, l4: 0.065615, l5: 0.063705, l6: 0.064047

[epoch:  50/100000, batch:    58/  187, ite: 4635] train loss: 0.348353, tar: 0.038727 
l0: 0.039349, l1: 0.042761, l2: 0.047459, l3: 0.047248, l4: 0.051827, l5: 0.054345, l6: 0.062009

[epoch:  50/100000, batch:    60/  187, ite: 4636] train loss: 0.348347, tar: 0.038728 
l0: 0.033977, l1: 0.033727, l2: 0.035790, l3: 0.036525, l4: 0.055126, l5: 0.056592, l6: 0.052719

[epoch:  50/100000, batch:    62/  187, ite: 4637] train loss: 0.348278, tar: 0.038721 
l0: 0.027047, l1: 0.028114, l2: 0.027229, l3: 0.029038, l4: 0.046019, l5: 0.049755, l6: 0.055705

[epoch:  50/100000, batch:    64/  187, ite: 4638] train loss: 0.348145, tar: 0.038703 
l0: 0.043648, l1: 0.049423, l2: 0.043180, l3: 0.040708, l4: 0.073668, l5: 0.076169, l6: 0.071066

[epoch:  50/100000, batch:    66/  187, ite: 4639] train loss: 0.348222, tar: 0.038710 
l0: 0.047791, l1: 0.052747, l2: 0.061559, l3: 0.054988, l4: 0.074294, l5: 0.070246, l6: 0.063469

[epoch:  50/100000, batch:    68/  187, ite: 4640] train loss: 0.348343, tar: 0.038724 
l0: 0.034797, l1: 0.034674, l2: 0.036743, l3: 0.037440, l4: 0.049214, l5: 0.056017, l6: 0.059535

[epoch:  50/100000, batch:    70/  187, ite: 4641] train loss: 0.348280, tar: 0.038718 
l0: 0.031458, l1: 0.029883, l2: 0.039653, l3: 0.032456, l4: 0.043054, l5: 0.048821, l6: 0.052257

[epoch:  50/100000, batch:    72/  187, ite: 4642] train loss: 0.348170, tar: 0.038707 
l0: 0.022894, l1: 0.024630, l2: 0.026871, l3: 0.026280, l4: 0.038311, l5: 0.042617, l6: 0.039898

[epoch:  50/100000, batch:    74/  187, ite: 4643] train loss: 0.347973, tar: 0.038682 
l0: 0.035485, l1: 0.037367, l2: 0.031563, l3: 0.033795, l4: 0.043775, l5: 0.049793, l6: 0.049901

[epoch:  50/100000, batch:    76/  187, ite: 4644] train loss: 0.347870, tar: 0.038678 
l0: 0.027075, l1: 0.025544, l2: 0.029667, l3: 0.032690, l4: 0.051372, l5: 0.056745, l6: 0.057651

[epoch:  50/100000, batch:    78/  187, ite: 4645] train loss: 0.347766, tar: 0.038660 
l0: 0.034403, l1: 0.032016, l2: 0.049625, l3: 0.051752, l4: 0.065227, l5: 0.050693, l6: 0.062094

[epoch:  50/100000, batch:    80/  187, ite: 4646] train loss: 0.347763, tar: 0.038653 
l0: 0.048591, l1: 0.048631, l2: 0.049929, l3: 0.055485, l4: 0.084319, l5: 0.072576, l6: 0.073146

[epoch:  50/100000, batch:    82/  187, ite: 4647] train loss: 0.347894, tar: 0.038668 
l0: 0.036540, l1: 0.033819, l2: 0.051703, l3: 0.063170, l4: 0.050541, l5: 0.049225, l6: 0.043606

[epoch:  50/100000, batch:    84/  187, ite: 4648] train loss: 0.347865, tar: 0.038665 
l0: 0.022401, l1: 0.022886, l2: 0.027703, l3: 0.033624, l4: 0.046263, l5: 0.051322, l6: 0.052491

[epoch:  50/100000, batch:    86/  187, ite: 4649] train loss: 0.347724, tar: 0.038640 
l0: 0.047161, l1: 0.053389, l2: 0.058980, l3: 0.055915, l4: 0.052703, l5: 0.054355, l6: 0.061340

[epoch:  50/100000, batch:    88/  187, ite: 4650] train loss: 0.347780, tar: 0.038653 
l0: 0.029479, l1: 0.034104, l2: 0.025267, l3: 0.027409, l4: 0.049722, l5: 0.041644, l6: 0.040089

[epoch:  50/100000, batch:    90/  187, ite: 4651] train loss: 0.347626, tar: 0.038639 
l0: 0.027741, l1: 0.026295, l2: 0.033830, l3: 0.038326, l4: 0.047180, l5: 0.042262, l6: 0.042749

[epoch:  50/100000, batch:    92/  187, ite: 4652] train loss: 0.347489, tar: 0.038622 
l0: 0.056618, l1: 0.058884, l2: 0.062919, l3: 0.070432, l4: 0.066743, l5: 0.072732, l6: 0.068824

[epoch:  50/100000, batch:    94/  187, ite: 4653] train loss: 0.347657, tar: 0.038650 
l0: 0.025176, l1: 0.026351, l2: 0.026490, l3: 0.029575, l4: 0.039707, l5: 0.032965, l6: 0.034988

[epoch:  50/100000, batch:    96/  187, ite: 4654] train loss: 0.347455, tar: 0.038629 
l0: 0.064998, l1: 0.072654, l2: 0.066151, l3: 0.072878, l4: 0.084572, l5: 0.055821, l6: 0.062196

[epoch:  50/100000, batch:    98/  187, ite: 4655] train loss: 0.347656, tar: 0.038669 
l0: 0.031516, l1: 0.029948, l2: 0.045095, l3: 0.046383, l4: 0.043462, l5: 0.039460, l6: 0.041078

[epoch:  50/100000, batch:   100/  187, ite: 4656] train loss: 0.347548, tar: 0.038659 
l0: 0.035475, l1: 0.035086, l2: 0.054288, l3: 0.051899, l4: 0.042664, l5: 0.039797, l6: 0.043131

[epoch:  50/100000, batch:   102/  187, ite: 4657] train loss: 0.347479, tar: 0.038654 
l0: 0.031567, l1: 0.033483, l2: 0.040382, l3: 0.034144, l4: 0.035678, l5: 0.033580, l6: 0.031723

[epoch:  50/100000, batch:   104/  187, ite: 4658] train loss: 0.347317, tar: 0.038643 
l0: 0.031938, l1: 0.028493, l2: 0.050035, l3: 0.055021, l4: 0.060914, l5: 0.055662, l6: 0.055985

[epoch:  50/100000, batch:   106/  187, ite: 4659] train loss: 0.347303, tar: 0.038633 
l0: 0.026871, l1: 0.026522, l2: 0.037513, l3: 0.035144, l4: 0.063652, l5: 0.057835, l6: 0.067229

[epoch:  50/100000, batch:   108/  187, ite: 4660] train loss: 0.347253, tar: 0.038615 
l0: 0.046200, l1: 0.047006, l2: 0.054682, l3: 0.055829, l4: 0.061573, l5: 0.059204, l6: 0.074862

[epoch:  50/100000, batch:   110/  187, ite: 4661] train loss: 0.347332, tar: 0.038626 
l0: 0.033850, l1: 0.034049, l2: 0.050671, l3: 0.046680, l4: 0.048987, l5: 0.055574, l6: 0.078468

[epoch:  50/100000, batch:   112/  187, ite: 4662] train loss: 0.347334, tar: 0.038619 
l0: 0.028401, l1: 0.029619, l2: 0.032617, l3: 0.033800, l4: 0.054731, l5: 0.061399, l6: 0.054320

[epoch:  50/100000, batch:   114/  187, ite: 4663] train loss: 0.347254, tar: 0.038604 
l0: 0.052480, l1: 0.054014, l2: 0.057579, l3: 0.055145, l4: 0.069703, l5: 0.075690, l6: 0.071419

[epoch:  50/100000, batch:   116/  187, ite: 4664] train loss: 0.347388, tar: 0.038625 
l0: 0.024179, l1: 0.038072, l2: 0.030693, l3: 0.023236, l4: 0.026866, l5: 0.025439, l6: 0.028141

[epoch:  50/100000, batch:   118/  187, ite: 4665] train loss: 0.347161, tar: 0.038603 
l0: 0.029541, l1: 0.031285, l2: 0.030977, l3: 0.034483, l4: 0.042970, l5: 0.039255, l6: 0.054538

[epoch:  50/100000, batch:   120/  187, ite: 4666] train loss: 0.347035, tar: 0.038589 
l0: 0.048050, l1: 0.049391, l2: 0.047994, l3: 0.051010, l4: 0.068519, l5: 0.081584, l6: 0.087372

[epoch:  50/100000, batch:   122/  187, ite: 4667] train loss: 0.347165, tar: 0.038604 
l0: 0.061132, l1: 0.061563, l2: 0.054175, l3: 0.060681, l4: 0.087786, l5: 0.086096, l6: 0.090330

[epoch:  50/100000, batch:   124/  187, ite: 4668] train loss: 0.347397, tar: 0.038637 
l0: 0.025101, l1: 0.029818, l2: 0.045375, l3: 0.040236, l4: 0.062415, l5: 0.055600, l6: 0.058918

[epoch:  50/100000, batch:   126/  187, ite: 4669] train loss: 0.347352, tar: 0.038617 
l0: 0.032821, l1: 0.041703, l2: 0.050155, l3: 0.046767, l4: 0.041283, l5: 0.034243, l6: 0.028517

[epoch:  50/100000, batch:   128/  187, ite: 4670] train loss: 0.347245, tar: 0.038608 
l0: 0.027783, l1: 0.027915, l2: 0.032491, l3: 0.035345, l4: 0.046250, l5: 0.046724, l6: 0.040268

[epoch:  50/100000, batch:   130/  187, ite: 4671] train loss: 0.347110, tar: 0.038592 
l0: 0.023502, l1: 0.021668, l2: 0.028013, l3: 0.031508, l4: 0.058774, l5: 0.065945, l6: 0.064792

[epoch:  50/100000, batch:   132/  187, ite: 4672] train loss: 0.347031, tar: 0.038570 
l0: 0.022215, l1: 0.025753, l2: 0.024427, l3: 0.031168, l4: 0.032773, l5: 0.039354, l6: 0.031953

[epoch:  50/100000, batch:   134/  187, ite: 4673] train loss: 0.346824, tar: 0.038545 
l0: 0.018955, l1: 0.017123, l2: 0.029735, l3: 0.029978, l4: 0.039995, l5: 0.045384, l6: 0.052578

[epoch:  50/100000, batch:   136/  187, ite: 4674] train loss: 0.346656, tar: 0.038516 
l0: 0.036907, l1: 0.034110, l2: 0.050877, l3: 0.052534, l4: 0.051979, l5: 0.054489, l6: 0.057871

[epoch:  50/100000, batch:   138/  187, ite: 4675] train loss: 0.346645, tar: 0.038514 
l0: 0.029351, l1: 0.027569, l2: 0.033303, l3: 0.039983, l4: 0.059562, l5: 0.053840, l6: 0.051840

[epoch:  50/100000, batch:   140/  187, ite: 4676] train loss: 0.346569, tar: 0.038500 
l0: 0.040408, l1: 0.046025, l2: 0.047929, l3: 0.036718, l4: 0.058022, l5: 0.063756, l6: 0.053056

[epoch:  50/100000, batch:   142/  187, ite: 4677] train loss: 0.346568, tar: 0.038503 
l0: 0.031318, l1: 0.037389, l2: 0.029680, l3: 0.030261, l4: 0.061258, l5: 0.058050, l6: 0.049574

[epoch:  50/100000, batch:   144/  187, ite: 4678] train loss: 0.346496, tar: 0.038493 
l0: 0.029588, l1: 0.029910, l2: 0.031296, l3: 0.035168, l4: 0.050972, l5: 0.048723, l6: 0.047365

[epoch:  50/100000, batch:   146/  187, ite: 4679] train loss: 0.346388, tar: 0.038480 
l0: 0.020368, l1: 0.022036, l2: 0.023121, l3: 0.019158, l4: 0.029555, l5: 0.029292, l6: 0.029935

[epoch:  50/100000, batch:   148/  187, ite: 4680] train loss: 0.346133, tar: 0.038453 
l0: 0.026974, l1: 0.031483, l2: 0.027869, l3: 0.026507, l4: 0.034547, l5: 0.034787, l6: 0.034584

[epoch:  50/100000, batch:   150/  187, ite: 4681] train loss: 0.345943, tar: 0.038436 
l0: 0.036387, l1: 0.033236, l2: 0.048259, l3: 0.047723, l4: 0.067456, l5: 0.074093, l6: 0.069979

[epoch:  50/100000, batch:   152/  187, ite: 4682] train loss: 0.345989, tar: 0.038433 
l0: 0.052871, l1: 0.055269, l2: 0.074198, l3: 0.078708, l4: 0.060878, l5: 0.052205, l6: 0.047449

[epoch:  50/100000, batch:   154/  187, ite: 4683] train loss: 0.346100, tar: 0.038454 
l0: 0.012867, l1: 0.012666, l2: 0.017364, l3: 0.015010, l4: 0.018878, l5: 0.029654, l6: 0.023586

[epoch:  50/100000, batch:   156/  187, ite: 4684] train loss: 0.345784, tar: 0.038417 
l0: 0.038989, l1: 0.036361, l2: 0.038199, l3: 0.045290, l4: 0.050789, l5: 0.055996, l6: 0.057165

[epoch:  50/100000, batch:   158/  187, ite: 4685] train loss: 0.345750, tar: 0.038418 
l0: 0.027276, l1: 0.029136, l2: 0.034711, l3: 0.033901, l4: 0.029716, l5: 0.032838, l6: 0.034262

[epoch:  50/100000, batch:   160/  187, ite: 4686] train loss: 0.345570, tar: 0.038401 
l0: 0.034733, l1: 0.033863, l2: 0.038832, l3: 0.048786, l4: 0.073044, l5: 0.059983, l6: 0.049053

[epoch:  50/100000, batch:   162/  187, ite: 4687] train loss: 0.345559, tar: 0.038396 
l0: 0.029885, l1: 0.033096, l2: 0.031046, l3: 0.031099, l4: 0.047580, l5: 0.045559, l6: 0.047591

[epoch:  50/100000, batch:   164/  187, ite: 4688] train loss: 0.345443, tar: 0.038384 
l0: 0.035681, l1: 0.032964, l2: 0.042183, l3: 0.045855, l4: 0.051785, l5: 0.059416, l6: 0.078645

[epoch:  50/100000, batch:   166/  187, ite: 4689] train loss: 0.345445, tar: 0.038380 
l0: 0.039837, l1: 0.042217, l2: 0.046749, l3: 0.042191, l4: 0.040373, l5: 0.045778, l6: 0.046389

[epoch:  50/100000, batch:   168/  187, ite: 4690] train loss: 0.345384, tar: 0.038382 
l0: 0.027300, l1: 0.025393, l2: 0.042112, l3: 0.041437, l4: 0.038581, l5: 0.040555, l6: 0.043649

[epoch:  50/100000, batch:   170/  187, ite: 4691] train loss: 0.345259, tar: 0.038366 
l0: 0.028551, l1: 0.031437, l2: 0.031238, l3: 0.028788, l4: 0.037343, l5: 0.048323, l6: 0.043562

[epoch:  50/100000, batch:   172/  187, ite: 4692] train loss: 0.345120, tar: 0.038352 
l0: 0.025129, l1: 0.031329, l2: 0.034369, l3: 0.036649, l4: 0.032436, l5: 0.031799, l6: 0.034628

[epoch:  50/100000, batch:   174/  187, ite: 4693] train loss: 0.344949, tar: 0.038333 
l0: 0.025073, l1: 0.027220, l2: 0.029920, l3: 0.032106, l4: 0.036494, l5: 0.031684, l6: 0.030920

[epoch:  50/100000, batch:   176/  187, ite: 4694] train loss: 0.344759, tar: 0.038313 
l0: 0.033804, l1: 0.035737, l2: 0.047218, l3: 0.050739, l4: 0.036929, l5: 0.040720, l6: 0.041565

[epoch:  50/100000, batch:   178/  187, ite: 4695] train loss: 0.344676, tar: 0.038307 
l0: 0.054282, l1: 0.067150, l2: 0.047173, l3: 0.061664, l4: 0.063966, l5: 0.059206, l6: 0.050296

[epoch:  50/100000, batch:   180/  187, ite: 4696] train loss: 0.344761, tar: 0.038330 
l0: 0.027647, l1: 0.030177, l2: 0.026136, l3: 0.027778, l4: 0.038717, l5: 0.042392, l6: 0.051929

[epoch:  50/100000, batch:   182/  187, ite: 4697] train loss: 0.344617, tar: 0.038315 
l0: 0.039850, l1: 0.040414, l2: 0.038379, l3: 0.044791, l4: 0.060887, l5: 0.050465, l6: 0.052016

[epoch:  50/100000, batch:   184/  187, ite: 4698] train loss: 0.344592, tar: 0.038317 
l0: 0.027749, l1: 0.029276, l2: 0.031704, l3: 0.037215, l4: 0.054502, l5: 0.040436, l6: 0.040626

[epoch:  50/100000, batch:   186/  187, ite: 4699] train loss: 0.344473, tar: 0.038302 
l0: 0.022430, l1: 0.022887, l2: 0.024387, l3: 0.024747, l4: 0.027439, l5: 0.034101, l6: 0.030183

[epoch:  50/100000, batch:   188/  187, ite: 4700] train loss: 0.344247, tar: 0.038279 
l0: 0.025062, l1: 0.025582, l2: 0.031477, l3: 0.032946, l4: 0.045229, l5: 0.042033, l6: 0.045721

[epoch:  51/100000, batch:     2/  187, ite: 4701] train loss: 0.344109, tar: 0.038260 
l0: 0.029777, l1: 0.033993, l2: 0.037136, l3: 0.037593, l4: 0.041634, l5: 0.045354, l6: 0.044489

[epoch:  51/100000, batch:     4/  187, ite: 4702] train loss: 0.344004, tar: 0.038248 
l0: 0.026070, l1: 0.024390, l2: 0.025020, l3: 0.034749, l4: 0.059915, l5: 0.058550, l6: 0.049154

[epoch:  51/100000, batch:     6/  187, ite: 4703] train loss: 0.343910, tar: 0.038231 
l0: 0.018664, l1: 0.018573, l2: 0.022406, l3: 0.022049, l4: 0.021593, l5: 0.020403, l6: 0.022898

[epoch:  51/100000, batch:     8/  187, ite: 4704] train loss: 0.343629, tar: 0.038203 
l0: 0.027946, l1: 0.029038, l2: 0.035398, l3: 0.028690, l4: 0.035005, l5: 0.033307, l6: 0.037444

[epoch:  51/100000, batch:    10/  187, ite: 4705] train loss: 0.343464, tar: 0.038188 
l0: 0.048863, l1: 0.043443, l2: 0.058973, l3: 0.060882, l4: 0.087295, l5: 0.079585, l6: 0.083950

[epoch:  51/100000, batch:    12/  187, ite: 4706] train loss: 0.343633, tar: 0.038204 
l0: 0.020753, l1: 0.021805, l2: 0.021385, l3: 0.021631, l4: 0.031719, l5: 0.036296, l6: 0.028723

[epoch:  51/100000, batch:    14/  187, ite: 4707] train loss: 0.343405, tar: 0.038179 
l0: 0.021512, l1: 0.029540, l2: 0.025792, l3: 0.023594, l4: 0.037812, l5: 0.037364, l6: 0.046517

[epoch:  51/100000, batch:    16/  187, ite: 4708] train loss: 0.343234, tar: 0.038155 
l0: 0.027646, l1: 0.026404, l2: 0.027113, l3: 0.030651, l4: 0.050512, l5: 0.050124, l6: 0.045855

[epoch:  51/100000, batch:    18/  187, ite: 4709] train loss: 0.343114, tar: 0.038141 
l0: 0.019132, l1: 0.021264, l2: 0.017693, l3: 0.020083, l4: 0.032365, l5: 0.033804, l6: 0.026167

[epoch:  51/100000, batch:    20/  187, ite: 4710] train loss: 0.342871, tar: 0.038114 
l0: 0.025386, l1: 0.025169, l2: 0.022139, l3: 0.030982, l4: 0.051572, l5: 0.055465, l6: 0.042007

[epoch:  51/100000, batch:    22/  187, ite: 4711] train loss: 0.342744, tar: 0.038096 
l0: 0.028219, l1: 0.029550, l2: 0.035501, l3: 0.032159, l4: 0.042587, l5: 0.040215, l6: 0.039488

[epoch:  51/100000, batch:    24/  187, ite: 4712] train loss: 0.342610, tar: 0.038082 
l0: 0.027821, l1: 0.026917, l2: 0.031978, l3: 0.033217, l4: 0.034280, l5: 0.034675, l6: 0.036575

[epoch:  51/100000, batch:    26/  187, ite: 4713] train loss: 0.342446, tar: 0.038068 
l0: 0.023760, l1: 0.023944, l2: 0.023984, l3: 0.024102, l4: 0.042962, l5: 0.045508, l6: 0.046144

[epoch:  51/100000, batch:    28/  187, ite: 4714] train loss: 0.342289, tar: 0.038048 
l0: 0.025637, l1: 0.025908, l2: 0.032036, l3: 0.029814, l4: 0.048055, l5: 0.053049, l6: 0.058450

[epoch:  51/100000, batch:    30/  187, ite: 4715] train loss: 0.342192, tar: 0.038030 
l0: 0.040361, l1: 0.040072, l2: 0.038329, l3: 0.040051, l4: 0.048860, l5: 0.062654, l6: 0.061416

[epoch:  51/100000, batch:    32/  187, ite: 4716] train loss: 0.342178, tar: 0.038033 
l0: 0.031468, l1: 0.034623, l2: 0.035259, l3: 0.032364, l4: 0.035859, l5: 0.030635, l6: 0.029140

[epoch:  51/100000, batch:    34/  187, ite: 4717] train loss: 0.342020, tar: 0.038024 
l0: 0.026468, l1: 0.032496, l2: 0.026603, l3: 0.025552, l4: 0.030161, l5: 0.034697, l6: 0.027908

[epoch:  51/100000, batch:    36/  187, ite: 4718] train loss: 0.341828, tar: 0.038008 
l0: 0.015671, l1: 0.014591, l2: 0.018064, l3: 0.020183, l4: 0.023332, l5: 0.038076, l6: 0.037182

[epoch:  51/100000, batch:    38/  187, ite: 4719] train loss: 0.341585, tar: 0.037977 
l0: 0.028763, l1: 0.027220, l2: 0.031466, l3: 0.045864, l4: 0.038370, l5: 0.036412, l6: 0.038843

[epoch:  51/100000, batch:    40/  187, ite: 4720] train loss: 0.341453, tar: 0.037964 
l0: 0.038167, l1: 0.038909, l2: 0.046688, l3: 0.040369, l4: 0.047365, l5: 0.046921, l6: 0.051170

[epoch:  51/100000, batch:    42/  187, ite: 4721] train loss: 0.341409, tar: 0.037965 
l0: 0.026991, l1: 0.025639, l2: 0.034847, l3: 0.032886, l4: 0.038892, l5: 0.049060, l6: 0.045173

[epoch:  51/100000, batch:    44/  187, ite: 4722] train loss: 0.341287, tar: 0.037949 
l0: 0.058410, l1: 0.066945, l2: 0.049830, l3: 0.056323, l4: 0.067381, l5: 0.054867, l6: 0.061329

[epoch:  51/100000, batch:    46/  187, ite: 4723] train loss: 0.341390, tar: 0.037978 
l0: 0.039299, l1: 0.033881, l2: 0.048826, l3: 0.051465, l4: 0.072540, l5: 0.092231, l6: 0.092532

[epoch:  51/100000, batch:    48/  187, ite: 4724] train loss: 0.341513, tar: 0.037980 
l0: 0.025352, l1: 0.026932, l2: 0.033846, l3: 0.031643, l4: 0.060236, l5: 0.055400, l6: 0.050712

[epoch:  51/100000, batch:    50/  187, ite: 4725] train loss: 0.341434, tar: 0.037962 
l0: 0.029467, l1: 0.030892, l2: 0.030799, l3: 0.034887, l4: 0.031877, l5: 0.037331, l6: 0.041728

[epoch:  51/100000, batch:    52/  187, ite: 4726] train loss: 0.341290, tar: 0.037950 
l0: 0.020581, l1: 0.018634, l2: 0.022174, l3: 0.026949, l4: 0.073793, l5: 0.073712, l6: 0.075436

[epoch:  51/100000, batch:    54/  187, ite: 4727] train loss: 0.341249, tar: 0.037927 
l0: 0.017169, l1: 0.018107, l2: 0.033790, l3: 0.030685, l4: 0.054164, l5: 0.039253, l6: 0.032871

[epoch:  51/100000, batch:    56/  187, ite: 4728] train loss: 0.341090, tar: 0.037898 
l0: 0.032368, l1: 0.038419, l2: 0.027501, l3: 0.026687, l4: 0.054223, l5: 0.061236, l6: 0.076115

[epoch:  51/100000, batch:    58/  187, ite: 4729] train loss: 0.341057, tar: 0.037890 
l0: 0.024524, l1: 0.025393, l2: 0.038996, l3: 0.040849, l4: 0.045375, l5: 0.034552, l6: 0.029633

[epoch:  51/100000, batch:    60/  187, ite: 4730] train loss: 0.340917, tar: 0.037872 
l0: 0.027419, l1: 0.023599, l2: 0.036671, l3: 0.041570, l4: 0.064937, l5: 0.066842, l6: 0.056956

[epoch:  51/100000, batch:    62/  187, ite: 4731] train loss: 0.340886, tar: 0.037858 
l0: 0.021102, l1: 0.020777, l2: 0.028675, l3: 0.030114, l4: 0.031915, l5: 0.030074, l6: 0.033087

[epoch:  51/100000, batch:    64/  187, ite: 4732] train loss: 0.340688, tar: 0.037835 
l0: 0.026481, l1: 0.027187, l2: 0.030095, l3: 0.034427, l4: 0.040600, l5: 0.040264, l6: 0.042464

[epoch:  51/100000, batch:    66/  187, ite: 4733] train loss: 0.340552, tar: 0.037819 
l0: 0.046839, l1: 0.047810, l2: 0.049136, l3: 0.049764, l4: 0.038415, l5: 0.043257, l6: 0.042693

[epoch:  51/100000, batch:    68/  187, ite: 4734] train loss: 0.340522, tar: 0.037832 
l0: 0.021903, l1: 0.020931, l2: 0.025921, l3: 0.027901, l4: 0.047969, l5: 0.046202, l6: 0.048565

[epoch:  51/100000, batch:    70/  187, ite: 4735] train loss: 0.340384, tar: 0.037810 
l0: 0.035409, l1: 0.037933, l2: 0.036873, l3: 0.037552, l4: 0.050290, l5: 0.047790, l6: 0.045276

[epoch:  51/100000, batch:    72/  187, ite: 4736] train loss: 0.340317, tar: 0.037807 
l0: 0.022382, l1: 0.021102, l2: 0.025320, l3: 0.028447, l4: 0.040213, l5: 0.035317, l6: 0.034156

[epoch:  51/100000, batch:    74/  187, ite: 4737] train loss: 0.340136, tar: 0.037786 
l0: 0.021505, l1: 0.019247, l2: 0.036449, l3: 0.036140, l4: 0.049862, l5: 0.048226, l6: 0.042335

[epoch:  51/100000, batch:    76/  187, ite: 4738] train loss: 0.340019, tar: 0.037764 
l0: 0.026892, l1: 0.026858, l2: 0.036336, l3: 0.034968, l4: 0.040563, l5: 0.038418, l6: 0.040189

[epoch:  51/100000, batch:    78/  187, ite: 4739] train loss: 0.339889, tar: 0.037749 
l0: 0.051665, l1: 0.050513, l2: 0.067282, l3: 0.061169, l4: 0.074280, l5: 0.075568, l6: 0.073704

[epoch:  51/100000, batch:    80/  187, ite: 4740] train loss: 0.340044, tar: 0.037768 
l0: 0.018016, l1: 0.020689, l2: 0.021580, l3: 0.023562, l4: 0.031943, l5: 0.033418, l6: 0.033502

[epoch:  51/100000, batch:    82/  187, ite: 4741] train loss: 0.339832, tar: 0.037741 
l0: 0.026778, l1: 0.021962, l2: 0.031439, l3: 0.034304, l4: 0.053483, l5: 0.069122, l6: 0.070053

[epoch:  51/100000, batch:    84/  187, ite: 4742] train loss: 0.339787, tar: 0.037726 
l0: 0.031993, l1: 0.035539, l2: 0.031621, l3: 0.035517, l4: 0.046304, l5: 0.047456, l6: 0.056033

[epoch:  51/100000, batch:    86/  187, ite: 4743] train loss: 0.339713, tar: 0.037719 
l0: 0.035368, l1: 0.035630, l2: 0.035841, l3: 0.034475, l4: 0.063076, l5: 0.072542, l6: 0.073875

[epoch:  51/100000, batch:    88/  187, ite: 4744] train loss: 0.339728, tar: 0.037716 
l0: 0.021579, l1: 0.022550, l2: 0.027661, l3: 0.026471, l4: 0.054127, l5: 0.053489, l6: 0.061550

[epoch:  51/100000, batch:    90/  187, ite: 4745] train loss: 0.339631, tar: 0.037694 
l0: 0.028633, l1: 0.027912, l2: 0.040302, l3: 0.043776, l4: 0.048929, l5: 0.051555, l6: 0.060187

[epoch:  51/100000, batch:    92/  187, ite: 4746] train loss: 0.339580, tar: 0.037682 
l0: 0.057290, l1: 0.058216, l2: 0.071101, l3: 0.070394, l4: 0.074296, l5: 0.065489, l6: 0.056750

[epoch:  51/100000, batch:    94/  187, ite: 4747] train loss: 0.339732, tar: 0.037708 
l0: 0.036743, l1: 0.040855, l2: 0.043892, l3: 0.047613, l4: 0.042890, l5: 0.038181, l6: 0.049654

[epoch:  51/100000, batch:    96/  187, ite: 4748] train loss: 0.339679, tar: 0.037707 
l0: 0.023970, l1: 0.026085, l2: 0.025489, l3: 0.025845, l4: 0.036092, l5: 0.041177, l6: 0.051778

[epoch:  51/100000, batch:    98/  187, ite: 4749] train loss: 0.339533, tar: 0.037688 
l0: 0.019519, l1: 0.017447, l2: 0.029434, l3: 0.030235, l4: 0.050183, l5: 0.047212, l6: 0.047836

[epoch:  51/100000, batch:   100/  187, ite: 4750] train loss: 0.339403, tar: 0.037664 
l0: 0.034225, l1: 0.039057, l2: 0.031225, l3: 0.029498, l4: 0.046190, l5: 0.051882, l6: 0.069503

[epoch:  51/100000, batch:   102/  187, ite: 4751] train loss: 0.339352, tar: 0.037660 
l0: 0.022882, l1: 0.023185, l2: 0.035690, l3: 0.032436, l4: 0.035136, l5: 0.041658, l6: 0.036904

[epoch:  51/100000, batch:   104/  187, ite: 4752] train loss: 0.339204, tar: 0.037640 
l0: 0.040119, l1: 0.041185, l2: 0.051354, l3: 0.056409, l4: 0.050566, l5: 0.055152, l6: 0.057467

[epoch:  51/100000, batch:   106/  187, ite: 4753] train loss: 0.339221, tar: 0.037643 
l0: 0.028580, l1: 0.025832, l2: 0.031347, l3: 0.037266, l4: 0.046964, l5: 0.046725, l6: 0.057235

[epoch:  51/100000, batch:   108/  187, ite: 4754] train loss: 0.339135, tar: 0.037631 
l0: 0.032734, l1: 0.029232, l2: 0.035052, l3: 0.044001, l4: 0.055815, l5: 0.052192, l6: 0.062620

[epoch:  51/100000, batch:   110/  187, ite: 4755] train loss: 0.339098, tar: 0.037625 
l0: 0.021620, l1: 0.018815, l2: 0.025920, l3: 0.024432, l4: 0.045293, l5: 0.050293, l6: 0.055201

[epoch:  51/100000, batch:   112/  187, ite: 4756] train loss: 0.338969, tar: 0.037604 
l0: 0.023838, l1: 0.025953, l2: 0.030677, l3: 0.030283, l4: 0.041695, l5: 0.035600, l6: 0.034215

[epoch:  51/100000, batch:   114/  187, ite: 4757] train loss: 0.338815, tar: 0.037585 
l0: 0.024478, l1: 0.027951, l2: 0.026248, l3: 0.027437, l4: 0.050245, l5: 0.045991, l6: 0.053624

[epoch:  51/100000, batch:   116/  187, ite: 4758] train loss: 0.338706, tar: 0.037568 
l0: 0.076499, l1: 0.075951, l2: 0.084322, l3: 0.094969, l4: 0.080834, l5: 0.099229, l6: 0.082567

[epoch:  51/100000, batch:   118/  187, ite: 4759] train loss: 0.339043, tar: 0.037619 
l0: 0.033114, l1: 0.047462, l2: 0.032362, l3: 0.025839, l4: 0.033208, l5: 0.032911, l6: 0.052367

[epoch:  51/100000, batch:   120/  187, ite: 4760] train loss: 0.338935, tar: 0.037613 
l0: 0.033077, l1: 0.044039, l2: 0.032822, l3: 0.025583, l4: 0.044762, l5: 0.038652, l6: 0.031162

[epoch:  51/100000, batch:   122/  187, ite: 4761] train loss: 0.338818, tar: 0.037607 
l0: 0.026095, l1: 0.027838, l2: 0.032251, l3: 0.035235, l4: 0.086730, l5: 0.051670, l6: 0.038868

[epoch:  51/100000, batch:   124/  187, ite: 4762] train loss: 0.338766, tar: 0.037592 
l0: 0.031026, l1: 0.027968, l2: 0.044964, l3: 0.043646, l4: 0.062304, l5: 0.073696, l6: 0.062592

[epoch:  51/100000, batch:   126/  187, ite: 4763] train loss: 0.338776, tar: 0.037584 
l0: 0.019752, l1: 0.019877, l2: 0.026787, l3: 0.023949, l4: 0.043558, l5: 0.035472, l6: 0.036044

[epoch:  51/100000, batch:   128/  187, ite: 4764] train loss: 0.338601, tar: 0.037560 
l0: 0.023995, l1: 0.020624, l2: 0.028395, l3: 0.028050, l4: 0.042932, l5: 0.056014, l6: 0.060478

[epoch:  51/100000, batch:   130/  187, ite: 4765] train loss: 0.338499, tar: 0.037543 
l0: 0.046392, l1: 0.045412, l2: 0.047146, l3: 0.052401, l4: 0.095013, l5: 0.083199, l6: 0.073494

[epoch:  51/100000, batch:   132/  187, ite: 4766] train loss: 0.338635, tar: 0.037554 
l0: 0.016816, l1: 0.015149, l2: 0.020501, l3: 0.024973, l4: 0.048981, l5: 0.055486, l6: 0.065658

[epoch:  51/100000, batch:   134/  187, ite: 4767] train loss: 0.338517, tar: 0.037527 
l0: 0.012327, l1: 0.011913, l2: 0.016779, l3: 0.018745, l4: 0.028981, l5: 0.034047, l6: 0.032535

[epoch:  51/100000, batch:   136/  187, ite: 4768] train loss: 0.338278, tar: 0.037494 
l0: 0.020475, l1: 0.018616, l2: 0.029589, l3: 0.027872, l4: 0.054498, l5: 0.074884, l6: 0.074989

[epoch:  51/100000, batch:   138/  187, ite: 4769] train loss: 0.338230, tar: 0.037472 
l0: 0.031458, l1: 0.031784, l2: 0.034148, l3: 0.039776, l4: 0.048695, l5: 0.049287, l6: 0.054256

[epoch:  51/100000, batch:   140/  187, ite: 4770] train loss: 0.338166, tar: 0.037464 
l0: 0.020378, l1: 0.024318, l2: 0.029311, l3: 0.029441, l4: 0.030565, l5: 0.031079, l6: 0.030566

[epoch:  51/100000, batch:   142/  187, ite: 4771] train loss: 0.337981, tar: 0.037442 
l0: 0.020929, l1: 0.020392, l2: 0.027285, l3: 0.024681, l4: 0.040907, l5: 0.047907, l6: 0.046323

[epoch:  51/100000, batch:   144/  187, ite: 4772] train loss: 0.337839, tar: 0.037421 
l0: 0.025520, l1: 0.025006, l2: 0.036741, l3: 0.037939, l4: 0.046893, l5: 0.049492, l6: 0.033656

[epoch:  51/100000, batch:   146/  187, ite: 4773] train loss: 0.337733, tar: 0.037405 
l0: 0.023206, l1: 0.025976, l2: 0.028534, l3: 0.028716, l4: 0.050004, l5: 0.046018, l6: 0.052277

[epoch:  51/100000, batch:   148/  187, ite: 4774] train loss: 0.337625, tar: 0.037387 
l0: 0.028309, l1: 0.024626, l2: 0.044248, l3: 0.048014, l4: 0.056416, l5: 0.051410, l6: 0.044874

[epoch:  51/100000, batch:   150/  187, ite: 4775] train loss: 0.337574, tar: 0.037375 
l0: 0.021331, l1: 0.021691, l2: 0.027188, l3: 0.032589, l4: 0.064655, l5: 0.051343, l6: 0.050183

[epoch:  51/100000, batch:   152/  187, ite: 4776] train loss: 0.337486, tar: 0.037355 
l0: 0.022498, l1: 0.023986, l2: 0.028056, l3: 0.032294, l4: 0.032803, l5: 0.033640, l6: 0.033895

[epoch:  51/100000, batch:   154/  187, ite: 4777] train loss: 0.337318, tar: 0.037336 
l0: 0.028208, l1: 0.028460, l2: 0.030765, l3: 0.038656, l4: 0.056475, l5: 0.058967, l6: 0.056511

[epoch:  51/100000, batch:   156/  187, ite: 4778] train loss: 0.337267, tar: 0.037324 
l0: 0.026913, l1: 0.024966, l2: 0.032439, l3: 0.033826, l4: 0.053396, l5: 0.058315, l6: 0.049582

[epoch:  51/100000, batch:   158/  187, ite: 4779] train loss: 0.337193, tar: 0.037311 
l0: 0.033469, l1: 0.035074, l2: 0.030569, l3: 0.037483, l4: 0.047540, l5: 0.048760, l6: 0.050327

[epoch:  51/100000, batch:   160/  187, ite: 4780] train loss: 0.337124, tar: 0.037306 
l0: 0.019603, l1: 0.016977, l2: 0.030737, l3: 0.034982, l4: 0.051738, l5: 0.053601, l6: 0.048298

[epoch:  51/100000, batch:   162/  187, ite: 4781] train loss: 0.337020, tar: 0.037283 
l0: 0.025516, l1: 0.027117, l2: 0.026227, l3: 0.027594, l4: 0.039741, l5: 0.043579, l6: 0.051428

[epoch:  51/100000, batch:   164/  187, ite: 4782] train loss: 0.336898, tar: 0.037268 
l0: 0.027552, l1: 0.024735, l2: 0.041912, l3: 0.042658, l4: 0.042099, l5: 0.040350, l6: 0.043961

[epoch:  51/100000, batch:   166/  187, ite: 4783] train loss: 0.336803, tar: 0.037255 
l0: 0.019689, l1: 0.019740, l2: 0.020313, l3: 0.020614, l4: 0.035990, l5: 0.046453, l6: 0.037072

[epoch:  51/100000, batch:   168/  187, ite: 4784] train loss: 0.336629, tar: 0.037233 
l0: 0.032733, l1: 0.030105, l2: 0.035458, l3: 0.040647, l4: 0.048879, l5: 0.063631, l6: 0.069427

[epoch:  51/100000, batch:   170/  187, ite: 4785] train loss: 0.336609, tar: 0.037227 
l0: 0.019416, l1: 0.016552, l2: 0.022732, l3: 0.028214, l4: 0.046537, l5: 0.057314, l6: 0.055241

[epoch:  51/100000, batch:   172/  187, ite: 4786] train loss: 0.336494, tar: 0.037205 
l0: 0.023378, l1: 0.024635, l2: 0.025080, l3: 0.024212, l4: 0.048022, l5: 0.049863, l6: 0.041511

[epoch:  51/100000, batch:   174/  187, ite: 4787] train loss: 0.336367, tar: 0.037187 
l0: 0.026241, l1: 0.030098, l2: 0.029321, l3: 0.029024, l4: 0.056840, l5: 0.049406, l6: 0.050215

[epoch:  51/100000, batch:   176/  187, ite: 4788] train loss: 0.336284, tar: 0.037173 
l0: 0.019013, l1: 0.017066, l2: 0.027487, l3: 0.033854, l4: 0.078573, l5: 0.073849, l6: 0.070245

[epoch:  51/100000, batch:   178/  187, ite: 4789] train loss: 0.336263, tar: 0.037150 
l0: 0.034224, l1: 0.032195, l2: 0.044180, l3: 0.048786, l4: 0.047095, l5: 0.050677, l6: 0.045430

[epoch:  51/100000, batch:   180/  187, ite: 4790] train loss: 0.336221, tar: 0.037147 
l0: 0.023766, l1: 0.023096, l2: 0.026393, l3: 0.024873, l4: 0.044877, l5: 0.056473, l6: 0.051730

[epoch:  51/100000, batch:   182/  187, ite: 4791] train loss: 0.336113, tar: 0.037130 
l0: 0.046480, l1: 0.054000, l2: 0.043024, l3: 0.036292, l4: 0.048151, l5: 0.057812, l6: 0.047023

[epoch:  51/100000, batch:   184/  187, ite: 4792] train loss: 0.336109, tar: 0.037141 
l0: 0.017288, l1: 0.018975, l2: 0.021930, l3: 0.022060, l4: 0.027517, l5: 0.032117, l6: 0.030175

[epoch:  51/100000, batch:   186/  187, ite: 4793] train loss: 0.335900, tar: 0.037116 
l0: 0.022109, l1: 0.016159, l2: 0.026505, l3: 0.038334, l4: 0.120778, l5: 0.134900, l6: 0.090523

[epoch:  51/100000, batch:   188/  187, ite: 4794] train loss: 0.336043, tar: 0.037097 
l0: 0.028258, l1: 0.034947, l2: 0.052686, l3: 0.041002, l4: 0.043177, l5: 0.044236, l6: 0.054678

[epoch:  52/100000, batch:     2/  187, ite: 4795] train loss: 0.335996, tar: 0.037086 
l0: 0.023006, l1: 0.023091, l2: 0.026086, l3: 0.030028, l4: 0.056920, l5: 0.055629, l6: 0.054856

[epoch:  52/100000, batch:     4/  187, ite: 4796] train loss: 0.335913, tar: 0.037069 
l0: 0.022079, l1: 0.023798, l2: 0.028966, l3: 0.031538, l4: 0.037353, l5: 0.040687, l6: 0.042765

[epoch:  52/100000, batch:     6/  187, ite: 4797] train loss: 0.335776, tar: 0.037050 
l0: 0.023647, l1: 0.021126, l2: 0.024131, l3: 0.035209, l4: 0.054772, l5: 0.058027, l6: 0.066786

[epoch:  52/100000, batch:     8/  187, ite: 4798] train loss: 0.335711, tar: 0.037033 
l0: 0.025960, l1: 0.025128, l2: 0.037319, l3: 0.037561, l4: 0.037060, l5: 0.045546, l6: 0.054724

[epoch:  52/100000, batch:    10/  187, ite: 4799] train loss: 0.335620, tar: 0.037019 
l0: 0.040665, l1: 0.044013, l2: 0.058276, l3: 0.045077, l4: 0.046584, l5: 0.056342, l6: 0.050214

[epoch:  52/100000, batch:    12/  187, ite: 4800] train loss: 0.335627, tar: 0.037024 
l0: 0.039786, l1: 0.041910, l2: 0.045951, l3: 0.046111, l4: 0.049031, l5: 0.047560, l6: 0.041642

[epoch:  52/100000, batch:    14/  187, ite: 4801] train loss: 0.335598, tar: 0.037027 
l0: 0.019479, l1: 0.020847, l2: 0.028960, l3: 0.029857, l4: 0.035101, l5: 0.040361, l6: 0.037906

[epoch:  52/100000, batch:    16/  187, ite: 4802] train loss: 0.335444, tar: 0.037005 
l0: 0.021700, l1: 0.023478, l2: 0.026787, l3: 0.025092, l4: 0.036706, l5: 0.050414, l6: 0.033172

[epoch:  52/100000, batch:    18/  187, ite: 4803] train loss: 0.335297, tar: 0.036986 
l0: 0.027390, l1: 0.028367, l2: 0.027879, l3: 0.028921, l4: 0.048628, l5: 0.048025, l6: 0.049737

[epoch:  52/100000, batch:    20/  187, ite: 4804] train loss: 0.335202, tar: 0.036974 
l0: 0.041943, l1: 0.042534, l2: 0.037969, l3: 0.043191, l4: 0.064670, l5: 0.064140, l6: 0.082601

[epoch:  52/100000, batch:    22/  187, ite: 4805] train loss: 0.335254, tar: 0.036981 
l0: 0.054303, l1: 0.045765, l2: 0.092766, l3: 0.082607, l4: 0.095120, l5: 0.099652, l6: 0.136829

[epoch:  52/100000, batch:    24/  187, ite: 4806] train loss: 0.335591, tar: 0.037002 
l0: 0.015928, l1: 0.013778, l2: 0.023116, l3: 0.030366, l4: 0.029045, l5: 0.030654, l6: 0.032976

[epoch:  52/100000, batch:    26/  187, ite: 4807] train loss: 0.335393, tar: 0.036976 
l0: 0.020390, l1: 0.020510, l2: 0.021308, l3: 0.025093, l4: 0.048275, l5: 0.053414, l6: 0.046936

[epoch:  52/100000, batch:    28/  187, ite: 4808] train loss: 0.335270, tar: 0.036955 
l0: 0.035920, l1: 0.029938, l2: 0.050219, l3: 0.059357, l4: 0.091272, l5: 0.084653, l6: 0.086828

[epoch:  52/100000, batch:    30/  187, ite: 4809] train loss: 0.335398, tar: 0.036954 
l0: 0.035742, l1: 0.039038, l2: 0.031859, l3: 0.034520, l4: 0.067638, l5: 0.085966, l6: 0.092264

[epoch:  52/100000, batch:    32/  187, ite: 4810] train loss: 0.335461, tar: 0.036953 
l0: 0.025984, l1: 0.023640, l2: 0.032831, l3: 0.034877, l4: 0.057769, l5: 0.061025, l6: 0.068752

[epoch:  52/100000, batch:    34/  187, ite: 4811] train loss: 0.335424, tar: 0.036939 
l0: 0.055492, l1: 0.050245, l2: 0.075641, l3: 0.074970, l4: 0.069206, l5: 0.079369, l6: 0.082499

[epoch:  52/100000, batch:    36/  187, ite: 4812] train loss: 0.335611, tar: 0.036962 
l0: 0.027833, l1: 0.028965, l2: 0.029544, l3: 0.031758, l4: 0.045858, l5: 0.043852, l6: 0.047674

[epoch:  52/100000, batch:    38/  187, ite: 4813] train loss: 0.335512, tar: 0.036951 
l0: 0.023646, l1: 0.027513, l2: 0.026567, l3: 0.022250, l4: 0.042560, l5: 0.044304, l6: 0.044754

[epoch:  52/100000, batch:    40/  187, ite: 4814] train loss: 0.335385, tar: 0.036934 
l0: 0.021696, l1: 0.021666, l2: 0.025430, l3: 0.027616, l4: 0.045916, l5: 0.050262, l6: 0.047958

[epoch:  52/100000, batch:    42/  187, ite: 4815] train loss: 0.335268, tar: 0.036916 
l0: 0.034714, l1: 0.032436, l2: 0.041393, l3: 0.043206, l4: 0.060368, l5: 0.060608, l6: 0.061232

[epoch:  52/100000, batch:    44/  187, ite: 4816] train loss: 0.335267, tar: 0.036913 
l0: 0.026730, l1: 0.027260, l2: 0.036712, l3: 0.041396, l4: 0.040774, l5: 0.044663, l6: 0.046063

[epoch:  52/100000, batch:    46/  187, ite: 4817] train loss: 0.335179, tar: 0.036900 
l0: 0.048099, l1: 0.044580, l2: 0.046191, l3: 0.054975, l4: 0.079030, l5: 0.072333, l6: 0.076767

[epoch:  52/100000, batch:    48/  187, ite: 4818] train loss: 0.335285, tar: 0.036914 
l0: 0.040822, l1: 0.037945, l2: 0.056692, l3: 0.060079, l4: 0.075667, l5: 0.069304, l6: 0.069373

[epoch:  52/100000, batch:    50/  187, ite: 4819] train loss: 0.335376, tar: 0.036919 
l0: 0.044139, l1: 0.054211, l2: 0.044987, l3: 0.057186, l4: 0.056036, l5: 0.059109, l6: 0.056471

[epoch:  52/100000, batch:    52/  187, ite: 4820] train loss: 0.335421, tar: 0.036928 
l0: 0.038373, l1: 0.038614, l2: 0.046067, l3: 0.049690, l4: 0.058678, l5: 0.055843, l6: 0.058110

[epoch:  52/100000, batch:    54/  187, ite: 4821] train loss: 0.335433, tar: 0.036929 
l0: 0.041917, l1: 0.040241, l2: 0.057850, l3: 0.063919, l4: 0.073614, l5: 0.065512, l6: 0.053043

[epoch:  52/100000, batch:    56/  187, ite: 4822] train loss: 0.335507, tar: 0.036936 
l0: 0.040794, l1: 0.050096, l2: 0.042722, l3: 0.039074, l4: 0.087619, l5: 0.084191, l6: 0.089173

[epoch:  52/100000, batch:    58/  187, ite: 4823] train loss: 0.335626, tar: 0.036940 
l0: 0.038087, l1: 0.031835, l2: 0.053009, l3: 0.063905, l4: 0.102418, l5: 0.102625, l6: 0.083821

[epoch:  52/100000, batch:    60/  187, ite: 4824] train loss: 0.335796, tar: 0.036942 
l0: 0.066222, l1: 0.071243, l2: 0.086570, l3: 0.081186, l4: 0.063036, l5: 0.061898, l6: 0.064115

[epoch:  52/100000, batch:    62/  187, ite: 4825] train loss: 0.335988, tar: 0.036977 
l0: 0.028335, l1: 0.029613, l2: 0.038898, l3: 0.036891, l4: 0.046194, l5: 0.042457, l6: 0.042504

[epoch:  52/100000, batch:    64/  187, ite: 4826] train loss: 0.335902, tar: 0.036967 
l0: 0.040902, l1: 0.040860, l2: 0.044401, l3: 0.049480, l4: 0.059435, l5: 0.053910, l6: 0.070146

[epoch:  52/100000, batch:    66/  187, ite: 4827] train loss: 0.335930, tar: 0.036971 
l0: 0.029631, l1: 0.033370, l2: 0.037479, l3: 0.042246, l4: 0.041710, l5: 0.034516, l6: 0.034055

[epoch:  52/100000, batch:    68/  187, ite: 4828] train loss: 0.335830, tar: 0.036963 
l0: 0.043198, l1: 0.046261, l2: 0.045706, l3: 0.045515, l4: 0.056355, l5: 0.051867, l6: 0.054322

[epoch:  52/100000, batch:    70/  187, ite: 4829] train loss: 0.335839, tar: 0.036970 
l0: 0.045588, l1: 0.050829, l2: 0.073656, l3: 0.056918, l4: 0.049183, l5: 0.037368, l6: 0.038469

[epoch:  52/100000, batch:    72/  187, ite: 4830] train loss: 0.335858, tar: 0.036980 
l0: 0.032455, l1: 0.029605, l2: 0.033110, l3: 0.045447, l4: 0.062540, l5: 0.061640, l6: 0.076811

[epoch:  52/100000, batch:    74/  187, ite: 4831] train loss: 0.335865, tar: 0.036975 
l0: 0.044799, l1: 0.042141, l2: 0.049264, l3: 0.053506, l4: 0.062355, l5: 0.073417, l6: 0.067438

[epoch:  52/100000, batch:    76/  187, ite: 4832] train loss: 0.335934, tar: 0.036984 
l0: 0.023646, l1: 0.023129, l2: 0.032083, l3: 0.029832, l4: 0.041188, l5: 0.040207, l6: 0.041050

[epoch:  52/100000, batch:    78/  187, ite: 4833] train loss: 0.335808, tar: 0.036968 
l0: 0.018725, l1: 0.017723, l2: 0.026760, l3: 0.024723, l4: 0.036787, l5: 0.035328, l6: 0.038806

[epoch:  52/100000, batch:    80/  187, ite: 4834] train loss: 0.335644, tar: 0.036947 
l0: 0.039091, l1: 0.042477, l2: 0.038362, l3: 0.039410, l4: 0.044615, l5: 0.040810, l6: 0.040029

[epoch:  52/100000, batch:    82/  187, ite: 4835] train loss: 0.335583, tar: 0.036949 
l0: 0.028868, l1: 0.024334, l2: 0.041826, l3: 0.049020, l4: 0.089312, l5: 0.091936, l6: 0.067243

[epoch:  52/100000, batch:    84/  187, ite: 4836] train loss: 0.335651, tar: 0.036939 
l0: 0.030435, l1: 0.030961, l2: 0.036895, l3: 0.040362, l4: 0.040232, l5: 0.037073, l6: 0.037864

[epoch:  52/100000, batch:    86/  187, ite: 4837] train loss: 0.335553, tar: 0.036932 
l0: 0.031726, l1: 0.027938, l2: 0.050634, l3: 0.067632, l4: 0.092645, l5: 0.096297, l6: 0.076199

[epoch:  52/100000, batch:    88/  187, ite: 4838] train loss: 0.335682, tar: 0.036925 
l0: 0.026165, l1: 0.026108, l2: 0.029279, l3: 0.032804, l4: 0.054727, l5: 0.066192, l6: 0.062378

[epoch:  52/100000, batch:    90/  187, ite: 4839] train loss: 0.335636, tar: 0.036913 
l0: 0.038255, l1: 0.049011, l2: 0.036200, l3: 0.029784, l4: 0.041655, l5: 0.043849, l6: 0.055023

[epoch:  52/100000, batch:    92/  187, ite: 4840] train loss: 0.335586, tar: 0.036914 
l0: 0.028797, l1: 0.028245, l2: 0.030126, l3: 0.034279, l4: 0.041243, l5: 0.040717, l6: 0.047857

[epoch:  52/100000, batch:    94/  187, ite: 4841] train loss: 0.335486, tar: 0.036905 
l0: 0.035445, l1: 0.035537, l2: 0.039686, l3: 0.046486, l4: 0.063541, l5: 0.078988, l6: 0.077649

[epoch:  52/100000, batch:    96/  187, ite: 4842] train loss: 0.335536, tar: 0.036903 
l0: 0.025290, l1: 0.027612, l2: 0.023500, l3: 0.024238, l4: 0.034396, l5: 0.043983, l6: 0.035648

[epoch:  52/100000, batch:    98/  187, ite: 4843] train loss: 0.335393, tar: 0.036889 
l0: 0.023556, l1: 0.022868, l2: 0.030910, l3: 0.031837, l4: 0.037671, l5: 0.042281, l6: 0.053863

[epoch:  52/100000, batch:   100/  187, ite: 4844] train loss: 0.335283, tar: 0.036873 
l0: 0.027267, l1: 0.025816, l2: 0.038185, l3: 0.043740, l4: 0.054828, l5: 0.050894, l6: 0.052619

[epoch:  52/100000, batch:   102/  187, ite: 4845] train loss: 0.335233, tar: 0.036862 
l0: 0.030725, l1: 0.036827, l2: 0.032582, l3: 0.035728, l4: 0.042565, l5: 0.047388, l6: 0.047904

[epoch:  52/100000, batch:   104/  187, ite: 4846] train loss: 0.335161, tar: 0.036855 
l0: 0.027558, l1: 0.025166, l2: 0.038142, l3: 0.042123, l4: 0.056251, l5: 0.058312, l6: 0.060790

[epoch:  52/100000, batch:   106/  187, ite: 4847] train loss: 0.335129, tar: 0.036844 
l0: 0.028669, l1: 0.027165, l2: 0.045644, l3: 0.046929, l4: 0.062620, l5: 0.058472, l6: 0.061104

[epoch:  52/100000, batch:   108/  187, ite: 4848] train loss: 0.335124, tar: 0.036834 
l0: 0.021088, l1: 0.023879, l2: 0.022426, l3: 0.027843, l4: 0.040497, l5: 0.044237, l6: 0.051654

[epoch:  52/100000, batch:   110/  187, ite: 4849] train loss: 0.335002, tar: 0.036815 
l0: 0.024731, l1: 0.030909, l2: 0.029774, l3: 0.025286, l4: 0.030069, l5: 0.034759, l6: 0.032575

[epoch:  52/100000, batch:   112/  187, ite: 4850] train loss: 0.334853, tar: 0.036801 
l0: 0.022361, l1: 0.020946, l2: 0.030852, l3: 0.039107, l4: 0.039025, l5: 0.038354, l6: 0.040099

[epoch:  52/100000, batch:   114/  187, ite: 4851] train loss: 0.334730, tar: 0.036784 
l0: 0.017053, l1: 0.020244, l2: 0.019040, l3: 0.017850, l4: 0.029330, l5: 0.027964, l6: 0.031057

[epoch:  52/100000, batch:   116/  187, ite: 4852] train loss: 0.334528, tar: 0.036761 
l0: 0.021924, l1: 0.023618, l2: 0.025962, l3: 0.024148, l4: 0.033533, l5: 0.038025, l6: 0.038738

[epoch:  52/100000, batch:   118/  187, ite: 4853] train loss: 0.334377, tar: 0.036744 
l0: 0.017948, l1: 0.017029, l2: 0.025019, l3: 0.032558, l4: 0.040746, l5: 0.037678, l6: 0.039291

[epoch:  52/100000, batch:   120/  187, ite: 4854] train loss: 0.334232, tar: 0.036722 
l0: 0.030006, l1: 0.024989, l2: 0.041547, l3: 0.051780, l4: 0.060777, l5: 0.060016, l6: 0.055600

[epoch:  52/100000, batch:   122/  187, ite: 4855] train loss: 0.334221, tar: 0.036714 
l0: 0.018153, l1: 0.022183, l2: 0.020465, l3: 0.022865, l4: 0.027402, l5: 0.031178, l6: 0.034304

[epoch:  52/100000, batch:   124/  187, ite: 4856] train loss: 0.334037, tar: 0.036692 
l0: 0.020861, l1: 0.022332, l2: 0.022447, l3: 0.023419, l4: 0.030666, l5: 0.031989, l6: 0.033734

[epoch:  52/100000, batch:   126/  187, ite: 4857] train loss: 0.333863, tar: 0.036674 
l0: 0.047735, l1: 0.060347, l2: 0.043130, l3: 0.054538, l4: 0.029993, l5: 0.027942, l6: 0.031906

[epoch:  52/100000, batch:   128/  187, ite: 4858] train loss: 0.333819, tar: 0.036687 
l0: 0.034847, l1: 0.038619, l2: 0.034272, l3: 0.042462, l4: 0.063414, l5: 0.064978, l6: 0.069273

[epoch:  52/100000, batch:   130/  187, ite: 4859] train loss: 0.333835, tar: 0.036684 
l0: 0.027070, l1: 0.025714, l2: 0.032016, l3: 0.038398, l4: 0.037417, l5: 0.045441, l6: 0.050846

[epoch:  52/100000, batch:   132/  187, ite: 4860] train loss: 0.333746, tar: 0.036673 
l0: 0.019174, l1: 0.019833, l2: 0.019928, l3: 0.027365, l4: 0.032666, l5: 0.030917, l6: 0.026861

[epoch:  52/100000, batch:   134/  187, ite: 4861] train loss: 0.333563, tar: 0.036653 
l0: 0.038392, l1: 0.045637, l2: 0.037717, l3: 0.040516, l4: 0.056743, l5: 0.049710, l6: 0.039039

[epoch:  52/100000, batch:   136/  187, ite: 4862] train loss: 0.333533, tar: 0.036655 
l0: 0.041407, l1: 0.041229, l2: 0.041036, l3: 0.051236, l4: 0.042858, l5: 0.043852, l6: 0.051930

[epoch:  52/100000, batch:   138/  187, ite: 4863] train loss: 0.333510, tar: 0.036660 
l0: 0.043723, l1: 0.048452, l2: 0.050143, l3: 0.049566, l4: 0.058634, l5: 0.053244, l6: 0.048636

[epoch:  52/100000, batch:   140/  187, ite: 4864] train loss: 0.333532, tar: 0.036669 
l0: 0.047868, l1: 0.053429, l2: 0.050760, l3: 0.048696, l4: 0.047299, l5: 0.042088, l6: 0.037366

[epoch:  52/100000, batch:   142/  187, ite: 4865] train loss: 0.333525, tar: 0.036682 
l0: 0.026347, l1: 0.033862, l2: 0.023518, l3: 0.024367, l4: 0.038418, l5: 0.038648, l6: 0.042250

[epoch:  52/100000, batch:   144/  187, ite: 4866] train loss: 0.333403, tar: 0.036670 
l0: 0.022036, l1: 0.023542, l2: 0.029550, l3: 0.028547, l4: 0.027781, l5: 0.026139, l6: 0.024118

[epoch:  52/100000, batch:   146/  187, ite: 4867] train loss: 0.333228, tar: 0.036653 
l0: 0.026695, l1: 0.026299, l2: 0.025303, l3: 0.035756, l4: 0.057468, l5: 0.068263, l6: 0.048563

[epoch:  52/100000, batch:   148/  187, ite: 4868] train loss: 0.333176, tar: 0.036641 
l0: 0.041401, l1: 0.040715, l2: 0.041804, l3: 0.041497, l4: 0.080005, l5: 0.081556, l6: 0.088296

[epoch:  52/100000, batch:   150/  187, ite: 4869] train loss: 0.333270, tar: 0.036647 
l0: 0.045292, l1: 0.048146, l2: 0.034217, l3: 0.049081, l4: 0.083561, l5: 0.068045, l6: 0.054315

[epoch:  52/100000, batch:   152/  187, ite: 4870] train loss: 0.333327, tar: 0.036657 
l0: 0.027210, l1: 0.026628, l2: 0.039463, l3: 0.038372, l4: 0.054888, l5: 0.057024, l6: 0.046038

[epoch:  52/100000, batch:   154/  187, ite: 4871] train loss: 0.333277, tar: 0.036646 
l0: 0.024250, l1: 0.023127, l2: 0.023346, l3: 0.030990, l4: 0.064765, l5: 0.070898, l6: 0.072646

[epoch:  52/100000, batch:   156/  187, ite: 4872] train loss: 0.333250, tar: 0.036632 
l0: 0.064900, l1: 0.065325, l2: 0.067285, l3: 0.074418, l4: 0.090516, l5: 0.079003, l6: 0.075953

[epoch:  52/100000, batch:   158/  187, ite: 4873] train loss: 0.333461, tar: 0.036664 
l0: 0.038382, l1: 0.037048, l2: 0.052490, l3: 0.055436, l4: 0.051117, l5: 0.042327, l6: 0.050587

[epoch:  52/100000, batch:   160/  187, ite: 4874] train loss: 0.333454, tar: 0.036666 
l0: 0.025633, l1: 0.025584, l2: 0.031898, l3: 0.028051, l4: 0.042494, l5: 0.049795, l6: 0.049821

[epoch:  52/100000, batch:   162/  187, ite: 4875] train loss: 0.333363, tar: 0.036653 
l0: 0.018809, l1: 0.019934, l2: 0.018430, l3: 0.017777, l4: 0.047432, l5: 0.051282, l6: 0.041366

[epoch:  52/100000, batch:   164/  187, ite: 4876] train loss: 0.333228, tar: 0.036633 
l0: 0.027618, l1: 0.028916, l2: 0.029996, l3: 0.033917, l4: 0.045924, l5: 0.038528, l6: 0.038728

[epoch:  52/100000, batch:   166/  187, ite: 4877] train loss: 0.333125, tar: 0.036623 
l0: 0.016205, l1: 0.015845, l2: 0.017506, l3: 0.016232, l4: 0.028749, l5: 0.035477, l6: 0.037499

[epoch:  52/100000, batch:   168/  187, ite: 4878] train loss: 0.332937, tar: 0.036600 
l0: 0.039857, l1: 0.040254, l2: 0.044490, l3: 0.045250, l4: 0.061669, l5: 0.051581, l6: 0.055006

[epoch:  52/100000, batch:   170/  187, ite: 4879] train loss: 0.332943, tar: 0.036603 
l0: 0.048190, l1: 0.042475, l2: 0.073782, l3: 0.072157, l4: 0.052169, l5: 0.060482, l6: 0.071666

[epoch:  52/100000, batch:   172/  187, ite: 4880] train loss: 0.333043, tar: 0.036616 
l0: 0.029236, l1: 0.026973, l2: 0.039341, l3: 0.043386, l4: 0.058400, l5: 0.063522, l6: 0.060703

[epoch:  52/100000, batch:   174/  187, ite: 4881] train loss: 0.333030, tar: 0.036608 
l0: 0.017065, l1: 0.017437, l2: 0.032898, l3: 0.029348, l4: 0.047939, l5: 0.048468, l6: 0.045946

[epoch:  52/100000, batch:   176/  187, ite: 4882] train loss: 0.332923, tar: 0.036586 
l0: 0.027914, l1: 0.027757, l2: 0.031852, l3: 0.046106, l4: 0.043205, l5: 0.036876, l6: 0.037076

[epoch:  52/100000, batch:   178/  187, ite: 4883] train loss: 0.332830, tar: 0.036576 
l0: 0.026558, l1: 0.022734, l2: 0.043335, l3: 0.048402, l4: 0.054050, l5: 0.054164, l6: 0.042430

[epoch:  52/100000, batch:   180/  187, ite: 4884] train loss: 0.332783, tar: 0.036565 
l0: 0.029993, l1: 0.031556, l2: 0.033134, l3: 0.035085, l4: 0.063199, l5: 0.061430, l6: 0.058171

[epoch:  52/100000, batch:   182/  187, ite: 4885] train loss: 0.332761, tar: 0.036557 
l0: 0.012437, l1: 0.016069, l2: 0.018193, l3: 0.019251, l4: 0.048011, l5: 0.037490, l6: 0.041467

[epoch:  52/100000, batch:   184/  187, ite: 4886] train loss: 0.332603, tar: 0.036530 
l0: 0.030175, l1: 0.030335, l2: 0.040458, l3: 0.044524, l4: 0.057994, l5: 0.049722, l6: 0.043475

[epoch:  52/100000, batch:   186/  187, ite: 4887] train loss: 0.332562, tar: 0.036523 
l0: 0.032518, l1: 0.037057, l2: 0.044703, l3: 0.033832, l4: 0.042864, l5: 0.038300, l6: 0.052173

[epoch:  52/100000, batch:   188/  187, ite: 4888] train loss: 0.332505, tar: 0.036518 
l0: 0.026344, l1: 0.027127, l2: 0.034092, l3: 0.034902, l4: 0.042947, l5: 0.036850, l6: 0.034922

[epoch:  53/100000, batch:     2/  187, ite: 4889] train loss: 0.332398, tar: 0.036507 
l0: 0.025337, l1: 0.034735, l2: 0.023559, l3: 0.019049, l4: 0.051485, l5: 0.041103, l6: 0.036053

[epoch:  53/100000, batch:     4/  187, ite: 4890] train loss: 0.332284, tar: 0.036494 
l0: 0.031774, l1: 0.035884, l2: 0.035012, l3: 0.028414, l4: 0.033583, l5: 0.030639, l6: 0.033236

[epoch:  53/100000, batch:     6/  187, ite: 4891] train loss: 0.332168, tar: 0.036489 
l0: 0.019029, l1: 0.021026, l2: 0.022049, l3: 0.022261, l4: 0.030654, l5: 0.032441, l6: 0.030449

[epoch:  53/100000, batch:     8/  187, ite: 4892] train loss: 0.331995, tar: 0.036470 
l0: 0.024699, l1: 0.026088, l2: 0.021640, l3: 0.023954, l4: 0.034399, l5: 0.036552, l6: 0.040152

[epoch:  53/100000, batch:    10/  187, ite: 4893] train loss: 0.331855, tar: 0.036456 
l0: 0.020537, l1: 0.021063, l2: 0.026590, l3: 0.027606, l4: 0.031055, l5: 0.027810, l6: 0.023315

[epoch:  53/100000, batch:    12/  187, ite: 4894] train loss: 0.331683, tar: 0.036439 
l0: 0.025212, l1: 0.027872, l2: 0.028742, l3: 0.024445, l4: 0.028446, l5: 0.025051, l6: 0.030711

[epoch:  53/100000, batch:    14/  187, ite: 4895] train loss: 0.331525, tar: 0.036426 
l0: 0.031727, l1: 0.035413, l2: 0.038783, l3: 0.037865, l4: 0.044502, l5: 0.041035, l6: 0.042292

[epoch:  53/100000, batch:    16/  187, ite: 4896] train loss: 0.331458, tar: 0.036421 
l0: 0.026652, l1: 0.025502, l2: 0.029773, l3: 0.034194, l4: 0.056928, l5: 0.053407, l6: 0.057597

[epoch:  53/100000, batch:    18/  187, ite: 4897] train loss: 0.331406, tar: 0.036410 
l0: 0.023079, l1: 0.020675, l2: 0.026415, l3: 0.030276, l4: 0.050123, l5: 0.059651, l6: 0.054128

[epoch:  53/100000, batch:    20/  187, ite: 4898] train loss: 0.331331, tar: 0.036395 
l0: 0.028698, l1: 0.031408, l2: 0.028674, l3: 0.028887, l4: 0.049245, l5: 0.040861, l6: 0.044891

[epoch:  53/100000, batch:    22/  187, ite: 4899] train loss: 0.331243, tar: 0.036386 
l0: 0.021198, l1: 0.021237, l2: 0.022593, l3: 0.031086, l4: 0.030926, l5: 0.029300, l6: 0.032497

[epoch:  53/100000, batch:    24/  187, ite: 4900] train loss: 0.331085, tar: 0.036370 
l0: 0.022800, l1: 0.022874, l2: 0.027143, l3: 0.027739, l4: 0.032380, l5: 0.034128, l6: 0.033571

[epoch:  53/100000, batch:    26/  187, ite: 4901] train loss: 0.330940, tar: 0.036355 
l0: 0.020318, l1: 0.020150, l2: 0.022658, l3: 0.021538, l4: 0.034983, l5: 0.033525, l6: 0.038066

[epoch:  53/100000, batch:    28/  187, ite: 4902] train loss: 0.330785, tar: 0.036337 
l0: 0.021630, l1: 0.020508, l2: 0.044290, l3: 0.054187, l4: 0.024009, l5: 0.023240, l6: 0.025698

[epoch:  53/100000, batch:    30/  187, ite: 4903] train loss: 0.330656, tar: 0.036320 
l0: 0.024464, l1: 0.024970, l2: 0.029580, l3: 0.025464, l4: 0.029081, l5: 0.034484, l6: 0.033046

[epoch:  53/100000, batch:    32/  187, ite: 4904] train loss: 0.330512, tar: 0.036307 
l0: 0.045600, l1: 0.051286, l2: 0.043891, l3: 0.049393, l4: 0.035625, l5: 0.033580, l6: 0.036408

[epoch:  53/100000, batch:    34/  187, ite: 4905] train loss: 0.330474, tar: 0.036318 
l0: 0.033448, l1: 0.034155, l2: 0.045144, l3: 0.047449, l4: 0.034679, l5: 0.032983, l6: 0.034597

[epoch:  53/100000, batch:    36/  187, ite: 4906] train loss: 0.330399, tar: 0.036314 
l0: 0.034113, l1: 0.035811, l2: 0.031798, l3: 0.038421, l4: 0.060487, l5: 0.055711, l6: 0.045737

[epoch:  53/100000, batch:    38/  187, ite: 4907] train loss: 0.330368, tar: 0.036312 
l0: 0.023179, l1: 0.024362, l2: 0.028888, l3: 0.038026, l4: 0.031925, l5: 0.023660, l6: 0.022081

[epoch:  53/100000, batch:    40/  187, ite: 4908] train loss: 0.330215, tar: 0.036298 
l0: 0.029545, l1: 0.028733, l2: 0.024390, l3: 0.028765, l4: 0.048447, l5: 0.065444, l6: 0.077771

[epoch:  53/100000, batch:    42/  187, ite: 4909] train loss: 0.330186, tar: 0.036290 
l0: 0.019713, l1: 0.019225, l2: 0.030637, l3: 0.033610, l4: 0.040583, l5: 0.041885, l6: 0.042235

[epoch:  53/100000, batch:    44/  187, ite: 4910] train loss: 0.330073, tar: 0.036272 
l0: 0.026228, l1: 0.025950, l2: 0.038980, l3: 0.036964, l4: 0.047547, l5: 0.044602, l6: 0.046618

[epoch:  53/100000, batch:    46/  187, ite: 4911] train loss: 0.330004, tar: 0.036261 
l0: 0.014649, l1: 0.015683, l2: 0.020295, l3: 0.019448, l4: 0.040369, l5: 0.036019, l6: 0.031673

[epoch:  53/100000, batch:    48/  187, ite: 4912] train loss: 0.329837, tar: 0.036237 
l0: 0.022549, l1: 0.025825, l2: 0.025528, l3: 0.034163, l4: 0.042442, l5: 0.036625, l6: 0.036771

[epoch:  53/100000, batch:    50/  187, ite: 4913] train loss: 0.329721, tar: 0.036222 
l0: 0.035056, l1: 0.037822, l2: 0.031941, l3: 0.035263, l4: 0.047219, l5: 0.046486, l6: 0.051171

[epoch:  53/100000, batch:    52/  187, ite: 4914] train loss: 0.329672, tar: 0.036221 
l0: 0.029987, l1: 0.032255, l2: 0.035554, l3: 0.033100, l4: 0.036536, l5: 0.035334, l6: 0.035523

[epoch:  53/100000, batch:    54/  187, ite: 4915] train loss: 0.329572, tar: 0.036214 
l0: 0.013893, l1: 0.014919, l2: 0.017247, l3: 0.016419, l4: 0.036129, l5: 0.033995, l6: 0.033530

[epoch:  53/100000, batch:    56/  187, ite: 4916] train loss: 0.329394, tar: 0.036190 
l0: 0.015288, l1: 0.016961, l2: 0.014801, l3: 0.016399, l4: 0.026990, l5: 0.020622, l6: 0.020383

[epoch:  53/100000, batch:    58/  187, ite: 4917] train loss: 0.329178, tar: 0.036167 
l0: 0.015401, l1: 0.016832, l2: 0.015291, l3: 0.016149, l4: 0.036490, l5: 0.038411, l6: 0.032778

[epoch:  53/100000, batch:    60/  187, ite: 4918] train loss: 0.329006, tar: 0.036144 
l0: 0.044098, l1: 0.044638, l2: 0.054978, l3: 0.054100, l4: 0.046437, l5: 0.044175, l6: 0.049120

[epoch:  53/100000, batch:    62/  187, ite: 4919] train loss: 0.329015, tar: 0.036153 
l0: 0.033452, l1: 0.032339, l2: 0.034117, l3: 0.034982, l4: 0.047029, l5: 0.053351, l6: 0.054587

[epoch:  53/100000, batch:    64/  187, ite: 4920] train loss: 0.328973, tar: 0.036150 
l0: 0.016987, l1: 0.017164, l2: 0.016561, l3: 0.019176, l4: 0.041639, l5: 0.042908, l6: 0.046205

[epoch:  53/100000, batch:    66/  187, ite: 4921] train loss: 0.328834, tar: 0.036129 
l0: 0.017552, l1: 0.021833, l2: 0.029375, l3: 0.031350, l4: 0.038276, l5: 0.033730, l6: 0.028553

[epoch:  53/100000, batch:    68/  187, ite: 4922] train loss: 0.328695, tar: 0.036109 
l0: 0.023144, l1: 0.019442, l2: 0.031148, l3: 0.033265, l4: 0.057297, l5: 0.068516, l6: 0.069693

[epoch:  53/100000, batch:    70/  187, ite: 4923] train loss: 0.328666, tar: 0.036095 
l0: 0.027760, l1: 0.029815, l2: 0.022346, l3: 0.028489, l4: 0.032401, l5: 0.039826, l6: 0.037783

[epoch:  53/100000, batch:    72/  187, ite: 4924] train loss: 0.328547, tar: 0.036086 
l0: 0.030698, l1: 0.030257, l2: 0.030699, l3: 0.028629, l4: 0.046299, l5: 0.064213, l6: 0.066059

[epoch:  53/100000, batch:    74/  187, ite: 4925] train loss: 0.328513, tar: 0.036080 
l0: 0.018089, l1: 0.017632, l2: 0.022720, l3: 0.023931, l4: 0.025184, l5: 0.024888, l6: 0.021684

[epoch:  53/100000, batch:    76/  187, ite: 4926] train loss: 0.328324, tar: 0.036061 
l0: 0.021026, l1: 0.020007, l2: 0.019923, l3: 0.024221, l4: 0.030023, l5: 0.032127, l6: 0.030421

[epoch:  53/100000, batch:    78/  187, ite: 4927] train loss: 0.328162, tar: 0.036045 
l0: 0.013633, l1: 0.013771, l2: 0.019819, l3: 0.018214, l4: 0.020167, l5: 0.026454, l6: 0.026784

[epoch:  53/100000, batch:    80/  187, ite: 4928] train loss: 0.327958, tar: 0.036020 
l0: 0.046910, l1: 0.050472, l2: 0.039354, l3: 0.039127, l4: 0.057528, l5: 0.065630, l6: 0.059705

[epoch:  53/100000, batch:    82/  187, ite: 4929] train loss: 0.327991, tar: 0.036032 
l0: 0.017323, l1: 0.017648, l2: 0.020647, l3: 0.023682, l4: 0.043609, l5: 0.041053, l6: 0.041350

[epoch:  53/100000, batch:    84/  187, ite: 4930] train loss: 0.327859, tar: 0.036012 
l0: 0.021299, l1: 0.027556, l2: 0.025859, l3: 0.015831, l4: 0.018781, l5: 0.022342, l6: 0.020352

[epoch:  53/100000, batch:    86/  187, ite: 4931] train loss: 0.327670, tar: 0.035996 
l0: 0.024369, l1: 0.027616, l2: 0.020064, l3: 0.020406, l4: 0.055772, l5: 0.054066, l6: 0.060105

[epoch:  53/100000, batch:    88/  187, ite: 4932] train loss: 0.327600, tar: 0.035984 
l0: 0.020874, l1: 0.022031, l2: 0.029077, l3: 0.031723, l4: 0.033924, l5: 0.034152, l6: 0.031724

[epoch:  53/100000, batch:    90/  187, ite: 4933] train loss: 0.327467, tar: 0.035968 
l0: 0.038666, l1: 0.036935, l2: 0.034618, l3: 0.034454, l4: 0.076576, l5: 0.078227, l6: 0.079362

[epoch:  53/100000, batch:    92/  187, ite: 4934] train loss: 0.327522, tar: 0.035970 
l0: 0.017995, l1: 0.017099, l2: 0.029973, l3: 0.035087, l4: 0.033724, l5: 0.034779, l6: 0.036667

[epoch:  53/100000, batch:    94/  187, ite: 4935] train loss: 0.327391, tar: 0.035951 
l0: 0.028424, l1: 0.026947, l2: 0.044443, l3: 0.039172, l4: 0.067808, l5: 0.058224, l6: 0.062440

[epoch:  53/100000, batch:    96/  187, ite: 4936] train loss: 0.327392, tar: 0.035943 
l0: 0.031467, l1: 0.032171, l2: 0.025587, l3: 0.035883, l4: 0.052666, l5: 0.045891, l6: 0.049260

[epoch:  53/100000, batch:    98/  187, ite: 4937] train loss: 0.327333, tar: 0.035938 
l0: 0.013762, l1: 0.012514, l2: 0.014883, l3: 0.017625, l4: 0.028047, l5: 0.030639, l6: 0.038008

[epoch:  53/100000, batch:   100/  187, ite: 4938] train loss: 0.327150, tar: 0.035915 
l0: 0.019228, l1: 0.017660, l2: 0.027583, l3: 0.029197, l4: 0.055013, l5: 0.046373, l6: 0.047003

[epoch:  53/100000, batch:   102/  187, ite: 4939] train loss: 0.327060, tar: 0.035897 
l0: 0.031141, l1: 0.029543, l2: 0.045311, l3: 0.040342, l4: 0.047649, l5: 0.049709, l6: 0.056537

[epoch:  53/100000, batch:   104/  187, ite: 4940] train loss: 0.327031, tar: 0.035892 
l0: 0.030616, l1: 0.032916, l2: 0.032595, l3: 0.036334, l4: 0.039727, l5: 0.038176, l6: 0.042029

[epoch:  53/100000, batch:   106/  187, ite: 4941] train loss: 0.326952, tar: 0.035886 
l0: 0.037898, l1: 0.035146, l2: 0.053413, l3: 0.051312, l4: 0.059530, l5: 0.058690, l6: 0.068386

[epoch:  53/100000, batch:   108/  187, ite: 4942] train loss: 0.326991, tar: 0.035888 
l0: 0.029926, l1: 0.031074, l2: 0.023842, l3: 0.025413, l4: 0.028441, l5: 0.040275, l6: 0.035420

[epoch:  53/100000, batch:   110/  187, ite: 4943] train loss: 0.326872, tar: 0.035882 
l0: 0.026089, l1: 0.022694, l2: 0.030216, l3: 0.037564, l4: 0.079930, l5: 0.080544, l6: 0.079188

[epoch:  53/100000, batch:   112/  187, ite: 4944] train loss: 0.326903, tar: 0.035872 
l0: 0.026580, l1: 0.027205, l2: 0.034401, l3: 0.033273, l4: 0.040197, l5: 0.040583, l6: 0.037407

[epoch:  53/100000, batch:   114/  187, ite: 4945] train loss: 0.326811, tar: 0.035862 
l0: 0.024888, l1: 0.025979, l2: 0.022917, l3: 0.023798, l4: 0.040656, l5: 0.044984, l6: 0.042471

[epoch:  53/100000, batch:   116/  187, ite: 4946] train loss: 0.326704, tar: 0.035850 
l0: 0.028802, l1: 0.038174, l2: 0.025585, l3: 0.021722, l4: 0.042304, l5: 0.058754, l6: 0.055694

[epoch:  53/100000, batch:   118/  187, ite: 4947] train loss: 0.326645, tar: 0.035843 
l0: 0.024222, l1: 0.023609, l2: 0.030415, l3: 0.036515, l4: 0.075171, l5: 0.072538, l6: 0.057382

[epoch:  53/100000, batch:   120/  187, ite: 4948] train loss: 0.326638, tar: 0.035831 
l0: 0.022064, l1: 0.019810, l2: 0.026818, l3: 0.035879, l4: 0.040948, l5: 0.041497, l6: 0.047864

[epoch:  53/100000, batch:   122/  187, ite: 4949] train loss: 0.326541, tar: 0.035816 
l0: 0.022246, l1: 0.020975, l2: 0.029879, l3: 0.028117, l4: 0.036063, l5: 0.041125, l6: 0.040121

[epoch:  53/100000, batch:   124/  187, ite: 4950] train loss: 0.326428, tar: 0.035802 
l0: 0.027152, l1: 0.023715, l2: 0.037681, l3: 0.043743, l4: 0.044543, l5: 0.043056, l6: 0.043552

[epoch:  53/100000, batch:   126/  187, ite: 4951] train loss: 0.326361, tar: 0.035793 
l0: 0.053238, l1: 0.053535, l2: 0.065945, l3: 0.057683, l4: 0.065268, l5: 0.061348, l6: 0.082605

[epoch:  53/100000, batch:   128/  187, ite: 4952] train loss: 0.326480, tar: 0.035811 
l0: 0.029080, l1: 0.033081, l2: 0.031299, l3: 0.027827, l4: 0.035308, l5: 0.037038, l6: 0.035616

[epoch:  53/100000, batch:   130/  187, ite: 4953] train loss: 0.326378, tar: 0.035804 
l0: 0.010887, l1: 0.013347, l2: 0.020657, l3: 0.020983, l4: 0.027345, l5: 0.028853, l6: 0.038655

[epoch:  53/100000, batch:   132/  187, ite: 4954] train loss: 0.326205, tar: 0.035778 
l0: 0.061631, l1: 0.054377, l2: 0.082318, l3: 0.074112, l4: 0.075635, l5: 0.098242, l6: 0.107873

[epoch:  53/100000, batch:   134/  187, ite: 4955] train loss: 0.326443, tar: 0.035805 
l0: 0.026473, l1: 0.026574, l2: 0.022945, l3: 0.028417, l4: 0.054756, l5: 0.060293, l6: 0.061476

[epoch:  53/100000, batch:   136/  187, ite: 4956] train loss: 0.326396, tar: 0.035795 
l0: 0.026630, l1: 0.027046, l2: 0.030909, l3: 0.027339, l4: 0.038461, l5: 0.036704, l6: 0.044674

[epoch:  53/100000, batch:   138/  187, ite: 4957] train loss: 0.326297, tar: 0.035786 
l0: 0.018727, l1: 0.019853, l2: 0.023536, l3: 0.022831, l4: 0.039905, l5: 0.038859, l6: 0.045807

[epoch:  53/100000, batch:   140/  187, ite: 4958] train loss: 0.326175, tar: 0.035768 
l0: 0.057187, l1: 0.060983, l2: 0.055761, l3: 0.053922, l4: 0.069406, l5: 0.066597, l6: 0.062006

[epoch:  53/100000, batch:   142/  187, ite: 4959] train loss: 0.326279, tar: 0.035790 
l0: 0.029315, l1: 0.029530, l2: 0.035864, l3: 0.036634, l4: 0.047117, l5: 0.041144, l6: 0.055289

[epoch:  53/100000, batch:   144/  187, ite: 4960] train loss: 0.326225, tar: 0.035783 
l0: 0.025882, l1: 0.025573, l2: 0.036504, l3: 0.034310, l4: 0.048533, l5: 0.045718, l6: 0.041669

[epoch:  53/100000, batch:   146/  187, ite: 4961] train loss: 0.326155, tar: 0.035773 
l0: 0.026767, l1: 0.024234, l2: 0.033588, l3: 0.034378, l4: 0.056787, l5: 0.058003, l6: 0.063401

[epoch:  53/100000, batch:   148/  187, ite: 4962] train loss: 0.326124, tar: 0.035764 
l0: 0.024099, l1: 0.023620, l2: 0.026248, l3: 0.033765, l4: 0.044383, l5: 0.034520, l6: 0.045034

[epoch:  53/100000, batch:   150/  187, ite: 4963] train loss: 0.326026, tar: 0.035752 
l0: 0.042337, l1: 0.047472, l2: 0.041766, l3: 0.041742, l4: 0.044648, l5: 0.051623, l6: 0.058052

[epoch:  53/100000, batch:   152/  187, ite: 4964] train loss: 0.326028, tar: 0.035758 
l0: 0.033889, l1: 0.038579, l2: 0.031348, l3: 0.028653, l4: 0.036168, l5: 0.034210, l6: 0.037492

[epoch:  53/100000, batch:   154/  187, ite: 4965] train loss: 0.325939, tar: 0.035756 
l0: 0.046763, l1: 0.040725, l2: 0.064413, l3: 0.067324, l4: 0.098892, l5: 0.114846, l6: 0.111077

[epoch:  53/100000, batch:   156/  187, ite: 4966] train loss: 0.326165, tar: 0.035768 
l0: 0.046375, l1: 0.052181, l2: 0.051984, l3: 0.049973, l4: 0.029427, l5: 0.029806, l6: 0.051127

[epoch:  53/100000, batch:   158/  187, ite: 4967] train loss: 0.326149, tar: 0.035779 
l0: 0.075391, l1: 0.075621, l2: 0.063098, l3: 0.067411, l4: 0.092178, l5: 0.104823, l6: 0.140346

[epoch:  53/100000, batch:   160/  187, ite: 4968] train loss: 0.326452, tar: 0.035820 
l0: 0.022797, l1: 0.025258, l2: 0.033629, l3: 0.027497, l4: 0.039040, l5: 0.037790, l6: 0.034585

[epoch:  53/100000, batch:   162/  187, ite: 4969] train loss: 0.326342, tar: 0.035806 
l0: 0.020963, l1: 0.018799, l2: 0.035080, l3: 0.036674, l4: 0.038471, l5: 0.047206, l6: 0.050564

[epoch:  53/100000, batch:   164/  187, ite: 4970] train loss: 0.326261, tar: 0.035791 
l0: 0.033040, l1: 0.035025, l2: 0.039024, l3: 0.036234, l4: 0.061382, l5: 0.060293, l6: 0.052383

[epoch:  53/100000, batch:   166/  187, ite: 4971] train loss: 0.326252, tar: 0.035788 
l0: 0.032184, l1: 0.029944, l2: 0.046015, l3: 0.051841, l4: 0.045682, l5: 0.047059, l6: 0.050810

[epoch:  53/100000, batch:   168/  187, ite: 4972] train loss: 0.326229, tar: 0.035784 
l0: 0.025706, l1: 0.026341, l2: 0.039727, l3: 0.035153, l4: 0.054129, l5: 0.052166, l6: 0.044677

[epoch:  53/100000, batch:   170/  187, ite: 4973] train loss: 0.326179, tar: 0.035774 
l0: 0.022705, l1: 0.024630, l2: 0.027006, l3: 0.023086, l4: 0.038177, l5: 0.041949, l6: 0.034571

[epoch:  53/100000, batch:   172/  187, ite: 4974] train loss: 0.326062, tar: 0.035761 
l0: 0.026334, l1: 0.024554, l2: 0.040967, l3: 0.040364, l4: 0.037500, l5: 0.038766, l6: 0.047685

[epoch:  53/100000, batch:   174/  187, ite: 4975] train loss: 0.325990, tar: 0.035751 
l0: 0.050641, l1: 0.053511, l2: 0.048775, l3: 0.046299, l4: 0.059903, l5: 0.052512, l6: 0.073365

[epoch:  53/100000, batch:   176/  187, ite: 4976] train loss: 0.326051, tar: 0.035766 
l0: 0.013670, l1: 0.013134, l2: 0.022817, l3: 0.023613, l4: 0.042619, l5: 0.042923, l6: 0.042023

[epoch:  53/100000, batch:   178/  187, ite: 4977] train loss: 0.325923, tar: 0.035744 
l0: 0.031534, l1: 0.035770, l2: 0.035999, l3: 0.035371, l4: 0.038767, l5: 0.035296, l6: 0.036273

[epoch:  53/100000, batch:   180/  187, ite: 4978] train loss: 0.325844, tar: 0.035739 
l0: 0.019877, l1: 0.021496, l2: 0.023924, l3: 0.031076, l4: 0.031529, l5: 0.036408, l6: 0.027862

[epoch:  53/100000, batch:   182/  187, ite: 4979] train loss: 0.325707, tar: 0.035723 
l0: 0.022502, l1: 0.020405, l2: 0.032951, l3: 0.032975, l4: 0.040626, l5: 0.041775, l6: 0.044161

[epoch:  53/100000, batch:   184/  187, ite: 4980] train loss: 0.325615, tar: 0.035710 
l0: 0.041940, l1: 0.042433, l2: 0.049503, l3: 0.051388, l4: 0.061724, l5: 0.066866, l6: 0.062745

[epoch:  53/100000, batch:   186/  187, ite: 4981] train loss: 0.325667, tar: 0.035716 
l0: 0.026668, l1: 0.026080, l2: 0.024764, l3: 0.028180, l4: 0.042100, l5: 0.047940, l6: 0.051847

[epoch:  53/100000, batch:   188/  187, ite: 4982] train loss: 0.325588, tar: 0.035707 
l0: 0.028439, l1: 0.029216, l2: 0.031166, l3: 0.035355, l4: 0.060864, l5: 0.049468, l6: 0.044009

[epoch:  54/100000, batch:     2/  187, ite: 4983] train loss: 0.325540, tar: 0.035699 
l0: 0.026486, l1: 0.024858, l2: 0.036897, l3: 0.038071, l4: 0.040615, l5: 0.040274, l6: 0.047963

[epoch:  54/100000, batch:     4/  187, ite: 4984] train loss: 0.325468, tar: 0.035690 
l0: 0.019576, l1: 0.020257, l2: 0.023854, l3: 0.022876, l4: 0.044452, l5: 0.044390, l6: 0.047499

[epoch:  54/100000, batch:     6/  187, ite: 4985] train loss: 0.325364, tar: 0.035674 
l0: 0.046101, l1: 0.050226, l2: 0.036407, l3: 0.043998, l4: 0.060951, l5: 0.060088, l6: 0.081877

[epoch:  54/100000, batch:     8/  187, ite: 4986] train loss: 0.325419, tar: 0.035684 
l0: 0.038138, l1: 0.040074, l2: 0.035690, l3: 0.033101, l4: 0.053821, l5: 0.054549, l6: 0.070494

[epoch:  54/100000, batch:    10/  187, ite: 4987] train loss: 0.325420, tar: 0.035687 
l0: 0.026796, l1: 0.026535, l2: 0.031372, l3: 0.034668, l4: 0.047611, l5: 0.040236, l6: 0.052852

[epoch:  54/100000, batch:    12/  187, ite: 4988] train loss: 0.325354, tar: 0.035678 
l0: 0.025849, l1: 0.027034, l2: 0.027069, l3: 0.027939, l4: 0.040406, l5: 0.036382, l6: 0.044891

[epoch:  54/100000, batch:    14/  187, ite: 4989] train loss: 0.325257, tar: 0.035668 
l0: 0.030349, l1: 0.028115, l2: 0.028755, l3: 0.034353, l4: 0.071852, l5: 0.080726, l6: 0.053054

[epoch:  54/100000, batch:    16/  187, ite: 4990] train loss: 0.325259, tar: 0.035662 
l0: 0.022093, l1: 0.020676, l2: 0.025359, l3: 0.027216, l4: 0.053142, l5: 0.061677, l6: 0.048548

[epoch:  54/100000, batch:    18/  187, ite: 4991] train loss: 0.325192, tar: 0.035649 
l0: 0.018003, l1: 0.018887, l2: 0.018653, l3: 0.019163, l4: 0.044448, l5: 0.040801, l6: 0.032752

[epoch:  54/100000, batch:    20/  187, ite: 4992] train loss: 0.325058, tar: 0.035631 
l0: 0.022414, l1: 0.022414, l2: 0.028100, l3: 0.032842, l4: 0.054515, l5: 0.045280, l6: 0.043457

[epoch:  54/100000, batch:    22/  187, ite: 4993] train loss: 0.324981, tar: 0.035618 
l0: 0.020524, l1: 0.019473, l2: 0.023528, l3: 0.021466, l4: 0.036954, l5: 0.041957, l6: 0.041029

[epoch:  54/100000, batch:    24/  187, ite: 4994] train loss: 0.324861, tar: 0.035602 
l0: 0.015884, l1: 0.016862, l2: 0.016383, l3: 0.019028, l4: 0.062163, l5: 0.049437, l6: 0.056357

[epoch:  54/100000, batch:    26/  187, ite: 4995] train loss: 0.324771, tar: 0.035583 
l0: 0.025820, l1: 0.025196, l2: 0.027538, l3: 0.032023, l4: 0.041006, l5: 0.040058, l6: 0.043879

[epoch:  54/100000, batch:    28/  187, ite: 4996] train loss: 0.324682, tar: 0.035573 
l0: 0.032795, l1: 0.030589, l2: 0.039148, l3: 0.045527, l4: 0.057259, l5: 0.063940, l6: 0.065655

[epoch:  54/100000, batch:    30/  187, ite: 4997] train loss: 0.324692, tar: 0.035570 
l0: 0.024026, l1: 0.022936, l2: 0.030351, l3: 0.033316, l4: 0.037704, l5: 0.040336, l6: 0.040348

[epoch:  54/100000, batch:    32/  187, ite: 4998] train loss: 0.324596, tar: 0.035558 
l0: 0.043500, l1: 0.044561, l2: 0.048012, l3: 0.041160, l4: 0.073069, l5: 0.071818, l6: 0.069363

[epoch:  54/100000, batch:    34/  187, ite: 4999] train loss: 0.324663, tar: 0.035566 
l0: 0.029354, l1: 0.033046, l2: 0.025830, l3: 0.022910, l4: 0.031690, l5: 0.032094, l6: 0.037872

[epoch:  54/100000, batch:    36/  187, ite: 5000] train loss: 0.324551, tar: 0.035560 
l0: 0.033304, l1: 0.031826, l2: 0.046239, l3: 0.042260, l4: 0.068164, l5: 0.067176, l6: 0.054726

[epoch:  54/100000, batch:    38/  187, ite: 5001] train loss: 0.324570, tar: 0.035558 
l0: 0.019710, l1: 0.018806, l2: 0.024233, l3: 0.026488, l4: 0.050264, l5: 0.051442, l6: 0.039624

[epoch:  54/100000, batch:    40/  187, ite: 5002] train loss: 0.324477, tar: 0.035542 
l0: 0.034594, l1: 0.030992, l2: 0.043019, l3: 0.051002, l4: 0.065611, l5: 0.070999, l6: 0.077014

[epoch:  54/100000, batch:    42/  187, ite: 5003] train loss: 0.324525, tar: 0.035541 
l0: 0.025147, l1: 0.025236, l2: 0.028931, l3: 0.036081, l4: 0.037029, l5: 0.036910, l6: 0.041368

[epoch:  54/100000, batch:    44/  187, ite: 5004] train loss: 0.324432, tar: 0.035531 
l0: 0.023490, l1: 0.026474, l2: 0.026374, l3: 0.024962, l4: 0.031144, l5: 0.031819, l6: 0.035841

[epoch:  54/100000, batch:    46/  187, ite: 5005] train loss: 0.324308, tar: 0.035519 
l0: 0.012821, l1: 0.016603, l2: 0.033122, l3: 0.017191, l4: 0.030508, l5: 0.038151, l6: 0.033945

[epoch:  54/100000, batch:    48/  187, ite: 5006] train loss: 0.324167, tar: 0.035496 
l0: 0.029133, l1: 0.027033, l2: 0.044037, l3: 0.043671, l4: 0.054421, l5: 0.057315, l6: 0.040149

[epoch:  54/100000, batch:    50/  187, ite: 5007] train loss: 0.324139, tar: 0.035490 
l0: 0.018910, l1: 0.017351, l2: 0.022575, l3: 0.024000, l4: 0.048620, l5: 0.038365, l6: 0.044935

[epoch:  54/100000, batch:    52/  187, ite: 5008] train loss: 0.324030, tar: 0.035474 
l0: 0.020974, l1: 0.023022, l2: 0.032562, l3: 0.023527, l4: 0.034770, l5: 0.037480, l6: 0.045930

[epoch:  54/100000, batch:    54/  187, ite: 5009] train loss: 0.323925, tar: 0.035459 
l0: 0.018373, l1: 0.019968, l2: 0.021014, l3: 0.016186, l4: 0.034866, l5: 0.036475, l6: 0.021857

[epoch:  54/100000, batch:    56/  187, ite: 5010] train loss: 0.323772, tar: 0.035442 
l0: 0.033493, l1: 0.032873, l2: 0.045701, l3: 0.042268, l4: 0.049750, l5: 0.055559, l6: 0.050975

[epoch:  54/100000, batch:    58/  187, ite: 5011] train loss: 0.323759, tar: 0.035440 
l0: 0.021466, l1: 0.017150, l2: 0.028766, l3: 0.037434, l4: 0.053800, l5: 0.055519, l6: 0.056199

[epoch:  54/100000, batch:    60/  187, ite: 5012] train loss: 0.323706, tar: 0.035427 
l0: 0.015732, l1: 0.015615, l2: 0.016969, l3: 0.019147, l4: 0.034035, l5: 0.031768, l6: 0.032930

[epoch:  54/100000, batch:    62/  187, ite: 5013] train loss: 0.323550, tar: 0.035407 
l0: 0.028139, l1: 0.031495, l2: 0.029723, l3: 0.028911, l4: 0.045238, l5: 0.043213, l6: 0.050905

[epoch:  54/100000, batch:    64/  187, ite: 5014] train loss: 0.323485, tar: 0.035400 
l0: 0.041330, l1: 0.041401, l2: 0.047922, l3: 0.053488, l4: 0.052872, l5: 0.058256, l6: 0.062052

[epoch:  54/100000, batch:    66/  187, ite: 5015] train loss: 0.323519, tar: 0.035406 
l0: 0.028531, l1: 0.029531, l2: 0.026785, l3: 0.035089, l4: 0.056025, l5: 0.055626, l6: 0.054659

[epoch:  54/100000, batch:    68/  187, ite: 5016] train loss: 0.323482, tar: 0.035399 
l0: 0.023644, l1: 0.022173, l2: 0.033797, l3: 0.038625, l4: 0.048801, l5: 0.049937, l6: 0.052001

[epoch:  54/100000, batch:    70/  187, ite: 5017] train loss: 0.323429, tar: 0.035387 
l0: 0.022456, l1: 0.020178, l2: 0.025341, l3: 0.031084, l4: 0.043217, l5: 0.052984, l6: 0.050145

[epoch:  54/100000, batch:    72/  187, ite: 5018] train loss: 0.323352, tar: 0.035375 
l0: 0.027804, l1: 0.027793, l2: 0.043840, l3: 0.047700, l4: 0.050100, l5: 0.043291, l6: 0.048720

[epoch:  54/100000, batch:    74/  187, ite: 5019] train loss: 0.323318, tar: 0.035367 
l0: 0.017932, l1: 0.019212, l2: 0.022541, l3: 0.026468, l4: 0.035769, l5: 0.033581, l6: 0.036053

[epoch:  54/100000, batch:    76/  187, ite: 5020] train loss: 0.323189, tar: 0.035350 
l0: 0.023007, l1: 0.021927, l2: 0.027017, l3: 0.030745, l4: 0.066583, l5: 0.053235, l6: 0.061384

[epoch:  54/100000, batch:    78/  187, ite: 5021] train loss: 0.323151, tar: 0.035338 
l0: 0.022670, l1: 0.022416, l2: 0.025947, l3: 0.033083, l4: 0.034896, l5: 0.034531, l6: 0.040411

[epoch:  54/100000, batch:    80/  187, ite: 5022] train loss: 0.323044, tar: 0.035326 
l0: 0.031644, l1: 0.032053, l2: 0.050357, l3: 0.047869, l4: 0.038865, l5: 0.050761, l6: 0.047465

[epoch:  54/100000, batch:    82/  187, ite: 5023] train loss: 0.323020, tar: 0.035322 
l0: 0.014456, l1: 0.014216, l2: 0.025567, l3: 0.025501, l4: 0.036309, l5: 0.033196, l6: 0.034240

[epoch:  54/100000, batch:    84/  187, ite: 5024] train loss: 0.322884, tar: 0.035302 
l0: 0.027462, l1: 0.030289, l2: 0.029420, l3: 0.027312, l4: 0.044730, l5: 0.044147, l6: 0.051186

[epoch:  54/100000, batch:    86/  187, ite: 5025] train loss: 0.322817, tar: 0.035294 
l0: 0.017548, l1: 0.017839, l2: 0.018369, l3: 0.020095, l4: 0.034367, l5: 0.035051, l6: 0.031794

[epoch:  54/100000, batch:    88/  187, ite: 5026] train loss: 0.322673, tar: 0.035277 
l0: 0.009716, l1: 0.008958, l2: 0.013797, l3: 0.016894, l4: 0.024779, l5: 0.028390, l6: 0.025248

[epoch:  54/100000, batch:    90/  187, ite: 5027] train loss: 0.322484, tar: 0.035252 
l0: 0.026207, l1: 0.025662, l2: 0.030748, l3: 0.031151, l4: 0.049770, l5: 0.046135, l6: 0.044360

[epoch:  54/100000, batch:    92/  187, ite: 5028] train loss: 0.322417, tar: 0.035243 
l0: 0.054981, l1: 0.052773, l2: 0.058816, l3: 0.061404, l4: 0.073211, l5: 0.069318, l6: 0.079562

[epoch:  54/100000, batch:    94/  187, ite: 5029] train loss: 0.322541, tar: 0.035262 
l0: 0.020757, l1: 0.021433, l2: 0.021710, l3: 0.022418, l4: 0.035544, l5: 0.037702, l6: 0.031536

[epoch:  54/100000, batch:    96/  187, ite: 5030] train loss: 0.322414, tar: 0.035248 
l0: 0.019051, l1: 0.020604, l2: 0.017668, l3: 0.020136, l4: 0.025559, l5: 0.029974, l6: 0.029766

[epoch:  54/100000, batch:    98/  187, ite: 5031] train loss: 0.322259, tar: 0.035233 
l0: 0.029624, l1: 0.028219, l2: 0.040932, l3: 0.043095, l4: 0.047944, l5: 0.038720, l6: 0.044747

[epoch:  54/100000, batch:   100/  187, ite: 5032] train loss: 0.322211, tar: 0.035227 
l0: 0.019968, l1: 0.020166, l2: 0.024396, l3: 0.026672, l4: 0.033773, l5: 0.036758, l6: 0.036649

[epoch:  54/100000, batch:   102/  187, ite: 5033] train loss: 0.322091, tar: 0.035212 
l0: 0.046684, l1: 0.047018, l2: 0.044291, l3: 0.067598, l4: 0.090199, l5: 0.062877, l6: 0.066959

[epoch:  54/100000, batch:   104/  187, ite: 5034] train loss: 0.322191, tar: 0.035223 
l0: 0.031884, l1: 0.032077, l2: 0.043402, l3: 0.045574, l4: 0.056708, l5: 0.051282, l6: 0.062139

[epoch:  54/100000, batch:   106/  187, ite: 5035] train loss: 0.322192, tar: 0.035220 
l0: 0.043692, l1: 0.041246, l2: 0.056363, l3: 0.056890, l4: 0.051821, l5: 0.077586, l6: 0.087030

[epoch:  54/100000, batch:   108/  187, ite: 5036] train loss: 0.322282, tar: 0.035228 
l0: 0.031091, l1: 0.039997, l2: 0.024553, l3: 0.028262, l4: 0.038174, l5: 0.038660, l6: 0.041636

[epoch:  54/100000, batch:   110/  187, ite: 5037] train loss: 0.322204, tar: 0.035224 
l0: 0.022631, l1: 0.023056, l2: 0.034555, l3: 0.036866, l4: 0.039351, l5: 0.036678, l6: 0.034512

[epoch:  54/100000, batch:   112/  187, ite: 5038] train loss: 0.322113, tar: 0.035212 
l0: 0.063768, l1: 0.066534, l2: 0.067014, l3: 0.090128, l4: 0.070855, l5: 0.064870, l6: 0.075938

[epoch:  54/100000, batch:   114/  187, ite: 5039] train loss: 0.322284, tar: 0.035240 
l0: 0.036940, l1: 0.036210, l2: 0.052248, l3: 0.053011, l4: 0.044800, l5: 0.047121, l6: 0.052873

[epoch:  54/100000, batch:   116/  187, ite: 5040] train loss: 0.322285, tar: 0.035241 
l0: 0.032115, l1: 0.036412, l2: 0.032481, l3: 0.030352, l4: 0.042800, l5: 0.038068, l6: 0.041253

[epoch:  54/100000, batch:   118/  187, ite: 5041] train loss: 0.322219, tar: 0.035238 
l0: 0.075339, l1: 0.085146, l2: 0.082982, l3: 0.085089, l4: 0.126855, l5: 0.137884, l6: 0.100169

[epoch:  54/100000, batch:   120/  187, ite: 5042] train loss: 0.322575, tar: 0.035277 
l0: 0.031285, l1: 0.029341, l2: 0.045028, l3: 0.052165, l4: 0.063056, l5: 0.059250, l6: 0.062189

[epoch:  54/100000, batch:   122/  187, ite: 5043] train loss: 0.322594, tar: 0.035273 
l0: 0.039521, l1: 0.035843, l2: 0.048792, l3: 0.051957, l4: 0.099727, l5: 0.096266, l6: 0.103225

[epoch:  54/100000, batch:   124/  187, ite: 5044] train loss: 0.322740, tar: 0.035277 
l0: 0.018828, l1: 0.019249, l2: 0.016551, l3: 0.019182, l4: 0.050951, l5: 0.047150, l6: 0.050115

[epoch:  54/100000, batch:   126/  187, ite: 5045] train loss: 0.322644, tar: 0.035261 
l0: 0.023215, l1: 0.023547, l2: 0.032532, l3: 0.039590, l4: 0.056468, l5: 0.059305, l6: 0.054479

[epoch:  54/100000, batch:   128/  187, ite: 5046] train loss: 0.322612, tar: 0.035250 
l0: 0.030283, l1: 0.031629, l2: 0.036936, l3: 0.036855, l4: 0.086589, l5: 0.078112, l6: 0.059020

[epoch:  54/100000, batch:   130/  187, ite: 5047] train loss: 0.322647, tar: 0.035245 
l0: 0.022513, l1: 0.025662, l2: 0.025509, l3: 0.032217, l4: 0.078777, l5: 0.061560, l6: 0.051098

[epoch:  54/100000, batch:   132/  187, ite: 5048] train loss: 0.322623, tar: 0.035233 
l0: 0.049851, l1: 0.046730, l2: 0.076712, l3: 0.065396, l4: 0.093655, l5: 0.089211, l6: 0.101511

[epoch:  54/100000, batch:   134/  187, ite: 5049] train loss: 0.322814, tar: 0.035247 
l0: 0.060990, l1: 0.067732, l2: 0.070025, l3: 0.057713, l4: 0.065412, l5: 0.055624, l6: 0.041864

[epoch:  54/100000, batch:   136/  187, ite: 5050] train loss: 0.322906, tar: 0.035271 
l0: 0.046478, l1: 0.044537, l2: 0.060465, l3: 0.063632, l4: 0.052073, l5: 0.048120, l6: 0.055843

[epoch:  54/100000, batch:   138/  187, ite: 5051] train loss: 0.322952, tar: 0.035282 
l0: 0.030426, l1: 0.037368, l2: 0.030116, l3: 0.026466, l4: 0.028930, l5: 0.027085, l6: 0.027842

[epoch:  54/100000, batch:   140/  187, ite: 5052] train loss: 0.322843, tar: 0.035277 
l0: 0.017154, l1: 0.021970, l2: 0.024484, l3: 0.025251, l4: 0.032721, l5: 0.036143, l6: 0.037508

[epoch:  54/100000, batch:   142/  187, ite: 5053] train loss: 0.322721, tar: 0.035260 
l0: 0.036223, l1: 0.033788, l2: 0.053383, l3: 0.058814, l4: 0.055215, l5: 0.047255, l6: 0.057564

[epoch:  54/100000, batch:   144/  187, ite: 5054] train loss: 0.322740, tar: 0.035261 
l0: 0.050179, l1: 0.048785, l2: 0.077284, l3: 0.075418, l4: 0.069271, l5: 0.059075, l6: 0.049545

[epoch:  54/100000, batch:   146/  187, ite: 5055] train loss: 0.322841, tar: 0.035275 
l0: 0.043412, l1: 0.045664, l2: 0.059344, l3: 0.062772, l4: 0.045255, l5: 0.042223, l6: 0.044597

[epoch:  54/100000, batch:   148/  187, ite: 5056] train loss: 0.322860, tar: 0.035283 
l0: 0.036153, l1: 0.035562, l2: 0.044377, l3: 0.047537, l4: 0.068309, l5: 0.059298, l6: 0.055631

[epoch:  54/100000, batch:   150/  187, ite: 5057] train loss: 0.322883, tar: 0.035284 
l0: 0.034537, l1: 0.033883, l2: 0.044575, l3: 0.044511, l4: 0.045144, l5: 0.043414, l6: 0.046703

[epoch:  54/100000, batch:   152/  187, ite: 5058] train loss: 0.322855, tar: 0.035283 
l0: 0.027069, l1: 0.026713, l2: 0.039007, l3: 0.041143, l4: 0.047403, l5: 0.045764, l6: 0.038581

[epoch:  54/100000, batch:   154/  187, ite: 5059] train loss: 0.322801, tar: 0.035275 
l0: 0.055258, l1: 0.059931, l2: 0.070853, l3: 0.066555, l4: 0.050584, l5: 0.053176, l6: 0.063641

[epoch:  54/100000, batch:   156/  187, ite: 5060] train loss: 0.322892, tar: 0.035294 
l0: 0.034959, l1: 0.027748, l2: 0.061675, l3: 0.081803, l4: 0.080633, l5: 0.071156, l6: 0.080218

[epoch:  54/100000, batch:   158/  187, ite: 5061] train loss: 0.323001, tar: 0.035294 
l0: 0.041410, l1: 0.043403, l2: 0.063199, l3: 0.067581, l4: 0.062384, l5: 0.057626, l6: 0.056462

[epoch:  54/100000, batch:   160/  187, ite: 5062] train loss: 0.323066, tar: 0.035300 
l0: 0.036507, l1: 0.034121, l2: 0.055507, l3: 0.058430, l4: 0.052957, l5: 0.060281, l6: 0.077988

[epoch:  54/100000, batch:   162/  187, ite: 5063] train loss: 0.323116, tar: 0.035301 
l0: 0.022112, l1: 0.022309, l2: 0.031364, l3: 0.034782, l4: 0.044439, l5: 0.037953, l6: 0.031546

[epoch:  54/100000, batch:   164/  187, ite: 5064] train loss: 0.323023, tar: 0.035288 
l0: 0.021879, l1: 0.021810, l2: 0.029727, l3: 0.033829, l4: 0.036778, l5: 0.033052, l6: 0.042244

[epoch:  54/100000, batch:   166/  187, ite: 5065] train loss: 0.322926, tar: 0.035276 
l0: 0.173422, l1: 0.174408, l2: 0.243759, l3: 0.195520, l4: 0.263118, l5: 0.213073, l6: 0.231373

[epoch:  54/100000, batch:   168/  187, ite: 5066] train loss: 0.324025, tar: 0.035405 
l0: 0.021056, l1: 0.022031, l2: 0.023587, l3: 0.026720, l4: 0.039849, l5: 0.041188, l6: 0.043359

[epoch:  54/100000, batch:   170/  187, ite: 5067] train loss: 0.323925, tar: 0.035392 
l0: 0.031030, l1: 0.036163, l2: 0.036922, l3: 0.034979, l4: 0.056721, l5: 0.057578, l6: 0.062142

[epoch:  54/100000, batch:   172/  187, ite: 5068] train loss: 0.323917, tar: 0.035388 
l0: 0.034044, l1: 0.038321, l2: 0.049574, l3: 0.051959, l4: 0.063315, l5: 0.056744, l6: 0.064078

[epoch:  54/100000, batch:   174/  187, ite: 5069] train loss: 0.323949, tar: 0.035387 
l0: 0.024479, l1: 0.022791, l2: 0.035137, l3: 0.031621, l4: 0.050017, l5: 0.060881, l6: 0.060226

[epoch:  54/100000, batch:   176/  187, ite: 5070] train loss: 0.323913, tar: 0.035376 
l0: 0.052000, l1: 0.050259, l2: 0.060664, l3: 0.087880, l4: 0.120849, l5: 0.091872, l6: 0.086556

[epoch:  54/100000, batch:   178/  187, ite: 5071] train loss: 0.324124, tar: 0.035392 
l0: 0.058951, l1: 0.062366, l2: 0.079825, l3: 0.082385, l4: 0.140517, l5: 0.112135, l6: 0.120282

[epoch:  54/100000, batch:   180/  187, ite: 5072] train loss: 0.324434, tar: 0.035414 
l0: 0.051364, l1: 0.048977, l2: 0.062405, l3: 0.095874, l4: 0.120274, l5: 0.087981, l6: 0.080456

[epoch:  54/100000, batch:   182/  187, ite: 5073] train loss: 0.324642, tar: 0.035429 
l0: 0.045121, l1: 0.046904, l2: 0.057294, l3: 0.060945, l4: 0.056640, l5: 0.057010, l6: 0.048960

[epoch:  54/100000, batch:   184/  187, ite: 5074] train loss: 0.324687, tar: 0.035438 
l0: 0.021009, l1: 0.022604, l2: 0.028290, l3: 0.027411, l4: 0.040077, l5: 0.040468, l6: 0.043841

[epoch:  54/100000, batch:   186/  187, ite: 5075] train loss: 0.324593, tar: 0.035424 
l0: 0.064154, l1: 0.069489, l2: 0.112632, l3: 0.112677, l4: 0.089632, l5: 0.068263, l6: 0.052423

[epoch:  54/100000, batch:   188/  187, ite: 5076] train loss: 0.324820, tar: 0.035451 
l0: 0.053486, l1: 0.063945, l2: 0.055785, l3: 0.069810, l4: 0.081804, l5: 0.103439, l6: 0.086640

[epoch:  55/100000, batch:     2/  187, ite: 5077] train loss: 0.324997, tar: 0.035468 
l0: 0.028111, l1: 0.030709, l2: 0.036050, l3: 0.039054, l4: 0.048045, l5: 0.061645, l6: 0.054735

[epoch:  55/100000, batch:     4/  187, ite: 5078] train loss: 0.324972, tar: 0.035461 
l0: 0.026318, l1: 0.022815, l2: 0.058828, l3: 0.065645, l4: 0.058378, l5: 0.059653, l6: 0.060317

[epoch:  55/100000, batch:     6/  187, ite: 5079] train loss: 0.324997, tar: 0.035452 
l0: 0.060963, l1: 0.074814, l2: 0.061281, l3: 0.066558, l4: 0.072279, l5: 0.068972, l6: 0.079653

[epoch:  55/100000, batch:     8/  187, ite: 5080] train loss: 0.325145, tar: 0.035476 
l0: 0.075675, l1: 0.069542, l2: 0.084668, l3: 0.092894, l4: 0.125440, l5: 0.139284, l6: 0.191009

[epoch:  55/100000, batch:    10/  187, ite: 5081] train loss: 0.325564, tar: 0.035513 
l0: 0.033354, l1: 0.034503, l2: 0.043884, l3: 0.045551, l4: 0.054959, l5: 0.052672, l6: 0.052565

[epoch:  55/100000, batch:    12/  187, ite: 5082] train loss: 0.325557, tar: 0.035511 
l0: 0.029248, l1: 0.030390, l2: 0.042468, l3: 0.048172, l4: 0.058620, l5: 0.054645, l6: 0.059498

[epoch:  55/100000, batch:    14/  187, ite: 5083] train loss: 0.325554, tar: 0.035506 
l0: 0.056144, l1: 0.050843, l2: 0.082345, l3: 0.079257, l4: 0.075402, l5: 0.104388, l6: 0.118358

[epoch:  55/100000, batch:    16/  187, ite: 5084] train loss: 0.325777, tar: 0.035525 
l0: 0.054308, l1: 0.047238, l2: 0.076655, l3: 0.092588, l4: 0.149365, l5: 0.142797, l6: 0.117362

[epoch:  55/100000, batch:    18/  187, ite: 5085] train loss: 0.326104, tar: 0.035542 
l0: 0.041100, l1: 0.057721, l2: 0.038446, l3: 0.034037, l4: 0.043165, l5: 0.035354, l6: 0.045132

[epoch:  55/100000, batch:    20/  187, ite: 5086] train loss: 0.326075, tar: 0.035547 
l0: 0.060505, l1: 0.074925, l2: 0.048702, l3: 0.044689, l4: 0.051802, l5: 0.046377, l6: 0.074899

[epoch:  55/100000, batch:    22/  187, ite: 5087] train loss: 0.326145, tar: 0.035570 
l0: 0.033466, l1: 0.033733, l2: 0.040902, l3: 0.042752, l4: 0.059524, l5: 0.060949, l6: 0.070824

[epoch:  55/100000, batch:    24/  187, ite: 5088] train loss: 0.326160, tar: 0.035568 
l0: 0.036923, l1: 0.043459, l2: 0.033273, l3: 0.042086, l4: 0.061082, l5: 0.051713, l6: 0.049340

[epoch:  55/100000, batch:    26/  187, ite: 5089] train loss: 0.326152, tar: 0.035569 
l0: 0.027324, l1: 0.026640, l2: 0.045031, l3: 0.057555, l4: 0.061043, l5: 0.045069, l6: 0.059186

[epoch:  55/100000, batch:    28/  187, ite: 5090] train loss: 0.326148, tar: 0.035562 
l0: 0.055840, l1: 0.051726, l2: 0.057256, l3: 0.069736, l4: 0.110074, l5: 0.114772, l6: 0.095415

[epoch:  55/100000, batch:    30/  187, ite: 5091] train loss: 0.326358, tar: 0.035580 
l0: 0.046160, l1: 0.044142, l2: 0.063478, l3: 0.075203, l4: 0.095720, l5: 0.094449, l6: 0.070953

[epoch:  55/100000, batch:    32/  187, ite: 5092] train loss: 0.326507, tar: 0.035590 
l0: 0.031444, l1: 0.026581, l2: 0.043036, l3: 0.052066, l4: 0.064014, l5: 0.084378, l6: 0.063129

[epoch:  55/100000, batch:    34/  187, ite: 5093] train loss: 0.326542, tar: 0.035586 
l0: 0.046869, l1: 0.055220, l2: 0.055646, l3: 0.045470, l4: 0.054397, l5: 0.049119, l6: 0.067283

[epoch:  55/100000, batch:    36/  187, ite: 5094] train loss: 0.326586, tar: 0.035596 
l0: 0.064563, l1: 0.072747, l2: 0.072471, l3: 0.053292, l4: 0.067027, l5: 0.065943, l6: 0.075971

[epoch:  55/100000, batch:    38/  187, ite: 5095] train loss: 0.326719, tar: 0.035623 
l0: 0.026705, l1: 0.027524, l2: 0.033769, l3: 0.040239, l4: 0.045087, l5: 0.044074, l6: 0.038498

[epoch:  55/100000, batch:    40/  187, ite: 5096] train loss: 0.326654, tar: 0.035615 
l0: 0.018537, l1: 0.016013, l2: 0.031971, l3: 0.045069, l4: 0.045027, l5: 0.046764, l6: 0.040766

[epoch:  55/100000, batch:    42/  187, ite: 5097] train loss: 0.326579, tar: 0.035599 
l0: 0.036013, l1: 0.036609, l2: 0.062300, l3: 0.065389, l4: 0.069957, l5: 0.061524, l6: 0.060188

[epoch:  55/100000, batch:    44/  187, ite: 5098] train loss: 0.326638, tar: 0.035600 
l0: 0.045724, l1: 0.045790, l2: 0.048683, l3: 0.049602, l4: 0.062842, l5: 0.068414, l6: 0.064359

[epoch:  55/100000, batch:    46/  187, ite: 5099] train loss: 0.326692, tar: 0.035609 
l0: 0.032548, l1: 0.036104, l2: 0.032672, l3: 0.038844, l4: 0.039564, l5: 0.035629, l6: 0.034859

[epoch:  55/100000, batch:    48/  187, ite: 5100] train loss: 0.326622, tar: 0.035606 
l0: 0.033111, l1: 0.033072, l2: 0.046060, l3: 0.042748, l4: 0.049038, l5: 0.054431, l6: 0.056399

[epoch:  55/100000, batch:    50/  187, ite: 5101] train loss: 0.326612, tar: 0.035604 
l0: 0.062515, l1: 0.065906, l2: 0.089728, l3: 0.105315, l4: 0.086013, l5: 0.090640, l6: 0.073708

[epoch:  55/100000, batch:    52/  187, ite: 5102] train loss: 0.326836, tar: 0.035628 
l0: 0.068020, l1: 0.070656, l2: 0.070237, l3: 0.068228, l4: 0.092567, l5: 0.102630, l6: 0.108208

[epoch:  55/100000, batch:    54/  187, ite: 5103] train loss: 0.327066, tar: 0.035658 
l0: 0.035857, l1: 0.036933, l2: 0.042190, l3: 0.045312, l4: 0.056086, l5: 0.051530, l6: 0.065925

[epoch:  55/100000, batch:    56/  187, ite: 5104] train loss: 0.327072, tar: 0.035658 
l0: 0.033103, l1: 0.031979, l2: 0.040071, l3: 0.040597, l4: 0.059595, l5: 0.053445, l6: 0.055204

[epoch:  55/100000, batch:    58/  187, ite: 5105] train loss: 0.327060, tar: 0.035655 
l0: 0.040714, l1: 0.042232, l2: 0.042213, l3: 0.044464, l4: 0.062363, l5: 0.069756, l6: 0.069917

[epoch:  55/100000, batch:    60/  187, ite: 5106] train loss: 0.327101, tar: 0.035660 
l0: 0.042690, l1: 0.034924, l2: 0.081822, l3: 0.088756, l4: 0.114093, l5: 0.100179, l6: 0.122475

[epoch:  55/100000, batch:    62/  187, ite: 5107] train loss: 0.327333, tar: 0.035666 
l0: 0.057464, l1: 0.061982, l2: 0.084602, l3: 0.079555, l4: 0.099359, l5: 0.078755, l6: 0.088827

[epoch:  55/100000, batch:    64/  187, ite: 5108] train loss: 0.327535, tar: 0.035686 
l0: 0.058197, l1: 0.065739, l2: 0.064214, l3: 0.063234, l4: 0.060422, l5: 0.067987, l6: 0.066209

[epoch:  55/100000, batch:    66/  187, ite: 5109] train loss: 0.327642, tar: 0.035706 
l0: 0.042493, l1: 0.034773, l2: 0.062933, l3: 0.053776, l4: 0.112097, l5: 0.124877, l6: 0.130345

[epoch:  55/100000, batch:    68/  187, ite: 5110] train loss: 0.327852, tar: 0.035712 
l0: 0.030325, l1: 0.026978, l2: 0.042259, l3: 0.045247, l4: 0.051657, l5: 0.059285, l6: 0.060151

[epoch:  55/100000, batch:    70/  187, ite: 5111] train loss: 0.327842, tar: 0.035708 
l0: 0.026159, l1: 0.025172, l2: 0.050299, l3: 0.045698, l4: 0.046056, l5: 0.038976, l6: 0.038008

[epoch:  55/100000, batch:    72/  187, ite: 5112] train loss: 0.327790, tar: 0.035699 
l0: 0.025537, l1: 0.025913, l2: 0.034330, l3: 0.033378, l4: 0.053701, l5: 0.057573, l6: 0.062568

[epoch:  55/100000, batch:    74/  187, ite: 5113] train loss: 0.327759, tar: 0.035690 
l0: 0.052338, l1: 0.056535, l2: 0.067389, l3: 0.065194, l4: 0.061438, l5: 0.064087, l6: 0.061766

[epoch:  55/100000, batch:    76/  187, ite: 5114] train loss: 0.327849, tar: 0.035705 
l0: 0.042119, l1: 0.039886, l2: 0.058035, l3: 0.066581, l4: 0.065452, l5: 0.074469, l6: 0.062524

[epoch:  55/100000, batch:    78/  187, ite: 5115] train loss: 0.327922, tar: 0.035711 
l0: 0.039236, l1: 0.039813, l2: 0.042119, l3: 0.041450, l4: 0.053145, l5: 0.057197, l6: 0.056974

[epoch:  55/100000, batch:    80/  187, ite: 5116] train loss: 0.327924, tar: 0.035714 
l0: 0.033227, l1: 0.034412, l2: 0.035036, l3: 0.032555, l4: 0.049957, l5: 0.059401, l6: 0.066988

[epoch:  55/100000, batch:    82/  187, ite: 5117] train loss: 0.327909, tar: 0.035712 
l0: 0.040850, l1: 0.043060, l2: 0.050992, l3: 0.056277, l4: 0.111476, l5: 0.104196, l6: 0.098579

[epoch:  55/100000, batch:    84/  187, ite: 5118] train loss: 0.328068, tar: 0.035716 
l0: 0.029723, l1: 0.027622, l2: 0.035624, l3: 0.039786, l4: 0.061787, l5: 0.079654, l6: 0.075776

[epoch:  55/100000, batch:    86/  187, ite: 5119] train loss: 0.328088, tar: 0.035711 
l0: 0.061919, l1: 0.069626, l2: 0.072261, l3: 0.073762, l4: 0.082869, l5: 0.071881, l6: 0.058542

[epoch:  55/100000, batch:    88/  187, ite: 5120] train loss: 0.328233, tar: 0.035734 
l0: 0.027464, l1: 0.025187, l2: 0.036689, l3: 0.035277, l4: 0.058724, l5: 0.070571, l6: 0.073844

[epoch:  55/100000, batch:    90/  187, ite: 5121] train loss: 0.328232, tar: 0.035727 
l0: 0.034997, l1: 0.036134, l2: 0.039991, l3: 0.040221, l4: 0.047766, l5: 0.060228, l6: 0.061312

[epoch:  55/100000, batch:    92/  187, ite: 5122] train loss: 0.328226, tar: 0.035726 
l0: 0.029917, l1: 0.025821, l2: 0.044166, l3: 0.045134, l4: 0.067715, l5: 0.081776, l6: 0.079265

[epoch:  55/100000, batch:    94/  187, ite: 5123] train loss: 0.328266, tar: 0.035721 
l0: 0.101128, l1: 0.111522, l2: 0.125729, l3: 0.087406, l4: 0.096038, l5: 0.101738, l6: 0.115653

[epoch:  55/100000, batch:    96/  187, ite: 5124] train loss: 0.328632, tar: 0.035779 
l0: 0.025278, l1: 0.027848, l2: 0.030589, l3: 0.037367, l4: 0.071368, l5: 0.084436, l6: 0.079672

[epoch:  55/100000, batch:    98/  187, ite: 5125] train loss: 0.328657, tar: 0.035770 
l0: 0.030786, l1: 0.032049, l2: 0.038925, l3: 0.039283, l4: 0.061348, l5: 0.068602, l6: 0.067937

[epoch:  55/100000, batch:   100/  187, ite: 5126] train loss: 0.328666, tar: 0.035765 
l0: 0.033877, l1: 0.032560, l2: 0.037729, l3: 0.039214, l4: 0.083433, l5: 0.094658, l6: 0.096834

[epoch:  55/100000, batch:   102/  187, ite: 5127] train loss: 0.328745, tar: 0.035764 
l0: 0.021621, l1: 0.026527, l2: 0.030451, l3: 0.027015, l4: 0.030634, l5: 0.037324, l6: 0.041687

[epoch:  55/100000, batch:   104/  187, ite: 5128] train loss: 0.328645, tar: 0.035751 
l0: 0.040435, l1: 0.046935, l2: 0.050346, l3: 0.052736, l4: 0.049402, l5: 0.047827, l6: 0.045557

[epoch:  55/100000, batch:   106/  187, ite: 5129] train loss: 0.328649, tar: 0.035755 
l0: 0.056899, l1: 0.060256, l2: 0.045927, l3: 0.053528, l4: 0.096286, l5: 0.092174, l6: 0.102922

[epoch:  55/100000, batch:   108/  187, ite: 5130] train loss: 0.328808, tar: 0.035774 
l0: 0.028335, l1: 0.031921, l2: 0.032909, l3: 0.027679, l4: 0.027448, l5: 0.032521, l6: 0.030717

[epoch:  55/100000, batch:   110/  187, ite: 5131] train loss: 0.328704, tar: 0.035767 
l0: 0.044515, l1: 0.040876, l2: 0.074793, l3: 0.073204, l4: 0.101216, l5: 0.099358, l6: 0.104720

[epoch:  55/100000, batch:   112/  187, ite: 5132] train loss: 0.328889, tar: 0.035775 
l0: 0.055618, l1: 0.053273, l2: 0.071200, l3: 0.074352, l4: 0.097618, l5: 0.085392, l6: 0.087685

[epoch:  55/100000, batch:   114/  187, ite: 5133] train loss: 0.329063, tar: 0.035793 
l0: 0.031343, l1: 0.035591, l2: 0.034910, l3: 0.028757, l4: 0.053465, l5: 0.045250, l6: 0.047959

[epoch:  55/100000, batch:   116/  187, ite: 5134] train loss: 0.329017, tar: 0.035789 
l0: 0.059042, l1: 0.056812, l2: 0.070149, l3: 0.077586, l4: 0.090956, l5: 0.081926, l6: 0.087774

[epoch:  55/100000, batch:   118/  187, ite: 5135] train loss: 0.329189, tar: 0.035809 
l0: 0.046210, l1: 0.041695, l2: 0.076251, l3: 0.074175, l4: 0.087220, l5: 0.105942, l6: 0.096221

[epoch:  55/100000, batch:   120/  187, ite: 5136] train loss: 0.329364, tar: 0.035818 
l0: 0.029574, l1: 0.025172, l2: 0.043346, l3: 0.038805, l4: 0.062104, l5: 0.076860, l6: 0.085426

[epoch:  55/100000, batch:   122/  187, ite: 5137] train loss: 0.329392, tar: 0.035813 
l0: 0.045200, l1: 0.045233, l2: 0.068256, l3: 0.072871, l4: 0.083581, l5: 0.065451, l6: 0.061677

[epoch:  55/100000, batch:   124/  187, ite: 5138] train loss: 0.329491, tar: 0.035821 
l0: 0.021830, l1: 0.021882, l2: 0.027444, l3: 0.027257, l4: 0.056324, l5: 0.051555, l6: 0.054751

[epoch:  55/100000, batch:   126/  187, ite: 5139] train loss: 0.329431, tar: 0.035809 
l0: 0.028635, l1: 0.031417, l2: 0.032174, l3: 0.033741, l4: 0.050875, l5: 0.050058, l6: 0.046097

[epoch:  55/100000, batch:   128/  187, ite: 5140] train loss: 0.329381, tar: 0.035803 
l0: 0.033017, l1: 0.030857, l2: 0.047433, l3: 0.048705, l4: 0.059599, l5: 0.059003, l6: 0.079056

[epoch:  55/100000, batch:   130/  187, ite: 5141] train loss: 0.329406, tar: 0.035800 
l0: 0.071524, l1: 0.081125, l2: 0.077920, l3: 0.067204, l4: 0.103833, l5: 0.089211, l6: 0.082526

[epoch:  55/100000, batch:   132/  187, ite: 5142] train loss: 0.329620, tar: 0.035831 
l0: 0.071205, l1: 0.090130, l2: 0.066592, l3: 0.057712, l4: 0.075283, l5: 0.066025, l6: 0.068513

[epoch:  55/100000, batch:   134/  187, ite: 5143] train loss: 0.329765, tar: 0.035862 
l0: 0.028453, l1: 0.032464, l2: 0.032520, l3: 0.034293, l4: 0.055331, l5: 0.065335, l6: 0.069460

[epoch:  55/100000, batch:   136/  187, ite: 5144] train loss: 0.329754, tar: 0.035856 
l0: 0.034321, l1: 0.031813, l2: 0.058450, l3: 0.060202, l4: 0.073059, l5: 0.066914, l6: 0.067010

[epoch:  55/100000, batch:   138/  187, ite: 5145] train loss: 0.329809, tar: 0.035855 
l0: 0.030912, l1: 0.033321, l2: 0.038198, l3: 0.034570, l4: 0.040805, l5: 0.048377, l6: 0.055691

[epoch:  55/100000, batch:   140/  187, ite: 5146] train loss: 0.329767, tar: 0.035850 
l0: 0.025325, l1: 0.025703, l2: 0.032189, l3: 0.032639, l4: 0.067706, l5: 0.077030, l6: 0.079590

[epoch:  55/100000, batch:   142/  187, ite: 5147] train loss: 0.329776, tar: 0.035841 
l0: 0.033870, l1: 0.043086, l2: 0.038137, l3: 0.030036, l4: 0.089393, l5: 0.091333, l6: 0.079662

[epoch:  55/100000, batch:   144/  187, ite: 5148] train loss: 0.329842, tar: 0.035839 
l0: 0.042844, l1: 0.044594, l2: 0.044335, l3: 0.045953, l4: 0.061412, l5: 0.063183, l6: 0.070864

[epoch:  55/100000, batch:   146/  187, ite: 5149] train loss: 0.329880, tar: 0.035845 
l0: 0.023624, l1: 0.023728, l2: 0.029493, l3: 0.027369, l4: 0.063011, l5: 0.052506, l6: 0.062729

[epoch:  55/100000, batch:   148/  187, ite: 5150] train loss: 0.329838, tar: 0.035835 
l0: 0.024564, l1: 0.023197, l2: 0.034350, l3: 0.031246, l4: 0.075287, l5: 0.074304, l6: 0.060955

[epoch:  55/100000, batch:   150/  187, ite: 5151] train loss: 0.329833, tar: 0.035825 
l0: 0.029044, l1: 0.031038, l2: 0.031524, l3: 0.029288, l4: 0.060053, l5: 0.064516, l6: 0.046850

[epoch:  55/100000, batch:   152/  187, ite: 5152] train loss: 0.329801, tar: 0.035819 
l0: 0.045194, l1: 0.043701, l2: 0.060193, l3: 0.060116, l4: 0.067862, l5: 0.066717, l6: 0.076083

[epoch:  55/100000, batch:   154/  187, ite: 5153] train loss: 0.329879, tar: 0.035827 
l0: 0.015083, l1: 0.018175, l2: 0.020565, l3: 0.016920, l4: 0.028345, l5: 0.036934, l6: 0.028781

[epoch:  55/100000, batch:   156/  187, ite: 5154] train loss: 0.329736, tar: 0.035809 
l0: 0.024525, l1: 0.030768, l2: 0.020834, l3: 0.021922, l4: 0.039274, l5: 0.042232, l6: 0.034492

[epoch:  55/100000, batch:   158/  187, ite: 5155] train loss: 0.329635, tar: 0.035800 
l0: 0.028306, l1: 0.029851, l2: 0.036206, l3: 0.047246, l4: 0.056551, l5: 0.046419, l6: 0.049184

[epoch:  55/100000, batch:   160/  187, ite: 5156] train loss: 0.329604, tar: 0.035793 
l0: 0.026619, l1: 0.029034, l2: 0.039205, l3: 0.040719, l4: 0.086093, l5: 0.076611, l6: 0.051925

[epoch:  55/100000, batch:   162/  187, ite: 5157] train loss: 0.329622, tar: 0.035785 
l0: 0.050029, l1: 0.056628, l2: 0.066109, l3: 0.060548, l4: 0.066401, l5: 0.048280, l6: 0.050079

[epoch:  55/100000, batch:   164/  187, ite: 5158] train loss: 0.329681, tar: 0.035797 
l0: 0.015037, l1: 0.014758, l2: 0.022273, l3: 0.020168, l4: 0.026611, l5: 0.034206, l6: 0.035613

[epoch:  55/100000, batch:   166/  187, ite: 5159] train loss: 0.329542, tar: 0.035780 
l0: 0.050645, l1: 0.055915, l2: 0.052952, l3: 0.062869, l4: 0.099130, l5: 0.083579, l6: 0.081006

[epoch:  55/100000, batch:   168/  187, ite: 5160] train loss: 0.329677, tar: 0.035792 
l0: 0.020732, l1: 0.020542, l2: 0.023885, l3: 0.023953, l4: 0.038191, l5: 0.038879, l6: 0.042329

[epoch:  55/100000, batch:   170/  187, ite: 5161] train loss: 0.329573, tar: 0.035779 
l0: 0.029580, l1: 0.028568, l2: 0.038836, l3: 0.041763, l4: 0.051859, l5: 0.050888, l6: 0.057491

[epoch:  55/100000, batch:   172/  187, ite: 5162] train loss: 0.329547, tar: 0.035774 
l0: 0.026121, l1: 0.025739, l2: 0.030054, l3: 0.030674, l4: 0.037033, l5: 0.038642, l6: 0.047774

[epoch:  55/100000, batch:   174/  187, ite: 5163] train loss: 0.329466, tar: 0.035766 
l0: 0.051250, l1: 0.052448, l2: 0.055616, l3: 0.059780, l4: 0.043030, l5: 0.061067, l6: 0.055326

[epoch:  55/100000, batch:   176/  187, ite: 5164] train loss: 0.329508, tar: 0.035779 
l0: 0.026675, l1: 0.026538, l2: 0.031678, l3: 0.030292, l4: 0.078771, l5: 0.071784, l6: 0.054905

[epoch:  55/100000, batch:   178/  187, ite: 5165] train loss: 0.329501, tar: 0.035771 
l0: 0.056485, l1: 0.056846, l2: 0.066739, l3: 0.060742, l4: 0.095799, l5: 0.086119, l6: 0.078155

[epoch:  55/100000, batch:   180/  187, ite: 5166] train loss: 0.329648, tar: 0.035789 
l0: 0.024717, l1: 0.021697, l2: 0.045329, l3: 0.050065, l4: 0.045187, l5: 0.047181, l6: 0.042921

[epoch:  55/100000, batch:   182/  187, ite: 5167] train loss: 0.329603, tar: 0.035779 
l0: 0.024714, l1: 0.025765, l2: 0.037707, l3: 0.035006, l4: 0.052855, l5: 0.053656, l6: 0.056484

[epoch:  55/100000, batch:   184/  187, ite: 5168] train loss: 0.329566, tar: 0.035770 
l0: 0.049361, l1: 0.040958, l2: 0.092120, l3: 0.103270, l4: 0.101230, l5: 0.106953, l6: 0.111177

[epoch:  55/100000, batch:   186/  187, ite: 5169] train loss: 0.329801, tar: 0.035782 
l0: 0.034580, l1: 0.040324, l2: 0.040216, l3: 0.036969, l4: 0.041260, l5: 0.042770, l6: 0.038199

[epoch:  55/100000, batch:   188/  187, ite: 5170] train loss: 0.329754, tar: 0.035781 
l0: 0.081757, l1: 0.093563, l2: 0.084328, l3: 0.086525, l4: 0.082758, l5: 0.076692, l6: 0.088101

[epoch:  56/100000, batch:     2/  187, ite: 5171] train loss: 0.329979, tar: 0.035820 
l0: 0.028887, l1: 0.024737, l2: 0.037734, l3: 0.037377, l4: 0.059835, l5: 0.064173, l6: 0.075542

[epoch:  56/100000, batch:     4/  187, ite: 5172] train loss: 0.329978, tar: 0.035814 
l0: 0.026060, l1: 0.025571, l2: 0.024584, l3: 0.027888, l4: 0.059257, l5: 0.065624, l6: 0.060725

[epoch:  56/100000, batch:     6/  187, ite: 5173] train loss: 0.329944, tar: 0.035806 
l0: 0.049978, l1: 0.053433, l2: 0.055776, l3: 0.054281, l4: 0.061320, l5: 0.062294, l6: 0.053327

[epoch:  56/100000, batch:     8/  187, ite: 5174] train loss: 0.329995, tar: 0.035818 
l0: 0.018481, l1: 0.017318, l2: 0.033098, l3: 0.030343, l4: 0.036279, l5: 0.043536, l6: 0.040517

[epoch:  56/100000, batch:    10/  187, ite: 5175] train loss: 0.329901, tar: 0.035803 
l0: 0.016928, l1: 0.017182, l2: 0.019573, l3: 0.017753, l4: 0.033556, l5: 0.040740, l6: 0.044943

[epoch:  56/100000, batch:    12/  187, ite: 5176] train loss: 0.329783, tar: 0.035787 
l0: 0.043804, l1: 0.041337, l2: 0.053432, l3: 0.061353, l4: 0.059513, l5: 0.070397, l6: 0.068936

[epoch:  56/100000, batch:    14/  187, ite: 5177] train loss: 0.329841, tar: 0.035794 
l0: 0.021690, l1: 0.021080, l2: 0.025622, l3: 0.025179, l4: 0.041771, l5: 0.041823, l6: 0.043770

[epoch:  56/100000, batch:    16/  187, ite: 5178] train loss: 0.329749, tar: 0.035782 
l0: 0.084631, l1: 0.087168, l2: 0.127882, l3: 0.127782, l4: 0.078415, l5: 0.092647, l6: 0.085338

[epoch:  56/100000, batch:    18/  187, ite: 5179] train loss: 0.330049, tar: 0.035823 
l0: 0.032614, l1: 0.028862, l2: 0.036678, l3: 0.039967, l4: 0.069900, l5: 0.082826, l6: 0.091941

[epoch:  56/100000, batch:    20/  187, ite: 5180] train loss: 0.330094, tar: 0.035820 
l0: 0.019353, l1: 0.019477, l2: 0.019284, l3: 0.018751, l4: 0.032070, l5: 0.036227, l6: 0.034823

[epoch:  56/100000, batch:    22/  187, ite: 5181] train loss: 0.329967, tar: 0.035807 
l0: 0.031724, l1: 0.031043, l2: 0.040181, l3: 0.045026, l4: 0.052081, l5: 0.067141, l6: 0.052337

[epoch:  56/100000, batch:    24/  187, ite: 5182] train loss: 0.329958, tar: 0.035803 
l0: 0.033325, l1: 0.031891, l2: 0.050428, l3: 0.052973, l4: 0.057076, l5: 0.050276, l6: 0.049268

[epoch:  56/100000, batch:    26/  187, ite: 5183] train loss: 0.329954, tar: 0.035801 
l0: 0.029308, l1: 0.027594, l2: 0.040035, l3: 0.044711, l4: 0.056039, l5: 0.063922, l6: 0.061288

[epoch:  56/100000, batch:    28/  187, ite: 5184] train loss: 0.329948, tar: 0.035795 
l0: 0.024859, l1: 0.022468, l2: 0.026349, l3: 0.031527, l4: 0.051476, l5: 0.060747, l6: 0.057421

[epoch:  56/100000, batch:    30/  187, ite: 5185] train loss: 0.329901, tar: 0.035786 
l0: 0.029876, l1: 0.029536, l2: 0.033142, l3: 0.035106, l4: 0.045121, l5: 0.049648, l6: 0.053973

[epoch:  56/100000, batch:    32/  187, ite: 5186] train loss: 0.329856, tar: 0.035781 
l0: 0.035836, l1: 0.031574, l2: 0.050503, l3: 0.060607, l4: 0.113684, l5: 0.081666, l6: 0.098402

[epoch:  56/100000, batch:    34/  187, ite: 5187] train loss: 0.329976, tar: 0.035781 
l0: 0.022821, l1: 0.023367, l2: 0.024051, l3: 0.024120, l4: 0.058666, l5: 0.059304, l6: 0.060055

[epoch:  56/100000, batch:    36/  187, ite: 5188] train loss: 0.329928, tar: 0.035770 
l0: 0.053193, l1: 0.057633, l2: 0.055762, l3: 0.060300, l4: 0.084510, l5: 0.071682, l6: 0.079444

[epoch:  56/100000, batch:    38/  187, ite: 5189] train loss: 0.330039, tar: 0.035785 
l0: 0.027778, l1: 0.025995, l2: 0.033906, l3: 0.041213, l4: 0.054056, l5: 0.063186, l6: 0.067677

[epoch:  56/100000, batch:    40/  187, ite: 5190] train loss: 0.330026, tar: 0.035778 
l0: 0.020898, l1: 0.022731, l2: 0.023424, l3: 0.023720, l4: 0.037970, l5: 0.047052, l6: 0.047687

[epoch:  56/100000, batch:    42/  187, ite: 5191] train loss: 0.329936, tar: 0.035766 
l0: 0.058134, l1: 0.067923, l2: 0.068958, l3: 0.075269, l4: 0.059408, l5: 0.050200, l6: 0.048654

[epoch:  56/100000, batch:    44/  187, ite: 5192] train loss: 0.330019, tar: 0.035785 
l0: 0.023685, l1: 0.022981, l2: 0.037149, l3: 0.040575, l4: 0.054052, l5: 0.058908, l6: 0.051796

[epoch:  56/100000, batch:    46/  187, ite: 5193] train loss: 0.329985, tar: 0.035774 
l0: 0.044236, l1: 0.050498, l2: 0.082805, l3: 0.077316, l4: 0.036929, l5: 0.033685, l6: 0.031545

[epoch:  56/100000, batch:    48/  187, ite: 5194] train loss: 0.330007, tar: 0.035782 
l0: 0.037837, l1: 0.044539, l2: 0.027540, l3: 0.030173, l4: 0.065557, l5: 0.057114, l6: 0.049888

[epoch:  56/100000, batch:    50/  187, ite: 5195] train loss: 0.329993, tar: 0.035783 
l0: 0.024734, l1: 0.032392, l2: 0.029483, l3: 0.026960, l4: 0.028216, l5: 0.027717, l6: 0.025635

[epoch:  56/100000, batch:    52/  187, ite: 5196] train loss: 0.329880, tar: 0.035774 
l0: 0.021991, l1: 0.021677, l2: 0.029890, l3: 0.029261, l4: 0.034793, l5: 0.051227, l6: 0.045973

[epoch:  56/100000, batch:    54/  187, ite: 5197] train loss: 0.329801, tar: 0.035763 
l0: 0.024712, l1: 0.028960, l2: 0.028824, l3: 0.029990, l4: 0.045864, l5: 0.052464, l6: 0.048692

[epoch:  56/100000, batch:    56/  187, ite: 5198] train loss: 0.329742, tar: 0.035753 
l0: 0.032441, l1: 0.033634, l2: 0.040831, l3: 0.047214, l4: 0.054841, l5: 0.053464, l6: 0.049686

[epoch:  56/100000, batch:    58/  187, ite: 5199] train loss: 0.329727, tar: 0.035751 
l0: 0.060784, l1: 0.067811, l2: 0.071923, l3: 0.064403, l4: 0.069981, l5: 0.060613, l6: 0.053540

[epoch:  56/100000, batch:    60/  187, ite: 5200] train loss: 0.329827, tar: 0.035771 
l0: 0.042357, l1: 0.042445, l2: 0.045768, l3: 0.046164, l4: 0.057303, l5: 0.078655, l6: 0.074284

[epoch:  56/100000, batch:    62/  187, ite: 5201] train loss: 0.329874, tar: 0.035777 
l0: 0.030633, l1: 0.032568, l2: 0.031502, l3: 0.031952, l4: 0.063396, l5: 0.058001, l6: 0.058009

[epoch:  56/100000, batch:    64/  187, ite: 5202] train loss: 0.329855, tar: 0.035773 
l0: 0.030760, l1: 0.027382, l2: 0.043873, l3: 0.042856, l4: 0.049220, l5: 0.063058, l6: 0.059334

[epoch:  56/100000, batch:    66/  187, ite: 5203] train loss: 0.329843, tar: 0.035768 
l0: 0.027011, l1: 0.023982, l2: 0.031591, l3: 0.025985, l4: 0.042720, l5: 0.057565, l6: 0.062456

[epoch:  56/100000, batch:    68/  187, ite: 5204] train loss: 0.329795, tar: 0.035761 
l0: 0.017123, l1: 0.019124, l2: 0.020266, l3: 0.023632, l4: 0.048611, l5: 0.045292, l6: 0.044363

[epoch:  56/100000, batch:    70/  187, ite: 5205] train loss: 0.329702, tar: 0.035746 
l0: 0.024155, l1: 0.025786, l2: 0.027132, l3: 0.033113, l4: 0.029141, l5: 0.028699, l6: 0.032614

[epoch:  56/100000, batch:    72/  187, ite: 5206] train loss: 0.329595, tar: 0.035736 
l0: 0.042164, l1: 0.034713, l2: 0.047245, l3: 0.042681, l4: 0.064493, l5: 0.107401, l6: 0.122332

[epoch:  56/100000, batch:    74/  187, ite: 5207] train loss: 0.329704, tar: 0.035741 
l0: 0.031505, l1: 0.035382, l2: 0.033101, l3: 0.031702, l4: 0.047248, l5: 0.059235, l6: 0.062820

[epoch:  56/100000, batch:    76/  187, ite: 5208] train loss: 0.329680, tar: 0.035738 
l0: 0.026199, l1: 0.023650, l2: 0.035514, l3: 0.037699, l4: 0.059591, l5: 0.054553, l6: 0.055024

[epoch:  56/100000, batch:    78/  187, ite: 5209] train loss: 0.329650, tar: 0.035730 
l0: 0.025480, l1: 0.026036, l2: 0.025484, l3: 0.026047, l4: 0.036149, l5: 0.044992, l6: 0.043541

[epoch:  56/100000, batch:    80/  187, ite: 5210] train loss: 0.329565, tar: 0.035722 
l0: 0.038983, l1: 0.039019, l2: 0.044746, l3: 0.043173, l4: 0.046249, l5: 0.050700, l6: 0.046166

[epoch:  56/100000, batch:    82/  187, ite: 5211] train loss: 0.329548, tar: 0.035724 
l0: 0.029766, l1: 0.029066, l2: 0.036850, l3: 0.042618, l4: 0.052025, l5: 0.053721, l6: 0.052907

[epoch:  56/100000, batch:    84/  187, ite: 5212] train loss: 0.329521, tar: 0.035719 
l0: 0.031356, l1: 0.030032, l2: 0.034720, l3: 0.038846, l4: 0.051776, l5: 0.058404, l6: 0.054853

[epoch:  56/100000, batch:    86/  187, ite: 5213] train loss: 0.329497, tar: 0.035716 
l0: 0.024463, l1: 0.024906, l2: 0.027912, l3: 0.028075, l4: 0.051054, l5: 0.046733, l6: 0.039762

[epoch:  56/100000, batch:    88/  187, ite: 5214] train loss: 0.329426, tar: 0.035706 
l0: 0.043935, l1: 0.045149, l2: 0.043443, l3: 0.047935, l4: 0.085306, l5: 0.081605, l6: 0.089065

[epoch:  56/100000, batch:    90/  187, ite: 5215] train loss: 0.329514, tar: 0.035713 
l0: 0.043885, l1: 0.042116, l2: 0.049899, l3: 0.055603, l4: 0.070734, l5: 0.065372, l6: 0.075004

[epoch:  56/100000, batch:    92/  187, ite: 5216] train loss: 0.329574, tar: 0.035720 
l0: 0.107781, l1: 0.095482, l2: 0.160189, l3: 0.145827, l4: 0.301932, l5: 0.261950, l6: 0.262184

[epoch:  56/100000, batch:    94/  187, ite: 5217] train loss: 0.330400, tar: 0.035779 
l0: 0.035705, l1: 0.037197, l2: 0.040079, l3: 0.042379, l4: 0.055341, l5: 0.053112, l6: 0.059545

[epoch:  56/100000, batch:    96/  187, ite: 5218] train loss: 0.330395, tar: 0.035779 
l0: 0.037217, l1: 0.040637, l2: 0.048835, l3: 0.039055, l4: 0.081000, l5: 0.075197, l6: 0.078396

[epoch:  56/100000, batch:    98/  187, ite: 5219] train loss: 0.330452, tar: 0.035780 
l0: 0.028763, l1: 0.035559, l2: 0.044557, l3: 0.035441, l4: 0.024091, l5: 0.024379, l6: 0.026984

[epoch:  56/100000, batch:   100/  187, ite: 5220] train loss: 0.330361, tar: 0.035775 
l0: 0.027031, l1: 0.025487, l2: 0.032101, l3: 0.034897, l4: 0.052063, l5: 0.043558, l6: 0.052268

[epoch:  56/100000, batch:   102/  187, ite: 5221] train loss: 0.330310, tar: 0.035767 
l0: 0.017508, l1: 0.021202, l2: 0.034138, l3: 0.023484, l4: 0.042466, l5: 0.044283, l6: 0.033913

[epoch:  56/100000, batch:   104/  187, ite: 5222] train loss: 0.330217, tar: 0.035752 
l0: 0.041568, l1: 0.038219, l2: 0.059258, l3: 0.059685, l4: 0.063972, l5: 0.067925, l6: 0.073993

[epoch:  56/100000, batch:   106/  187, ite: 5223] train loss: 0.330278, tar: 0.035757 
l0: 0.028624, l1: 0.026608, l2: 0.053348, l3: 0.052823, l4: 0.056309, l5: 0.052794, l6: 0.053975

[epoch:  56/100000, batch:   108/  187, ite: 5224] train loss: 0.330273, tar: 0.035751 
l0: 0.016694, l1: 0.015978, l2: 0.022765, l3: 0.021047, l4: 0.032713, l5: 0.043010, l6: 0.043984

[epoch:  56/100000, batch:   110/  187, ite: 5225] train loss: 0.330164, tar: 0.035736 
l0: 0.034164, l1: 0.034240, l2: 0.043370, l3: 0.059785, l4: 0.104628, l5: 0.102255, l6: 0.099724

[epoch:  56/100000, batch:   112/  187, ite: 5226] train loss: 0.330284, tar: 0.035734 
l0: 0.028159, l1: 0.026968, l2: 0.048210, l3: 0.043916, l4: 0.056237, l5: 0.049586, l6: 0.050847

[epoch:  56/100000, batch:   114/  187, ite: 5227] train loss: 0.330263, tar: 0.035728 
l0: 0.044865, l1: 0.058072, l2: 0.034077, l3: 0.046739, l4: 0.025101, l5: 0.018069, l6: 0.030039

[epoch:  56/100000, batch:   116/  187, ite: 5228] train loss: 0.330203, tar: 0.035736 
l0: 0.035219, l1: 0.037294, l2: 0.041492, l3: 0.041476, l4: 0.060156, l5: 0.058212, l6: 0.063185

[epoch:  56/100000, batch:   118/  187, ite: 5229] train loss: 0.330209, tar: 0.035735 
l0: 0.041381, l1: 0.044785, l2: 0.053754, l3: 0.048050, l4: 0.052507, l5: 0.052024, l6: 0.076648

[epoch:  56/100000, batch:   120/  187, ite: 5230] train loss: 0.330240, tar: 0.035740 
l0: 0.027755, l1: 0.026411, l2: 0.039909, l3: 0.047840, l4: 0.068545, l5: 0.073611, l6: 0.068053

[epoch:  56/100000, batch:   122/  187, ite: 5231] train loss: 0.330258, tar: 0.035733 
l0: 0.021235, l1: 0.019843, l2: 0.038665, l3: 0.045086, l4: 0.042599, l5: 0.041812, l6: 0.039764

[epoch:  56/100000, batch:   124/  187, ite: 5232] train loss: 0.330192, tar: 0.035722 
l0: 0.027824, l1: 0.026298, l2: 0.038131, l3: 0.053855, l4: 0.073155, l5: 0.061111, l6: 0.068327

[epoch:  56/100000, batch:   126/  187, ite: 5233] train loss: 0.330207, tar: 0.035715 
l0: 0.026134, l1: 0.027719, l2: 0.031048, l3: 0.034154, l4: 0.051828, l5: 0.047418, l6: 0.042490

[epoch:  56/100000, batch:   128/  187, ite: 5234] train loss: 0.330151, tar: 0.035708 
l0: 0.027307, l1: 0.027646, l2: 0.031530, l3: 0.029465, l4: 0.056197, l5: 0.050234, l6: 0.056713

[epoch:  56/100000, batch:   130/  187, ite: 5235] train loss: 0.330110, tar: 0.035701 
l0: 0.025837, l1: 0.026293, l2: 0.028691, l3: 0.028356, l4: 0.046832, l5: 0.046092, l6: 0.049579

[epoch:  56/100000, batch:   132/  187, ite: 5236] train loss: 0.330046, tar: 0.035693 
l0: 0.012868, l1: 0.011979, l2: 0.018017, l3: 0.019948, l4: 0.039024, l5: 0.041248, l6: 0.045328

[epoch:  56/100000, batch:   134/  187, ite: 5237] train loss: 0.329932, tar: 0.035674 
l0: 0.024528, l1: 0.023868, l2: 0.028139, l3: 0.032264, l4: 0.048526, l5: 0.053681, l6: 0.040554

[epoch:  56/100000, batch:   136/  187, ite: 5238] train loss: 0.329868, tar: 0.035665 
l0: 0.088111, l1: 0.083645, l2: 0.133601, l3: 0.129883, l4: 0.126622, l5: 0.142435, l6: 0.122654

[epoch:  56/100000, batch:   138/  187, ite: 5239] train loss: 0.330270, tar: 0.035708 
l0: 0.046270, l1: 0.040568, l2: 0.079939, l3: 0.077297, l4: 0.118942, l5: 0.109204, l6: 0.115305

[epoch:  56/100000, batch:   140/  187, ite: 5240] train loss: 0.330477, tar: 0.035716 
l0: 0.047317, l1: 0.048275, l2: 0.058151, l3: 0.067922, l4: 0.088281, l5: 0.091664, l6: 0.082123

[epoch:  56/100000, batch:   142/  187, ite: 5241] train loss: 0.330601, tar: 0.035725 
l0: 0.021003, l1: 0.020363, l2: 0.027707, l3: 0.028142, l4: 0.042901, l5: 0.039178, l6: 0.041346

[epoch:  56/100000, batch:   144/  187, ite: 5242] train loss: 0.330512, tar: 0.035714 
l0: 0.017271, l1: 0.015862, l2: 0.024106, l3: 0.027367, l4: 0.041514, l5: 0.041693, l6: 0.043895

[epoch:  56/100000, batch:   146/  187, ite: 5243] train loss: 0.330416, tar: 0.035699 
l0: 0.053262, l1: 0.052581, l2: 0.067705, l3: 0.061925, l4: 0.080658, l5: 0.086290, l6: 0.102518

[epoch:  56/100000, batch:   148/  187, ite: 5244] train loss: 0.330557, tar: 0.035713 
l0: 0.018650, l1: 0.017175, l2: 0.040661, l3: 0.042370, l4: 0.052093, l5: 0.049792, l6: 0.061122

[epoch:  56/100000, batch:   150/  187, ite: 5245] train loss: 0.330518, tar: 0.035699 
l0: 0.016828, l1: 0.015639, l2: 0.017322, l3: 0.020587, l4: 0.037646, l5: 0.043009, l6: 0.043429

[epoch:  56/100000, batch:   152/  187, ite: 5246] train loss: 0.330408, tar: 0.035684 
l0: 0.031895, l1: 0.038741, l2: 0.020844, l3: 0.019169, l4: 0.031390, l5: 0.036151, l6: 0.035264

[epoch:  56/100000, batch:   154/  187, ite: 5247] train loss: 0.330315, tar: 0.035681 
l0: 0.042889, l1: 0.042679, l2: 0.066621, l3: 0.061819, l4: 0.070419, l5: 0.070787, l6: 0.070881

[epoch:  56/100000, batch:   156/  187, ite: 5248] train loss: 0.330391, tar: 0.035687 
l0: 0.034539, l1: 0.034133, l2: 0.051019, l3: 0.055510, l4: 0.064102, l5: 0.058188, l6: 0.053019

[epoch:  56/100000, batch:   158/  187, ite: 5249] train loss: 0.330407, tar: 0.035686 
l0: 0.049777, l1: 0.057320, l2: 0.056710, l3: 0.052986, l4: 0.040934, l5: 0.039672, l6: 0.043304

[epoch:  56/100000, batch:   160/  187, ite: 5250] train loss: 0.330416, tar: 0.035697 
l0: 0.042130, l1: 0.047416, l2: 0.041607, l3: 0.043448, l4: 0.049567, l5: 0.046532, l6: 0.037584

[epoch:  56/100000, batch:   162/  187, ite: 5251] train loss: 0.330398, tar: 0.035702 
l0: 0.020537, l1: 0.021525, l2: 0.029891, l3: 0.031331, l4: 0.045084, l5: 0.045518, l6: 0.039779

[epoch:  56/100000, batch:   164/  187, ite: 5252] train loss: 0.330321, tar: 0.035690 
l0: 0.033086, l1: 0.039437, l2: 0.045287, l3: 0.034233, l4: 0.035993, l5: 0.037412, l6: 0.036739

[epoch:  56/100000, batch:   166/  187, ite: 5253] train loss: 0.330266, tar: 0.035688 
l0: 0.043099, l1: 0.044743, l2: 0.040008, l3: 0.035834, l4: 0.050482, l5: 0.057524, l6: 0.065365

[epoch:  56/100000, batch:   168/  187, ite: 5254] train loss: 0.330272, tar: 0.035694 
l0: 0.029273, l1: 0.030343, l2: 0.032910, l3: 0.035493, l4: 0.040309, l5: 0.041066, l6: 0.044291

[epoch:  56/100000, batch:   170/  187, ite: 5255] train loss: 0.330211, tar: 0.035689 
l0: 0.027126, l1: 0.029051, l2: 0.026836, l3: 0.030670, l4: 0.045237, l5: 0.043287, l6: 0.038586

[epoch:  56/100000, batch:   172/  187, ite: 5256] train loss: 0.330140, tar: 0.035682 
l0: 0.022092, l1: 0.023078, l2: 0.027352, l3: 0.028222, l4: 0.039573, l5: 0.032569, l6: 0.034167

[epoch:  56/100000, batch:   174/  187, ite: 5257] train loss: 0.330042, tar: 0.035671 
l0: 0.039168, l1: 0.044069, l2: 0.040422, l3: 0.039296, l4: 0.043846, l5: 0.044519, l6: 0.040380

[epoch:  56/100000, batch:   176/  187, ite: 5258] train loss: 0.330011, tar: 0.035674 
l0: 0.026308, l1: 0.026636, l2: 0.028943, l3: 0.033315, l4: 0.066045, l5: 0.063845, l6: 0.063044

[epoch:  56/100000, batch:   178/  187, ite: 5259] train loss: 0.329994, tar: 0.035667 
l0: 0.030279, l1: 0.031237, l2: 0.044601, l3: 0.047812, l4: 0.072496, l5: 0.070163, l6: 0.063179

[epoch:  56/100000, batch:   180/  187, ite: 5260] train loss: 0.330017, tar: 0.035662 
l0: 0.029165, l1: 0.029014, l2: 0.037277, l3: 0.045027, l4: 0.036731, l5: 0.036119, l6: 0.039783

[epoch:  56/100000, batch:   182/  187, ite: 5261] train loss: 0.329956, tar: 0.035657 
l0: 0.023089, l1: 0.024519, l2: 0.026222, l3: 0.025813, l4: 0.054409, l5: 0.070886, l6: 0.056278

[epoch:  56/100000, batch:   184/  187, ite: 5262] train loss: 0.329918, tar: 0.035647 
l0: 0.023553, l1: 0.024134, l2: 0.032625, l3: 0.033146, l4: 0.065844, l5: 0.077884, l6: 0.060837

[epoch:  56/100000, batch:   186/  187, ite: 5263] train loss: 0.329908, tar: 0.035638 
l0: 0.029262, l1: 0.028931, l2: 0.044941, l3: 0.054098, l4: 0.042778, l5: 0.033513, l6: 0.037989

[epoch:  56/100000, batch:   188/  187, ite: 5264] train loss: 0.329862, tar: 0.035633 
l0: 0.044031, l1: 0.049881, l2: 0.048489, l3: 0.046587, l4: 0.060816, l5: 0.056552, l6: 0.054790

[epoch:  57/100000, batch:     2/  187, ite: 5265] train loss: 0.329887, tar: 0.035639 
l0: 0.032411, l1: 0.039252, l2: 0.030582, l3: 0.030792, l4: 0.041560, l5: 0.044315, l6: 0.042644

[epoch:  57/100000, batch:     4/  187, ite: 5266] train loss: 0.329833, tar: 0.035637 
l0: 0.022892, l1: 0.023184, l2: 0.026006, l3: 0.027314, l4: 0.041771, l5: 0.036333, l6: 0.042621

[epoch:  57/100000, batch:     6/  187, ite: 5267] train loss: 0.329746, tar: 0.035627 
l0: 0.028768, l1: 0.029265, l2: 0.034753, l3: 0.031411, l4: 0.031126, l5: 0.037814, l6: 0.038052

[epoch:  57/100000, batch:     8/  187, ite: 5268] train loss: 0.329669, tar: 0.035621 
l0: 0.019669, l1: 0.018832, l2: 0.028706, l3: 0.034719, l4: 0.050546, l5: 0.043046, l6: 0.051461

[epoch:  57/100000, batch:    10/  187, ite: 5269] train loss: 0.329603, tar: 0.035609 
l0: 0.019922, l1: 0.019118, l2: 0.032051, l3: 0.032757, l4: 0.040942, l5: 0.040992, l6: 0.034208

[epoch:  57/100000, batch:    12/  187, ite: 5270] train loss: 0.329517, tar: 0.035596 
l0: 0.038526, l1: 0.039922, l2: 0.042889, l3: 0.043714, l4: 0.049663, l5: 0.052129, l6: 0.045154

[epoch:  57/100000, batch:    14/  187, ite: 5271] train loss: 0.329503, tar: 0.035599 
l0: 0.021048, l1: 0.020539, l2: 0.032285, l3: 0.030649, l4: 0.047478, l5: 0.048877, l6: 0.052592

[epoch:  57/100000, batch:    16/  187, ite: 5272] train loss: 0.329444, tar: 0.035587 
l0: 0.027262, l1: 0.023809, l2: 0.038743, l3: 0.035712, l4: 0.045532, l5: 0.068931, l6: 0.079222

[epoch:  57/100000, batch:    18/  187, ite: 5273] train loss: 0.329436, tar: 0.035581 
l0: 0.027437, l1: 0.031325, l2: 0.030354, l3: 0.030555, l4: 0.029736, l5: 0.029463, l6: 0.032701

[epoch:  57/100000, batch:    20/  187, ite: 5274] train loss: 0.329343, tar: 0.035574 
l0: 0.017508, l1: 0.017360, l2: 0.024605, l3: 0.026655, l4: 0.053694, l5: 0.047984, l6: 0.044761

[epoch:  57/100000, batch:    22/  187, ite: 5275] train loss: 0.329267, tar: 0.035560 
l0: 0.021425, l1: 0.022393, l2: 0.030007, l3: 0.027589, l4: 0.052741, l5: 0.050785, l6: 0.045286

[epoch:  57/100000, batch:    24/  187, ite: 5276] train loss: 0.329205, tar: 0.035549 
l0: 0.033338, l1: 0.031284, l2: 0.044798, l3: 0.040523, l4: 0.057337, l5: 0.059609, l6: 0.068937

[epoch:  57/100000, batch:    26/  187, ite: 5277] train loss: 0.329210, tar: 0.035547 
l0: 0.018012, l1: 0.017030, l2: 0.023809, l3: 0.023350, l4: 0.034511, l5: 0.038007, l6: 0.037276

[epoch:  57/100000, batch:    28/  187, ite: 5278] train loss: 0.329103, tar: 0.035534 
l0: 0.014997, l1: 0.015803, l2: 0.017464, l3: 0.016916, l4: 0.022892, l5: 0.030330, l6: 0.032260

[epoch:  57/100000, batch:    30/  187, ite: 5279] train loss: 0.328963, tar: 0.035517 
l0: 0.025689, l1: 0.026385, l2: 0.032781, l3: 0.034633, l4: 0.032743, l5: 0.033653, l6: 0.035483

[epoch:  57/100000, batch:    32/  187, ite: 5280] train loss: 0.328879, tar: 0.035510 
l0: 0.014440, l1: 0.014840, l2: 0.027871, l3: 0.032113, l4: 0.053075, l5: 0.046000, l6: 0.036182

[epoch:  57/100000, batch:    34/  187, ite: 5281] train loss: 0.328798, tar: 0.035493 
l0: 0.027652, l1: 0.028377, l2: 0.028538, l3: 0.028641, l4: 0.039706, l5: 0.043960, l6: 0.044077

[epoch:  57/100000, batch:    36/  187, ite: 5282] train loss: 0.328729, tar: 0.035487 
l0: 0.017055, l1: 0.018139, l2: 0.029432, l3: 0.025217, l4: 0.038826, l5: 0.041968, l6: 0.040502

[epoch:  57/100000, batch:    38/  187, ite: 5283] train loss: 0.328638, tar: 0.035473 
l0: 0.036979, l1: 0.037471, l2: 0.052466, l3: 0.048495, l4: 0.071322, l5: 0.060185, l6: 0.069013

[epoch:  57/100000, batch:    40/  187, ite: 5284] train loss: 0.328675, tar: 0.035474 
l0: 0.023857, l1: 0.026835, l2: 0.020039, l3: 0.020509, l4: 0.031227, l5: 0.034810, l6: 0.037276

[epoch:  57/100000, batch:    42/  187, ite: 5285] train loss: 0.328570, tar: 0.035465 
l0: 0.013196, l1: 0.011634, l2: 0.025529, l3: 0.031086, l4: 0.039804, l5: 0.037909, l6: 0.039706

[epoch:  57/100000, batch:    44/  187, ite: 5286] train loss: 0.328469, tar: 0.035448 
l0: 0.029082, l1: 0.035821, l2: 0.035863, l3: 0.038683, l4: 0.055499, l5: 0.043041, l6: 0.046422

[epoch:  57/100000, batch:    46/  187, ite: 5287] train loss: 0.328435, tar: 0.035443 
l0: 0.031011, l1: 0.029766, l2: 0.039307, l3: 0.040437, l4: 0.062231, l5: 0.064831, l6: 0.057664

[epoch:  57/100000, batch:    48/  187, ite: 5288] train loss: 0.328433, tar: 0.035439 
l0: 0.040524, l1: 0.041517, l2: 0.033947, l3: 0.036681, l4: 0.080347, l5: 0.083216, l6: 0.083681

[epoch:  57/100000, batch:    50/  187, ite: 5289] train loss: 0.328488, tar: 0.035443 
l0: 0.080891, l1: 0.090852, l2: 0.078477, l3: 0.077098, l4: 0.082991, l5: 0.071403, l6: 0.069472

[epoch:  57/100000, batch:    52/  187, ite: 5290] train loss: 0.328661, tar: 0.035478 
l0: 0.058875, l1: 0.052722, l2: 0.085424, l3: 0.076231, l4: 0.119087, l5: 0.140287, l6: 0.140352

[epoch:  57/100000, batch:    54/  187, ite: 5291] train loss: 0.328927, tar: 0.035497 
l0: 0.028914, l1: 0.030118, l2: 0.048410, l3: 0.041694, l4: 0.052388, l5: 0.052332, l6: 0.048284

[epoch:  57/100000, batch:    56/  187, ite: 5292] train loss: 0.328907, tar: 0.035491 
l0: 0.027259, l1: 0.030437, l2: 0.029756, l3: 0.029993, l4: 0.037614, l5: 0.032367, l6: 0.033820

[epoch:  57/100000, batch:    58/  187, ite: 5293] train loss: 0.328823, tar: 0.035485 
l0: 0.025301, l1: 0.026564, l2: 0.034224, l3: 0.032038, l4: 0.052096, l5: 0.041333, l6: 0.033134

[epoch:  57/100000, batch:    60/  187, ite: 5294] train loss: 0.328758, tar: 0.035477 
l0: 0.030425, l1: 0.033187, l2: 0.037465, l3: 0.035371, l4: 0.041771, l5: 0.051089, l6: 0.051825

[epoch:  57/100000, batch:    62/  187, ite: 5295] train loss: 0.328722, tar: 0.035473 
l0: 0.042411, l1: 0.042429, l2: 0.056629, l3: 0.051159, l4: 0.053716, l5: 0.061620, l6: 0.069995

[epoch:  57/100000, batch:    64/  187, ite: 5296] train loss: 0.328760, tar: 0.035479 
l0: 0.034227, l1: 0.034736, l2: 0.041737, l3: 0.040144, l4: 0.048224, l5: 0.046100, l6: 0.040834

[epoch:  57/100000, batch:    66/  187, ite: 5297] train loss: 0.328727, tar: 0.035478 
l0: 0.054671, l1: 0.063463, l2: 0.056811, l3: 0.054063, l4: 0.049867, l5: 0.040561, l6: 0.035480

[epoch:  57/100000, batch:    68/  187, ite: 5298] train loss: 0.328747, tar: 0.035493 
l0: 0.024446, l1: 0.024661, l2: 0.041073, l3: 0.038356, l4: 0.049440, l5: 0.048180, l6: 0.054192

[epoch:  57/100000, batch:    70/  187, ite: 5299] train loss: 0.328710, tar: 0.035484 
l0: 0.029190, l1: 0.036427, l2: 0.033304, l3: 0.032417, l4: 0.038478, l5: 0.035865, l6: 0.034884

[epoch:  57/100000, batch:    72/  187, ite: 5300] train loss: 0.328642, tar: 0.035479 
l0: 0.025854, l1: 0.026195, l2: 0.033102, l3: 0.036510, l4: 0.042835, l5: 0.048518, l6: 0.055026

[epoch:  57/100000, batch:    74/  187, ite: 5301] train loss: 0.328595, tar: 0.035472 
l0: 0.023013, l1: 0.022522, l2: 0.036031, l3: 0.033468, l4: 0.038369, l5: 0.044745, l6: 0.043837

[epoch:  57/100000, batch:    76/  187, ite: 5302] train loss: 0.328529, tar: 0.035462 
l0: 0.042492, l1: 0.044587, l2: 0.046136, l3: 0.047080, l4: 0.049177, l5: 0.049925, l6: 0.051799

[epoch:  57/100000, batch:    78/  187, ite: 5303] train loss: 0.328531, tar: 0.035468 
l0: 0.030689, l1: 0.032580, l2: 0.034196, l3: 0.039082, l4: 0.045423, l5: 0.040602, l6: 0.046160

[epoch:  57/100000, batch:    80/  187, ite: 5304] train loss: 0.328485, tar: 0.035464 
l0: 0.035524, l1: 0.040434, l2: 0.044919, l3: 0.042264, l4: 0.049554, l5: 0.048000, l6: 0.063941

[epoch:  57/100000, batch:    82/  187, ite: 5305] train loss: 0.328482, tar: 0.035464 
l0: 0.020582, l1: 0.021952, l2: 0.029150, l3: 0.026739, l4: 0.041801, l5: 0.037778, l6: 0.034386

[epoch:  57/100000, batch:    84/  187, ite: 5306] train loss: 0.328393, tar: 0.035453 
l0: 0.041623, l1: 0.037627, l2: 0.048892, l3: 0.056713, l4: 0.060127, l5: 0.069324, l6: 0.080540

[epoch:  57/100000, batch:    86/  187, ite: 5307] train loss: 0.328444, tar: 0.035457 
l0: 0.022832, l1: 0.022304, l2: 0.028624, l3: 0.028307, l4: 0.048931, l5: 0.059801, l6: 0.064445

[epoch:  57/100000, batch:    88/  187, ite: 5308] train loss: 0.328403, tar: 0.035448 
l0: 0.048048, l1: 0.049935, l2: 0.057199, l3: 0.053484, l4: 0.072024, l5: 0.075546, l6: 0.071467

[epoch:  57/100000, batch:    90/  187, ite: 5309] train loss: 0.328479, tar: 0.035457 
l0: 0.025667, l1: 0.027495, l2: 0.031853, l3: 0.029310, l4: 0.038022, l5: 0.038130, l6: 0.044661

[epoch:  57/100000, batch:    92/  187, ite: 5310] train loss: 0.328408, tar: 0.035450 
l0: 0.034153, l1: 0.031701, l2: 0.045743, l3: 0.048840, l4: 0.052597, l5: 0.051664, l6: 0.052203

[epoch:  57/100000, batch:    94/  187, ite: 5311] train loss: 0.328399, tar: 0.035449 
l0: 0.020445, l1: 0.021639, l2: 0.024005, l3: 0.021579, l4: 0.037140, l5: 0.031506, l6: 0.032156

[epoch:  57/100000, batch:    96/  187, ite: 5312] train loss: 0.328292, tar: 0.035437 
l0: 0.031933, l1: 0.033729, l2: 0.028405, l3: 0.027758, l4: 0.042960, l5: 0.052042, l6: 0.052307

[epoch:  57/100000, batch:    98/  187, ite: 5313] train loss: 0.328247, tar: 0.035435 
l0: 0.016662, l1: 0.017214, l2: 0.021551, l3: 0.019795, l4: 0.037453, l5: 0.064703, l6: 0.045910

[epoch:  57/100000, batch:   100/  187, ite: 5314] train loss: 0.328167, tar: 0.035420 
l0: 0.017788, l1: 0.017188, l2: 0.028254, l3: 0.028045, l4: 0.040622, l5: 0.043276, l6: 0.048237

[epoch:  57/100000, batch:   102/  187, ite: 5315] train loss: 0.328088, tar: 0.035407 
l0: 0.018111, l1: 0.021156, l2: 0.026394, l3: 0.025623, l4: 0.026930, l5: 0.029223, l6: 0.030853

[epoch:  57/100000, batch:   104/  187, ite: 5316] train loss: 0.327974, tar: 0.035394 
l0: 0.029520, l1: 0.029801, l2: 0.039254, l3: 0.039410, l4: 0.040683, l5: 0.044634, l6: 0.048942

[epoch:  57/100000, batch:   106/  187, ite: 5317] train loss: 0.327932, tar: 0.035389 
l0: 0.011177, l1: 0.014142, l2: 0.015435, l3: 0.014722, l4: 0.029067, l5: 0.025683, l6: 0.019577

[epoch:  57/100000, batch:   108/  187, ite: 5318] train loss: 0.327781, tar: 0.035371 
l0: 0.045135, l1: 0.040977, l2: 0.067692, l3: 0.067718, l4: 0.065925, l5: 0.072808, l6: 0.088186

[epoch:  57/100000, batch:   110/  187, ite: 5319] train loss: 0.327873, tar: 0.035378 
l0: 0.027095, l1: 0.025561, l2: 0.032356, l3: 0.037159, l4: 0.046048, l5: 0.046326, l6: 0.041705

[epoch:  57/100000, batch:   112/  187, ite: 5320] train loss: 0.327819, tar: 0.035372 
l0: 0.009914, l1: 0.016609, l2: 0.010549, l3: 0.008251, l4: 0.007788, l5: 0.006061, l6: 0.005261

[epoch:  57/100000, batch:   114/  187, ite: 5321] train loss: 0.327619, tar: 0.035353 
l0: 0.026568, l1: 0.030763, l2: 0.030221, l3: 0.030406, l4: 0.036385, l5: 0.041536, l6: 0.034938

[epoch:  57/100000, batch:   116/  187, ite: 5322] train loss: 0.327546, tar: 0.035346 
l0: 0.019109, l1: 0.018193, l2: 0.042666, l3: 0.043197, l4: 0.039512, l5: 0.044560, l6: 0.046521

[epoch:  57/100000, batch:   118/  187, ite: 5323] train loss: 0.327490, tar: 0.035334 
l0: 0.016845, l1: 0.018103, l2: 0.019124, l3: 0.016946, l4: 0.029261, l5: 0.026878, l6: 0.027893

[epoch:  57/100000, batch:   120/  187, ite: 5324] train loss: 0.327360, tar: 0.035320 
l0: 0.027358, l1: 0.033065, l2: 0.021943, l3: 0.025310, l4: 0.053055, l5: 0.045521, l6: 0.044252

[epoch:  57/100000, batch:   122/  187, ite: 5325] train loss: 0.327302, tar: 0.035314 
l0: 0.024674, l1: 0.027301, l2: 0.022186, l3: 0.021644, l4: 0.039174, l5: 0.043285, l6: 0.045809

[epoch:  57/100000, batch:   124/  187, ite: 5326] train loss: 0.327224, tar: 0.035306 
l0: 0.020740, l1: 0.022346, l2: 0.027094, l3: 0.028739, l4: 0.040020, l5: 0.038328, l6: 0.041377

[epoch:  57/100000, batch:   126/  187, ite: 5327] train loss: 0.327142, tar: 0.035295 
l0: 0.020520, l1: 0.018987, l2: 0.026001, l3: 0.028210, l4: 0.040983, l5: 0.046928, l6: 0.029041

[epoch:  57/100000, batch:   128/  187, ite: 5328] train loss: 0.327055, tar: 0.035284 
l0: 0.061267, l1: 0.059729, l2: 0.073084, l3: 0.084265, l4: 0.140554, l5: 0.112778, l6: 0.123098

[epoch:  57/100000, batch:   130/  187, ite: 5329] train loss: 0.327301, tar: 0.035303 
l0: 0.034129, l1: 0.032545, l2: 0.037818, l3: 0.045232, l4: 0.071005, l5: 0.077181, l6: 0.046000

[epoch:  57/100000, batch:   132/  187, ite: 5330] train loss: 0.327314, tar: 0.035303 
l0: 0.022468, l1: 0.023071, l2: 0.026035, l3: 0.025615, l4: 0.058364, l5: 0.059159, l6: 0.047442

[epoch:  57/100000, batch:   134/  187, ite: 5331] train loss: 0.327265, tar: 0.035293 
l0: 0.022334, l1: 0.020099, l2: 0.043516, l3: 0.043215, l4: 0.047969, l5: 0.051524, l6: 0.048748

[epoch:  57/100000, batch:   136/  187, ite: 5332] train loss: 0.327227, tar: 0.035283 
l0: 0.024656, l1: 0.030352, l2: 0.019688, l3: 0.019373, l4: 0.043246, l5: 0.037890, l6: 0.041030

[epoch:  57/100000, batch:   138/  187, ite: 5333] train loss: 0.327144, tar: 0.035275 
l0: 0.034494, l1: 0.041369, l2: 0.031323, l3: 0.027634, l4: 0.035464, l5: 0.029252, l6: 0.030890

[epoch:  57/100000, batch:   140/  187, ite: 5334] train loss: 0.327071, tar: 0.035275 
l0: 0.013662, l1: 0.014418, l2: 0.019950, l3: 0.020088, l4: 0.032278, l5: 0.033418, l6: 0.026472

[epoch:  57/100000, batch:   142/  187, ite: 5335] train loss: 0.326947, tar: 0.035258 
l0: 0.032422, l1: 0.034697, l2: 0.043005, l3: 0.040703, l4: 0.052205, l5: 0.051073, l6: 0.050746

[epoch:  57/100000, batch:   144/  187, ite: 5336] train loss: 0.326930, tar: 0.035256 
l0: 0.020492, l1: 0.019049, l2: 0.027402, l3: 0.028478, l4: 0.054999, l5: 0.049942, l6: 0.047908

[epoch:  57/100000, batch:   146/  187, ite: 5337] train loss: 0.326871, tar: 0.035245 
l0: 0.021114, l1: 0.019332, l2: 0.036200, l3: 0.038606, l4: 0.042325, l5: 0.037284, l6: 0.039420

[epoch:  57/100000, batch:   148/  187, ite: 5338] train loss: 0.326802, tar: 0.035235 
l0: 0.021529, l1: 0.020357, l2: 0.023034, l3: 0.026053, l4: 0.043847, l5: 0.044063, l6: 0.045489

[epoch:  57/100000, batch:   150/  187, ite: 5339] train loss: 0.326725, tar: 0.035224 
l0: 0.042504, l1: 0.041255, l2: 0.043833, l3: 0.051577, l4: 0.071669, l5: 0.056676, l6: 0.070463

[epoch:  57/100000, batch:   152/  187, ite: 5340] train loss: 0.326764, tar: 0.035230 
l0: 0.024405, l1: 0.024695, l2: 0.021587, l3: 0.020001, l4: 0.037878, l5: 0.051593, l6: 0.052702

[epoch:  57/100000, batch:   154/  187, ite: 5341] train loss: 0.326694, tar: 0.035222 
l0: 0.037063, l1: 0.041028, l2: 0.039745, l3: 0.043556, l4: 0.051141, l5: 0.043823, l6: 0.036003

[epoch:  57/100000, batch:   156/  187, ite: 5342] train loss: 0.326668, tar: 0.035223 
l0: 0.019693, l1: 0.019038, l2: 0.020310, l3: 0.022392, l4: 0.048988, l5: 0.049263, l6: 0.049333

[epoch:  57/100000, batch:   158/  187, ite: 5343] train loss: 0.326595, tar: 0.035212 
l0: 0.028944, l1: 0.027570, l2: 0.037364, l3: 0.044849, l4: 0.052094, l5: 0.050568, l6: 0.047798

[epoch:  57/100000, batch:   160/  187, ite: 5344] train loss: 0.326568, tar: 0.035207 
l0: 0.029776, l1: 0.029358, l2: 0.033537, l3: 0.034327, l4: 0.047801, l5: 0.050517, l6: 0.049842

[epoch:  57/100000, batch:   162/  187, ite: 5345] train loss: 0.326529, tar: 0.035203 
l0: 0.045073, l1: 0.042775, l2: 0.061178, l3: 0.062180, l4: 0.059290, l5: 0.059278, l6: 0.060845

[epoch:  57/100000, batch:   164/  187, ite: 5346] train loss: 0.326577, tar: 0.035210 
l0: 0.018706, l1: 0.020441, l2: 0.023447, l3: 0.020522, l4: 0.026980, l5: 0.026212, l6: 0.022534

[epoch:  57/100000, batch:   166/  187, ite: 5347] train loss: 0.326452, tar: 0.035198 
l0: 0.014297, l1: 0.016617, l2: 0.016783, l3: 0.017977, l4: 0.034110, l5: 0.031596, l6: 0.036873

[epoch:  57/100000, batch:   168/  187, ite: 5348] train loss: 0.326335, tar: 0.035183 
l0: 0.029465, l1: 0.027715, l2: 0.033140, l3: 0.039609, l4: 0.056982, l5: 0.061204, l6: 0.052612

[epoch:  57/100000, batch:   170/  187, ite: 5349] train loss: 0.326316, tar: 0.035178 
l0: 0.022621, l1: 0.025013, l2: 0.035464, l3: 0.032534, l4: 0.057988, l5: 0.048620, l6: 0.044355

[epoch:  57/100000, batch:   172/  187, ite: 5350] train loss: 0.326272, tar: 0.035169 
l0: 0.039883, l1: 0.038341, l2: 0.043059, l3: 0.053515, l4: 0.083837, l5: 0.079632, l6: 0.057955

[epoch:  57/100000, batch:   174/  187, ite: 5351] train loss: 0.326324, tar: 0.035172 
l0: 0.020357, l1: 0.018244, l2: 0.026931, l3: 0.034424, l4: 0.040542, l5: 0.040209, l6: 0.049423

[epoch:  57/100000, batch:   176/  187, ite: 5352] train loss: 0.326252, tar: 0.035161 
l0: 0.028410, l1: 0.027484, l2: 0.030212, l3: 0.035986, l4: 0.050873, l5: 0.049662, l6: 0.055710

[epoch:  57/100000, batch:   178/  187, ite: 5353] train loss: 0.326217, tar: 0.035157 
l0: 0.013549, l1: 0.013650, l2: 0.015652, l3: 0.018134, l4: 0.036951, l5: 0.038932, l6: 0.040834

[epoch:  57/100000, batch:   180/  187, ite: 5354] train loss: 0.326107, tar: 0.035141 
l0: 0.021573, l1: 0.024738, l2: 0.033563, l3: 0.032928, l4: 0.032295, l5: 0.032455, l6: 0.026799

[epoch:  57/100000, batch:   182/  187, ite: 5355] train loss: 0.326018, tar: 0.035131 
l0: 0.022064, l1: 0.023346, l2: 0.024380, l3: 0.023948, l4: 0.029827, l5: 0.031741, l6: 0.032495

[epoch:  57/100000, batch:   184/  187, ite: 5356] train loss: 0.325916, tar: 0.035121 
l0: 0.050183, l1: 0.057019, l2: 0.049568, l3: 0.055108, l4: 0.043557, l5: 0.043930, l6: 0.051733

[epoch:  57/100000, batch:   186/  187, ite: 5357] train loss: 0.325934, tar: 0.035132 
l0: 0.020778, l1: 0.024836, l2: 0.024785, l3: 0.025319, l4: 0.039704, l5: 0.031747, l6: 0.036767

[epoch:  57/100000, batch:   188/  187, ite: 5358] train loss: 0.325844, tar: 0.035121 
l0: 0.030185, l1: 0.030562, l2: 0.031171, l3: 0.034457, l4: 0.048738, l5: 0.044124, l6: 0.045808

[epoch:  58/100000, batch:     2/  187, ite: 5359] train loss: 0.325800, tar: 0.035118 
l0: 0.030146, l1: 0.031395, l2: 0.033237, l3: 0.033096, l4: 0.053033, l5: 0.045536, l6: 0.042724

[epoch:  58/100000, batch:     4/  187, ite: 5360] train loss: 0.325758, tar: 0.035114 
l0: 0.055430, l1: 0.055564, l2: 0.074895, l3: 0.079075, l4: 0.052364, l5: 0.050762, l6: 0.055600

[epoch:  58/100000, batch:     6/  187, ite: 5361] train loss: 0.325830, tar: 0.035129 
l0: 0.012606, l1: 0.011473, l2: 0.019184, l3: 0.021056, l4: 0.035626, l5: 0.037513, l6: 0.031454

[epoch:  58/100000, batch:     8/  187, ite: 5362] train loss: 0.325715, tar: 0.035113 
l0: 0.015472, l1: 0.016840, l2: 0.017920, l3: 0.017924, l4: 0.027993, l5: 0.028870, l6: 0.025286

[epoch:  58/100000, batch:    10/  187, ite: 5363] train loss: 0.325586, tar: 0.035098 
l0: 0.024844, l1: 0.022547, l2: 0.031653, l3: 0.035991, l4: 0.050432, l5: 0.052708, l6: 0.055767

[epoch:  58/100000, batch:    12/  187, ite: 5364] train loss: 0.325548, tar: 0.035091 
l0: 0.014690, l1: 0.015601, l2: 0.017201, l3: 0.020163, l4: 0.021822, l5: 0.018977, l6: 0.023707

[epoch:  58/100000, batch:    14/  187, ite: 5365] train loss: 0.325406, tar: 0.035076 
l0: 0.016591, l1: 0.016159, l2: 0.024335, l3: 0.024399, l4: 0.035704, l5: 0.040304, l6: 0.042471

[epoch:  58/100000, batch:    16/  187, ite: 5366] train loss: 0.325315, tar: 0.035062 
l0: 0.022824, l1: 0.021475, l2: 0.029512, l3: 0.027778, l4: 0.033880, l5: 0.043055, l6: 0.035072

[epoch:  58/100000, batch:    18/  187, ite: 5367] train loss: 0.325233, tar: 0.035053 
l0: 0.024817, l1: 0.025165, l2: 0.025980, l3: 0.025792, l4: 0.034365, l5: 0.037073, l6: 0.043594

[epoch:  58/100000, batch:    20/  187, ite: 5368] train loss: 0.325154, tar: 0.035046 
l0: 0.025139, l1: 0.022189, l2: 0.045739, l3: 0.045607, l4: 0.049919, l5: 0.050844, l6: 0.050417

[epoch:  58/100000, batch:    22/  187, ite: 5369] train loss: 0.325128, tar: 0.035038 
l0: 0.023919, l1: 0.026299, l2: 0.024460, l3: 0.026265, l4: 0.039098, l5: 0.049915, l6: 0.043035

[epoch:  58/100000, batch:    24/  187, ite: 5370] train loss: 0.325061, tar: 0.035030 
l0: 0.022942, l1: 0.023559, l2: 0.033897, l3: 0.035540, l4: 0.043328, l5: 0.042320, l6: 0.049502

[epoch:  58/100000, batch:    26/  187, ite: 5371] train loss: 0.325007, tar: 0.035022 
l0: 0.029564, l1: 0.032055, l2: 0.034325, l3: 0.030867, l4: 0.035816, l5: 0.035552, l6: 0.033639

[epoch:  58/100000, batch:    28/  187, ite: 5372] train loss: 0.324939, tar: 0.035018 
l0: 0.023531, l1: 0.022111, l2: 0.036704, l3: 0.040227, l4: 0.048402, l5: 0.042943, l6: 0.045915

[epoch:  58/100000, batch:    30/  187, ite: 5373] train loss: 0.324891, tar: 0.035009 
l0: 0.029603, l1: 0.030753, l2: 0.027927, l3: 0.027289, l4: 0.043129, l5: 0.048851, l6: 0.047307

[epoch:  58/100000, batch:    32/  187, ite: 5374] train loss: 0.324840, tar: 0.035005 
l0: 0.016471, l1: 0.016295, l2: 0.025412, l3: 0.029423, l4: 0.049813, l5: 0.042064, l6: 0.038127

[epoch:  58/100000, batch:    34/  187, ite: 5375] train loss: 0.324762, tar: 0.034992 
l0: 0.019659, l1: 0.022044, l2: 0.021469, l3: 0.023421, l4: 0.045790, l5: 0.044439, l6: 0.046863

[epoch:  58/100000, batch:    36/  187, ite: 5376] train loss: 0.324689, tar: 0.034981 
l0: 0.013475, l1: 0.015853, l2: 0.012511, l3: 0.014607, l4: 0.023065, l5: 0.029643, l6: 0.032434

[epoch:  58/100000, batch:    38/  187, ite: 5377] train loss: 0.324556, tar: 0.034965 
l0: 0.011406, l1: 0.010766, l2: 0.013785, l3: 0.014863, l4: 0.021392, l5: 0.021480, l6: 0.020226

[epoch:  58/100000, batch:    40/  187, ite: 5378] train loss: 0.324403, tar: 0.034948 
l0: 0.032488, l1: 0.040883, l2: 0.043779, l3: 0.037312, l4: 0.031006, l5: 0.026289, l6: 0.034625

[epoch:  58/100000, batch:    42/  187, ite: 5379] train loss: 0.324346, tar: 0.034946 
l0: 0.048157, l1: 0.055127, l2: 0.047594, l3: 0.042997, l4: 0.035220, l5: 0.041498, l6: 0.048554

[epoch:  58/100000, batch:    44/  187, ite: 5380] train loss: 0.324343, tar: 0.034956 
l0: 0.014281, l1: 0.014469, l2: 0.020329, l3: 0.026048, l4: 0.046007, l5: 0.048663, l6: 0.038926

[epoch:  58/100000, batch:    46/  187, ite: 5381] train loss: 0.324259, tar: 0.034941 
l0: 0.017775, l1: 0.018445, l2: 0.022307, l3: 0.024063, l4: 0.034827, l5: 0.036330, l6: 0.030716

[epoch:  58/100000, batch:    48/  187, ite: 5382] train loss: 0.324158, tar: 0.034928 
l0: 0.021017, l1: 0.023107, l2: 0.020424, l3: 0.027499, l4: 0.034170, l5: 0.032872, l6: 0.027354

[epoch:  58/100000, batch:    50/  187, ite: 5383] train loss: 0.324058, tar: 0.034918 
l0: 0.012178, l1: 0.015134, l2: 0.012267, l3: 0.014885, l4: 0.017417, l5: 0.021106, l6: 0.023068

[epoch:  58/100000, batch:    52/  187, ite: 5384] train loss: 0.323908, tar: 0.034902 
l0: 0.016819, l1: 0.015469, l2: 0.032008, l3: 0.034002, l4: 0.025950, l5: 0.032819, l6: 0.029612

[epoch:  58/100000, batch:    54/  187, ite: 5385] train loss: 0.323809, tar: 0.034889 
l0: 0.027141, l1: 0.030868, l2: 0.020202, l3: 0.017408, l4: 0.036469, l5: 0.036989, l6: 0.037143

[epoch:  58/100000, batch:    56/  187, ite: 5386] train loss: 0.323724, tar: 0.034883 
l0: 0.034289, l1: 0.032077, l2: 0.043818, l3: 0.040585, l4: 0.066875, l5: 0.061039, l6: 0.049684

[epoch:  58/100000, batch:    58/  187, ite: 5387] train loss: 0.323727, tar: 0.034883 
l0: 0.022878, l1: 0.022239, l2: 0.036029, l3: 0.041605, l4: 0.042987, l5: 0.045763, l6: 0.037929

[epoch:  58/100000, batch:    60/  187, ite: 5388] train loss: 0.323674, tar: 0.034874 
l0: 0.012342, l1: 0.013153, l2: 0.014799, l3: 0.016557, l4: 0.019054, l5: 0.018524, l6: 0.017543

[epoch:  58/100000, batch:    62/  187, ite: 5389] train loss: 0.323521, tar: 0.034858 
l0: 0.029881, l1: 0.033431, l2: 0.032939, l3: 0.031344, l4: 0.043667, l5: 0.033789, l6: 0.036721

[epoch:  58/100000, batch:    64/  187, ite: 5390] train loss: 0.323463, tar: 0.034854 
l0: 0.029999, l1: 0.031271, l2: 0.033016, l3: 0.029526, l4: 0.063163, l5: 0.063415, l6: 0.064255

[epoch:  58/100000, batch:    66/  187, ite: 5391] train loss: 0.323456, tar: 0.034851 
l0: 0.031794, l1: 0.029403, l2: 0.042611, l3: 0.046635, l4: 0.033191, l5: 0.034379, l6: 0.040009

[epoch:  58/100000, batch:    68/  187, ite: 5392] train loss: 0.323409, tar: 0.034849 
l0: 0.017592, l1: 0.017839, l2: 0.030685, l3: 0.033917, l4: 0.025838, l5: 0.029832, l6: 0.028030

[epoch:  58/100000, batch:    70/  187, ite: 5393] train loss: 0.323309, tar: 0.034836 
l0: 0.015126, l1: 0.015306, l2: 0.017704, l3: 0.018501, l4: 0.030664, l5: 0.026659, l6: 0.026421

[epoch:  58/100000, batch:    72/  187, ite: 5394] train loss: 0.323185, tar: 0.034822 
l0: 0.022797, l1: 0.021984, l2: 0.029375, l3: 0.032906, l4: 0.034916, l5: 0.033507, l6: 0.031139

[epoch:  58/100000, batch:    74/  187, ite: 5395] train loss: 0.323101, tar: 0.034813 
l0: 0.019829, l1: 0.018111, l2: 0.020770, l3: 0.024238, l4: 0.040232, l5: 0.039452, l6: 0.045272

[epoch:  58/100000, batch:    76/  187, ite: 5396] train loss: 0.323019, tar: 0.034803 
l0: 0.024805, l1: 0.027697, l2: 0.026831, l3: 0.026811, l4: 0.032376, l5: 0.034900, l6: 0.038236

[epoch:  58/100000, batch:    78/  187, ite: 5397] train loss: 0.322939, tar: 0.034796 
l0: 0.016443, l1: 0.018409, l2: 0.018324, l3: 0.021278, l4: 0.032085, l5: 0.024215, l6: 0.027668

[epoch:  58/100000, batch:    80/  187, ite: 5398] train loss: 0.322821, tar: 0.034782 
l0: 0.018856, l1: 0.016238, l2: 0.023459, l3: 0.025409, l4: 0.032735, l5: 0.042091, l6: 0.048683

[epoch:  58/100000, batch:    82/  187, ite: 5399] train loss: 0.322739, tar: 0.034771 
l0: 0.021227, l1: 0.021116, l2: 0.023781, l3: 0.026672, l4: 0.035943, l5: 0.041436, l6: 0.043975

[epoch:  58/100000, batch:    84/  187, ite: 5400] train loss: 0.322661, tar: 0.034761 
l0: 0.020598, l1: 0.020398, l2: 0.022286, l3: 0.024979, l4: 0.058582, l5: 0.056433, l6: 0.056444

[epoch:  58/100000, batch:    86/  187, ite: 5401] train loss: 0.322617, tar: 0.034751 
l0: 0.027039, l1: 0.025553, l2: 0.029652, l3: 0.029580, l4: 0.047773, l5: 0.055238, l6: 0.068796

[epoch:  58/100000, batch:    88/  187, ite: 5402] train loss: 0.322589, tar: 0.034746 
l0: 0.036050, l1: 0.044769, l2: 0.033543, l3: 0.041353, l4: 0.040792, l5: 0.038311, l6: 0.038971

[epoch:  58/100000, batch:    90/  187, ite: 5403] train loss: 0.322554, tar: 0.034747 
l0: 0.039279, l1: 0.032532, l2: 0.041115, l3: 0.055624, l4: 0.081428, l5: 0.087395, l6: 0.090515

[epoch:  58/100000, batch:    92/  187, ite: 5404] train loss: 0.322629, tar: 0.034750 
l0: 0.023904, l1: 0.024427, l2: 0.028940, l3: 0.028560, l4: 0.033922, l5: 0.031290, l6: 0.031099

[epoch:  58/100000, batch:    94/  187, ite: 5405] train loss: 0.322543, tar: 0.034742 
l0: 0.033597, l1: 0.038238, l2: 0.045890, l3: 0.043603, l4: 0.043980, l5: 0.033016, l6: 0.020827

[epoch:  58/100000, batch:    96/  187, ite: 5406] train loss: 0.322498, tar: 0.034741 
l0: 0.022169, l1: 0.024509, l2: 0.023358, l3: 0.021461, l4: 0.029704, l5: 0.032126, l6: 0.032908

[epoch:  58/100000, batch:    98/  187, ite: 5407] train loss: 0.322401, tar: 0.034732 
l0: 0.017913, l1: 0.020571, l2: 0.019472, l3: 0.021998, l4: 0.025989, l5: 0.024398, l6: 0.021267

[epoch:  58/100000, batch:   100/  187, ite: 5408] train loss: 0.322280, tar: 0.034721 
l0: 0.044079, l1: 0.045230, l2: 0.046976, l3: 0.052643, l4: 0.049172, l5: 0.049242, l6: 0.048530

[epoch:  58/100000, batch:   102/  187, ite: 5409] train loss: 0.322290, tar: 0.034727 
l0: 0.050518, l1: 0.051874, l2: 0.033353, l3: 0.040408, l4: 0.065346, l5: 0.082296, l6: 0.066933

[epoch:  58/100000, batch:   104/  187, ite: 5410] train loss: 0.322338, tar: 0.034738 
l0: 0.038467, l1: 0.032642, l2: 0.056037, l3: 0.068364, l4: 0.077359, l5: 0.074269, l6: 0.083080

[epoch:  58/100000, batch:   106/  187, ite: 5411] train loss: 0.322415, tar: 0.034741 
l0: 0.023850, l1: 0.026732, l2: 0.018731, l3: 0.020537, l4: 0.028935, l5: 0.031443, l6: 0.028655

[epoch:  58/100000, batch:   108/  187, ite: 5412] train loss: 0.322313, tar: 0.034733 
l0: 0.030529, l1: 0.029810, l2: 0.033918, l3: 0.035703, l4: 0.046994, l5: 0.047448, l6: 0.047377

[epoch:  58/100000, batch:   110/  187, ite: 5413] train loss: 0.322277, tar: 0.034730 
l0: 0.019234, l1: 0.018182, l2: 0.024542, l3: 0.030900, l4: 0.034037, l5: 0.032806, l6: 0.035542

[epoch:  58/100000, batch:   112/  187, ite: 5414] train loss: 0.322187, tar: 0.034719 
l0: 0.020648, l1: 0.020323, l2: 0.024797, l3: 0.021429, l4: 0.038628, l5: 0.047644, l6: 0.035668

[epoch:  58/100000, batch:   114/  187, ite: 5415] train loss: 0.322107, tar: 0.034709 
l0: 0.033851, l1: 0.032766, l2: 0.034279, l3: 0.040063, l4: 0.050557, l5: 0.056140, l6: 0.049325

[epoch:  58/100000, batch:   116/  187, ite: 5416] train loss: 0.322090, tar: 0.034709 
l0: 0.016238, l1: 0.016472, l2: 0.017735, l3: 0.018626, l4: 0.039600, l5: 0.042142, l6: 0.041128

[epoch:  58/100000, batch:   118/  187, ite: 5417] train loss: 0.321998, tar: 0.034696 
l0: 0.016880, l1: 0.018733, l2: 0.017786, l3: 0.019145, l4: 0.025060, l5: 0.027180, l6: 0.029781

[epoch:  58/100000, batch:   120/  187, ite: 5418] train loss: 0.321880, tar: 0.034683 
l0: 0.027682, l1: 0.030169, l2: 0.041205, l3: 0.033418, l4: 0.057540, l5: 0.057723, l6: 0.048671

[epoch:  58/100000, batch:   122/  187, ite: 5419] train loss: 0.321862, tar: 0.034678 
l0: 0.025016, l1: 0.025827, l2: 0.030617, l3: 0.032151, l4: 0.050871, l5: 0.053761, l6: 0.058758

[epoch:  58/100000, batch:   124/  187, ite: 5420] train loss: 0.321830, tar: 0.034671 
l0: 0.024039, l1: 0.026927, l2: 0.027787, l3: 0.026620, l4: 0.039014, l5: 0.038801, l6: 0.040463

[epoch:  58/100000, batch:   126/  187, ite: 5421] train loss: 0.321761, tar: 0.034664 
l0: 0.032287, l1: 0.034480, l2: 0.037496, l3: 0.035408, l4: 0.042718, l5: 0.043063, l6: 0.042825

[epoch:  58/100000, batch:   128/  187, ite: 5422] train loss: 0.321724, tar: 0.034662 
l0: 0.032991, l1: 0.034580, l2: 0.026911, l3: 0.032494, l4: 0.074676, l5: 0.064485, l6: 0.061311

[epoch:  58/100000, batch:   130/  187, ite: 5423] train loss: 0.321728, tar: 0.034661 
l0: 0.020287, l1: 0.020363, l2: 0.028334, l3: 0.025739, l4: 0.032069, l5: 0.031827, l6: 0.029486

[epoch:  58/100000, batch:   132/  187, ite: 5424] train loss: 0.321634, tar: 0.034651 
l0: 0.024588, l1: 0.021793, l2: 0.029093, l3: 0.033966, l4: 0.055422, l5: 0.076045, l6: 0.076615

[epoch:  58/100000, batch:   134/  187, ite: 5425] train loss: 0.321631, tar: 0.034644 
l0: 0.015918, l1: 0.015811, l2: 0.021316, l3: 0.020016, l4: 0.034005, l5: 0.033752, l6: 0.035117

[epoch:  58/100000, batch:   136/  187, ite: 5426] train loss: 0.321529, tar: 0.034631 
l0: 0.016397, l1: 0.017011, l2: 0.014827, l3: 0.014361, l4: 0.032601, l5: 0.037399, l6: 0.036547

[epoch:  58/100000, batch:   138/  187, ite: 5427] train loss: 0.321422, tar: 0.034618 
l0: 0.020395, l1: 0.019284, l2: 0.026949, l3: 0.028255, l4: 0.054093, l5: 0.059442, l6: 0.059100

[epoch:  58/100000, batch:   140/  187, ite: 5428] train loss: 0.321384, tar: 0.034608 
l0: 0.021235, l1: 0.024698, l2: 0.022870, l3: 0.022050, l4: 0.041282, l5: 0.034956, l6: 0.031618

[epoch:  58/100000, batch:   142/  187, ite: 5429] train loss: 0.321298, tar: 0.034599 
l0: 0.044457, l1: 0.046719, l2: 0.043867, l3: 0.045641, l4: 0.042082, l5: 0.040763, l6: 0.040958

[epoch:  58/100000, batch:   144/  187, ite: 5430] train loss: 0.321287, tar: 0.034606 
l0: 0.035485, l1: 0.032530, l2: 0.053336, l3: 0.048951, l4: 0.066983, l5: 0.073664, l6: 0.068966

[epoch:  58/100000, batch:   146/  187, ite: 5431] train loss: 0.321327, tar: 0.034606 
l0: 0.022881, l1: 0.022580, l2: 0.026657, l3: 0.028832, l4: 0.058107, l5: 0.064396, l6: 0.060000

[epoch:  58/100000, batch:   148/  187, ite: 5432] train loss: 0.321301, tar: 0.034598 
l0: 0.021570, l1: 0.022965, l2: 0.025343, l3: 0.024964, l4: 0.031748, l5: 0.034649, l6: 0.031789

[epoch:  58/100000, batch:   150/  187, ite: 5433] train loss: 0.321212, tar: 0.034589 
l0: 0.010083, l1: 0.010965, l2: 0.010471, l3: 0.012828, l4: 0.029060, l5: 0.031893, l6: 0.035901

[epoch:  58/100000, batch:   152/  187, ite: 5434] train loss: 0.321086, tar: 0.034572 
l0: 0.032907, l1: 0.031714, l2: 0.035400, l3: 0.037934, l4: 0.044134, l5: 0.045075, l6: 0.052071

[epoch:  58/100000, batch:   154/  187, ite: 5435] train loss: 0.321057, tar: 0.034571 
l0: 0.031883, l1: 0.032004, l2: 0.032340, l3: 0.035199, l4: 0.051133, l5: 0.052102, l6: 0.048794

[epoch:  58/100000, batch:   156/  187, ite: 5436] train loss: 0.321031, tar: 0.034569 
l0: 0.012783, l1: 0.012145, l2: 0.016635, l3: 0.016843, l4: 0.022620, l5: 0.025857, l6: 0.030786

[epoch:  58/100000, batch:   158/  187, ite: 5437] train loss: 0.320903, tar: 0.034554 
l0: 0.014261, l1: 0.015321, l2: 0.014627, l3: 0.019599, l4: 0.030952, l5: 0.040022, l6: 0.047792

[epoch:  58/100000, batch:   160/  187, ite: 5438] train loss: 0.320807, tar: 0.034540 
l0: 0.027119, l1: 0.027576, l2: 0.034740, l3: 0.031005, l4: 0.044800, l5: 0.044944, l6: 0.040047

[epoch:  58/100000, batch:   162/  187, ite: 5439] train loss: 0.320758, tar: 0.034534 
l0: 0.028020, l1: 0.030432, l2: 0.025935, l3: 0.033360, l4: 0.033297, l5: 0.031914, l6: 0.037256

[epoch:  58/100000, batch:   164/  187, ite: 5440] train loss: 0.320688, tar: 0.034530 
l0: 0.026459, l1: 0.024508, l2: 0.038543, l3: 0.036064, l4: 0.041805, l5: 0.047169, l6: 0.045335

[epoch:  58/100000, batch:   166/  187, ite: 5441] train loss: 0.320646, tar: 0.034524 
l0: 0.023718, l1: 0.024941, l2: 0.035576, l3: 0.032304, l4: 0.038986, l5: 0.035961, l6: 0.034690

[epoch:  58/100000, batch:   168/  187, ite: 5442] train loss: 0.320580, tar: 0.034517 
l0: 0.032543, l1: 0.038172, l2: 0.034333, l3: 0.032777, l4: 0.025444, l5: 0.030140, l6: 0.035110

[epoch:  58/100000, batch:   170/  187, ite: 5443] train loss: 0.320516, tar: 0.034515 
l0: 0.030793, l1: 0.028849, l2: 0.036310, l3: 0.037193, l4: 0.050545, l5: 0.053377, l6: 0.047333

[epoch:  58/100000, batch:   172/  187, ite: 5444] train loss: 0.320491, tar: 0.034513 
l0: 0.021422, l1: 0.021671, l2: 0.024039, l3: 0.027188, l4: 0.043254, l5: 0.037093, l6: 0.044290

[epoch:  58/100000, batch:   174/  187, ite: 5445] train loss: 0.320421, tar: 0.034504 
l0: 0.019141, l1: 0.021028, l2: 0.020660, l3: 0.021751, l4: 0.036928, l5: 0.037322, l6: 0.035972

[epoch:  58/100000, batch:   176/  187, ite: 5446] train loss: 0.320333, tar: 0.034493 
l0: 0.022938, l1: 0.024284, l2: 0.021889, l3: 0.021861, l4: 0.046252, l5: 0.039002, l6: 0.041273

[epoch:  58/100000, batch:   178/  187, ite: 5447] train loss: 0.320262, tar: 0.034485 
l0: 0.032332, l1: 0.030643, l2: 0.036606, l3: 0.039448, l4: 0.066041, l5: 0.076259, l6: 0.079282

[epoch:  58/100000, batch:   180/  187, ite: 5448] train loss: 0.320290, tar: 0.034484 
l0: 0.024455, l1: 0.024486, l2: 0.024489, l3: 0.027916, l4: 0.048810, l5: 0.047932, l6: 0.047859

[epoch:  58/100000, batch:   182/  187, ite: 5449] train loss: 0.320238, tar: 0.034477 
l0: 0.016402, l1: 0.015788, l2: 0.023859, l3: 0.028041, l4: 0.036678, l5: 0.032813, l6: 0.033045

[epoch:  58/100000, batch:   184/  187, ite: 5450] train loss: 0.320146, tar: 0.034464 
l0: 0.026309, l1: 0.025383, l2: 0.033147, l3: 0.035406, l4: 0.052473, l5: 0.041810, l6: 0.046169

[epoch:  58/100000, batch:   186/  187, ite: 5451] train loss: 0.320105, tar: 0.034459 
l0: 0.026933, l1: 0.028516, l2: 0.031882, l3: 0.028419, l4: 0.036792, l5: 0.040127, l6: 0.049027

[epoch:  58/100000, batch:   188/  187, ite: 5452] train loss: 0.320051, tar: 0.034454 
l0: 0.024539, l1: 0.023516, l2: 0.038285, l3: 0.041084, l4: 0.048342, l5: 0.056838, l6: 0.048697

[epoch:  59/100000, batch:     2/  187, ite: 5453] train loss: 0.320025, tar: 0.034447 
l0: 0.019266, l1: 0.020593, l2: 0.024155, l3: 0.021360, l4: 0.037139, l5: 0.045882, l6: 0.041958

[epoch:  59/100000, batch:     4/  187, ite: 5454] train loss: 0.319949, tar: 0.034436 
l0: 0.015196, l1: 0.014948, l2: 0.021998, l3: 0.024796, l4: 0.029689, l5: 0.028417, l6: 0.035144

[epoch:  59/100000, batch:     6/  187, ite: 5455] train loss: 0.319846, tar: 0.034423 
l0: 0.018272, l1: 0.019580, l2: 0.028353, l3: 0.024442, l4: 0.030911, l5: 0.029369, l6: 0.024992

[epoch:  59/100000, batch:     8/  187, ite: 5456] train loss: 0.319747, tar: 0.034412 
l0: 0.020534, l1: 0.019904, l2: 0.023035, l3: 0.025974, l4: 0.036720, l5: 0.036476, l6: 0.041249

[epoch:  59/100000, batch:    10/  187, ite: 5457] train loss: 0.319668, tar: 0.034402 
l0: 0.019312, l1: 0.017361, l2: 0.032088, l3: 0.035051, l4: 0.049636, l5: 0.046373, l6: 0.046695

[epoch:  59/100000, batch:    12/  187, ite: 5458] train loss: 0.319618, tar: 0.034392 
l0: 0.030343, l1: 0.031939, l2: 0.030899, l3: 0.034062, l4: 0.029600, l5: 0.028554, l6: 0.039843

[epoch:  59/100000, batch:    14/  187, ite: 5459] train loss: 0.319553, tar: 0.034389 
l0: 0.070359, l1: 0.073000, l2: 0.085673, l3: 0.084318, l4: 0.075547, l5: 0.058434, l6: 0.060918

[epoch:  59/100000, batch:    16/  187, ite: 5460] train loss: 0.319682, tar: 0.034414 
l0: 0.025849, l1: 0.025756, l2: 0.026666, l3: 0.032923, l4: 0.045897, l5: 0.049759, l6: 0.052337

[epoch:  59/100000, batch:    18/  187, ite: 5461] train loss: 0.319641, tar: 0.034408 
l0: 0.027311, l1: 0.026400, l2: 0.030883, l3: 0.033761, l4: 0.057573, l5: 0.053252, l6: 0.064477

[epoch:  59/100000, batch:    20/  187, ite: 5462] train loss: 0.319623, tar: 0.034403 
l0: 0.024381, l1: 0.021215, l2: 0.037172, l3: 0.036224, l4: 0.037770, l5: 0.045204, l6: 0.051765

[epoch:  59/100000, batch:    22/  187, ite: 5463] train loss: 0.319578, tar: 0.034396 
l0: 0.016901, l1: 0.018394, l2: 0.018546, l3: 0.019345, l4: 0.030037, l5: 0.030006, l6: 0.030310

[epoch:  59/100000, batch:    24/  187, ite: 5464] train loss: 0.319472, tar: 0.034384 
l0: 0.023246, l1: 0.026614, l2: 0.031713, l3: 0.033146, l4: 0.024562, l5: 0.023156, l6: 0.030344

[epoch:  59/100000, batch:    26/  187, ite: 5465] train loss: 0.319385, tar: 0.034377 
l0: 0.012334, l1: 0.012589, l2: 0.020899, l3: 0.020892, l4: 0.038692, l5: 0.032490, l6: 0.041246

[epoch:  59/100000, batch:    28/  187, ite: 5466] train loss: 0.319289, tar: 0.034362 
l0: 0.019657, l1: 0.019229, l2: 0.024501, l3: 0.029848, l4: 0.038470, l5: 0.036047, l6: 0.035068

[epoch:  59/100000, batch:    30/  187, ite: 5467] train loss: 0.319210, tar: 0.034352 
l0: 0.019892, l1: 0.022886, l2: 0.016651, l3: 0.019264, l4: 0.026964, l5: 0.028933, l6: 0.035157

[epoch:  59/100000, batch:    32/  187, ite: 5468] train loss: 0.319108, tar: 0.034342 
l0: 0.037800, l1: 0.037262, l2: 0.047923, l3: 0.054176, l4: 0.058484, l5: 0.053709, l6: 0.051849

[epoch:  59/100000, batch:    34/  187, ite: 5469] train loss: 0.319123, tar: 0.034344 
l0: 0.020267, l1: 0.025397, l2: 0.026399, l3: 0.023681, l4: 0.031440, l5: 0.030675, l6: 0.035962

[epoch:  59/100000, batch:    36/  187, ite: 5470] train loss: 0.319038, tar: 0.034335 
l0: 0.014640, l1: 0.015700, l2: 0.017709, l3: 0.017786, l4: 0.027934, l5: 0.026347, l6: 0.023353

[epoch:  59/100000, batch:    38/  187, ite: 5471] train loss: 0.318919, tar: 0.034321 
l0: 0.017799, l1: 0.017424, l2: 0.021776, l3: 0.026737, l4: 0.036119, l5: 0.035591, l6: 0.033877

[epoch:  59/100000, batch:    40/  187, ite: 5472] train loss: 0.318831, tar: 0.034310 
l0: 0.029466, l1: 0.030055, l2: 0.028308, l3: 0.031532, l4: 0.058897, l5: 0.058170, l6: 0.055330

[epoch:  59/100000, batch:    42/  187, ite: 5473] train loss: 0.318812, tar: 0.034307 
l0: 0.019668, l1: 0.022727, l2: 0.020870, l3: 0.020892, l4: 0.037091, l5: 0.043324, l6: 0.037581

[epoch:  59/100000, batch:    44/  187, ite: 5474] train loss: 0.318733, tar: 0.034297 
l0: 0.012741, l1: 0.012863, l2: 0.032807, l3: 0.030408, l4: 0.024558, l5: 0.022000, l6: 0.018573

[epoch:  59/100000, batch:    46/  187, ite: 5475] train loss: 0.318621, tar: 0.034282 
l0: 0.017840, l1: 0.018705, l2: 0.020442, l3: 0.020730, l4: 0.027192, l5: 0.025560, l6: 0.026574

[epoch:  59/100000, batch:    48/  187, ite: 5476] train loss: 0.318512, tar: 0.034271 
l0: 0.016577, l1: 0.016809, l2: 0.017372, l3: 0.025073, l4: 0.045735, l5: 0.047986, l6: 0.046841

[epoch:  59/100000, batch:    50/  187, ite: 5477] train loss: 0.318443, tar: 0.034259 
l0: 0.018304, l1: 0.018689, l2: 0.019398, l3: 0.023882, l4: 0.036712, l5: 0.043389, l6: 0.032879

[epoch:  59/100000, batch:    52/  187, ite: 5478] train loss: 0.318358, tar: 0.034248 
l0: 0.020928, l1: 0.021226, l2: 0.021566, l3: 0.024562, l4: 0.031310, l5: 0.027506, l6: 0.027984

[epoch:  59/100000, batch:    54/  187, ite: 5479] train loss: 0.318261, tar: 0.034239 
l0: 0.017599, l1: 0.017666, l2: 0.021246, l3: 0.024813, l4: 0.041704, l5: 0.038196, l6: 0.037844

[epoch:  59/100000, batch:    56/  187, ite: 5480] train loss: 0.318181, tar: 0.034228 
l0: 0.031047, l1: 0.031215, l2: 0.039865, l3: 0.042104, l4: 0.034537, l5: 0.033664, l6: 0.037381

[epoch:  59/100000, batch:    58/  187, ite: 5481] train loss: 0.318134, tar: 0.034226 
l0: 0.017846, l1: 0.016041, l2: 0.027415, l3: 0.027300, l4: 0.037171, l5: 0.041298, l6: 0.031977

[epoch:  59/100000, batch:    60/  187, ite: 5482] train loss: 0.318054, tar: 0.034215 
l0: 0.030734, l1: 0.026965, l2: 0.056385, l3: 0.045188, l4: 0.076970, l5: 0.073769, l6: 0.072527

[epoch:  59/100000, batch:    62/  187, ite: 5483] train loss: 0.318098, tar: 0.034213 
l0: 0.010435, l1: 0.012048, l2: 0.011904, l3: 0.017364, l4: 0.024106, l5: 0.027845, l6: 0.023608

[epoch:  59/100000, batch:    64/  187, ite: 5484] train loss: 0.317969, tar: 0.034196 
l0: 0.029226, l1: 0.032879, l2: 0.025058, l3: 0.025863, l4: 0.044033, l5: 0.049403, l6: 0.036116

[epoch:  59/100000, batch:    66/  187, ite: 5485] train loss: 0.317918, tar: 0.034193 
l0: 0.021316, l1: 0.020262, l2: 0.026584, l3: 0.028276, l4: 0.041365, l5: 0.041939, l6: 0.043115

[epoch:  59/100000, batch:    68/  187, ite: 5486] train loss: 0.317854, tar: 0.034184 
l0: 0.017883, l1: 0.018515, l2: 0.026589, l3: 0.025660, l4: 0.025409, l5: 0.024797, l6: 0.026676

[epoch:  59/100000, batch:    70/  187, ite: 5487] train loss: 0.317752, tar: 0.034174 
l0: 0.021512, l1: 0.022038, l2: 0.029490, l3: 0.037662, l4: 0.032438, l5: 0.029120, l6: 0.028141

[epoch:  59/100000, batch:    72/  187, ite: 5488] train loss: 0.317673, tar: 0.034165 
l0: 0.016575, l1: 0.016533, l2: 0.018507, l3: 0.022903, l4: 0.034722, l5: 0.042137, l6: 0.035964

[epoch:  59/100000, batch:    74/  187, ite: 5489] train loss: 0.317585, tar: 0.034153 
l0: 0.024023, l1: 0.026271, l2: 0.024022, l3: 0.024065, l4: 0.040463, l5: 0.037420, l6: 0.036094

[epoch:  59/100000, batch:    76/  187, ite: 5490] train loss: 0.317515, tar: 0.034146 
l0: 0.024852, l1: 0.023966, l2: 0.023126, l3: 0.033702, l4: 0.041542, l5: 0.044704, l6: 0.044991

[epoch:  59/100000, batch:    78/  187, ite: 5491] train loss: 0.317461, tar: 0.034140 
l0: 0.019550, l1: 0.019273, l2: 0.021907, l3: 0.022477, l4: 0.029838, l5: 0.034299, l6: 0.038834

[epoch:  59/100000, batch:    80/  187, ite: 5492] train loss: 0.317373, tar: 0.034130 
l0: 0.016576, l1: 0.018987, l2: 0.023989, l3: 0.016709, l4: 0.028940, l5: 0.034905, l6: 0.029173

[epoch:  59/100000, batch:    82/  187, ite: 5493] train loss: 0.317274, tar: 0.034119 
l0: 0.016733, l1: 0.016655, l2: 0.021700, l3: 0.019852, l4: 0.032449, l5: 0.028402, l6: 0.030750

[epoch:  59/100000, batch:    84/  187, ite: 5494] train loss: 0.317173, tar: 0.034107 
l0: 0.030461, l1: 0.029247, l2: 0.032824, l3: 0.030704, l4: 0.047436, l5: 0.055340, l6: 0.052129

[epoch:  59/100000, batch:    86/  187, ite: 5495] train loss: 0.317147, tar: 0.034105 
l0: 0.018637, l1: 0.020811, l2: 0.022437, l3: 0.022648, l4: 0.028401, l5: 0.025850, l6: 0.027782

[epoch:  59/100000, batch:    88/  187, ite: 5496] train loss: 0.317046, tar: 0.034094 
l0: 0.015752, l1: 0.016926, l2: 0.036356, l3: 0.020278, l4: 0.041986, l5: 0.049684, l6: 0.035309

[epoch:  59/100000, batch:    90/  187, ite: 5497] train loss: 0.316979, tar: 0.034082 
l0: 0.016932, l1: 0.015651, l2: 0.027062, l3: 0.024212, l4: 0.062737, l5: 0.055722, l6: 0.057616

[epoch:  59/100000, batch:    92/  187, ite: 5498] train loss: 0.316941, tar: 0.034071 
l0: 0.013932, l1: 0.014203, l2: 0.018682, l3: 0.018610, l4: 0.024820, l5: 0.027354, l6: 0.029509

[epoch:  59/100000, batch:    94/  187, ite: 5499] train loss: 0.316827, tar: 0.034057 
l0: 0.021562, l1: 0.021380, l2: 0.024274, l3: 0.027635, l4: 0.033993, l5: 0.033097, l6: 0.031954

[epoch:  59/100000, batch:    96/  187, ite: 5500] train loss: 0.316745, tar: 0.034049 
l0: 0.024055, l1: 0.033316, l2: 0.020680, l3: 0.014503, l4: 0.022450, l5: 0.019368, l6: 0.022977

[epoch:  59/100000, batch:    98/  187, ite: 5501] train loss: 0.316639, tar: 0.034042 
l0: 0.020536, l1: 0.022054, l2: 0.019777, l3: 0.020686, l4: 0.027040, l5: 0.023850, l6: 0.025985

[epoch:  59/100000, batch:   100/  187, ite: 5502] train loss: 0.316535, tar: 0.034033 
l0: 0.022264, l1: 0.023400, l2: 0.037279, l3: 0.031135, l4: 0.025913, l5: 0.027119, l6: 0.021242

[epoch:  59/100000, batch:   102/  187, ite: 5503] train loss: 0.316449, tar: 0.034025 
l0: 0.017528, l1: 0.015739, l2: 0.021533, l3: 0.023986, l4: 0.025745, l5: 0.037075, l6: 0.045283

[epoch:  59/100000, batch:   104/  187, ite: 5504] train loss: 0.316363, tar: 0.034014 
l0: 0.018931, l1: 0.019378, l2: 0.035671, l3: 0.038198, l4: 0.042784, l5: 0.034400, l6: 0.030226

[epoch:  59/100000, batch:   106/  187, ite: 5505] train loss: 0.316299, tar: 0.034004 
l0: 0.019405, l1: 0.019579, l2: 0.023332, l3: 0.025367, l4: 0.032055, l5: 0.031239, l6: 0.032175

[epoch:  59/100000, batch:   108/  187, ite: 5506] train loss: 0.316211, tar: 0.033995 
l0: 0.022659, l1: 0.025754, l2: 0.022167, l3: 0.023326, l4: 0.045139, l5: 0.038208, l6: 0.037660

[epoch:  59/100000, batch:   110/  187, ite: 5507] train loss: 0.316143, tar: 0.033987 
l0: 0.018277, l1: 0.020002, l2: 0.017315, l3: 0.016719, l4: 0.022700, l5: 0.022194, l6: 0.024894

[epoch:  59/100000, batch:   112/  187, ite: 5508] train loss: 0.316028, tar: 0.033977 
l0: 0.017375, l1: 0.016766, l2: 0.025167, l3: 0.025600, l4: 0.027799, l5: 0.035240, l6: 0.034078

[epoch:  59/100000, batch:   114/  187, ite: 5509] train loss: 0.315939, tar: 0.033966 
l0: 0.018857, l1: 0.018195, l2: 0.021839, l3: 0.026539, l4: 0.039469, l5: 0.044845, l6: 0.037203

[epoch:  59/100000, batch:   116/  187, ite: 5510] train loss: 0.315867, tar: 0.033956 
l0: 0.020138, l1: 0.021129, l2: 0.024956, l3: 0.022802, l4: 0.033548, l5: 0.037271, l6: 0.034664

[epoch:  59/100000, batch:   118/  187, ite: 5511] train loss: 0.315787, tar: 0.033946 
l0: 0.031060, l1: 0.036161, l2: 0.037950, l3: 0.025104, l4: 0.044874, l5: 0.043952, l6: 0.045561

[epoch:  59/100000, batch:   120/  187, ite: 5512] train loss: 0.315753, tar: 0.033945 
l0: 0.026045, l1: 0.024607, l2: 0.033067, l3: 0.034979, l4: 0.055903, l5: 0.061950, l6: 0.070600

[epoch:  59/100000, batch:   122/  187, ite: 5513] train loss: 0.315747, tar: 0.033939 
l0: 0.029884, l1: 0.029909, l2: 0.037679, l3: 0.036118, l4: 0.029553, l5: 0.034700, l6: 0.031222

[epoch:  59/100000, batch:   124/  187, ite: 5514] train loss: 0.315690, tar: 0.033937 
l0: 0.017666, l1: 0.019932, l2: 0.018504, l3: 0.020716, l4: 0.030969, l5: 0.026878, l6: 0.036648

[epoch:  59/100000, batch:   126/  187, ite: 5515] train loss: 0.315595, tar: 0.033926 
l0: 0.037598, l1: 0.043629, l2: 0.036301, l3: 0.034179, l4: 0.038607, l5: 0.029941, l6: 0.031222

[epoch:  59/100000, batch:   128/  187, ite: 5516] train loss: 0.315552, tar: 0.033928 
l0: 0.030185, l1: 0.030147, l2: 0.044389, l3: 0.041807, l4: 0.029286, l5: 0.032404, l6: 0.035954

[epoch:  59/100000, batch:   130/  187, ite: 5517] train loss: 0.315505, tar: 0.033926 
l0: 0.015004, l1: 0.013310, l2: 0.017388, l3: 0.018919, l4: 0.044969, l5: 0.047067, l6: 0.039960

[epoch:  59/100000, batch:   132/  187, ite: 5518] train loss: 0.315427, tar: 0.033913 
l0: 0.013980, l1: 0.013137, l2: 0.016096, l3: 0.014820, l4: 0.032794, l5: 0.039313, l6: 0.042478

[epoch:  59/100000, batch:   134/  187, ite: 5519] train loss: 0.315333, tar: 0.033900 
l0: 0.020381, l1: 0.020734, l2: 0.027885, l3: 0.026715, l4: 0.037733, l5: 0.038664, l6: 0.037798

[epoch:  59/100000, batch:   136/  187, ite: 5520] train loss: 0.315264, tar: 0.033891 
l0: 0.023773, l1: 0.024965, l2: 0.026165, l3: 0.029940, l4: 0.036259, l5: 0.033594, l6: 0.040536

[epoch:  59/100000, batch:   138/  187, ite: 5521] train loss: 0.315198, tar: 0.033885 
l0: 0.027258, l1: 0.025437, l2: 0.036236, l3: 0.034990, l4: 0.049778, l5: 0.054776, l6: 0.063028

[epoch:  59/100000, batch:   140/  187, ite: 5522] train loss: 0.315182, tar: 0.033880 
l0: 0.037169, l1: 0.040234, l2: 0.033074, l3: 0.033536, l4: 0.070608, l5: 0.063629, l6: 0.079347

[epoch:  59/100000, batch:   142/  187, ite: 5523] train loss: 0.315210, tar: 0.033883 
l0: 0.019423, l1: 0.021954, l2: 0.019575, l3: 0.020211, l4: 0.030317, l5: 0.036036, l6: 0.034106

[epoch:  59/100000, batch:   144/  187, ite: 5524] train loss: 0.315122, tar: 0.033873 
l0: 0.021115, l1: 0.021827, l2: 0.023915, l3: 0.024085, l4: 0.037098, l5: 0.033280, l6: 0.033059

[epoch:  59/100000, batch:   146/  187, ite: 5525] train loss: 0.315043, tar: 0.033865 
l0: 0.032553, l1: 0.036160, l2: 0.038462, l3: 0.039464, l4: 0.032019, l5: 0.040254, l6: 0.038154

[epoch:  59/100000, batch:   148/  187, ite: 5526] train loss: 0.315005, tar: 0.033864 
l0: 0.047600, l1: 0.048672, l2: 0.043809, l3: 0.050001, l4: 0.066771, l5: 0.059432, l6: 0.075774

[epoch:  59/100000, batch:   150/  187, ite: 5527] train loss: 0.315056, tar: 0.033873 
l0: 0.016994, l1: 0.017736, l2: 0.022138, l3: 0.026294, l4: 0.056286, l5: 0.038724, l6: 0.050393

[epoch:  59/100000, batch:   152/  187, ite: 5528] train loss: 0.314999, tar: 0.033862 
l0: 0.027655, l1: 0.026203, l2: 0.031965, l3: 0.035869, l4: 0.074211, l5: 0.074220, l6: 0.084199

[epoch:  59/100000, batch:   154/  187, ite: 5529] train loss: 0.315025, tar: 0.033858 
l0: 0.048279, l1: 0.056779, l2: 0.058365, l3: 0.047283, l4: 0.055600, l5: 0.048649, l6: 0.042634

[epoch:  59/100000, batch:   156/  187, ite: 5530] train loss: 0.315053, tar: 0.033867 
l0: 0.030354, l1: 0.029440, l2: 0.041400, l3: 0.048781, l4: 0.056264, l5: 0.059058, l6: 0.052149

[epoch:  59/100000, batch:   158/  187, ite: 5531] train loss: 0.315054, tar: 0.033865 
l0: 0.007871, l1: 0.012025, l2: 0.013676, l3: 0.008656, l4: 0.020548, l5: 0.016716, l6: 0.015582

[epoch:  59/100000, batch:   160/  187, ite: 5532] train loss: 0.314911, tar: 0.033848 
l0: 0.021195, l1: 0.023136, l2: 0.020961, l3: 0.020260, l4: 0.036411, l5: 0.044353, l6: 0.047628

[epoch:  59/100000, batch:   162/  187, ite: 5533] train loss: 0.314845, tar: 0.033840 
l0: 0.019300, l1: 0.022309, l2: 0.018584, l3: 0.018410, l4: 0.027890, l5: 0.030300, l6: 0.029986

[epoch:  59/100000, batch:   164/  187, ite: 5534] train loss: 0.314748, tar: 0.033830 
l0: 0.021653, l1: 0.023806, l2: 0.020934, l3: 0.023990, l4: 0.031755, l5: 0.035249, l6: 0.027810

[epoch:  59/100000, batch:   166/  187, ite: 5535] train loss: 0.314664, tar: 0.033822 
l0: 0.044598, l1: 0.048876, l2: 0.055381, l3: 0.047005, l4: 0.059880, l5: 0.067190, l6: 0.061484

[epoch:  59/100000, batch:   168/  187, ite: 5536] train loss: 0.314709, tar: 0.033829 
l0: 0.053367, l1: 0.058669, l2: 0.055092, l3: 0.057705, l4: 0.066562, l5: 0.063136, l6: 0.070256

[epoch:  59/100000, batch:   170/  187, ite: 5537] train loss: 0.314781, tar: 0.033842 
l0: 0.066654, l1: 0.062484, l2: 0.064512, l3: 0.066287, l4: 0.076861, l5: 0.104457, l6: 0.107504

[epoch:  59/100000, batch:   172/  187, ite: 5538] train loss: 0.314933, tar: 0.033863 
l0: 0.034864, l1: 0.038111, l2: 0.034128, l3: 0.033589, l4: 0.057138, l5: 0.053010, l6: 0.051313

[epoch:  59/100000, batch:   174/  187, ite: 5539] train loss: 0.314925, tar: 0.033864 
l0: 0.025044, l1: 0.023913, l2: 0.026433, l3: 0.030346, l4: 0.045515, l5: 0.051712, l6: 0.059062

[epoch:  59/100000, batch:   176/  187, ite: 5540] train loss: 0.314890, tar: 0.033858 
l0: 0.017163, l1: 0.019152, l2: 0.016978, l3: 0.015927, l4: 0.033945, l5: 0.030840, l6: 0.028758

[epoch:  59/100000, batch:   178/  187, ite: 5541] train loss: 0.314792, tar: 0.033847 
l0: 0.018748, l1: 0.020519, l2: 0.021440, l3: 0.021804, l4: 0.026434, l5: 0.029210, l6: 0.043263

[epoch:  59/100000, batch:   180/  187, ite: 5542] train loss: 0.314705, tar: 0.033838 
l0: 0.021250, l1: 0.026106, l2: 0.021093, l3: 0.020832, l4: 0.046241, l5: 0.039963, l6: 0.049970

[epoch:  59/100000, batch:   182/  187, ite: 5543] train loss: 0.314647, tar: 0.033829 
l0: 0.027916, l1: 0.024565, l2: 0.030709, l3: 0.037805, l4: 0.053039, l5: 0.065900, l6: 0.078378

[epoch:  59/100000, batch:   184/  187, ite: 5544] train loss: 0.314650, tar: 0.033826 
l0: 0.020779, l1: 0.024816, l2: 0.018718, l3: 0.018429, l4: 0.041824, l5: 0.034663, l6: 0.031814

[epoch:  59/100000, batch:   186/  187, ite: 5545] train loss: 0.314570, tar: 0.033817 
l0: 0.062500, l1: 0.066681, l2: 0.074545, l3: 0.070008, l4: 0.052086, l5: 0.043444, l6: 0.066486

[epoch:  59/100000, batch:   188/  187, ite: 5546] train loss: 0.314648, tar: 0.033836 
l0: 0.021189, l1: 0.023419, l2: 0.026015, l3: 0.022993, l4: 0.035607, l5: 0.037708, l6: 0.038005

[epoch:  60/100000, batch:     2/  187, ite: 5547] train loss: 0.314577, tar: 0.033828 
l0: 0.053820, l1: 0.062092, l2: 0.044373, l3: 0.043606, l4: 0.068301, l5: 0.073630, l6: 0.065475

[epoch:  60/100000, batch:     4/  187, ite: 5548] train loss: 0.314640, tar: 0.033840 
l0: 0.021650, l1: 0.019918, l2: 0.033943, l3: 0.036039, l4: 0.055806, l5: 0.055746, l6: 0.042924

[epoch:  60/100000, batch:     6/  187, ite: 5549] train loss: 0.314608, tar: 0.033833 
l0: 0.026110, l1: 0.025524, l2: 0.030816, l3: 0.034065, l4: 0.076113, l5: 0.069458, l6: 0.059828

[epoch:  60/100000, batch:     8/  187, ite: 5550] train loss: 0.314613, tar: 0.033828 
l0: 0.032216, l1: 0.032610, l2: 0.040401, l3: 0.044364, l4: 0.054812, l5: 0.054586, l6: 0.059949

[epoch:  60/100000, batch:    10/  187, ite: 5551] train loss: 0.314616, tar: 0.033827 
l0: 0.021582, l1: 0.023835, l2: 0.017083, l3: 0.017078, l4: 0.032269, l5: 0.032669, l6: 0.034903

[epoch:  60/100000, batch:    12/  187, ite: 5552] train loss: 0.314529, tar: 0.033819 
l0: 0.038790, l1: 0.037157, l2: 0.036238, l3: 0.042381, l4: 0.041596, l5: 0.054279, l6: 0.052827

[epoch:  60/100000, batch:    14/  187, ite: 5553] train loss: 0.314521, tar: 0.033822 
l0: 0.021619, l1: 0.022499, l2: 0.025732, l3: 0.025692, l4: 0.032518, l5: 0.030397, l6: 0.029718

[epoch:  60/100000, batch:    16/  187, ite: 5554] train loss: 0.314440, tar: 0.033814 
l0: 0.024658, l1: 0.025261, l2: 0.026736, l3: 0.027611, l4: 0.037770, l5: 0.037747, l6: 0.042445

[epoch:  60/100000, batch:    18/  187, ite: 5555] train loss: 0.314381, tar: 0.033808 
l0: 0.019729, l1: 0.023245, l2: 0.020538, l3: 0.018519, l4: 0.024594, l5: 0.021283, l6: 0.022732

[epoch:  60/100000, batch:    20/  187, ite: 5556] train loss: 0.314276, tar: 0.033799 
l0: 0.020573, l1: 0.025216, l2: 0.024960, l3: 0.028160, l4: 0.037985, l5: 0.031112, l6: 0.028010

[epoch:  60/100000, batch:    22/  187, ite: 5557] train loss: 0.314200, tar: 0.033791 
l0: 0.019281, l1: 0.021762, l2: 0.020176, l3: 0.018586, l4: 0.031304, l5: 0.024666, l6: 0.030961

[epoch:  60/100000, batch:    24/  187, ite: 5558] train loss: 0.314105, tar: 0.033781 
l0: 0.024591, l1: 0.028954, l2: 0.024231, l3: 0.022849, l4: 0.039172, l5: 0.029304, l6: 0.027372

[epoch:  60/100000, batch:    26/  187, ite: 5559] train loss: 0.314029, tar: 0.033775 
l0: 0.020614, l1: 0.022505, l2: 0.024064, l3: 0.023657, l4: 0.025354, l5: 0.024554, l6: 0.025419

[epoch:  60/100000, batch:    28/  187, ite: 5560] train loss: 0.313935, tar: 0.033767 
l0: 0.016557, l1: 0.016480, l2: 0.020283, l3: 0.018869, l4: 0.036965, l5: 0.036027, l6: 0.038488

[epoch:  60/100000, batch:    30/  187, ite: 5561] train loss: 0.313851, tar: 0.033756 
l0: 0.017320, l1: 0.018216, l2: 0.018316, l3: 0.016740, l4: 0.027434, l5: 0.028651, l6: 0.031348

[epoch:  60/100000, batch:    32/  187, ite: 5562] train loss: 0.313751, tar: 0.033745 
l0: 0.018863, l1: 0.018418, l2: 0.019332, l3: 0.023149, l4: 0.042476, l5: 0.050135, l6: 0.044856

[epoch:  60/100000, batch:    34/  187, ite: 5563] train loss: 0.313690, tar: 0.033736 
l0: 0.018227, l1: 0.017385, l2: 0.024325, l3: 0.026106, l4: 0.037358, l5: 0.035948, l6: 0.036762

[epoch:  60/100000, batch:    36/  187, ite: 5564] train loss: 0.313615, tar: 0.033726 
l0: 0.024294, l1: 0.017588, l2: 0.036427, l3: 0.046461, l4: 0.044834, l5: 0.055067, l6: 0.049721

[epoch:  60/100000, batch:    38/  187, ite: 5565] train loss: 0.313589, tar: 0.033720 
l0: 0.024494, l1: 0.022543, l2: 0.022811, l3: 0.024015, l4: 0.048162, l5: 0.050580, l6: 0.056526

[epoch:  60/100000, batch:    40/  187, ite: 5566] train loss: 0.313548, tar: 0.033714 
l0: 0.038886, l1: 0.040306, l2: 0.043000, l3: 0.040122, l4: 0.037583, l5: 0.037037, l6: 0.039675

[epoch:  60/100000, batch:    42/  187, ite: 5567] train loss: 0.313525, tar: 0.033717 
l0: 0.017674, l1: 0.015055, l2: 0.019892, l3: 0.023338, l4: 0.048994, l5: 0.059465, l6: 0.063175

[epoch:  60/100000, batch:    44/  187, ite: 5568] train loss: 0.313483, tar: 0.033707 
l0: 0.021974, l1: 0.024325, l2: 0.023938, l3: 0.024524, l4: 0.039488, l5: 0.034116, l6: 0.031082

[epoch:  60/100000, batch:    46/  187, ite: 5569] train loss: 0.313410, tar: 0.033700 
l0: 0.015297, l1: 0.014773, l2: 0.017723, l3: 0.018070, l4: 0.031480, l5: 0.029905, l6: 0.028259

[epoch:  60/100000, batch:    48/  187, ite: 5570] train loss: 0.313309, tar: 0.033688 
l0: 0.039355, l1: 0.039885, l2: 0.045483, l3: 0.037162, l4: 0.051083, l5: 0.057415, l6: 0.077264

[epoch:  60/100000, batch:    50/  187, ite: 5571] train loss: 0.313331, tar: 0.033692 
l0: 0.026298, l1: 0.024962, l2: 0.030150, l3: 0.034508, l4: 0.029118, l5: 0.035575, l6: 0.027070

[epoch:  60/100000, batch:    52/  187, ite: 5572] train loss: 0.313264, tar: 0.033687 
l0: 0.018919, l1: 0.020391, l2: 0.021211, l3: 0.018864, l4: 0.034356, l5: 0.031069, l6: 0.035049

[epoch:  60/100000, batch:    54/  187, ite: 5573] train loss: 0.313179, tar: 0.033677 
l0: 0.012531, l1: 0.014184, l2: 0.016854, l3: 0.017165, l4: 0.016586, l5: 0.016500, l6: 0.017697

[epoch:  60/100000, batch:    56/  187, ite: 5574] train loss: 0.313051, tar: 0.033664 
l0: 0.016481, l1: 0.017270, l2: 0.017103, l3: 0.018239, l4: 0.024991, l5: 0.024719, l6: 0.028249

[epoch:  60/100000, batch:    58/  187, ite: 5575] train loss: 0.312946, tar: 0.033653 
l0: 0.017828, l1: 0.017567, l2: 0.021685, l3: 0.023676, l4: 0.037363, l5: 0.034209, l6: 0.037383

[epoch:  60/100000, batch:    60/  187, ite: 5576] train loss: 0.312868, tar: 0.033643 
l0: 0.019424, l1: 0.019814, l2: 0.019412, l3: 0.021052, l4: 0.037998, l5: 0.039382, l6: 0.040389

[epoch:  60/100000, batch:    62/  187, ite: 5577] train loss: 0.312794, tar: 0.033634 
l0: 0.046059, l1: 0.044081, l2: 0.060507, l3: 0.067092, l4: 0.076720, l5: 0.056829, l6: 0.063100

[epoch:  60/100000, batch:    64/  187, ite: 5578] train loss: 0.312859, tar: 0.033642 
l0: 0.030090, l1: 0.027434, l2: 0.054247, l3: 0.061398, l4: 0.057469, l5: 0.051155, l6: 0.049758

[epoch:  60/100000, batch:    66/  187, ite: 5579] train loss: 0.312871, tar: 0.033640 
l0: 0.025486, l1: 0.027512, l2: 0.033900, l3: 0.032773, l4: 0.024485, l5: 0.020902, l6: 0.022836

[epoch:  60/100000, batch:    68/  187, ite: 5580] train loss: 0.312792, tar: 0.033634 
l0: 0.040849, l1: 0.040199, l2: 0.036185, l3: 0.036735, l4: 0.072924, l5: 0.075960, l6: 0.091737

[epoch:  60/100000, batch:    70/  187, ite: 5581] train loss: 0.312843, tar: 0.033639 
l0: 0.023696, l1: 0.025639, l2: 0.030269, l3: 0.029130, l4: 0.036040, l5: 0.034249, l6: 0.029963

[epoch:  60/100000, batch:    72/  187, ite: 5582] train loss: 0.312778, tar: 0.033633 
l0: 0.026306, l1: 0.026741, l2: 0.030870, l3: 0.036853, l4: 0.036987, l5: 0.036210, l6: 0.031880

[epoch:  60/100000, batch:    74/  187, ite: 5583] train loss: 0.312723, tar: 0.033628 
l0: 0.026057, l1: 0.023518, l2: 0.026988, l3: 0.033164, l4: 0.053945, l5: 0.063224, l6: 0.053584

[epoch:  60/100000, batch:    76/  187, ite: 5584] train loss: 0.312702, tar: 0.033623 
l0: 0.011984, l1: 0.013617, l2: 0.020167, l3: 0.021690, l4: 0.012879, l5: 0.018176, l6: 0.013610

[epoch:  60/100000, batch:    78/  187, ite: 5585] train loss: 0.312576, tar: 0.033610 
l0: 0.017589, l1: 0.018533, l2: 0.019706, l3: 0.019072, l4: 0.032482, l5: 0.033023, l6: 0.035451

[epoch:  60/100000, batch:    80/  187, ite: 5586] train loss: 0.312490, tar: 0.033600 
l0: 0.014939, l1: 0.015082, l2: 0.017816, l3: 0.018870, l4: 0.029747, l5: 0.029284, l6: 0.034640

[epoch:  60/100000, batch:    82/  187, ite: 5587] train loss: 0.312394, tar: 0.033588 
l0: 0.020428, l1: 0.020055, l2: 0.024159, l3: 0.027290, l4: 0.052671, l5: 0.055846, l6: 0.039286

[epoch:  60/100000, batch:    84/  187, ite: 5588] train loss: 0.312348, tar: 0.033580 
l0: 0.012023, l1: 0.011222, l2: 0.014262, l3: 0.014570, l4: 0.021648, l5: 0.022635, l6: 0.020811

[epoch:  60/100000, batch:    86/  187, ite: 5589] train loss: 0.312225, tar: 0.033566 
l0: 0.036705, l1: 0.032885, l2: 0.037952, l3: 0.044784, l4: 0.050653, l5: 0.063379, l6: 0.065664

[epoch:  60/100000, batch:    88/  187, ite: 5590] train loss: 0.312238, tar: 0.033568 
l0: 0.015207, l1: 0.016867, l2: 0.014277, l3: 0.008567, l4: 0.039355, l5: 0.046291, l6: 0.045990

[epoch:  60/100000, batch:    90/  187, ite: 5591] train loss: 0.312159, tar: 0.033556 
l0: 0.017050, l1: 0.016977, l2: 0.023112, l3: 0.019917, l4: 0.019691, l5: 0.020649, l6: 0.036174

[epoch:  60/100000, batch:    92/  187, ite: 5592] train loss: 0.312059, tar: 0.033546 
l0: 0.069565, l1: 0.073937, l2: 0.077133, l3: 0.074318, l4: 0.080581, l5: 0.063066, l6: 0.061506

[epoch:  60/100000, batch:    94/  187, ite: 5593] train loss: 0.312177, tar: 0.033569 
l0: 0.030999, l1: 0.028924, l2: 0.033258, l3: 0.038077, l4: 0.061491, l5: 0.063272, l6: 0.063258

[epoch:  60/100000, batch:    96/  187, ite: 5594] train loss: 0.312181, tar: 0.033567 
l0: 0.022503, l1: 0.023129, l2: 0.032151, l3: 0.028256, l4: 0.045786, l5: 0.046148, l6: 0.037908

[epoch:  60/100000, batch:    98/  187, ite: 5595] train loss: 0.312134, tar: 0.033560 
l0: 0.015885, l1: 0.015624, l2: 0.020124, l3: 0.020860, l4: 0.030307, l5: 0.032738, l6: 0.036032

[epoch:  60/100000, batch:   100/  187, ite: 5596] train loss: 0.312046, tar: 0.033549 
l0: 0.029997, l1: 0.030763, l2: 0.032780, l3: 0.034242, l4: 0.044324, l5: 0.045684, l6: 0.055896

[epoch:  60/100000, batch:   102/  187, ite: 5597] train loss: 0.312022, tar: 0.033547 
l0: 0.017474, l1: 0.017165, l2: 0.024275, l3: 0.023963, l4: 0.044654, l5: 0.040515, l6: 0.046210

[epoch:  60/100000, batch:   104/  187, ite: 5598] train loss: 0.311960, tar: 0.033537 
l0: 0.020344, l1: 0.020494, l2: 0.029069, l3: 0.026266, l4: 0.025886, l5: 0.023750, l6: 0.029855

[epoch:  60/100000, batch:   106/  187, ite: 5599] train loss: 0.311875, tar: 0.033529 
l0: 0.048472, l1: 0.051336, l2: 0.052242, l3: 0.056630, l4: 0.046593, l5: 0.039927, l6: 0.045135

[epoch:  60/100000, batch:   108/  187, ite: 5600] train loss: 0.311893, tar: 0.033538 
l0: 0.016078, l1: 0.016373, l2: 0.018295, l3: 0.023708, l4: 0.024201, l5: 0.024519, l6: 0.027027

[epoch:  60/100000, batch:   110/  187, ite: 5601] train loss: 0.311792, tar: 0.033527 
l0: 0.021345, l1: 0.019761, l2: 0.029510, l3: 0.037963, l4: 0.043640, l5: 0.037817, l6: 0.037554

[epoch:  60/100000, batch:   112/  187, ite: 5602] train loss: 0.311739, tar: 0.033519 
l0: 0.031891, l1: 0.031190, l2: 0.058038, l3: 0.052263, l4: 0.036212, l5: 0.039042, l6: 0.041499

[epoch:  60/100000, batch:   114/  187, ite: 5603] train loss: 0.311726, tar: 0.033518 
l0: 0.030382, l1: 0.032267, l2: 0.032798, l3: 0.033434, l4: 0.043584, l5: 0.049779, l6: 0.052109

[epoch:  60/100000, batch:   116/  187, ite: 5604] train loss: 0.311703, tar: 0.033516 
l0: 0.033085, l1: 0.037275, l2: 0.029794, l3: 0.033457, l4: 0.050864, l5: 0.039150, l6: 0.048771

[epoch:  60/100000, batch:   118/  187, ite: 5605] train loss: 0.311678, tar: 0.033516 
l0: 0.034508, l1: 0.032246, l2: 0.040083, l3: 0.037560, l4: 0.049319, l5: 0.053754, l6: 0.056888

[epoch:  60/100000, batch:   120/  187, ite: 5606] train loss: 0.311674, tar: 0.033517 
l0: 0.019966, l1: 0.019296, l2: 0.024164, l3: 0.022069, l4: 0.042609, l5: 0.038724, l6: 0.035801

[epoch:  60/100000, batch:   122/  187, ite: 5607] train loss: 0.311606, tar: 0.033508 
l0: 0.016086, l1: 0.014267, l2: 0.019401, l3: 0.023716, l4: 0.033610, l5: 0.036560, l6: 0.038698

[epoch:  60/100000, batch:   124/  187, ite: 5608] train loss: 0.311525, tar: 0.033497 
l0: 0.020570, l1: 0.019912, l2: 0.022747, l3: 0.026895, l4: 0.032731, l5: 0.032136, l6: 0.031769

[epoch:  60/100000, batch:   126/  187, ite: 5609] train loss: 0.311448, tar: 0.033489 
l0: 0.013163, l1: 0.012942, l2: 0.015567, l3: 0.016877, l4: 0.014796, l5: 0.012761, l6: 0.020678

[epoch:  60/100000, batch:   128/  187, ite: 5610] train loss: 0.311321, tar: 0.033477 
l0: 0.033882, l1: 0.032676, l2: 0.035143, l3: 0.040878, l4: 0.048922, l5: 0.048390, l6: 0.041731

[epoch:  60/100000, batch:   130/  187, ite: 5611] train loss: 0.311302, tar: 0.033477 
l0: 0.024016, l1: 0.024001, l2: 0.025701, l3: 0.027338, l4: 0.038725, l5: 0.039316, l6: 0.049560

[epoch:  60/100000, batch:   132/  187, ite: 5612] train loss: 0.311251, tar: 0.033471 
l0: 0.024842, l1: 0.024964, l2: 0.030256, l3: 0.034128, l4: 0.052462, l5: 0.060129, l6: 0.066860

[epoch:  60/100000, batch:   134/  187, ite: 5613] train loss: 0.311240, tar: 0.033466 
l0: 0.025480, l1: 0.025821, l2: 0.032255, l3: 0.036592, l4: 0.039032, l5: 0.036040, l6: 0.039491

[epoch:  60/100000, batch:   136/  187, ite: 5614] train loss: 0.311193, tar: 0.033461 
l0: 0.031860, l1: 0.031046, l2: 0.043420, l3: 0.041279, l4: 0.050612, l5: 0.050430, l6: 0.045848

[epoch:  60/100000, batch:   138/  187, ite: 5615] train loss: 0.311182, tar: 0.033460 
l0: 0.016055, l1: 0.016835, l2: 0.017570, l3: 0.017168, l4: 0.032584, l5: 0.030306, l6: 0.028324

[epoch:  60/100000, batch:   140/  187, ite: 5616] train loss: 0.311088, tar: 0.033449 
l0: 0.023097, l1: 0.022846, l2: 0.028629, l3: 0.028649, l4: 0.033940, l5: 0.034958, l6: 0.036692

[epoch:  60/100000, batch:   142/  187, ite: 5617] train loss: 0.311025, tar: 0.033443 
l0: 0.019546, l1: 0.020117, l2: 0.022800, l3: 0.026166, l4: 0.046922, l5: 0.043490, l6: 0.044559

[epoch:  60/100000, batch:   144/  187, ite: 5618] train loss: 0.310971, tar: 0.033434 
l0: 0.019750, l1: 0.021113, l2: 0.021125, l3: 0.020148, l4: 0.029616, l5: 0.030678, l6: 0.025707

[epoch:  60/100000, batch:   146/  187, ite: 5619] train loss: 0.310882, tar: 0.033426 
l0: 0.010843, l1: 0.011936, l2: 0.018172, l3: 0.015102, l4: 0.047275, l5: 0.043361, l6: 0.032776

[epoch:  60/100000, batch:   148/  187, ite: 5620] train loss: 0.310801, tar: 0.033412 
l0: 0.015025, l1: 0.017111, l2: 0.018484, l3: 0.019519, l4: 0.047782, l5: 0.040535, l6: 0.035600

[epoch:  60/100000, batch:   150/  187, ite: 5621] train loss: 0.310729, tar: 0.033400 
l0: 0.013754, l1: 0.015599, l2: 0.015553, l3: 0.016373, l4: 0.026737, l5: 0.026784, l6: 0.029448

[epoch:  60/100000, batch:   152/  187, ite: 5622] train loss: 0.310627, tar: 0.033388 
l0: 0.032598, l1: 0.033712, l2: 0.036234, l3: 0.039199, l4: 0.067871, l5: 0.059865, l6: 0.047668

[epoch:  60/100000, batch:   154/  187, ite: 5623] train loss: 0.310631, tar: 0.033388 
l0: 0.017568, l1: 0.016036, l2: 0.022778, l3: 0.023367, l4: 0.081654, l5: 0.057213, l6: 0.061686

[epoch:  60/100000, batch:   156/  187, ite: 5624] train loss: 0.310612, tar: 0.033378 
l0: 0.033539, l1: 0.035561, l2: 0.029153, l3: 0.030021, l4: 0.049962, l5: 0.051662, l6: 0.062742

[epoch:  60/100000, batch:   158/  187, ite: 5625] train loss: 0.310601, tar: 0.033378 
l0: 0.038642, l1: 0.039411, l2: 0.053018, l3: 0.039482, l4: 0.072877, l5: 0.065226, l6: 0.057641

[epoch:  60/100000, batch:   160/  187, ite: 5626] train loss: 0.310635, tar: 0.033381 
l0: 0.020306, l1: 0.019497, l2: 0.022595, l3: 0.025030, l4: 0.035164, l5: 0.040927, l6: 0.040179

[epoch:  60/100000, batch:   162/  187, ite: 5627] train loss: 0.310570, tar: 0.033373 
l0: 0.014767, l1: 0.014457, l2: 0.014993, l3: 0.017924, l4: 0.031357, l5: 0.047178, l6: 0.043055

[epoch:  60/100000, batch:   164/  187, ite: 5628] train loss: 0.310492, tar: 0.033362 
l0: 0.025437, l1: 0.023939, l2: 0.038131, l3: 0.035731, l4: 0.044954, l5: 0.043030, l6: 0.039297

[epoch:  60/100000, batch:   166/  187, ite: 5629] train loss: 0.310455, tar: 0.033357 
l0: 0.024968, l1: 0.022094, l2: 0.028955, l3: 0.031839, l4: 0.039684, l5: 0.044594, l6: 0.053347

[epoch:  60/100000, batch:   168/  187, ite: 5630] train loss: 0.310415, tar: 0.033352 
l0: 0.019559, l1: 0.020145, l2: 0.016976, l3: 0.019687, l4: 0.031342, l5: 0.036696, l6: 0.042209

[epoch:  60/100000, batch:   170/  187, ite: 5631] train loss: 0.310339, tar: 0.033343 
l0: 0.010388, l1: 0.010522, l2: 0.011369, l3: 0.012809, l4: 0.020465, l5: 0.019411, l6: 0.021154

[epoch:  60/100000, batch:   172/  187, ite: 5632] train loss: 0.310214, tar: 0.033329 
l0: 0.023271, l1: 0.023608, l2: 0.019609, l3: 0.025016, l4: 0.068048, l5: 0.064153, l6: 0.056542

[epoch:  60/100000, batch:   174/  187, ite: 5633] train loss: 0.310196, tar: 0.033323 
l0: 0.015357, l1: 0.017628, l2: 0.017719, l3: 0.018182, l4: 0.019674, l5: 0.019388, l6: 0.015086

[epoch:  60/100000, batch:   176/  187, ite: 5634] train loss: 0.310081, tar: 0.033312 
l0: 0.018974, l1: 0.018710, l2: 0.021533, l3: 0.024243, l4: 0.048237, l5: 0.046754, l6: 0.042127

[epoch:  60/100000, batch:   178/  187, ite: 5635] train loss: 0.310026, tar: 0.033303 
l0: 0.019145, l1: 0.018776, l2: 0.023733, l3: 0.025256, l4: 0.039067, l5: 0.039555, l6: 0.047884

[epoch:  60/100000, batch:   180/  187, ite: 5636] train loss: 0.309967, tar: 0.033295 
l0: 0.018212, l1: 0.018829, l2: 0.019541, l3: 0.020852, l4: 0.039599, l5: 0.038646, l6: 0.034808

[epoch:  60/100000, batch:   182/  187, ite: 5637] train loss: 0.309894, tar: 0.033286 
l0: 0.024637, l1: 0.027724, l2: 0.025305, l3: 0.023023, l4: 0.039365, l5: 0.036821, l6: 0.034781

[epoch:  60/100000, batch:   184/  187, ite: 5638] train loss: 0.309834, tar: 0.033280 
l0: 0.019562, l1: 0.019199, l2: 0.024448, l3: 0.024529, l4: 0.034168, l5: 0.032429, l6: 0.041593

[epoch:  60/100000, batch:   186/  187, ite: 5639] train loss: 0.309765, tar: 0.033272 
l0: 0.012837, l1: 0.016517, l2: 0.028380, l3: 0.015270, l4: 0.031906, l5: 0.024542, l6: 0.026151

[epoch:  60/100000, batch:   188/  187, ite: 5640] train loss: 0.309671, tar: 0.033259 
l0: 0.025863, l1: 0.031638, l2: 0.021334, l3: 0.019950, l4: 0.031310, l5: 0.029233, l6: 0.023202

[epoch:  61/100000, batch:     2/  187, ite: 5641] train loss: 0.309593, tar: 0.033255 
l0: 0.021771, l1: 0.021699, l2: 0.024108, l3: 0.027814, l4: 0.054583, l5: 0.046370, l6: 0.040898

[epoch:  61/100000, batch:     4/  187, ite: 5642] train loss: 0.309549, tar: 0.033248 
l0: 0.015537, l1: 0.014638, l2: 0.020452, l3: 0.019683, l4: 0.038339, l5: 0.037681, l6: 0.034625

[epoch:  61/100000, batch:     6/  187, ite: 5643] train loss: 0.309471, tar: 0.033237 
l0: 0.019027, l1: 0.020049, l2: 0.019709, l3: 0.022252, l4: 0.035760, l5: 0.033948, l6: 0.028626

[epoch:  61/100000, batch:     8/  187, ite: 5644] train loss: 0.309392, tar: 0.033229 
l0: 0.014584, l1: 0.013363, l2: 0.019821, l3: 0.021833, l4: 0.030120, l5: 0.032462, l6: 0.041532

[epoch:  61/100000, batch:    10/  187, ite: 5645] train loss: 0.309309, tar: 0.033217 
l0: 0.016296, l1: 0.017203, l2: 0.024862, l3: 0.025851, l4: 0.038243, l5: 0.034807, l6: 0.021118

[epoch:  61/100000, batch:    12/  187, ite: 5646] train loss: 0.309230, tar: 0.033207 
l0: 0.017922, l1: 0.016765, l2: 0.017283, l3: 0.022652, l4: 0.039863, l5: 0.043324, l6: 0.050892

[epoch:  61/100000, batch:    14/  187, ite: 5647] train loss: 0.309169, tar: 0.033198 
l0: 0.011241, l1: 0.015789, l2: 0.014726, l3: 0.012532, l4: 0.023114, l5: 0.019857, l6: 0.012927

[epoch:  61/100000, batch:    16/  187, ite: 5648] train loss: 0.309048, tar: 0.033184 
l0: 0.013697, l1: 0.013503, l2: 0.014750, l3: 0.020084, l4: 0.038714, l5: 0.036950, l6: 0.036108

[epoch:  61/100000, batch:    18/  187, ite: 5649] train loss: 0.308966, tar: 0.033173 
l0: 0.024049, l1: 0.023884, l2: 0.032764, l3: 0.030857, l4: 0.033416, l5: 0.031740, l6: 0.027909

[epoch:  61/100000, batch:    20/  187, ite: 5650] train loss: 0.308903, tar: 0.033167 
l0: 0.013908, l1: 0.015278, l2: 0.016928, l3: 0.015394, l4: 0.018810, l5: 0.017053, l6: 0.018337

[epoch:  61/100000, batch:    22/  187, ite: 5651] train loss: 0.308786, tar: 0.033155 
l0: 0.020166, l1: 0.022342, l2: 0.021033, l3: 0.020570, l4: 0.026537, l5: 0.027670, l6: 0.033653

[epoch:  61/100000, batch:    24/  187, ite: 5652] train loss: 0.308703, tar: 0.033147 
l0: 0.015687, l1: 0.015613, l2: 0.019703, l3: 0.024743, l4: 0.037100, l5: 0.036869, l6: 0.033818

[epoch:  61/100000, batch:    26/  187, ite: 5653] train loss: 0.308627, tar: 0.033137 
l0: 0.022238, l1: 0.022263, l2: 0.025645, l3: 0.027175, l4: 0.038470, l5: 0.038982, l6: 0.034060

[epoch:  61/100000, batch:    28/  187, ite: 5654] train loss: 0.308567, tar: 0.033130 
l0: 0.023102, l1: 0.025270, l2: 0.022242, l3: 0.024231, l4: 0.034378, l5: 0.032227, l6: 0.037890

[epoch:  61/100000, batch:    30/  187, ite: 5655] train loss: 0.308501, tar: 0.033124 
l0: 0.031173, l1: 0.028919, l2: 0.035452, l3: 0.041093, l4: 0.038894, l5: 0.051781, l6: 0.054408

[epoch:  61/100000, batch:    32/  187, ite: 5656] train loss: 0.308485, tar: 0.033123 
l0: 0.010670, l1: 0.010716, l2: 0.012938, l3: 0.014367, l4: 0.030168, l5: 0.027161, l6: 0.027452

[epoch:  61/100000, batch:    34/  187, ite: 5657] train loss: 0.308379, tar: 0.033110 
l0: 0.018102, l1: 0.016712, l2: 0.026186, l3: 0.026275, l4: 0.026284, l5: 0.032655, l6: 0.032453

[epoch:  61/100000, batch:    36/  187, ite: 5658] train loss: 0.308301, tar: 0.033100 
l0: 0.018449, l1: 0.018730, l2: 0.021290, l3: 0.021633, l4: 0.033635, l5: 0.031377, l6: 0.032334

[epoch:  61/100000, batch:    38/  187, ite: 5659] train loss: 0.308222, tar: 0.033092 
l0: 0.025585, l1: 0.028948, l2: 0.022826, l3: 0.022798, l4: 0.033119, l5: 0.032682, l6: 0.032875

[epoch:  61/100000, batch:    40/  187, ite: 5660] train loss: 0.308156, tar: 0.033087 
l0: 0.021109, l1: 0.020955, l2: 0.027095, l3: 0.030287, l4: 0.036915, l5: 0.033403, l6: 0.033967

[epoch:  61/100000, batch:    42/  187, ite: 5661] train loss: 0.308093, tar: 0.033080 
l0: 0.016710, l1: 0.016141, l2: 0.018575, l3: 0.022057, l4: 0.024344, l5: 0.022131, l6: 0.024152

[epoch:  61/100000, batch:    44/  187, ite: 5662] train loss: 0.307995, tar: 0.033070 
l0: 0.015487, l1: 0.016126, l2: 0.020352, l3: 0.020889, l4: 0.033417, l5: 0.032125, l6: 0.024225

[epoch:  61/100000, batch:    46/  187, ite: 5663] train loss: 0.307907, tar: 0.033059 
l0: 0.015230, l1: 0.017786, l2: 0.013264, l3: 0.012934, l4: 0.030728, l5: 0.026989, l6: 0.025308

[epoch:  61/100000, batch:    48/  187, ite: 5664] train loss: 0.307808, tar: 0.033049 
l0: 0.017121, l1: 0.017053, l2: 0.024564, l3: 0.032885, l4: 0.030032, l5: 0.028252, l6: 0.031366

[epoch:  61/100000, batch:    50/  187, ite: 5665] train loss: 0.307732, tar: 0.033039 
l0: 0.013065, l1: 0.013057, l2: 0.017528, l3: 0.014460, l4: 0.028972, l5: 0.028480, l6: 0.031959

[epoch:  61/100000, batch:    52/  187, ite: 5666] train loss: 0.307635, tar: 0.033027 
l0: 0.035569, l1: 0.029214, l2: 0.065594, l3: 0.076677, l4: 0.058176, l5: 0.052348, l6: 0.059326

[epoch:  61/100000, batch:    54/  187, ite: 5667] train loss: 0.307677, tar: 0.033029 
l0: 0.057372, l1: 0.057434, l2: 0.060973, l3: 0.062463, l4: 0.054278, l5: 0.059802, l6: 0.050931

[epoch:  61/100000, batch:    56/  187, ite: 5668] train loss: 0.307734, tar: 0.033043 
l0: 0.018336, l1: 0.020017, l2: 0.021858, l3: 0.021052, l4: 0.027917, l5: 0.027104, l6: 0.024992

[epoch:  61/100000, batch:    58/  187, ite: 5669] train loss: 0.307646, tar: 0.033035 
l0: 0.028611, l1: 0.034263, l2: 0.024625, l3: 0.027023, l4: 0.043932, l5: 0.040164, l6: 0.037151

[epoch:  61/100000, batch:    60/  187, ite: 5670] train loss: 0.307603, tar: 0.033032 
l0: 0.039286, l1: 0.041205, l2: 0.042929, l3: 0.045176, l4: 0.054616, l5: 0.047446, l6: 0.043646

[epoch:  61/100000, batch:    62/  187, ite: 5671] train loss: 0.307607, tar: 0.033036 
l0: 0.018623, l1: 0.016620, l2: 0.029037, l3: 0.029025, l4: 0.064958, l5: 0.053713, l6: 0.048529

[epoch:  61/100000, batch:    64/  187, ite: 5672] train loss: 0.307579, tar: 0.033027 
l0: 0.020303, l1: 0.019610, l2: 0.024810, l3: 0.030058, l4: 0.031739, l5: 0.044493, l6: 0.043333

[epoch:  61/100000, batch:    66/  187, ite: 5673] train loss: 0.307524, tar: 0.033019 
l0: 0.026519, l1: 0.029590, l2: 0.051061, l3: 0.037934, l4: 0.050987, l5: 0.051522, l6: 0.053830

[epoch:  61/100000, batch:    68/  187, ite: 5674] train loss: 0.307520, tar: 0.033016 
l0: 0.046188, l1: 0.051798, l2: 0.048405, l3: 0.041565, l4: 0.049626, l5: 0.056864, l6: 0.051568

[epoch:  61/100000, batch:    70/  187, ite: 5675] train loss: 0.307543, tar: 0.033023 
l0: 0.031287, l1: 0.032375, l2: 0.041076, l3: 0.034192, l4: 0.042342, l5: 0.047946, l6: 0.056354

[epoch:  61/100000, batch:    72/  187, ite: 5676] train loss: 0.307530, tar: 0.033022 
l0: 0.015350, l1: 0.016171, l2: 0.015654, l3: 0.017797, l4: 0.032833, l5: 0.029401, l6: 0.028199

[epoch:  61/100000, batch:    74/  187, ite: 5677] train loss: 0.307439, tar: 0.033012 
l0: 0.017638, l1: 0.017786, l2: 0.014900, l3: 0.014521, l4: 0.023500, l5: 0.024036, l6: 0.030481

[epoch:  61/100000, batch:    76/  187, ite: 5678] train loss: 0.307341, tar: 0.033003 
l0: 0.028356, l1: 0.028514, l2: 0.036639, l3: 0.033707, l4: 0.042432, l5: 0.040326, l6: 0.039863

[epoch:  61/100000, batch:    78/  187, ite: 5679] train loss: 0.307307, tar: 0.033000 
l0: 0.026397, l1: 0.028341, l2: 0.030080, l3: 0.031947, l4: 0.038922, l5: 0.043382, l6: 0.038246

[epoch:  61/100000, batch:    80/  187, ite: 5680] train loss: 0.307265, tar: 0.032996 
l0: 0.028566, l1: 0.027332, l2: 0.045377, l3: 0.046758, l4: 0.035486, l5: 0.041020, l6: 0.038531

[epoch:  61/100000, batch:    82/  187, ite: 5681] train loss: 0.307239, tar: 0.032993 
l0: 0.036904, l1: 0.038166, l2: 0.041119, l3: 0.040788, l4: 0.052277, l5: 0.054844, l6: 0.048094

[epoch:  61/100000, batch:    84/  187, ite: 5682] train loss: 0.307242, tar: 0.032996 
l0: 0.020127, l1: 0.027567, l2: 0.020452, l3: 0.021215, l4: 0.050478, l5: 0.044693, l6: 0.041711

[epoch:  61/100000, batch:    86/  187, ite: 5683] train loss: 0.307194, tar: 0.032988 
l0: 0.019425, l1: 0.021886, l2: 0.022306, l3: 0.019954, l4: 0.026383, l5: 0.026805, l6: 0.027100

[epoch:  61/100000, batch:    88/  187, ite: 5684] train loss: 0.307108, tar: 0.032980 
l0: 0.014177, l1: 0.015524, l2: 0.014649, l3: 0.015482, l4: 0.020935, l5: 0.019512, l6: 0.018721

[epoch:  61/100000, batch:    90/  187, ite: 5685] train loss: 0.306997, tar: 0.032969 
l0: 0.024995, l1: 0.021833, l2: 0.041914, l3: 0.041430, l4: 0.050767, l5: 0.054385, l6: 0.060566

[epoch:  61/100000, batch:    92/  187, ite: 5686] train loss: 0.306990, tar: 0.032964 
l0: 0.013816, l1: 0.013748, l2: 0.017402, l3: 0.016324, l4: 0.025251, l5: 0.027471, l6: 0.029694

[epoch:  61/100000, batch:    94/  187, ite: 5687] train loss: 0.306893, tar: 0.032953 
l0: 0.029532, l1: 0.034238, l2: 0.028382, l3: 0.027076, l4: 0.050989, l5: 0.053867, l6: 0.070324

[epoch:  61/100000, batch:    96/  187, ite: 5688] train loss: 0.306886, tar: 0.032951 
l0: 0.013538, l1: 0.012659, l2: 0.021461, l3: 0.023246, l4: 0.020890, l5: 0.027365, l6: 0.023169

[epoch:  61/100000, batch:    98/  187, ite: 5689] train loss: 0.306789, tar: 0.032939 
l0: 0.017034, l1: 0.018184, l2: 0.021027, l3: 0.020566, l4: 0.028020, l5: 0.027773, l6: 0.033246

[epoch:  61/100000, batch:   100/  187, ite: 5690] train loss: 0.306705, tar: 0.032930 
l0: 0.027197, l1: 0.029876, l2: 0.029985, l3: 0.030792, l4: 0.043509, l5: 0.040433, l6: 0.040498

[epoch:  61/100000, batch:   102/  187, ite: 5691] train loss: 0.306667, tar: 0.032926 
l0: 0.033905, l1: 0.036389, l2: 0.047050, l3: 0.043981, l4: 0.051154, l5: 0.039129, l6: 0.040401

[epoch:  61/100000, batch:   104/  187, ite: 5692] train loss: 0.306659, tar: 0.032927 
l0: 0.019966, l1: 0.019554, l2: 0.019960, l3: 0.018650, l4: 0.030036, l5: 0.039553, l6: 0.058957

[epoch:  61/100000, batch:   106/  187, ite: 5693] train loss: 0.306599, tar: 0.032919 
l0: 0.015361, l1: 0.016218, l2: 0.017378, l3: 0.018056, l4: 0.025716, l5: 0.025632, l6: 0.022807

[epoch:  61/100000, batch:   108/  187, ite: 5694] train loss: 0.306502, tar: 0.032909 
l0: 0.024996, l1: 0.024604, l2: 0.026328, l3: 0.028721, l4: 0.039913, l5: 0.041504, l6: 0.048329

[epoch:  61/100000, batch:   110/  187, ite: 5695] train loss: 0.306459, tar: 0.032904 
l0: 0.024889, l1: 0.025171, l2: 0.032834, l3: 0.027557, l4: 0.035135, l5: 0.035158, l6: 0.035094

[epoch:  61/100000, batch:   112/  187, ite: 5696] train loss: 0.306406, tar: 0.032900 
l0: 0.025322, l1: 0.028595, l2: 0.027951, l3: 0.023588, l4: 0.031307, l5: 0.031868, l6: 0.038980

[epoch:  61/100000, batch:   114/  187, ite: 5697] train loss: 0.306348, tar: 0.032895 
l0: 0.070002, l1: 0.076385, l2: 0.095186, l3: 0.064617, l4: 0.070502, l5: 0.070042, l6: 0.062485

[epoch:  61/100000, batch:   116/  187, ite: 5698] train loss: 0.306467, tar: 0.032917 
l0: 0.011313, l1: 0.011908, l2: 0.014247, l3: 0.014053, l4: 0.017379, l5: 0.018406, l6: 0.019583

[epoch:  61/100000, batch:   118/  187, ite: 5699] train loss: 0.306350, tar: 0.032904 
l0: 0.020940, l1: 0.023572, l2: 0.025939, l3: 0.025504, l4: 0.030894, l5: 0.031018, l6: 0.036304

[epoch:  61/100000, batch:   120/  187, ite: 5700] train loss: 0.306284, tar: 0.032897 
l0: 0.019847, l1: 0.019484, l2: 0.031247, l3: 0.030372, l4: 0.041509, l5: 0.035268, l6: 0.031409

[epoch:  61/100000, batch:   122/  187, ite: 5701] train loss: 0.306227, tar: 0.032889 
l0: 0.018930, l1: 0.020656, l2: 0.022097, l3: 0.021761, l4: 0.038577, l5: 0.043460, l6: 0.048453

[epoch:  61/100000, batch:   124/  187, ite: 5702] train loss: 0.306172, tar: 0.032881 
l0: 0.043827, l1: 0.042503, l2: 0.074894, l3: 0.066461, l4: 0.067373, l5: 0.076722, l6: 0.087861

[epoch:  61/100000, batch:   126/  187, ite: 5703] train loss: 0.306262, tar: 0.032888 
l0: 0.030630, l1: 0.026768, l2: 0.033864, l3: 0.039314, l4: 0.083641, l5: 0.097850, l6: 0.096948

[epoch:  61/100000, batch:   128/  187, ite: 5704] train loss: 0.306323, tar: 0.032886 
l0: 0.022488, l1: 0.024042, l2: 0.025120, l3: 0.022431, l4: 0.044412, l5: 0.042011, l6: 0.039808

[epoch:  61/100000, batch:   130/  187, ite: 5705] train loss: 0.306272, tar: 0.032880 
l0: 0.026310, l1: 0.022679, l2: 0.029029, l3: 0.032747, l4: 0.053228, l5: 0.058972, l6: 0.063248

[epoch:  61/100000, batch:   132/  187, ite: 5706] train loss: 0.306260, tar: 0.032876 
l0: 0.019994, l1: 0.019491, l2: 0.023793, l3: 0.024986, l4: 0.041913, l5: 0.055036, l6: 0.059477

[epoch:  61/100000, batch:   134/  187, ite: 5707] train loss: 0.306224, tar: 0.032869 
l0: 0.025694, l1: 0.023182, l2: 0.035284, l3: 0.035813, l4: 0.044010, l5: 0.047885, l6: 0.046502

[epoch:  61/100000, batch:   136/  187, ite: 5708] train loss: 0.306196, tar: 0.032865 
l0: 0.025816, l1: 0.026853, l2: 0.030376, l3: 0.030570, l4: 0.041765, l5: 0.049816, l6: 0.054978

[epoch:  61/100000, batch:   138/  187, ite: 5709] train loss: 0.306169, tar: 0.032861 
l0: 0.025860, l1: 0.024899, l2: 0.031114, l3: 0.030159, l4: 0.052769, l5: 0.060829, l6: 0.060492

[epoch:  61/100000, batch:   140/  187, ite: 5710] train loss: 0.306158, tar: 0.032856 
l0: 0.009215, l1: 0.012284, l2: 0.011211, l3: 0.007473, l4: 0.015922, l5: 0.017995, l6: 0.015230

[epoch:  61/100000, batch:   142/  187, ite: 5711] train loss: 0.306031, tar: 0.032843 
l0: 0.029670, l1: 0.023385, l2: 0.043267, l3: 0.051095, l4: 0.065640, l5: 0.089396, l6: 0.097138

[epoch:  61/100000, batch:   144/  187, ite: 5712] train loss: 0.306086, tar: 0.032841 
l0: 0.012866, l1: 0.016334, l2: 0.012463, l3: 0.014069, l4: 0.029342, l5: 0.030591, l6: 0.032867

[epoch:  61/100000, batch:   146/  187, ite: 5713] train loss: 0.305994, tar: 0.032829 
l0: 0.013608, l1: 0.014108, l2: 0.014147, l3: 0.015236, l4: 0.031659, l5: 0.032525, l6: 0.039246

[epoch:  61/100000, batch:   148/  187, ite: 5714] train loss: 0.305909, tar: 0.032818 
l0: 0.018006, l1: 0.019439, l2: 0.022158, l3: 0.021374, l4: 0.034965, l5: 0.039030, l6: 0.029368

[epoch:  61/100000, batch:   150/  187, ite: 5715] train loss: 0.305838, tar: 0.032809 
l0: 0.030651, l1: 0.031497, l2: 0.035031, l3: 0.031649, l4: 0.045554, l5: 0.049965, l6: 0.068907

[epoch:  61/100000, batch:   152/  187, ite: 5716] train loss: 0.305831, tar: 0.032808 
l0: 0.016842, l1: 0.015720, l2: 0.018536, l3: 0.019598, l4: 0.023846, l5: 0.024989, l6: 0.026921

[epoch:  61/100000, batch:   154/  187, ite: 5717] train loss: 0.305738, tar: 0.032799 
l0: 0.036155, l1: 0.034647, l2: 0.047686, l3: 0.057161, l4: 0.041988, l5: 0.047590, l6: 0.056516

[epoch:  61/100000, batch:   156/  187, ite: 5718] train loss: 0.305747, tar: 0.032801 
l0: 0.035434, l1: 0.038502, l2: 0.038819, l3: 0.036553, l4: 0.042952, l5: 0.041443, l6: 0.041801

[epoch:  61/100000, batch:   158/  187, ite: 5719] train loss: 0.305730, tar: 0.032802 
l0: 0.020557, l1: 0.020977, l2: 0.025712, l3: 0.024705, l4: 0.033188, l5: 0.031882, l6: 0.036268

[epoch:  61/100000, batch:   160/  187, ite: 5720] train loss: 0.305664, tar: 0.032795 
l0: 0.026463, l1: 0.027384, l2: 0.025905, l3: 0.030125, l4: 0.040264, l5: 0.040509, l6: 0.045998

[epoch:  61/100000, batch:   162/  187, ite: 5721] train loss: 0.305624, tar: 0.032791 
l0: 0.017327, l1: 0.016717, l2: 0.026838, l3: 0.026819, l4: 0.038454, l5: 0.033940, l6: 0.036444

[epoch:  61/100000, batch:   164/  187, ite: 5722] train loss: 0.305561, tar: 0.032782 
l0: 0.026157, l1: 0.030898, l2: 0.028191, l3: 0.027249, l4: 0.048310, l5: 0.044734, l6: 0.049858

[epoch:  61/100000, batch:   166/  187, ite: 5723] train loss: 0.305532, tar: 0.032779 
l0: 0.019449, l1: 0.018224, l2: 0.030011, l3: 0.030209, l4: 0.037956, l5: 0.039418, l6: 0.043513

[epoch:  61/100000, batch:   168/  187, ite: 5724] train loss: 0.305481, tar: 0.032771 
l0: 0.049302, l1: 0.045842, l2: 0.065627, l3: 0.079728, l4: 0.151775, l5: 0.133352, l6: 0.113529

[epoch:  61/100000, batch:   170/  187, ite: 5725] train loss: 0.305675, tar: 0.032780 
l0: 0.019957, l1: 0.019725, l2: 0.027096, l3: 0.026229, l4: 0.054853, l5: 0.051867, l6: 0.041007

[epoch:  61/100000, batch:   172/  187, ite: 5726] train loss: 0.305637, tar: 0.032773 
l0: 0.037908, l1: 0.035692, l2: 0.047542, l3: 0.045442, l4: 0.079308, l5: 0.086347, l6: 0.077037

[epoch:  61/100000, batch:   174/  187, ite: 5727] train loss: 0.305697, tar: 0.032776 
l0: 0.020086, l1: 0.019531, l2: 0.025325, l3: 0.025435, l4: 0.037692, l5: 0.039053, l6: 0.053103

[epoch:  61/100000, batch:   176/  187, ite: 5728] train loss: 0.305648, tar: 0.032769 
l0: 0.019090, l1: 0.017284, l2: 0.035968, l3: 0.038889, l4: 0.052083, l5: 0.049528, l6: 0.051671

[epoch:  61/100000, batch:   178/  187, ite: 5729] train loss: 0.305624, tar: 0.032761 
l0: 0.025741, l1: 0.028116, l2: 0.026626, l3: 0.029800, l4: 0.034978, l5: 0.039416, l6: 0.035071

[epoch:  61/100000, batch:   180/  187, ite: 5730] train loss: 0.305574, tar: 0.032757 
l0: 0.027293, l1: 0.027434, l2: 0.030277, l3: 0.026031, l4: 0.032098, l5: 0.039831, l6: 0.032558

[epoch:  61/100000, batch:   182/  187, ite: 5731] train loss: 0.305522, tar: 0.032754 
l0: 0.027735, l1: 0.033626, l2: 0.030253, l3: 0.032908, l4: 0.031607, l5: 0.031981, l6: 0.032682

[epoch:  61/100000, batch:   184/  187, ite: 5732] train loss: 0.305473, tar: 0.032751 
l0: 0.026587, l1: 0.026811, l2: 0.029579, l3: 0.030234, l4: 0.050991, l5: 0.044533, l6: 0.055345

[epoch:  61/100000, batch:   186/  187, ite: 5733] train loss: 0.305449, tar: 0.032747 
l0: 0.027744, l1: 0.027943, l2: 0.036960, l3: 0.043611, l4: 0.038152, l5: 0.046736, l6: 0.030620

[epoch:  61/100000, batch:   188/  187, ite: 5734] train loss: 0.305418, tar: 0.032744 
l0: 0.037649, l1: 0.036121, l2: 0.036244, l3: 0.042501, l4: 0.078250, l5: 0.076710, l6: 0.068631

[epoch:  62/100000, batch:     2/  187, ite: 5735] train loss: 0.305459, tar: 0.032747 
l0: 0.024523, l1: 0.025735, l2: 0.027741, l3: 0.028766, l4: 0.036915, l5: 0.034094, l6: 0.042131

[epoch:  62/100000, batch:     4/  187, ite: 5736] train loss: 0.305410, tar: 0.032742 
l0: 0.029368, l1: 0.027286, l2: 0.036513, l3: 0.041757, l4: 0.056120, l5: 0.056115, l6: 0.063485

[epoch:  62/100000, batch:     6/  187, ite: 5737] train loss: 0.305413, tar: 0.032740 
l0: 0.015972, l1: 0.014781, l2: 0.028386, l3: 0.031085, l4: 0.047517, l5: 0.040700, l6: 0.033951

[epoch:  62/100000, batch:     8/  187, ite: 5738] train loss: 0.305359, tar: 0.032731 
l0: 0.027444, l1: 0.030074, l2: 0.035918, l3: 0.035303, l4: 0.046642, l5: 0.054000, l6: 0.051409

[epoch:  62/100000, batch:    10/  187, ite: 5739] train loss: 0.305345, tar: 0.032728 
l0: 0.023520, l1: 0.023265, l2: 0.028613, l3: 0.031163, l4: 0.081344, l5: 0.042828, l6: 0.049535

[epoch:  62/100000, batch:    12/  187, ite: 5740] train loss: 0.305331, tar: 0.032722 
l0: 0.019711, l1: 0.020039, l2: 0.027196, l3: 0.029189, l4: 0.037700, l5: 0.042166, l6: 0.048310

[epoch:  62/100000, batch:    14/  187, ite: 5741] train loss: 0.305284, tar: 0.032715 
l0: 0.027289, l1: 0.025677, l2: 0.036614, l3: 0.036322, l4: 0.045754, l5: 0.049454, l6: 0.054413

[epoch:  62/100000, batch:    16/  187, ite: 5742] train loss: 0.305267, tar: 0.032712 
l0: 0.051659, l1: 0.056706, l2: 0.052068, l3: 0.046649, l4: 0.049980, l5: 0.046787, l6: 0.044853

[epoch:  62/100000, batch:    18/  187, ite: 5743] train loss: 0.305292, tar: 0.032723 
l0: 0.013588, l1: 0.013601, l2: 0.017105, l3: 0.017134, l4: 0.041292, l5: 0.044477, l6: 0.041385

[epoch:  62/100000, batch:    20/  187, ite: 5744] train loss: 0.305225, tar: 0.032712 
l0: 0.016762, l1: 0.016235, l2: 0.022558, l3: 0.023047, l4: 0.031139, l5: 0.030638, l6: 0.035752

[epoch:  62/100000, batch:    22/  187, ite: 5745] train loss: 0.305151, tar: 0.032703 
l0: 0.029719, l1: 0.032445, l2: 0.029678, l3: 0.025714, l4: 0.059722, l5: 0.042284, l6: 0.043251

[epoch:  62/100000, batch:    24/  187, ite: 5746] train loss: 0.305127, tar: 0.032701 
l0: 0.031055, l1: 0.026362, l2: 0.055050, l3: 0.053673, l4: 0.048863, l5: 0.044306, l6: 0.053242

[epoch:  62/100000, batch:    26/  187, ite: 5747] train loss: 0.305131, tar: 0.032700 
l0: 0.016160, l1: 0.016213, l2: 0.018106, l3: 0.018986, l4: 0.049722, l5: 0.050001, l6: 0.044469

[epoch:  62/100000, batch:    28/  187, ite: 5748] train loss: 0.305079, tar: 0.032690 
l0: 0.022509, l1: 0.023585, l2: 0.033603, l3: 0.028615, l4: 0.030860, l5: 0.026435, l6: 0.021985

[epoch:  62/100000, batch:    30/  187, ite: 5749] train loss: 0.305012, tar: 0.032685 
l0: 0.016134, l1: 0.016493, l2: 0.020638, l3: 0.022204, l4: 0.031966, l5: 0.024504, l6: 0.024038

[epoch:  62/100000, batch:    32/  187, ite: 5750] train loss: 0.304927, tar: 0.032675 
l0: 0.019154, l1: 0.017826, l2: 0.028807, l3: 0.034414, l4: 0.041197, l5: 0.034886, l6: 0.035321

[epoch:  62/100000, batch:    34/  187, ite: 5751] train loss: 0.304873, tar: 0.032667 
l0: 0.012583, l1: 0.014010, l2: 0.018539, l3: 0.021228, l4: 0.037877, l5: 0.027931, l6: 0.032026

[epoch:  62/100000, batch:    36/  187, ite: 5752] train loss: 0.304793, tar: 0.032656 
l0: 0.010431, l1: 0.011086, l2: 0.015010, l3: 0.015794, l4: 0.016850, l5: 0.021425, l6: 0.023665

[epoch:  62/100000, batch:    38/  187, ite: 5753] train loss: 0.304684, tar: 0.032643 
l0: 0.021565, l1: 0.019672, l2: 0.031054, l3: 0.032624, l4: 0.037026, l5: 0.037665, l6: 0.047933

[epoch:  62/100000, batch:    40/  187, ite: 5754] train loss: 0.304640, tar: 0.032637 
l0: 0.019051, l1: 0.016967, l2: 0.026966, l3: 0.030206, l4: 0.065964, l5: 0.050033, l6: 0.057714

[epoch:  62/100000, batch:    42/  187, ite: 5755] train loss: 0.304619, tar: 0.032629 
l0: 0.039875, l1: 0.036529, l2: 0.039882, l3: 0.043170, l4: 0.041807, l5: 0.052665, l6: 0.057873

[epoch:  62/100000, batch:    44/  187, ite: 5756] train loss: 0.304623, tar: 0.032633 
l0: 0.013373, l1: 0.012351, l2: 0.016851, l3: 0.016265, l4: 0.022934, l5: 0.027302, l6: 0.034598

[epoch:  62/100000, batch:    46/  187, ite: 5757] train loss: 0.304531, tar: 0.032622 
l0: 0.025489, l1: 0.025314, l2: 0.024335, l3: 0.032542, l4: 0.038132, l5: 0.041634, l6: 0.033437

[epoch:  62/100000, batch:    48/  187, ite: 5758] train loss: 0.304484, tar: 0.032618 
l0: 0.018619, l1: 0.019901, l2: 0.028194, l3: 0.028736, l4: 0.034430, l5: 0.027973, l6: 0.027449

[epoch:  62/100000, batch:    50/  187, ite: 5759] train loss: 0.304416, tar: 0.032610 
l0: 0.020956, l1: 0.021180, l2: 0.024257, l3: 0.025283, l4: 0.042526, l5: 0.040044, l6: 0.032886

[epoch:  62/100000, batch:    52/  187, ite: 5760] train loss: 0.304361, tar: 0.032604 
l0: 0.017447, l1: 0.016474, l2: 0.020234, l3: 0.022555, l4: 0.041693, l5: 0.042123, l6: 0.032321

[epoch:  62/100000, batch:    54/  187, ite: 5761] train loss: 0.304297, tar: 0.032595 
l0: 0.018483, l1: 0.022044, l2: 0.020341, l3: 0.021074, l4: 0.039060, l5: 0.032030, l6: 0.030847

[epoch:  62/100000, batch:    56/  187, ite: 5762] train loss: 0.304229, tar: 0.032587 
l0: 0.023265, l1: 0.023752, l2: 0.025366, l3: 0.025876, l4: 0.031213, l5: 0.029345, l6: 0.043471

[epoch:  62/100000, batch:    58/  187, ite: 5763] train loss: 0.304171, tar: 0.032582 
l0: 0.018941, l1: 0.020740, l2: 0.018354, l3: 0.017708, l4: 0.037718, l5: 0.032066, l6: 0.031769

[epoch:  62/100000, batch:    60/  187, ite: 5764] train loss: 0.304099, tar: 0.032574 
l0: 0.022359, l1: 0.024714, l2: 0.020498, l3: 0.022364, l4: 0.031684, l5: 0.030281, l6: 0.029908

[epoch:  62/100000, batch:    62/  187, ite: 5765] train loss: 0.304030, tar: 0.032568 
l0: 0.037707, l1: 0.037950, l2: 0.036554, l3: 0.037963, l4: 0.042823, l5: 0.049984, l6: 0.060951

[epoch:  62/100000, batch:    64/  187, ite: 5766] train loss: 0.304030, tar: 0.032571 
l0: 0.021715, l1: 0.022380, l2: 0.025825, l3: 0.027798, l4: 0.031839, l5: 0.029842, l6: 0.032343

[epoch:  62/100000, batch:    66/  187, ite: 5767] train loss: 0.303966, tar: 0.032565 
l0: 0.022157, l1: 0.023756, l2: 0.020928, l3: 0.024719, l4: 0.053984, l5: 0.037107, l6: 0.040666

[epoch:  62/100000, batch:    68/  187, ite: 5768] train loss: 0.303921, tar: 0.032559 
l0: 0.016582, l1: 0.017343, l2: 0.023178, l3: 0.023663, l4: 0.024431, l5: 0.025693, l6: 0.023842

[epoch:  62/100000, batch:    70/  187, ite: 5769] train loss: 0.303836, tar: 0.032550 
l0: 0.017250, l1: 0.017286, l2: 0.021191, l3: 0.019079, l4: 0.028868, l5: 0.033401, l6: 0.031800

[epoch:  62/100000, batch:    72/  187, ite: 5770] train loss: 0.303760, tar: 0.032542 
l0: 0.017293, l1: 0.017021, l2: 0.022602, l3: 0.029173, l4: 0.030148, l5: 0.030549, l6: 0.034582

[epoch:  62/100000, batch:    74/  187, ite: 5771] train loss: 0.303691, tar: 0.032533 
l0: 0.025406, l1: 0.027423, l2: 0.027803, l3: 0.025906, l4: 0.030667, l5: 0.035382, l6: 0.034734

[epoch:  62/100000, batch:    76/  187, ite: 5772] train loss: 0.303637, tar: 0.032529 
l0: 0.015289, l1: 0.015783, l2: 0.020096, l3: 0.017473, l4: 0.021128, l5: 0.022944, l6: 0.021882

[epoch:  62/100000, batch:    78/  187, ite: 5773] train loss: 0.303541, tar: 0.032519 
l0: 0.014202, l1: 0.016378, l2: 0.015800, l3: 0.015717, l4: 0.023887, l5: 0.023239, l6: 0.019820

[epoch:  62/100000, batch:    80/  187, ite: 5774] train loss: 0.303443, tar: 0.032509 
l0: 0.012800, l1: 0.014902, l2: 0.018726, l3: 0.016304, l4: 0.024782, l5: 0.022677, l6: 0.027676

[epoch:  62/100000, batch:    82/  187, ite: 5775] train loss: 0.303350, tar: 0.032498 
l0: 0.024612, l1: 0.025031, l2: 0.030842, l3: 0.030296, l4: 0.043513, l5: 0.041992, l6: 0.039269

[epoch:  62/100000, batch:    84/  187, ite: 5776] train loss: 0.303311, tar: 0.032493 
l0: 0.020906, l1: 0.021155, l2: 0.022984, l3: 0.021553, l4: 0.039561, l5: 0.044426, l6: 0.046716

[epoch:  62/100000, batch:    86/  187, ite: 5777] train loss: 0.303263, tar: 0.032487 
l0: 0.016923, l1: 0.020560, l2: 0.023879, l3: 0.014682, l4: 0.031037, l5: 0.035636, l6: 0.023089

[epoch:  62/100000, batch:    88/  187, ite: 5778] train loss: 0.303186, tar: 0.032478 
l0: 0.028207, l1: 0.028876, l2: 0.022691, l3: 0.027964, l4: 0.043368, l5: 0.041362, l6: 0.042376

[epoch:  62/100000, batch:    90/  187, ite: 5779] train loss: 0.303147, tar: 0.032476 
l0: 0.052222, l1: 0.050725, l2: 0.061176, l3: 0.083162, l4: 0.100350, l5: 0.084896, l6: 0.059305

[epoch:  62/100000, batch:    92/  187, ite: 5780] train loss: 0.303253, tar: 0.032487 
l0: 0.016186, l1: 0.016807, l2: 0.023465, l3: 0.022097, l4: 0.026470, l5: 0.022778, l6: 0.026057

[epoch:  62/100000, batch:    94/  187, ite: 5781] train loss: 0.303169, tar: 0.032478 
l0: 0.011008, l1: 0.011327, l2: 0.012959, l3: 0.011951, l4: 0.020079, l5: 0.020303, l6: 0.017451

[epoch:  62/100000, batch:    96/  187, ite: 5782] train loss: 0.303058, tar: 0.032466 
l0: 0.013085, l1: 0.012013, l2: 0.014887, l3: 0.020037, l4: 0.031548, l5: 0.036693, l6: 0.031099

[epoch:  62/100000, batch:    98/  187, ite: 5783] train loss: 0.302978, tar: 0.032455 
l0: 0.018494, l1: 0.019220, l2: 0.020775, l3: 0.020062, l4: 0.030405, l5: 0.035899, l6: 0.033144

[epoch:  62/100000, batch:   100/  187, ite: 5784] train loss: 0.302908, tar: 0.032447 
l0: 0.024784, l1: 0.027809, l2: 0.024083, l3: 0.026122, l4: 0.039148, l5: 0.041520, l6: 0.040809

[epoch:  62/100000, batch:   102/  187, ite: 5785] train loss: 0.302864, tar: 0.032443 
l0: 0.021785, l1: 0.018986, l2: 0.029450, l3: 0.030801, l4: 0.047009, l5: 0.051271, l6: 0.045873

[epoch:  62/100000, batch:   104/  187, ite: 5786] train loss: 0.302831, tar: 0.032437 
l0: 0.020371, l1: 0.019729, l2: 0.023840, l3: 0.024919, l4: 0.040263, l5: 0.042500, l6: 0.040584

[epoch:  62/100000, batch:   106/  187, ite: 5787] train loss: 0.302781, tar: 0.032430 
l0: 0.019615, l1: 0.019581, l2: 0.032283, l3: 0.035927, l4: 0.021884, l5: 0.021297, l6: 0.024440

[epoch:  62/100000, batch:   108/  187, ite: 5788] train loss: 0.302709, tar: 0.032423 
l0: 0.028492, l1: 0.027870, l2: 0.034091, l3: 0.044328, l4: 0.031871, l5: 0.033392, l6: 0.034296

[epoch:  62/100000, batch:   110/  187, ite: 5789] train loss: 0.302671, tar: 0.032420 
l0: 0.011099, l1: 0.012834, l2: 0.019781, l3: 0.018679, l4: 0.020238, l5: 0.025010, l6: 0.016087

[epoch:  62/100000, batch:   112/  187, ite: 5790] train loss: 0.302571, tar: 0.032409 
l0: 0.025421, l1: 0.023739, l2: 0.038949, l3: 0.048265, l4: 0.042496, l5: 0.045543, l6: 0.052384

[epoch:  62/100000, batch:   114/  187, ite: 5791] train loss: 0.302557, tar: 0.032405 
l0: 0.040435, l1: 0.043283, l2: 0.043891, l3: 0.042665, l4: 0.041327, l5: 0.047399, l6: 0.047918

[epoch:  62/100000, batch:   116/  187, ite: 5792] train loss: 0.302559, tar: 0.032409 
l0: 0.016921, l1: 0.017973, l2: 0.021315, l3: 0.028530, l4: 0.034662, l5: 0.028324, l6: 0.031572

[epoch:  62/100000, batch:   118/  187, ite: 5793] train loss: 0.302490, tar: 0.032400 
l0: 0.023940, l1: 0.023585, l2: 0.023642, l3: 0.027915, l4: 0.044032, l5: 0.046598, l6: 0.061863

[epoch:  62/100000, batch:   120/  187, ite: 5794] train loss: 0.302462, tar: 0.032396 
l0: 0.022161, l1: 0.020565, l2: 0.030873, l3: 0.035886, l4: 0.062572, l5: 0.066764, l6: 0.063026

[epoch:  62/100000, batch:   122/  187, ite: 5795] train loss: 0.302462, tar: 0.032390 
l0: 0.017403, l1: 0.015735, l2: 0.023983, l3: 0.025464, l4: 0.030489, l5: 0.031878, l6: 0.033178

[epoch:  62/100000, batch:   124/  187, ite: 5796] train loss: 0.302392, tar: 0.032382 
l0: 0.013655, l1: 0.013576, l2: 0.015239, l3: 0.017283, l4: 0.024656, l5: 0.029095, l6: 0.026230

[epoch:  62/100000, batch:   126/  187, ite: 5797] train loss: 0.302302, tar: 0.032371 
l0: 0.017425, l1: 0.017935, l2: 0.016406, l3: 0.014350, l4: 0.027136, l5: 0.030109, l6: 0.035214

[epoch:  62/100000, batch:   128/  187, ite: 5798] train loss: 0.302222, tar: 0.032363 
l0: 0.018523, l1: 0.017783, l2: 0.020176, l3: 0.020991, l4: 0.032847, l5: 0.035505, l6: 0.039261

[epoch:  62/100000, batch:   130/  187, ite: 5799] train loss: 0.302157, tar: 0.032355 
l0: 0.028111, l1: 0.030521, l2: 0.036268, l3: 0.040112, l4: 0.041897, l5: 0.037800, l6: 0.044884

[epoch:  62/100000, batch:   132/  187, ite: 5800] train loss: 0.302133, tar: 0.032353 
l0: 0.019629, l1: 0.022645, l2: 0.019856, l3: 0.018962, l4: 0.023871, l5: 0.024761, l6: 0.025003

[epoch:  62/100000, batch:   134/  187, ite: 5801] train loss: 0.302051, tar: 0.032346 
l0: 0.028514, l1: 0.028954, l2: 0.029303, l3: 0.036022, l4: 0.045546, l5: 0.043319, l6: 0.045080

[epoch:  62/100000, batch:   136/  187, ite: 5802] train loss: 0.302026, tar: 0.032344 
l0: 0.027805, l1: 0.027518, l2: 0.036214, l3: 0.038837, l4: 0.094917, l5: 0.090744, l6: 0.088191

[epoch:  62/100000, batch:   138/  187, ite: 5803] train loss: 0.302083, tar: 0.032341 
l0: 0.016811, l1: 0.017975, l2: 0.017864, l3: 0.018995, l4: 0.030894, l5: 0.039590, l6: 0.035307

[epoch:  62/100000, batch:   140/  187, ite: 5804] train loss: 0.302014, tar: 0.032333 
l0: 0.046811, l1: 0.048986, l2: 0.047293, l3: 0.038934, l4: 0.058794, l5: 0.063424, l6: 0.063268

[epoch:  62/100000, batch:   142/  187, ite: 5805] train loss: 0.302050, tar: 0.032341 
l0: 0.029546, l1: 0.034260, l2: 0.035036, l3: 0.031700, l4: 0.028023, l5: 0.029203, l6: 0.030240

[epoch:  62/100000, batch:   144/  187, ite: 5806] train loss: 0.302003, tar: 0.032339 
l0: 0.020496, l1: 0.021691, l2: 0.022921, l3: 0.023606, l4: 0.031281, l5: 0.036919, l6: 0.039551

[epoch:  62/100000, batch:   146/  187, ite: 5807] train loss: 0.301945, tar: 0.032333 
l0: 0.028025, l1: 0.027539, l2: 0.027775, l3: 0.034402, l4: 0.064870, l5: 0.053698, l6: 0.046955

[epoch:  62/100000, batch:   148/  187, ite: 5808] train loss: 0.301935, tar: 0.032330 
l0: 0.018377, l1: 0.018701, l2: 0.021832, l3: 0.025326, l4: 0.034561, l5: 0.045754, l6: 0.052209

[epoch:  62/100000, batch:   150/  187, ite: 5809] train loss: 0.301888, tar: 0.032322 
l0: 0.035312, l1: 0.035150, l2: 0.041338, l3: 0.035950, l4: 0.045529, l5: 0.048919, l6: 0.055359

[epoch:  62/100000, batch:   152/  187, ite: 5810] train loss: 0.301885, tar: 0.032324 
l0: 0.011457, l1: 0.017211, l2: 0.012801, l3: 0.015275, l4: 0.038494, l5: 0.038193, l6: 0.042499

[epoch:  62/100000, batch:   154/  187, ite: 5811] train loss: 0.301816, tar: 0.032313 
l0: 0.018155, l1: 0.019960, l2: 0.023386, l3: 0.020802, l4: 0.027132, l5: 0.031962, l6: 0.038924

[epoch:  62/100000, batch:   156/  187, ite: 5812] train loss: 0.301749, tar: 0.032305 
l0: 0.025431, l1: 0.025978, l2: 0.044405, l3: 0.039372, l4: 0.042390, l5: 0.039398, l6: 0.029571

[epoch:  62/100000, batch:   158/  187, ite: 5813] train loss: 0.301718, tar: 0.032301 
l0: 0.028852, l1: 0.033460, l2: 0.027343, l3: 0.026979, l4: 0.044238, l5: 0.037724, l6: 0.034765

[epoch:  62/100000, batch:   160/  187, ite: 5814] train loss: 0.301680, tar: 0.032299 
l0: 0.013383, l1: 0.014134, l2: 0.019199, l3: 0.024501, l4: 0.034818, l5: 0.032743, l6: 0.032025

[epoch:  62/100000, batch:   162/  187, ite: 5815] train loss: 0.301608, tar: 0.032289 
l0: 0.017553, l1: 0.020557, l2: 0.019554, l3: 0.018379, l4: 0.022455, l5: 0.022993, l6: 0.020999

[epoch:  62/100000, batch:   164/  187, ite: 5816] train loss: 0.301521, tar: 0.032281 
l0: 0.018324, l1: 0.018941, l2: 0.019022, l3: 0.022464, l4: 0.033474, l5: 0.037698, l6: 0.040488

[epoch:  62/100000, batch:   166/  187, ite: 5817] train loss: 0.301460, tar: 0.032273 
l0: 0.019896, l1: 0.021059, l2: 0.019119, l3: 0.020449, l4: 0.031175, l5: 0.033937, l6: 0.035324

[epoch:  62/100000, batch:   168/  187, ite: 5818] train loss: 0.301393, tar: 0.032266 
l0: 0.039808, l1: 0.042728, l2: 0.031057, l3: 0.038877, l4: 0.067497, l5: 0.065586, l6: 0.063952

[epoch:  62/100000, batch:   170/  187, ite: 5819] train loss: 0.301420, tar: 0.032270 
l0: 0.011956, l1: 0.011556, l2: 0.014635, l3: 0.017361, l4: 0.029113, l5: 0.029878, l6: 0.026725

[epoch:  62/100000, batch:   172/  187, ite: 5820] train loss: 0.301332, tar: 0.032259 
l0: 0.020713, l1: 0.025067, l2: 0.030909, l3: 0.027672, l4: 0.040938, l5: 0.035002, l6: 0.042293

[epoch:  62/100000, batch:   174/  187, ite: 5821] train loss: 0.301289, tar: 0.032253 
l0: 0.025127, l1: 0.021192, l2: 0.040763, l3: 0.044790, l4: 0.048044, l5: 0.049598, l6: 0.056200

[epoch:  62/100000, batch:   176/  187, ite: 5822] train loss: 0.301280, tar: 0.032249 
l0: 0.033433, l1: 0.033950, l2: 0.028039, l3: 0.029645, l4: 0.051353, l5: 0.051354, l6: 0.055363

[epoch:  62/100000, batch:   178/  187, ite: 5823] train loss: 0.301270, tar: 0.032249 
l0: 0.017913, l1: 0.017849, l2: 0.016195, l3: 0.020406, l4: 0.042123, l5: 0.049191, l6: 0.045909

[epoch:  62/100000, batch:   180/  187, ite: 5824] train loss: 0.301220, tar: 0.032242 
l0: 0.022877, l1: 0.022094, l2: 0.024077, l3: 0.030047, l4: 0.044804, l5: 0.044745, l6: 0.055998

[epoch:  62/100000, batch:   182/  187, ite: 5825] train loss: 0.301189, tar: 0.032236 
l0: 0.018013, l1: 0.018129, l2: 0.018810, l3: 0.024364, l4: 0.024947, l5: 0.024868, l6: 0.026181

[epoch:  62/100000, batch:   184/  187, ite: 5826] train loss: 0.301109, tar: 0.032229 
l0: 0.017979, l1: 0.019125, l2: 0.021631, l3: 0.024098, l4: 0.042714, l5: 0.035951, l6: 0.030165

[epoch:  62/100000, batch:   186/  187, ite: 5827] train loss: 0.301049, tar: 0.032221 
l0: 0.027877, l1: 0.028431, l2: 0.030984, l3: 0.043368, l4: 0.035681, l5: 0.035938, l6: 0.037843

[epoch:  62/100000, batch:   188/  187, ite: 5828] train loss: 0.301016, tar: 0.032218 
l0: 0.014449, l1: 0.014946, l2: 0.017671, l3: 0.017776, l4: 0.025441, l5: 0.026794, l6: 0.032426

[epoch:  63/100000, batch:     2/  187, ite: 5829] train loss: 0.300933, tar: 0.032209 
l0: 0.022653, l1: 0.022222, l2: 0.024795, l3: 0.025287, l4: 0.034916, l5: 0.041342, l6: 0.047280

[epoch:  63/100000, batch:     4/  187, ite: 5830] train loss: 0.300888, tar: 0.032204 
l0: 0.024195, l1: 0.022408, l2: 0.028116, l3: 0.035178, l4: 0.057426, l5: 0.052565, l6: 0.055570

[epoch:  63/100000, batch:     6/  187, ite: 5831] train loss: 0.300874, tar: 0.032199 
l0: 0.017490, l1: 0.017295, l2: 0.028173, l3: 0.028945, l4: 0.033743, l5: 0.040724, l6: 0.041266

[epoch:  63/100000, batch:     8/  187, ite: 5832] train loss: 0.300823, tar: 0.032191 
l0: 0.014873, l1: 0.015771, l2: 0.038856, l3: 0.034317, l4: 0.035655, l5: 0.027584, l6: 0.021609

[epoch:  63/100000, batch:    10/  187, ite: 5833] train loss: 0.300762, tar: 0.032182 
l0: 0.018550, l1: 0.023246, l2: 0.013523, l3: 0.014282, l4: 0.020401, l5: 0.021832, l6: 0.022322

[epoch:  63/100000, batch:    12/  187, ite: 5834] train loss: 0.300671, tar: 0.032174 
l0: 0.013496, l1: 0.014052, l2: 0.017635, l3: 0.020215, l4: 0.030271, l5: 0.033824, l6: 0.028257

[epoch:  63/100000, batch:    14/  187, ite: 5835] train loss: 0.300593, tar: 0.032164 
l0: 0.014344, l1: 0.014930, l2: 0.017504, l3: 0.023716, l4: 0.043013, l5: 0.048976, l6: 0.047383

[epoch:  63/100000, batch:    16/  187, ite: 5836] train loss: 0.300544, tar: 0.032154 
l0: 0.020110, l1: 0.020282, l2: 0.018645, l3: 0.023515, l4: 0.046680, l5: 0.043172, l6: 0.046393

[epoch:  63/100000, batch:    18/  187, ite: 5837] train loss: 0.300499, tar: 0.032148 
l0: 0.024175, l1: 0.023486, l2: 0.024368, l3: 0.026722, l4: 0.031791, l5: 0.033878, l6: 0.050709

[epoch:  63/100000, batch:    20/  187, ite: 5838] train loss: 0.300453, tar: 0.032143 
l0: 0.048651, l1: 0.047950, l2: 0.075840, l3: 0.073772, l4: 0.084433, l5: 0.084804, l6: 0.070844

[epoch:  63/100000, batch:    22/  187, ite: 5839] train loss: 0.300554, tar: 0.032152 
l0: 0.013453, l1: 0.013589, l2: 0.016101, l3: 0.020969, l4: 0.041968, l5: 0.043549, l6: 0.055551

[epoch:  63/100000, batch:    24/  187, ite: 5840] train loss: 0.300502, tar: 0.032142 
l0: 0.017212, l1: 0.017505, l2: 0.025772, l3: 0.029945, l4: 0.042704, l5: 0.037776, l6: 0.045295

[epoch:  63/100000, batch:    26/  187, ite: 5841] train loss: 0.300456, tar: 0.032134 
l0: 0.024831, l1: 0.023869, l2: 0.024493, l3: 0.029839, l4: 0.038183, l5: 0.043536, l6: 0.055848

[epoch:  63/100000, batch:    28/  187, ite: 5842] train loss: 0.300424, tar: 0.032130 
l0: 0.019988, l1: 0.019384, l2: 0.022145, l3: 0.021387, l4: 0.036626, l5: 0.039528, l6: 0.041322

[epoch:  63/100000, batch:    30/  187, ite: 5843] train loss: 0.300369, tar: 0.032124 
l0: 0.022713, l1: 0.027144, l2: 0.020883, l3: 0.022313, l4: 0.023284, l5: 0.020920, l6: 0.022445

[epoch:  63/100000, batch:    32/  187, ite: 5844] train loss: 0.300293, tar: 0.032119 
l0: 0.013191, l1: 0.012596, l2: 0.015561, l3: 0.021378, l4: 0.069737, l5: 0.054877, l6: 0.054099

[epoch:  63/100000, batch:    34/  187, ite: 5845] train loss: 0.300261, tar: 0.032108 
l0: 0.009796, l1: 0.010167, l2: 0.013369, l3: 0.017513, l4: 0.017993, l5: 0.027085, l6: 0.026370

[epoch:  63/100000, batch:    36/  187, ite: 5846] train loss: 0.300165, tar: 0.032096 
l0: 0.025746, l1: 0.025058, l2: 0.030697, l3: 0.028415, l4: 0.040136, l5: 0.054019, l6: 0.061910

[epoch:  63/100000, batch:    38/  187, ite: 5847] train loss: 0.300146, tar: 0.032093 
l0: 0.016941, l1: 0.019223, l2: 0.024737, l3: 0.024573, l4: 0.044943, l5: 0.032118, l6: 0.034707

[epoch:  63/100000, batch:    40/  187, ite: 5848] train loss: 0.300091, tar: 0.032085 
l0: 0.014570, l1: 0.014291, l2: 0.017530, l3: 0.018001, l4: 0.026238, l5: 0.029219, l6: 0.036110

[epoch:  63/100000, batch:    42/  187, ite: 5849] train loss: 0.300013, tar: 0.032075 
l0: 0.018717, l1: 0.019371, l2: 0.023973, l3: 0.023224, l4: 0.033914, l5: 0.031556, l6: 0.042721

[epoch:  63/100000, batch:    44/  187, ite: 5850] train loss: 0.299955, tar: 0.032068 
l0: 0.019557, l1: 0.019164, l2: 0.026780, l3: 0.027357, l4: 0.057819, l5: 0.049665, l6: 0.039397

[epoch:  63/100000, batch:    46/  187, ite: 5851] train loss: 0.299922, tar: 0.032061 
l0: 0.011528, l1: 0.012318, l2: 0.014958, l3: 0.014285, l4: 0.042989, l5: 0.038052, l6: 0.039804

[epoch:  63/100000, batch:    48/  187, ite: 5852] train loss: 0.299854, tar: 0.032050 
l0: 0.014378, l1: 0.012632, l2: 0.015253, l3: 0.020141, l4: 0.042987, l5: 0.043299, l6: 0.049133

[epoch:  63/100000, batch:    50/  187, ite: 5853] train loss: 0.299799, tar: 0.032040 
l0: 0.050112, l1: 0.048877, l2: 0.060336, l3: 0.052261, l4: 0.052611, l5: 0.062684, l6: 0.062640

[epoch:  63/100000, batch:    52/  187, ite: 5854] train loss: 0.299848, tar: 0.032050 
l0: 0.037270, l1: 0.036769, l2: 0.038784, l3: 0.045096, l4: 0.049566, l5: 0.056995, l6: 0.050923

[epoch:  63/100000, batch:    54/  187, ite: 5855] train loss: 0.299856, tar: 0.032053 
l0: 0.011131, l1: 0.010687, l2: 0.015828, l3: 0.015622, l4: 0.019054, l5: 0.019800, l6: 0.025404

[epoch:  63/100000, batch:    56/  187, ite: 5856] train loss: 0.299758, tar: 0.032042 
l0: 0.011280, l1: 0.011694, l2: 0.013683, l3: 0.013901, l4: 0.028040, l5: 0.029004, l6: 0.024524

[epoch:  63/100000, batch:    58/  187, ite: 5857] train loss: 0.299668, tar: 0.032031 
l0: 0.021398, l1: 0.021346, l2: 0.027729, l3: 0.027942, l4: 0.059938, l5: 0.049887, l6: 0.052436

[epoch:  63/100000, batch:    60/  187, ite: 5858] train loss: 0.299647, tar: 0.032025 
l0: 0.016166, l1: 0.015766, l2: 0.021655, l3: 0.020463, l4: 0.026808, l5: 0.026054, l6: 0.033392

[epoch:  63/100000, batch:    62/  187, ite: 5859] train loss: 0.299572, tar: 0.032016 
l0: 0.012240, l1: 0.013323, l2: 0.012311, l3: 0.014267, l4: 0.024500, l5: 0.022807, l6: 0.023871

[epoch:  63/100000, batch:    64/  187, ite: 5860] train loss: 0.299477, tar: 0.032006 
l0: 0.019655, l1: 0.019412, l2: 0.024126, l3: 0.025228, l4: 0.035835, l5: 0.039175, l6: 0.034869

[epoch:  63/100000, batch:    66/  187, ite: 5861] train loss: 0.299423, tar: 0.031999 
l0: 0.014485, l1: 0.014649, l2: 0.017451, l3: 0.018725, l4: 0.033110, l5: 0.035571, l6: 0.035536

[epoch:  63/100000, batch:    68/  187, ite: 5862] train loss: 0.299353, tar: 0.031990 
l0: 0.018299, l1: 0.019939, l2: 0.022171, l3: 0.020859, l4: 0.044409, l5: 0.046961, l6: 0.051350

[epoch:  63/100000, batch:    70/  187, ite: 5863] train loss: 0.299312, tar: 0.031982 
l0: 0.014829, l1: 0.015025, l2: 0.022274, l3: 0.019170, l4: 0.021403, l5: 0.022703, l6: 0.023218

[epoch:  63/100000, batch:    72/  187, ite: 5864] train loss: 0.299226, tar: 0.031973 
l0: 0.026718, l1: 0.030032, l2: 0.027727, l3: 0.024770, l4: 0.051139, l5: 0.041396, l6: 0.046201

[epoch:  63/100000, batch:    74/  187, ite: 5865] train loss: 0.299199, tar: 0.031970 
l0: 0.018341, l1: 0.017766, l2: 0.019941, l3: 0.026027, l4: 0.043249, l5: 0.041679, l6: 0.042791

[epoch:  63/100000, batch:    76/  187, ite: 5866] train loss: 0.299151, tar: 0.031963 
l0: 0.016106, l1: 0.017066, l2: 0.021991, l3: 0.021880, l4: 0.027232, l5: 0.024582, l6: 0.030391

[epoch:  63/100000, batch:    78/  187, ite: 5867] train loss: 0.299076, tar: 0.031954 
l0: 0.014580, l1: 0.014048, l2: 0.018199, l3: 0.017573, l4: 0.033828, l5: 0.034972, l6: 0.037769

[epoch:  63/100000, batch:    80/  187, ite: 5868] train loss: 0.299007, tar: 0.031945 
l0: 0.015444, l1: 0.016591, l2: 0.026574, l3: 0.020236, l4: 0.037398, l5: 0.041187, l6: 0.023337

[epoch:  63/100000, batch:    82/  187, ite: 5869] train loss: 0.298944, tar: 0.031936 
l0: 0.017542, l1: 0.020078, l2: 0.021517, l3: 0.024036, l4: 0.056318, l5: 0.050086, l6: 0.056192

[epoch:  63/100000, batch:    84/  187, ite: 5870] train loss: 0.298916, tar: 0.031929 
l0: 0.015959, l1: 0.016361, l2: 0.018777, l3: 0.020511, l4: 0.031370, l5: 0.032544, l6: 0.052727

[epoch:  63/100000, batch:    86/  187, ite: 5871] train loss: 0.298856, tar: 0.031920 
l0: 0.023582, l1: 0.025323, l2: 0.026518, l3: 0.033259, l4: 0.043422, l5: 0.036958, l6: 0.030749

[epoch:  63/100000, batch:    88/  187, ite: 5872] train loss: 0.298814, tar: 0.031916 
l0: 0.016844, l1: 0.018041, l2: 0.017781, l3: 0.020531, l4: 0.036134, l5: 0.031164, l6: 0.037618

[epoch:  63/100000, batch:    90/  187, ite: 5873] train loss: 0.298750, tar: 0.031908 
l0: 0.037646, l1: 0.041209, l2: 0.039051, l3: 0.039769, l4: 0.058858, l5: 0.048938, l6: 0.044264

[epoch:  63/100000, batch:    92/  187, ite: 5874] train loss: 0.298756, tar: 0.031911 
l0: 0.013447, l1: 0.014259, l2: 0.017446, l3: 0.017894, l4: 0.038788, l5: 0.031860, l6: 0.032449

[epoch:  63/100000, batch:    94/  187, ite: 5875] train loss: 0.298685, tar: 0.031901 
l0: 0.020618, l1: 0.022110, l2: 0.027586, l3: 0.023796, l4: 0.027403, l5: 0.024064, l6: 0.024493

[epoch:  63/100000, batch:    96/  187, ite: 5876] train loss: 0.298616, tar: 0.031895 
l0: 0.011350, l1: 0.012107, l2: 0.014850, l3: 0.016692, l4: 0.025649, l5: 0.021663, l6: 0.026958

[epoch:  63/100000, batch:    98/  187, ite: 5877] train loss: 0.298526, tar: 0.031884 
l0: 0.017946, l1: 0.018173, l2: 0.020007, l3: 0.019718, l4: 0.042152, l5: 0.044424, l6: 0.056059

[epoch:  63/100000, batch:   100/  187, ite: 5878] train loss: 0.298483, tar: 0.031876 
l0: 0.026337, l1: 0.022201, l2: 0.035798, l3: 0.038152, l4: 0.042856, l5: 0.043758, l6: 0.053272

[epoch:  63/100000, batch:   102/  187, ite: 5879] train loss: 0.298464, tar: 0.031873 
l0: 0.016176, l1: 0.015366, l2: 0.021022, l3: 0.020573, l4: 0.025170, l5: 0.027521, l6: 0.028974

[epoch:  63/100000, batch:   104/  187, ite: 5880] train loss: 0.298388, tar: 0.031865 
l0: 0.064202, l1: 0.069704, l2: 0.070431, l3: 0.068778, l4: 0.047448, l5: 0.034289, l6: 0.056432

[epoch:  63/100000, batch:   106/  187, ite: 5881] train loss: 0.298448, tar: 0.031882 
l0: 0.016558, l1: 0.014468, l2: 0.024327, l3: 0.026725, l4: 0.051153, l5: 0.053685, l6: 0.057541

[epoch:  63/100000, batch:   108/  187, ite: 5882] train loss: 0.298419, tar: 0.031874 
l0: 0.019015, l1: 0.018452, l2: 0.029978, l3: 0.028002, l4: 0.030650, l5: 0.033596, l6: 0.028046

[epoch:  63/100000, batch:   110/  187, ite: 5883] train loss: 0.298360, tar: 0.031867 
l0: 0.018871, l1: 0.023070, l2: 0.019939, l3: 0.020644, l4: 0.039334, l5: 0.036781, l6: 0.039641

[epoch:  63/100000, batch:   112/  187, ite: 5884] train loss: 0.298307, tar: 0.031860 
l0: 0.022060, l1: 0.023701, l2: 0.020653, l3: 0.020083, l4: 0.035783, l5: 0.033189, l6: 0.023109

[epoch:  63/100000, batch:   114/  187, ite: 5885] train loss: 0.298244, tar: 0.031855 
l0: 0.014423, l1: 0.017269, l2: 0.014387, l3: 0.014206, l4: 0.031674, l5: 0.026546, l6: 0.023707

[epoch:  63/100000, batch:   116/  187, ite: 5886] train loss: 0.298161, tar: 0.031846 
l0: 0.015170, l1: 0.015426, l2: 0.019668, l3: 0.019143, l4: 0.029278, l5: 0.028152, l6: 0.030322

[epoch:  63/100000, batch:   118/  187, ite: 5887] train loss: 0.298086, tar: 0.031837 
l0: 0.016830, l1: 0.016314, l2: 0.024620, l3: 0.022237, l4: 0.019373, l5: 0.022453, l6: 0.029584

[epoch:  63/100000, batch:   120/  187, ite: 5888] train loss: 0.298009, tar: 0.031829 
l0: 0.020309, l1: 0.018855, l2: 0.023562, l3: 0.028843, l4: 0.035574, l5: 0.037047, l6: 0.050584

[epoch:  63/100000, batch:   122/  187, ite: 5889] train loss: 0.297965, tar: 0.031823 
l0: 0.014437, l1: 0.011920, l2: 0.019772, l3: 0.025969, l4: 0.054568, l5: 0.065192, l6: 0.055995

[epoch:  63/100000, batch:   124/  187, ite: 5890] train loss: 0.297938, tar: 0.031814 
l0: 0.017742, l1: 0.018611, l2: 0.017386, l3: 0.015928, l4: 0.025542, l5: 0.027405, l6: 0.028616

[epoch:  63/100000, batch:   126/  187, ite: 5891] train loss: 0.297860, tar: 0.031806 
l0: 0.004610, l1: 0.004952, l2: 0.008069, l3: 0.007177, l4: 0.015350, l5: 0.015593, l6: 0.015839

[epoch:  63/100000, batch:   128/  187, ite: 5892] train loss: 0.297741, tar: 0.031792 
l0: 0.020078, l1: 0.023294, l2: 0.017856, l3: 0.021958, l4: 0.034260, l5: 0.028758, l6: 0.021835

[epoch:  63/100000, batch:   130/  187, ite: 5893] train loss: 0.297672, tar: 0.031786 
l0: 0.019590, l1: 0.019616, l2: 0.023646, l3: 0.022343, l4: 0.030488, l5: 0.037586, l6: 0.036732

[epoch:  63/100000, batch:   132/  187, ite: 5894] train loss: 0.297616, tar: 0.031779 
l0: 0.022328, l1: 0.021420, l2: 0.017940, l3: 0.024049, l4: 0.053954, l5: 0.046989, l6: 0.050791

[epoch:  63/100000, batch:   134/  187, ite: 5895] train loss: 0.297584, tar: 0.031774 
l0: 0.017271, l1: 0.017999, l2: 0.021054, l3: 0.020922, l4: 0.034284, l5: 0.029421, l6: 0.029493

[epoch:  63/100000, batch:   136/  187, ite: 5896] train loss: 0.297517, tar: 0.031767 
l0: 0.016799, l1: 0.023223, l2: 0.009248, l3: 0.009810, l4: 0.024150, l5: 0.022581, l6: 0.016268

[epoch:  63/100000, batch:   138/  187, ite: 5897] train loss: 0.297424, tar: 0.031759 
l0: 0.037573, l1: 0.035873, l2: 0.044573, l3: 0.048814, l4: 0.058116, l5: 0.051150, l6: 0.059782

[epoch:  63/100000, batch:   140/  187, ite: 5898] train loss: 0.297445, tar: 0.031762 
l0: 0.016081, l1: 0.013980, l2: 0.020438, l3: 0.024520, l4: 0.042202, l5: 0.048561, l6: 0.061143

[epoch:  63/100000, batch:   142/  187, ite: 5899] train loss: 0.297407, tar: 0.031754 
l0: 0.014078, l1: 0.014034, l2: 0.017831, l3: 0.021317, l4: 0.040021, l5: 0.040707, l6: 0.043072

[epoch:  63/100000, batch:   144/  187, ite: 5900] train loss: 0.297351, tar: 0.031744 
l0: 0.016594, l1: 0.019194, l2: 0.017592, l3: 0.018564, l4: 0.032969, l5: 0.031914, l6: 0.030009

[epoch:  63/100000, batch:   146/  187, ite: 5901] train loss: 0.297283, tar: 0.031736 
l0: 0.019362, l1: 0.021164, l2: 0.025160, l3: 0.023103, l4: 0.046520, l5: 0.038862, l6: 0.044723

[epoch:  63/100000, batch:   148/  187, ite: 5902] train loss: 0.297242, tar: 0.031730 
l0: 0.033164, l1: 0.037271, l2: 0.039985, l3: 0.034151, l4: 0.029395, l5: 0.030249, l6: 0.036215

[epoch:  63/100000, batch:   150/  187, ite: 5903] train loss: 0.297212, tar: 0.031731 
l0: 0.022521, l1: 0.022338, l2: 0.024307, l3: 0.027607, l4: 0.032048, l5: 0.031780, l6: 0.032401

[epoch:  63/100000, batch:   152/  187, ite: 5904] train loss: 0.297157, tar: 0.031726 
l0: 0.014687, l1: 0.014447, l2: 0.015882, l3: 0.019461, l4: 0.029899, l5: 0.027871, l6: 0.029104

[epoch:  63/100000, batch:   154/  187, ite: 5905] train loss: 0.297080, tar: 0.031717 
l0: 0.025884, l1: 0.028210, l2: 0.028757, l3: 0.030531, l4: 0.044620, l5: 0.043110, l6: 0.043878

[epoch:  63/100000, batch:   156/  187, ite: 5906] train loss: 0.297053, tar: 0.031714 
l0: 0.021404, l1: 0.020237, l2: 0.022486, l3: 0.025261, l4: 0.032867, l5: 0.036222, l6: 0.037639

[epoch:  63/100000, batch:   158/  187, ite: 5907] train loss: 0.297000, tar: 0.031708 
l0: 0.017574, l1: 0.017332, l2: 0.023630, l3: 0.025842, l4: 0.060986, l5: 0.049460, l6: 0.049362

[epoch:  63/100000, batch:   160/  187, ite: 5908] train loss: 0.296972, tar: 0.031701 
l0: 0.017725, l1: 0.021843, l2: 0.015832, l3: 0.013576, l4: 0.036417, l5: 0.039075, l6: 0.043224

[epoch:  63/100000, batch:   162/  187, ite: 5909] train loss: 0.296915, tar: 0.031694 
l0: 0.017465, l1: 0.017582, l2: 0.016502, l3: 0.017038, l4: 0.036034, l5: 0.030878, l6: 0.025629

[epoch:  63/100000, batch:   164/  187, ite: 5910] train loss: 0.296844, tar: 0.031686 
l0: 0.021274, l1: 0.025693, l2: 0.027600, l3: 0.027113, l4: 0.038381, l5: 0.037164, l6: 0.035306

[epoch:  63/100000, batch:   166/  187, ite: 5911] train loss: 0.296800, tar: 0.031681 
l0: 0.010548, l1: 0.011343, l2: 0.013220, l3: 0.016019, l4: 0.017958, l5: 0.021074, l6: 0.023507

[epoch:  63/100000, batch:   168/  187, ite: 5912] train loss: 0.296704, tar: 0.031670 
l0: 0.019397, l1: 0.020170, l2: 0.018357, l3: 0.019696, l4: 0.037359, l5: 0.044700, l6: 0.045328

[epoch:  63/100000, batch:   170/  187, ite: 5913] train loss: 0.296656, tar: 0.031663 
l0: 0.045762, l1: 0.048830, l2: 0.055571, l3: 0.050405, l4: 0.055040, l5: 0.045179, l6: 0.045819

[epoch:  63/100000, batch:   172/  187, ite: 5914] train loss: 0.296682, tar: 0.031671 
l0: 0.024818, l1: 0.025016, l2: 0.027005, l3: 0.027631, l4: 0.053057, l5: 0.050164, l6: 0.052496

[epoch:  63/100000, batch:   174/  187, ite: 5915] train loss: 0.296663, tar: 0.031667 
l0: 0.024699, l1: 0.026106, l2: 0.023696, l3: 0.031374, l4: 0.042607, l5: 0.042513, l6: 0.042084

[epoch:  63/100000, batch:   176/  187, ite: 5916] train loss: 0.296630, tar: 0.031664 
l0: 0.023003, l1: 0.023058, l2: 0.031466, l3: 0.031786, l4: 0.029270, l5: 0.033141, l6: 0.031001

[epoch:  63/100000, batch:   178/  187, ite: 5917] train loss: 0.296581, tar: 0.031659 
l0: 0.012362, l1: 0.012597, l2: 0.014530, l3: 0.019695, l4: 0.040597, l5: 0.035757, l6: 0.036226

[epoch:  63/100000, batch:   180/  187, ite: 5918] train loss: 0.296516, tar: 0.031649 
l0: 0.022881, l1: 0.021925, l2: 0.028171, l3: 0.033102, l4: 0.038511, l5: 0.035556, l6: 0.034773

[epoch:  63/100000, batch:   182/  187, ite: 5919] train loss: 0.296474, tar: 0.031644 
l0: 0.014149, l1: 0.014519, l2: 0.019042, l3: 0.020388, l4: 0.036271, l5: 0.030484, l6: 0.035361

[epoch:  63/100000, batch:   184/  187, ite: 5920] train loss: 0.296408, tar: 0.031635 
l0: 0.026303, l1: 0.025722, l2: 0.032507, l3: 0.037702, l4: 0.039854, l5: 0.039090, l6: 0.048974

[epoch:  63/100000, batch:   186/  187, ite: 5921] train loss: 0.296384, tar: 0.031633 
l0: 0.022803, l1: 0.022449, l2: 0.029616, l3: 0.030851, l4: 0.036792, l5: 0.034500, l6: 0.034695

[epoch:  63/100000, batch:   188/  187, ite: 5922] train loss: 0.296340, tar: 0.031628 
l0: 0.012707, l1: 0.013925, l2: 0.012488, l3: 0.012971, l4: 0.027573, l5: 0.033346, l6: 0.035119

[epoch:  64/100000, batch:     2/  187, ite: 5923] train loss: 0.296263, tar: 0.031618 
l0: 0.018718, l1: 0.020472, l2: 0.023745, l3: 0.024959, l4: 0.024128, l5: 0.021728, l6: 0.022402

[epoch:  64/100000, batch:     4/  187, ite: 5924] train loss: 0.296190, tar: 0.031611 
l0: 0.014818, l1: 0.013654, l2: 0.024111, l3: 0.024409, l4: 0.037663, l5: 0.033852, l6: 0.037013

[epoch:  64/100000, batch:     6/  187, ite: 5925] train loss: 0.296132, tar: 0.031603 
l0: 0.019122, l1: 0.019262, l2: 0.023975, l3: 0.024952, l4: 0.045437, l5: 0.037805, l6: 0.040441

[epoch:  64/100000, batch:     8/  187, ite: 5926] train loss: 0.296088, tar: 0.031596 
l0: 0.018621, l1: 0.026332, l2: 0.046679, l3: 0.026605, l4: 0.034525, l5: 0.032854, l6: 0.041613

[epoch:  64/100000, batch:    10/  187, ite: 5927] train loss: 0.296052, tar: 0.031589 
l0: 0.015943, l1: 0.015242, l2: 0.019047, l3: 0.022246, l4: 0.037245, l5: 0.039616, l6: 0.040022

[epoch:  64/100000, batch:    12/  187, ite: 5928] train loss: 0.295997, tar: 0.031581 
l0: 0.016871, l1: 0.016876, l2: 0.023449, l3: 0.023796, l4: 0.042974, l5: 0.041696, l6: 0.035061

[epoch:  64/100000, batch:    14/  187, ite: 5929] train loss: 0.295948, tar: 0.031574 
l0: 0.010577, l1: 0.011455, l2: 0.012929, l3: 0.013670, l4: 0.031703, l5: 0.027082, l6: 0.029315

[epoch:  64/100000, batch:    16/  187, ite: 5930] train loss: 0.295865, tar: 0.031563 
l0: 0.020642, l1: 0.020728, l2: 0.027959, l3: 0.028725, l4: 0.032805, l5: 0.032346, l6: 0.034787

[epoch:  64/100000, batch:    18/  187, ite: 5931] train loss: 0.295814, tar: 0.031557 
l0: 0.018841, l1: 0.021691, l2: 0.024767, l3: 0.020928, l4: 0.027412, l5: 0.029032, l6: 0.029936

[epoch:  64/100000, batch:    20/  187, ite: 5932] train loss: 0.295751, tar: 0.031551 
l0: 0.015405, l1: 0.016257, l2: 0.031091, l3: 0.024555, l4: 0.019444, l5: 0.024992, l6: 0.019408

[epoch:  64/100000, batch:    22/  187, ite: 5933] train loss: 0.295676, tar: 0.031542 
l0: 0.015590, l1: 0.014247, l2: 0.019752, l3: 0.022600, l4: 0.038758, l5: 0.034264, l6: 0.026527

[epoch:  64/100000, batch:    24/  187, ite: 5934] train loss: 0.295612, tar: 0.031534 
l0: 0.018719, l1: 0.020750, l2: 0.022284, l3: 0.021094, l4: 0.026938, l5: 0.027244, l6: 0.030850

[epoch:  64/100000, batch:    26/  187, ite: 5935] train loss: 0.295546, tar: 0.031527 
l0: 0.014062, l1: 0.017109, l2: 0.012116, l3: 0.013129, l4: 0.028969, l5: 0.026912, l6: 0.025685

[epoch:  64/100000, batch:    28/  187, ite: 5936] train loss: 0.295464, tar: 0.031518 
l0: 0.019172, l1: 0.018682, l2: 0.022295, l3: 0.024328, l4: 0.050501, l5: 0.052648, l6: 0.055849

[epoch:  64/100000, batch:    30/  187, ite: 5937] train loss: 0.295438, tar: 0.031512 
l0: 0.009379, l1: 0.009738, l2: 0.012088, l3: 0.012106, l4: 0.014178, l5: 0.012576, l6: 0.015034

[epoch:  64/100000, batch:    32/  187, ite: 5938] train loss: 0.295329, tar: 0.031501 
l0: 0.019732, l1: 0.018054, l2: 0.020300, l3: 0.028235, l4: 0.051940, l5: 0.058605, l6: 0.053012

[epoch:  64/100000, batch:    34/  187, ite: 5939] train loss: 0.295306, tar: 0.031494 
l0: 0.020916, l1: 0.013536, l2: 0.023085, l3: 0.036033, l4: 0.077820, l5: 0.093285, l6: 0.103020

[epoch:  64/100000, batch:    36/  187, ite: 5940] train loss: 0.295343, tar: 0.031489 
l0: 0.024465, l1: 0.023213, l2: 0.035410, l3: 0.030871, l4: 0.035406, l5: 0.032741, l6: 0.038226

[epoch:  64/100000, batch:    38/  187, ite: 5941] train loss: 0.295304, tar: 0.031485 
l0: 0.011258, l1: 0.011153, l2: 0.018440, l3: 0.017237, l4: 0.027537, l5: 0.025563, l6: 0.024898

[epoch:  64/100000, batch:    40/  187, ite: 5942] train loss: 0.295222, tar: 0.031475 
l0: 0.023211, l1: 0.021721, l2: 0.024957, l3: 0.028672, l4: 0.041802, l5: 0.039933, l6: 0.039520

[epoch:  64/100000, batch:    42/  187, ite: 5943] train loss: 0.295183, tar: 0.031471 
l0: 0.028125, l1: 0.027669, l2: 0.037909, l3: 0.042550, l4: 0.045193, l5: 0.051316, l6: 0.051743

[epoch:  64/100000, batch:    44/  187, ite: 5944] train loss: 0.295178, tar: 0.031469 
l0: 0.021273, l1: 0.024519, l2: 0.029105, l3: 0.024095, l4: 0.032960, l5: 0.032146, l6: 0.027762

[epoch:  64/100000, batch:    46/  187, ite: 5945] train loss: 0.295125, tar: 0.031464 
l0: 0.039250, l1: 0.037770, l2: 0.047580, l3: 0.050664, l4: 0.055501, l5: 0.053780, l6: 0.049332

[epoch:  64/100000, batch:    48/  187, ite: 5946] train loss: 0.295145, tar: 0.031468 
l0: 0.016490, l1: 0.016609, l2: 0.020050, l3: 0.021486, l4: 0.029900, l5: 0.035608, l6: 0.041123

[epoch:  64/100000, batch:    50/  187, ite: 5947] train loss: 0.295086, tar: 0.031460 
l0: 0.024048, l1: 0.025010, l2: 0.023428, l3: 0.022278, l4: 0.035047, l5: 0.039390, l6: 0.035875

[epoch:  64/100000, batch:    52/  187, ite: 5948] train loss: 0.295040, tar: 0.031456 
l0: 0.006965, l1: 0.007221, l2: 0.011123, l3: 0.013834, l4: 0.015669, l5: 0.016900, l6: 0.021738

[epoch:  64/100000, batch:    54/  187, ite: 5949] train loss: 0.294937, tar: 0.031444 
l0: 0.028165, l1: 0.032925, l2: 0.033489, l3: 0.028787, l4: 0.035847, l5: 0.035157, l6: 0.032750

[epoch:  64/100000, batch:    56/  187, ite: 5950] train loss: 0.294902, tar: 0.031442 
l0: 0.023024, l1: 0.022352, l2: 0.029106, l3: 0.039000, l4: 0.033840, l5: 0.028136, l6: 0.028632

[epoch:  64/100000, batch:    58/  187, ite: 5951] train loss: 0.294855, tar: 0.031438 
l0: 0.019683, l1: 0.021600, l2: 0.026700, l3: 0.022090, l4: 0.028747, l5: 0.030949, l6: 0.032554

[epoch:  64/100000, batch:    60/  187, ite: 5952] train loss: 0.294798, tar: 0.031432 
l0: 0.012305, l1: 0.014136, l2: 0.016713, l3: 0.015311, l4: 0.031932, l5: 0.024984, l6: 0.026832

[epoch:  64/100000, batch:    62/  187, ite: 5953] train loss: 0.294719, tar: 0.031422 
l0: 0.014986, l1: 0.016733, l2: 0.017278, l3: 0.015579, l4: 0.031165, l5: 0.036198, l6: 0.035693

[epoch:  64/100000, batch:    64/  187, ite: 5954] train loss: 0.294654, tar: 0.031413 
l0: 0.018526, l1: 0.020004, l2: 0.026648, l3: 0.023408, l4: 0.036417, l5: 0.033472, l6: 0.033616

[epoch:  64/100000, batch:    66/  187, ite: 5955] train loss: 0.294602, tar: 0.031407 
l0: 0.012098, l1: 0.011922, l2: 0.015426, l3: 0.014710, l4: 0.027655, l5: 0.032960, l6: 0.026711

[epoch:  64/100000, batch:    68/  187, ite: 5956] train loss: 0.294524, tar: 0.031397 
l0: 0.017087, l1: 0.018936, l2: 0.015894, l3: 0.016944, l4: 0.029094, l5: 0.028722, l6: 0.026813

[epoch:  64/100000, batch:    70/  187, ite: 5957] train loss: 0.294452, tar: 0.031390 
l0: 0.015128, l1: 0.016211, l2: 0.018454, l3: 0.018075, l4: 0.027870, l5: 0.028251, l6: 0.026922

[epoch:  64/100000, batch:    72/  187, ite: 5958] train loss: 0.294378, tar: 0.031381 
l0: 0.039715, l1: 0.035862, l2: 0.042200, l3: 0.051617, l4: 0.059936, l5: 0.061884, l6: 0.063156

[epoch:  64/100000, batch:    74/  187, ite: 5959] train loss: 0.294409, tar: 0.031386 
l0: 0.018824, l1: 0.020425, l2: 0.015727, l3: 0.015669, l4: 0.034985, l5: 0.034346, l6: 0.036294

[epoch:  64/100000, batch:    76/  187, ite: 5960] train loss: 0.294349, tar: 0.031379 
l0: 0.014251, l1: 0.014427, l2: 0.020873, l3: 0.023613, l4: 0.023282, l5: 0.029127, l6: 0.037315

[epoch:  64/100000, batch:    78/  187, ite: 5961] train loss: 0.294282, tar: 0.031371 
l0: 0.020129, l1: 0.024481, l2: 0.017785, l3: 0.014286, l4: 0.025144, l5: 0.027648, l6: 0.020329

[epoch:  64/100000, batch:    80/  187, ite: 5962] train loss: 0.294208, tar: 0.031365 
l0: 0.012665, l1: 0.012777, l2: 0.019997, l3: 0.025231, l4: 0.030653, l5: 0.032644, l6: 0.026954

[epoch:  64/100000, batch:    82/  187, ite: 5963] train loss: 0.294140, tar: 0.031355 
l0: 0.017330, l1: 0.017392, l2: 0.018530, l3: 0.020978, l4: 0.030173, l5: 0.032787, l6: 0.036066

[epoch:  64/100000, batch:    84/  187, ite: 5964] train loss: 0.294079, tar: 0.031348 
l0: 0.018707, l1: 0.021545, l2: 0.019793, l3: 0.017169, l4: 0.018319, l5: 0.022125, l6: 0.020150

[epoch:  64/100000, batch:    86/  187, ite: 5965] train loss: 0.293999, tar: 0.031342 
l0: 0.020559, l1: 0.021842, l2: 0.027338, l3: 0.023560, l4: 0.023399, l5: 0.022435, l6: 0.024138

[epoch:  64/100000, batch:    88/  187, ite: 5966] train loss: 0.293933, tar: 0.031336 
l0: 0.023934, l1: 0.027618, l2: 0.023310, l3: 0.024859, l4: 0.034302, l5: 0.031107, l6: 0.032269

[epoch:  64/100000, batch:    90/  187, ite: 5967] train loss: 0.293883, tar: 0.031332 
l0: 0.027235, l1: 0.031095, l2: 0.031655, l3: 0.027712, l4: 0.021913, l5: 0.021088, l6: 0.025082

[epoch:  64/100000, batch:    92/  187, ite: 5968] train loss: 0.293829, tar: 0.031330 
l0: 0.018435, l1: 0.019109, l2: 0.030623, l3: 0.031008, l4: 0.052899, l5: 0.045547, l6: 0.051624

[epoch:  64/100000, batch:    94/  187, ite: 5969] train loss: 0.293806, tar: 0.031324 
l0: 0.047174, l1: 0.057102, l2: 0.034615, l3: 0.037313, l4: 0.026406, l5: 0.033790, l6: 0.049214

[epoch:  64/100000, batch:    96/  187, ite: 5970] train loss: 0.293802, tar: 0.031332 
l0: 0.016749, l1: 0.017033, l2: 0.022721, l3: 0.019560, l4: 0.042764, l5: 0.036810, l6: 0.041047

[epoch:  64/100000, batch:    98/  187, ite: 5971] train loss: 0.293752, tar: 0.031324 
l0: 0.021241, l1: 0.023170, l2: 0.017601, l3: 0.020501, l4: 0.037735, l5: 0.038187, l6: 0.042969

[epoch:  64/100000, batch:   100/  187, ite: 5972] train loss: 0.293706, tar: 0.031319 
l0: 0.023584, l1: 0.022928, l2: 0.030059, l3: 0.034262, l4: 0.033756, l5: 0.028210, l6: 0.029084

[epoch:  64/100000, batch:   102/  187, ite: 5973] train loss: 0.293659, tar: 0.031315 
l0: 0.018193, l1: 0.019547, l2: 0.029248, l3: 0.022618, l4: 0.035318, l5: 0.036321, l6: 0.040594

[epoch:  64/100000, batch:   104/  187, ite: 5974] train loss: 0.293613, tar: 0.031309 
l0: 0.014707, l1: 0.015221, l2: 0.015972, l3: 0.013914, l4: 0.021861, l5: 0.017845, l6: 0.032929

[epoch:  64/100000, batch:   106/  187, ite: 5975] train loss: 0.293531, tar: 0.031300 
l0: 0.017622, l1: 0.020442, l2: 0.014350, l3: 0.015120, l4: 0.027690, l5: 0.024444, l6: 0.023624

[epoch:  64/100000, batch:   108/  187, ite: 5976] train loss: 0.293455, tar: 0.031293 
l0: 0.015047, l1: 0.014697, l2: 0.019780, l3: 0.024390, l4: 0.027838, l5: 0.024186, l6: 0.031679

[epoch:  64/100000, batch:   110/  187, ite: 5977] train loss: 0.293386, tar: 0.031285 
l0: 0.017539, l1: 0.018975, l2: 0.020270, l3: 0.022637, l4: 0.021763, l5: 0.023073, l6: 0.024800

[epoch:  64/100000, batch:   112/  187, ite: 5978] train loss: 0.293313, tar: 0.031278 
l0: 0.037025, l1: 0.035125, l2: 0.047530, l3: 0.050410, l4: 0.073833, l5: 0.074407, l6: 0.073408

[epoch:  64/100000, batch:   114/  187, ite: 5979] train loss: 0.293363, tar: 0.031281 
l0: 0.020601, l1: 0.019784, l2: 0.027169, l3: 0.028572, l4: 0.045820, l5: 0.043710, l6: 0.031956

[epoch:  64/100000, batch:   116/  187, ite: 5980] train loss: 0.293325, tar: 0.031276 
l0: 0.068934, l1: 0.073482, l2: 0.068612, l3: 0.054874, l4: 0.066524, l5: 0.065691, l6: 0.066652

[epoch:  64/100000, batch:   118/  187, ite: 5981] train loss: 0.293411, tar: 0.031295 
l0: 0.020955, l1: 0.020787, l2: 0.023525, l3: 0.023898, l4: 0.043693, l5: 0.040411, l6: 0.036662

[epoch:  64/100000, batch:   120/  187, ite: 5982] train loss: 0.293369, tar: 0.031290 
l0: 0.015924, l1: 0.017370, l2: 0.018268, l3: 0.019225, l4: 0.033654, l5: 0.034633, l6: 0.029542

[epoch:  64/100000, batch:   122/  187, ite: 5983] train loss: 0.293306, tar: 0.031282 
l0: 0.029995, l1: 0.033876, l2: 0.037023, l3: 0.036209, l4: 0.028244, l5: 0.028192, l6: 0.022258

[epoch:  64/100000, batch:   124/  187, ite: 5984] train loss: 0.293267, tar: 0.031281 
l0: 0.024269, l1: 0.024661, l2: 0.024151, l3: 0.022231, l4: 0.037083, l5: 0.050097, l6: 0.067185

[epoch:  64/100000, batch:   126/  187, ite: 5985] train loss: 0.293245, tar: 0.031278 
l0: 0.036405, l1: 0.036279, l2: 0.046177, l3: 0.045085, l4: 0.042628, l5: 0.039146, l6: 0.053192

[epoch:  64/100000, batch:   128/  187, ite: 5986] train loss: 0.293248, tar: 0.031280 
l0: 0.036126, l1: 0.043219, l2: 0.041399, l3: 0.037594, l4: 0.055783, l5: 0.045249, l6: 0.050479

[epoch:  64/100000, batch:   130/  187, ite: 5987] train loss: 0.293256, tar: 0.031283 
l0: 0.020758, l1: 0.023849, l2: 0.016520, l3: 0.016713, l4: 0.033096, l5: 0.038166, l6: 0.033021

[epoch:  64/100000, batch:   132/  187, ite: 5988] train loss: 0.293201, tar: 0.031277 
l0: 0.013145, l1: 0.013019, l2: 0.016584, l3: 0.018438, l4: 0.032306, l5: 0.030985, l6: 0.022071

[epoch:  64/100000, batch:   134/  187, ite: 5989] train loss: 0.293127, tar: 0.031268 
l0: 0.014090, l1: 0.015366, l2: 0.018297, l3: 0.024088, l4: 0.036385, l5: 0.041836, l6: 0.036385

[epoch:  64/100000, batch:   136/  187, ite: 5990] train loss: 0.293073, tar: 0.031260 
l0: 0.018670, l1: 0.017436, l2: 0.020147, l3: 0.020729, l4: 0.028825, l5: 0.034417, l6: 0.039648

[epoch:  64/100000, batch:   138/  187, ite: 5991] train loss: 0.293016, tar: 0.031253 
l0: 0.021691, l1: 0.021479, l2: 0.024418, l3: 0.024321, l4: 0.032722, l5: 0.038058, l6: 0.038530

[epoch:  64/100000, batch:   140/  187, ite: 5992] train loss: 0.292970, tar: 0.031248 
l0: 0.019555, l1: 0.017123, l2: 0.029077, l3: 0.030359, l4: 0.043859, l5: 0.042310, l6: 0.039114

[epoch:  64/100000, batch:   142/  187, ite: 5993] train loss: 0.292934, tar: 0.031243 
l0: 0.014996, l1: 0.015152, l2: 0.022560, l3: 0.020638, l4: 0.027776, l5: 0.029884, l6: 0.027780

[epoch:  64/100000, batch:   144/  187, ite: 5994] train loss: 0.292867, tar: 0.031234 
l0: 0.021447, l1: 0.023560, l2: 0.025068, l3: 0.024363, l4: 0.053140, l5: 0.056144, l6: 0.048568

[epoch:  64/100000, batch:   146/  187, ite: 5995] train loss: 0.292847, tar: 0.031230 
l0: 0.013251, l1: 0.014755, l2: 0.017929, l3: 0.016810, l4: 0.033993, l5: 0.035607, l6: 0.036586

[epoch:  64/100000, batch:   148/  187, ite: 5996] train loss: 0.292785, tar: 0.031221 
l0: 0.038846, l1: 0.036927, l2: 0.064162, l3: 0.059945, l4: 0.047829, l5: 0.036660, l6: 0.038026

[epoch:  64/100000, batch:   150/  187, ite: 5997] train loss: 0.292799, tar: 0.031224 
l0: 0.025943, l1: 0.023742, l2: 0.024248, l3: 0.032420, l4: 0.036254, l5: 0.036794, l6: 0.047655

[epoch:  64/100000, batch:   152/  187, ite: 5998] train loss: 0.292767, tar: 0.031222 
l0: 0.028238, l1: 0.029630, l2: 0.034545, l3: 0.029105, l4: 0.029882, l5: 0.027953, l6: 0.045936

[epoch:  64/100000, batch:   154/  187, ite: 5999] train loss: 0.292733, tar: 0.031220 
l0: 0.025475, l1: 0.022000, l2: 0.043092, l3: 0.051462, l4: 0.054919, l5: 0.053591, l6: 0.052686

[epoch:  64/100000, batch:   156/  187, ite: 6000] train loss: 0.292738, tar: 0.031217 
l0: 0.025094, l1: 0.030368, l2: 0.024740, l3: 0.024933, l4: 0.040736, l5: 0.035130, l6: 0.037526

[epoch:  64/100000, batch:   158/  187, ite: 6001] train loss: 0.218527, tar: 0.025094 
l0: 0.031610, l1: 0.031063, l2: 0.023110, l3: 0.027580, l4: 0.043310, l5: 0.050796, l6: 0.076071

[epoch:  64/100000, batch:   160/  187, ite: 6002] train loss: 0.251032, tar: 0.028352 
l0: 0.026515, l1: 0.028486, l2: 0.025772, l3: 0.030494, l4: 0.034878, l5: 0.030545, l6: 0.022876

[epoch:  64/100000, batch:   162/  187, ite: 6003] train loss: 0.233877, tar: 0.027740 
l0: 0.020425, l1: 0.018398, l2: 0.023420, l3: 0.032537, l4: 0.067973, l5: 0.065181, l6: 0.038692

[epoch:  64/100000, batch:   164/  187, ite: 6004] train loss: 0.242064, tar: 0.025911 
l0: 0.018539, l1: 0.017880, l2: 0.023328, l3: 0.027491, l4: 0.034408, l5: 0.030058, l6: 0.029489

[epoch:  64/100000, batch:   166/  187, ite: 6005] train loss: 0.229890, tar: 0.024437 
l0: 0.015519, l1: 0.015288, l2: 0.018396, l3: 0.022387, l4: 0.035473, l5: 0.037422, l6: 0.038278

[epoch:  64/100000, batch:   168/  187, ite: 6006] train loss: 0.222035, tar: 0.022951 
l0: 0.021050, l1: 0.021257, l2: 0.028064, l3: 0.027815, l4: 0.052353, l5: 0.049643, l6: 0.047385

[epoch:  64/100000, batch:   170/  187, ite: 6007] train loss: 0.225683, tar: 0.022679 
l0: 0.018547, l1: 0.018735, l2: 0.023499, l3: 0.025733, l4: 0.040556, l5: 0.037513, l6: 0.030953

[epoch:  64/100000, batch:   172/  187, ite: 6008] train loss: 0.221914, tar: 0.022162 
l0: 0.024791, l1: 0.025086, l2: 0.023726, l3: 0.025097, l4: 0.035728, l5: 0.039238, l6: 0.040615

[epoch:  64/100000, batch:   174/  187, ite: 6009] train loss: 0.221066, tar: 0.022455 
l0: 0.017029, l1: 0.017142, l2: 0.017413, l3: 0.021828, l4: 0.031114, l5: 0.030974, l6: 0.028563

[epoch:  64/100000, batch:   176/  187, ite: 6010] train loss: 0.215366, tar: 0.021912 
l0: 0.023237, l1: 0.020764, l2: 0.029138, l3: 0.028387, l4: 0.041669, l5: 0.049712, l6: 0.058924

[epoch:  64/100000, batch:   178/  187, ite: 6011] train loss: 0.218681, tar: 0.022032 
l0: 0.028842, l1: 0.028374, l2: 0.028823, l3: 0.031700, l4: 0.044308, l5: 0.042812, l6: 0.036862

[epoch:  64/100000, batch:   180/  187, ite: 6012] train loss: 0.220601, tar: 0.022600 
l0: 0.022309, l1: 0.024811, l2: 0.020836, l3: 0.022013, l4: 0.041635, l5: 0.035067, l6: 0.026463

[epoch:  64/100000, batch:   182/  187, ite: 6013] train loss: 0.218488, tar: 0.022578 
l0: 0.031772, l1: 0.031776, l2: 0.037129, l3: 0.040833, l4: 0.053251, l5: 0.048117, l6: 0.044307

[epoch:  64/100000, batch:   184/  187, ite: 6014] train loss: 0.223395, tar: 0.023234 
l0: 0.031800, l1: 0.028279, l2: 0.037837, l3: 0.039759, l4: 0.030738, l5: 0.046070, l6: 0.059832

[epoch:  64/100000, batch:   186/  187, ite: 6015] train loss: 0.226790, tar: 0.023805 
l0: 0.024517, l1: 0.023396, l2: 0.022932, l3: 0.021149, l4: 0.035259, l5: 0.049262, l6: 0.063184

[epoch:  64/100000, batch:   188/  187, ite: 6016] train loss: 0.227597, tar: 0.023850 
l0: 0.025237, l1: 0.029059, l2: 0.030728, l3: 0.027905, l4: 0.031107, l5: 0.023058, l6: 0.025272

[epoch:  65/100000, batch:     2/  187, ite: 6017] train loss: 0.225524, tar: 0.023931 
l0: 0.021454, l1: 0.023896, l2: 0.025886, l3: 0.025031, l4: 0.034287, l5: 0.029684, l6: 0.027780

[epoch:  65/100000, batch:     4/  187, ite: 6018] train loss: 0.223440, tar: 0.023794 
l0: 0.025019, l1: 0.022935, l2: 0.029108, l3: 0.032023, l4: 0.050836, l5: 0.055826, l6: 0.065602

[epoch:  65/100000, batch:     6/  187, ite: 6019] train loss: 0.226488, tar: 0.023858 
l0: 0.022222, l1: 0.021824, l2: 0.029766, l3: 0.033726, l4: 0.044170, l5: 0.035583, l6: 0.032112

[epoch:  65/100000, batch:     8/  187, ite: 6020] train loss: 0.226134, tar: 0.023776 
l0: 0.017692, l1: 0.017437, l2: 0.025581, l3: 0.028300, l4: 0.027973, l5: 0.024569, l6: 0.025702

[epoch:  65/100000, batch:    10/  187, ite: 6021] train loss: 0.223330, tar: 0.023487 
l0: 0.020351, l1: 0.021110, l2: 0.027106, l3: 0.025791, l4: 0.029286, l5: 0.034652, l6: 0.036797

[epoch:  65/100000, batch:    12/  187, ite: 6022] train loss: 0.222047, tar: 0.023344 
l0: 0.018653, l1: 0.018110, l2: 0.025457, l3: 0.024914, l4: 0.022777, l5: 0.029554, l6: 0.040572

[epoch:  65/100000, batch:    14/  187, ite: 6023] train loss: 0.220220, tar: 0.023140 
l0: 0.026709, l1: 0.025497, l2: 0.024079, l3: 0.024819, l4: 0.036011, l5: 0.044094, l6: 0.062381

[epoch:  65/100000, batch:    16/  187, ite: 6024] train loss: 0.221194, tar: 0.023289 
l0: 0.016954, l1: 0.016915, l2: 0.019623, l3: 0.021392, l4: 0.039829, l5: 0.036032, l6: 0.039571

[epoch:  65/100000, batch:    18/  187, ite: 6025] train loss: 0.219959, tar: 0.023036 
l0: 0.016274, l1: 0.019806, l2: 0.019341, l3: 0.015888, l4: 0.022281, l5: 0.019140, l6: 0.022704

[epoch:  65/100000, batch:    20/  187, ite: 6026] train loss: 0.216708, tar: 0.022775 
l0: 0.019587, l1: 0.022665, l2: 0.023648, l3: 0.023576, l4: 0.023870, l5: 0.025243, l6: 0.025823

[epoch:  65/100000, batch:    22/  187, ite: 6027] train loss: 0.214771, tar: 0.022657 
l0: 0.017805, l1: 0.017231, l2: 0.015720, l3: 0.015707, l4: 0.019760, l5: 0.024406, l6: 0.043201

[epoch:  65/100000, batch:    24/  187, ite: 6028] train loss: 0.212595, tar: 0.022484 
l0: 0.019852, l1: 0.018816, l2: 0.033356, l3: 0.033950, l4: 0.037393, l5: 0.035804, l6: 0.044534

[epoch:  65/100000, batch:    26/  187, ite: 6029] train loss: 0.212978, tar: 0.022393 
l0: 0.013014, l1: 0.013260, l2: 0.014098, l3: 0.012903, l4: 0.026279, l5: 0.030542, l6: 0.023634

[epoch:  65/100000, batch:    28/  187, ite: 6030] train loss: 0.210336, tar: 0.022081 
l0: 0.019795, l1: 0.018685, l2: 0.021602, l3: 0.021295, l4: 0.038602, l5: 0.040469, l6: 0.054062

[epoch:  65/100000, batch:    30/  187, ite: 6031] train loss: 0.210471, tar: 0.022007 
l0: 0.016884, l1: 0.015906, l2: 0.018459, l3: 0.018133, l4: 0.032022, l5: 0.036732, l6: 0.039814

[epoch:  65/100000, batch:    32/  187, ite: 6032] train loss: 0.209455, tar: 0.021847 
l0: 0.038721, l1: 0.035356, l2: 0.050429, l3: 0.057246, l4: 0.096125, l5: 0.088459, l6: 0.074324

[epoch:  65/100000, batch:    34/  187, ite: 6033] train loss: 0.216461, tar: 0.022358 
l0: 0.016369, l1: 0.018572, l2: 0.018998, l3: 0.018057, l4: 0.016629, l5: 0.016375, l6: 0.014825

[epoch:  65/100000, batch:    36/  187, ite: 6034] train loss: 0.213619, tar: 0.022182 
l0: 0.021138, l1: 0.025411, l2: 0.023205, l3: 0.019447, l4: 0.023081, l5: 0.016603, l6: 0.020657

[epoch:  65/100000, batch:    38/  187, ite: 6035] train loss: 0.211788, tar: 0.022152 
l0: 0.010419, l1: 0.010760, l2: 0.012865, l3: 0.014980, l4: 0.028671, l5: 0.026800, l6: 0.024051

[epoch:  65/100000, batch:    40/  187, ite: 6036] train loss: 0.209476, tar: 0.021826 
l0: 0.018199, l1: 0.019912, l2: 0.022145, l3: 0.021429, l4: 0.031760, l5: 0.028490, l6: 0.024083

[epoch:  65/100000, batch:    42/  187, ite: 6037] train loss: 0.208301, tar: 0.021728 
l0: 0.012086, l1: 0.014787, l2: 0.011369, l3: 0.010185, l4: 0.025605, l5: 0.019799, l6: 0.032419

[epoch:  65/100000, batch:    44/  187, ite: 6038] train loss: 0.206142, tar: 0.021475 
l0: 0.020030, l1: 0.019735, l2: 0.027266, l3: 0.026428, l4: 0.033204, l5: 0.032015, l6: 0.028842

[epoch:  65/100000, batch:    46/  187, ite: 6039] train loss: 0.205664, tar: 0.021437 
l0: 0.011786, l1: 0.011731, l2: 0.015690, l3: 0.017181, l4: 0.031736, l5: 0.036158, l6: 0.030389

[epoch:  65/100000, batch:    48/  187, ite: 6040] train loss: 0.204389, tar: 0.021196 
l0: 0.040693, l1: 0.039356, l2: 0.037730, l3: 0.044331, l4: 0.064057, l5: 0.061582, l6: 0.064323

[epoch:  65/100000, batch:    50/  187, ite: 6041] train loss: 0.207991, tar: 0.021672 
l0: 0.022182, l1: 0.023522, l2: 0.019011, l3: 0.018813, l4: 0.026677, l5: 0.026120, l6: 0.027440

[epoch:  65/100000, batch:    52/  187, ite: 6042] train loss: 0.206938, tar: 0.021684 
l0: 0.019137, l1: 0.020199, l2: 0.022617, l3: 0.022958, l4: 0.054086, l5: 0.060101, l6: 0.035445

[epoch:  65/100000, batch:    54/  187, ite: 6043] train loss: 0.207580, tar: 0.021625 
l0: 0.013757, l1: 0.014371, l2: 0.016461, l3: 0.016062, l4: 0.022762, l5: 0.024000, l6: 0.028312

[epoch:  65/100000, batch:    56/  187, ite: 6044] train loss: 0.205947, tar: 0.021446 
l0: 0.012230, l1: 0.012157, l2: 0.015594, l3: 0.017432, l4: 0.026206, l5: 0.020788, l6: 0.025122

[epoch:  65/100000, batch:    58/  187, ite: 6045] train loss: 0.204249, tar: 0.021241 
l0: 0.010220, l1: 0.011086, l2: 0.011891, l3: 0.014978, l4: 0.046389, l5: 0.036532, l6: 0.029759

[epoch:  65/100000, batch:    60/  187, ite: 6046] train loss: 0.203306, tar: 0.021001 
l0: 0.013715, l1: 0.013974, l2: 0.015590, l3: 0.017115, l4: 0.024470, l5: 0.028300, l6: 0.031034

[epoch:  65/100000, batch:    62/  187, ite: 6047] train loss: 0.202048, tar: 0.020846 
l0: 0.013159, l1: 0.013786, l2: 0.014889, l3: 0.016262, l4: 0.019492, l5: 0.023258, l6: 0.035168

[epoch:  65/100000, batch:    64/  187, ite: 6048] train loss: 0.200672, tar: 0.020686 
l0: 0.013719, l1: 0.012752, l2: 0.020985, l3: 0.026314, l4: 0.043660, l5: 0.039289, l6: 0.039121

[epoch:  65/100000, batch:    66/  187, ite: 6049] train loss: 0.200574, tar: 0.020544 
l0: 0.009912, l1: 0.010840, l2: 0.014029, l3: 0.014265, l4: 0.025521, l5: 0.021491, l6: 0.020709

[epoch:  65/100000, batch:    68/  187, ite: 6050] train loss: 0.198898, tar: 0.020331 
l0: 0.015769, l1: 0.012997, l2: 0.020506, l3: 0.028765, l4: 0.062761, l5: 0.080685, l6: 0.045005

[epoch:  65/100000, batch:    70/  187, ite: 6051] train loss: 0.200223, tar: 0.020242 
l0: 0.080372, l1: 0.072312, l2: 0.083290, l3: 0.090471, l4: 0.133050, l5: 0.150696, l6: 0.184630

[epoch:  65/100000, batch:    72/  187, ite: 6052] train loss: 0.211658, tar: 0.021398 
l0: 0.021346, l1: 0.020238, l2: 0.024715, l3: 0.026243, l4: 0.060483, l5: 0.054318, l6: 0.067696

[epoch:  65/100000, batch:    74/  187, ite: 6053] train loss: 0.212853, tar: 0.021397 
l0: 0.018275, l1: 0.020429, l2: 0.022636, l3: 0.021499, l4: 0.036198, l5: 0.031376, l6: 0.026353

[epoch:  65/100000, batch:    76/  187, ite: 6054] train loss: 0.212185, tar: 0.021340 
l0: 0.030402, l1: 0.025813, l2: 0.044162, l3: 0.041350, l4: 0.057519, l5: 0.062486, l6: 0.063104

[epoch:  65/100000, batch:    78/  187, ite: 6055] train loss: 0.214233, tar: 0.021504 
l0: 0.015806, l1: 0.015306, l2: 0.018021, l3: 0.018738, l4: 0.027291, l5: 0.029958, l6: 0.025402

[epoch:  65/100000, batch:    80/  187, ite: 6056] train loss: 0.213096, tar: 0.021403 
l0: 0.010912, l1: 0.012683, l2: 0.013014, l3: 0.013501, l4: 0.018032, l5: 0.017939, l6: 0.028653

[epoch:  65/100000, batch:    82/  187, ite: 6057] train loss: 0.211370, tar: 0.021219 
l0: 0.023108, l1: 0.022883, l2: 0.024737, l3: 0.028356, l4: 0.067188, l5: 0.063748, l6: 0.071566

[epoch:  65/100000, batch:    84/  187, ite: 6058] train loss: 0.212925, tar: 0.021251 
l0: 0.015584, l1: 0.016894, l2: 0.031802, l3: 0.026033, l4: 0.029246, l5: 0.036934, l6: 0.034057

[epoch:  65/100000, batch:    86/  187, ite: 6059] train loss: 0.212546, tar: 0.021155 
l0: 0.017728, l1: 0.020405, l2: 0.024019, l3: 0.028648, l4: 0.035290, l5: 0.033542, l6: 0.035233

[epoch:  65/100000, batch:    88/  187, ite: 6060] train loss: 0.212252, tar: 0.021098 
l0: 0.025395, l1: 0.026329, l2: 0.038039, l3: 0.051901, l4: 0.028629, l5: 0.033505, l6: 0.034098

[epoch:  65/100000, batch:    90/  187, ite: 6061] train loss: 0.212672, tar: 0.021168 
l0: 0.021130, l1: 0.025186, l2: 0.023651, l3: 0.023052, l4: 0.027561, l5: 0.026818, l6: 0.025378

[epoch:  65/100000, batch:    92/  187, ite: 6062] train loss: 0.212028, tar: 0.021168 
l0: 0.033188, l1: 0.038273, l2: 0.036923, l3: 0.025844, l4: 0.031886, l5: 0.031923, l6: 0.038105

[epoch:  65/100000, batch:    94/  187, ite: 6063] train loss: 0.212411, tar: 0.021359 
l0: 0.238247, l1: 0.259439, l2: 0.260559, l3: 0.208747, l4: 0.192956, l5: 0.148871, l6: 0.183867

[epoch:  65/100000, batch:    96/  187, ite: 6064] train loss: 0.232416, tar: 0.024747 
l0: 0.018689, l1: 0.020346, l2: 0.022008, l3: 0.022163, l4: 0.030059, l5: 0.027403, l6: 0.031499

[epoch:  65/100000, batch:    98/  187, ite: 6065] train loss: 0.231489, tar: 0.024654 
l0: 0.022022, l1: 0.022421, l2: 0.025212, l3: 0.030436, l4: 0.044161, l5: 0.040988, l6: 0.040002

[epoch:  65/100000, batch:   100/  187, ite: 6066] train loss: 0.231394, tar: 0.024614 
l0: 0.074767, l1: 0.076517, l2: 0.059493, l3: 0.065959, l4: 0.072958, l5: 0.087169, l6: 0.091185

[epoch:  65/100000, batch:   102/  187, ite: 6067] train loss: 0.235822, tar: 0.025363 
l0: 0.026646, l1: 0.042330, l2: 0.030095, l3: 0.029005, l4: 0.037753, l5: 0.040920, l6: 0.047927

[epoch:  65/100000, batch:   104/  187, ite: 6068] train loss: 0.236099, tar: 0.025382 
l0: 0.027163, l1: 0.030573, l2: 0.029645, l3: 0.029173, l4: 0.045196, l5: 0.042516, l6: 0.038320

[epoch:  65/100000, batch:   106/  187, ite: 6069] train loss: 0.236193, tar: 0.025408 
l0: 0.026923, l1: 0.027891, l2: 0.035321, l3: 0.036925, l4: 0.044297, l5: 0.039334, l6: 0.045565

[epoch:  65/100000, batch:   108/  187, ite: 6070] train loss: 0.236480, tar: 0.025429 
l0: 0.017725, l1: 0.016871, l2: 0.023581, l3: 0.030417, l4: 0.048101, l5: 0.049461, l6: 0.048725

[epoch:  65/100000, batch:   110/  187, ite: 6071] train loss: 0.236457, tar: 0.025321 
l0: 0.041547, l1: 0.045300, l2: 0.042927, l3: 0.039263, l4: 0.065009, l5: 0.064274, l6: 0.065729

[epoch:  65/100000, batch:   112/  187, ite: 6072] train loss: 0.238229, tar: 0.025546 
l0: 0.023319, l1: 0.023962, l2: 0.027592, l3: 0.029255, l4: 0.033472, l5: 0.031938, l6: 0.026170

[epoch:  65/100000, batch:   114/  187, ite: 6073] train loss: 0.237647, tar: 0.025516 
l0: 0.032795, l1: 0.031189, l2: 0.040865, l3: 0.049494, l4: 0.061999, l5: 0.073815, l6: 0.070416

[epoch:  65/100000, batch:   116/  187, ite: 6074] train loss: 0.239308, tar: 0.025614 
l0: 0.022300, l1: 0.021612, l2: 0.030225, l3: 0.032882, l4: 0.042602, l5: 0.047657, l6: 0.043392

[epoch:  65/100000, batch:   118/  187, ite: 6075] train loss: 0.239326, tar: 0.025570 
l0: 0.026775, l1: 0.025217, l2: 0.026938, l3: 0.027859, l4: 0.041070, l5: 0.049500, l6: 0.063689

[epoch:  65/100000, batch:   120/  187, ite: 6076] train loss: 0.239612, tar: 0.025586 
l0: 0.035474, l1: 0.038808, l2: 0.035028, l3: 0.037822, l4: 0.040048, l5: 0.046045, l6: 0.054061

[epoch:  65/100000, batch:   122/  187, ite: 6077] train loss: 0.240231, tar: 0.025714 
l0: 0.068224, l1: 0.081858, l2: 0.081782, l3: 0.062601, l4: 0.037719, l5: 0.042094, l6: 0.047137

[epoch:  65/100000, batch:   124/  187, ite: 6078] train loss: 0.242554, tar: 0.026259 
l0: 0.025618, l1: 0.026085, l2: 0.027058, l3: 0.029384, l4: 0.036861, l5: 0.035384, l6: 0.044810

[epoch:  65/100000, batch:   126/  187, ite: 6079] train loss: 0.242334, tar: 0.026251 
l0: 0.025166, l1: 0.026860, l2: 0.034095, l3: 0.033563, l4: 0.024904, l5: 0.027055, l6: 0.028901

[epoch:  65/100000, batch:   128/  187, ite: 6080] train loss: 0.241812, tar: 0.026237 
l0: 0.048048, l1: 0.041449, l2: 0.084872, l3: 0.084894, l4: 0.101002, l5: 0.100588, l6: 0.088642

[epoch:  65/100000, batch:   130/  187, ite: 6081] train loss: 0.245610, tar: 0.026507 
l0: 0.029043, l1: 0.031777, l2: 0.029859, l3: 0.027999, l4: 0.037903, l5: 0.040795, l6: 0.029970

[epoch:  65/100000, batch:   132/  187, ite: 6082] train loss: 0.245388, tar: 0.026538 
l0: 0.023881, l1: 0.026503, l2: 0.020492, l3: 0.024202, l4: 0.034114, l5: 0.033047, l6: 0.027861

[epoch:  65/100000, batch:   134/  187, ite: 6083] train loss: 0.244722, tar: 0.026506 
l0: 0.023316, l1: 0.025660, l2: 0.022505, l3: 0.023778, l4: 0.030910, l5: 0.034122, l6: 0.039006

[epoch:  65/100000, batch:   136/  187, ite: 6084] train loss: 0.244181, tar: 0.026468 
l0: 0.027849, l1: 0.031514, l2: 0.027141, l3: 0.028025, l4: 0.056007, l5: 0.050328, l6: 0.042771

[epoch:  65/100000, batch:   138/  187, ite: 6085] train loss: 0.244410, tar: 0.026484 
l0: 0.031427, l1: 0.036822, l2: 0.032238, l3: 0.032190, l4: 0.033899, l5: 0.029362, l6: 0.022878

[epoch:  65/100000, batch:   140/  187, ite: 6086] train loss: 0.244112, tar: 0.026541 
l0: 0.029532, l1: 0.031678, l2: 0.038867, l3: 0.034796, l4: 0.037137, l5: 0.031901, l6: 0.032216

[epoch:  65/100000, batch:   142/  187, ite: 6087] train loss: 0.244020, tar: 0.026576 
l0: 0.027318, l1: 0.029065, l2: 0.032150, l3: 0.029200, l4: 0.036186, l5: 0.038683, l6: 0.040630

[epoch:  65/100000, batch:   144/  187, ite: 6088] train loss: 0.243898, tar: 0.026584 
l0: 0.017426, l1: 0.020343, l2: 0.017586, l3: 0.018044, l4: 0.046155, l5: 0.038360, l6: 0.030304

[epoch:  65/100000, batch:   146/  187, ite: 6089] train loss: 0.243272, tar: 0.026481 
l0: 0.036561, l1: 0.037943, l2: 0.046285, l3: 0.050854, l4: 0.055479, l5: 0.043070, l6: 0.038993

[epoch:  65/100000, batch:   148/  187, ite: 6090] train loss: 0.244004, tar: 0.026593 
l0: 0.046640, l1: 0.048711, l2: 0.053559, l3: 0.042834, l4: 0.046676, l5: 0.054908, l6: 0.049248

[epoch:  65/100000, batch:   150/  187, ite: 6091] train loss: 0.245088, tar: 0.026814 
l0: 0.015627, l1: 0.015871, l2: 0.018357, l3: 0.018415, l4: 0.026541, l5: 0.031567, l6: 0.023820

[epoch:  65/100000, batch:   152/  187, ite: 6092] train loss: 0.244056, tar: 0.026692 
l0: 0.036651, l1: 0.042145, l2: 0.050639, l3: 0.055039, l4: 0.052612, l5: 0.037425, l6: 0.031717

[epoch:  65/100000, batch:   154/  187, ite: 6093] train loss: 0.244725, tar: 0.026799 
l0: 0.020171, l1: 0.021514, l2: 0.020842, l3: 0.022441, l4: 0.039620, l5: 0.042338, l6: 0.030885

[epoch:  65/100000, batch:   156/  187, ite: 6094] train loss: 0.244226, tar: 0.026728 
l0: 0.016032, l1: 0.015945, l2: 0.017849, l3: 0.018558, l4: 0.027100, l5: 0.027600, l6: 0.034318

[epoch:  65/100000, batch:   158/  187, ite: 6095] train loss: 0.243312, tar: 0.026616 
l0: 0.034310, l1: 0.035910, l2: 0.043296, l3: 0.041794, l4: 0.041785, l5: 0.040956, l6: 0.036950

[epoch:  65/100000, batch:   160/  187, ite: 6096] train loss: 0.243642, tar: 0.026696 
l0: 0.022838, l1: 0.022070, l2: 0.028586, l3: 0.029590, l4: 0.045443, l5: 0.053271, l6: 0.049489

[epoch:  65/100000, batch:   162/  187, ite: 6097] train loss: 0.243721, tar: 0.026656 
l0: 0.022854, l1: 0.026552, l2: 0.025125, l3: 0.026855, l4: 0.028812, l5: 0.032489, l6: 0.029014

[epoch:  65/100000, batch:   164/  187, ite: 6098] train loss: 0.243190, tar: 0.026617 
l0: 0.019620, l1: 0.019650, l2: 0.023042, l3: 0.020525, l4: 0.029323, l5: 0.031380, l6: 0.038074

[epoch:  65/100000, batch:   166/  187, ite: 6099] train loss: 0.242568, tar: 0.026547 
l0: 0.027306, l1: 0.030118, l2: 0.023010, l3: 0.029504, l4: 0.053482, l5: 0.048748, l6: 0.051044

[epoch:  65/100000, batch:   168/  187, ite: 6100] train loss: 0.242774, tar: 0.026554 
l0: 0.051909, l1: 0.049315, l2: 0.052515, l3: 0.065132, l4: 0.053438, l5: 0.060666, l6: 0.067109

[epoch:  65/100000, batch:   170/  187, ite: 6101] train loss: 0.244332, tar: 0.026805 
l0: 0.025197, l1: 0.026036, l2: 0.025741, l3: 0.025671, l4: 0.029800, l5: 0.033488, l6: 0.033720

[epoch:  65/100000, batch:   172/  187, ite: 6102] train loss: 0.243894, tar: 0.026790 
l0: 0.017286, l1: 0.016892, l2: 0.020506, l3: 0.021926, l4: 0.028691, l5: 0.028192, l6: 0.023086

[epoch:  65/100000, batch:   174/  187, ite: 6103] train loss: 0.243046, tar: 0.026697 
l0: 0.021564, l1: 0.020155, l2: 0.024857, l3: 0.025555, l4: 0.053445, l5: 0.050583, l6: 0.059342

[epoch:  65/100000, batch:   176/  187, ite: 6104] train loss: 0.243166, tar: 0.026648 
l0: 0.045860, l1: 0.028752, l2: 0.051582, l3: 0.072882, l4: 0.166844, l5: 0.165918, l6: 0.241721

[epoch:  65/100000, batch:   178/  187, ite: 6105] train loss: 0.248217, tar: 0.026831 
l0: 0.021578, l1: 0.020628, l2: 0.023197, l3: 0.024197, l4: 0.037363, l5: 0.050516, l6: 0.047033

[epoch:  65/100000, batch:   180/  187, ite: 6106] train loss: 0.247994, tar: 0.026781 
l0: 0.014866, l1: 0.015198, l2: 0.019081, l3: 0.016758, l4: 0.027158, l5: 0.029091, l6: 0.024932

[epoch:  65/100000, batch:   182/  187, ite: 6107] train loss: 0.247050, tar: 0.026670 
l0: 0.025264, l1: 0.027363, l2: 0.029260, l3: 0.030036, l4: 0.030613, l5: 0.038382, l6: 0.035990

[epoch:  65/100000, batch:   184/  187, ite: 6108] train loss: 0.246771, tar: 0.026657 
l0: 0.017889, l1: 0.017650, l2: 0.015994, l3: 0.019170, l4: 0.033725, l5: 0.030078, l6: 0.031419

[epoch:  65/100000, batch:   186/  187, ite: 6109] train loss: 0.246030, tar: 0.026577 
l0: 0.022200, l1: 0.021631, l2: 0.021844, l3: 0.025894, l4: 0.027221, l5: 0.027177, l6: 0.029664

[epoch:  65/100000, batch:   188/  187, ite: 6110] train loss: 0.245390, tar: 0.026537 
l0: 0.049864, l1: 0.050376, l2: 0.046587, l3: 0.056330, l4: 0.056006, l5: 0.054215, l6: 0.062351

[epoch:  66/100000, batch:     2/  187, ite: 6111] train loss: 0.246564, tar: 0.026747 
l0: 0.020584, l1: 0.021509, l2: 0.025654, l3: 0.024712, l4: 0.023302, l5: 0.025183, l6: 0.023982

[epoch:  66/100000, batch:     4/  187, ite: 6112] train loss: 0.245835, tar: 0.026692 
l0: 0.025609, l1: 0.026441, l2: 0.027572, l3: 0.030308, l4: 0.050352, l5: 0.041508, l6: 0.054790

[epoch:  66/100000, batch:     6/  187, ite: 6113] train loss: 0.245930, tar: 0.026682 
l0: 0.021970, l1: 0.019757, l2: 0.022892, l3: 0.021140, l4: 0.045786, l5: 0.057407, l6: 0.066906

[epoch:  66/100000, batch:     8/  187, ite: 6114] train loss: 0.246017, tar: 0.026641 
l0: 0.021163, l1: 0.022035, l2: 0.026739, l3: 0.029062, l4: 0.035212, l5: 0.039255, l6: 0.039927

[epoch:  66/100000, batch:    10/  187, ite: 6115] train loss: 0.245733, tar: 0.026593 
l0: 0.022485, l1: 0.021440, l2: 0.018972, l3: 0.027539, l4: 0.053660, l5: 0.051266, l6: 0.042464

[epoch:  66/100000, batch:    12/  187, ite: 6116] train loss: 0.245665, tar: 0.026558 
l0: 0.017658, l1: 0.017572, l2: 0.019753, l3: 0.025042, l4: 0.034294, l5: 0.037422, l6: 0.034023

[epoch:  66/100000, batch:    14/  187, ite: 6117] train loss: 0.245153, tar: 0.026482 
l0: 0.018280, l1: 0.021884, l2: 0.023184, l3: 0.020888, l4: 0.024272, l5: 0.031588, l6: 0.029426

[epoch:  66/100000, batch:    16/  187, ite: 6118] train loss: 0.244512, tar: 0.026412 
l0: 0.021924, l1: 0.021332, l2: 0.027575, l3: 0.030808, l4: 0.040155, l5: 0.038706, l6: 0.055790

[epoch:  66/100000, batch:    18/  187, ite: 6119] train loss: 0.244443, tar: 0.026375 
l0: 0.025843, l1: 0.024023, l2: 0.034692, l3: 0.041167, l4: 0.048386, l5: 0.051305, l6: 0.043724

[epoch:  66/100000, batch:    20/  187, ite: 6120] train loss: 0.244649, tar: 0.026370 
l0: 0.020347, l1: 0.019007, l2: 0.025730, l3: 0.026172, l4: 0.034836, l5: 0.042066, l6: 0.052987

[epoch:  66/100000, batch:    22/  187, ite: 6121] train loss: 0.244455, tar: 0.026320 
l0: 0.029587, l1: 0.027078, l2: 0.041702, l3: 0.036896, l4: 0.050615, l5: 0.058821, l6: 0.052071

[epoch:  66/100000, batch:    24/  187, ite: 6122] train loss: 0.244884, tar: 0.026347 
l0: 0.035263, l1: 0.036629, l2: 0.045946, l3: 0.051680, l4: 0.044171, l5: 0.046811, l6: 0.028733

[epoch:  66/100000, batch:    26/  187, ite: 6123] train loss: 0.245244, tar: 0.026420 
l0: 0.015290, l1: 0.017055, l2: 0.017176, l3: 0.015735, l4: 0.028586, l5: 0.025352, l6: 0.024037

[epoch:  66/100000, batch:    28/  187, ite: 6124] train loss: 0.244421, tar: 0.026330 
l0: 0.009995, l1: 0.009469, l2: 0.010642, l3: 0.015829, l4: 0.047586, l5: 0.047314, l6: 0.040581

[epoch:  66/100000, batch:    30/  187, ite: 6125] train loss: 0.243917, tar: 0.026199 
l0: 0.023996, l1: 0.021959, l2: 0.029346, l3: 0.036313, l4: 0.064419, l5: 0.058419, l6: 0.065087

[epoch:  66/100000, batch:    32/  187, ite: 6126] train loss: 0.244359, tar: 0.026182 
l0: 0.030442, l1: 0.030301, l2: 0.029987, l3: 0.035871, l4: 0.041839, l5: 0.049091, l6: 0.048980

[epoch:  66/100000, batch:    34/  187, ite: 6127] train loss: 0.244533, tar: 0.026215 
l0: 0.020358, l1: 0.022004, l2: 0.019798, l3: 0.020365, l4: 0.025002, l5: 0.024610, l6: 0.026717

[epoch:  66/100000, batch:    36/  187, ite: 6128] train loss: 0.243864, tar: 0.026170 
l0: 0.018515, l1: 0.017771, l2: 0.021053, l3: 0.026117, l4: 0.039976, l5: 0.036383, l6: 0.031827

[epoch:  66/100000, batch:    38/  187, ite: 6129] train loss: 0.243459, tar: 0.026110 
l0: 0.024625, l1: 0.026284, l2: 0.026680, l3: 0.027274, l4: 0.039371, l5: 0.042846, l6: 0.042279

[epoch:  66/100000, batch:    40/  187, ite: 6130] train loss: 0.243351, tar: 0.026099 
l0: 0.011423, l1: 0.011268, l2: 0.012634, l3: 0.015229, l4: 0.036654, l5: 0.034019, l6: 0.033242

[epoch:  66/100000, batch:    42/  187, ite: 6131] train loss: 0.242672, tar: 0.025987 
l0: 0.013295, l1: 0.014409, l2: 0.018533, l3: 0.017391, l4: 0.021969, l5: 0.023550, l6: 0.025110

[epoch:  66/100000, batch:    44/  187, ite: 6132] train loss: 0.241851, tar: 0.025891 
l0: 0.022142, l1: 0.020525, l2: 0.026627, l3: 0.025377, l4: 0.043580, l5: 0.046199, l6: 0.061511

[epoch:  66/100000, batch:    46/  187, ite: 6133] train loss: 0.241882, tar: 0.025862 
l0: 0.019418, l1: 0.018407, l2: 0.021554, l3: 0.022570, l4: 0.048786, l5: 0.052195, l6: 0.074997

[epoch:  66/100000, batch:    48/  187, ite: 6134] train loss: 0.242001, tar: 0.025814 
l0: 0.009799, l1: 0.009831, l2: 0.013814, l3: 0.014914, l4: 0.022192, l5: 0.020451, l6: 0.029648

[epoch:  66/100000, batch:    50/  187, ite: 6135] train loss: 0.241103, tar: 0.025696 
l0: 0.026232, l1: 0.028850, l2: 0.031986, l3: 0.028941, l4: 0.039945, l5: 0.040635, l6: 0.046030

[epoch:  66/100000, batch:    52/  187, ite: 6136] train loss: 0.241114, tar: 0.025700 
l0: 0.017982, l1: 0.017736, l2: 0.020325, l3: 0.022791, l4: 0.028651, l5: 0.031176, l6: 0.024496

[epoch:  66/100000, batch:    54/  187, ite: 6137] train loss: 0.240545, tar: 0.025643 
l0: 0.015115, l1: 0.016070, l2: 0.018611, l3: 0.022340, l4: 0.023324, l5: 0.018648, l6: 0.022350

[epoch:  66/100000, batch:    56/  187, ite: 6138] train loss: 0.239790, tar: 0.025567 
l0: 0.017405, l1: 0.015550, l2: 0.023817, l3: 0.026814, l4: 0.035815, l5: 0.034844, l6: 0.036590

[epoch:  66/100000, batch:    58/  187, ite: 6139] train loss: 0.239438, tar: 0.025508 
l0: 0.013218, l1: 0.013228, l2: 0.014082, l3: 0.019639, l4: 0.019426, l5: 0.024116, l6: 0.027283

[epoch:  66/100000, batch:    60/  187, ite: 6140] train loss: 0.238664, tar: 0.025421 
l0: 0.019844, l1: 0.017769, l2: 0.039523, l3: 0.039417, l4: 0.061583, l5: 0.057532, l6: 0.054372

[epoch:  66/100000, batch:    62/  187, ite: 6141] train loss: 0.239028, tar: 0.025381 
l0: 0.016272, l1: 0.015751, l2: 0.019087, l3: 0.018685, l4: 0.039049, l5: 0.039179, l6: 0.038585

[epoch:  66/100000, batch:    64/  187, ite: 6142] train loss: 0.238659, tar: 0.025317 
l0: 0.021330, l1: 0.019238, l2: 0.023977, l3: 0.027095, l4: 0.048458, l5: 0.067038, l6: 0.068567

[epoch:  66/100000, batch:    66/  187, ite: 6143] train loss: 0.238918, tar: 0.025289 
l0: 0.036493, l1: 0.037311, l2: 0.049441, l3: 0.054276, l4: 0.061276, l5: 0.051270, l6: 0.054958

[epoch:  66/100000, batch:    68/  187, ite: 6144] train loss: 0.239655, tar: 0.025367 
l0: 0.033363, l1: 0.032818, l2: 0.043028, l3: 0.051328, l4: 0.074704, l5: 0.059018, l6: 0.063832

[epoch:  66/100000, batch:    70/  187, ite: 6145] train loss: 0.240472, tar: 0.025422 
l0: 0.025469, l1: 0.029668, l2: 0.023253, l3: 0.023749, l4: 0.026063, l5: 0.029093, l6: 0.024426

[epoch:  66/100000, batch:    72/  187, ite: 6146] train loss: 0.240069, tar: 0.025422 
l0: 0.018371, l1: 0.019308, l2: 0.021271, l3: 0.021477, l4: 0.044231, l5: 0.046025, l6: 0.049336

[epoch:  66/100000, batch:    74/  187, ite: 6147] train loss: 0.239933, tar: 0.025374 
l0: 0.021196, l1: 0.023502, l2: 0.019324, l3: 0.017439, l4: 0.041980, l5: 0.034814, l6: 0.037016

[epoch:  66/100000, batch:    76/  187, ite: 6148] train loss: 0.239631, tar: 0.025346 
l0: 0.044116, l1: 0.042567, l2: 0.044569, l3: 0.051303, l4: 0.057112, l5: 0.060595, l6: 0.063183

[epoch:  66/100000, batch:    78/  187, ite: 6149] train loss: 0.240462, tar: 0.025472 
l0: 0.016601, l1: 0.017310, l2: 0.017658, l3: 0.018337, l4: 0.036470, l5: 0.036603, l6: 0.040739

[epoch:  66/100000, batch:    80/  187, ite: 6150] train loss: 0.240084, tar: 0.025413 
l0: 0.015377, l1: 0.015193, l2: 0.017664, l3: 0.020520, l4: 0.032265, l5: 0.029702, l6: 0.031654

[epoch:  66/100000, batch:    82/  187, ite: 6151] train loss: 0.239569, tar: 0.025346 
l0: 0.020331, l1: 0.019747, l2: 0.025143, l3: 0.027181, l4: 0.038822, l5: 0.039620, l6: 0.041403

[epoch:  66/100000, batch:    84/  187, ite: 6152] train loss: 0.239389, tar: 0.025313 
l0: 0.013237, l1: 0.012490, l2: 0.020996, l3: 0.022029, l4: 0.052127, l5: 0.046100, l6: 0.042954

[epoch:  66/100000, batch:    86/  187, ite: 6153] train loss: 0.239197, tar: 0.025234 
l0: 0.017835, l1: 0.018611, l2: 0.019474, l3: 0.023396, l4: 0.034330, l5: 0.034546, l6: 0.029626

[epoch:  66/100000, batch:    88/  187, ite: 6154] train loss: 0.238798, tar: 0.025186 
l0: 0.009656, l1: 0.010471, l2: 0.012575, l3: 0.013353, l4: 0.025480, l5: 0.034163, l6: 0.028885

[epoch:  66/100000, batch:    90/  187, ite: 6155] train loss: 0.238126, tar: 0.025086 
l0: 0.020725, l1: 0.021351, l2: 0.022898, l3: 0.027805, l4: 0.033608, l5: 0.042693, l6: 0.047333

[epoch:  66/100000, batch:    92/  187, ite: 6156] train loss: 0.237987, tar: 0.025058 
l0: 0.030668, l1: 0.034062, l2: 0.030054, l3: 0.026186, l4: 0.050078, l5: 0.059490, l6: 0.054543

[epoch:  66/100000, batch:    94/  187, ite: 6157] train loss: 0.238287, tar: 0.025094 
l0: 0.017009, l1: 0.015920, l2: 0.020169, l3: 0.028286, l4: 0.063487, l5: 0.059463, l6: 0.051260

[epoch:  66/100000, batch:    96/  187, ite: 6158] train loss: 0.238396, tar: 0.025043 
l0: 0.015308, l1: 0.014089, l2: 0.016388, l3: 0.021642, l4: 0.041334, l5: 0.038224, l6: 0.042278

[epoch:  66/100000, batch:    98/  187, ite: 6159] train loss: 0.238087, tar: 0.024982 
l0: 0.021959, l1: 0.024873, l2: 0.023340, l3: 0.021488, l4: 0.036004, l5: 0.032704, l6: 0.035833

[epoch:  66/100000, batch:   100/  187, ite: 6160] train loss: 0.237825, tar: 0.024963 
l0: 0.026954, l1: 0.031032, l2: 0.029101, l3: 0.023994, l4: 0.035897, l5: 0.027713, l6: 0.038307

[epoch:  66/100000, batch:   102/  187, ite: 6161] train loss: 0.237671, tar: 0.024975 
l0: 0.013837, l1: 0.016055, l2: 0.014699, l3: 0.015824, l4: 0.023504, l5: 0.023953, l6: 0.018485

[epoch:  66/100000, batch:   104/  187, ite: 6162] train loss: 0.236984, tar: 0.024906 
l0: 0.020468, l1: 0.023193, l2: 0.018082, l3: 0.022375, l4: 0.044252, l5: 0.044145, l6: 0.037345

[epoch:  66/100000, batch:   106/  187, ite: 6163] train loss: 0.236818, tar: 0.024879 
l0: 0.012659, l1: 0.013092, l2: 0.013290, l3: 0.015017, l4: 0.023630, l5: 0.024257, l6: 0.026922

[epoch:  66/100000, batch:   108/  187, ite: 6164] train loss: 0.236159, tar: 0.024805 
l0: 0.029968, l1: 0.031972, l2: 0.034247, l3: 0.031306, l4: 0.084022, l5: 0.079452, l6: 0.090881

[epoch:  66/100000, batch:   110/  187, ite: 6165] train loss: 0.237042, tar: 0.024836 
l0: 0.016935, l1: 0.016671, l2: 0.019380, l3: 0.021511, l4: 0.028352, l5: 0.028953, l6: 0.033094

[epoch:  66/100000, batch:   112/  187, ite: 6166] train loss: 0.236608, tar: 0.024788 
l0: 0.016553, l1: 0.016570, l2: 0.017350, l3: 0.018068, l4: 0.029391, l5: 0.030817, l6: 0.041805

[epoch:  66/100000, batch:   114/  187, ite: 6167] train loss: 0.236212, tar: 0.024739 
l0: 0.032144, l1: 0.032217, l2: 0.038397, l3: 0.034963, l4: 0.033099, l5: 0.041339, l6: 0.037154

[epoch:  66/100000, batch:   116/  187, ite: 6168] train loss: 0.236290, tar: 0.024783 
l0: 0.021879, l1: 0.023617, l2: 0.025370, l3: 0.024818, l4: 0.031946, l5: 0.035303, l6: 0.032651

[epoch:  66/100000, batch:   118/  187, ite: 6169] train loss: 0.236049, tar: 0.024766 
l0: 0.008475, l1: 0.008245, l2: 0.009768, l3: 0.013455, l4: 0.024405, l5: 0.022034, l6: 0.033986

[epoch:  66/100000, batch:   120/  187, ite: 6170] train loss: 0.235369, tar: 0.024670 
l0: 0.018654, l1: 0.018516, l2: 0.014478, l3: 0.016128, l4: 0.015016, l5: 0.019644, l6: 0.026534

[epoch:  66/100000, batch:   122/  187, ite: 6171] train loss: 0.234747, tar: 0.024635 
l0: 0.028387, l1: 0.029399, l2: 0.050232, l3: 0.048099, l4: 0.038266, l5: 0.040238, l6: 0.038135

[epoch:  66/100000, batch:   124/  187, ite: 6172] train loss: 0.234968, tar: 0.024657 
l0: 0.009806, l1: 0.008796, l2: 0.014026, l3: 0.014499, l4: 0.053100, l5: 0.053409, l6: 0.051993

[epoch:  66/100000, batch:   126/  187, ite: 6173] train loss: 0.234798, tar: 0.024571 
l0: 0.016840, l1: 0.016401, l2: 0.022782, l3: 0.023616, l4: 0.032972, l5: 0.035278, l6: 0.035497

[epoch:  66/100000, batch:   128/  187, ite: 6174] train loss: 0.234503, tar: 0.024526 
l0: 0.023531, l1: 0.022161, l2: 0.025405, l3: 0.028591, l4: 0.058793, l5: 0.054473, l6: 0.051268

[epoch:  66/100000, batch:   130/  187, ite: 6175] train loss: 0.234672, tar: 0.024521 
l0: 0.012322, l1: 0.010280, l2: 0.016653, l3: 0.017056, l4: 0.019481, l5: 0.022663, l6: 0.041567

[epoch:  66/100000, batch:   132/  187, ite: 6176] train loss: 0.234135, tar: 0.024451 
l0: 0.025744, l1: 0.021153, l2: 0.038328, l3: 0.035494, l4: 0.041842, l5: 0.055996, l6: 0.055590

[epoch:  66/100000, batch:   134/  187, ite: 6177] train loss: 0.234361, tar: 0.024459 
l0: 0.020953, l1: 0.025233, l2: 0.022178, l3: 0.018281, l4: 0.022099, l5: 0.024852, l6: 0.022396

[epoch:  66/100000, batch:   136/  187, ite: 6178] train loss: 0.233920, tar: 0.024439 
l0: 0.016948, l1: 0.015036, l2: 0.018876, l3: 0.021770, l4: 0.051325, l5: 0.056439, l6: 0.053966

[epoch:  66/100000, batch:   138/  187, ite: 6179] train loss: 0.233923, tar: 0.024397 
l0: 0.017362, l1: 0.017831, l2: 0.026519, l3: 0.026689, l4: 0.031631, l5: 0.031482, l6: 0.031890

[epoch:  66/100000, batch:   140/  187, ite: 6180] train loss: 0.233642, tar: 0.024358 
l0: 0.016583, l1: 0.014963, l2: 0.033862, l3: 0.033070, l4: 0.029480, l5: 0.032959, l6: 0.034705

[epoch:  66/100000, batch:   142/  187, ite: 6181] train loss: 0.233432, tar: 0.024315 
l0: 0.019469, l1: 0.021273, l2: 0.019984, l3: 0.017821, l4: 0.037612, l5: 0.037683, l6: 0.039955

[epoch:  66/100000, batch:   144/  187, ite: 6182] train loss: 0.233214, tar: 0.024288 
l0: 0.013528, l1: 0.016041, l2: 0.013532, l3: 0.014428, l4: 0.027274, l5: 0.024304, l6: 0.029133

[epoch:  66/100000, batch:   146/  187, ite: 6183] train loss: 0.232695, tar: 0.024230 
l0: 0.040699, l1: 0.039225, l2: 0.049782, l3: 0.051583, l4: 0.074073, l5: 0.061983, l6: 0.059518

[epoch:  66/100000, batch:   148/  187, ite: 6184] train loss: 0.233479, tar: 0.024319 
l0: 0.056395, l1: 0.057198, l2: 0.061768, l3: 0.057867, l4: 0.080581, l5: 0.065097, l6: 0.082635

[epoch:  66/100000, batch:   150/  187, ite: 6185] train loss: 0.234712, tar: 0.024493 
l0: 0.014257, l1: 0.014506, l2: 0.019560, l3: 0.020807, l4: 0.037260, l5: 0.034579, l6: 0.041922

[epoch:  66/100000, batch:   152/  187, ite: 6186] train loss: 0.234433, tar: 0.024438 
l0: 0.024100, l1: 0.024673, l2: 0.020391, l3: 0.025660, l4: 0.041915, l5: 0.031749, l6: 0.043039

[epoch:  66/100000, batch:   154/  187, ite: 6187] train loss: 0.234311, tar: 0.024436 
l0: 0.009610, l1: 0.008793, l2: 0.013661, l3: 0.014263, l4: 0.029674, l5: 0.031126, l6: 0.044272

[epoch:  66/100000, batch:   156/  187, ite: 6188] train loss: 0.233870, tar: 0.024357 
l0: 0.017548, l1: 0.019144, l2: 0.017943, l3: 0.018621, l4: 0.050902, l5: 0.045239, l6: 0.038711

[epoch:  66/100000, batch:   158/  187, ite: 6189] train loss: 0.233733, tar: 0.024321 
l0: 0.017202, l1: 0.018568, l2: 0.019051, l3: 0.017662, l4: 0.037615, l5: 0.036033, l6: 0.033735

[epoch:  66/100000, batch:   160/  187, ite: 6190] train loss: 0.233450, tar: 0.024283 
l0: 0.022981, l1: 0.024353, l2: 0.029831, l3: 0.028150, l4: 0.035185, l5: 0.034759, l6: 0.035425

[epoch:  66/100000, batch:   162/  187, ite: 6191] train loss: 0.233331, tar: 0.024277 
l0: 0.010532, l1: 0.011267, l2: 0.012551, l3: 0.014079, l4: 0.021909, l5: 0.023842, l6: 0.014314

[epoch:  66/100000, batch:   164/  187, ite: 6192] train loss: 0.232680, tar: 0.024205 
l0: 0.024387, l1: 0.023780, l2: 0.030422, l3: 0.031939, l4: 0.031329, l5: 0.044587, l6: 0.040469

[epoch:  66/100000, batch:   166/  187, ite: 6193] train loss: 0.232651, tar: 0.024206 
l0: 0.017797, l1: 0.018099, l2: 0.020426, l3: 0.019850, l4: 0.034401, l5: 0.038409, l6: 0.053651

[epoch:  66/100000, batch:   168/  187, ite: 6194] train loss: 0.232496, tar: 0.024173 
l0: 0.027960, l1: 0.030136, l2: 0.022582, l3: 0.023314, l4: 0.029518, l5: 0.032802, l6: 0.032815

[epoch:  66/100000, batch:   170/  187, ite: 6195] train loss: 0.232325, tar: 0.024192 
l0: 0.018789, l1: 0.019783, l2: 0.018914, l3: 0.019160, l4: 0.029272, l5: 0.030004, l6: 0.031836

[epoch:  66/100000, batch:   172/  187, ite: 6196] train loss: 0.231995, tar: 0.024165 
l0: 0.036704, l1: 0.039345, l2: 0.038815, l3: 0.036646, l4: 0.070072, l5: 0.071938, l6: 0.070574

[epoch:  66/100000, batch:   174/  187, ite: 6197] train loss: 0.232666, tar: 0.024228 
l0: 0.028703, l1: 0.025889, l2: 0.040921, l3: 0.041077, l4: 0.087128, l5: 0.082031, l6: 0.076212

[epoch:  66/100000, batch:   176/  187, ite: 6198] train loss: 0.233420, tar: 0.024251 
l0: 0.024819, l1: 0.027658, l2: 0.027673, l3: 0.027830, l4: 0.037276, l5: 0.042825, l6: 0.031713

[epoch:  66/100000, batch:   178/  187, ite: 6199] train loss: 0.233351, tar: 0.024254 
l0: 0.013993, l1: 0.013688, l2: 0.019422, l3: 0.020930, l4: 0.037752, l5: 0.036154, l6: 0.033326

[epoch:  66/100000, batch:   180/  187, ite: 6200] train loss: 0.233061, tar: 0.024203 
l0: 0.024881, l1: 0.025038, l2: 0.040119, l3: 0.040520, l4: 0.034619, l5: 0.031651, l6: 0.026415

[epoch:  66/100000, batch:   182/  187, ite: 6201] train loss: 0.233012, tar: 0.024206 
l0: 0.021489, l1: 0.020880, l2: 0.025714, l3: 0.025023, l4: 0.037775, l5: 0.038574, l6: 0.038648

[epoch:  66/100000, batch:   184/  187, ite: 6202] train loss: 0.232889, tar: 0.024192 
l0: 0.026827, l1: 0.031733, l2: 0.024927, l3: 0.024423, l4: 0.030215, l5: 0.032722, l6: 0.031722

[epoch:  66/100000, batch:   186/  187, ite: 6203] train loss: 0.232739, tar: 0.024205 
l0: 0.017112, l1: 0.019925, l2: 0.017931, l3: 0.019406, l4: 0.030820, l5: 0.031007, l6: 0.035200

[epoch:  66/100000, batch:   188/  187, ite: 6204] train loss: 0.232439, tar: 0.024171 
l0: 0.016670, l1: 0.018866, l2: 0.014211, l3: 0.014354, l4: 0.036370, l5: 0.031227, l6: 0.032616

[epoch:  67/100000, batch:     2/  187, ite: 6205] train loss: 0.232106, tar: 0.024134 
l0: 0.025178, l1: 0.024343, l2: 0.034189, l3: 0.035835, l4: 0.041910, l5: 0.041528, l6: 0.047083

[epoch:  67/100000, batch:     4/  187, ite: 6206] train loss: 0.232194, tar: 0.024139 
l0: 0.030000, l1: 0.033804, l2: 0.032844, l3: 0.032938, l4: 0.034138, l5: 0.035736, l6: 0.030729

[epoch:  67/100000, batch:     6/  187, ite: 6207] train loss: 0.232184, tar: 0.024167 
l0: 0.012563, l1: 0.011262, l2: 0.021642, l3: 0.018907, l4: 0.046011, l5: 0.053063, l6: 0.039103

[epoch:  67/100000, batch:     8/  187, ite: 6208] train loss: 0.232041, tar: 0.024112 
l0: 0.013548, l1: 0.012431, l2: 0.019293, l3: 0.024299, l4: 0.017663, l5: 0.019956, l6: 0.022441

[epoch:  67/100000, batch:    10/  187, ite: 6209] train loss: 0.231551, tar: 0.024061 
l0: 0.036619, l1: 0.032622, l2: 0.047187, l3: 0.049274, l4: 0.068125, l5: 0.077832, l6: 0.081212

[epoch:  67/100000, batch:    12/  187, ite: 6210] train loss: 0.232320, tar: 0.024121 
l0: 0.032765, l1: 0.038866, l2: 0.032414, l3: 0.029238, l4: 0.032472, l5: 0.035650, l6: 0.030761

[epoch:  67/100000, batch:    14/  187, ite: 6211] train loss: 0.232319, tar: 0.024162 
l0: 0.023543, l1: 0.023516, l2: 0.031621, l3: 0.031008, l4: 0.028181, l5: 0.027205, l6: 0.030130

[epoch:  67/100000, batch:    16/  187, ite: 6212] train loss: 0.232144, tar: 0.024159 
l0: 0.022069, l1: 0.021394, l2: 0.027057, l3: 0.026850, l4: 0.038127, l5: 0.036604, l6: 0.038592

[epoch:  67/100000, batch:    18/  187, ite: 6213] train loss: 0.232043, tar: 0.024149 
l0: 0.022612, l1: 0.023194, l2: 0.028464, l3: 0.026923, l4: 0.042193, l5: 0.036073, l6: 0.036677

[epoch:  67/100000, batch:    20/  187, ite: 6214] train loss: 0.231969, tar: 0.024142 
l0: 0.015179, l1: 0.015671, l2: 0.017615, l3: 0.017372, l4: 0.025114, l5: 0.028360, l6: 0.026016

[epoch:  67/100000, batch:    22/  187, ite: 6215] train loss: 0.231566, tar: 0.024100 
l0: 0.018543, l1: 0.018504, l2: 0.023401, l3: 0.023163, l4: 0.033511, l5: 0.032773, l6: 0.035981

[epoch:  67/100000, batch:    24/  187, ite: 6216] train loss: 0.231354, tar: 0.024075 
l0: 0.028686, l1: 0.029089, l2: 0.020784, l3: 0.023427, l4: 0.041311, l5: 0.048089, l6: 0.037462

[epoch:  67/100000, batch:    26/  187, ite: 6217] train loss: 0.231343, tar: 0.024096 
l0: 0.014324, l1: 0.013869, l2: 0.038277, l3: 0.040170, l4: 0.045064, l5: 0.052297, l6: 0.028708

[epoch:  67/100000, batch:    28/  187, ite: 6218] train loss: 0.231349, tar: 0.024051 
l0: 0.037992, l1: 0.039459, l2: 0.043035, l3: 0.045951, l4: 0.043590, l5: 0.041469, l6: 0.040108

[epoch:  67/100000, batch:    30/  187, ite: 6219] train loss: 0.231624, tar: 0.024115 
l0: 0.017414, l1: 0.016819, l2: 0.018900, l3: 0.021480, l4: 0.044417, l5: 0.046051, l6: 0.034156

[epoch:  67/100000, batch:    32/  187, ite: 6220] train loss: 0.231477, tar: 0.024084 
l0: 0.021364, l1: 0.020937, l2: 0.027325, l3: 0.031473, l4: 0.051120, l5: 0.036778, l6: 0.044116

[epoch:  67/100000, batch:    34/  187, ite: 6221] train loss: 0.231484, tar: 0.024072 
l0: 0.014346, l1: 0.013712, l2: 0.017179, l3: 0.018233, l4: 0.033651, l5: 0.040609, l6: 0.041548

[epoch:  67/100000, batch:    36/  187, ite: 6222] train loss: 0.231249, tar: 0.024028 
l0: 0.016874, l1: 0.018298, l2: 0.019802, l3: 0.017618, l4: 0.033163, l5: 0.032065, l6: 0.038866

[epoch:  67/100000, batch:    38/  187, ite: 6223] train loss: 0.231004, tar: 0.023996 
l0: 0.016669, l1: 0.021127, l2: 0.019834, l3: 0.016839, l4: 0.025579, l5: 0.033294, l6: 0.033117

[epoch:  67/100000, batch:    40/  187, ite: 6224] train loss: 0.230716, tar: 0.023963 
l0: 0.017183, l1: 0.016127, l2: 0.020479, l3: 0.025641, l4: 0.037766, l5: 0.036894, l6: 0.039643

[epoch:  67/100000, batch:    42/  187, ite: 6225] train loss: 0.230552, tar: 0.023933 
l0: 0.025984, l1: 0.028269, l2: 0.028695, l3: 0.026660, l4: 0.026886, l5: 0.030526, l6: 0.035191

[epoch:  67/100000, batch:    44/  187, ite: 6226] train loss: 0.230427, tar: 0.023942 
l0: 0.024065, l1: 0.022147, l2: 0.024494, l3: 0.026672, l4: 0.028325, l5: 0.041185, l6: 0.040404

[epoch:  67/100000, batch:    46/  187, ite: 6227] train loss: 0.230325, tar: 0.023943 
l0: 0.012399, l1: 0.012728, l2: 0.014308, l3: 0.015926, l4: 0.025132, l5: 0.024446, l6: 0.018795

[epoch:  67/100000, batch:    48/  187, ite: 6228] train loss: 0.229857, tar: 0.023892 
l0: 0.015742, l1: 0.015576, l2: 0.018277, l3: 0.017883, l4: 0.033383, l5: 0.034046, l6: 0.033566

[epoch:  67/100000, batch:    50/  187, ite: 6229] train loss: 0.229589, tar: 0.023857 
l0: 0.008271, l1: 0.013860, l2: 0.016491, l3: 0.014361, l4: 0.015113, l5: 0.018041, l6: 0.026125

[epoch:  67/100000, batch:    52/  187, ite: 6230] train loss: 0.229079, tar: 0.023789 
l0: 0.028585, l1: 0.025263, l2: 0.031225, l3: 0.041703, l4: 0.071415, l5: 0.080557, l6: 0.050551

[epoch:  67/100000, batch:    54/  187, ite: 6231] train loss: 0.229513, tar: 0.023810 
l0: 0.017936, l1: 0.017817, l2: 0.020942, l3: 0.021156, l4: 0.031381, l5: 0.033800, l6: 0.033696

[epoch:  67/100000, batch:    56/  187, ite: 6232] train loss: 0.229285, tar: 0.023784 
l0: 0.016199, l1: 0.015384, l2: 0.025116, l3: 0.027086, l4: 0.030268, l5: 0.032551, l6: 0.025977

[epoch:  67/100000, batch:    58/  187, ite: 6233] train loss: 0.229042, tar: 0.023752 
l0: 0.029692, l1: 0.033399, l2: 0.030493, l3: 0.032760, l4: 0.032948, l5: 0.036505, l6: 0.030162

[epoch:  67/100000, batch:    60/  187, ite: 6234] train loss: 0.229029, tar: 0.023777 
l0: 0.015602, l1: 0.016032, l2: 0.026209, l3: 0.029787, l4: 0.026759, l5: 0.028460, l6: 0.025527

[epoch:  67/100000, batch:    62/  187, ite: 6235] train loss: 0.228771, tar: 0.023742 
l0: 0.016970, l1: 0.018101, l2: 0.020047, l3: 0.022315, l4: 0.030351, l5: 0.029021, l6: 0.024487

[epoch:  67/100000, batch:    64/  187, ite: 6236] train loss: 0.228485, tar: 0.023714 
l0: 0.021401, l1: 0.022088, l2: 0.025262, l3: 0.029282, l4: 0.046708, l5: 0.039345, l6: 0.038412

[epoch:  67/100000, batch:    66/  187, ite: 6237] train loss: 0.228459, tar: 0.023704 
l0: 0.015232, l1: 0.015716, l2: 0.018066, l3: 0.017663, l4: 0.034909, l5: 0.033636, l6: 0.024957

[epoch:  67/100000, batch:    68/  187, ite: 6238] train loss: 0.228173, tar: 0.023668 
l0: 0.021603, l1: 0.022351, l2: 0.027680, l3: 0.028581, l4: 0.038096, l5: 0.036393, l6: 0.033605

[epoch:  67/100000, batch:    70/  187, ite: 6239] train loss: 0.228089, tar: 0.023660 
l0: 0.017026, l1: 0.015680, l2: 0.021504, l3: 0.027247, l4: 0.053325, l5: 0.061271, l6: 0.065035

[epoch:  67/100000, batch:    72/  187, ite: 6240] train loss: 0.228227, tar: 0.023632 
l0: 0.020273, l1: 0.020872, l2: 0.022392, l3: 0.021885, l4: 0.030176, l5: 0.029870, l6: 0.028565

[epoch:  67/100000, batch:    74/  187, ite: 6241] train loss: 0.228002, tar: 0.023618 
l0: 0.021444, l1: 0.024918, l2: 0.021727, l3: 0.021961, l4: 0.034612, l5: 0.034531, l6: 0.031991

[epoch:  67/100000, batch:    76/  187, ite: 6242] train loss: 0.227850, tar: 0.023609 
l0: 0.026543, l1: 0.028601, l2: 0.037124, l3: 0.030941, l4: 0.027586, l5: 0.028804, l6: 0.026597

[epoch:  67/100000, batch:    78/  187, ite: 6243] train loss: 0.227761, tar: 0.023621 
l0: 0.020607, l1: 0.022891, l2: 0.021057, l3: 0.018728, l4: 0.021597, l5: 0.023673, l6: 0.021736

[epoch:  67/100000, batch:    80/  187, ite: 6244] train loss: 0.227443, tar: 0.023609 
l0: 0.018931, l1: 0.018774, l2: 0.019872, l3: 0.027914, l4: 0.052079, l5: 0.051408, l6: 0.044152

[epoch:  67/100000, batch:    82/  187, ite: 6245] train loss: 0.227467, tar: 0.023590 
l0: 0.014779, l1: 0.020033, l2: 0.019198, l3: 0.020634, l4: 0.033373, l5: 0.027441, l6: 0.028527

[epoch:  67/100000, batch:    84/  187, ite: 6246] train loss: 0.227208, tar: 0.023554 
l0: 0.012390, l1: 0.014462, l2: 0.016129, l3: 0.013933, l4: 0.023307, l5: 0.019697, l6: 0.021572

[epoch:  67/100000, batch:    86/  187, ite: 6247] train loss: 0.226780, tar: 0.023509 
l0: 0.017794, l1: 0.016367, l2: 0.027316, l3: 0.030241, l4: 0.041307, l5: 0.040928, l6: 0.042276

[epoch:  67/100000, batch:    88/  187, ite: 6248] train loss: 0.226738, tar: 0.023486 
l0: 0.021769, l1: 0.021643, l2: 0.028962, l3: 0.027032, l4: 0.055514, l5: 0.043974, l6: 0.047999

[epoch:  67/100000, batch:    90/  187, ite: 6249] train loss: 0.226819, tar: 0.023479 
l0: 0.026773, l1: 0.024222, l2: 0.028993, l3: 0.048050, l4: 0.078226, l5: 0.068473, l6: 0.067123

[epoch:  67/100000, batch:    92/  187, ite: 6250] train loss: 0.227279, tar: 0.023492 
l0: 0.011449, l1: 0.010936, l2: 0.028907, l3: 0.028254, l4: 0.035117, l5: 0.037139, l6: 0.037493

[epoch:  67/100000, batch:    94/  187, ite: 6251] train loss: 0.227128, tar: 0.023444 
l0: 0.017211, l1: 0.015127, l2: 0.023222, l3: 0.032122, l4: 0.031622, l5: 0.029786, l6: 0.029282

[epoch:  67/100000, batch:    96/  187, ite: 6252] train loss: 0.226934, tar: 0.023419 
l0: 0.010031, l1: 0.009494, l2: 0.010212, l3: 0.018977, l4: 0.034343, l5: 0.030889, l6: 0.026952

[epoch:  67/100000, batch:    98/  187, ite: 6253] train loss: 0.226594, tar: 0.023366 
l0: 0.013774, l1: 0.012976, l2: 0.019286, l3: 0.021094, l4: 0.026652, l5: 0.028905, l6: 0.028170

[epoch:  67/100000, batch:   100/  187, ite: 6254] train loss: 0.226296, tar: 0.023328 
l0: 0.015063, l1: 0.013376, l2: 0.017799, l3: 0.019960, l4: 0.030542, l5: 0.039231, l6: 0.041213

[epoch:  67/100000, batch:   102/  187, ite: 6255] train loss: 0.226103, tar: 0.023296 
l0: 0.015010, l1: 0.017217, l2: 0.011735, l3: 0.015265, l4: 0.023239, l5: 0.024397, l6: 0.026002

[epoch:  67/100000, batch:   104/  187, ite: 6256] train loss: 0.225739, tar: 0.023264 
l0: 0.013582, l1: 0.013603, l2: 0.012890, l3: 0.013721, l4: 0.021080, l5: 0.019561, l6: 0.021127

[epoch:  67/100000, batch:   106/  187, ite: 6257] train loss: 0.225310, tar: 0.023226 
l0: 0.020604, l1: 0.021154, l2: 0.025052, l3: 0.030783, l4: 0.028029, l5: 0.033239, l6: 0.031785

[epoch:  67/100000, batch:   108/  187, ite: 6258] train loss: 0.225176, tar: 0.023216 
l0: 0.013048, l1: 0.012372, l2: 0.020126, l3: 0.026537, l4: 0.034649, l5: 0.033030, l6: 0.027546

[epoch:  67/100000, batch:   110/  187, ite: 6259] train loss: 0.224953, tar: 0.023177 
l0: 0.022185, l1: 0.024491, l2: 0.022911, l3: 0.022270, l4: 0.034534, l5: 0.030532, l6: 0.029149

[epoch:  67/100000, batch:   112/  187, ite: 6260] train loss: 0.224803, tar: 0.023173 
l0: 0.022334, l1: 0.024472, l2: 0.020181, l3: 0.020860, l4: 0.022096, l5: 0.022716, l6: 0.024813

[epoch:  67/100000, batch:   114/  187, ite: 6261] train loss: 0.224545, tar: 0.023170 
l0: 0.037622, l1: 0.041802, l2: 0.050865, l3: 0.038472, l4: 0.059131, l5: 0.049183, l6: 0.042154

[epoch:  67/100000, batch:   116/  187, ite: 6262] train loss: 0.224907, tar: 0.023225 
l0: 0.015791, l1: 0.017781, l2: 0.014868, l3: 0.016511, l4: 0.029292, l5: 0.030606, l6: 0.032847

[epoch:  67/100000, batch:   118/  187, ite: 6263] train loss: 0.224651, tar: 0.023196 
l0: 0.030465, l1: 0.032649, l2: 0.032787, l3: 0.025794, l4: 0.044800, l5: 0.047924, l6: 0.052550

[epoch:  67/100000, batch:   120/  187, ite: 6264] train loss: 0.224811, tar: 0.023224 
l0: 0.019678, l1: 0.019517, l2: 0.026806, l3: 0.028676, l4: 0.028706, l5: 0.028991, l6: 0.035640

[epoch:  67/100000, batch:   122/  187, ite: 6265] train loss: 0.224672, tar: 0.023211 
l0: 0.010989, l1: 0.010739, l2: 0.012912, l3: 0.014843, l4: 0.026486, l5: 0.031180, l6: 0.040167

[epoch:  67/100000, batch:   124/  187, ite: 6266] train loss: 0.224382, tar: 0.023165 
l0: 0.022233, l1: 0.019181, l2: 0.027882, l3: 0.037911, l4: 0.058653, l5: 0.063602, l6: 0.057270

[epoch:  67/100000, batch:   126/  187, ite: 6267] train loss: 0.224615, tar: 0.023161 
l0: 0.015514, l1: 0.015366, l2: 0.018330, l3: 0.018410, l4: 0.029361, l5: 0.027813, l6: 0.021940

[epoch:  67/100000, batch:   128/  187, ite: 6268] train loss: 0.224325, tar: 0.023133 
l0: 0.019190, l1: 0.021153, l2: 0.017200, l3: 0.023484, l4: 0.018416, l5: 0.019010, l6: 0.019323

[epoch:  67/100000, batch:   130/  187, ite: 6269] train loss: 0.224003, tar: 0.023118 
l0: 0.021959, l1: 0.023319, l2: 0.023937, l3: 0.024510, l4: 0.041395, l5: 0.035129, l6: 0.036941

[epoch:  67/100000, batch:   132/  187, ite: 6270] train loss: 0.223941, tar: 0.023114 
l0: 0.016061, l1: 0.017377, l2: 0.017891, l3: 0.017690, l4: 0.020670, l5: 0.023360, l6: 0.022296

[epoch:  67/100000, batch:   134/  187, ite: 6271] train loss: 0.223614, tar: 0.023088 
l0: 0.022164, l1: 0.021649, l2: 0.021628, l3: 0.027949, l4: 0.027264, l5: 0.026236, l6: 0.028875

[epoch:  67/100000, batch:   136/  187, ite: 6272] train loss: 0.223438, tar: 0.023084 
l0: 0.017355, l1: 0.018109, l2: 0.020382, l3: 0.026029, l4: 0.056999, l5: 0.052286, l6: 0.056050

[epoch:  67/100000, batch:   138/  187, ite: 6273] train loss: 0.223525, tar: 0.023063 
l0: 0.022567, l1: 0.024095, l2: 0.023015, l3: 0.027177, l4: 0.047444, l5: 0.040571, l6: 0.038707

[epoch:  67/100000, batch:   140/  187, ite: 6274] train loss: 0.223525, tar: 0.023061 
l0: 0.021747, l1: 0.023052, l2: 0.023590, l3: 0.026413, l4: 0.034724, l5: 0.034161, l6: 0.035410

[epoch:  67/100000, batch:   142/  187, ite: 6275] train loss: 0.223436, tar: 0.023057 
l0: 0.014194, l1: 0.012512, l2: 0.020221, l3: 0.019238, l4: 0.034296, l5: 0.037585, l6: 0.061042

[epoch:  67/100000, batch:   144/  187, ite: 6276] train loss: 0.223348, tar: 0.023025 
l0: 0.015941, l1: 0.014690, l2: 0.016425, l3: 0.017262, l4: 0.029323, l5: 0.030833, l6: 0.038012

[epoch:  67/100000, batch:   146/  187, ite: 6277] train loss: 0.223128, tar: 0.022999 
l0: 0.012231, l1: 0.013695, l2: 0.015389, l3: 0.011147, l4: 0.039242, l5: 0.036959, l6: 0.024770

[epoch:  67/100000, batch:   148/  187, ite: 6278] train loss: 0.222877, tar: 0.022960 
l0: 0.025088, l1: 0.026100, l2: 0.037907, l3: 0.032924, l4: 0.046092, l5: 0.046241, l6: 0.042170

[epoch:  67/100000, batch:   150/  187, ite: 6279] train loss: 0.222998, tar: 0.022968 
l0: 0.037850, l1: 0.040084, l2: 0.035826, l3: 0.041432, l4: 0.036853, l5: 0.034973, l6: 0.045979

[epoch:  67/100000, batch:   152/  187, ite: 6280] train loss: 0.223177, tar: 0.023021 
l0: 0.018930, l1: 0.021024, l2: 0.019412, l3: 0.019056, l4: 0.027907, l5: 0.024648, l6: 0.021536

[epoch:  67/100000, batch:   154/  187, ite: 6281] train loss: 0.222925, tar: 0.023006 
l0: 0.015034, l1: 0.014709, l2: 0.021493, l3: 0.024073, l4: 0.050314, l5: 0.049915, l6: 0.043703

[epoch:  67/100000, batch:   156/  187, ite: 6282] train loss: 0.222912, tar: 0.022978 
l0: 0.010214, l1: 0.010114, l2: 0.013895, l3: 0.016996, l4: 0.033449, l5: 0.029766, l6: 0.045153

[epoch:  67/100000, batch:   158/  187, ite: 6283] train loss: 0.222688, tar: 0.022933 
l0: 0.014306, l1: 0.014698, l2: 0.019370, l3: 0.018332, l4: 0.025343, l5: 0.022737, l6: 0.024311

[epoch:  67/100000, batch:   160/  187, ite: 6284] train loss: 0.222394, tar: 0.022903 
l0: 0.015834, l1: 0.016843, l2: 0.017003, l3: 0.016708, l4: 0.023496, l5: 0.025712, l6: 0.026221

[epoch:  67/100000, batch:   162/  187, ite: 6285] train loss: 0.222111, tar: 0.022878 
l0: 0.014447, l1: 0.014983, l2: 0.016850, l3: 0.016382, l4: 0.025836, l5: 0.026175, l6: 0.028717

[epoch:  67/100000, batch:   164/  187, ite: 6286] train loss: 0.221836, tar: 0.022848 
l0: 0.014494, l1: 0.013457, l2: 0.016126, l3: 0.017879, l4: 0.046295, l5: 0.046806, l6: 0.047923

[epoch:  67/100000, batch:   166/  187, ite: 6287] train loss: 0.221770, tar: 0.022819 
l0: 0.008665, l1: 0.010052, l2: 0.008457, l3: 0.010652, l4: 0.021404, l5: 0.027606, l6: 0.026063

[epoch:  67/100000, batch:   168/  187, ite: 6288] train loss: 0.221392, tar: 0.022770 
l0: 0.025620, l1: 0.022396, l2: 0.029740, l3: 0.034311, l4: 0.056652, l5: 0.056044, l6: 0.052203

[epoch:  67/100000, batch:   170/  187, ite: 6289] train loss: 0.221585, tar: 0.022780 
l0: 0.012106, l1: 0.013828, l2: 0.019376, l3: 0.014943, l4: 0.035748, l5: 0.027581, l6: 0.021613

[epoch:  67/100000, batch:   172/  187, ite: 6290] train loss: 0.221321, tar: 0.022743 
l0: 0.016889, l1: 0.014811, l2: 0.023733, l3: 0.028418, l4: 0.038430, l5: 0.036651, l6: 0.039333

[epoch:  67/100000, batch:   174/  187, ite: 6291] train loss: 0.221242, tar: 0.022723 
l0: 0.017671, l1: 0.017104, l2: 0.017909, l3: 0.019478, l4: 0.035308, l5: 0.037172, l6: 0.036674

[epoch:  67/100000, batch:   176/  187, ite: 6292] train loss: 0.221105, tar: 0.022706 
l0: 0.012980, l1: 0.014140, l2: 0.012439, l3: 0.015387, l4: 0.027270, l5: 0.025769, l6: 0.027688

[epoch:  67/100000, batch:   178/  187, ite: 6293] train loss: 0.220814, tar: 0.022673 
l0: 0.013592, l1: 0.012708, l2: 0.014819, l3: 0.017355, l4: 0.036053, l5: 0.030542, l6: 0.030004

[epoch:  67/100000, batch:   180/  187, ite: 6294] train loss: 0.220590, tar: 0.022642 
l0: 0.006458, l1: 0.007702, l2: 0.006598, l3: 0.010998, l4: 0.016509, l5: 0.014860, l6: 0.022284

[epoch:  67/100000, batch:   182/  187, ite: 6295] train loss: 0.220132, tar: 0.022587 
l0: 0.015855, l1: 0.018025, l2: 0.026693, l3: 0.017988, l4: 0.036764, l5: 0.033555, l6: 0.035705

[epoch:  67/100000, batch:   184/  187, ite: 6296] train loss: 0.220012, tar: 0.022564 
l0: 0.012614, l1: 0.014007, l2: 0.014731, l3: 0.012721, l4: 0.021779, l5: 0.021968, l6: 0.018718

[epoch:  67/100000, batch:   186/  187, ite: 6297] train loss: 0.219663, tar: 0.022531 
l0: 0.004832, l1: 0.005251, l2: 0.006888, l3: 0.006882, l4: 0.021310, l5: 0.022057, l6: 0.016406

[epoch:  67/100000, batch:   188/  187, ite: 6298] train loss: 0.219207, tar: 0.022471 
l0: 0.030225, l1: 0.034353, l2: 0.037631, l3: 0.030468, l4: 0.034561, l5: 0.033818, l6: 0.035383

[epoch:  68/100000, batch:     2/  187, ite: 6299] train loss: 0.219264, tar: 0.022497 
l0: 0.017203, l1: 0.016828, l2: 0.017607, l3: 0.018079, l4: 0.036991, l5: 0.035525, l6: 0.043970

[epoch:  68/100000, batch:     4/  187, ite: 6300] train loss: 0.219154, tar: 0.022480 
l0: 0.015440, l1: 0.015120, l2: 0.024037, l3: 0.030730, l4: 0.033006, l5: 0.032005, l6: 0.028996

[epoch:  68/100000, batch:     6/  187, ite: 6301] train loss: 0.219022, tar: 0.022456 
l0: 0.020490, l1: 0.021471, l2: 0.020491, l3: 0.021024, l4: 0.042231, l5: 0.041990, l6: 0.042359

[epoch:  68/100000, batch:     8/  187, ite: 6302] train loss: 0.218992, tar: 0.022450 
l0: 0.016880, l1: 0.018171, l2: 0.016225, l3: 0.018208, l4: 0.026163, l5: 0.024096, l6: 0.026990

[epoch:  68/100000, batch:    10/  187, ite: 6303] train loss: 0.218754, tar: 0.022431 
l0: 0.011305, l1: 0.011837, l2: 0.012545, l3: 0.012550, l4: 0.021590, l5: 0.019508, l6: 0.022327

[epoch:  68/100000, batch:    12/  187, ite: 6304] train loss: 0.218401, tar: 0.022395 
l0: 0.020989, l1: 0.022084, l2: 0.021287, l3: 0.021316, l4: 0.036587, l5: 0.041651, l6: 0.042426

[epoch:  68/100000, batch:    14/  187, ite: 6305] train loss: 0.218362, tar: 0.022390 
l0: 0.030525, l1: 0.034657, l2: 0.026337, l3: 0.030385, l4: 0.024433, l5: 0.020613, l6: 0.024816

[epoch:  68/100000, batch:    16/  187, ite: 6306] train loss: 0.218275, tar: 0.022417 
l0: 0.010339, l1: 0.012250, l2: 0.010944, l3: 0.010002, l4: 0.017824, l5: 0.016986, l6: 0.012776

[epoch:  68/100000, batch:    18/  187, ite: 6307] train loss: 0.217861, tar: 0.022377 
l0: 0.018796, l1: 0.017326, l2: 0.021967, l3: 0.023890, l4: 0.044479, l5: 0.050724, l6: 0.051047

[epoch:  68/100000, batch:    20/  187, ite: 6308] train loss: 0.217895, tar: 0.022366 
l0: 0.024533, l1: 0.026050, l2: 0.028464, l3: 0.026920, l4: 0.041344, l5: 0.033825, l6: 0.030496

[epoch:  68/100000, batch:    22/  187, ite: 6309] train loss: 0.217874, tar: 0.022373 
l0: 0.037324, l1: 0.033789, l2: 0.044206, l3: 0.053364, l4: 0.063841, l5: 0.058726, l6: 0.060529

[epoch:  68/100000, batch:    24/  187, ite: 6310] train loss: 0.218306, tar: 0.022421 
l0: 0.007884, l1: 0.007986, l2: 0.011815, l3: 0.011023, l4: 0.027718, l5: 0.026075, l6: 0.025331

[epoch:  68/100000, batch:    26/  187, ite: 6311] train loss: 0.217983, tar: 0.022374 
l0: 0.010691, l1: 0.010560, l2: 0.010695, l3: 0.013074, l4: 0.014746, l5: 0.015815, l6: 0.021657

[epoch:  68/100000, batch:    28/  187, ite: 6312] train loss: 0.217596, tar: 0.022337 
l0: 0.023262, l1: 0.023330, l2: 0.024226, l3: 0.030875, l4: 0.036990, l5: 0.032281, l6: 0.031342

[epoch:  68/100000, batch:    30/  187, ite: 6313] train loss: 0.217547, tar: 0.022340 
l0: 0.012618, l1: 0.013576, l2: 0.019522, l3: 0.020206, l4: 0.027657, l5: 0.023991, l6: 0.023882

[epoch:  68/100000, batch:    32/  187, ite: 6314] train loss: 0.217305, tar: 0.022309 
l0: 0.028489, l1: 0.027122, l2: 0.039932, l3: 0.042156, l4: 0.039938, l5: 0.038049, l6: 0.038976

[epoch:  68/100000, batch:    34/  187, ite: 6315] train loss: 0.217424, tar: 0.022328 
l0: 0.025318, l1: 0.022203, l2: 0.026941, l3: 0.043990, l4: 0.064353, l5: 0.062885, l6: 0.072266

[epoch:  68/100000, batch:    36/  187, ite: 6316] train loss: 0.217742, tar: 0.022338 
l0: 0.024784, l1: 0.025080, l2: 0.017307, l3: 0.023675, l4: 0.027826, l5: 0.026619, l6: 0.031643

[epoch:  68/100000, batch:    38/  187, ite: 6317] train loss: 0.217613, tar: 0.022346 
l0: 0.008796, l1: 0.010004, l2: 0.009561, l3: 0.009030, l4: 0.022792, l5: 0.026996, l6: 0.026078

[epoch:  68/100000, batch:    40/  187, ite: 6318] train loss: 0.217285, tar: 0.022303 
l0: 0.021185, l1: 0.017856, l2: 0.020719, l3: 0.021691, l4: 0.040258, l5: 0.053408, l6: 0.069286

[epoch:  68/100000, batch:    42/  187, ite: 6319] train loss: 0.217370, tar: 0.022299 
l0: 0.015388, l1: 0.014261, l2: 0.018151, l3: 0.020518, l4: 0.032046, l5: 0.034914, l6: 0.035054

[epoch:  68/100000, batch:    44/  187, ite: 6320] train loss: 0.217223, tar: 0.022278 
l0: 0.014045, l1: 0.014476, l2: 0.017501, l3: 0.017926, l4: 0.025035, l5: 0.025983, l6: 0.032056

[epoch:  68/100000, batch:    46/  187, ite: 6321] train loss: 0.217004, tar: 0.022252 
l0: 0.019147, l1: 0.020267, l2: 0.023431, l3: 0.030270, l4: 0.045448, l5: 0.047662, l6: 0.043282

[epoch:  68/100000, batch:    48/  187, ite: 6322] train loss: 0.217043, tar: 0.022243 
l0: 0.019106, l1: 0.017249, l2: 0.022513, l3: 0.025196, l4: 0.045807, l5: 0.057018, l6: 0.046233

[epoch:  68/100000, batch:    50/  187, ite: 6323] train loss: 0.217093, tar: 0.022233 
l0: 0.026400, l1: 0.025806, l2: 0.031624, l3: 0.026040, l4: 0.030784, l5: 0.033145, l6: 0.039258

[epoch:  68/100000, batch:    52/  187, ite: 6324] train loss: 0.217080, tar: 0.022246 
l0: 0.017519, l1: 0.018775, l2: 0.020450, l3: 0.016566, l4: 0.044968, l5: 0.034583, l6: 0.041773

[epoch:  68/100000, batch:    54/  187, ite: 6325] train loss: 0.217011, tar: 0.022231 
l0: 0.013839, l1: 0.013348, l2: 0.016413, l3: 0.020639, l4: 0.022427, l5: 0.023779, l6: 0.023551

[epoch:  68/100000, batch:    56/  187, ite: 6326] train loss: 0.216757, tar: 0.022205 
l0: 0.018883, l1: 0.019349, l2: 0.020484, l3: 0.028895, l4: 0.027318, l5: 0.028012, l6: 0.025091

[epoch:  68/100000, batch:    58/  187, ite: 6327] train loss: 0.216608, tar: 0.022195 
l0: 0.009967, l1: 0.009545, l2: 0.011803, l3: 0.014220, l4: 0.023804, l5: 0.022118, l6: 0.020004

[epoch:  68/100000, batch:    60/  187, ite: 6328] train loss: 0.216287, tar: 0.022158 
l0: 0.015721, l1: 0.017656, l2: 0.014791, l3: 0.023276, l4: 0.020069, l5: 0.017364, l6: 0.017674

[epoch:  68/100000, batch:    62/  187, ite: 6329] train loss: 0.216014, tar: 0.022138 
l0: 0.014754, l1: 0.016155, l2: 0.014928, l3: 0.013668, l4: 0.025577, l5: 0.020863, l6: 0.023565

[epoch:  68/100000, batch:    64/  187, ite: 6330] train loss: 0.215752, tar: 0.022116 
l0: 0.015864, l1: 0.017367, l2: 0.015675, l3: 0.019028, l4: 0.024384, l5: 0.021313, l6: 0.017985

[epoch:  68/100000, batch:    66/  187, ite: 6331] train loss: 0.215498, tar: 0.022097 
l0: 0.020687, l1: 0.022412, l2: 0.024742, l3: 0.023868, l4: 0.032428, l5: 0.026579, l6: 0.032930

[epoch:  68/100000, batch:    68/  187, ite: 6332] train loss: 0.215402, tar: 0.022093 
l0: 0.015502, l1: 0.016211, l2: 0.018321, l3: 0.024182, l4: 0.057744, l5: 0.035505, l6: 0.039491

[epoch:  68/100000, batch:    70/  187, ite: 6333] train loss: 0.215377, tar: 0.022073 
l0: 0.013725, l1: 0.014128, l2: 0.014715, l3: 0.018687, l4: 0.020146, l5: 0.017863, l6: 0.019070

[epoch:  68/100000, batch:    72/  187, ite: 6334] train loss: 0.215086, tar: 0.022048 
l0: 0.021881, l1: 0.024183, l2: 0.016923, l3: 0.021881, l4: 0.045421, l5: 0.033532, l6: 0.035096

[epoch:  68/100000, batch:    74/  187, ite: 6335] train loss: 0.215038, tar: 0.022048 
l0: 0.031076, l1: 0.030387, l2: 0.034154, l3: 0.035322, l4: 0.053506, l5: 0.057346, l6: 0.059013

[epoch:  68/100000, batch:    76/  187, ite: 6336] train loss: 0.215293, tar: 0.022074 
l0: 0.020223, l1: 0.019753, l2: 0.032916, l3: 0.025549, l4: 0.049191, l5: 0.040430, l6: 0.042219

[epoch:  68/100000, batch:    78/  187, ite: 6337] train loss: 0.215338, tar: 0.022069 
l0: 0.018800, l1: 0.017583, l2: 0.024968, l3: 0.027723, l4: 0.029884, l5: 0.029738, l6: 0.032306

[epoch:  68/100000, batch:    80/  187, ite: 6338] train loss: 0.215236, tar: 0.022059 
l0: 0.014539, l1: 0.015836, l2: 0.015647, l3: 0.021148, l4: 0.026924, l5: 0.026674, l6: 0.037562

[epoch:  68/100000, batch:    82/  187, ite: 6339] train loss: 0.215068, tar: 0.022037 
l0: 0.020997, l1: 0.018367, l2: 0.033710, l3: 0.038416, l4: 0.039264, l5: 0.035660, l6: 0.043165

[epoch:  68/100000, batch:    84/  187, ite: 6340] train loss: 0.215111, tar: 0.022034 
l0: 0.011404, l1: 0.012739, l2: 0.013063, l3: 0.012135, l4: 0.020018, l5: 0.019803, l6: 0.024173

[epoch:  68/100000, batch:    86/  187, ite: 6341] train loss: 0.214812, tar: 0.022003 
l0: 0.023775, l1: 0.022832, l2: 0.027288, l3: 0.026519, l4: 0.053787, l5: 0.044795, l6: 0.047651

[epoch:  68/100000, batch:    88/  187, ite: 6342] train loss: 0.214905, tar: 0.022008 
l0: 0.016879, l1: 0.016836, l2: 0.030746, l3: 0.036854, l4: 0.042764, l5: 0.029937, l6: 0.033361

[epoch:  68/100000, batch:    90/  187, ite: 6343] train loss: 0.214883, tar: 0.021993 
l0: 0.012739, l1: 0.014254, l2: 0.011688, l3: 0.012696, l4: 0.033051, l5: 0.037352, l6: 0.039833

[epoch:  68/100000, batch:    92/  187, ite: 6344] train loss: 0.214729, tar: 0.021966 
l0: 0.030397, l1: 0.035516, l2: 0.040948, l3: 0.036234, l4: 0.047661, l5: 0.032644, l6: 0.030350

[epoch:  68/100000, batch:    94/  187, ite: 6345] train loss: 0.214842, tar: 0.021991 
l0: 0.015360, l1: 0.016017, l2: 0.017354, l3: 0.016446, l4: 0.030390, l5: 0.029593, l6: 0.029811

[epoch:  68/100000, batch:    96/  187, ite: 6346] train loss: 0.214669, tar: 0.021971 
l0: 0.017527, l1: 0.015146, l2: 0.017178, l3: 0.033684, l4: 0.085443, l5: 0.076078, l6: 0.077172

[epoch:  68/100000, batch:    98/  187, ite: 6347] train loss: 0.214979, tar: 0.021959 
l0: 0.012602, l1: 0.013870, l2: 0.015363, l3: 0.014435, l4: 0.024233, l5: 0.024369, l6: 0.029216

[epoch:  68/100000, batch:   100/  187, ite: 6348] train loss: 0.214746, tar: 0.021932 
l0: 0.027269, l1: 0.025169, l2: 0.053120, l3: 0.042944, l4: 0.031180, l5: 0.035037, l6: 0.031460

[epoch:  68/100000, batch:   102/  187, ite: 6349] train loss: 0.214836, tar: 0.021947 
l0: 0.036070, l1: 0.029711, l2: 0.047180, l3: 0.060832, l4: 0.083390, l5: 0.080227, l6: 0.090862

[epoch:  68/100000, batch:   104/  187, ite: 6350] train loss: 0.215446, tar: 0.021987 
l0: 0.018206, l1: 0.018621, l2: 0.020661, l3: 0.025787, l4: 0.037553, l5: 0.028600, l6: 0.030299

[epoch:  68/100000, batch:   106/  187, ite: 6351] train loss: 0.215344, tar: 0.021977 
l0: 0.014791, l1: 0.013661, l2: 0.021679, l3: 0.024430, l4: 0.034895, l5: 0.034948, l6: 0.038764

[epoch:  68/100000, batch:   108/  187, ite: 6352] train loss: 0.215253, tar: 0.021956 
l0: 0.022776, l1: 0.022700, l2: 0.029391, l3: 0.030817, l4: 0.035690, l5: 0.038544, l6: 0.042432

[epoch:  68/100000, batch:   110/  187, ite: 6353] train loss: 0.215273, tar: 0.021959 
l0: 0.013779, l1: 0.014377, l2: 0.016633, l3: 0.018312, l4: 0.027823, l5: 0.028211, l6: 0.033692

[epoch:  68/100000, batch:   112/  187, ite: 6354] train loss: 0.215097, tar: 0.021935 
l0: 0.013464, l1: 0.014375, l2: 0.013992, l3: 0.016633, l4: 0.023223, l5: 0.025949, l6: 0.023746

[epoch:  68/100000, batch:   114/  187, ite: 6355] train loss: 0.214861, tar: 0.021912 
l0: 0.020746, l1: 0.021195, l2: 0.024378, l3: 0.025690, l4: 0.047338, l5: 0.048942, l6: 0.044576

[epoch:  68/100000, batch:   116/  187, ite: 6356] train loss: 0.214911, tar: 0.021908 
l0: 0.014629, l1: 0.015072, l2: 0.020028, l3: 0.019024, l4: 0.043807, l5: 0.042510, l6: 0.045921

[epoch:  68/100000, batch:   118/  187, ite: 6357] train loss: 0.214872, tar: 0.021888 
l0: 0.025409, l1: 0.026809, l2: 0.028679, l3: 0.026292, l4: 0.032041, l5: 0.033743, l6: 0.031653

[epoch:  68/100000, batch:   120/  187, ite: 6358] train loss: 0.214844, tar: 0.021898 
l0: 0.017430, l1: 0.019759, l2: 0.018837, l3: 0.018083, l4: 0.038568, l5: 0.034376, l6: 0.040111

[epoch:  68/100000, batch:   122/  187, ite: 6359] train loss: 0.214767, tar: 0.021885 
l0: 0.015031, l1: 0.016149, l2: 0.016076, l3: 0.014951, l4: 0.028424, l5: 0.028693, l6: 0.027679

[epoch:  68/100000, batch:   124/  187, ite: 6360] train loss: 0.214578, tar: 0.021866 
l0: 0.014421, l1: 0.015522, l2: 0.014712, l3: 0.014822, l4: 0.022808, l5: 0.021789, l6: 0.030078

[epoch:  68/100000, batch:   126/  187, ite: 6361] train loss: 0.214356, tar: 0.021846 
l0: 0.016320, l1: 0.016134, l2: 0.021143, l3: 0.019325, l4: 0.033039, l5: 0.030628, l6: 0.030211

[epoch:  68/100000, batch:   128/  187, ite: 6362] train loss: 0.214224, tar: 0.021830 
l0: 0.020893, l1: 0.021138, l2: 0.022969, l3: 0.023589, l4: 0.032472, l5: 0.030336, l6: 0.030556

[epoch:  68/100000, batch:   130/  187, ite: 6363] train loss: 0.214135, tar: 0.021828 
l0: 0.014929, l1: 0.017032, l2: 0.020435, l3: 0.022384, l4: 0.053421, l5: 0.051257, l6: 0.041990

[epoch:  68/100000, batch:   132/  187, ite: 6364] train loss: 0.214155, tar: 0.021809 
l0: 0.024554, l1: 0.022518, l2: 0.041976, l3: 0.038347, l4: 0.034578, l5: 0.037996, l6: 0.041756

[epoch:  68/100000, batch:   134/  187, ite: 6365] train loss: 0.214231, tar: 0.021816 
l0: 0.015343, l1: 0.013997, l2: 0.020465, l3: 0.019638, l4: 0.028617, l5: 0.034159, l6: 0.033608

[epoch:  68/100000, batch:   136/  187, ite: 6366] train loss: 0.214099, tar: 0.021799 
l0: 0.023877, l1: 0.024528, l2: 0.029842, l3: 0.028034, l4: 0.040780, l5: 0.045756, l6: 0.041033

[epoch:  68/100000, batch:   138/  187, ite: 6367] train loss: 0.214152, tar: 0.021804 
l0: 0.017657, l1: 0.019708, l2: 0.017432, l3: 0.017330, l4: 0.035712, l5: 0.041781, l6: 0.041968

[epoch:  68/100000, batch:   140/  187, ite: 6368] train loss: 0.214091, tar: 0.021793 
l0: 0.018192, l1: 0.016741, l2: 0.026197, l3: 0.028621, l4: 0.046653, l5: 0.042444, l6: 0.040433

[epoch:  68/100000, batch:   142/  187, ite: 6369] train loss: 0.214105, tar: 0.021783 
l0: 0.016527, l1: 0.016563, l2: 0.019648, l3: 0.019369, l4: 0.026124, l5: 0.022891, l6: 0.033761

[epoch:  68/100000, batch:   144/  187, ite: 6370] train loss: 0.213945, tar: 0.021769 
l0: 0.011576, l1: 0.010575, l2: 0.016755, l3: 0.019498, l4: 0.037628, l5: 0.046619, l6: 0.033984

[epoch:  68/100000, batch:   146/  187, ite: 6371] train loss: 0.213845, tar: 0.021742 
l0: 0.035430, l1: 0.035836, l2: 0.033499, l3: 0.033859, l4: 0.036840, l5: 0.048492, l6: 0.059618

[epoch:  68/100000, batch:   148/  187, ite: 6372] train loss: 0.214032, tar: 0.021778 
l0: 0.020629, l1: 0.022396, l2: 0.022666, l3: 0.021452, l4: 0.040922, l5: 0.032162, l6: 0.033843

[epoch:  68/100000, batch:   150/  187, ite: 6373] train loss: 0.213979, tar: 0.021775 
l0: 0.023392, l1: 0.025495, l2: 0.021800, l3: 0.019822, l4: 0.034071, l5: 0.034319, l6: 0.038441

[epoch:  68/100000, batch:   152/  187, ite: 6374] train loss: 0.213934, tar: 0.021780 
l0: 0.024764, l1: 0.027663, l2: 0.022879, l3: 0.023547, l4: 0.039017, l5: 0.041458, l6: 0.035894

[epoch:  68/100000, batch:   154/  187, ite: 6375] train loss: 0.213937, tar: 0.021788 
l0: 0.011982, l1: 0.012567, l2: 0.012394, l3: 0.012322, l4: 0.033305, l5: 0.035279, l6: 0.052334

[epoch:  68/100000, batch:   156/  187, ite: 6376] train loss: 0.213821, tar: 0.021762 
l0: 0.017259, l1: 0.018256, l2: 0.021470, l3: 0.021033, l4: 0.025313, l5: 0.034562, l6: 0.028081

[epoch:  68/100000, batch:   158/  187, ite: 6377] train loss: 0.213694, tar: 0.021750 
l0: 0.024211, l1: 0.022378, l2: 0.032396, l3: 0.040017, l4: 0.064118, l5: 0.066047, l6: 0.056222

[epoch:  68/100000, batch:   160/  187, ite: 6378] train loss: 0.213937, tar: 0.021756 
l0: 0.015168, l1: 0.012068, l2: 0.020070, l3: 0.025877, l4: 0.031248, l5: 0.036813, l6: 0.044889

[epoch:  68/100000, batch:   162/  187, ite: 6379] train loss: 0.213863, tar: 0.021739 
l0: 0.017792, l1: 0.019068, l2: 0.019063, l3: 0.018954, l4: 0.041824, l5: 0.048595, l6: 0.047269

[epoch:  68/100000, batch:   164/  187, ite: 6380] train loss: 0.213860, tar: 0.021728 
l0: 0.015676, l1: 0.015052, l2: 0.015446, l3: 0.016513, l4: 0.034566, l5: 0.044081, l6: 0.035971

[epoch:  68/100000, batch:   166/  187, ite: 6381] train loss: 0.213764, tar: 0.021712 
l0: 0.045509, l1: 0.049382, l2: 0.049404, l3: 0.049374, l4: 0.026180, l5: 0.031140, l6: 0.042322

[epoch:  68/100000, batch:   168/  187, ite: 6382] train loss: 0.213972, tar: 0.021775 
l0: 0.015118, l1: 0.014158, l2: 0.018745, l3: 0.017282, l4: 0.025826, l5: 0.025736, l6: 0.030264

[epoch:  68/100000, batch:   170/  187, ite: 6383] train loss: 0.213798, tar: 0.021757 
l0: 0.023751, l1: 0.026214, l2: 0.026877, l3: 0.024486, l4: 0.037058, l5: 0.043075, l6: 0.045474

[epoch:  68/100000, batch:   172/  187, ite: 6384] train loss: 0.213832, tar: 0.021763 
l0: 0.020460, l1: 0.020263, l2: 0.022903, l3: 0.024042, l4: 0.034122, l5: 0.036043, l6: 0.039754

[epoch:  68/100000, batch:   174/  187, ite: 6385] train loss: 0.213790, tar: 0.021759 
l0: 0.009912, l1: 0.009975, l2: 0.012480, l3: 0.012554, l4: 0.021411, l5: 0.018610, l6: 0.020782

[epoch:  68/100000, batch:   176/  187, ite: 6386] train loss: 0.213510, tar: 0.021729 
l0: 0.026132, l1: 0.028501, l2: 0.025489, l3: 0.027891, l4: 0.042480, l5: 0.037721, l6: 0.043031

[epoch:  68/100000, batch:   178/  187, ite: 6387] train loss: 0.213556, tar: 0.021740 
l0: 0.018262, l1: 0.017793, l2: 0.021866, l3: 0.027501, l4: 0.027862, l5: 0.029021, l6: 0.023815

[epoch:  68/100000, batch:   180/  187, ite: 6388] train loss: 0.213433, tar: 0.021731 
l0: 0.008788, l1: 0.008887, l2: 0.030959, l3: 0.030412, l4: 0.027865, l5: 0.022347, l6: 0.018566

[epoch:  68/100000, batch:   182/  187, ite: 6389] train loss: 0.213265, tar: 0.021698 
l0: 0.017956, l1: 0.017278, l2: 0.017523, l3: 0.022388, l4: 0.031727, l5: 0.035234, l6: 0.037659

[epoch:  68/100000, batch:   184/  187, ite: 6390] train loss: 0.213179, tar: 0.021688 
l0: 0.025144, l1: 0.021154, l2: 0.034785, l3: 0.044119, l4: 0.097678, l5: 0.079002, l6: 0.072700

[epoch:  68/100000, batch:   186/  187, ite: 6391] train loss: 0.213592, tar: 0.021697 
l0: 0.010880, l1: 0.010406, l2: 0.026018, l3: 0.027572, l4: 0.025901, l5: 0.027063, l6: 0.015455

[epoch:  68/100000, batch:   188/  187, ite: 6392] train loss: 0.213412, tar: 0.021669 
l0: 0.027446, l1: 0.027049, l2: 0.025743, l3: 0.030134, l4: 0.058984, l5: 0.050199, l6: 0.058762

[epoch:  69/100000, batch:     2/  187, ite: 6393] train loss: 0.213577, tar: 0.021684 
l0: 0.012807, l1: 0.011852, l2: 0.021059, l3: 0.021867, l4: 0.019905, l5: 0.025247, l6: 0.027110

[epoch:  69/100000, batch:     4/  187, ite: 6394] train loss: 0.213390, tar: 0.021661 
l0: 0.011037, l1: 0.011355, l2: 0.018052, l3: 0.022912, l4: 0.024086, l5: 0.031547, l6: 0.032124

[epoch:  69/100000, batch:     6/  187, ite: 6395] train loss: 0.213233, tar: 0.021635 
l0: 0.020027, l1: 0.021828, l2: 0.024861, l3: 0.022591, l4: 0.030753, l5: 0.026441, l6: 0.035565

[epoch:  69/100000, batch:     8/  187, ite: 6396] train loss: 0.213154, tar: 0.021631 
l0: 0.012731, l1: 0.014057, l2: 0.017290, l3: 0.019209, l4: 0.031267, l5: 0.027568, l6: 0.028584

[epoch:  69/100000, batch:    10/  187, ite: 6397] train loss: 0.212997, tar: 0.021608 
l0: 0.021188, l1: 0.021600, l2: 0.019661, l3: 0.022620, l4: 0.029238, l5: 0.029277, l6: 0.030396

[epoch:  69/100000, batch:    12/  187, ite: 6398] train loss: 0.212899, tar: 0.021607 
l0: 0.026872, l1: 0.034455, l2: 0.014404, l3: 0.018139, l4: 0.037410, l5: 0.039017, l6: 0.031161

[epoch:  69/100000, batch:    14/  187, ite: 6399] train loss: 0.212870, tar: 0.021620 
l0: 0.010208, l1: 0.010792, l2: 0.013941, l3: 0.014794, l4: 0.019907, l5: 0.020481, l6: 0.036464

[epoch:  69/100000, batch:    16/  187, ite: 6400] train loss: 0.212654, tar: 0.021592 
l0: 0.016515, l1: 0.016617, l2: 0.016986, l3: 0.019477, l4: 0.027933, l5: 0.035330, l6: 0.036459

[epoch:  69/100000, batch:    18/  187, ite: 6401] train loss: 0.212546, tar: 0.021579 
l0: 0.023728, l1: 0.022524, l2: 0.026829, l3: 0.026211, l4: 0.045352, l5: 0.051194, l6: 0.055207

[epoch:  69/100000, batch:    20/  187, ite: 6402] train loss: 0.212642, tar: 0.021584 
l0: 0.014199, l1: 0.015652, l2: 0.016559, l3: 0.015407, l4: 0.022362, l5: 0.022957, l6: 0.023357

[epoch:  69/100000, batch:    22/  187, ite: 6403] train loss: 0.212438, tar: 0.021566 
l0: 0.011642, l1: 0.013054, l2: 0.010469, l3: 0.012725, l4: 0.037896, l5: 0.032066, l6: 0.031309

[epoch:  69/100000, batch:    24/  187, ite: 6404] train loss: 0.212281, tar: 0.021541 
l0: 0.014441, l1: 0.013983, l2: 0.018396, l3: 0.020629, l4: 0.027216, l5: 0.032605, l6: 0.041963

[epoch:  69/100000, batch:    26/  187, ite: 6405] train loss: 0.212175, tar: 0.021524 
l0: 0.020328, l1: 0.024666, l2: 0.021147, l3: 0.017172, l4: 0.029082, l5: 0.025254, l6: 0.030869

[epoch:  69/100000, batch:    28/  187, ite: 6406] train loss: 0.212068, tar: 0.021521 
l0: 0.021477, l1: 0.022794, l2: 0.020931, l3: 0.019137, l4: 0.032889, l5: 0.033870, l6: 0.042865

[epoch:  69/100000, batch:    30/  187, ite: 6407] train loss: 0.212023, tar: 0.021521 
l0: 0.018641, l1: 0.019916, l2: 0.021131, l3: 0.018613, l4: 0.042908, l5: 0.037384, l6: 0.051524

[epoch:  69/100000, batch:    32/  187, ite: 6408] train loss: 0.212018, tar: 0.021514 
l0: 0.009971, l1: 0.010706, l2: 0.009802, l3: 0.011284, l4: 0.027275, l5: 0.025770, l6: 0.029269

[epoch:  69/100000, batch:    34/  187, ite: 6409] train loss: 0.211803, tar: 0.021486 
l0: 0.019799, l1: 0.022004, l2: 0.017207, l3: 0.018498, l4: 0.026748, l5: 0.026425, l6: 0.023797

[epoch:  69/100000, batch:    36/  187, ite: 6410] train loss: 0.211664, tar: 0.021482 
l0: 0.018520, l1: 0.022655, l2: 0.018353, l3: 0.018098, l4: 0.026500, l5: 0.031828, l6: 0.025322

[epoch:  69/100000, batch:    38/  187, ite: 6411] train loss: 0.211541, tar: 0.021474 
l0: 0.019121, l1: 0.018085, l2: 0.021300, l3: 0.025455, l4: 0.028009, l5: 0.028604, l6: 0.028537

[epoch:  69/100000, batch:    40/  187, ite: 6412] train loss: 0.211438, tar: 0.021469 
l0: 0.023700, l1: 0.022124, l2: 0.030939, l3: 0.034151, l4: 0.030193, l5: 0.030633, l6: 0.027897

[epoch:  69/100000, batch:    42/  187, ite: 6413] train loss: 0.211409, tar: 0.021474 
l0: 0.015204, l1: 0.015470, l2: 0.015279, l3: 0.016844, l4: 0.029479, l5: 0.031035, l6: 0.037784

[epoch:  69/100000, batch:    44/  187, ite: 6414] train loss: 0.211288, tar: 0.021459 
l0: 0.011975, l1: 0.011738, l2: 0.012083, l3: 0.011757, l4: 0.023634, l5: 0.028977, l6: 0.031864

[epoch:  69/100000, batch:    46/  187, ite: 6415] train loss: 0.211097, tar: 0.021436 
l0: 0.013972, l1: 0.015137, l2: 0.019263, l3: 0.021500, l4: 0.047971, l5: 0.038711, l6: 0.033077

[epoch:  69/100000, batch:    48/  187, ite: 6416] train loss: 0.211045, tar: 0.021418 
l0: 0.022646, l1: 0.022419, l2: 0.026085, l3: 0.027722, l4: 0.060070, l5: 0.055806, l6: 0.045256

[epoch:  69/100000, batch:    50/  187, ite: 6417] train loss: 0.211163, tar: 0.021421 
l0: 0.017451, l1: 0.015932, l2: 0.025341, l3: 0.026513, l4: 0.046219, l5: 0.045082, l6: 0.041010

[epoch:  69/100000, batch:    52/  187, ite: 6418] train loss: 0.211178, tar: 0.021412 
l0: 0.023002, l1: 0.022832, l2: 0.029113, l3: 0.031711, l4: 0.044434, l5: 0.043216, l6: 0.034131

[epoch:  69/100000, batch:    54/  187, ite: 6419] train loss: 0.211219, tar: 0.021415 
l0: 0.018636, l1: 0.017793, l2: 0.019157, l3: 0.022939, l4: 0.041042, l5: 0.037196, l6: 0.044420

[epoch:  69/100000, batch:    56/  187, ite: 6420] train loss: 0.211195, tar: 0.021409 
l0: 0.012270, l1: 0.012057, l2: 0.014922, l3: 0.014715, l4: 0.021510, l5: 0.025152, l6: 0.027069

[epoch:  69/100000, batch:    58/  187, ite: 6421] train loss: 0.210997, tar: 0.021387 
l0: 0.036803, l1: 0.035396, l2: 0.033020, l3: 0.040645, l4: 0.066728, l5: 0.061697, l6: 0.090233

[epoch:  69/100000, batch:    60/  187, ite: 6422] train loss: 0.211361, tar: 0.021424 
l0: 0.016893, l1: 0.017416, l2: 0.018683, l3: 0.016972, l4: 0.033266, l5: 0.035155, l6: 0.036340

[epoch:  69/100000, batch:    62/  187, ite: 6423] train loss: 0.211274, tar: 0.021413 
l0: 0.022881, l1: 0.023992, l2: 0.026709, l3: 0.027557, l4: 0.027712, l5: 0.027113, l6: 0.034215

[epoch:  69/100000, batch:    64/  187, ite: 6424] train loss: 0.211224, tar: 0.021416 
l0: 0.014845, l1: 0.014885, l2: 0.018808, l3: 0.018246, l4: 0.024772, l5: 0.024394, l6: 0.023232

[epoch:  69/100000, batch:    66/  187, ite: 6425] train loss: 0.211055, tar: 0.021401 
l0: 0.016409, l1: 0.017359, l2: 0.020654, l3: 0.020125, l4: 0.034940, l5: 0.037686, l6: 0.037731

[epoch:  69/100000, batch:    68/  187, ite: 6426] train loss: 0.210994, tar: 0.021389 
l0: 0.028549, l1: 0.026916, l2: 0.035589, l3: 0.034131, l4: 0.056373, l5: 0.056763, l6: 0.062266

[epoch:  69/100000, batch:    70/  187, ite: 6427] train loss: 0.211203, tar: 0.021406 
l0: 0.012555, l1: 0.011942, l2: 0.015820, l3: 0.019456, l4: 0.023124, l5: 0.022651, l6: 0.025766

[epoch:  69/100000, batch:    72/  187, ite: 6428] train loss: 0.211017, tar: 0.021385 
l0: 0.026632, l1: 0.022861, l2: 0.026817, l3: 0.042429, l4: 0.077788, l5: 0.069410, l6: 0.085687

[epoch:  69/100000, batch:    74/  187, ite: 6429] train loss: 0.211344, tar: 0.021397 
l0: 0.025680, l1: 0.027057, l2: 0.037817, l3: 0.032930, l4: 0.036791, l5: 0.037112, l6: 0.040952

[epoch:  69/100000, batch:    76/  187, ite: 6430] train loss: 0.211407, tar: 0.021407 
l0: 0.016265, l1: 0.015824, l2: 0.018729, l3: 0.021543, l4: 0.034953, l5: 0.033744, l6: 0.039449

[epoch:  69/100000, batch:    78/  187, ite: 6431] train loss: 0.211336, tar: 0.021395 
l0: 0.023315, l1: 0.026131, l2: 0.022018, l3: 0.021701, l4: 0.035294, l5: 0.035021, l6: 0.032500

[epoch:  69/100000, batch:    80/  187, ite: 6432] train loss: 0.211300, tar: 0.021400 
l0: 0.015602, l1: 0.015060, l2: 0.020739, l3: 0.021742, l4: 0.029403, l5: 0.027833, l6: 0.027732

[epoch:  69/100000, batch:    82/  187, ite: 6433] train loss: 0.211177, tar: 0.021386 
l0: 0.019989, l1: 0.023289, l2: 0.024159, l3: 0.020547, l4: 0.051927, l5: 0.041999, l6: 0.039160

[epoch:  69/100000, batch:    84/  187, ite: 6434] train loss: 0.211200, tar: 0.021383 
l0: 0.019623, l1: 0.019534, l2: 0.018332, l3: 0.021505, l4: 0.033038, l5: 0.034473, l6: 0.038388

[epoch:  69/100000, batch:    86/  187, ite: 6435] train loss: 0.211139, tar: 0.021379 
l0: 0.015875, l1: 0.017309, l2: 0.020811, l3: 0.025125, l4: 0.052523, l5: 0.035393, l6: 0.038911

[epoch:  69/100000, batch:    88/  187, ite: 6436] train loss: 0.211128, tar: 0.021367 
l0: 0.016066, l1: 0.016439, l2: 0.015578, l3: 0.016970, l4: 0.031631, l5: 0.031465, l6: 0.024418

[epoch:  69/100000, batch:    90/  187, ite: 6437] train loss: 0.210994, tar: 0.021354 
l0: 0.012874, l1: 0.014405, l2: 0.015452, l3: 0.014329, l4: 0.019154, l5: 0.018637, l6: 0.019995

[epoch:  69/100000, batch:    92/  187, ite: 6438] train loss: 0.210774, tar: 0.021335 
l0: 0.021865, l1: 0.022895, l2: 0.021226, l3: 0.022618, l4: 0.028775, l5: 0.028557, l6: 0.032623

[epoch:  69/100000, batch:    94/  187, ite: 6439] train loss: 0.210701, tar: 0.021336 
l0: 0.015358, l1: 0.016328, l2: 0.021353, l3: 0.016594, l4: 0.025305, l5: 0.024190, l6: 0.037836

[epoch:  69/100000, batch:    96/  187, ite: 6440] train loss: 0.210579, tar: 0.021323 
l0: 0.021402, l1: 0.023948, l2: 0.024275, l3: 0.023206, l4: 0.038545, l5: 0.033099, l6: 0.035417

[epoch:  69/100000, batch:    98/  187, ite: 6441] train loss: 0.210554, tar: 0.021323 
l0: 0.025193, l1: 0.027009, l2: 0.023753, l3: 0.024185, l4: 0.057758, l5: 0.058475, l6: 0.052000

[epoch:  69/100000, batch:   100/  187, ite: 6442] train loss: 0.210685, tar: 0.021332 
l0: 0.019466, l1: 0.018200, l2: 0.017383, l3: 0.022936, l4: 0.056014, l5: 0.058685, l6: 0.062910

[epoch:  69/100000, batch:   102/  187, ite: 6443] train loss: 0.210786, tar: 0.021327 
l0: 0.010438, l1: 0.010637, l2: 0.011222, l3: 0.012243, l4: 0.021100, l5: 0.019045, l6: 0.017667

[epoch:  69/100000, batch:   104/  187, ite: 6444] train loss: 0.210542, tar: 0.021303 
l0: 0.019175, l1: 0.019904, l2: 0.020455, l3: 0.021720, l4: 0.025927, l5: 0.025984, l6: 0.022641

[epoch:  69/100000, batch:   106/  187, ite: 6445] train loss: 0.210419, tar: 0.021298 
l0: 0.018248, l1: 0.017757, l2: 0.021103, l3: 0.021517, l4: 0.039102, l5: 0.032271, l6: 0.037453

[epoch:  69/100000, batch:   108/  187, ite: 6446] train loss: 0.210368, tar: 0.021291 
l0: 0.015238, l1: 0.017974, l2: 0.013067, l3: 0.013990, l4: 0.023150, l5: 0.017190, l6: 0.015926

[epoch:  69/100000, batch:   110/  187, ite: 6447] train loss: 0.210158, tar: 0.021278 
l0: 0.021021, l1: 0.018535, l2: 0.036489, l3: 0.035965, l4: 0.030340, l5: 0.031461, l6: 0.032943

[epoch:  69/100000, batch:   112/  187, ite: 6448] train loss: 0.210150, tar: 0.021277 
l0: 0.013959, l1: 0.013876, l2: 0.017772, l3: 0.019363, l4: 0.042067, l5: 0.039042, l6: 0.039203

[epoch:  69/100000, batch:   114/  187, ite: 6449] train loss: 0.210095, tar: 0.021261 
l0: 0.017363, l1: 0.017597, l2: 0.021699, l3: 0.023238, l4: 0.028584, l5: 0.026655, l6: 0.031741

[epoch:  69/100000, batch:   116/  187, ite: 6450] train loss: 0.209999, tar: 0.021252 
l0: 0.016463, l1: 0.018356, l2: 0.014858, l3: 0.016151, l4: 0.028163, l5: 0.023980, l6: 0.022240

[epoch:  69/100000, batch:   118/  187, ite: 6451] train loss: 0.209844, tar: 0.021242 
l0: 0.025328, l1: 0.028032, l2: 0.025291, l3: 0.023733, l4: 0.046887, l5: 0.043506, l6: 0.042898

[epoch:  69/100000, batch:   120/  187, ite: 6452] train loss: 0.209901, tar: 0.021251 
l0: 0.012184, l1: 0.011826, l2: 0.013449, l3: 0.015659, l4: 0.022280, l5: 0.023656, l6: 0.019189

[epoch:  69/100000, batch:   122/  187, ite: 6453] train loss: 0.209699, tar: 0.021231 
l0: 0.016147, l1: 0.016255, l2: 0.021212, l3: 0.021587, l4: 0.026877, l5: 0.026103, l6: 0.025806

[epoch:  69/100000, batch:   124/  187, ite: 6454] train loss: 0.209576, tar: 0.021219 
l0: 0.015234, l1: 0.016166, l2: 0.016971, l3: 0.016592, l4: 0.023214, l5: 0.023351, l6: 0.024983

[epoch:  69/100000, batch:   126/  187, ite: 6455] train loss: 0.209416, tar: 0.021206 
l0: 0.014469, l1: 0.014624, l2: 0.018041, l3: 0.017704, l4: 0.024200, l5: 0.023502, l6: 0.027164

[epoch:  69/100000, batch:   128/  187, ite: 6456] train loss: 0.209263, tar: 0.021192 
l0: 0.016092, l1: 0.020217, l2: 0.025857, l3: 0.018058, l4: 0.024147, l5: 0.031435, l6: 0.036468

[epoch:  69/100000, batch:   130/  187, ite: 6457] train loss: 0.209182, tar: 0.021180 
l0: 0.018647, l1: 0.017484, l2: 0.024989, l3: 0.025832, l4: 0.040864, l5: 0.045089, l6: 0.043409

[epoch:  69/100000, batch:   132/  187, ite: 6458] train loss: 0.209197, tar: 0.021175 
l0: 0.013192, l1: 0.012899, l2: 0.018184, l3: 0.022869, l4: 0.034243, l5: 0.031394, l6: 0.038797

[epoch:  69/100000, batch:   134/  187, ite: 6459] train loss: 0.209115, tar: 0.021157 
l0: 0.006674, l1: 0.007101, l2: 0.007457, l3: 0.007075, l4: 0.013264, l5: 0.013223, l6: 0.012187

[epoch:  69/100000, batch:   136/  187, ite: 6460] train loss: 0.208806, tar: 0.021126 
l0: 0.012739, l1: 0.014318, l2: 0.013940, l3: 0.012150, l4: 0.031189, l5: 0.032757, l6: 0.032732

[epoch:  69/100000, batch:   138/  187, ite: 6461] train loss: 0.208678, tar: 0.021108 
l0: 0.014366, l1: 0.015205, l2: 0.020338, l3: 0.018449, l4: 0.019018, l5: 0.018744, l6: 0.026619

[epoch:  69/100000, batch:   140/  187, ite: 6462] train loss: 0.208514, tar: 0.021093 
l0: 0.017523, l1: 0.017997, l2: 0.024951, l3: 0.022996, l4: 0.033722, l5: 0.031660, l6: 0.035389

[epoch:  69/100000, batch:   142/  187, ite: 6463] train loss: 0.208462, tar: 0.021085 
l0: 0.049312, l1: 0.051230, l2: 0.061199, l3: 0.057257, l4: 0.071273, l5: 0.065441, l6: 0.060307

[epoch:  69/100000, batch:   144/  187, ite: 6464] train loss: 0.208909, tar: 0.021146 
l0: 0.028547, l1: 0.026833, l2: 0.031336, l3: 0.032336, l4: 0.032532, l5: 0.040869, l6: 0.041641

[epoch:  69/100000, batch:   146/  187, ite: 6465] train loss: 0.208963, tar: 0.021162 
l0: 0.015297, l1: 0.015401, l2: 0.017926, l3: 0.019401, l4: 0.038048, l5: 0.040288, l6: 0.044343

[epoch:  69/100000, batch:   148/  187, ite: 6466] train loss: 0.208924, tar: 0.021150 
l0: 0.013148, l1: 0.015044, l2: 0.015963, l3: 0.015162, l4: 0.015290, l5: 0.015075, l6: 0.018259

[epoch:  69/100000, batch:   150/  187, ite: 6467] train loss: 0.208708, tar: 0.021132 
l0: 0.037029, l1: 0.037579, l2: 0.041715, l3: 0.038543, l4: 0.037601, l5: 0.038774, l6: 0.044402

[epoch:  69/100000, batch:   152/  187, ite: 6468] train loss: 0.208851, tar: 0.021166 
l0: 0.022323, l1: 0.022305, l2: 0.021218, l3: 0.020511, l4: 0.039225, l5: 0.044144, l6: 0.039492

[epoch:  69/100000, batch:   154/  187, ite: 6469] train loss: 0.208852, tar: 0.021169 
l0: 0.010424, l1: 0.013942, l2: 0.018992, l3: 0.014661, l4: 0.027275, l5: 0.022720, l6: 0.025374

[epoch:  69/100000, batch:   156/  187, ite: 6470] train loss: 0.208691, tar: 0.021146 
l0: 0.017482, l1: 0.017633, l2: 0.021315, l3: 0.022904, l4: 0.025473, l5: 0.025830, l6: 0.026118

[epoch:  69/100000, batch:   158/  187, ite: 6471] train loss: 0.208581, tar: 0.021138 
l0: 0.017045, l1: 0.018348, l2: 0.017491, l3: 0.020034, l4: 0.030871, l5: 0.025012, l6: 0.032624

[epoch:  69/100000, batch:   160/  187, ite: 6472] train loss: 0.208481, tar: 0.021130 
l0: 0.019494, l1: 0.018371, l2: 0.024675, l3: 0.027226, l4: 0.030141, l5: 0.031186, l6: 0.029711

[epoch:  69/100000, batch:   162/  187, ite: 6473] train loss: 0.208422, tar: 0.021126 
l0: 0.014520, l1: 0.014829, l2: 0.015329, l3: 0.017397, l4: 0.036372, l5: 0.037079, l6: 0.034734

[epoch:  69/100000, batch:   164/  187, ite: 6474] train loss: 0.208342, tar: 0.021112 
l0: 0.007733, l1: 0.010131, l2: 0.009907, l3: 0.007727, l4: 0.016675, l5: 0.014352, l6: 0.016079

[epoch:  69/100000, batch:   166/  187, ite: 6475] train loss: 0.208077, tar: 0.021084 
l0: 0.024062, l1: 0.023165, l2: 0.035272, l3: 0.032825, l4: 0.055530, l5: 0.055374, l6: 0.057874

[epoch:  69/100000, batch:   168/  187, ite: 6476] train loss: 0.208237, tar: 0.021090 
l0: 0.012858, l1: 0.011605, l2: 0.013031, l3: 0.015608, l4: 0.048286, l5: 0.046945, l6: 0.051469

[epoch:  69/100000, batch:   170/  187, ite: 6477] train loss: 0.208219, tar: 0.021073 
l0: 0.021512, l1: 0.022907, l2: 0.026627, l3: 0.023921, l4: 0.029739, l5: 0.039071, l6: 0.056736

[epoch:  69/100000, batch:   172/  187, ite: 6478] train loss: 0.208245, tar: 0.021074 
l0: 0.013134, l1: 0.013359, l2: 0.018785, l3: 0.018411, l4: 0.035387, l5: 0.038679, l6: 0.032615

[epoch:  69/100000, batch:   174/  187, ite: 6479] train loss: 0.208166, tar: 0.021057 
l0: 0.013109, l1: 0.013102, l2: 0.016079, l3: 0.017434, l4: 0.028327, l5: 0.023994, l6: 0.022573

[epoch:  69/100000, batch:   176/  187, ite: 6480] train loss: 0.208013, tar: 0.021041 
l0: 0.011857, l1: 0.011966, l2: 0.015130, l3: 0.015311, l4: 0.027753, l5: 0.026501, l6: 0.034656

[epoch:  69/100000, batch:   178/  187, ite: 6481] train loss: 0.207878, tar: 0.021022 
l0: 0.019924, l1: 0.019387, l2: 0.023741, l3: 0.022912, l4: 0.050815, l5: 0.050230, l6: 0.048833

[epoch:  69/100000, batch:   180/  187, ite: 6482] train loss: 0.207936, tar: 0.021019 
l0: 0.012715, l1: 0.013447, l2: 0.013906, l3: 0.011138, l4: 0.027584, l5: 0.029959, l6: 0.028024

[epoch:  69/100000, batch:   182/  187, ite: 6483] train loss: 0.207788, tar: 0.021002 
l0: 0.009755, l1: 0.009994, l2: 0.009958, l3: 0.011752, l4: 0.029373, l5: 0.025472, l6: 0.030272

[epoch:  69/100000, batch:   184/  187, ite: 6484] train loss: 0.207621, tar: 0.020979 
l0: 0.016204, l1: 0.016060, l2: 0.020802, l3: 0.019506, l4: 0.034920, l5: 0.030326, l6: 0.029249

[epoch:  69/100000, batch:   186/  187, ite: 6485] train loss: 0.207537, tar: 0.020969 
l0: 0.012215, l1: 0.012144, l2: 0.013739, l3: 0.015446, l4: 0.023722, l5: 0.024467, l6: 0.026268

[epoch:  69/100000, batch:   188/  187, ite: 6486] train loss: 0.207373, tar: 0.020951 
l0: 0.016649, l1: 0.019511, l2: 0.020058, l3: 0.016929, l4: 0.023532, l5: 0.026984, l6: 0.027210

[epoch:  70/100000, batch:     2/  187, ite: 6487] train loss: 0.207257, tar: 0.020942 
l0: 0.017578, l1: 0.018158, l2: 0.021981, l3: 0.019733, l4: 0.037556, l5: 0.039284, l6: 0.039057

[epoch:  70/100000, batch:     4/  187, ite: 6488] train loss: 0.207229, tar: 0.020935 
l0: 0.010149, l1: 0.011329, l2: 0.010905, l3: 0.011520, l4: 0.018422, l5: 0.021420, l6: 0.025130

[epoch:  70/100000, batch:     6/  187, ite: 6489] train loss: 0.207028, tar: 0.020913 
l0: 0.008961, l1: 0.008690, l2: 0.015449, l3: 0.017281, l4: 0.013130, l5: 0.012059, l6: 0.011849

[epoch:  70/100000, batch:     8/  187, ite: 6490] train loss: 0.206784, tar: 0.020889 
l0: 0.013790, l1: 0.014862, l2: 0.021530, l3: 0.022428, l4: 0.049702, l5: 0.036159, l6: 0.030764

[epoch:  70/100000, batch:    10/  187, ite: 6491] train loss: 0.206748, tar: 0.020875 
l0: 0.018943, l1: 0.018571, l2: 0.025608, l3: 0.029140, l4: 0.046547, l5: 0.043293, l6: 0.037018

[epoch:  70/100000, batch:    12/  187, ite: 6492] train loss: 0.206773, tar: 0.020871 
l0: 0.011899, l1: 0.011884, l2: 0.013933, l3: 0.014260, l4: 0.021779, l5: 0.025500, l6: 0.023819

[epoch:  70/100000, batch:    14/  187, ite: 6493] train loss: 0.206603, tar: 0.020852 
l0: 0.015824, l1: 0.017164, l2: 0.018599, l3: 0.017092, l4: 0.023533, l5: 0.022923, l6: 0.023772

[epoch:  70/100000, batch:    16/  187, ite: 6494] train loss: 0.206466, tar: 0.020842 
l0: 0.018736, l1: 0.019075, l2: 0.022048, l3: 0.022370, l4: 0.029256, l5: 0.027966, l6: 0.030269

[epoch:  70/100000, batch:    18/  187, ite: 6495] train loss: 0.206392, tar: 0.020838 
l0: 0.008464, l1: 0.008030, l2: 0.011964, l3: 0.012744, l4: 0.027209, l5: 0.027590, l6: 0.026313

[epoch:  70/100000, batch:    20/  187, ite: 6496] train loss: 0.206222, tar: 0.020813 
l0: 0.019589, l1: 0.019898, l2: 0.028936, l3: 0.028562, l4: 0.044920, l5: 0.034420, l6: 0.032053

[epoch:  70/100000, batch:    22/  187, ite: 6497] train loss: 0.206227, tar: 0.020811 
l0: 0.010321, l1: 0.010632, l2: 0.012742, l3: 0.011246, l4: 0.016390, l5: 0.023463, l6: 0.020780

[epoch:  70/100000, batch:    24/  187, ite: 6498] train loss: 0.206025, tar: 0.020789 
l0: 0.011369, l1: 0.012417, l2: 0.013433, l3: 0.012504, l4: 0.016032, l5: 0.014851, l6: 0.014029

[epoch:  70/100000, batch:    26/  187, ite: 6499] train loss: 0.205801, tar: 0.020771 
l0: 0.008717, l1: 0.008594, l2: 0.011572, l3: 0.013111, l4: 0.024412, l5: 0.025863, l6: 0.034849

[epoch:  70/100000, batch:    28/  187, ite: 6500] train loss: 0.205644, tar: 0.020746 
l0: 0.013707, l1: 0.012461, l2: 0.019824, l3: 0.024036, l4: 0.022587, l5: 0.022432, l6: 0.027112

[epoch:  70/100000, batch:    30/  187, ite: 6501] train loss: 0.205517, tar: 0.020732 
l0: 0.052086, l1: 0.061042, l2: 0.041992, l3: 0.042446, l4: 0.058448, l5: 0.064089, l6: 0.046280

[epoch:  70/100000, batch:    32/  187, ite: 6502] train loss: 0.205838, tar: 0.020795 
l0: 0.013742, l1: 0.016139, l2: 0.013410, l3: 0.012988, l4: 0.019647, l5: 0.021464, l6: 0.019444

[epoch:  70/100000, batch:    34/  187, ite: 6503] train loss: 0.205661, tar: 0.020781 
l0: 0.019402, l1: 0.017698, l2: 0.028103, l3: 0.029497, l4: 0.048529, l5: 0.044176, l6: 0.050061

[epoch:  70/100000, batch:    36/  187, ite: 6504] train loss: 0.205724, tar: 0.020778 
l0: 0.016740, l1: 0.016747, l2: 0.017974, l3: 0.017712, l4: 0.041913, l5: 0.044963, l6: 0.039874

[epoch:  70/100000, batch:    38/  187, ite: 6505] train loss: 0.205705, tar: 0.020770 
l0: 0.007235, l1: 0.007869, l2: 0.015110, l3: 0.012316, l4: 0.024913, l5: 0.020340, l6: 0.012662

[epoch:  70/100000, batch:    40/  187, ite: 6506] train loss: 0.205497, tar: 0.020743 
l0: 0.008209, l1: 0.009036, l2: 0.009836, l3: 0.010049, l4: 0.022801, l5: 0.021782, l6: 0.020908

[epoch:  70/100000, batch:    42/  187, ite: 6507] train loss: 0.205294, tar: 0.020719 
l0: 0.036750, l1: 0.042444, l2: 0.034008, l3: 0.034468, l4: 0.027996, l5: 0.021956, l6: 0.017545

[epoch:  70/100000, batch:    44/  187, ite: 6508] train loss: 0.205313, tar: 0.020750 
l0: 0.025397, l1: 0.028313, l2: 0.026607, l3: 0.031299, l4: 0.062398, l5: 0.049340, l6: 0.049192

[epoch:  70/100000, batch:    46/  187, ite: 6509] train loss: 0.205445, tar: 0.020759 
l0: 0.081205, l1: 0.081779, l2: 0.064177, l3: 0.076788, l4: 0.114860, l5: 0.131230, l6: 0.128769

[epoch:  70/100000, batch:    48/  187, ite: 6510] train loss: 0.206373, tar: 0.020878 
l0: 0.020594, l1: 0.019330, l2: 0.024133, l3: 0.028582, l4: 0.034961, l5: 0.032763, l6: 0.031111

[epoch:  70/100000, batch:    50/  187, ite: 6511] train loss: 0.206344, tar: 0.020877 
l0: 0.020884, l1: 0.018938, l2: 0.028143, l3: 0.031755, l4: 0.051291, l5: 0.042624, l6: 0.043455

[epoch:  70/100000, batch:    52/  187, ite: 6512] train loss: 0.206404, tar: 0.020877 
l0: 0.019478, l1: 0.018303, l2: 0.017879, l3: 0.021270, l4: 0.037854, l5: 0.042136, l6: 0.041463

[epoch:  70/100000, batch:    54/  187, ite: 6513] train loss: 0.206389, tar: 0.020875 
l0: 0.018773, l1: 0.019184, l2: 0.022906, l3: 0.022801, l4: 0.032878, l5: 0.032030, l6: 0.033704

[epoch:  70/100000, batch:    56/  187, ite: 6514] train loss: 0.206342, tar: 0.020871 
l0: 0.041841, l1: 0.039117, l2: 0.045849, l3: 0.046865, l4: 0.047353, l5: 0.056731, l6: 0.060416

[epoch:  70/100000, batch:    58/  187, ite: 6515] train loss: 0.206598, tar: 0.020911 
l0: 0.013460, l1: 0.014147, l2: 0.014850, l3: 0.017240, l4: 0.018834, l5: 0.020393, l6: 0.019238

[epoch:  70/100000, batch:    60/  187, ite: 6516] train loss: 0.206426, tar: 0.020897 
l0: 0.099823, l1: 0.100123, l2: 0.119770, l3: 0.115522, l4: 0.136790, l5: 0.128240, l6: 0.117995

[epoch:  70/100000, batch:    62/  187, ite: 6517] train loss: 0.207610, tar: 0.021049 
l0: 0.008802, l1: 0.010149, l2: 0.011285, l3: 0.012536, l4: 0.016483, l5: 0.016249, l6: 0.013270

[epoch:  70/100000, batch:    64/  187, ite: 6518] train loss: 0.207380, tar: 0.021026 
l0: 0.022247, l1: 0.021437, l2: 0.028594, l3: 0.034318, l4: 0.036858, l5: 0.035348, l6: 0.044830

[epoch:  70/100000, batch:    66/  187, ite: 6519] train loss: 0.207412, tar: 0.021028 
l0: 0.018203, l1: 0.019027, l2: 0.017832, l3: 0.021348, l4: 0.032842, l5: 0.034789, l6: 0.043499

[epoch:  70/100000, batch:    68/  187, ite: 6520] train loss: 0.207373, tar: 0.021023 
l0: 0.053424, l1: 0.054691, l2: 0.073646, l3: 0.074705, l4: 0.039881, l5: 0.037919, l6: 0.031688

[epoch:  70/100000, batch:    70/  187, ite: 6521] train loss: 0.207678, tar: 0.021085 
l0: 0.032291, l1: 0.030494, l2: 0.048442, l3: 0.050979, l4: 0.063371, l5: 0.055185, l6: 0.054060

[epoch:  70/100000, batch:    72/  187, ite: 6522] train loss: 0.207921, tar: 0.021106 
l0: 0.049453, l1: 0.053061, l2: 0.057890, l3: 0.057061, l4: 0.045307, l5: 0.046987, l6: 0.046083

[epoch:  70/100000, batch:    74/  187, ite: 6523] train loss: 0.208204, tar: 0.021161 
l0: 0.022536, l1: 0.021484, l2: 0.037197, l3: 0.038283, l4: 0.040883, l5: 0.030860, l6: 0.035098

[epoch:  70/100000, batch:    76/  187, ite: 6524] train loss: 0.208239, tar: 0.021163 
l0: 0.032240, l1: 0.033166, l2: 0.035457, l3: 0.040576, l4: 0.044095, l5: 0.041323, l6: 0.033771

[epoch:  70/100000, batch:    78/  187, ite: 6525] train loss: 0.208339, tar: 0.021184 
l0: 0.026893, l1: 0.025067, l2: 0.037300, l3: 0.039106, l4: 0.058776, l5: 0.060405, l6: 0.057588

[epoch:  70/100000, batch:    80/  187, ite: 6526] train loss: 0.208523, tar: 0.021195 
l0: 0.033322, l1: 0.030138, l2: 0.051804, l3: 0.056163, l4: 0.076704, l5: 0.073550, l6: 0.062530

[epoch:  70/100000, batch:    82/  187, ite: 6527] train loss: 0.208856, tar: 0.021218 
l0: 0.056911, l1: 0.051477, l2: 0.089167, l3: 0.088078, l4: 0.071199, l5: 0.084253, l6: 0.074183

[epoch:  70/100000, batch:    84/  187, ite: 6528] train loss: 0.209436, tar: 0.021286 
l0: 0.021665, l1: 0.020104, l2: 0.035342, l3: 0.031299, l4: 0.041501, l5: 0.049515, l6: 0.052728

[epoch:  70/100000, batch:    86/  187, ite: 6529] train loss: 0.209517, tar: 0.021287 
l0: 0.026007, l1: 0.026727, l2: 0.033323, l3: 0.033182, l4: 0.031928, l5: 0.035107, l6: 0.029432

[epoch:  70/100000, batch:    88/  187, ite: 6530] train loss: 0.209529, tar: 0.021295 
l0: 0.029146, l1: 0.026255, l2: 0.048043, l3: 0.050334, l4: 0.041292, l5: 0.050141, l6: 0.045287

[epoch:  70/100000, batch:    90/  187, ite: 6531] train loss: 0.209681, tar: 0.021310 
l0: 0.036712, l1: 0.033039, l2: 0.098415, l3: 0.109944, l4: 0.104583, l5: 0.096678, l6: 0.104752

[epoch:  70/100000, batch:    92/  187, ite: 6532] train loss: 0.210385, tar: 0.021339 
l0: 0.037727, l1: 0.039024, l2: 0.055135, l3: 0.042456, l4: 0.039328, l5: 0.041582, l6: 0.045532

[epoch:  70/100000, batch:    94/  187, ite: 6533] train loss: 0.210555, tar: 0.021370 
l0: 0.037460, l1: 0.038274, l2: 0.058426, l3: 0.052508, l4: 0.076193, l5: 0.077625, l6: 0.076071

[epoch:  70/100000, batch:    96/  187, ite: 6534] train loss: 0.210940, tar: 0.021400 
l0: 0.032249, l1: 0.034529, l2: 0.043042, l3: 0.036508, l4: 0.055399, l5: 0.057721, l6: 0.067151

[epoch:  70/100000, batch:    98/  187, ite: 6535] train loss: 0.211157, tar: 0.021420 
l0: 0.025644, l1: 0.029613, l2: 0.024171, l3: 0.023271, l4: 0.032047, l5: 0.035324, l6: 0.039443

[epoch:  70/100000, batch:   100/  187, ite: 6536] train loss: 0.211154, tar: 0.021428 
l0: 0.024423, l1: 0.022588, l2: 0.039947, l3: 0.039537, l4: 0.049717, l5: 0.053956, l6: 0.054934

[epoch:  70/100000, batch:   102/  187, ite: 6537] train loss: 0.211291, tar: 0.021434 
l0: 0.024971, l1: 0.028282, l2: 0.030745, l3: 0.034073, l4: 0.050021, l5: 0.049250, l6: 0.049955

[epoch:  70/100000, batch:   104/  187, ite: 6538] train loss: 0.211395, tar: 0.021440 
l0: 0.016789, l1: 0.016531, l2: 0.023869, l3: 0.024285, l4: 0.029407, l5: 0.032383, l6: 0.037435

[epoch:  70/100000, batch:   106/  187, ite: 6539] train loss: 0.211338, tar: 0.021432 
l0: 0.024052, l1: 0.032866, l2: 0.020894, l3: 0.022792, l4: 0.033153, l5: 0.027333, l6: 0.030643

[epoch:  70/100000, batch:   108/  187, ite: 6540] train loss: 0.211302, tar: 0.021437 
l0: 0.024818, l1: 0.029074, l2: 0.026459, l3: 0.030229, l4: 0.046092, l5: 0.047747, l6: 0.046603

[epoch:  70/100000, batch:   110/  187, ite: 6541] train loss: 0.211375, tar: 0.021443 
l0: 0.017142, l1: 0.022800, l2: 0.021774, l3: 0.022269, l4: 0.024398, l5: 0.017112, l6: 0.018665

[epoch:  70/100000, batch:   112/  187, ite: 6542] train loss: 0.211251, tar: 0.021435 
l0: 0.027283, l1: 0.027655, l2: 0.047259, l3: 0.051274, l4: 0.064632, l5: 0.052255, l6: 0.057493

[epoch:  70/100000, batch:   114/  187, ite: 6543] train loss: 0.211466, tar: 0.021446 
l0: 0.022074, l1: 0.025990, l2: 0.033995, l3: 0.040749, l4: 0.042132, l5: 0.040029, l6: 0.038237

[epoch:  70/100000, batch:   116/  187, ite: 6544] train loss: 0.211525, tar: 0.021447 
l0: 0.057618, l1: 0.057650, l2: 0.041709, l3: 0.047526, l4: 0.052148, l5: 0.058311, l6: 0.088112

[epoch:  70/100000, batch:   118/  187, ite: 6545] train loss: 0.211876, tar: 0.021513 
l0: 0.031050, l1: 0.028778, l2: 0.044125, l3: 0.052191, l4: 0.061652, l5: 0.063722, l6: 0.062725

[epoch:  70/100000, batch:   120/  187, ite: 6546] train loss: 0.212118, tar: 0.021531 
l0: 0.024984, l1: 0.025212, l2: 0.036035, l3: 0.031693, l4: 0.038614, l5: 0.039590, l6: 0.043914

[epoch:  70/100000, batch:   122/  187, ite: 6547] train loss: 0.212169, tar: 0.021537 
l0: 0.030177, l1: 0.031139, l2: 0.030146, l3: 0.030400, l4: 0.047282, l5: 0.049324, l6: 0.054154

[epoch:  70/100000, batch:   124/  187, ite: 6548] train loss: 0.212280, tar: 0.021553 
l0: 0.036723, l1: 0.037711, l2: 0.044868, l3: 0.039582, l4: 0.049410, l5: 0.053009, l6: 0.052469

[epoch:  70/100000, batch:   126/  187, ite: 6549] train loss: 0.212465, tar: 0.021580 
l0: 0.024121, l1: 0.023157, l2: 0.027737, l3: 0.033347, l4: 0.050104, l5: 0.048228, l6: 0.058670

[epoch:  70/100000, batch:   128/  187, ite: 6550] train loss: 0.212561, tar: 0.021585 
l0: 0.024541, l1: 0.026223, l2: 0.027065, l3: 0.027402, l4: 0.036962, l5: 0.038787, l6: 0.050548

[epoch:  70/100000, batch:   130/  187, ite: 6551] train loss: 0.212595, tar: 0.021590 
l0: 0.046106, l1: 0.048501, l2: 0.040719, l3: 0.047171, l4: 0.067199, l5: 0.063714, l6: 0.058073

[epoch:  70/100000, batch:   132/  187, ite: 6552] train loss: 0.212883, tar: 0.021635 
l0: 0.024129, l1: 0.023912, l2: 0.029025, l3: 0.027702, l4: 0.029486, l5: 0.032964, l6: 0.042151

[epoch:  70/100000, batch:   134/  187, ite: 6553] train loss: 0.212877, tar: 0.021639 
l0: 0.022583, l1: 0.023322, l2: 0.024449, l3: 0.029220, l4: 0.048172, l5: 0.039154, l6: 0.033854

[epoch:  70/100000, batch:   136/  187, ite: 6554] train loss: 0.212891, tar: 0.021641 
l0: 0.019848, l1: 0.021448, l2: 0.031320, l3: 0.033248, l4: 0.035023, l5: 0.027116, l6: 0.025044

[epoch:  70/100000, batch:   138/  187, ite: 6555] train loss: 0.212855, tar: 0.021638 
l0: 0.025457, l1: 0.026015, l2: 0.033979, l3: 0.036311, l4: 0.043937, l5: 0.035450, l6: 0.036049

[epoch:  70/100000, batch:   140/  187, ite: 6556] train loss: 0.212899, tar: 0.021645 
l0: 0.039555, l1: 0.036930, l2: 0.046832, l3: 0.050228, l4: 0.068667, l5: 0.069608, l6: 0.073363

[epoch:  70/100000, batch:   142/  187, ite: 6557] train loss: 0.213208, tar: 0.021677 
l0: 0.007514, l1: 0.008957, l2: 0.020678, l3: 0.017387, l4: 0.016669, l5: 0.015612, l6: 0.011756

[epoch:  70/100000, batch:   144/  187, ite: 6558] train loss: 0.213003, tar: 0.021651 
l0: 0.026927, l1: 0.025166, l2: 0.033190, l3: 0.041689, l4: 0.072458, l5: 0.065454, l6: 0.066211

[epoch:  70/100000, batch:   146/  187, ite: 6559] train loss: 0.213214, tar: 0.021661 
l0: 0.049696, l1: 0.049896, l2: 0.047809, l3: 0.048241, l4: 0.073014, l5: 0.088774, l6: 0.086951

[epoch:  70/100000, batch:   148/  187, ite: 6560] train loss: 0.213627, tar: 0.021711 
l0: 0.026009, l1: 0.024060, l2: 0.031936, l3: 0.031334, l4: 0.060993, l5: 0.070811, l6: 0.072694

[epoch:  70/100000, batch:   150/  187, ite: 6561] train loss: 0.213813, tar: 0.021719 
l0: 0.013964, l1: 0.013458, l2: 0.015591, l3: 0.021512, l4: 0.060151, l5: 0.043699, l6: 0.042349

[epoch:  70/100000, batch:   152/  187, ite: 6562] train loss: 0.213807, tar: 0.021705 
l0: 0.024851, l1: 0.024950, l2: 0.028542, l3: 0.031409, l4: 0.037577, l5: 0.034289, l6: 0.035097

[epoch:  70/100000, batch:   154/  187, ite: 6563] train loss: 0.213812, tar: 0.021710 
l0: 0.018241, l1: 0.017844, l2: 0.020895, l3: 0.022333, l4: 0.030232, l5: 0.038219, l6: 0.035034

[epoch:  70/100000, batch:   156/  187, ite: 6564] train loss: 0.213757, tar: 0.021704 
l0: 0.013228, l1: 0.012712, l2: 0.020396, l3: 0.019310, l4: 0.036366, l5: 0.040348, l6: 0.034202

[epoch:  70/100000, batch:   158/  187, ite: 6565] train loss: 0.213692, tar: 0.021689 
l0: 0.014438, l1: 0.014077, l2: 0.019826, l3: 0.017663, l4: 0.027831, l5: 0.032413, l6: 0.041893

[epoch:  70/100000, batch:   160/  187, ite: 6566] train loss: 0.213611, tar: 0.021676 
l0: 0.029696, l1: 0.027715, l2: 0.030558, l3: 0.033944, l4: 0.062026, l5: 0.072830, l6: 0.084768

[epoch:  70/100000, batch:   162/  187, ite: 6567] train loss: 0.213837, tar: 0.021690 
l0: 0.034433, l1: 0.032196, l2: 0.038892, l3: 0.046840, l4: 0.051707, l5: 0.068240, l6: 0.061923

[epoch:  70/100000, batch:   164/  187, ite: 6568] train loss: 0.214049, tar: 0.021713 
l0: 0.011509, l1: 0.012529, l2: 0.017258, l3: 0.018079, l4: 0.023175, l5: 0.028260, l6: 0.028091

[epoch:  70/100000, batch:   166/  187, ite: 6569] train loss: 0.213917, tar: 0.021695 
l0: 0.018411, l1: 0.021029, l2: 0.018284, l3: 0.017825, l4: 0.022172, l5: 0.021935, l6: 0.022260

[epoch:  70/100000, batch:   168/  187, ite: 6570] train loss: 0.213790, tar: 0.021689 
l0: 0.020190, l1: 0.022123, l2: 0.019070, l3: 0.017889, l4: 0.025182, l5: 0.028284, l6: 0.030281

[epoch:  70/100000, batch:   170/  187, ite: 6571] train loss: 0.213701, tar: 0.021687 
l0: 0.021035, l1: 0.023814, l2: 0.023032, l3: 0.022529, l4: 0.041632, l5: 0.042710, l6: 0.040767

[epoch:  70/100000, batch:   172/  187, ite: 6572] train loss: 0.213705, tar: 0.021685 
l0: 0.017193, l1: 0.017004, l2: 0.021318, l3: 0.021291, l4: 0.038538, l5: 0.041293, l6: 0.042369

[epoch:  70/100000, batch:   174/  187, ite: 6573] train loss: 0.213679, tar: 0.021678 
l0: 0.017054, l1: 0.018816, l2: 0.020917, l3: 0.018813, l4: 0.019438, l5: 0.023245, l6: 0.027258

[epoch:  70/100000, batch:   176/  187, ite: 6574] train loss: 0.213560, tar: 0.021670 
l0: 0.016277, l1: 0.016033, l2: 0.022176, l3: 0.021652, l4: 0.021870, l5: 0.025820, l6: 0.034157

[epoch:  70/100000, batch:   178/  187, ite: 6575] train loss: 0.213463, tar: 0.021660 
l0: 0.031262, l1: 0.031849, l2: 0.036042, l3: 0.038040, l4: 0.043870, l5: 0.040654, l6: 0.037799

[epoch:  70/100000, batch:   180/  187, ite: 6576] train loss: 0.213543, tar: 0.021677 
l0: 0.014023, l1: 0.012770, l2: 0.027400, l3: 0.025205, l4: 0.031087, l5: 0.031884, l6: 0.041659

[epoch:  70/100000, batch:   182/  187, ite: 6577] train loss: 0.213492, tar: 0.021664 
l0: 0.014057, l1: 0.014641, l2: 0.015618, l3: 0.017641, l4: 0.041574, l5: 0.052886, l6: 0.035179

[epoch:  70/100000, batch:   184/  187, ite: 6578] train loss: 0.213454, tar: 0.021650 
l0: 0.018382, l1: 0.016534, l2: 0.025085, l3: 0.025763, l4: 0.036629, l5: 0.048439, l6: 0.051189

[epoch:  70/100000, batch:   186/  187, ite: 6579] train loss: 0.213469, tar: 0.021645 
l0: 0.013927, l1: 0.013487, l2: 0.018480, l3: 0.020678, l4: 0.036394, l5: 0.035773, l6: 0.033754

[epoch:  70/100000, batch:   188/  187, ite: 6580] train loss: 0.213399, tar: 0.021631 
l0: 0.017674, l1: 0.017374, l2: 0.020372, l3: 0.021699, l4: 0.054633, l5: 0.051045, l6: 0.046499

[epoch:  71/100000, batch:     2/  187, ite: 6581] train loss: 0.213426, tar: 0.021625 
l0: 0.020341, l1: 0.020705, l2: 0.022835, l3: 0.023167, l4: 0.036609, l5: 0.038868, l6: 0.041397

[epoch:  71/100000, batch:     4/  187, ite: 6582] train loss: 0.213410, tar: 0.021622 
l0: 0.020261, l1: 0.020993, l2: 0.027665, l3: 0.025595, l4: 0.034819, l5: 0.033678, l6: 0.027313

[epoch:  71/100000, batch:     6/  187, ite: 6583] train loss: 0.213370, tar: 0.021620 
l0: 0.023929, l1: 0.023476, l2: 0.027616, l3: 0.035785, l4: 0.051600, l5: 0.051390, l6: 0.055883

[epoch:  71/100000, batch:     8/  187, ite: 6584] train loss: 0.213466, tar: 0.021624 
l0: 0.017357, l1: 0.019918, l2: 0.017552, l3: 0.019440, l4: 0.043558, l5: 0.039442, l6: 0.033336

[epoch:  71/100000, batch:    10/  187, ite: 6585] train loss: 0.213427, tar: 0.021617 
l0: 0.016447, l1: 0.017621, l2: 0.017409, l3: 0.018102, l4: 0.031173, l5: 0.028630, l6: 0.028991

[epoch:  71/100000, batch:    12/  187, ite: 6586] train loss: 0.213333, tar: 0.021608 
l0: 0.014563, l1: 0.013528, l2: 0.021986, l3: 0.021775, l4: 0.022436, l5: 0.028268, l6: 0.025558

[epoch:  71/100000, batch:    14/  187, ite: 6587] train loss: 0.213222, tar: 0.021596 
l0: 0.023322, l1: 0.020384, l2: 0.032822, l3: 0.033328, l4: 0.044473, l5: 0.049003, l6: 0.072360

[epoch:  71/100000, batch:    16/  187, ite: 6588] train loss: 0.213329, tar: 0.021599 
l0: 0.021094, l1: 0.021390, l2: 0.023277, l3: 0.025300, l4: 0.077947, l5: 0.065734, l6: 0.069101

[epoch:  71/100000, batch:    18/  187, ite: 6589] train loss: 0.213482, tar: 0.021598 
l0: 0.017301, l1: 0.018077, l2: 0.018701, l3: 0.021347, l4: 0.044371, l5: 0.039639, l6: 0.034652

[epoch:  71/100000, batch:    20/  187, ite: 6590] train loss: 0.213449, tar: 0.021591 
l0: 0.013311, l1: 0.013568, l2: 0.014299, l3: 0.016139, l4: 0.021648, l5: 0.024456, l6: 0.020641

[epoch:  71/100000, batch:    22/  187, ite: 6591] train loss: 0.213298, tar: 0.021577 
l0: 0.022474, l1: 0.022659, l2: 0.025773, l3: 0.027012, l4: 0.039643, l5: 0.037397, l6: 0.041694

[epoch:  71/100000, batch:    24/  187, ite: 6592] train loss: 0.213304, tar: 0.021578 
l0: 0.026912, l1: 0.028819, l2: 0.030221, l3: 0.032584, l4: 0.040499, l5: 0.036117, l6: 0.031111

[epoch:  71/100000, batch:    26/  187, ite: 6593] train loss: 0.213326, tar: 0.021587 
l0: 0.005777, l1: 0.005932, l2: 0.006064, l3: 0.007208, l4: 0.022264, l5: 0.030893, l6: 0.037750

[epoch:  71/100000, batch:    28/  187, ite: 6594] train loss: 0.213162, tar: 0.021561 
l0: 0.012285, l1: 0.012355, l2: 0.014458, l3: 0.015230, l4: 0.028482, l5: 0.030027, l6: 0.039890

[epoch:  71/100000, batch:    30/  187, ite: 6595] train loss: 0.213060, tar: 0.021545 
l0: 0.015690, l1: 0.014572, l2: 0.027846, l3: 0.028880, l4: 0.047630, l5: 0.049834, l6: 0.041717

[epoch:  71/100000, batch:    32/  187, ite: 6596] train loss: 0.213082, tar: 0.021535 
l0: 0.009218, l1: 0.009403, l2: 0.011682, l3: 0.012401, l4: 0.027511, l5: 0.034140, l6: 0.032700

[epoch:  71/100000, batch:    34/  187, ite: 6597] train loss: 0.212955, tar: 0.021515 
l0: 0.012011, l1: 0.012700, l2: 0.011632, l3: 0.012674, l4: 0.023818, l5: 0.026062, l6: 0.025994

[epoch:  71/100000, batch:    36/  187, ite: 6598] train loss: 0.212807, tar: 0.021499 
l0: 0.020886, l1: 0.022161, l2: 0.030359, l3: 0.024405, l4: 0.026983, l5: 0.032873, l6: 0.031667

[epoch:  71/100000, batch:    38/  187, ite: 6599] train loss: 0.212768, tar: 0.021498 
l0: 0.016962, l1: 0.015811, l2: 0.019666, l3: 0.023186, l4: 0.042081, l5: 0.036071, l6: 0.043921

[epoch:  71/100000, batch:    40/  187, ite: 6600] train loss: 0.212743, tar: 0.021490 
l0: 0.011936, l1: 0.013493, l2: 0.013353, l3: 0.015257, l4: 0.019829, l5: 0.020407, l6: 0.019403

[epoch:  71/100000, batch:    42/  187, ite: 6601] train loss: 0.212578, tar: 0.021474 
l0: 0.029598, l1: 0.031455, l2: 0.031223, l3: 0.032947, l4: 0.040608, l5: 0.040152, l6: 0.041797

[epoch:  71/100000, batch:    44/  187, ite: 6602] train loss: 0.212637, tar: 0.021488 
l0: 0.014045, l1: 0.013666, l2: 0.019066, l3: 0.020792, l4: 0.030903, l5: 0.031109, l6: 0.023632

[epoch:  71/100000, batch:    46/  187, ite: 6603] train loss: 0.212538, tar: 0.021475 
l0: 0.012207, l1: 0.011968, l2: 0.014425, l3: 0.014999, l4: 0.022025, l5: 0.024721, l6: 0.032270

[epoch:  71/100000, batch:    48/  187, ite: 6604] train loss: 0.212406, tar: 0.021460 
l0: 0.017628, l1: 0.020379, l2: 0.018398, l3: 0.018744, l4: 0.038880, l5: 0.036767, l6: 0.035272

[epoch:  71/100000, batch:    50/  187, ite: 6605] train loss: 0.212362, tar: 0.021454 
l0: 0.011925, l1: 0.011677, l2: 0.014964, l3: 0.015632, l4: 0.023099, l5: 0.027100, l6: 0.035548

[epoch:  71/100000, batch:    52/  187, ite: 6606] train loss: 0.212243, tar: 0.021438 
l0: 0.013683, l1: 0.014295, l2: 0.017412, l3: 0.017272, l4: 0.026930, l5: 0.028178, l6: 0.026297

[epoch:  71/100000, batch:    54/  187, ite: 6607] train loss: 0.212130, tar: 0.021425 
l0: 0.023615, l1: 0.025143, l2: 0.030822, l3: 0.038992, l4: 0.031653, l5: 0.032013, l6: 0.034625

[epoch:  71/100000, batch:    56/  187, ite: 6608] train loss: 0.212138, tar: 0.021429 
l0: 0.011283, l1: 0.010884, l2: 0.014901, l3: 0.015513, l4: 0.030185, l5: 0.032978, l6: 0.042287

[epoch:  71/100000, batch:    58/  187, ite: 6609] train loss: 0.212049, tar: 0.021412 
l0: 0.010629, l1: 0.011390, l2: 0.015093, l3: 0.013940, l4: 0.031815, l5: 0.034170, l6: 0.031508

[epoch:  71/100000, batch:    60/  187, ite: 6610] train loss: 0.211945, tar: 0.021394 
l0: 0.013349, l1: 0.013485, l2: 0.016116, l3: 0.017035, l4: 0.023598, l5: 0.023449, l6: 0.026341

[epoch:  71/100000, batch:    62/  187, ite: 6611] train loss: 0.211817, tar: 0.021381 
l0: 0.019500, l1: 0.019066, l2: 0.026159, l3: 0.025346, l4: 0.045582, l5: 0.041371, l6: 0.042010

[epoch:  71/100000, batch:    64/  187, ite: 6612] train loss: 0.211829, tar: 0.021378 
l0: 0.024814, l1: 0.026219, l2: 0.034066, l3: 0.029974, l4: 0.030085, l5: 0.025695, l6: 0.023786

[epoch:  71/100000, batch:    66/  187, ite: 6613] train loss: 0.211800, tar: 0.021384 
l0: 0.017593, l1: 0.019030, l2: 0.020684, l3: 0.022683, l4: 0.017548, l5: 0.018144, l6: 0.022980

[epoch:  71/100000, batch:    68/  187, ite: 6614] train loss: 0.211681, tar: 0.021378 
l0: 0.023533, l1: 0.025053, l2: 0.025361, l3: 0.025988, l4: 0.041345, l5: 0.037476, l6: 0.039413

[epoch:  71/100000, batch:    70/  187, ite: 6615] train loss: 0.211692, tar: 0.021381 
l0: 0.019636, l1: 0.020149, l2: 0.025354, l3: 0.023806, l4: 0.051888, l5: 0.040910, l6: 0.039981

[epoch:  71/100000, batch:    72/  187, ite: 6616] train loss: 0.211708, tar: 0.021378 
l0: 0.018948, l1: 0.022051, l2: 0.018422, l3: 0.016233, l4: 0.022310, l5: 0.018881, l6: 0.019662

[epoch:  71/100000, batch:    74/  187, ite: 6617] train loss: 0.211586, tar: 0.021374 
l0: 0.028635, l1: 0.030615, l2: 0.033069, l3: 0.028037, l4: 0.041472, l5: 0.045824, l6: 0.044026

[epoch:  71/100000, batch:    76/  187, ite: 6618] train loss: 0.211651, tar: 0.021386 
l0: 0.014949, l1: 0.015900, l2: 0.016909, l3: 0.017189, l4: 0.027407, l5: 0.025188, l6: 0.025956

[epoch:  71/100000, batch:    78/  187, ite: 6619] train loss: 0.211541, tar: 0.021376 
l0: 0.012396, l1: 0.012562, l2: 0.014294, l3: 0.015119, l4: 0.023270, l5: 0.023438, l6: 0.023568

[epoch:  71/100000, batch:    80/  187, ite: 6620] train loss: 0.211401, tar: 0.021361 
l0: 0.013230, l1: 0.013051, l2: 0.017508, l3: 0.015007, l4: 0.023281, l5: 0.029668, l6: 0.031603

[epoch:  71/100000, batch:    82/  187, ite: 6621] train loss: 0.211291, tar: 0.021348 
l0: 0.022955, l1: 0.025892, l2: 0.023541, l3: 0.025443, l4: 0.031861, l5: 0.031309, l6: 0.029945

[epoch:  71/100000, batch:    84/  187, ite: 6622] train loss: 0.211259, tar: 0.021351 
l0: 0.013880, l1: 0.013604, l2: 0.016413, l3: 0.018496, l4: 0.022519, l5: 0.025008, l6: 0.024296

[epoch:  71/100000, batch:    86/  187, ite: 6623] train loss: 0.211135, tar: 0.021339 
l0: 0.011413, l1: 0.011643, l2: 0.014192, l3: 0.014664, l4: 0.025539, l5: 0.023361, l6: 0.028435

[epoch:  71/100000, batch:    88/  187, ite: 6624] train loss: 0.211004, tar: 0.021323 
l0: 0.015873, l1: 0.016595, l2: 0.017612, l3: 0.017654, l4: 0.025566, l5: 0.024697, l6: 0.028759

[epoch:  71/100000, batch:    90/  187, ite: 6625] train loss: 0.210901, tar: 0.021314 
l0: 0.014243, l1: 0.016213, l2: 0.013554, l3: 0.013460, l4: 0.024949, l5: 0.022667, l6: 0.039506

[epoch:  71/100000, batch:    92/  187, ite: 6626] train loss: 0.210795, tar: 0.021303 
l0: 0.016643, l1: 0.016806, l2: 0.024724, l3: 0.027518, l4: 0.035808, l5: 0.030962, l6: 0.035865

[epoch:  71/100000, batch:    94/  187, ite: 6627] train loss: 0.210759, tar: 0.021295 
l0: 0.019103, l1: 0.017795, l2: 0.032691, l3: 0.036603, l4: 0.048417, l5: 0.040772, l6: 0.040482

[epoch:  71/100000, batch:    96/  187, ite: 6628] train loss: 0.210799, tar: 0.021292 
l0: 0.028004, l1: 0.026938, l2: 0.040089, l3: 0.038952, l4: 0.025969, l5: 0.027093, l6: 0.023918

[epoch:  71/100000, batch:    98/  187, ite: 6629] train loss: 0.210799, tar: 0.021303 
l0: 0.013396, l1: 0.013187, l2: 0.017548, l3: 0.017773, l4: 0.025010, l5: 0.020028, l6: 0.026366

[epoch:  71/100000, batch:   100/  187, ite: 6630] train loss: 0.210676, tar: 0.021290 
l0: 0.019739, l1: 0.021184, l2: 0.026272, l3: 0.024377, l4: 0.029000, l5: 0.026693, l6: 0.031678

[epoch:  71/100000, batch:   102/  187, ite: 6631] train loss: 0.210626, tar: 0.021288 
l0: 0.018937, l1: 0.018445, l2: 0.022114, l3: 0.024319, l4: 0.037797, l5: 0.041314, l6: 0.043715

[epoch:  71/100000, batch:   104/  187, ite: 6632] train loss: 0.210620, tar: 0.021284 
l0: 0.012630, l1: 0.012938, l2: 0.015158, l3: 0.016682, l4: 0.029657, l5: 0.029635, l6: 0.026754

[epoch:  71/100000, batch:   106/  187, ite: 6633] train loss: 0.210514, tar: 0.021270 
l0: 0.017329, l1: 0.018148, l2: 0.021054, l3: 0.020638, l4: 0.019059, l5: 0.017986, l6: 0.022170

[epoch:  71/100000, batch:   108/  187, ite: 6634] train loss: 0.210397, tar: 0.021264 
l0: 0.013283, l1: 0.014262, l2: 0.015643, l3: 0.016801, l4: 0.030950, l5: 0.037980, l6: 0.034121

[epoch:  71/100000, batch:   110/  187, ite: 6635] train loss: 0.210322, tar: 0.021251 
l0: 0.020043, l1: 0.022769, l2: 0.021480, l3: 0.018988, l4: 0.029181, l5: 0.022802, l6: 0.030581

[epoch:  71/100000, batch:   112/  187, ite: 6636] train loss: 0.210252, tar: 0.021250 
l0: 0.016756, l1: 0.014640, l2: 0.026943, l3: 0.035452, l4: 0.027049, l5: 0.026909, l6: 0.033623

[epoch:  71/100000, batch:   114/  187, ite: 6637] train loss: 0.210207, tar: 0.021242 
l0: 0.020350, l1: 0.023777, l2: 0.018888, l3: 0.017260, l4: 0.020266, l5: 0.022786, l6: 0.022081

[epoch:  71/100000, batch:   116/  187, ite: 6638] train loss: 0.210105, tar: 0.021241 
l0: 0.014393, l1: 0.014522, l2: 0.016481, l3: 0.017674, l4: 0.019308, l5: 0.017870, l6: 0.021582

[epoch:  71/100000, batch:   118/  187, ite: 6639] train loss: 0.209967, tar: 0.021230 
l0: 0.017151, l1: 0.018519, l2: 0.015712, l3: 0.016698, l4: 0.032143, l5: 0.037956, l6: 0.036332

[epoch:  71/100000, batch:   120/  187, ite: 6640] train loss: 0.209912, tar: 0.021224 
l0: 0.017867, l1: 0.017757, l2: 0.019953, l3: 0.021207, l4: 0.029146, l5: 0.030234, l6: 0.029778

[epoch:  71/100000, batch:   122/  187, ite: 6641] train loss: 0.209843, tar: 0.021219 
l0: 0.011762, l1: 0.011287, l2: 0.016219, l3: 0.016412, l4: 0.024495, l5: 0.027865, l6: 0.027654

[epoch:  71/100000, batch:   124/  187, ite: 6642] train loss: 0.209728, tar: 0.021204 
l0: 0.012521, l1: 0.012578, l2: 0.029156, l3: 0.023308, l4: 0.027866, l5: 0.024400, l6: 0.033542

[epoch:  71/100000, batch:   126/  187, ite: 6643] train loss: 0.209656, tar: 0.021190 
l0: 0.016918, l1: 0.017448, l2: 0.019509, l3: 0.018916, l4: 0.033559, l5: 0.036422, l6: 0.038975

[epoch:  71/100000, batch:   128/  187, ite: 6644] train loss: 0.209612, tar: 0.021184 
l0: 0.011433, l1: 0.011819, l2: 0.011104, l3: 0.013238, l4: 0.025952, l5: 0.024212, l6: 0.019811

[epoch:  71/100000, batch:   130/  187, ite: 6645] train loss: 0.209470, tar: 0.021169 
l0: 0.012282, l1: 0.013374, l2: 0.016694, l3: 0.014705, l4: 0.033300, l5: 0.034440, l6: 0.028727

[epoch:  71/100000, batch:   132/  187, ite: 6646] train loss: 0.209383, tar: 0.021155 
l0: 0.018528, l1: 0.021918, l2: 0.018182, l3: 0.013030, l4: 0.015358, l5: 0.015683, l6: 0.025278

[epoch:  71/100000, batch:   134/  187, ite: 6647] train loss: 0.209257, tar: 0.021151 
l0: 0.013801, l1: 0.013481, l2: 0.018202, l3: 0.020750, l4: 0.031125, l5: 0.025832, l6: 0.031183

[epoch:  71/100000, batch:   136/  187, ite: 6648] train loss: 0.209172, tar: 0.021140 
l0: 0.025930, l1: 0.026166, l2: 0.028468, l3: 0.032286, l4: 0.051731, l5: 0.042415, l6: 0.038761

[epoch:  71/100000, batch:   138/  187, ite: 6649] train loss: 0.209229, tar: 0.021147 
l0: 0.027467, l1: 0.027234, l2: 0.029764, l3: 0.030240, l4: 0.038028, l5: 0.037150, l6: 0.043920

[epoch:  71/100000, batch:   140/  187, ite: 6650] train loss: 0.209267, tar: 0.021157 
l0: 0.018857, l1: 0.020047, l2: 0.022208, l3: 0.022295, l4: 0.026927, l5: 0.023667, l6: 0.018087

[epoch:  71/100000, batch:   142/  187, ite: 6651] train loss: 0.209179, tar: 0.021153 
l0: 0.012331, l1: 0.011974, l2: 0.020672, l3: 0.019162, l4: 0.031668, l5: 0.030585, l6: 0.027360

[epoch:  71/100000, batch:   144/  187, ite: 6652] train loss: 0.209094, tar: 0.021140 
l0: 0.021890, l1: 0.022332, l2: 0.021004, l3: 0.023052, l4: 0.029661, l5: 0.035971, l6: 0.045498

[epoch:  71/100000, batch:   146/  187, ite: 6653] train loss: 0.209079, tar: 0.021141 
l0: 0.012404, l1: 0.013504, l2: 0.012007, l3: 0.011443, l4: 0.022878, l5: 0.026991, l6: 0.025501

[epoch:  71/100000, batch:   148/  187, ite: 6654] train loss: 0.208950, tar: 0.021127 
l0: 0.018203, l1: 0.016524, l2: 0.022628, l3: 0.025639, l4: 0.032661, l5: 0.038001, l6: 0.037619

[epoch:  71/100000, batch:   150/  187, ite: 6655] train loss: 0.208923, tar: 0.021123 
l0: 0.015809, l1: 0.014980, l2: 0.021029, l3: 0.023350, l4: 0.036136, l5: 0.034709, l6: 0.037763

[epoch:  71/100000, batch:   152/  187, ite: 6656] train loss: 0.208885, tar: 0.021115 
l0: 0.036012, l1: 0.040322, l2: 0.027768, l3: 0.027534, l4: 0.056594, l5: 0.049596, l6: 0.044915

[epoch:  71/100000, batch:   154/  187, ite: 6657] train loss: 0.208997, tar: 0.021138 
l0: 0.012138, l1: 0.010701, l2: 0.012998, l3: 0.013091, l4: 0.024449, l5: 0.027429, l6: 0.029942

[epoch:  71/100000, batch:   156/  187, ite: 6658] train loss: 0.208878, tar: 0.021124 
l0: 0.017335, l1: 0.016691, l2: 0.019592, l3: 0.027756, l4: 0.048551, l5: 0.040665, l6: 0.037632

[epoch:  71/100000, batch:   158/  187, ite: 6659] train loss: 0.208877, tar: 0.021118 
l0: 0.020320, l1: 0.020524, l2: 0.023866, l3: 0.020493, l4: 0.030484, l5: 0.036037, l6: 0.036422

[epoch:  71/100000, batch:   160/  187, ite: 6660] train loss: 0.208846, tar: 0.021117 
l0: 0.018728, l1: 0.019249, l2: 0.022039, l3: 0.024467, l4: 0.031074, l5: 0.029899, l6: 0.026495

[epoch:  71/100000, batch:   162/  187, ite: 6661] train loss: 0.208790, tar: 0.021113 
l0: 0.018441, l1: 0.024839, l2: 0.020535, l3: 0.015678, l4: 0.019866, l5: 0.021184, l6: 0.023829

[epoch:  71/100000, batch:   164/  187, ite: 6662] train loss: 0.208693, tar: 0.021109 
l0: 0.044595, l1: 0.045853, l2: 0.040666, l3: 0.038583, l4: 0.058974, l5: 0.068534, l6: 0.081833

[epoch:  71/100000, batch:   166/  187, ite: 6663] train loss: 0.208950, tar: 0.021145 
l0: 0.018961, l1: 0.020984, l2: 0.025094, l3: 0.021556, l4: 0.040219, l5: 0.034012, l6: 0.035453

[epoch:  71/100000, batch:   168/  187, ite: 6664] train loss: 0.208930, tar: 0.021141 
l0: 0.014368, l1: 0.015202, l2: 0.015484, l3: 0.016819, l4: 0.038118, l5: 0.033392, l6: 0.045564

[epoch:  71/100000, batch:   170/  187, ite: 6665] train loss: 0.208885, tar: 0.021131 
l0: 0.014573, l1: 0.014285, l2: 0.019091, l3: 0.019436, l4: 0.033248, l5: 0.030765, l6: 0.041525

[epoch:  71/100000, batch:   172/  187, ite: 6666] train loss: 0.208831, tar: 0.021121 
l0: 0.016569, l1: 0.020188, l2: 0.014080, l3: 0.014155, l4: 0.025652, l5: 0.026319, l6: 0.023134

[epoch:  71/100000, batch:   174/  187, ite: 6667] train loss: 0.208728, tar: 0.021115 
l0: 0.012757, l1: 0.013087, l2: 0.016935, l3: 0.015372, l4: 0.021111, l5: 0.023601, l6: 0.029029

[epoch:  71/100000, batch:   176/  187, ite: 6668] train loss: 0.208613, tar: 0.021102 
l0: 0.010106, l1: 0.009962, l2: 0.018449, l3: 0.018176, l4: 0.027543, l5: 0.029121, l6: 0.027692

[epoch:  71/100000, batch:   178/  187, ite: 6669] train loss: 0.208512, tar: 0.021086 
l0: 0.013952, l1: 0.012895, l2: 0.016740, l3: 0.022907, l4: 0.037745, l5: 0.041422, l6: 0.040568

[epoch:  71/100000, batch:   180/  187, ite: 6670] train loss: 0.208479, tar: 0.021075 
l0: 0.014489, l1: 0.014763, l2: 0.017064, l3: 0.018492, l4: 0.013876, l5: 0.015250, l6: 0.013784

[epoch:  71/100000, batch:   182/  187, ite: 6671] train loss: 0.208329, tar: 0.021065 
l0: 0.012902, l1: 0.012959, l2: 0.019278, l3: 0.019424, l4: 0.027660, l5: 0.030313, l6: 0.026111

[epoch:  71/100000, batch:   184/  187, ite: 6672] train loss: 0.208240, tar: 0.021053 
l0: 0.016507, l1: 0.017203, l2: 0.015641, l3: 0.017594, l4: 0.039292, l5: 0.043534, l6: 0.038702

[epoch:  71/100000, batch:   186/  187, ite: 6673] train loss: 0.208211, tar: 0.021046 
l0: 0.016270, l1: 0.015653, l2: 0.016055, l3: 0.018465, l4: 0.018834, l5: 0.021846, l6: 0.031241

[epoch:  71/100000, batch:   188/  187, ite: 6674] train loss: 0.208107, tar: 0.021039 
l0: 0.016646, l1: 0.017576, l2: 0.021336, l3: 0.020932, l4: 0.027768, l5: 0.027188, l6: 0.026977

[epoch:  72/100000, batch:     2/  187, ite: 6675] train loss: 0.208033, tar: 0.021033 
l0: 0.009948, l1: 0.011008, l2: 0.011939, l3: 0.011123, l4: 0.020846, l5: 0.020715, l6: 0.022025

[epoch:  72/100000, batch:     4/  187, ite: 6676] train loss: 0.207885, tar: 0.021016 
l0: 0.015179, l1: 0.015589, l2: 0.017386, l3: 0.019390, l4: 0.034560, l5: 0.038314, l6: 0.036002

[epoch:  72/100000, batch:     6/  187, ite: 6677] train loss: 0.207838, tar: 0.021008 
l0: 0.015828, l1: 0.017428, l2: 0.017366, l3: 0.016286, l4: 0.028833, l5: 0.023582, l6: 0.025102

[epoch:  72/100000, batch:     8/  187, ite: 6678] train loss: 0.207745, tar: 0.021000 
l0: 0.030832, l1: 0.029555, l2: 0.031450, l3: 0.038131, l4: 0.050189, l5: 0.045292, l6: 0.061670

[epoch:  72/100000, batch:    10/  187, ite: 6679] train loss: 0.207862, tar: 0.021014 
l0: 0.007007, l1: 0.006708, l2: 0.010431, l3: 0.011524, l4: 0.018684, l5: 0.019480, l6: 0.023336

[epoch:  72/100000, batch:    12/  187, ite: 6680] train loss: 0.207699, tar: 0.020994 
l0: 0.012503, l1: 0.013325, l2: 0.014595, l3: 0.016303, l4: 0.023399, l5: 0.022098, l6: 0.022496

[epoch:  72/100000, batch:    14/  187, ite: 6681] train loss: 0.207577, tar: 0.020981 
l0: 0.016319, l1: 0.017505, l2: 0.020054, l3: 0.020290, l4: 0.035744, l5: 0.031105, l6: 0.023088

[epoch:  72/100000, batch:    16/  187, ite: 6682] train loss: 0.207513, tar: 0.020975 
l0: 0.019078, l1: 0.017896, l2: 0.020688, l3: 0.026066, l4: 0.051776, l5: 0.055170, l6: 0.054089

[epoch:  72/100000, batch:    18/  187, ite: 6683] train loss: 0.207568, tar: 0.020972 
l0: 0.030348, l1: 0.041686, l2: 0.028866, l3: 0.027902, l4: 0.040455, l5: 0.055289, l6: 0.060521

[epoch:  72/100000, batch:    20/  187, ite: 6684] train loss: 0.207681, tar: 0.020985 
l0: 0.030897, l1: 0.030610, l2: 0.040981, l3: 0.039328, l4: 0.037338, l5: 0.031941, l6: 0.035219

[epoch:  72/100000, batch:    22/  187, ite: 6685] train loss: 0.207738, tar: 0.021000 
l0: 0.018463, l1: 0.020211, l2: 0.017228, l3: 0.018069, l4: 0.026946, l5: 0.028256, l6: 0.025581

[epoch:  72/100000, batch:    24/  187, ite: 6686] train loss: 0.207660, tar: 0.020996 
l0: 0.018809, l1: 0.020432, l2: 0.019212, l3: 0.017526, l4: 0.039070, l5: 0.031395, l6: 0.035391

[epoch:  72/100000, batch:    26/  187, ite: 6687] train loss: 0.207623, tar: 0.020993 
l0: 0.013267, l1: 0.013870, l2: 0.016443, l3: 0.016038, l4: 0.028102, l5: 0.024163, l6: 0.027445

[epoch:  72/100000, batch:    28/  187, ite: 6688] train loss: 0.207524, tar: 0.020982 
l0: 0.015663, l1: 0.015567, l2: 0.018499, l3: 0.018644, l4: 0.032611, l5: 0.030591, l6: 0.029263

[epoch:  72/100000, batch:    30/  187, ite: 6689] train loss: 0.207456, tar: 0.020974 
l0: 0.014741, l1: 0.014662, l2: 0.019125, l3: 0.019503, l4: 0.028475, l5: 0.025864, l6: 0.030964

[epoch:  72/100000, batch:    32/  187, ite: 6690] train loss: 0.207377, tar: 0.020965 
l0: 0.023245, l1: 0.023559, l2: 0.023775, l3: 0.025599, l4: 0.043187, l5: 0.043538, l6: 0.038593

[epoch:  72/100000, batch:    34/  187, ite: 6691] train loss: 0.207398, tar: 0.020968 
l0: 0.028642, l1: 0.031788, l2: 0.027744, l3: 0.025186, l4: 0.034739, l5: 0.036628, l6: 0.029045

[epoch:  72/100000, batch:    36/  187, ite: 6692] train loss: 0.207407, tar: 0.020979 
l0: 0.014852, l1: 0.016083, l2: 0.019122, l3: 0.019201, l4: 0.023786, l5: 0.027509, l6: 0.033914

[epoch:  72/100000, batch:    38/  187, ite: 6693] train loss: 0.207331, tar: 0.020971 
l0: 0.020304, l1: 0.019857, l2: 0.027253, l3: 0.026519, l4: 0.027430, l5: 0.021064, l6: 0.028684

[epoch:  72/100000, batch:    40/  187, ite: 6694] train loss: 0.207278, tar: 0.020970 
l0: 0.015911, l1: 0.016493, l2: 0.015794, l3: 0.016933, l4: 0.027818, l5: 0.025547, l6: 0.024075

[epoch:  72/100000, batch:    42/  187, ite: 6695] train loss: 0.207185, tar: 0.020962 
l0: 0.012892, l1: 0.013355, l2: 0.013932, l3: 0.014481, l4: 0.018913, l5: 0.018418, l6: 0.021171

[epoch:  72/100000, batch:    44/  187, ite: 6696] train loss: 0.207050, tar: 0.020951 
l0: 0.013729, l1: 0.014412, l2: 0.018365, l3: 0.014402, l4: 0.022351, l5: 0.022775, l6: 0.026595

[epoch:  72/100000, batch:    46/  187, ite: 6697] train loss: 0.206943, tar: 0.020940 
l0: 0.012510, l1: 0.012432, l2: 0.013649, l3: 0.013739, l4: 0.028406, l5: 0.026337, l6: 0.031266

[epoch:  72/100000, batch:    48/  187, ite: 6698] train loss: 0.206845, tar: 0.020928 
l0: 0.015811, l1: 0.017790, l2: 0.015669, l3: 0.015984, l4: 0.026076, l5: 0.020248, l6: 0.020860

[epoch:  72/100000, batch:    50/  187, ite: 6699] train loss: 0.206739, tar: 0.020921 
l0: 0.017536, l1: 0.018232, l2: 0.018930, l3: 0.016000, l4: 0.037030, l5: 0.039646, l6: 0.034058

[epoch:  72/100000, batch:    52/  187, ite: 6700] train loss: 0.206703, tar: 0.020916 
l0: 0.015179, l1: 0.017666, l2: 0.014236, l3: 0.013662, l4: 0.022485, l5: 0.022443, l6: 0.021213

[epoch:  72/100000, batch:    54/  187, ite: 6701] train loss: 0.206589, tar: 0.020908 
l0: 0.015336, l1: 0.015807, l2: 0.017441, l3: 0.019789, l4: 0.029269, l5: 0.023002, l6: 0.030645

[epoch:  72/100000, batch:    56/  187, ite: 6702] train loss: 0.206510, tar: 0.020900 
l0: 0.010997, l1: 0.011787, l2: 0.014282, l3: 0.014089, l4: 0.016546, l5: 0.016074, l6: 0.017496

[epoch:  72/100000, batch:    58/  187, ite: 6703] train loss: 0.206360, tar: 0.020886 
l0: 0.015911, l1: 0.013943, l2: 0.022696, l3: 0.028181, l4: 0.035751, l5: 0.034346, l6: 0.045800

[epoch:  72/100000, batch:    60/  187, ite: 6704] train loss: 0.206346, tar: 0.020879 
l0: 0.017486, l1: 0.018695, l2: 0.023211, l3: 0.020843, l4: 0.038477, l5: 0.030864, l6: 0.030039

[epoch:  72/100000, batch:    62/  187, ite: 6705] train loss: 0.206309, tar: 0.020874 
l0: 0.010095, l1: 0.010664, l2: 0.010361, l3: 0.010957, l4: 0.017558, l5: 0.019815, l6: 0.020398

[epoch:  72/100000, batch:    64/  187, ite: 6706] train loss: 0.206158, tar: 0.020859 
l0: 0.020821, l1: 0.021870, l2: 0.023883, l3: 0.027185, l4: 0.030514, l5: 0.024436, l6: 0.026968

[epoch:  72/100000, batch:    66/  187, ite: 6707] train loss: 0.206115, tar: 0.020859 
l0: 0.014063, l1: 0.014460, l2: 0.013826, l3: 0.015189, l4: 0.029850, l5: 0.030334, l6: 0.037217

[epoch:  72/100000, batch:    68/  187, ite: 6708] train loss: 0.206042, tar: 0.020849 
l0: 0.038809, l1: 0.040374, l2: 0.043741, l3: 0.037932, l4: 0.054147, l5: 0.046103, l6: 0.067071

[epoch:  72/100000, batch:    70/  187, ite: 6709] train loss: 0.206215, tar: 0.020874 
l0: 0.012902, l1: 0.013082, l2: 0.014567, l3: 0.015008, l4: 0.027127, l5: 0.024315, l6: 0.025799

[epoch:  72/100000, batch:    72/  187, ite: 6710] train loss: 0.206111, tar: 0.020863 
l0: 0.019637, l1: 0.018424, l2: 0.024212, l3: 0.024603, l4: 0.043769, l5: 0.040383, l6: 0.041265

[epoch:  72/100000, batch:    74/  187, ite: 6711] train loss: 0.206120, tar: 0.020862 
l0: 0.012293, l1: 0.013072, l2: 0.013024, l3: 0.012860, l4: 0.015642, l5: 0.017907, l6: 0.019605

[epoch:  72/100000, batch:    76/  187, ite: 6712] train loss: 0.205977, tar: 0.020850 
l0: 0.021977, l1: 0.021189, l2: 0.025180, l3: 0.028179, l4: 0.054651, l5: 0.056667, l6: 0.041024

[epoch:  72/100000, batch:    78/  187, ite: 6713] train loss: 0.206037, tar: 0.020851 
l0: 0.010042, l1: 0.011014, l2: 0.014130, l3: 0.011567, l4: 0.023264, l5: 0.024627, l6: 0.025284

[epoch:  72/100000, batch:    80/  187, ite: 6714] train loss: 0.205917, tar: 0.020836 
l0: 0.034965, l1: 0.039804, l2: 0.041499, l3: 0.039102, l4: 0.016901, l5: 0.017755, l6: 0.025183

[epoch:  72/100000, batch:    82/  187, ite: 6715] train loss: 0.205930, tar: 0.020856 
l0: 0.015425, l1: 0.015567, l2: 0.016125, l3: 0.016876, l4: 0.030990, l5: 0.035203, l6: 0.033078

[epoch:  72/100000, batch:    84/  187, ite: 6716] train loss: 0.205870, tar: 0.020848 
l0: 0.019883, l1: 0.019783, l2: 0.023660, l3: 0.024429, l4: 0.029681, l5: 0.027982, l6: 0.030411

[epoch:  72/100000, batch:    86/  187, ite: 6717] train loss: 0.205828, tar: 0.020847 
l0: 0.008678, l1: 0.007848, l2: 0.010649, l3: 0.012488, l4: 0.029369, l5: 0.028358, l6: 0.032958

[epoch:  72/100000, batch:    88/  187, ite: 6718] train loss: 0.205723, tar: 0.020830 
l0: 0.014920, l1: 0.014139, l2: 0.020411, l3: 0.022050, l4: 0.049282, l5: 0.047899, l6: 0.051132

[epoch:  72/100000, batch:    90/  187, ite: 6719] train loss: 0.205743, tar: 0.020822 
l0: 0.014560, l1: 0.014264, l2: 0.019044, l3: 0.021543, l4: 0.040497, l5: 0.034628, l6: 0.031012

[epoch:  72/100000, batch:    92/  187, ite: 6720] train loss: 0.205701, tar: 0.020813 
l0: 0.011059, l1: 0.011194, l2: 0.012290, l3: 0.013670, l4: 0.031260, l5: 0.031006, l6: 0.023019

[epoch:  72/100000, batch:    94/  187, ite: 6721] train loss: 0.205601, tar: 0.020799 
l0: 0.006767, l1: 0.007173, l2: 0.007810, l3: 0.007486, l4: 0.014717, l5: 0.014231, l6: 0.019666

[epoch:  72/100000, batch:    96/  187, ite: 6722] train loss: 0.205424, tar: 0.020780 
l0: 0.020170, l1: 0.019377, l2: 0.032133, l3: 0.031830, l4: 0.051646, l5: 0.049353, l6: 0.035454

[epoch:  72/100000, batch:    98/  187, ite: 6723] train loss: 0.205471, tar: 0.020779 
l0: 0.024829, l1: 0.029774, l2: 0.021475, l3: 0.018583, l4: 0.021652, l5: 0.023961, l6: 0.026772

[epoch:  72/100000, batch:   100/  187, ite: 6724] train loss: 0.205418, tar: 0.020785 
l0: 0.017419, l1: 0.019199, l2: 0.022237, l3: 0.021406, l4: 0.030311, l5: 0.027402, l6: 0.025831

[epoch:  72/100000, batch:   102/  187, ite: 6725] train loss: 0.205361, tar: 0.020780 
l0: 0.023402, l1: 0.025931, l2: 0.019296, l3: 0.019283, l4: 0.033480, l5: 0.031089, l6: 0.033766

[epoch:  72/100000, batch:   104/  187, ite: 6726] train loss: 0.205335, tar: 0.020784 
l0: 0.011559, l1: 0.011577, l2: 0.013350, l3: 0.013050, l4: 0.018812, l5: 0.017076, l6: 0.017249

[epoch:  72/100000, batch:   106/  187, ite: 6727] train loss: 0.205193, tar: 0.020771 
l0: 0.012542, l1: 0.011699, l2: 0.016519, l3: 0.019733, l4: 0.049193, l5: 0.037508, l6: 0.043730

[epoch:  72/100000, batch:   108/  187, ite: 6728] train loss: 0.205174, tar: 0.020760 
l0: 0.011145, l1: 0.011614, l2: 0.013309, l3: 0.012727, l4: 0.034757, l5: 0.031596, l6: 0.031888

[epoch:  72/100000, batch:   110/  187, ite: 6729] train loss: 0.205094, tar: 0.020746 
l0: 0.018660, l1: 0.019616, l2: 0.026855, l3: 0.025313, l4: 0.038561, l5: 0.031365, l6: 0.036831

[epoch:  72/100000, batch:   112/  187, ite: 6730] train loss: 0.205083, tar: 0.020744 
l0: 0.017382, l1: 0.019756, l2: 0.019439, l3: 0.017238, l4: 0.025834, l5: 0.027121, l6: 0.031640

[epoch:  72/100000, batch:   114/  187, ite: 6731] train loss: 0.205019, tar: 0.020739 
l0: 0.008030, l1: 0.009222, l2: 0.008306, l3: 0.008542, l4: 0.022145, l5: 0.020186, l6: 0.017386

[epoch:  72/100000, batch:   116/  187, ite: 6732] train loss: 0.204867, tar: 0.020722 
l0: 0.025131, l1: 0.025885, l2: 0.028233, l3: 0.028874, l4: 0.027864, l5: 0.025424, l6: 0.029084

[epoch:  72/100000, batch:   118/  187, ite: 6733] train loss: 0.204848, tar: 0.020728 
l0: 0.025207, l1: 0.029461, l2: 0.027139, l3: 0.023893, l4: 0.040287, l5: 0.037343, l6: 0.022390

[epoch:  72/100000, batch:   120/  187, ite: 6734] train loss: 0.204849, tar: 0.020734 
l0: 0.012873, l1: 0.013622, l2: 0.013471, l3: 0.015336, l4: 0.019009, l5: 0.016237, l6: 0.012832

[epoch:  72/100000, batch:   122/  187, ite: 6735] train loss: 0.204711, tar: 0.020723 
l0: 0.019336, l1: 0.019144, l2: 0.020425, l3: 0.025876, l4: 0.042111, l5: 0.041976, l6: 0.038785

[epoch:  72/100000, batch:   124/  187, ite: 6736] train loss: 0.204715, tar: 0.020721 
l0: 0.017132, l1: 0.019085, l2: 0.017910, l3: 0.019296, l4: 0.029786, l5: 0.028889, l6: 0.021342

[epoch:  72/100000, batch:   126/  187, ite: 6737] train loss: 0.204645, tar: 0.020716 
l0: 0.026693, l1: 0.026794, l2: 0.032369, l3: 0.024902, l4: 0.020010, l5: 0.022408, l6: 0.028611

[epoch:  72/100000, batch:   128/  187, ite: 6738] train loss: 0.204614, tar: 0.020724 
l0: 0.019087, l1: 0.020821, l2: 0.016702, l3: 0.016653, l4: 0.028643, l5: 0.027806, l6: 0.033066

[epoch:  72/100000, batch:   130/  187, ite: 6739] train loss: 0.204558, tar: 0.020722 
l0: 0.012755, l1: 0.012335, l2: 0.014950, l3: 0.018551, l4: 0.031814, l5: 0.033254, l6: 0.037065

[epoch:  72/100000, batch:   132/  187, ite: 6740] train loss: 0.204499, tar: 0.020711 
l0: 0.016955, l1: 0.015851, l2: 0.021002, l3: 0.021158, l4: 0.028830, l5: 0.027487, l6: 0.036422

[epoch:  72/100000, batch:   134/  187, ite: 6741] train loss: 0.204449, tar: 0.020706 
l0: 0.012335, l1: 0.013767, l2: 0.011807, l3: 0.012492, l4: 0.020733, l5: 0.021993, l6: 0.027560

[epoch:  72/100000, batch:   136/  187, ite: 6742] train loss: 0.204336, tar: 0.020695 
l0: 0.024541, l1: 0.024909, l2: 0.031661, l3: 0.033111, l4: 0.026376, l5: 0.024644, l6: 0.023480

[epoch:  72/100000, batch:   138/  187, ite: 6743] train loss: 0.204315, tar: 0.020700 
l0: 0.008146, l1: 0.010713, l2: 0.013175, l3: 0.013694, l4: 0.024455, l5: 0.021255, l6: 0.012560

[epoch:  72/100000, batch:   140/  187, ite: 6744] train loss: 0.204180, tar: 0.020683 
l0: 0.039583, l1: 0.043597, l2: 0.051677, l3: 0.047490, l4: 0.041900, l5: 0.033255, l6: 0.031691

[epoch:  72/100000, batch:   142/  187, ite: 6745] train loss: 0.204294, tar: 0.020709 
l0: 0.025712, l1: 0.025379, l2: 0.032432, l3: 0.029891, l4: 0.034114, l5: 0.039055, l6: 0.040024

[epoch:  72/100000, batch:   144/  187, ite: 6746] train loss: 0.204324, tar: 0.020715 
l0: 0.017975, l1: 0.018742, l2: 0.019807, l3: 0.020187, l4: 0.028745, l5: 0.030590, l6: 0.029483

[epoch:  72/100000, batch:   146/  187, ite: 6747] train loss: 0.204272, tar: 0.020712 
l0: 0.012189, l1: 0.013248, l2: 0.012682, l3: 0.010790, l4: 0.015579, l5: 0.018635, l6: 0.022833

[epoch:  72/100000, batch:   148/  187, ite: 6748] train loss: 0.204141, tar: 0.020700 
l0: 0.012666, l1: 0.011905, l2: 0.014324, l3: 0.017795, l4: 0.021036, l5: 0.017987, l6: 0.024621

[epoch:  72/100000, batch:   150/  187, ite: 6749] train loss: 0.204029, tar: 0.020690 
l0: 0.018490, l1: 0.018724, l2: 0.027037, l3: 0.025185, l4: 0.033049, l5: 0.031209, l6: 0.027152

[epoch:  72/100000, batch:   152/  187, ite: 6750] train loss: 0.203998, tar: 0.020687 
l0: 0.012968, l1: 0.013221, l2: 0.013326, l3: 0.016050, l4: 0.026216, l5: 0.026752, l6: 0.025259

[epoch:  72/100000, batch:   154/  187, ite: 6751] train loss: 0.203905, tar: 0.020676 
l0: 0.021964, l1: 0.024016, l2: 0.020921, l3: 0.022064, l4: 0.033366, l5: 0.034343, l6: 0.033199

[epoch:  72/100000, batch:   156/  187, ite: 6752] train loss: 0.203886, tar: 0.020678 
l0: 0.027961, l1: 0.030110, l2: 0.027193, l3: 0.027252, l4: 0.037341, l5: 0.038391, l6: 0.032496

[epoch:  72/100000, batch:   158/  187, ite: 6753] train loss: 0.203908, tar: 0.020688 
l0: 0.019513, l1: 0.018456, l2: 0.022043, l3: 0.023744, l4: 0.024793, l5: 0.031656, l6: 0.038091

[epoch:  72/100000, batch:   160/  187, ite: 6754] train loss: 0.203874, tar: 0.020686 
l0: 0.015181, l1: 0.016422, l2: 0.023181, l3: 0.020544, l4: 0.027193, l5: 0.027000, l6: 0.027971

[epoch:  72/100000, batch:   162/  187, ite: 6755] train loss: 0.203813, tar: 0.020679 
l0: 0.019526, l1: 0.019123, l2: 0.020096, l3: 0.024541, l4: 0.032720, l5: 0.029057, l6: 0.034601

[epoch:  72/100000, batch:   164/  187, ite: 6756] train loss: 0.203781, tar: 0.020677 
l0: 0.023764, l1: 0.023991, l2: 0.031255, l3: 0.034757, l4: 0.034220, l5: 0.027812, l6: 0.035057

[epoch:  72/100000, batch:   166/  187, ite: 6757] train loss: 0.203790, tar: 0.020682 
l0: 0.020134, l1: 0.018534, l2: 0.024140, l3: 0.025633, l4: 0.042011, l5: 0.045869, l6: 0.048748

[epoch:  72/100000, batch:   168/  187, ite: 6758] train loss: 0.203818, tar: 0.020681 
l0: 0.016189, l1: 0.015444, l2: 0.017722, l3: 0.020269, l4: 0.028615, l5: 0.031554, l6: 0.026744

[epoch:  72/100000, batch:   170/  187, ite: 6759] train loss: 0.203756, tar: 0.020675 
l0: 0.016700, l1: 0.015952, l2: 0.018095, l3: 0.019259, l4: 0.035186, l5: 0.043946, l6: 0.048603

[epoch:  72/100000, batch:   172/  187, ite: 6760] train loss: 0.203748, tar: 0.020670 
l0: 0.012035, l1: 0.012198, l2: 0.012829, l3: 0.013119, l4: 0.020027, l5: 0.021460, l6: 0.023836

[epoch:  72/100000, batch:   174/  187, ite: 6761] train loss: 0.203632, tar: 0.020658 
l0: 0.018627, l1: 0.019849, l2: 0.026417, l3: 0.024965, l4: 0.024744, l5: 0.021521, l6: 0.025515

[epoch:  72/100000, batch:   176/  187, ite: 6762] train loss: 0.203577, tar: 0.020656 
l0: 0.015398, l1: 0.016322, l2: 0.028966, l3: 0.019312, l4: 0.025123, l5: 0.023188, l6: 0.019280

[epoch:  72/100000, batch:   178/  187, ite: 6763] train loss: 0.203504, tar: 0.020649 
l0: 0.015633, l1: 0.016997, l2: 0.018518, l3: 0.016858, l4: 0.029805, l5: 0.031175, l6: 0.023658

[epoch:  72/100000, batch:   180/  187, ite: 6764] train loss: 0.203437, tar: 0.020642 
l0: 0.010827, l1: 0.011539, l2: 0.014766, l3: 0.013183, l4: 0.021259, l5: 0.018832, l6: 0.020117

[epoch:  72/100000, batch:   182/  187, ite: 6765] train loss: 0.203316, tar: 0.020629 
l0: 0.018222, l1: 0.021295, l2: 0.019471, l3: 0.026879, l4: 0.040083, l5: 0.025444, l6: 0.026074

[epoch:  72/100000, batch:   184/  187, ite: 6766] train loss: 0.203282, tar: 0.020626 
l0: 0.013286, l1: 0.012670, l2: 0.015838, l3: 0.018647, l4: 0.029032, l5: 0.028639, l6: 0.028710

[epoch:  72/100000, batch:   186/  187, ite: 6767] train loss: 0.203208, tar: 0.020617 
l0: 0.011719, l1: 0.009800, l2: 0.028490, l3: 0.027158, l4: 0.033472, l5: 0.048071, l6: 0.038350

[epoch:  72/100000, batch:   188/  187, ite: 6768] train loss: 0.203200, tar: 0.020605 
l0: 0.026263, l1: 0.026810, l2: 0.028178, l3: 0.027365, l4: 0.039711, l5: 0.040706, l6: 0.032752

[epoch:  73/100000, batch:     2/  187, ite: 6769] train loss: 0.203224, tar: 0.020612 
l0: 0.015042, l1: 0.016214, l2: 0.015720, l3: 0.014557, l4: 0.023645, l5: 0.022383, l6: 0.023926

[epoch:  73/100000, batch:     4/  187, ite: 6770] train loss: 0.203131, tar: 0.020605 
l0: 0.008585, l1: 0.009595, l2: 0.010618, l3: 0.011052, l4: 0.017313, l5: 0.021095, l6: 0.024006

[epoch:  73/100000, batch:     6/  187, ite: 6771] train loss: 0.203000, tar: 0.020590 
l0: 0.033523, l1: 0.035928, l2: 0.043394, l3: 0.046196, l4: 0.041526, l5: 0.030780, l6: 0.035692

[epoch:  73/100000, batch:     8/  187, ite: 6772] train loss: 0.203083, tar: 0.020606 
l0: 0.014542, l1: 0.014367, l2: 0.018037, l3: 0.017967, l4: 0.022698, l5: 0.027767, l6: 0.029560

[epoch:  73/100000, batch:    10/  187, ite: 6773] train loss: 0.203008, tar: 0.020599 
l0: 0.011522, l1: 0.012973, l2: 0.016117, l3: 0.014572, l4: 0.020939, l5: 0.019323, l6: 0.022686

[epoch:  73/100000, batch:    12/  187, ite: 6774] train loss: 0.202899, tar: 0.020587 
l0: 0.021802, l1: 0.021204, l2: 0.028075, l3: 0.028344, l4: 0.027045, l5: 0.027196, l6: 0.028363

[epoch:  73/100000, batch:    14/  187, ite: 6775] train loss: 0.202872, tar: 0.020588 
l0: 0.013289, l1: 0.011777, l2: 0.016063, l3: 0.018058, l4: 0.027667, l5: 0.026827, l6: 0.030422

[epoch:  73/100000, batch:    16/  187, ite: 6776] train loss: 0.202796, tar: 0.020579 
l0: 0.014915, l1: 0.016389, l2: 0.017588, l3: 0.020179, l4: 0.026837, l5: 0.029383, l6: 0.026285

[epoch:  73/100000, batch:    18/  187, ite: 6777] train loss: 0.202730, tar: 0.020572 
l0: 0.008290, l1: 0.008927, l2: 0.009707, l3: 0.010617, l4: 0.015457, l5: 0.018389, l6: 0.016789

[epoch:  73/100000, batch:    20/  187, ite: 6778] train loss: 0.202583, tar: 0.020556 
l0: 0.014243, l1: 0.018110, l2: 0.013439, l3: 0.014013, l4: 0.025564, l5: 0.028278, l6: 0.025584

[epoch:  73/100000, batch:    22/  187, ite: 6779] train loss: 0.202501, tar: 0.020548 
l0: 0.016083, l1: 0.018683, l2: 0.017107, l3: 0.019705, l4: 0.043635, l5: 0.054947, l6: 0.059687

[epoch:  73/100000, batch:    24/  187, ite: 6780] train loss: 0.202536, tar: 0.020542 
l0: 0.018035, l1: 0.022791, l2: 0.026034, l3: 0.023875, l4: 0.030929, l5: 0.020143, l6: 0.014598

[epoch:  73/100000, batch:    26/  187, ite: 6781] train loss: 0.202477, tar: 0.020539 
l0: 0.010803, l1: 0.009870, l2: 0.015487, l3: 0.015684, l4: 0.031344, l5: 0.036501, l6: 0.031606

[epoch:  73/100000, batch:    28/  187, ite: 6782] train loss: 0.202412, tar: 0.020526 
l0: 0.014475, l1: 0.016432, l2: 0.017470, l3: 0.015391, l4: 0.026645, l5: 0.024384, l6: 0.023830

[epoch:  73/100000, batch:    30/  187, ite: 6783] train loss: 0.202330, tar: 0.020519 
l0: 0.016659, l1: 0.016908, l2: 0.020613, l3: 0.017326, l4: 0.033817, l5: 0.037450, l6: 0.035930

[epoch:  73/100000, batch:    32/  187, ite: 6784] train loss: 0.202300, tar: 0.020514 
l0: 0.012877, l1: 0.010855, l2: 0.019817, l3: 0.028754, l4: 0.043794, l5: 0.039127, l6: 0.033321

[epoch:  73/100000, batch:    34/  187, ite: 6785] train loss: 0.202283, tar: 0.020504 
l0: 0.014269, l1: 0.014701, l2: 0.017322, l3: 0.020237, l4: 0.029483, l5: 0.030921, l6: 0.029381

[epoch:  73/100000, batch:    36/  187, ite: 6786] train loss: 0.202224, tar: 0.020496 
l0: 0.015599, l1: 0.017431, l2: 0.017522, l3: 0.017786, l4: 0.024069, l5: 0.018379, l6: 0.027103

[epoch:  73/100000, batch:    38/  187, ite: 6787] train loss: 0.202143, tar: 0.020490 
l0: 0.010884, l1: 0.011256, l2: 0.015078, l3: 0.014421, l4: 0.031278, l5: 0.031192, l6: 0.026573

[epoch:  73/100000, batch:    40/  187, ite: 6788] train loss: 0.202065, tar: 0.020478 
l0: 0.017658, l1: 0.017446, l2: 0.016743, l3: 0.018543, l4: 0.022103, l5: 0.023632, l6: 0.030545

[epoch:  73/100000, batch:    42/  187, ite: 6789] train loss: 0.201994, tar: 0.020474 
l0: 0.013375, l1: 0.014838, l2: 0.016657, l3: 0.014555, l4: 0.019417, l5: 0.018297, l6: 0.021460

[epoch:  73/100000, batch:    44/  187, ite: 6790] train loss: 0.201889, tar: 0.020465 
l0: 0.014127, l1: 0.013741, l2: 0.019282, l3: 0.018829, l4: 0.031470, l5: 0.031013, l6: 0.033522

[epoch:  73/100000, batch:    46/  187, ite: 6791] train loss: 0.201838, tar: 0.020457 
l0: 0.014906, l1: 0.015401, l2: 0.017231, l3: 0.018569, l4: 0.027786, l5: 0.025381, l6: 0.025491

[epoch:  73/100000, batch:    48/  187, ite: 6792] train loss: 0.201766, tar: 0.020450 
l0: 0.015251, l1: 0.015827, l2: 0.017532, l3: 0.015358, l4: 0.029790, l5: 0.031377, l6: 0.028529

[epoch:  73/100000, batch:    50/  187, ite: 6793] train loss: 0.201706, tar: 0.020444 
l0: 0.015728, l1: 0.016067, l2: 0.013226, l3: 0.016193, l4: 0.027368, l5: 0.029775, l6: 0.030726

[epoch:  73/100000, batch:    52/  187, ite: 6794] train loss: 0.201639, tar: 0.020438 
l0: 0.011092, l1: 0.014471, l2: 0.007881, l3: 0.008563, l4: 0.015090, l5: 0.017084, l6: 0.015682

[epoch:  73/100000, batch:    54/  187, ite: 6795] train loss: 0.201499, tar: 0.020426 
l0: 0.030220, l1: 0.024761, l2: 0.032586, l3: 0.044771, l4: 0.053777, l5: 0.062749, l6: 0.073498

[epoch:  73/100000, batch:    56/  187, ite: 6796] train loss: 0.201651, tar: 0.020438 
l0: 0.011401, l1: 0.010814, l2: 0.015185, l3: 0.017577, l4: 0.021098, l5: 0.020026, l6: 0.030261

[epoch:  73/100000, batch:    58/  187, ite: 6797] train loss: 0.201556, tar: 0.020427 
l0: 0.009914, l1: 0.009778, l2: 0.016680, l3: 0.017693, l4: 0.031963, l5: 0.031346, l6: 0.022511

[epoch:  73/100000, batch:    60/  187, ite: 6798] train loss: 0.201479, tar: 0.020414 
l0: 0.016710, l1: 0.014828, l2: 0.021846, l3: 0.025235, l4: 0.029128, l5: 0.030485, l6: 0.026429

[epoch:  73/100000, batch:    62/  187, ite: 6799] train loss: 0.201433, tar: 0.020409 
l0: 0.016080, l1: 0.016077, l2: 0.015085, l3: 0.017328, l4: 0.034132, l5: 0.027415, l6: 0.026449

[epoch:  73/100000, batch:    64/  187, ite: 6800] train loss: 0.201372, tar: 0.020404 
l0: 0.017829, l1: 0.017408, l2: 0.023622, l3: 0.024782, l4: 0.039623, l5: 0.041307, l6: 0.041549

[epoch:  73/100000, batch:    66/  187, ite: 6801] train loss: 0.201378, tar: 0.020400 
l0: 0.014517, l1: 0.013854, l2: 0.015602, l3: 0.018380, l4: 0.033392, l5: 0.034817, l6: 0.029617

[epoch:  73/100000, batch:    68/  187, ite: 6802] train loss: 0.201326, tar: 0.020393 
l0: 0.013011, l1: 0.013140, l2: 0.014208, l3: 0.015654, l4: 0.018375, l5: 0.019268, l6: 0.018701

[epoch:  73/100000, batch:    70/  187, ite: 6803] train loss: 0.201215, tar: 0.020384 
l0: 0.015148, l1: 0.014711, l2: 0.022950, l3: 0.020174, l4: 0.033760, l5: 0.033172, l6: 0.030534

[epoch:  73/100000, batch:    72/  187, ite: 6804] train loss: 0.201177, tar: 0.020377 
l0: 0.011971, l1: 0.013017, l2: 0.014606, l3: 0.013996, l4: 0.027044, l5: 0.023091, l6: 0.021995

[epoch:  73/100000, batch:    74/  187, ite: 6805] train loss: 0.201083, tar: 0.020367 
l0: 0.009833, l1: 0.010131, l2: 0.009808, l3: 0.011267, l4: 0.023602, l5: 0.021097, l6: 0.026156

[epoch:  73/100000, batch:    76/  187, ite: 6806] train loss: 0.200973, tar: 0.020354 
l0: 0.027249, l1: 0.025451, l2: 0.024702, l3: 0.039317, l4: 0.099852, l5: 0.070318, l6: 0.060789

[epoch:  73/100000, batch:    78/  187, ite: 6807] train loss: 0.201155, tar: 0.020362 
l0: 0.017217, l1: 0.018677, l2: 0.020945, l3: 0.021424, l4: 0.029120, l5: 0.024063, l6: 0.022487

[epoch:  73/100000, batch:    80/  187, ite: 6808] train loss: 0.201096, tar: 0.020358 
l0: 0.009762, l1: 0.009250, l2: 0.018902, l3: 0.018983, l4: 0.023774, l5: 0.022894, l6: 0.018654

[epoch:  73/100000, batch:    82/  187, ite: 6809] train loss: 0.200999, tar: 0.020345 
l0: 0.010836, l1: 0.010556, l2: 0.015023, l3: 0.014545, l4: 0.017880, l5: 0.018848, l6: 0.025451

[epoch:  73/100000, batch:    84/  187, ite: 6810] train loss: 0.200890, tar: 0.020334 
l0: 0.021783, l1: 0.024283, l2: 0.029028, l3: 0.030495, l4: 0.029750, l5: 0.033236, l6: 0.041389

[epoch:  73/100000, batch:    86/  187, ite: 6811] train loss: 0.200901, tar: 0.020335 
l0: 0.021560, l1: 0.024581, l2: 0.020393, l3: 0.017264, l4: 0.024641, l5: 0.024892, l6: 0.034656

[epoch:  73/100000, batch:    88/  187, ite: 6812] train loss: 0.200861, tar: 0.020337 
l0: 0.023580, l1: 0.024598, l2: 0.025394, l3: 0.026863, l4: 0.030087, l5: 0.032390, l6: 0.032019

[epoch:  73/100000, batch:    90/  187, ite: 6813] train loss: 0.200853, tar: 0.020341 
l0: 0.015125, l1: 0.011860, l2: 0.024170, l3: 0.026771, l4: 0.032419, l5: 0.047572, l6: 0.093773

[epoch:  73/100000, batch:    92/  187, ite: 6814] train loss: 0.200916, tar: 0.020335 
l0: 0.017530, l1: 0.019100, l2: 0.019093, l3: 0.019963, l4: 0.034335, l5: 0.027942, l6: 0.027590

[epoch:  73/100000, batch:    94/  187, ite: 6815] train loss: 0.200873, tar: 0.020331 
l0: 0.021337, l1: 0.021852, l2: 0.025401, l3: 0.026280, l4: 0.066767, l5: 0.052978, l6: 0.032179

[epoch:  73/100000, batch:    96/  187, ite: 6816] train loss: 0.200929, tar: 0.020332 
l0: 0.014328, l1: 0.013930, l2: 0.019230, l3: 0.022048, l4: 0.048365, l5: 0.038798, l6: 0.030647

[epoch:  73/100000, batch:    98/  187, ite: 6817] train loss: 0.200912, tar: 0.020325 
l0: 0.008608, l1: 0.010143, l2: 0.009012, l3: 0.010668, l4: 0.027209, l5: 0.023261, l6: 0.032613

[epoch:  73/100000, batch:   100/  187, ite: 6818] train loss: 0.200815, tar: 0.020311 
l0: 0.012503, l1: 0.012872, l2: 0.013897, l3: 0.016680, l4: 0.030575, l5: 0.031829, l6: 0.029386

[epoch:  73/100000, batch:   102/  187, ite: 6819] train loss: 0.200750, tar: 0.020301 
l0: 0.028522, l1: 0.026652, l2: 0.029140, l3: 0.036131, l4: 0.048344, l5: 0.048110, l6: 0.044975

[epoch:  73/100000, batch:   104/  187, ite: 6820] train loss: 0.200825, tar: 0.020311 
l0: 0.014285, l1: 0.016146, l2: 0.011030, l3: 0.013020, l4: 0.028157, l5: 0.026264, l6: 0.028577

[epoch:  73/100000, batch:   106/  187, ite: 6821] train loss: 0.200748, tar: 0.020304 
l0: 0.013608, l1: 0.015550, l2: 0.012618, l3: 0.015350, l4: 0.027089, l5: 0.023770, l6: 0.023934

[epoch:  73/100000, batch:   108/  187, ite: 6822] train loss: 0.200664, tar: 0.020296 
l0: 0.010210, l1: 0.011828, l2: 0.009812, l3: 0.009572, l4: 0.014216, l5: 0.016001, l6: 0.022485

[epoch:  73/100000, batch:   110/  187, ite: 6823] train loss: 0.200535, tar: 0.020283 
l0: 0.013001, l1: 0.014439, l2: 0.018032, l3: 0.020700, l4: 0.033186, l5: 0.023775, l6: 0.024683

[epoch:  73/100000, batch:   112/  187, ite: 6824] train loss: 0.200471, tar: 0.020275 
l0: 0.005436, l1: 0.005632, l2: 0.007301, l3: 0.007366, l4: 0.014455, l5: 0.015692, l6: 0.014117

[epoch:  73/100000, batch:   114/  187, ite: 6825] train loss: 0.200312, tar: 0.020257 
l0: 0.019915, l1: 0.020011, l2: 0.020899, l3: 0.022295, l4: 0.024847, l5: 0.020569, l6: 0.028283

[epoch:  73/100000, batch:   116/  187, ite: 6826] train loss: 0.200260, tar: 0.020256 
l0: 0.011910, l1: 0.013354, l2: 0.014650, l3: 0.014858, l4: 0.029325, l5: 0.020310, l6: 0.021445

[epoch:  73/100000, batch:   118/  187, ite: 6827] train loss: 0.200170, tar: 0.020246 
l0: 0.009966, l1: 0.011350, l2: 0.011471, l3: 0.015481, l4: 0.020312, l5: 0.017167, l6: 0.015868

[epoch:  73/100000, batch:   120/  187, ite: 6828] train loss: 0.200051, tar: 0.020234 
l0: 0.010494, l1: 0.009947, l2: 0.013345, l3: 0.012243, l4: 0.024681, l5: 0.027624, l6: 0.036320

[epoch:  73/100000, batch:   122/  187, ite: 6829] train loss: 0.199972, tar: 0.020222 
l0: 0.012390, l1: 0.011573, l2: 0.016980, l3: 0.024563, l4: 0.050619, l5: 0.058007, l6: 0.035091

[epoch:  73/100000, batch:   124/  187, ite: 6830] train loss: 0.199983, tar: 0.020212 
l0: 0.018470, l1: 0.020767, l2: 0.018403, l3: 0.020900, l4: 0.039774, l5: 0.039491, l6: 0.040754

[epoch:  73/100000, batch:   126/  187, ite: 6831] train loss: 0.199981, tar: 0.020210 
l0: 0.018020, l1: 0.020792, l2: 0.020529, l3: 0.029425, l4: 0.034587, l5: 0.028123, l6: 0.030587

[epoch:  73/100000, batch:   128/  187, ite: 6832] train loss: 0.199960, tar: 0.020208 
l0: 0.027319, l1: 0.029389, l2: 0.039886, l3: 0.030637, l4: 0.051340, l5: 0.046794, l6: 0.048169

[epoch:  73/100000, batch:   130/  187, ite: 6833] train loss: 0.200048, tar: 0.020216 
l0: 0.020438, l1: 0.022946, l2: 0.020290, l3: 0.017789, l4: 0.025426, l5: 0.024449, l6: 0.023650

[epoch:  73/100000, batch:   132/  187, ite: 6834] train loss: 0.199994, tar: 0.020217 
l0: 0.021741, l1: 0.024193, l2: 0.025383, l3: 0.025756, l4: 0.036096, l5: 0.036917, l6: 0.040949

[epoch:  73/100000, batch:   134/  187, ite: 6835] train loss: 0.200007, tar: 0.020218 
l0: 0.008737, l1: 0.011840, l2: 0.008801, l3: 0.008073, l4: 0.014156, l5: 0.014989, l6: 0.019707

[epoch:  73/100000, batch:   136/  187, ite: 6836] train loss: 0.199871, tar: 0.020205 
l0: 0.037320, l1: 0.038419, l2: 0.026828, l3: 0.039178, l4: 0.081398, l5: 0.101932, l6: 0.099871

[epoch:  73/100000, batch:   138/  187, ite: 6837] train loss: 0.200140, tar: 0.020225 
l0: 0.017540, l1: 0.016203, l2: 0.024666, l3: 0.028315, l4: 0.051854, l5: 0.054211, l6: 0.060277

[epoch:  73/100000, batch:   140/  187, ite: 6838] train loss: 0.200203, tar: 0.020222 
l0: 0.013503, l1: 0.012307, l2: 0.014331, l3: 0.016912, l4: 0.034739, l5: 0.035491, l6: 0.034688

[epoch:  73/100000, batch:   142/  187, ite: 6839] train loss: 0.200158, tar: 0.020214 
l0: 0.026372, l1: 0.027395, l2: 0.024763, l3: 0.023891, l4: 0.030841, l5: 0.040288, l6: 0.037093

[epoch:  73/100000, batch:   144/  187, ite: 6840] train loss: 0.200170, tar: 0.020221 
l0: 0.019899, l1: 0.019166, l2: 0.022870, l3: 0.027361, l4: 0.046377, l5: 0.044925, l6: 0.049100

[epoch:  73/100000, batch:   146/  187, ite: 6841] train loss: 0.200205, tar: 0.020221 
l0: 0.017455, l1: 0.017453, l2: 0.020537, l3: 0.020154, l4: 0.032438, l5: 0.036789, l6: 0.033592

[epoch:  73/100000, batch:   148/  187, ite: 6842] train loss: 0.200179, tar: 0.020218 
l0: 0.013962, l1: 0.015013, l2: 0.014984, l3: 0.015798, l4: 0.024596, l5: 0.028211, l6: 0.035481

[epoch:  73/100000, batch:   150/  187, ite: 6843] train loss: 0.200118, tar: 0.020210 
l0: 0.003643, l1: 0.003646, l2: 0.005195, l3: 0.005236, l4: 0.007715, l5: 0.011053, l6: 0.010587

[epoch:  73/100000, batch:   152/  187, ite: 6844] train loss: 0.199936, tar: 0.020190 
l0: 0.019531, l1: 0.017384, l2: 0.022048, l3: 0.026065, l4: 0.045410, l5: 0.049129, l6: 0.063567

[epoch:  73/100000, batch:   154/  187, ite: 6845] train loss: 0.199987, tar: 0.020190 
l0: 0.023744, l1: 0.024461, l2: 0.027291, l3: 0.028348, l4: 0.032997, l5: 0.030459, l6: 0.033958

[epoch:  73/100000, batch:   156/  187, ite: 6846] train loss: 0.199989, tar: 0.020194 
l0: 0.008594, l1: 0.010101, l2: 0.007936, l3: 0.007285, l4: 0.015474, l5: 0.019453, l6: 0.025410

[epoch:  73/100000, batch:   158/  187, ite: 6847] train loss: 0.199864, tar: 0.020180 
l0: 0.033125, l1: 0.036797, l2: 0.028214, l3: 0.025635, l4: 0.031479, l5: 0.030351, l6: 0.028553

[epoch:  73/100000, batch:   160/  187, ite: 6848] train loss: 0.199881, tar: 0.020195 
l0: 0.018063, l1: 0.014748, l2: 0.018931, l3: 0.031977, l4: 0.081448, l5: 0.089672, l6: 0.141086

[epoch:  73/100000, batch:   162/  187, ite: 6849] train loss: 0.200112, tar: 0.020193 
l0: 0.019992, l1: 0.018673, l2: 0.019784, l3: 0.019606, l4: 0.049772, l5: 0.053308, l6: 0.071059

[epoch:  73/100000, batch:   164/  187, ite: 6850] train loss: 0.200173, tar: 0.020193 
l0: 0.014141, l1: 0.015819, l2: 0.012255, l3: 0.013825, l4: 0.027355, l5: 0.029718, l6: 0.026278

[epoch:  73/100000, batch:   166/  187, ite: 6851] train loss: 0.200102, tar: 0.020186 
l0: 0.039803, l1: 0.038442, l2: 0.044463, l3: 0.041906, l4: 0.051371, l5: 0.058518, l6: 0.060229

[epoch:  73/100000, batch:   168/  187, ite: 6852] train loss: 0.200260, tar: 0.020209 
l0: 0.018946, l1: 0.019114, l2: 0.018357, l3: 0.019970, l4: 0.034847, l5: 0.042930, l6: 0.039831

[epoch:  73/100000, batch:   170/  187, ite: 6853] train loss: 0.200252, tar: 0.020207 
l0: 0.012629, l1: 0.011467, l2: 0.015092, l3: 0.019275, l4: 0.034822, l5: 0.039483, l6: 0.039755

[epoch:  73/100000, batch:   172/  187, ite: 6854] train loss: 0.200220, tar: 0.020198 
l0: 0.019661, l1: 0.019577, l2: 0.021968, l3: 0.023306, l4: 0.039390, l5: 0.035357, l6: 0.043860

[epoch:  73/100000, batch:   174/  187, ite: 6855] train loss: 0.200223, tar: 0.020198 
l0: 0.017632, l1: 0.017501, l2: 0.015736, l3: 0.018848, l4: 0.030762, l5: 0.029700, l6: 0.036361

[epoch:  73/100000, batch:   176/  187, ite: 6856] train loss: 0.200184, tar: 0.020195 
l0: 0.029301, l1: 0.027139, l2: 0.027166, l3: 0.029404, l4: 0.068409, l5: 0.067040, l6: 0.071003

[epoch:  73/100000, batch:   178/  187, ite: 6857] train loss: 0.200323, tar: 0.020205 
l0: 0.014382, l1: 0.015361, l2: 0.013254, l3: 0.015889, l4: 0.036781, l5: 0.034155, l6: 0.038709

[epoch:  73/100000, batch:   180/  187, ite: 6858] train loss: 0.200286, tar: 0.020198 
l0: 0.021594, l1: 0.020862, l2: 0.022923, l3: 0.025282, l4: 0.040640, l5: 0.041806, l6: 0.048649

[epoch:  73/100000, batch:   182/  187, ite: 6859] train loss: 0.200311, tar: 0.020200 
l0: 0.013923, l1: 0.009954, l2: 0.020013, l3: 0.025069, l4: 0.058002, l5: 0.071120, l6: 0.099772

[epoch:  73/100000, batch:   184/  187, ite: 6860] train loss: 0.200425, tar: 0.020193 
l0: 0.039767, l1: 0.042801, l2: 0.043388, l3: 0.041106, l4: 0.046082, l5: 0.046090, l6: 0.047857

[epoch:  73/100000, batch:   186/  187, ite: 6861] train loss: 0.200548, tar: 0.020216 
l0: 0.017964, l1: 0.017251, l2: 0.022825, l3: 0.024744, l4: 0.034568, l5: 0.038829, l6: 0.043978

[epoch:  73/100000, batch:   188/  187, ite: 6862] train loss: 0.200548, tar: 0.020213 
l0: 0.008398, l1: 0.008632, l2: 0.009957, l3: 0.009867, l4: 0.026798, l5: 0.023159, l6: 0.021741

[epoch:  74/100000, batch:     2/  187, ite: 6863] train loss: 0.200441, tar: 0.020199 
l0: 0.018014, l1: 0.019244, l2: 0.017901, l3: 0.015785, l4: 0.035497, l5: 0.039876, l6: 0.036863

[epoch:  74/100000, batch:     4/  187, ite: 6864] train loss: 0.200421, tar: 0.020197 
l0: 0.016250, l1: 0.015812, l2: 0.018496, l3: 0.017475, l4: 0.042687, l5: 0.042787, l6: 0.045092

[epoch:  74/100000, batch:     6/  187, ite: 6865] train loss: 0.200419, tar: 0.020192 
l0: 0.009769, l1: 0.010020, l2: 0.013454, l3: 0.011542, l4: 0.027640, l5: 0.023835, l6: 0.016847

[epoch:  74/100000, batch:     8/  187, ite: 6866] train loss: 0.200318, tar: 0.020180 
l0: 0.020033, l1: 0.019307, l2: 0.020380, l3: 0.022845, l4: 0.041158, l5: 0.047190, l6: 0.042834

[epoch:  74/100000, batch:    10/  187, ite: 6867] train loss: 0.200334, tar: 0.020180 
l0: 0.016114, l1: 0.015628, l2: 0.027207, l3: 0.027873, l4: 0.044737, l5: 0.034587, l6: 0.042300

[epoch:  74/100000, batch:    12/  187, ite: 6868] train loss: 0.200343, tar: 0.020175 
l0: 0.015171, l1: 0.016254, l2: 0.015226, l3: 0.015416, l4: 0.033085, l5: 0.025674, l6: 0.037136

[epoch:  74/100000, batch:    14/  187, ite: 6869] train loss: 0.200294, tar: 0.020170 
l0: 0.011544, l1: 0.011375, l2: 0.017796, l3: 0.018434, l4: 0.033362, l5: 0.032476, l6: 0.028733

[epoch:  74/100000, batch:    16/  187, ite: 6870] train loss: 0.200241, tar: 0.020160 
l0: 0.018497, l1: 0.018473, l2: 0.019642, l3: 0.027762, l4: 0.074757, l5: 0.057663, l6: 0.059575

[epoch:  74/100000, batch:    18/  187, ite: 6871] train loss: 0.200328, tar: 0.020158 
l0: 0.024126, l1: 0.022832, l2: 0.025988, l3: 0.033733, l4: 0.076234, l5: 0.066295, l6: 0.069228

[epoch:  74/100000, batch:    20/  187, ite: 6872] train loss: 0.200464, tar: 0.020162 
l0: 0.014985, l1: 0.014984, l2: 0.018401, l3: 0.018420, l4: 0.026342, l5: 0.026080, l6: 0.022968

[epoch:  74/100000, batch:    22/  187, ite: 6873] train loss: 0.200397, tar: 0.020156 
l0: 0.012592, l1: 0.013074, l2: 0.012585, l3: 0.016763, l4: 0.032252, l5: 0.027549, l6: 0.035260

[epoch:  74/100000, batch:    24/  187, ite: 6874] train loss: 0.200339, tar: 0.020148 
l0: 0.011136, l1: 0.011685, l2: 0.014751, l3: 0.015955, l4: 0.028052, l5: 0.022327, l6: 0.023784

[epoch:  74/100000, batch:    26/  187, ite: 6875] train loss: 0.200256, tar: 0.020137 
l0: 0.016416, l1: 0.016421, l2: 0.016483, l3: 0.020785, l4: 0.028926, l5: 0.027997, l6: 0.028623

[epoch:  74/100000, batch:    28/  187, ite: 6876] train loss: 0.200206, tar: 0.020133 
l0: 0.013874, l1: 0.016051, l2: 0.014863, l3: 0.014546, l4: 0.023373, l5: 0.020686, l6: 0.023105

[epoch:  74/100000, batch:    30/  187, ite: 6877] train loss: 0.200121, tar: 0.020126 
l0: 0.016526, l1: 0.016525, l2: 0.018006, l3: 0.020133, l4: 0.037914, l5: 0.040905, l6: 0.033890

[epoch:  74/100000, batch:    32/  187, ite: 6878] train loss: 0.200103, tar: 0.020122 
l0: 0.020490, l1: 0.021139, l2: 0.021521, l3: 0.022475, l4: 0.048310, l5: 0.037798, l6: 0.038973

[epoch:  74/100000, batch:    34/  187, ite: 6879] train loss: 0.200115, tar: 0.020122 
l0: 0.018820, l1: 0.019782, l2: 0.019862, l3: 0.022426, l4: 0.038981, l5: 0.034226, l6: 0.043985

[epoch:  74/100000, batch:    36/  187, ite: 6880] train loss: 0.200113, tar: 0.020121 
l0: 0.017411, l1: 0.020594, l2: 0.015759, l3: 0.016184, l4: 0.022899, l5: 0.023185, l6: 0.019184

[epoch:  74/100000, batch:    38/  187, ite: 6881] train loss: 0.200039, tar: 0.020118 
l0: 0.013486, l1: 0.015034, l2: 0.011262, l3: 0.012847, l4: 0.024416, l5: 0.022800, l6: 0.022719

[epoch:  74/100000, batch:    40/  187, ite: 6882] train loss: 0.199951, tar: 0.020110 
l0: 0.018253, l1: 0.016235, l2: 0.023408, l3: 0.024685, l4: 0.044841, l5: 0.053630, l6: 0.050159

[epoch:  74/100000, batch:    42/  187, ite: 6883] train loss: 0.199987, tar: 0.020108 
l0: 0.013974, l1: 0.012626, l2: 0.019127, l3: 0.020369, l4: 0.029461, l5: 0.029641, l6: 0.034016

[epoch:  74/100000, batch:    44/  187, ite: 6884] train loss: 0.199941, tar: 0.020101 
l0: 0.014372, l1: 0.015087, l2: 0.016298, l3: 0.013085, l4: 0.022887, l5: 0.023769, l6: 0.024952

[epoch:  74/100000, batch:    46/  187, ite: 6885] train loss: 0.199862, tar: 0.020095 
l0: 0.010422, l1: 0.010393, l2: 0.012267, l3: 0.011696, l4: 0.022274, l5: 0.019542, l6: 0.021257

[epoch:  74/100000, batch:    48/  187, ite: 6886] train loss: 0.199758, tar: 0.020084 
l0: 0.018384, l1: 0.018526, l2: 0.019538, l3: 0.021768, l4: 0.026636, l5: 0.027322, l6: 0.028445

[epoch:  74/100000, batch:    50/  187, ite: 6887] train loss: 0.199714, tar: 0.020082 
l0: 0.012140, l1: 0.011635, l2: 0.013800, l3: 0.014009, l4: 0.049571, l5: 0.058072, l6: 0.077250

[epoch:  74/100000, batch:    52/  187, ite: 6888] train loss: 0.199755, tar: 0.020073 
l0: 0.012206, l1: 0.010817, l2: 0.021993, l3: 0.027345, l4: 0.028746, l5: 0.025967, l6: 0.022503

[epoch:  74/100000, batch:    54/  187, ite: 6889] train loss: 0.199699, tar: 0.020064 
l0: 0.020055, l1: 0.021869, l2: 0.020973, l3: 0.023148, l4: 0.030395, l5: 0.028422, l6: 0.029707

[epoch:  74/100000, batch:    56/  187, ite: 6890] train loss: 0.199671, tar: 0.020064 
l0: 0.023424, l1: 0.022194, l2: 0.025569, l3: 0.029435, l4: 0.086384, l5: 0.086711, l6: 0.074224

[epoch:  74/100000, batch:    58/  187, ite: 6891] train loss: 0.199837, tar: 0.020068 
l0: 0.018853, l1: 0.019519, l2: 0.021371, l3: 0.019063, l4: 0.033355, l5: 0.030745, l6: 0.034435

[epoch:  74/100000, batch:    60/  187, ite: 6892] train loss: 0.199812, tar: 0.020066 
l0: 0.019475, l1: 0.020203, l2: 0.024237, l3: 0.024806, l4: 0.035185, l5: 0.031215, l6: 0.034831

[epoch:  74/100000, batch:    62/  187, ite: 6893] train loss: 0.199801, tar: 0.020066 
l0: 0.011380, l1: 0.011120, l2: 0.013295, l3: 0.012209, l4: 0.039535, l5: 0.043973, l6: 0.047480

[epoch:  74/100000, batch:    64/  187, ite: 6894] train loss: 0.199778, tar: 0.020056 
l0: 0.015388, l1: 0.013370, l2: 0.016139, l3: 0.018783, l4: 0.040915, l5: 0.044964, l6: 0.044206

[epoch:  74/100000, batch:    66/  187, ite: 6895] train loss: 0.199771, tar: 0.020051 
l0: 0.025951, l1: 0.025255, l2: 0.025174, l3: 0.022940, l4: 0.041556, l5: 0.045528, l6: 0.055164

[epoch:  74/100000, batch:    68/  187, ite: 6896] train loss: 0.199818, tar: 0.020057 
l0: 0.010950, l1: 0.011289, l2: 0.013584, l3: 0.011360, l4: 0.020710, l5: 0.019927, l6: 0.021887

[epoch:  74/100000, batch:    70/  187, ite: 6897] train loss: 0.199717, tar: 0.020047 
l0: 0.012243, l1: 0.012245, l2: 0.015140, l3: 0.014266, l4: 0.038503, l5: 0.029920, l6: 0.035748

[epoch:  74/100000, batch:    72/  187, ite: 6898] train loss: 0.199671, tar: 0.020039 
l0: 0.010396, l1: 0.011148, l2: 0.013068, l3: 0.014316, l4: 0.030635, l5: 0.033738, l6: 0.038702

[epoch:  74/100000, batch:    74/  187, ite: 6899] train loss: 0.199618, tar: 0.020028 
l0: 0.013060, l1: 0.013359, l2: 0.016900, l3: 0.016824, l4: 0.022652, l5: 0.023777, l6: 0.023299

[epoch:  74/100000, batch:    76/  187, ite: 6900] train loss: 0.199540, tar: 0.020020 
l0: 0.016320, l1: 0.017456, l2: 0.016897, l3: 0.019195, l4: 0.026539, l5: 0.027632, l6: 0.023125

[epoch:  74/100000, batch:    78/  187, ite: 6901] train loss: 0.199482, tar: 0.020016 
l0: 0.019875, l1: 0.020445, l2: 0.021035, l3: 0.025464, l4: 0.033524, l5: 0.031892, l6: 0.028631

[epoch:  74/100000, batch:    80/  187, ite: 6902] train loss: 0.199461, tar: 0.020016 
l0: 0.010211, l1: 0.009756, l2: 0.011462, l3: 0.012391, l4: 0.018841, l5: 0.018915, l6: 0.023780

[epoch:  74/100000, batch:    82/  187, ite: 6903] train loss: 0.199357, tar: 0.020005 
l0: 0.011978, l1: 0.013833, l2: 0.016972, l3: 0.014774, l4: 0.043199, l5: 0.034250, l6: 0.023733

[epoch:  74/100000, batch:    84/  187, ite: 6904] train loss: 0.199312, tar: 0.019996 
l0: 0.010939, l1: 0.012203, l2: 0.010838, l3: 0.011810, l4: 0.024514, l5: 0.022538, l6: 0.021249

[epoch:  74/100000, batch:    86/  187, ite: 6905] train loss: 0.199218, tar: 0.019986 
l0: 0.009788, l1: 0.009662, l2: 0.015879, l3: 0.015746, l4: 0.026457, l5: 0.026283, l6: 0.020400

[epoch:  74/100000, batch:    88/  187, ite: 6906] train loss: 0.199135, tar: 0.019975 
l0: 0.062471, l1: 0.066085, l2: 0.067935, l3: 0.061454, l4: 0.070740, l5: 0.072755, l6: 0.061465

[epoch:  74/100000, batch:    90/  187, ite: 6907] train loss: 0.199426, tar: 0.020022 
l0: 0.022448, l1: 0.022153, l2: 0.030927, l3: 0.029614, l4: 0.029369, l5: 0.030929, l6: 0.034404

[epoch:  74/100000, batch:    92/  187, ite: 6908] train loss: 0.199427, tar: 0.020024 
l0: 0.026334, l1: 0.025278, l2: 0.028036, l3: 0.030181, l4: 0.053396, l5: 0.054061, l6: 0.060576

[epoch:  74/100000, batch:    94/  187, ite: 6909] train loss: 0.199513, tar: 0.020031 
l0: 0.014397, l1: 0.014525, l2: 0.017964, l3: 0.020562, l4: 0.028853, l5: 0.030057, l6: 0.028961

[epoch:  74/100000, batch:    96/  187, ite: 6910] train loss: 0.199464, tar: 0.020025 
l0: 0.021000, l1: 0.022573, l2: 0.022426, l3: 0.026413, l4: 0.024731, l5: 0.023590, l6: 0.019400

[epoch:  74/100000, batch:    98/  187, ite: 6911] train loss: 0.199421, tar: 0.020026 
l0: 0.012897, l1: 0.014441, l2: 0.014564, l3: 0.016455, l4: 0.021521, l5: 0.021608, l6: 0.020229

[epoch:  74/100000, batch:   100/  187, ite: 6912] train loss: 0.199336, tar: 0.020018 
l0: 0.010362, l1: 0.010711, l2: 0.011934, l3: 0.016223, l4: 0.042399, l5: 0.035827, l6: 0.033186

[epoch:  74/100000, batch:   102/  187, ite: 6913] train loss: 0.199294, tar: 0.020008 
l0: 0.016996, l1: 0.017461, l2: 0.013774, l3: 0.015845, l4: 0.016508, l5: 0.019030, l6: 0.019151

[epoch:  74/100000, batch:   104/  187, ite: 6914] train loss: 0.199205, tar: 0.020005 
l0: 0.017347, l1: 0.018940, l2: 0.020635, l3: 0.021589, l4: 0.023705, l5: 0.022907, l6: 0.025077

[epoch:  74/100000, batch:   106/  187, ite: 6915] train loss: 0.199152, tar: 0.020002 
l0: 0.009516, l1: 0.009201, l2: 0.010230, l3: 0.010929, l4: 0.025643, l5: 0.022981, l6: 0.019916

[epoch:  74/100000, batch:   108/  187, ite: 6916] train loss: 0.199053, tar: 0.019990 
l0: 0.012318, l1: 0.011656, l2: 0.013937, l3: 0.014630, l4: 0.026991, l5: 0.030059, l6: 0.031225

[epoch:  74/100000, batch:   110/  187, ite: 6917] train loss: 0.198989, tar: 0.019982 
l0: 0.016036, l1: 0.015454, l2: 0.021056, l3: 0.020708, l4: 0.027449, l5: 0.029630, l6: 0.028252

[epoch:  74/100000, batch:   112/  187, ite: 6918] train loss: 0.198945, tar: 0.019978 
l0: 0.022113, l1: 0.024419, l2: 0.021745, l3: 0.023273, l4: 0.022086, l5: 0.028082, l6: 0.033422

[epoch:  74/100000, batch:   114/  187, ite: 6919] train loss: 0.198919, tar: 0.019980 
l0: 0.013406, l1: 0.013841, l2: 0.018445, l3: 0.017910, l4: 0.025900, l5: 0.023019, l6: 0.026841

[epoch:  74/100000, batch:   116/  187, ite: 6920] train loss: 0.198855, tar: 0.019973 
l0: 0.009070, l1: 0.009003, l2: 0.014753, l3: 0.014528, l4: 0.022661, l5: 0.021751, l6: 0.020863

[epoch:  74/100000, batch:   118/  187, ite: 6921] train loss: 0.198761, tar: 0.019961 
l0: 0.021323, l1: 0.024916, l2: 0.018079, l3: 0.018944, l4: 0.041049, l5: 0.032513, l6: 0.028659

[epoch:  74/100000, batch:   120/  187, ite: 6922] train loss: 0.198747, tar: 0.019962 
l0: 0.010571, l1: 0.010799, l2: 0.012135, l3: 0.013532, l4: 0.020984, l5: 0.021730, l6: 0.020145

[epoch:  74/100000, batch:   122/  187, ite: 6923] train loss: 0.198650, tar: 0.019952 
l0: 0.009055, l1: 0.008831, l2: 0.008772, l3: 0.009014, l4: 0.022513, l5: 0.026874, l6: 0.028208

[epoch:  74/100000, batch:   124/  187, ite: 6924] train loss: 0.198558, tar: 0.019940 
l0: 0.018499, l1: 0.018791, l2: 0.019728, l3: 0.021399, l4: 0.032937, l5: 0.028662, l6: 0.031593

[epoch:  74/100000, batch:   126/  187, ite: 6925] train loss: 0.198529, tar: 0.019939 
l0: 0.017199, l1: 0.018201, l2: 0.022862, l3: 0.023717, l4: 0.041655, l5: 0.030459, l6: 0.031592

[epoch:  74/100000, batch:   128/  187, ite: 6926] train loss: 0.198515, tar: 0.019936 
l0: 0.014729, l1: 0.014858, l2: 0.017092, l3: 0.019782, l4: 0.019402, l5: 0.020235, l6: 0.022630

[epoch:  74/100000, batch:   130/  187, ite: 6927] train loss: 0.198440, tar: 0.019930 
l0: 0.010984, l1: 0.010789, l2: 0.015082, l3: 0.016133, l4: 0.026517, l5: 0.036097, l6: 0.029489

[epoch:  74/100000, batch:   132/  187, ite: 6928] train loss: 0.198382, tar: 0.019921 
l0: 0.021031, l1: 0.027511, l2: 0.019590, l3: 0.019276, l4: 0.035414, l5: 0.038526, l6: 0.034462

[epoch:  74/100000, batch:   134/  187, ite: 6929] train loss: 0.198379, tar: 0.019922 
l0: 0.013517, l1: 0.013571, l2: 0.019756, l3: 0.019650, l4: 0.024650, l5: 0.024582, l6: 0.025775

[epoch:  74/100000, batch:   136/  187, ite: 6930] train loss: 0.198318, tar: 0.019915 
l0: 0.008737, l1: 0.009654, l2: 0.009386, l3: 0.011352, l4: 0.012129, l5: 0.018677, l6: 0.021299

[epoch:  74/100000, batch:   138/  187, ite: 6931] train loss: 0.198203, tar: 0.019903 
l0: 0.010534, l1: 0.009675, l2: 0.012348, l3: 0.014885, l4: 0.018287, l5: 0.019580, l6: 0.021084

[epoch:  74/100000, batch:   140/  187, ite: 6932] train loss: 0.198105, tar: 0.019893 
l0: 0.035799, l1: 0.039278, l2: 0.032993, l3: 0.034851, l4: 0.033634, l5: 0.029941, l6: 0.032883

[epoch:  74/100000, batch:   142/  187, ite: 6933] train loss: 0.198149, tar: 0.019910 
l0: 0.013310, l1: 0.012304, l2: 0.015948, l3: 0.018575, l4: 0.027033, l5: 0.026591, l6: 0.023892

[epoch:  74/100000, batch:   144/  187, ite: 6934] train loss: 0.198084, tar: 0.019903 
l0: 0.007367, l1: 0.007492, l2: 0.008175, l3: 0.010126, l4: 0.008544, l5: 0.010147, l6: 0.009229

[epoch:  74/100000, batch:   146/  187, ite: 6935] train loss: 0.197938, tar: 0.019889 
l0: 0.019954, l1: 0.019538, l2: 0.020106, l3: 0.024580, l4: 0.038478, l5: 0.034996, l6: 0.037535

[epoch:  74/100000, batch:   148/  187, ite: 6936] train loss: 0.197935, tar: 0.019889 
l0: 0.012691, l1: 0.012947, l2: 0.017154, l3: 0.013467, l4: 0.017727, l5: 0.015932, l6: 0.019291

[epoch:  74/100000, batch:   150/  187, ite: 6937] train loss: 0.197840, tar: 0.019882 
l0: 0.021199, l1: 0.023400, l2: 0.028208, l3: 0.021750, l4: 0.025414, l5: 0.022492, l6: 0.024775

[epoch:  74/100000, batch:   152/  187, ite: 6938] train loss: 0.197807, tar: 0.019883 
l0: 0.030074, l1: 0.032389, l2: 0.031438, l3: 0.029356, l4: 0.043566, l5: 0.042743, l6: 0.047219

[epoch:  74/100000, batch:   154/  187, ite: 6939] train loss: 0.197870, tar: 0.019894 
l0: 0.011652, l1: 0.012574, l2: 0.018557, l3: 0.017469, l4: 0.021029, l5: 0.019300, l6: 0.024604

[epoch:  74/100000, batch:   156/  187, ite: 6940] train loss: 0.197793, tar: 0.019885 
l0: 0.011998, l1: 0.012601, l2: 0.011970, l3: 0.011880, l4: 0.027853, l5: 0.038564, l6: 0.038548

[epoch:  74/100000, batch:   158/  187, ite: 6941] train loss: 0.197746, tar: 0.019877 
l0: 0.010831, l1: 0.010301, l2: 0.023087, l3: 0.021155, l4: 0.025026, l5: 0.022496, l6: 0.022271

[epoch:  74/100000, batch:   160/  187, ite: 6942] train loss: 0.197679, tar: 0.019867 
l0: 0.012781, l1: 0.013200, l2: 0.014538, l3: 0.013974, l4: 0.029815, l5: 0.027717, l6: 0.029412

[epoch:  74/100000, batch:   162/  187, ite: 6943] train loss: 0.197620, tar: 0.019860 
l0: 0.016672, l1: 0.017103, l2: 0.017431, l3: 0.020918, l4: 0.052917, l5: 0.047343, l6: 0.035483

[epoch:  74/100000, batch:   164/  187, ite: 6944] train loss: 0.197631, tar: 0.019856 
l0: 0.013907, l1: 0.014324, l2: 0.016777, l3: 0.017900, l4: 0.032754, l5: 0.031846, l6: 0.032578

[epoch:  74/100000, batch:   166/  187, ite: 6945] train loss: 0.197591, tar: 0.019850 
l0: 0.015410, l1: 0.018328, l2: 0.016220, l3: 0.015939, l4: 0.030724, l5: 0.024851, l6: 0.021559

[epoch:  74/100000, batch:   168/  187, ite: 6946] train loss: 0.197533, tar: 0.019845 
l0: 0.024473, l1: 0.025674, l2: 0.024264, l3: 0.022245, l4: 0.042445, l5: 0.038169, l6: 0.048807

[epoch:  74/100000, batch:   170/  187, ite: 6947] train loss: 0.197563, tar: 0.019850 
l0: 0.011225, l1: 0.010060, l2: 0.013516, l3: 0.015983, l4: 0.031598, l5: 0.036194, l6: 0.029400

[epoch:  74/100000, batch:   172/  187, ite: 6948] train loss: 0.197511, tar: 0.019841 
l0: 0.008945, l1: 0.009507, l2: 0.010419, l3: 0.010190, l4: 0.016298, l5: 0.014620, l6: 0.016953

[epoch:  74/100000, batch:   174/  187, ite: 6949] train loss: 0.197394, tar: 0.019830 
l0: 0.024104, l1: 0.025496, l2: 0.026251, l3: 0.031141, l4: 0.035313, l5: 0.028098, l6: 0.027943

[epoch:  74/100000, batch:   176/  187, ite: 6950] train loss: 0.197395, tar: 0.019834 
l0: 0.012467, l1: 0.011845, l2: 0.016783, l3: 0.019378, l4: 0.025831, l5: 0.025302, l6: 0.027002

[epoch:  74/100000, batch:   178/  187, ite: 6951] train loss: 0.197334, tar: 0.019826 
l0: 0.022498, l1: 0.025009, l2: 0.023996, l3: 0.021508, l4: 0.024863, l5: 0.023474, l6: 0.023518

[epoch:  74/100000, batch:   180/  187, ite: 6952] train loss: 0.197300, tar: 0.019829 
l0: 0.017254, l1: 0.015014, l2: 0.031867, l3: 0.025773, l4: 0.026171, l5: 0.029291, l6: 0.029523

[epoch:  74/100000, batch:   182/  187, ite: 6953] train loss: 0.197276, tar: 0.019827 
l0: 0.028064, l1: 0.027307, l2: 0.028552, l3: 0.036103, l4: 0.053753, l5: 0.047963, l6: 0.055065

[epoch:  74/100000, batch:   184/  187, ite: 6954] train loss: 0.197359, tar: 0.019835 
l0: 0.013526, l1: 0.012952, l2: 0.017697, l3: 0.018526, l4: 0.018378, l5: 0.019908, l6: 0.022550

[epoch:  74/100000, batch:   186/  187, ite: 6955] train loss: 0.197282, tar: 0.019829 
l0: 0.020830, l1: 0.022095, l2: 0.021012, l3: 0.024125, l4: 0.023110, l5: 0.023413, l6: 0.024894

[epoch:  74/100000, batch:   188/  187, ite: 6956] train loss: 0.197243, tar: 0.019830 
l0: 0.008535, l1: 0.008995, l2: 0.010901, l3: 0.011594, l4: 0.014353, l5: 0.015743, l6: 0.017819

[epoch:  75/100000, batch:     2/  187, ite: 6957] train loss: 0.197128, tar: 0.019818 
l0: 0.030686, l1: 0.030126, l2: 0.034730, l3: 0.039640, l4: 0.032551, l5: 0.029348, l6: 0.040244

[epoch:  75/100000, batch:     4/  187, ite: 6958] train loss: 0.197170, tar: 0.019829 
l0: 0.009384, l1: 0.009433, l2: 0.009559, l3: 0.011132, l4: 0.029253, l5: 0.028064, l6: 0.027767

[epoch:  75/100000, batch:     6/  187, ite: 6959] train loss: 0.197095, tar: 0.019818 
l0: 0.010818, l1: 0.009926, l2: 0.010952, l3: 0.013217, l4: 0.020563, l5: 0.020802, l6: 0.025849

[epoch:  75/100000, batch:     8/  187, ite: 6960] train loss: 0.197006, tar: 0.019809 
l0: 0.023767, l1: 0.020702, l2: 0.036236, l3: 0.034707, l4: 0.037710, l5: 0.039112, l6: 0.040835

[epoch:  75/100000, batch:    10/  187, ite: 6961] train loss: 0.197044, tar: 0.019813 
l0: 0.008090, l1: 0.009192, l2: 0.008796, l3: 0.007865, l4: 0.017267, l5: 0.020789, l6: 0.019930

[epoch:  75/100000, batch:    12/  187, ite: 6962] train loss: 0.196934, tar: 0.019801 
l0: 0.013705, l1: 0.015283, l2: 0.016156, l3: 0.015431, l4: 0.027324, l5: 0.022333, l6: 0.019698

[epoch:  75/100000, batch:    14/  187, ite: 6963] train loss: 0.196865, tar: 0.019795 
l0: 0.019992, l1: 0.021907, l2: 0.024397, l3: 0.021901, l4: 0.050065, l5: 0.041056, l6: 0.040863

[epoch:  75/100000, batch:    16/  187, ite: 6964] train loss: 0.196889, tar: 0.019795 
l0: 0.014940, l1: 0.014064, l2: 0.016174, l3: 0.020474, l4: 0.026195, l5: 0.032419, l6: 0.033095

[epoch:  75/100000, batch:    18/  187, ite: 6965] train loss: 0.196848, tar: 0.019790 
l0: 0.019140, l1: 0.019530, l2: 0.019938, l3: 0.021632, l4: 0.026086, l5: 0.024244, l6: 0.033677

[epoch:  75/100000, batch:    20/  187, ite: 6966] train loss: 0.196814, tar: 0.019789 
l0: 0.018384, l1: 0.017575, l2: 0.030526, l3: 0.030920, l4: 0.037319, l5: 0.033806, l6: 0.029774

[epoch:  75/100000, batch:    22/  187, ite: 6967] train loss: 0.196816, tar: 0.019788 
l0: 0.014305, l1: 0.014839, l2: 0.015731, l3: 0.017345, l4: 0.020812, l5: 0.029022, l6: 0.035155

[epoch:  75/100000, batch:    24/  187, ite: 6968] train loss: 0.196765, tar: 0.019782 
l0: 0.018746, l1: 0.019608, l2: 0.020446, l3: 0.019497, l4: 0.025746, l5: 0.025794, l6: 0.032301

[epoch:  75/100000, batch:    26/  187, ite: 6969] train loss: 0.196729, tar: 0.019781 
l0: 0.014930, l1: 0.016402, l2: 0.012535, l3: 0.012229, l4: 0.025321, l5: 0.028282, l6: 0.038359

[epoch:  75/100000, batch:    28/  187, ite: 6970] train loss: 0.196679, tar: 0.019776 
l0: 0.017392, l1: 0.016708, l2: 0.022206, l3: 0.023078, l4: 0.049900, l5: 0.044615, l6: 0.046703

[epoch:  75/100000, batch:    30/  187, ite: 6971] train loss: 0.196703, tar: 0.019773 
l0: 0.013315, l1: 0.014164, l2: 0.014588, l3: 0.021249, l4: 0.028153, l5: 0.028002, l6: 0.030453

[epoch:  75/100000, batch:    32/  187, ite: 6972] train loss: 0.196655, tar: 0.019767 
l0: 0.016765, l1: 0.016756, l2: 0.018825, l3: 0.018788, l4: 0.031156, l5: 0.034862, l6: 0.030466

[epoch:  75/100000, batch:    34/  187, ite: 6973] train loss: 0.196625, tar: 0.019764 
l0: 0.017816, l1: 0.016664, l2: 0.020292, l3: 0.026946, l4: 0.058247, l5: 0.049426, l6: 0.056094

[epoch:  75/100000, batch:    36/  187, ite: 6974] train loss: 0.196675, tar: 0.019762 
l0: 0.014072, l1: 0.011650, l2: 0.014932, l3: 0.023193, l4: 0.041546, l5: 0.042658, l6: 0.043269

[epoch:  75/100000, batch:    38/  187, ite: 6975] train loss: 0.196670, tar: 0.019756 
l0: 0.016623, l1: 0.016326, l2: 0.020325, l3: 0.022139, l4: 0.028113, l5: 0.026620, l6: 0.029759

[epoch:  75/100000, batch:    40/  187, ite: 6976] train loss: 0.196632, tar: 0.019753 
l0: 0.014943, l1: 0.014163, l2: 0.017081, l3: 0.019272, l4: 0.034688, l5: 0.033223, l6: 0.037587

[epoch:  75/100000, batch:    42/  187, ite: 6977] train loss: 0.196606, tar: 0.019748 
l0: 0.015642, l1: 0.017085, l2: 0.013735, l3: 0.015042, l4: 0.017904, l5: 0.020304, l6: 0.018204

[epoch:  75/100000, batch:    44/  187, ite: 6978] train loss: 0.196526, tar: 0.019744 
l0: 0.020893, l1: 0.022826, l2: 0.027716, l3: 0.024167, l4: 0.032483, l5: 0.028518, l6: 0.031360

[epoch:  75/100000, batch:    46/  187, ite: 6979] train loss: 0.196517, tar: 0.019745 
l0: 0.015841, l1: 0.014968, l2: 0.019923, l3: 0.023132, l4: 0.027303, l5: 0.027300, l6: 0.028331

[epoch:  75/100000, batch:    48/  187, ite: 6980] train loss: 0.196476, tar: 0.019741 
l0: 0.012728, l1: 0.013983, l2: 0.014944, l3: 0.014305, l4: 0.021129, l5: 0.027699, l6: 0.023046

[epoch:  75/100000, batch:    50/  187, ite: 6981] train loss: 0.196406, tar: 0.019734 
l0: 0.034708, l1: 0.036103, l2: 0.038119, l3: 0.031934, l4: 0.036464, l5: 0.038050, l6: 0.043474

[epoch:  75/100000, batch:    52/  187, ite: 6982] train loss: 0.196470, tar: 0.019749 
l0: 0.009020, l1: 0.011037, l2: 0.009420, l3: 0.008481, l4: 0.018532, l5: 0.016935, l6: 0.015830

[epoch:  75/100000, batch:    54/  187, ite: 6983] train loss: 0.196361, tar: 0.019738 
l0: 0.011557, l1: 0.011931, l2: 0.017109, l3: 0.016461, l4: 0.037750, l5: 0.042938, l6: 0.036822

[epoch:  75/100000, batch:    56/  187, ite: 6984] train loss: 0.196339, tar: 0.019730 
l0: 0.014664, l1: 0.013142, l2: 0.022129, l3: 0.022485, l4: 0.033103, l5: 0.038517, l6: 0.031987

[epoch:  75/100000, batch:    58/  187, ite: 6985] train loss: 0.196318, tar: 0.019724 
l0: 0.011166, l1: 0.011704, l2: 0.013081, l3: 0.012873, l4: 0.018854, l5: 0.019298, l6: 0.016852

[epoch:  75/100000, batch:    60/  187, ite: 6986] train loss: 0.196224, tar: 0.019716 
l0: 0.012991, l1: 0.013658, l2: 0.015637, l3: 0.015722, l4: 0.043129, l5: 0.042765, l6: 0.049235

[epoch:  75/100000, batch:    62/  187, ite: 6987] train loss: 0.196221, tar: 0.019709 
l0: 0.022286, l1: 0.022938, l2: 0.023723, l3: 0.025662, l4: 0.023864, l5: 0.026583, l6: 0.042336

[epoch:  75/100000, batch:    64/  187, ite: 6988] train loss: 0.196212, tar: 0.019712 
l0: 0.015631, l1: 0.015846, l2: 0.018039, l3: 0.018583, l4: 0.028196, l5: 0.026006, l6: 0.027247

[epoch:  75/100000, batch:    66/  187, ite: 6989] train loss: 0.196165, tar: 0.019707 
l0: 0.009136, l1: 0.009706, l2: 0.017756, l3: 0.015978, l4: 0.033628, l5: 0.030345, l6: 0.023554

[epoch:  75/100000, batch:    68/  187, ite: 6990] train loss: 0.196108, tar: 0.019697 
l0: 0.026773, l1: 0.027025, l2: 0.025284, l3: 0.028725, l4: 0.043140, l5: 0.040357, l6: 0.050631

[epoch:  75/100000, batch:    70/  187, ite: 6991] train loss: 0.196155, tar: 0.019704 
l0: 0.014993, l1: 0.016034, l2: 0.014962, l3: 0.014172, l4: 0.025601, l5: 0.021951, l6: 0.027514

[epoch:  75/100000, batch:    72/  187, ite: 6992] train loss: 0.196093, tar: 0.019699 
l0: 0.015092, l1: 0.015133, l2: 0.020073, l3: 0.021347, l4: 0.041224, l5: 0.035345, l6: 0.034633

[epoch:  75/100000, batch:    74/  187, ite: 6993] train loss: 0.196080, tar: 0.019694 
l0: 0.008659, l1: 0.008991, l2: 0.011938, l3: 0.015676, l4: 0.024289, l5: 0.028051, l6: 0.019611

[epoch:  75/100000, batch:    76/  187, ite: 6994] train loss: 0.196001, tar: 0.019683 
l0: 0.009455, l1: 0.010018, l2: 0.013839, l3: 0.014050, l4: 0.019540, l5: 0.017942, l6: 0.017496

[epoch:  75/100000, batch:    78/  187, ite: 6995] train loss: 0.195906, tar: 0.019673 
l0: 0.010928, l1: 0.011237, l2: 0.010704, l3: 0.012986, l4: 0.015388, l5: 0.016166, l6: 0.019419

[epoch:  75/100000, batch:    80/  187, ite: 6996] train loss: 0.195807, tar: 0.019664 
l0: 0.011482, l1: 0.012415, l2: 0.012949, l3: 0.012472, l4: 0.017105, l5: 0.019174, l6: 0.020266

[epoch:  75/100000, batch:    82/  187, ite: 6997] train loss: 0.195717, tar: 0.019656 
l0: 0.016399, l1: 0.018075, l2: 0.020215, l3: 0.014040, l4: 0.019965, l5: 0.021751, l6: 0.024856

[epoch:  75/100000, batch:    84/  187, ite: 6998] train loss: 0.195656, tar: 0.019653 
l0: 0.007073, l1: 0.008100, l2: 0.009352, l3: 0.007091, l4: 0.017698, l5: 0.017557, l6: 0.015920

[epoch:  75/100000, batch:    86/  187, ite: 6999] train loss: 0.195543, tar: 0.019640 
l0: 0.019176, l1: 0.021114, l2: 0.025672, l3: 0.023034, l4: 0.036920, l5: 0.038122, l6: 0.030083

[epoch:  75/100000, batch:    88/  187, ite: 7000] train loss: 0.195542, tar: 0.019640 
l0: 0.010247, l1: 0.009819, l2: 0.011581, l3: 0.012371, l4: 0.023865, l5: 0.031935, l6: 0.047697

[epoch:  75/100000, batch:    90/  187, ite: 7001] train loss: 0.195494, tar: 0.019630 
l0: 0.005908, l1: 0.006588, l2: 0.009112, l3: 0.006713, l4: 0.010206, l5: 0.007779, l6: 0.006667

[epoch:  75/100000, batch:    92/  187, ite: 7002] train loss: 0.195352, tar: 0.019617 
l0: 0.011637, l1: 0.011765, l2: 0.016034, l3: 0.016895, l4: 0.026560, l5: 0.026846, l6: 0.036448

[epoch:  75/100000, batch:    94/  187, ite: 7003] train loss: 0.195303, tar: 0.019609 
l0: 0.017053, l1: 0.018461, l2: 0.019035, l3: 0.020559, l4: 0.031108, l5: 0.026689, l6: 0.027678

[epoch:  75/100000, batch:    96/  187, ite: 7004] train loss: 0.195268, tar: 0.019606 
l0: 0.011200, l1: 0.010842, l2: 0.013486, l3: 0.017930, l4: 0.027224, l5: 0.022190, l6: 0.017772

[epoch:  75/100000, batch:    98/  187, ite: 7005] train loss: 0.195194, tar: 0.019598 
l0: 0.012829, l1: 0.014006, l2: 0.011189, l3: 0.011837, l4: 0.028178, l5: 0.025155, l6: 0.025317

[epoch:  75/100000, batch:   100/  187, ite: 7006] train loss: 0.195127, tar: 0.019591 
l0: 0.032479, l1: 0.037566, l2: 0.027808, l3: 0.025584, l4: 0.034151, l5: 0.033298, l6: 0.035595

[epoch:  75/100000, batch:   102/  187, ite: 7007] train loss: 0.195159, tar: 0.019604 
l0: 0.020843, l1: 0.023332, l2: 0.019283, l3: 0.019677, l4: 0.031250, l5: 0.032091, l6: 0.030760

[epoch:  75/100000, batch:   104/  187, ite: 7008] train loss: 0.195141, tar: 0.019605 
l0: 0.014966, l1: 0.013731, l2: 0.016307, l3: 0.016750, l4: 0.029877, l5: 0.032877, l6: 0.035238

[epoch:  75/100000, batch:   106/  187, ite: 7009] train loss: 0.195106, tar: 0.019601 
l0: 0.012045, l1: 0.012519, l2: 0.011884, l3: 0.011365, l4: 0.018162, l5: 0.020440, l6: 0.019683

[epoch:  75/100000, batch:   108/  187, ite: 7010] train loss: 0.195018, tar: 0.019593 
l0: 0.013604, l1: 0.013821, l2: 0.017104, l3: 0.016329, l4: 0.019800, l5: 0.020045, l6: 0.024885

[epoch:  75/100000, batch:   110/  187, ite: 7011] train loss: 0.194949, tar: 0.019587 
l0: 0.011735, l1: 0.012007, l2: 0.015656, l3: 0.015653, l4: 0.041304, l5: 0.036286, l6: 0.037793

[epoch:  75/100000, batch:   112/  187, ite: 7012] train loss: 0.194925, tar: 0.019579 
l0: 0.021523, l1: 0.021004, l2: 0.025326, l3: 0.025528, l4: 0.025960, l5: 0.029297, l6: 0.035179

[epoch:  75/100000, batch:   114/  187, ite: 7013] train loss: 0.194914, tar: 0.019581 
l0: 0.011406, l1: 0.012810, l2: 0.013628, l3: 0.010948, l4: 0.032946, l5: 0.026810, l6: 0.026726

[epoch:  75/100000, batch:   116/  187, ite: 7014] train loss: 0.194855, tar: 0.019573 
l0: 0.012636, l1: 0.013373, l2: 0.015237, l3: 0.015666, l4: 0.024815, l5: 0.026179, l6: 0.028431

[epoch:  75/100000, batch:   118/  187, ite: 7015] train loss: 0.194797, tar: 0.019566 
l0: 0.037560, l1: 0.047676, l2: 0.041756, l3: 0.028309, l4: 0.032435, l5: 0.031401, l6: 0.043851

[epoch:  75/100000, batch:   120/  187, ite: 7016] train loss: 0.194864, tar: 0.019584 
l0: 0.017796, l1: 0.018054, l2: 0.015798, l3: 0.018945, l4: 0.041271, l5: 0.045475, l6: 0.043400

[epoch:  75/100000, batch:   122/  187, ite: 7017] train loss: 0.194870, tar: 0.019582 
l0: 0.019956, l1: 0.022825, l2: 0.018238, l3: 0.016252, l4: 0.035256, l5: 0.025089, l6: 0.020746

[epoch:  75/100000, batch:   124/  187, ite: 7018] train loss: 0.194834, tar: 0.019583 
l0: 0.024374, l1: 0.023868, l2: 0.035497, l3: 0.034703, l4: 0.063657, l5: 0.060486, l6: 0.037791

[epoch:  75/100000, batch:   126/  187, ite: 7019] train loss: 0.194918, tar: 0.019587 
l0: 0.014648, l1: 0.013307, l2: 0.016674, l3: 0.019573, l4: 0.020801, l5: 0.025956, l6: 0.025802

[epoch:  75/100000, batch:   128/  187, ite: 7020] train loss: 0.194861, tar: 0.019583 
l0: 0.042268, l1: 0.046018, l2: 0.037600, l3: 0.032678, l4: 0.041468, l5: 0.039940, l6: 0.061001

[epoch:  75/100000, batch:   130/  187, ite: 7021] train loss: 0.194965, tar: 0.019605 
l0: 0.015048, l1: 0.016690, l2: 0.017058, l3: 0.016090, l4: 0.027662, l5: 0.026611, l6: 0.022430

[epoch:  75/100000, batch:   132/  187, ite: 7022] train loss: 0.194913, tar: 0.019600 
l0: 0.036474, l1: 0.042430, l2: 0.039069, l3: 0.033249, l4: 0.042479, l5: 0.041164, l6: 0.055490

[epoch:  75/100000, batch:   134/  187, ite: 7023] train loss: 0.195006, tar: 0.019617 
l0: 0.013529, l1: 0.015893, l2: 0.014328, l3: 0.015512, l4: 0.024002, l5: 0.026453, l6: 0.035633

[epoch:  75/100000, batch:   136/  187, ite: 7024] train loss: 0.194958, tar: 0.019611 
l0: 0.026813, l1: 0.027061, l2: 0.032715, l3: 0.032700, l4: 0.039073, l5: 0.037067, l6: 0.034088

[epoch:  75/100000, batch:   138/  187, ite: 7025] train loss: 0.194991, tar: 0.019618 
l0: 0.018178, l1: 0.019376, l2: 0.017906, l3: 0.018028, l4: 0.014783, l5: 0.016266, l6: 0.019233

[epoch:  75/100000, batch:   140/  187, ite: 7026] train loss: 0.194922, tar: 0.019617 
l0: 0.015916, l1: 0.017243, l2: 0.019571, l3: 0.023515, l4: 0.035188, l5: 0.025713, l6: 0.026450

[epoch:  75/100000, batch:   142/  187, ite: 7027] train loss: 0.194892, tar: 0.019613 
l0: 0.013812, l1: 0.012028, l2: 0.018360, l3: 0.024045, l4: 0.035195, l5: 0.035469, l6: 0.031872

[epoch:  75/100000, batch:   144/  187, ite: 7028] train loss: 0.194868, tar: 0.019607 
l0: 0.020865, l1: 0.021945, l2: 0.021507, l3: 0.021794, l4: 0.034815, l5: 0.035253, l6: 0.035956

[epoch:  75/100000, batch:   146/  187, ite: 7029] train loss: 0.194865, tar: 0.019609 
l0: 0.010362, l1: 0.010839, l2: 0.012657, l3: 0.009889, l4: 0.025841, l5: 0.021661, l6: 0.020166

[epoch:  75/100000, batch:   148/  187, ite: 7030] train loss: 0.194784, tar: 0.019600 
l0: 0.015949, l1: 0.015034, l2: 0.015459, l3: 0.017744, l4: 0.038226, l5: 0.031684, l6: 0.032561

[epoch:  75/100000, batch:   150/  187, ite: 7031] train loss: 0.194757, tar: 0.019596 
l0: 0.010360, l1: 0.010435, l2: 0.011782, l3: 0.011934, l4: 0.014356, l5: 0.018663, l6: 0.019039

[epoch:  75/100000, batch:   152/  187, ite: 7032] train loss: 0.194662, tar: 0.019587 
l0: 0.022473, l1: 0.027210, l2: 0.017319, l3: 0.018868, l4: 0.030278, l5: 0.032981, l6: 0.036802

[epoch:  75/100000, batch:   154/  187, ite: 7033] train loss: 0.194654, tar: 0.019590 
l0: 0.015823, l1: 0.015536, l2: 0.016758, l3: 0.017685, l4: 0.023559, l5: 0.023757, l6: 0.024516

[epoch:  75/100000, batch:   156/  187, ite: 7034] train loss: 0.194598, tar: 0.019586 
l0: 0.013808, l1: 0.014426, l2: 0.013151, l3: 0.013390, l4: 0.024339, l5: 0.023036, l6: 0.027904

[epoch:  75/100000, batch:   158/  187, ite: 7035] train loss: 0.194536, tar: 0.019581 
l0: 0.011082, l1: 0.011833, l2: 0.011709, l3: 0.013131, l4: 0.019133, l5: 0.019470, l6: 0.024257

[epoch:  75/100000, batch:   160/  187, ite: 7036] train loss: 0.194455, tar: 0.019572 
l0: 0.026870, l1: 0.027277, l2: 0.034444, l3: 0.038151, l4: 0.040379, l5: 0.032606, l6: 0.023517

[epoch:  75/100000, batch:   162/  187, ite: 7037] train loss: 0.194483, tar: 0.019579 
l0: 0.018823, l1: 0.016423, l2: 0.024357, l3: 0.027740, l4: 0.024279, l5: 0.027849, l6: 0.026948

[epoch:  75/100000, batch:   164/  187, ite: 7038] train loss: 0.194456, tar: 0.019579 
l0: 0.016139, l1: 0.016298, l2: 0.019489, l3: 0.024388, l4: 0.021893, l5: 0.029933, l6: 0.026854

[epoch:  75/100000, batch:   166/  187, ite: 7039] train loss: 0.194418, tar: 0.019575 
l0: 0.012171, l1: 0.010509, l2: 0.028112, l3: 0.030909, l4: 0.045431, l5: 0.045807, l6: 0.042971

[epoch:  75/100000, batch:   168/  187, ite: 7040] train loss: 0.194438, tar: 0.019568 
l0: 0.016443, l1: 0.017350, l2: 0.017561, l3: 0.017251, l4: 0.016503, l5: 0.016717, l6: 0.022597

[epoch:  75/100000, batch:   170/  187, ite: 7041] train loss: 0.194371, tar: 0.019565 
l0: 0.013480, l1: 0.013258, l2: 0.018374, l3: 0.018596, l4: 0.029281, l5: 0.032681, l6: 0.030430

[epoch:  75/100000, batch:   172/  187, ite: 7042] train loss: 0.194334, tar: 0.019559 
l0: 0.014366, l1: 0.015412, l2: 0.013994, l3: 0.014993, l4: 0.026022, l5: 0.032807, l6: 0.035756

[epoch:  75/100000, batch:   174/  187, ite: 7043] train loss: 0.194295, tar: 0.019554 
l0: 0.036772, l1: 0.038670, l2: 0.037333, l3: 0.047221, l4: 0.085198, l5: 0.076420, l6: 0.041876

[epoch:  75/100000, batch:   176/  187, ite: 7044] train loss: 0.194457, tar: 0.019571 
l0: 0.011149, l1: 0.010742, l2: 0.014823, l3: 0.016765, l4: 0.032709, l5: 0.031303, l6: 0.027406

[epoch:  75/100000, batch:   178/  187, ite: 7045] train loss: 0.194410, tar: 0.019563 
l0: 0.009652, l1: 0.009816, l2: 0.011833, l3: 0.012146, l4: 0.035973, l5: 0.033999, l6: 0.035659

[epoch:  75/100000, batch:   180/  187, ite: 7046] train loss: 0.194366, tar: 0.019553 
l0: 0.018818, l1: 0.018539, l2: 0.024262, l3: 0.028703, l4: 0.034009, l5: 0.025613, l6: 0.029318

[epoch:  75/100000, batch:   182/  187, ite: 7047] train loss: 0.194352, tar: 0.019553 
l0: 0.012377, l1: 0.013903, l2: 0.014373, l3: 0.016498, l4: 0.016147, l5: 0.018572, l6: 0.019374

[epoch:  75/100000, batch:   184/  187, ite: 7048] train loss: 0.194273, tar: 0.019546 
l0: 0.014611, l1: 0.015274, l2: 0.017962, l3: 0.017152, l4: 0.024425, l5: 0.029435, l6: 0.034125

[epoch:  75/100000, batch:   186/  187, ite: 7049] train loss: 0.194233, tar: 0.019541 
l0: 0.030300, l1: 0.028426, l2: 0.040325, l3: 0.048064, l4: 0.085176, l5: 0.070176, l6: 0.063987

[epoch:  75/100000, batch:   188/  187, ite: 7050] train loss: 0.194397, tar: 0.019551 
l0: 0.012823, l1: 0.012663, l2: 0.015902, l3: 0.016472, l4: 0.028251, l5: 0.030905, l6: 0.025178

[epoch:  76/100000, batch:     2/  187, ite: 7051] train loss: 0.194348, tar: 0.019545 
l0: 0.022402, l1: 0.020437, l2: 0.024083, l3: 0.029040, l4: 0.054224, l5: 0.059437, l6: 0.056379

[epoch:  76/100000, batch:     4/  187, ite: 7052] train loss: 0.194416, tar: 0.019548 
l0: 0.054139, l1: 0.048796, l2: 0.059133, l3: 0.060850, l4: 0.075489, l5: 0.080042, l6: 0.087025

[epoch:  76/100000, batch:     6/  187, ite: 7053] train loss: 0.194673, tar: 0.019581 
l0: 0.019464, l1: 0.018814, l2: 0.018527, l3: 0.019567, l4: 0.043479, l5: 0.044431, l6: 0.057730

[epoch:  76/100000, batch:     8/  187, ite: 7054] train loss: 0.194699, tar: 0.019580 
l0: 0.007692, l1: 0.007917, l2: 0.008783, l3: 0.010877, l4: 0.025964, l5: 0.032753, l6: 0.020356

[epoch:  76/100000, batch:    10/  187, ite: 7055] train loss: 0.194623, tar: 0.019569 
l0: 0.017796, l1: 0.017835, l2: 0.022134, l3: 0.024892, l4: 0.036146, l5: 0.036029, l6: 0.042833

[epoch:  76/100000, batch:    12/  187, ite: 7056] train loss: 0.194626, tar: 0.019568 
l0: 0.010116, l1: 0.012358, l2: 0.013717, l3: 0.013623, l4: 0.023658, l5: 0.023045, l6: 0.009965

[epoch:  76/100000, batch:    14/  187, ite: 7057] train loss: 0.194542, tar: 0.019559 
l0: 0.020027, l1: 0.018737, l2: 0.022840, l3: 0.024149, l4: 0.031869, l5: 0.037106, l6: 0.034903

[epoch:  76/100000, batch:    16/  187, ite: 7058] train loss: 0.194538, tar: 0.019559 
l0: 0.012493, l1: 0.012953, l2: 0.015030, l3: 0.016658, l4: 0.021495, l5: 0.027921, l6: 0.020271

[epoch:  76/100000, batch:    18/  187, ite: 7059] train loss: 0.194474, tar: 0.019552 
l0: 0.012437, l1: 0.013058, l2: 0.010433, l3: 0.012432, l4: 0.042953, l5: 0.041518, l6: 0.051254

[epoch:  76/100000, batch:    20/  187, ite: 7060] train loss: 0.194464, tar: 0.019546 
l0: 0.015726, l1: 0.013746, l2: 0.026722, l3: 0.028892, l4: 0.034131, l5: 0.029835, l6: 0.039203

[epoch:  76/100000, batch:    22/  187, ite: 7061] train loss: 0.194458, tar: 0.019542 
l0: 0.010698, l1: 0.011252, l2: 0.012394, l3: 0.014495, l4: 0.020389, l5: 0.016318, l6: 0.016297

[epoch:  76/100000, batch:    24/  187, ite: 7062] train loss: 0.194371, tar: 0.019534 
l0: 0.029278, l1: 0.032564, l2: 0.040891, l3: 0.030024, l4: 0.048603, l5: 0.044180, l6: 0.047022

[epoch:  76/100000, batch:    26/  187, ite: 7063] train loss: 0.194445, tar: 0.019543 
l0: 0.014825, l1: 0.014186, l2: 0.017479, l3: 0.018130, l4: 0.036398, l5: 0.034295, l6: 0.046823

[epoch:  76/100000, batch:    28/  187, ite: 7064] train loss: 0.194433, tar: 0.019538 
l0: 0.014678, l1: 0.014999, l2: 0.014252, l3: 0.015932, l4: 0.032860, l5: 0.036238, l6: 0.032825

[epoch:  76/100000, batch:    30/  187, ite: 7065] train loss: 0.194402, tar: 0.019534 
l0: 0.009646, l1: 0.010034, l2: 0.012287, l3: 0.013797, l4: 0.021990, l5: 0.020385, l6: 0.029371

[epoch:  76/100000, batch:    32/  187, ite: 7066] train loss: 0.194330, tar: 0.019525 
l0: 0.019593, l1: 0.022043, l2: 0.017477, l3: 0.018740, l4: 0.042605, l5: 0.046817, l6: 0.051219

[epoch:  76/100000, batch:    34/  187, ite: 7067] train loss: 0.194353, tar: 0.019525 
l0: 0.019112, l1: 0.018879, l2: 0.019714, l3: 0.020780, l4: 0.045909, l5: 0.047649, l6: 0.049764

[epoch:  76/100000, batch:    36/  187, ite: 7068] train loss: 0.194379, tar: 0.019524 
l0: 0.024678, l1: 0.022536, l2: 0.020534, l3: 0.024726, l4: 0.055476, l5: 0.061760, l6: 0.070232

[epoch:  76/100000, batch:    38/  187, ite: 7069] train loss: 0.194459, tar: 0.019529 
l0: 0.019253, l1: 0.022038, l2: 0.021420, l3: 0.021031, l4: 0.037618, l5: 0.036931, l6: 0.040230

[epoch:  76/100000, batch:    40/  187, ite: 7070] train loss: 0.194462, tar: 0.019529 
l0: 0.012696, l1: 0.014146, l2: 0.016227, l3: 0.015218, l4: 0.027278, l5: 0.022465, l6: 0.021516

[epoch:  76/100000, batch:    42/  187, ite: 7071] train loss: 0.194402, tar: 0.019522 
l0: 0.016070, l1: 0.015367, l2: 0.018895, l3: 0.020623, l4: 0.027269, l5: 0.026434, l6: 0.022788

[epoch:  76/100000, batch:    44/  187, ite: 7072] train loss: 0.194358, tar: 0.019519 
l0: 0.019937, l1: 0.020729, l2: 0.022070, l3: 0.025759, l4: 0.027776, l5: 0.024662, l6: 0.026845

[epoch:  76/100000, batch:    46/  187, ite: 7073] train loss: 0.194333, tar: 0.019520 
l0: 0.037501, l1: 0.038684, l2: 0.028486, l3: 0.030569, l4: 0.054812, l5: 0.058877, l6: 0.066893

[epoch:  76/100000, batch:    48/  187, ite: 7074] train loss: 0.194446, tar: 0.019536 
l0: 0.027520, l1: 0.032170, l2: 0.024962, l3: 0.027677, l4: 0.037162, l5: 0.031509, l6: 0.037565

[epoch:  76/100000, batch:    50/  187, ite: 7075] train loss: 0.194469, tar: 0.019544 
l0: 0.020889, l1: 0.023575, l2: 0.021528, l3: 0.023514, l4: 0.039613, l5: 0.031593, l6: 0.019008

[epoch:  76/100000, batch:    52/  187, ite: 7076] train loss: 0.194455, tar: 0.019545 
l0: 0.011636, l1: 0.011333, l2: 0.014071, l3: 0.014631, l4: 0.034748, l5: 0.031853, l6: 0.027387

[epoch:  76/100000, batch:    54/  187, ite: 7077] train loss: 0.194410, tar: 0.019538 
l0: 0.016322, l1: 0.016611, l2: 0.023639, l3: 0.028535, l4: 0.034342, l5: 0.032342, l6: 0.034217

[epoch:  76/100000, batch:    56/  187, ite: 7078] train loss: 0.194402, tar: 0.019535 
l0: 0.033056, l1: 0.037767, l2: 0.030402, l3: 0.030003, l4: 0.031598, l5: 0.033844, l6: 0.037108

[epoch:  76/100000, batch:    58/  187, ite: 7079] train loss: 0.194438, tar: 0.019547 
l0: 0.018328, l1: 0.018088, l2: 0.020995, l3: 0.022085, l4: 0.028055, l5: 0.026801, l6: 0.031038

[epoch:  76/100000, batch:    60/  187, ite: 7080] train loss: 0.194412, tar: 0.019546 
l0: 0.018214, l1: 0.021194, l2: 0.021746, l3: 0.020822, l4: 0.025290, l5: 0.025105, l6: 0.019075

[epoch:  76/100000, batch:    62/  187, ite: 7081] train loss: 0.194372, tar: 0.019545 
l0: 0.018696, l1: 0.020827, l2: 0.019904, l3: 0.021742, l4: 0.028531, l5: 0.024050, l6: 0.024030

[epoch:  76/100000, batch:    64/  187, ite: 7082] train loss: 0.194338, tar: 0.019544 
l0: 0.020111, l1: 0.021260, l2: 0.023037, l3: 0.021941, l4: 0.032166, l5: 0.024497, l6: 0.031455

[epoch:  76/100000, batch:    66/  187, ite: 7083] train loss: 0.194320, tar: 0.019545 
l0: 0.018878, l1: 0.017470, l2: 0.024864, l3: 0.025554, l4: 0.029792, l5: 0.028486, l6: 0.042695

[epoch:  76/100000, batch:    68/  187, ite: 7084] train loss: 0.194314, tar: 0.019544 
l0: 0.031322, l1: 0.032446, l2: 0.033122, l3: 0.035490, l4: 0.061735, l5: 0.047688, l6: 0.049473

[epoch:  76/100000, batch:    70/  187, ite: 7085] train loss: 0.194403, tar: 0.019555 
l0: 0.012613, l1: 0.013593, l2: 0.013480, l3: 0.012504, l4: 0.023390, l5: 0.016893, l6: 0.017392

[epoch:  76/100000, batch:    72/  187, ite: 7086] train loss: 0.194325, tar: 0.019548 
l0: 0.020893, l1: 0.021496, l2: 0.027668, l3: 0.030218, l4: 0.031856, l5: 0.027716, l6: 0.027993

[epoch:  76/100000, batch:    74/  187, ite: 7087] train loss: 0.194319, tar: 0.019550 
l0: 0.021039, l1: 0.022054, l2: 0.022809, l3: 0.021513, l4: 0.036639, l5: 0.034167, l6: 0.037861

[epoch:  76/100000, batch:    76/  187, ite: 7088] train loss: 0.194321, tar: 0.019551 
l0: 0.018883, l1: 0.017782, l2: 0.025069, l3: 0.029935, l4: 0.034453, l5: 0.028343, l6: 0.035618

[epoch:  76/100000, batch:    78/  187, ite: 7089] train loss: 0.194317, tar: 0.019550 
l0: 0.036113, l1: 0.036050, l2: 0.040436, l3: 0.052825, l4: 0.031698, l5: 0.032879, l6: 0.034139

[epoch:  76/100000, batch:    80/  187, ite: 7090] train loss: 0.194381, tar: 0.019566 
l0: 0.017324, l1: 0.017610, l2: 0.025797, l3: 0.023356, l4: 0.031048, l5: 0.026023, l6: 0.025780

[epoch:  76/100000, batch:    82/  187, ite: 7091] train loss: 0.194356, tar: 0.019564 
l0: 0.025332, l1: 0.024615, l2: 0.029901, l3: 0.029463, l4: 0.049406, l5: 0.056776, l6: 0.049579

[epoch:  76/100000, batch:    84/  187, ite: 7092] train loss: 0.194421, tar: 0.019569 
l0: 0.018934, l1: 0.021371, l2: 0.019145, l3: 0.018577, l4: 0.020859, l5: 0.021918, l6: 0.020093

[epoch:  76/100000, batch:    86/  187, ite: 7093] train loss: 0.194372, tar: 0.019568 
l0: 0.014865, l1: 0.015106, l2: 0.016637, l3: 0.017198, l4: 0.039204, l5: 0.038735, l6: 0.035590

[epoch:  76/100000, batch:    88/  187, ite: 7094] train loss: 0.194356, tar: 0.019564 
l0: 0.010147, l1: 0.012575, l2: 0.013160, l3: 0.011008, l4: 0.014689, l5: 0.014522, l6: 0.017127

[epoch:  76/100000, batch:    90/  187, ite: 7095] train loss: 0.194264, tar: 0.019555 
l0: 0.017087, l1: 0.019033, l2: 0.017678, l3: 0.018303, l4: 0.033427, l5: 0.026658, l6: 0.026413

[epoch:  76/100000, batch:    92/  187, ite: 7096] train loss: 0.194231, tar: 0.019553 
l0: 0.017287, l1: 0.016027, l2: 0.019378, l3: 0.022528, l4: 0.046804, l5: 0.041407, l6: 0.043858

[epoch:  76/100000, batch:    94/  187, ite: 7097] train loss: 0.194243, tar: 0.019551 
l0: 0.015255, l1: 0.016806, l2: 0.016483, l3: 0.014767, l4: 0.015351, l5: 0.018708, l6: 0.021481

[epoch:  76/100000, batch:    96/  187, ite: 7098] train loss: 0.194174, tar: 0.019547 
l0: 0.012868, l1: 0.013039, l2: 0.016272, l3: 0.018842, l4: 0.019691, l5: 0.017495, l6: 0.025231

[epoch:  76/100000, batch:    98/  187, ite: 7099] train loss: 0.194110, tar: 0.019541 
l0: 0.022471, l1: 0.022781, l2: 0.028044, l3: 0.027097, l4: 0.033818, l5: 0.032798, l6: 0.031346

[epoch:  76/100000, batch:   100/  187, ite: 7100] train loss: 0.194114, tar: 0.019544 
l0: 0.012087, l1: 0.011709, l2: 0.014877, l3: 0.018454, l4: 0.020510, l5: 0.020319, l6: 0.018362

[epoch:  76/100000, batch:   102/  187, ite: 7101] train loss: 0.194043, tar: 0.019537 
l0: 0.019139, l1: 0.018529, l2: 0.019569, l3: 0.022528, l4: 0.032206, l5: 0.034451, l6: 0.035763

[epoch:  76/100000, batch:   104/  187, ite: 7102] train loss: 0.194032, tar: 0.019537 
l0: 0.019394, l1: 0.020126, l2: 0.019010, l3: 0.019275, l4: 0.048065, l5: 0.043454, l6: 0.043055

[epoch:  76/100000, batch:   106/  187, ite: 7103] train loss: 0.194049, tar: 0.019537 
l0: 0.016688, l1: 0.016372, l2: 0.017322, l3: 0.022575, l4: 0.031138, l5: 0.030511, l6: 0.036519

[epoch:  76/100000, batch:   108/  187, ite: 7104] train loss: 0.194028, tar: 0.019534 
l0: 0.012544, l1: 0.012482, l2: 0.013420, l3: 0.016113, l4: 0.021991, l5: 0.023979, l6: 0.022773

[epoch:  76/100000, batch:   110/  187, ite: 7105] train loss: 0.193964, tar: 0.019528 
l0: 0.020795, l1: 0.019805, l2: 0.023172, l3: 0.031402, l4: 0.040685, l5: 0.032924, l6: 0.031351

[epoch:  76/100000, batch:   112/  187, ite: 7106] train loss: 0.193970, tar: 0.019529 
l0: 0.013750, l1: 0.013140, l2: 0.015354, l3: 0.016740, l4: 0.034314, l5: 0.038423, l6: 0.039448

[epoch:  76/100000, batch:   114/  187, ite: 7107] train loss: 0.193949, tar: 0.019524 
l0: 0.022505, l1: 0.022947, l2: 0.024805, l3: 0.026383, l4: 0.025744, l5: 0.024865, l6: 0.029836

[epoch:  76/100000, batch:   116/  187, ite: 7108] train loss: 0.193934, tar: 0.019526 
l0: 0.013210, l1: 0.013162, l2: 0.016215, l3: 0.017550, l4: 0.032144, l5: 0.030146, l6: 0.030308

[epoch:  76/100000, batch:   118/  187, ite: 7109] train loss: 0.193897, tar: 0.019521 
l0: 0.015947, l1: 0.015808, l2: 0.016312, l3: 0.019958, l4: 0.026990, l5: 0.032601, l6: 0.032597

[epoch:  76/100000, batch:   120/  187, ite: 7110] train loss: 0.193867, tar: 0.019517 
l0: 0.013805, l1: 0.012800, l2: 0.014078, l3: 0.019069, l4: 0.026269, l5: 0.023376, l6: 0.027879

[epoch:  76/100000, batch:   122/  187, ite: 7111] train loss: 0.193816, tar: 0.019512 
l0: 0.009690, l1: 0.009350, l2: 0.011282, l3: 0.011610, l4: 0.029875, l5: 0.028412, l6: 0.031013

[epoch:  76/100000, batch:   124/  187, ite: 7112] train loss: 0.193759, tar: 0.019503 
l0: 0.015803, l1: 0.015728, l2: 0.020198, l3: 0.018583, l4: 0.040806, l5: 0.034254, l6: 0.034060

[epoch:  76/100000, batch:   126/  187, ite: 7113] train loss: 0.193746, tar: 0.019500 
l0: 0.011054, l1: 0.011657, l2: 0.013214, l3: 0.011824, l4: 0.018167, l5: 0.018218, l6: 0.016953

[epoch:  76/100000, batch:   128/  187, ite: 7114] train loss: 0.193663, tar: 0.019492 
l0: 0.012861, l1: 0.012496, l2: 0.018242, l3: 0.021016, l4: 0.023042, l5: 0.022115, l6: 0.022834

[epoch:  76/100000, batch:   130/  187, ite: 7115] train loss: 0.193609, tar: 0.019486 
l0: 0.020446, l1: 0.019820, l2: 0.023022, l3: 0.023303, l4: 0.043304, l5: 0.040788, l6: 0.052769

[epoch:  76/100000, batch:   132/  187, ite: 7116] train loss: 0.193635, tar: 0.019487 
l0: 0.022769, l1: 0.022522, l2: 0.035164, l3: 0.032310, l4: 0.045901, l5: 0.046868, l6: 0.046507

[epoch:  76/100000, batch:   134/  187, ite: 7117] train loss: 0.193688, tar: 0.019490 
l0: 0.015503, l1: 0.016060, l2: 0.016647, l3: 0.018160, l4: 0.029987, l5: 0.027092, l6: 0.031590

[epoch:  76/100000, batch:   136/  187, ite: 7118] train loss: 0.193653, tar: 0.019487 
l0: 0.012708, l1: 0.012770, l2: 0.013617, l3: 0.014187, l4: 0.030534, l5: 0.031225, l6: 0.030513

[epoch:  76/100000, batch:   138/  187, ite: 7119] train loss: 0.193610, tar: 0.019481 
l0: 0.010677, l1: 0.010658, l2: 0.013023, l3: 0.015712, l4: 0.020327, l5: 0.019221, l6: 0.024234

[epoch:  76/100000, batch:   140/  187, ite: 7120] train loss: 0.193539, tar: 0.019473 
l0: 0.014234, l1: 0.015177, l2: 0.017544, l3: 0.017804, l4: 0.024204, l5: 0.022143, l6: 0.021428

[epoch:  76/100000, batch:   142/  187, ite: 7121] train loss: 0.193484, tar: 0.019468 
l0: 0.021876, l1: 0.021981, l2: 0.030084, l3: 0.030527, l4: 0.026352, l5: 0.027156, l6: 0.024892

[epoch:  76/100000, batch:   144/  187, ite: 7122] train loss: 0.193475, tar: 0.019470 
l0: 0.019782, l1: 0.021526, l2: 0.019448, l3: 0.022961, l4: 0.029351, l5: 0.024514, l6: 0.032127

[epoch:  76/100000, batch:   146/  187, ite: 7123] train loss: 0.193454, tar: 0.019471 
l0: 0.007625, l1: 0.008259, l2: 0.010036, l3: 0.011041, l4: 0.017614, l5: 0.018325, l6: 0.013838

[epoch:  76/100000, batch:   148/  187, ite: 7124] train loss: 0.193359, tar: 0.019460 
l0: 0.019668, l1: 0.018769, l2: 0.023387, l3: 0.021861, l4: 0.018650, l5: 0.018931, l6: 0.032777

[epoch:  76/100000, batch:   150/  187, ite: 7125] train loss: 0.193324, tar: 0.019460 
l0: 0.014116, l1: 0.014911, l2: 0.016838, l3: 0.016490, l4: 0.033672, l5: 0.032602, l6: 0.039910

[epoch:  76/100000, batch:   152/  187, ite: 7126] train loss: 0.193302, tar: 0.019455 
l0: 0.048742, l1: 0.053485, l2: 0.055064, l3: 0.047520, l4: 0.053495, l5: 0.054113, l6: 0.057300

[epoch:  76/100000, batch:   154/  187, ite: 7127] train loss: 0.193458, tar: 0.019481 
l0: 0.019514, l1: 0.021867, l2: 0.020254, l3: 0.018378, l4: 0.028306, l5: 0.025976, l6: 0.027409

[epoch:  76/100000, batch:   156/  187, ite: 7128] train loss: 0.193430, tar: 0.019481 
l0: 0.010307, l1: 0.010581, l2: 0.011577, l3: 0.015764, l4: 0.027678, l5: 0.023233, l6: 0.026418

[epoch:  76/100000, batch:   158/  187, ite: 7129] train loss: 0.193370, tar: 0.019473 
l0: 0.015771, l1: 0.015640, l2: 0.023186, l3: 0.025575, l4: 0.033516, l5: 0.030066, l6: 0.034130

[epoch:  76/100000, batch:   160/  187, ite: 7130] train loss: 0.193356, tar: 0.019470 
l0: 0.018547, l1: 0.017755, l2: 0.032979, l3: 0.028858, l4: 0.028502, l5: 0.026213, l6: 0.023496

[epoch:  76/100000, batch:   162/  187, ite: 7131] train loss: 0.193341, tar: 0.019469 
l0: 0.018149, l1: 0.018683, l2: 0.024196, l3: 0.028260, l4: 0.040579, l5: 0.033908, l6: 0.030925

[epoch:  76/100000, batch:   164/  187, ite: 7132] train loss: 0.193343, tar: 0.019468 
l0: 0.024107, l1: 0.026209, l2: 0.026823, l3: 0.024560, l4: 0.027596, l5: 0.023942, l6: 0.024718

[epoch:  76/100000, batch:   166/  187, ite: 7133] train loss: 0.193329, tar: 0.019472 
l0: 0.027117, l1: 0.026301, l2: 0.032275, l3: 0.032044, l4: 0.039740, l5: 0.043383, l6: 0.042829

[epoch:  76/100000, batch:   168/  187, ite: 7134] train loss: 0.193373, tar: 0.019479 
l0: 0.021872, l1: 0.024228, l2: 0.027818, l3: 0.026454, l4: 0.013555, l5: 0.012538, l6: 0.018439

[epoch:  76/100000, batch:   170/  187, ite: 7135] train loss: 0.193331, tar: 0.019481 
l0: 0.010685, l1: 0.010895, l2: 0.012829, l3: 0.013789, l4: 0.015039, l5: 0.015754, l6: 0.021194

[epoch:  76/100000, batch:   172/  187, ite: 7136] train loss: 0.193249, tar: 0.019473 
l0: 0.012694, l1: 0.012704, l2: 0.013914, l3: 0.014895, l4: 0.027532, l5: 0.026893, l6: 0.026805

[epoch:  76/100000, batch:   174/  187, ite: 7137] train loss: 0.193198, tar: 0.019467 
l0: 0.010461, l1: 0.011272, l2: 0.011969, l3: 0.012121, l4: 0.014800, l5: 0.015654, l6: 0.014362

[epoch:  76/100000, batch:   176/  187, ite: 7138] train loss: 0.193108, tar: 0.019459 
l0: 0.021389, l1: 0.023040, l2: 0.017532, l3: 0.020946, l4: 0.029078, l5: 0.031086, l6: 0.029311

[epoch:  76/100000, batch:   178/  187, ite: 7139] train loss: 0.193090, tar: 0.019461 
l0: 0.013261, l1: 0.012353, l2: 0.019539, l3: 0.021377, l4: 0.032354, l5: 0.031867, l6: 0.026727

[epoch:  76/100000, batch:   180/  187, ite: 7140] train loss: 0.193058, tar: 0.019456 
l0: 0.015975, l1: 0.017440, l2: 0.017925, l3: 0.016154, l4: 0.020286, l5: 0.022045, l6: 0.029300

[epoch:  76/100000, batch:   182/  187, ite: 7141] train loss: 0.193011, tar: 0.019453 
l0: 0.014783, l1: 0.013867, l2: 0.021998, l3: 0.027602, l4: 0.033614, l5: 0.025357, l6: 0.024089

[epoch:  76/100000, batch:   184/  187, ite: 7142] train loss: 0.192983, tar: 0.019449 
l0: 0.011576, l1: 0.012581, l2: 0.017380, l3: 0.017908, l4: 0.015943, l5: 0.015053, l6: 0.015077

[epoch:  76/100000, batch:   186/  187, ite: 7143] train loss: 0.192907, tar: 0.019442 
l0: 0.007330, l1: 0.009031, l2: 0.008272, l3: 0.005212, l4: 0.033334, l5: 0.024552, l6: 0.014535

[epoch:  76/100000, batch:   188/  187, ite: 7144] train loss: 0.192828, tar: 0.019431 
l0: 0.013807, l1: 0.014748, l2: 0.017459, l3: 0.017302, l4: 0.016277, l5: 0.017118, l6: 0.019738

[epoch:  77/100000, batch:     2/  187, ite: 7145] train loss: 0.192761, tar: 0.019426 
l0: 0.014754, l1: 0.016615, l2: 0.018499, l3: 0.015454, l4: 0.032656, l5: 0.031207, l6: 0.027245

[epoch:  77/100000, batch:     4/  187, ite: 7146] train loss: 0.192729, tar: 0.019422 
l0: 0.011689, l1: 0.012721, l2: 0.012944, l3: 0.014208, l4: 0.022109, l5: 0.020184, l6: 0.018527

[epoch:  77/100000, batch:     6/  187, ite: 7147] train loss: 0.192659, tar: 0.019415 
l0: 0.013165, l1: 0.013103, l2: 0.013935, l3: 0.016606, l4: 0.026754, l5: 0.025989, l6: 0.024896

[epoch:  77/100000, batch:     8/  187, ite: 7148] train loss: 0.192608, tar: 0.019410 
l0: 0.009935, l1: 0.010023, l2: 0.011807, l3: 0.012408, l4: 0.019947, l5: 0.016206, l6: 0.016227

[epoch:  77/100000, batch:    10/  187, ite: 7149] train loss: 0.192525, tar: 0.019402 
l0: 0.009203, l1: 0.009059, l2: 0.017620, l3: 0.016705, l4: 0.019635, l5: 0.021866, l6: 0.024326

[epoch:  77/100000, batch:    12/  187, ite: 7150] train loss: 0.192460, tar: 0.019393 
l0: 0.016964, l1: 0.017072, l2: 0.015717, l3: 0.017987, l4: 0.018218, l5: 0.020324, l6: 0.022267

[epoch:  77/100000, batch:    14/  187, ite: 7151] train loss: 0.192405, tar: 0.019391 
l0: 0.018878, l1: 0.021130, l2: 0.025504, l3: 0.024594, l4: 0.030273, l5: 0.034600, l6: 0.034365

[epoch:  77/100000, batch:    16/  187, ite: 7152] train loss: 0.192402, tar: 0.019390 
l0: 0.015363, l1: 0.016115, l2: 0.013617, l3: 0.015140, l4: 0.017730, l5: 0.018555, l6: 0.023261

[epoch:  77/100000, batch:    18/  187, ite: 7153] train loss: 0.192339, tar: 0.019387 
l0: 0.014258, l1: 0.015504, l2: 0.017210, l3: 0.016500, l4: 0.021112, l5: 0.020639, l6: 0.025210

[epoch:  77/100000, batch:    20/  187, ite: 7154] train loss: 0.192285, tar: 0.019382 
l0: 0.018618, l1: 0.020155, l2: 0.023977, l3: 0.026787, l4: 0.036033, l5: 0.033424, l6: 0.024277

[epoch:  77/100000, batch:    22/  187, ite: 7155] train loss: 0.192278, tar: 0.019382 
l0: 0.011487, l1: 0.012356, l2: 0.013811, l3: 0.012390, l4: 0.019864, l5: 0.018185, l6: 0.018307

[epoch:  77/100000, batch:    24/  187, ite: 7156] train loss: 0.192203, tar: 0.019375 
l0: 0.022252, l1: 0.022051, l2: 0.024823, l3: 0.029978, l4: 0.037899, l5: 0.032250, l6: 0.029704

[epoch:  77/100000, batch:    26/  187, ite: 7157] train loss: 0.192209, tar: 0.019377 
l0: 0.019547, l1: 0.021852, l2: 0.021410, l3: 0.020006, l4: 0.029610, l5: 0.026986, l6: 0.026043

[epoch:  77/100000, batch:    28/  187, ite: 7158] train loss: 0.192186, tar: 0.019377 
l0: 0.012604, l1: 0.012591, l2: 0.014192, l3: 0.014978, l4: 0.023528, l5: 0.027329, l6: 0.023238

[epoch:  77/100000, batch:    30/  187, ite: 7159] train loss: 0.192131, tar: 0.019372 
l0: 0.011047, l1: 0.011985, l2: 0.010154, l3: 0.013153, l4: 0.021368, l5: 0.019349, l6: 0.017253

[epoch:  77/100000, batch:    32/  187, ite: 7160] train loss: 0.192055, tar: 0.019364 
l0: 0.017547, l1: 0.017774, l2: 0.021214, l3: 0.020773, l4: 0.035797, l5: 0.028170, l6: 0.029502

[epoch:  77/100000, batch:    34/  187, ite: 7161] train loss: 0.192037, tar: 0.019363 
l0: 0.015407, l1: 0.016145, l2: 0.016277, l3: 0.017122, l4: 0.019075, l5: 0.018957, l6: 0.024437

[epoch:  77/100000, batch:    36/  187, ite: 7162] train loss: 0.191981, tar: 0.019359 
l0: 0.015604, l1: 0.015941, l2: 0.014974, l3: 0.015285, l4: 0.017497, l5: 0.020590, l6: 0.020490

[epoch:  77/100000, batch:    38/  187, ite: 7163] train loss: 0.191920, tar: 0.019356 
l0: 0.008903, l1: 0.010123, l2: 0.011031, l3: 0.010233, l4: 0.028889, l5: 0.021819, l6: 0.015540

[epoch:  77/100000, batch:    40/  187, ite: 7164] train loss: 0.191847, tar: 0.019347 
l0: 0.025796, l1: 0.028489, l2: 0.027063, l3: 0.028245, l4: 0.041233, l5: 0.037063, l6: 0.045363

[epoch:  77/100000, batch:    42/  187, ite: 7165] train loss: 0.191882, tar: 0.019353 
l0: 0.008874, l1: 0.009438, l2: 0.011266, l3: 0.010258, l4: 0.016044, l5: 0.013952, l6: 0.016245

[epoch:  77/100000, batch:    44/  187, ite: 7166] train loss: 0.191791, tar: 0.019344 
l0: 0.020251, l1: 0.020204, l2: 0.019715, l3: 0.022978, l4: 0.050136, l5: 0.046435, l6: 0.040414

[epoch:  77/100000, batch:    46/  187, ite: 7167] train loss: 0.191816, tar: 0.019345 
l0: 0.007165, l1: 0.007739, l2: 0.008543, l3: 0.008704, l4: 0.017538, l5: 0.017370, l6: 0.017575

[epoch:  77/100000, batch:    48/  187, ite: 7168] train loss: 0.191724, tar: 0.019334 
l0: 0.016179, l1: 0.016827, l2: 0.015283, l3: 0.023227, l4: 0.032052, l5: 0.024723, l6: 0.027935

[epoch:  77/100000, batch:    50/  187, ite: 7169] train loss: 0.191694, tar: 0.019331 
l0: 0.005576, l1: 0.005717, l2: 0.007186, l3: 0.006099, l4: 0.024491, l5: 0.017035, l6: 0.016747

[epoch:  77/100000, batch:    52/  187, ite: 7170] train loss: 0.191601, tar: 0.019320 
l0: 0.019396, l1: 0.019713, l2: 0.025276, l3: 0.023849, l4: 0.038391, l5: 0.038487, l6: 0.036874

[epoch:  77/100000, batch:    54/  187, ite: 7171] train loss: 0.191609, tar: 0.019320 
l0: 0.012234, l1: 0.012957, l2: 0.013542, l3: 0.013913, l4: 0.019649, l5: 0.017472, l6: 0.017586

[epoch:  77/100000, batch:    56/  187, ite: 7172] train loss: 0.191537, tar: 0.019314 
l0: 0.012240, l1: 0.012448, l2: 0.012282, l3: 0.012387, l4: 0.021086, l5: 0.026390, l6: 0.032977

[epoch:  77/100000, batch:    58/  187, ite: 7173] train loss: 0.191485, tar: 0.019308 
l0: 0.009546, l1: 0.010761, l2: 0.012327, l3: 0.009747, l4: 0.014932, l5: 0.014042, l6: 0.017079

[epoch:  77/100000, batch:    60/  187, ite: 7174] train loss: 0.191397, tar: 0.019299 
l0: 0.014355, l1: 0.013519, l2: 0.015631, l3: 0.016067, l4: 0.042691, l5: 0.035345, l6: 0.037750

[epoch:  77/100000, batch:    62/  187, ite: 7175] train loss: 0.191383, tar: 0.019295 
l0: 0.019981, l1: 0.019366, l2: 0.019698, l3: 0.025548, l4: 0.026154, l5: 0.025587, l6: 0.038959

[epoch:  77/100000, batch:    64/  187, ite: 7176] train loss: 0.191370, tar: 0.019296 
l0: 0.010426, l1: 0.009440, l2: 0.012860, l3: 0.014849, l4: 0.027021, l5: 0.024344, l6: 0.027398

[epoch:  77/100000, batch:    66/  187, ite: 7177] train loss: 0.191314, tar: 0.019288 
l0: 0.006802, l1: 0.008344, l2: 0.008821, l3: 0.008548, l4: 0.016007, l5: 0.017405, l6: 0.023557

[epoch:  77/100000, batch:    68/  187, ite: 7178] train loss: 0.191228, tar: 0.019278 
l0: 0.012046, l1: 0.013575, l2: 0.012874, l3: 0.012734, l4: 0.022361, l5: 0.019717, l6: 0.022757

[epoch:  77/100000, batch:    70/  187, ite: 7179] train loss: 0.191164, tar: 0.019271 
l0: 0.018857, l1: 0.018176, l2: 0.028439, l3: 0.027317, l4: 0.021270, l5: 0.023279, l6: 0.018648

[epoch:  77/100000, batch:    72/  187, ite: 7180] train loss: 0.191134, tar: 0.019271 
l0: 0.008625, l1: 0.008732, l2: 0.009485, l3: 0.010570, l4: 0.020216, l5: 0.017854, l6: 0.019946

[epoch:  77/100000, batch:    74/  187, ite: 7181] train loss: 0.191053, tar: 0.019262 
l0: 0.013696, l1: 0.015634, l2: 0.019060, l3: 0.019719, l4: 0.025024, l5: 0.020761, l6: 0.030345

[epoch:  77/100000, batch:    76/  187, ite: 7182] train loss: 0.191014, tar: 0.019257 
l0: 0.020361, l1: 0.020178, l2: 0.019166, l3: 0.026201, l4: 0.030719, l5: 0.028710, l6: 0.026161

[epoch:  77/100000, batch:    78/  187, ite: 7183] train loss: 0.190997, tar: 0.019258 
l0: 0.009709, l1: 0.009531, l2: 0.012109, l3: 0.011050, l4: 0.023450, l5: 0.022933, l6: 0.021664

[epoch:  77/100000, batch:    80/  187, ite: 7184] train loss: 0.190929, tar: 0.019250 
l0: 0.014521, l1: 0.015537, l2: 0.014822, l3: 0.014719, l4: 0.015824, l5: 0.016377, l6: 0.016599

[epoch:  77/100000, batch:    82/  187, ite: 7185] train loss: 0.190860, tar: 0.019246 
l0: 0.007132, l1: 0.007111, l2: 0.007447, l3: 0.009481, l4: 0.014526, l5: 0.015069, l6: 0.009915

[epoch:  77/100000, batch:    84/  187, ite: 7186] train loss: 0.190758, tar: 0.019236 
l0: 0.013630, l1: 0.014263, l2: 0.015116, l3: 0.014470, l4: 0.021633, l5: 0.022112, l6: 0.025931

[epoch:  77/100000, batch:    86/  187, ite: 7187] train loss: 0.190705, tar: 0.019231 
l0: 0.010322, l1: 0.010673, l2: 0.013318, l3: 0.010638, l4: 0.034851, l5: 0.034255, l6: 0.034844

[epoch:  77/100000, batch:    88/  187, ite: 7188] train loss: 0.190670, tar: 0.019224 
l0: 0.015065, l1: 0.014799, l2: 0.016100, l3: 0.016853, l4: 0.041797, l5: 0.038830, l6: 0.033961

[epoch:  77/100000, batch:    90/  187, ite: 7189] train loss: 0.190658, tar: 0.019220 
l0: 0.010198, l1: 0.010341, l2: 0.012295, l3: 0.013126, l4: 0.024173, l5: 0.020964, l6: 0.021578

[epoch:  77/100000, batch:    92/  187, ite: 7190] train loss: 0.190593, tar: 0.019213 
l0: 0.005890, l1: 0.006569, l2: 0.008197, l3: 0.007123, l4: 0.011124, l5: 0.010810, l6: 0.014444

[epoch:  77/100000, batch:    94/  187, ite: 7191] train loss: 0.190487, tar: 0.019202 
l0: 0.012742, l1: 0.011751, l2: 0.015591, l3: 0.017228, l4: 0.025303, l5: 0.028861, l6: 0.030288

[epoch:  77/100000, batch:    96/  187, ite: 7192] train loss: 0.190446, tar: 0.019196 
l0: 0.010457, l1: 0.010982, l2: 0.012451, l3: 0.012199, l4: 0.022337, l5: 0.020052, l6: 0.020165

[epoch:  77/100000, batch:    98/  187, ite: 7193] train loss: 0.190377, tar: 0.019189 
l0: 0.015856, l1: 0.015819, l2: 0.013686, l3: 0.014923, l4: 0.022327, l5: 0.027402, l6: 0.029250

[epoch:  77/100000, batch:   100/  187, ite: 7194] train loss: 0.190334, tar: 0.019186 
l0: 0.009442, l1: 0.010025, l2: 0.012470, l3: 0.012057, l4: 0.019005, l5: 0.019174, l6: 0.019411

[epoch:  77/100000, batch:   102/  187, ite: 7195] train loss: 0.190260, tar: 0.019178 
l0: 0.014051, l1: 0.014670, l2: 0.018326, l3: 0.018141, l4: 0.018529, l5: 0.014951, l6: 0.016368

[epoch:  77/100000, batch:   104/  187, ite: 7196] train loss: 0.190197, tar: 0.019174 
l0: 0.011582, l1: 0.011037, l2: 0.016633, l3: 0.017749, l4: 0.022963, l5: 0.026029, l6: 0.031239

[epoch:  77/100000, batch:   106/  187, ite: 7197] train loss: 0.190153, tar: 0.019167 
l0: 0.009933, l1: 0.010103, l2: 0.011594, l3: 0.012439, l4: 0.019124, l5: 0.019545, l6: 0.018601

[epoch:  77/100000, batch:   108/  187, ite: 7198] train loss: 0.190079, tar: 0.019159 
l0: 0.012697, l1: 0.012101, l2: 0.016140, l3: 0.015833, l4: 0.027812, l5: 0.029542, l6: 0.041536

[epoch:  77/100000, batch:   110/  187, ite: 7199] train loss: 0.190050, tar: 0.019154 
l0: 0.008704, l1: 0.007364, l2: 0.011430, l3: 0.014413, l4: 0.025602, l5: 0.034062, l6: 0.034064

[epoch:  77/100000, batch:   112/  187, ite: 7200] train loss: 0.190005, tar: 0.019145 
l0: 0.011051, l1: 0.012195, l2: 0.010361, l3: 0.009912, l4: 0.019995, l5: 0.019220, l6: 0.020189

[epoch:  77/100000, batch:   114/  187, ite: 7201] train loss: 0.189932, tar: 0.019139 
l0: 0.011071, l1: 0.012060, l2: 0.011648, l3: 0.010989, l4: 0.017272, l5: 0.018024, l6: 0.021650

[epoch:  77/100000, batch:   116/  187, ite: 7202] train loss: 0.189860, tar: 0.019132 
l0: 0.014958, l1: 0.013785, l2: 0.024637, l3: 0.023820, l4: 0.031946, l5: 0.030511, l6: 0.030970

[epoch:  77/100000, batch:   118/  187, ite: 7203] train loss: 0.189844, tar: 0.019128 
l0: 0.007766, l1: 0.007482, l2: 0.011277, l3: 0.014281, l4: 0.032275, l5: 0.027576, l6: 0.024581

[epoch:  77/100000, batch:   120/  187, ite: 7204] train loss: 0.189790, tar: 0.019119 
l0: 0.013749, l1: 0.016506, l2: 0.013433, l3: 0.013808, l4: 0.022783, l5: 0.016599, l6: 0.015176

[epoch:  77/100000, batch:   122/  187, ite: 7205] train loss: 0.189726, tar: 0.019115 
l0: 0.014936, l1: 0.015828, l2: 0.015349, l3: 0.015387, l4: 0.028964, l5: 0.027484, l6: 0.032028

[epoch:  77/100000, batch:   124/  187, ite: 7206] train loss: 0.189693, tar: 0.019111 
l0: 0.011425, l1: 0.011444, l2: 0.017764, l3: 0.018788, l4: 0.020287, l5: 0.021603, l6: 0.017558

[epoch:  77/100000, batch:   126/  187, ite: 7207] train loss: 0.189634, tar: 0.019105 
l0: 0.017949, l1: 0.019073, l2: 0.016748, l3: 0.016132, l4: 0.030576, l5: 0.029283, l6: 0.030942

[epoch:  77/100000, batch:   128/  187, ite: 7208] train loss: 0.189610, tar: 0.019104 
l0: 0.011860, l1: 0.011359, l2: 0.012212, l3: 0.011938, l4: 0.019202, l5: 0.021565, l6: 0.024835

[epoch:  77/100000, batch:   130/  187, ite: 7209] train loss: 0.189547, tar: 0.019098 
l0: 0.021855, l1: 0.021838, l2: 0.020880, l3: 0.024816, l4: 0.026913, l5: 0.024286, l6: 0.023739

[epoch:  77/100000, batch:   132/  187, ite: 7210] train loss: 0.189526, tar: 0.019100 
l0: 0.056013, l1: 0.063791, l2: 0.041507, l3: 0.034311, l4: 0.019131, l5: 0.022761, l6: 0.028361

[epoch:  77/100000, batch:   134/  187, ite: 7211] train loss: 0.189589, tar: 0.019131 
l0: 0.016539, l1: 0.015235, l2: 0.017557, l3: 0.020098, l4: 0.028913, l5: 0.027360, l6: 0.027494

[epoch:  77/100000, batch:   136/  187, ite: 7212] train loss: 0.189559, tar: 0.019128 
l0: 0.013592, l1: 0.014399, l2: 0.014919, l3: 0.015865, l4: 0.034628, l5: 0.030312, l6: 0.030189

[epoch:  77/100000, batch:   138/  187, ite: 7213] train loss: 0.189529, tar: 0.019124 
l0: 0.020489, l1: 0.020070, l2: 0.021726, l3: 0.021779, l4: 0.026224, l5: 0.023182, l6: 0.026273

[epoch:  77/100000, batch:   140/  187, ite: 7214] train loss: 0.189505, tar: 0.019125 
l0: 0.024680, l1: 0.019960, l2: 0.025558, l3: 0.037104, l4: 0.048116, l5: 0.053684, l6: 0.048673

[epoch:  77/100000, batch:   142/  187, ite: 7215] train loss: 0.189561, tar: 0.019130 
l0: 0.010467, l1: 0.011654, l2: 0.011548, l3: 0.013905, l4: 0.016161, l5: 0.015766, l6: 0.021333

[epoch:  77/100000, batch:   144/  187, ite: 7216] train loss: 0.189488, tar: 0.019122 
l0: 0.018526, l1: 0.019718, l2: 0.023067, l3: 0.023236, l4: 0.015463, l5: 0.011569, l6: 0.014749

[epoch:  77/100000, batch:   146/  187, ite: 7217] train loss: 0.189436, tar: 0.019122 
l0: 0.014083, l1: 0.017609, l2: 0.013530, l3: 0.011880, l4: 0.021211, l5: 0.021568, l6: 0.021886

[epoch:  77/100000, batch:   148/  187, ite: 7218] train loss: 0.189381, tar: 0.019118 
l0: 0.014085, l1: 0.014334, l2: 0.020219, l3: 0.019521, l4: 0.029099, l5: 0.027874, l6: 0.030440

[epoch:  77/100000, batch:   150/  187, ite: 7219] train loss: 0.189353, tar: 0.019114 
l0: 0.012379, l1: 0.012659, l2: 0.014151, l3: 0.015088, l4: 0.021368, l5: 0.022127, l6: 0.028940

[epoch:  77/100000, batch:   152/  187, ite: 7220] train loss: 0.189302, tar: 0.019108 
l0: 0.013181, l1: 0.011358, l2: 0.028687, l3: 0.026380, l4: 0.026102, l5: 0.023983, l6: 0.017555

[epoch:  77/100000, batch:   154/  187, ite: 7221] train loss: 0.189267, tar: 0.019103 
l0: 0.018801, l1: 0.022150, l2: 0.023623, l3: 0.016170, l4: 0.024415, l5: 0.020618, l6: 0.017722

[epoch:  77/100000, batch:   156/  187, ite: 7222] train loss: 0.189230, tar: 0.019103 
l0: 0.009704, l1: 0.010681, l2: 0.011309, l3: 0.012290, l4: 0.026218, l5: 0.017287, l6: 0.014791

[epoch:  77/100000, batch:   158/  187, ite: 7223] train loss: 0.189159, tar: 0.019095 
l0: 0.012103, l1: 0.012039, l2: 0.012968, l3: 0.014837, l4: 0.027227, l5: 0.031680, l6: 0.034206

[epoch:  77/100000, batch:   160/  187, ite: 7224] train loss: 0.189123, tar: 0.019090 
l0: 0.015534, l1: 0.017016, l2: 0.017875, l3: 0.017488, l4: 0.024738, l5: 0.021424, l6: 0.025172

[epoch:  77/100000, batch:   162/  187, ite: 7225] train loss: 0.189082, tar: 0.019087 
l0: 0.010712, l1: 0.010490, l2: 0.015992, l3: 0.020548, l4: 0.026550, l5: 0.019942, l6: 0.018414

[epoch:  77/100000, batch:   164/  187, ite: 7226] train loss: 0.189028, tar: 0.019080 
l0: 0.015624, l1: 0.015359, l2: 0.014060, l3: 0.016637, l4: 0.036542, l5: 0.035055, l6: 0.044907

[epoch:  77/100000, batch:   166/  187, ite: 7227] train loss: 0.189019, tar: 0.019077 
l0: 0.016515, l1: 0.017545, l2: 0.016347, l3: 0.016907, l4: 0.044683, l5: 0.044472, l6: 0.049813

[epoch:  77/100000, batch:   168/  187, ite: 7228] train loss: 0.189033, tar: 0.019075 
l0: 0.011756, l1: 0.010835, l2: 0.010745, l3: 0.012841, l4: 0.049920, l5: 0.043394, l6: 0.045768

[epoch:  77/100000, batch:   170/  187, ite: 7229] train loss: 0.189030, tar: 0.019069 
l0: 0.013434, l1: 0.014946, l2: 0.015471, l3: 0.015917, l4: 0.015002, l5: 0.019927, l6: 0.026212

[epoch:  77/100000, batch:   172/  187, ite: 7230] train loss: 0.188974, tar: 0.019064 
l0: 0.014807, l1: 0.016575, l2: 0.015958, l3: 0.014875, l4: 0.021819, l5: 0.020280, l6: 0.018369

[epoch:  77/100000, batch:   174/  187, ite: 7231] train loss: 0.188921, tar: 0.019061 
l0: 0.016660, l1: 0.017128, l2: 0.015451, l3: 0.017552, l4: 0.017184, l5: 0.015782, l6: 0.023263

[epoch:  77/100000, batch:   176/  187, ite: 7232] train loss: 0.188867, tar: 0.019059 
l0: 0.013818, l1: 0.017356, l2: 0.012092, l3: 0.011338, l4: 0.022197, l5: 0.022168, l6: 0.034142

[epoch:  77/100000, batch:   178/  187, ite: 7233] train loss: 0.188822, tar: 0.019055 
l0: 0.009148, l1: 0.009843, l2: 0.008707, l3: 0.010095, l4: 0.022997, l5: 0.024458, l6: 0.023825

[epoch:  77/100000, batch:   180/  187, ite: 7234] train loss: 0.188757, tar: 0.019047 
l0: 0.016036, l1: 0.016607, l2: 0.013212, l3: 0.017383, l4: 0.028836, l5: 0.023166, l6: 0.028515

[epoch:  77/100000, batch:   182/  187, ite: 7235] train loss: 0.188721, tar: 0.019044 
l0: 0.008756, l1: 0.009512, l2: 0.008911, l3: 0.008712, l4: 0.019348, l5: 0.018750, l6: 0.020650

[epoch:  77/100000, batch:   184/  187, ite: 7236] train loss: 0.188645, tar: 0.019036 
l0: 0.026196, l1: 0.026083, l2: 0.036712, l3: 0.042385, l4: 0.043245, l5: 0.035907, l6: 0.030471

[epoch:  77/100000, batch:   186/  187, ite: 7237] train loss: 0.188687, tar: 0.019042 
l0: 0.007754, l1: 0.007797, l2: 0.009364, l3: 0.007540, l4: 0.009291, l5: 0.011588, l6: 0.010217

[epoch:  77/100000, batch:   188/  187, ite: 7238] train loss: 0.188586, tar: 0.019033 
l0: 0.010130, l1: 0.009965, l2: 0.015208, l3: 0.014055, l4: 0.026459, l5: 0.022134, l6: 0.025809

[epoch:  78/100000, batch:     2/  187, ite: 7239] train loss: 0.188534, tar: 0.019026 
l0: 0.015870, l1: 0.016028, l2: 0.015781, l3: 0.015561, l4: 0.025554, l5: 0.022606, l6: 0.029450

[epoch:  78/100000, batch:     4/  187, ite: 7240] train loss: 0.188495, tar: 0.019023 
l0: 0.012378, l1: 0.012107, l2: 0.013237, l3: 0.016599, l4: 0.034408, l5: 0.037350, l6: 0.044035

[epoch:  78/100000, batch:     6/  187, ite: 7241] train loss: 0.188480, tar: 0.019018 
l0: 0.013926, l1: 0.013957, l2: 0.013648, l3: 0.014381, l4: 0.024121, l5: 0.024667, l6: 0.026121

[epoch:  78/100000, batch:     8/  187, ite: 7242] train loss: 0.188434, tar: 0.019014 
l0: 0.010929, l1: 0.011111, l2: 0.011944, l3: 0.011686, l4: 0.018148, l5: 0.017779, l6: 0.017807

[epoch:  78/100000, batch:    10/  187, ite: 7243] train loss: 0.188362, tar: 0.019007 
l0: 0.007019, l1: 0.007078, l2: 0.008070, l3: 0.008605, l4: 0.017127, l5: 0.018018, l6: 0.018823

[epoch:  78/100000, batch:    12/  187, ite: 7244] train loss: 0.188279, tar: 0.018997 
l0: 0.014324, l1: 0.013961, l2: 0.017875, l3: 0.014433, l4: 0.011848, l5: 0.014701, l6: 0.012688

[epoch:  78/100000, batch:    14/  187, ite: 7245] train loss: 0.188208, tar: 0.018994 
l0: 0.019732, l1: 0.020636, l2: 0.026529, l3: 0.028448, l4: 0.026346, l5: 0.028461, l6: 0.024930

[epoch:  78/100000, batch:    16/  187, ite: 7246] train loss: 0.188197, tar: 0.018994 
l0: 0.019096, l1: 0.019574, l2: 0.020371, l3: 0.021363, l4: 0.024289, l5: 0.024730, l6: 0.024785

[epoch:  78/100000, batch:    18/  187, ite: 7247] train loss: 0.188170, tar: 0.018994 
l0: 0.014881, l1: 0.013218, l2: 0.014545, l3: 0.017736, l4: 0.041250, l5: 0.038997, l6: 0.047351

[epoch:  78/100000, batch:    20/  187, ite: 7248] train loss: 0.188170, tar: 0.018991 
l0: 0.010143, l1: 0.010547, l2: 0.010412, l3: 0.009928, l4: 0.022705, l5: 0.019321, l6: 0.017849

[epoch:  78/100000, batch:    22/  187, ite: 7249] train loss: 0.188100, tar: 0.018984 
l0: 0.015725, l1: 0.015879, l2: 0.016051, l3: 0.015742, l4: 0.025943, l5: 0.025718, l6: 0.019468

[epoch:  78/100000, batch:    24/  187, ite: 7250] train loss: 0.188057, tar: 0.018981 
l0: 0.015510, l1: 0.015244, l2: 0.017914, l3: 0.019683, l4: 0.036871, l5: 0.031874, l6: 0.034047

[epoch:  78/100000, batch:    26/  187, ite: 7251] train loss: 0.188044, tar: 0.018979 
l0: 0.022893, l1: 0.021165, l2: 0.024344, l3: 0.029165, l4: 0.048874, l5: 0.042131, l6: 0.050282

[epoch:  78/100000, batch:    28/  187, ite: 7252] train loss: 0.188084, tar: 0.018982 
l0: 0.020829, l1: 0.018912, l2: 0.021702, l3: 0.025397, l4: 0.046124, l5: 0.049262, l6: 0.044507

[epoch:  78/100000, batch:    30/  187, ite: 7253] train loss: 0.188115, tar: 0.018983 
l0: 0.012159, l1: 0.012470, l2: 0.012622, l3: 0.012751, l4: 0.027681, l5: 0.026739, l6: 0.036861

[epoch:  78/100000, batch:    32/  187, ite: 7254] train loss: 0.188078, tar: 0.018978 
l0: 0.015387, l1: 0.015401, l2: 0.015361, l3: 0.015374, l4: 0.028157, l5: 0.028744, l6: 0.033615

[epoch:  78/100000, batch:    34/  187, ite: 7255] train loss: 0.188049, tar: 0.018975 
l0: 0.011792, l1: 0.012075, l2: 0.013940, l3: 0.014056, l4: 0.019040, l5: 0.020679, l6: 0.019685

[epoch:  78/100000, batch:    36/  187, ite: 7256] train loss: 0.187988, tar: 0.018969 
l0: 0.009754, l1: 0.008845, l2: 0.012215, l3: 0.013254, l4: 0.022547, l5: 0.023368, l6: 0.020914

[epoch:  78/100000, batch:    38/  187, ite: 7257] train loss: 0.187927, tar: 0.018962 
l0: 0.006221, l1: 0.006210, l2: 0.009347, l3: 0.010874, l4: 0.014683, l5: 0.015442, l6: 0.014057

[epoch:  78/100000, batch:    40/  187, ite: 7258] train loss: 0.187838, tar: 0.018952 
l0: 0.013544, l1: 0.014846, l2: 0.013941, l3: 0.012974, l4: 0.015702, l5: 0.015036, l6: 0.020895

[epoch:  78/100000, batch:    42/  187, ite: 7259] train loss: 0.187774, tar: 0.018947 
l0: 0.014548, l1: 0.013791, l2: 0.018704, l3: 0.019464, l4: 0.026850, l5: 0.021623, l6: 0.031136

[epoch:  78/100000, batch:    44/  187, ite: 7260] train loss: 0.187741, tar: 0.018944 
l0: 0.012024, l1: 0.011744, l2: 0.014704, l3: 0.015497, l4: 0.030818, l5: 0.025873, l6: 0.032513

[epoch:  78/100000, batch:    46/  187, ite: 7261] train loss: 0.187706, tar: 0.018938 
l0: 0.011213, l1: 0.010276, l2: 0.016410, l3: 0.017342, l4: 0.024808, l5: 0.023517, l6: 0.026639

[epoch:  78/100000, batch:    48/  187, ite: 7262] train loss: 0.187660, tar: 0.018932 
l0: 0.010959, l1: 0.011107, l2: 0.013384, l3: 0.012674, l4: 0.026765, l5: 0.024891, l6: 0.032500

[epoch:  78/100000, batch:    50/  187, ite: 7263] train loss: 0.187616, tar: 0.018926 
l0: 0.015413, l1: 0.015087, l2: 0.020313, l3: 0.019385, l4: 0.036142, l5: 0.029993, l6: 0.031202

[epoch:  78/100000, batch:    52/  187, ite: 7264] train loss: 0.187600, tar: 0.018923 
l0: 0.012451, l1: 0.012822, l2: 0.019344, l3: 0.016836, l4: 0.025828, l5: 0.024472, l6: 0.027028

[epoch:  78/100000, batch:    54/  187, ite: 7265] train loss: 0.187562, tar: 0.018918 
l0: 0.010919, l1: 0.011887, l2: 0.008909, l3: 0.010509, l4: 0.021880, l5: 0.020464, l6: 0.016221

[epoch:  78/100000, batch:    56/  187, ite: 7266] train loss: 0.187493, tar: 0.018912 
l0: 0.019574, l1: 0.020024, l2: 0.039345, l3: 0.038843, l4: 0.041529, l5: 0.046761, l6: 0.039241

[epoch:  78/100000, batch:    58/  187, ite: 7267] train loss: 0.187539, tar: 0.018912 
l0: 0.015046, l1: 0.016533, l2: 0.017918, l3: 0.019656, l4: 0.025688, l5: 0.021896, l6: 0.023839

[epoch:  78/100000, batch:    60/  187, ite: 7268] train loss: 0.187502, tar: 0.018909 
l0: 0.009961, l1: 0.010368, l2: 0.012273, l3: 0.011459, l4: 0.024367, l5: 0.020968, l6: 0.018653

[epoch:  78/100000, batch:    62/  187, ite: 7269] train loss: 0.187439, tar: 0.018902 
l0: 0.017248, l1: 0.015615, l2: 0.019415, l3: 0.021237, l4: 0.035282, l5: 0.037635, l6: 0.047218

[epoch:  78/100000, batch:    64/  187, ite: 7270] train loss: 0.187444, tar: 0.018901 
l0: 0.013797, l1: 0.012746, l2: 0.024792, l3: 0.024467, l4: 0.028737, l5: 0.030084, l6: 0.029043

[epoch:  78/100000, batch:    66/  187, ite: 7271] train loss: 0.187425, tar: 0.018897 
l0: 0.024388, l1: 0.023535, l2: 0.025503, l3: 0.030467, l4: 0.048769, l5: 0.037848, l6: 0.061745

[epoch:  78/100000, batch:    68/  187, ite: 7272] train loss: 0.187476, tar: 0.018901 
l0: 0.021344, l1: 0.020390, l2: 0.022835, l3: 0.023753, l4: 0.043322, l5: 0.039256, l6: 0.058687

[epoch:  78/100000, batch:    70/  187, ite: 7273] train loss: 0.187509, tar: 0.018903 
l0: 0.017720, l1: 0.017131, l2: 0.018262, l3: 0.021338, l4: 0.031481, l5: 0.030948, l6: 0.025702

[epoch:  78/100000, batch:    72/  187, ite: 7274] train loss: 0.187490, tar: 0.018902 
l0: 0.013694, l1: 0.013388, l2: 0.019106, l3: 0.018479, l4: 0.024049, l5: 0.019864, l6: 0.022793

[epoch:  78/100000, batch:    74/  187, ite: 7275] train loss: 0.187446, tar: 0.018898 
l0: 0.013704, l1: 0.014559, l2: 0.014400, l3: 0.018426, l4: 0.028651, l5: 0.028884, l6: 0.029803

[epoch:  78/100000, batch:    76/  187, ite: 7276] train loss: 0.187415, tar: 0.018894 
l0: 0.011619, l1: 0.012915, l2: 0.010939, l3: 0.011248, l4: 0.023683, l5: 0.020094, l6: 0.022982

[epoch:  78/100000, batch:    78/  187, ite: 7277] train loss: 0.187357, tar: 0.018888 
l0: 0.012652, l1: 0.013288, l2: 0.008838, l3: 0.008671, l4: 0.021824, l5: 0.022930, l6: 0.024420

[epoch:  78/100000, batch:    80/  187, ite: 7278] train loss: 0.187299, tar: 0.018883 
l0: 0.010800, l1: 0.010627, l2: 0.011056, l3: 0.012331, l4: 0.031093, l5: 0.031375, l6: 0.032360

[epoch:  78/100000, batch:    82/  187, ite: 7279] train loss: 0.187262, tar: 0.018877 
l0: 0.012408, l1: 0.012520, l2: 0.012438, l3: 0.014680, l4: 0.026691, l5: 0.029031, l6: 0.030429

[epoch:  78/100000, batch:    84/  187, ite: 7280] train loss: 0.187223, tar: 0.018872 
l0: 0.018372, l1: 0.017079, l2: 0.025158, l3: 0.023911, l4: 0.024067, l5: 0.025353, l6: 0.026968

[epoch:  78/100000, batch:    86/  187, ite: 7281] train loss: 0.187203, tar: 0.018872 
l0: 0.022981, l1: 0.021810, l2: 0.025088, l3: 0.026625, l4: 0.034235, l5: 0.040950, l6: 0.041974

[epoch:  78/100000, batch:    88/  187, ite: 7282] train loss: 0.187223, tar: 0.018875 
l0: 0.019296, l1: 0.015347, l2: 0.026025, l3: 0.035246, l4: 0.055075, l5: 0.058469, l6: 0.064903

[epoch:  78/100000, batch:    90/  187, ite: 7283] train loss: 0.187291, tar: 0.018875 
l0: 0.010996, l1: 0.012108, l2: 0.014821, l3: 0.014930, l4: 0.019604, l5: 0.019633, l6: 0.016764

[epoch:  78/100000, batch:    92/  187, ite: 7284] train loss: 0.187230, tar: 0.018869 
l0: 0.006040, l1: 0.007341, l2: 0.009459, l3: 0.010872, l4: 0.015284, l5: 0.013527, l6: 0.015741

[epoch:  78/100000, batch:    94/  187, ite: 7285] train loss: 0.187145, tar: 0.018859 
l0: 0.018579, l1: 0.020460, l2: 0.018398, l3: 0.018745, l4: 0.023919, l5: 0.022755, l6: 0.033549

[epoch:  78/100000, batch:    96/  187, ite: 7286] train loss: 0.187122, tar: 0.018859 
l0: 0.020181, l1: 0.021299, l2: 0.018454, l3: 0.017625, l4: 0.023729, l5: 0.024313, l6: 0.031417

[epoch:  78/100000, batch:    98/  187, ite: 7287] train loss: 0.187098, tar: 0.018860 
l0: 0.014217, l1: 0.015928, l2: 0.015208, l3: 0.017983, l4: 0.033938, l5: 0.037808, l6: 0.042227

[epoch:  78/100000, batch:   100/  187, ite: 7288] train loss: 0.187091, tar: 0.018856 
l0: 0.015870, l1: 0.015332, l2: 0.017055, l3: 0.017268, l4: 0.030327, l5: 0.029768, l6: 0.026432

[epoch:  78/100000, batch:   102/  187, ite: 7289] train loss: 0.187063, tar: 0.018854 
l0: 0.009425, l1: 0.009091, l2: 0.016544, l3: 0.029496, l4: 0.025491, l5: 0.019879, l6: 0.016835

[epoch:  78/100000, batch:   104/  187, ite: 7290] train loss: 0.187017, tar: 0.018847 
l0: 0.008601, l1: 0.010208, l2: 0.008499, l3: 0.007112, l4: 0.019595, l5: 0.018087, l6: 0.015427

[epoch:  78/100000, batch:   106/  187, ite: 7291] train loss: 0.186940, tar: 0.018839 
l0: 0.013765, l1: 0.014451, l2: 0.015466, l3: 0.018480, l4: 0.020669, l5: 0.018987, l6: 0.018277

[epoch:  78/100000, batch:   108/  187, ite: 7292] train loss: 0.186888, tar: 0.018835 
l0: 0.013515, l1: 0.013966, l2: 0.014346, l3: 0.016489, l4: 0.025276, l5: 0.029115, l6: 0.024530

[epoch:  78/100000, batch:   110/  187, ite: 7293] train loss: 0.186849, tar: 0.018831 
l0: 0.007283, l1: 0.007840, l2: 0.009243, l3: 0.010500, l4: 0.025915, l5: 0.022105, l6: 0.025128

[epoch:  78/100000, batch:   112/  187, ite: 7294] train loss: 0.186789, tar: 0.018822 
l0: 0.007488, l1: 0.007664, l2: 0.008661, l3: 0.010373, l4: 0.017831, l5: 0.018011, l6: 0.024837

[epoch:  78/100000, batch:   114/  187, ite: 7295] train loss: 0.186718, tar: 0.018813 
l0: 0.015554, l1: 0.017585, l2: 0.012612, l3: 0.013607, l4: 0.028723, l5: 0.025996, l6: 0.017395

[epoch:  78/100000, batch:   116/  187, ite: 7296] train loss: 0.186675, tar: 0.018810 
l0: 0.024727, l1: 0.023268, l2: 0.021705, l3: 0.023472, l4: 0.065366, l5: 0.062219, l6: 0.069127

[epoch:  78/100000, batch:   118/  187, ite: 7297] train loss: 0.186755, tar: 0.018815 
l0: 0.011681, l1: 0.011770, l2: 0.012980, l3: 0.015304, l4: 0.029792, l5: 0.035200, l6: 0.032166

[epoch:  78/100000, batch:   120/  187, ite: 7298] train loss: 0.186725, tar: 0.018810 
l0: 0.006713, l1: 0.007240, l2: 0.007496, l3: 0.007648, l4: 0.013219, l5: 0.014525, l6: 0.021914

[epoch:  78/100000, batch:   122/  187, ite: 7299] train loss: 0.186642, tar: 0.018800 
l0: 0.016274, l1: 0.018735, l2: 0.018273, l3: 0.018158, l4: 0.047955, l5: 0.028366, l6: 0.026590

[epoch:  78/100000, batch:   124/  187, ite: 7300] train loss: 0.186633, tar: 0.018798 
l0: 0.038553, l1: 0.035665, l2: 0.050264, l3: 0.063520, l4: 0.036044, l5: 0.040572, l6: 0.040526

[epoch:  78/100000, batch:   126/  187, ite: 7301] train loss: 0.186724, tar: 0.018813 
l0: 0.012669, l1: 0.012499, l2: 0.014243, l3: 0.015950, l4: 0.047558, l5: 0.035590, l6: 0.034000

[epoch:  78/100000, batch:   128/  187, ite: 7302] train loss: 0.186713, tar: 0.018809 
l0: 0.008665, l1: 0.008216, l2: 0.010695, l3: 0.013938, l4: 0.027418, l5: 0.030156, l6: 0.028111

[epoch:  78/100000, batch:   130/  187, ite: 7303] train loss: 0.186667, tar: 0.018801 
l0: 0.010233, l1: 0.011847, l2: 0.009055, l3: 0.010858, l4: 0.018451, l5: 0.016766, l6: 0.015708

[epoch:  78/100000, batch:   132/  187, ite: 7304] train loss: 0.186595, tar: 0.018794 
l0: 0.014111, l1: 0.016171, l2: 0.014434, l3: 0.011584, l4: 0.016625, l5: 0.015874, l6: 0.017706

[epoch:  78/100000, batch:   134/  187, ite: 7305] train loss: 0.186534, tar: 0.018791 
l0: 0.007956, l1: 0.009392, l2: 0.007948, l3: 0.008910, l4: 0.017064, l5: 0.015150, l6: 0.015350

[epoch:  78/100000, batch:   136/  187, ite: 7306] train loss: 0.186454, tar: 0.018783 
l0: 0.019826, l1: 0.021139, l2: 0.021287, l3: 0.021955, l4: 0.037047, l5: 0.033867, l6: 0.029482

[epoch:  78/100000, batch:   138/  187, ite: 7307] train loss: 0.186452, tar: 0.018783 
l0: 0.009899, l1: 0.012123, l2: 0.010020, l3: 0.010037, l4: 0.017786, l5: 0.017326, l6: 0.018691

[epoch:  78/100000, batch:   140/  187, ite: 7308] train loss: 0.186383, tar: 0.018777 
l0: 0.012818, l1: 0.012662, l2: 0.013949, l3: 0.017681, l4: 0.029413, l5: 0.030435, l6: 0.025155

[epoch:  78/100000, batch:   142/  187, ite: 7309] train loss: 0.186349, tar: 0.018772 
l0: 0.012691, l1: 0.013882, l2: 0.013119, l3: 0.013773, l4: 0.022736, l5: 0.019994, l6: 0.025765

[epoch:  78/100000, batch:   144/  187, ite: 7310] train loss: 0.186300, tar: 0.018767 
l0: 0.014460, l1: 0.015191, l2: 0.015753, l3: 0.016401, l4: 0.030088, l5: 0.027488, l6: 0.036095

[epoch:  78/100000, batch:   146/  187, ite: 7311] train loss: 0.186277, tar: 0.018764 
l0: 0.016279, l1: 0.018003, l2: 0.011658, l3: 0.017321, l4: 0.023601, l5: 0.021195, l6: 0.022023

[epoch:  78/100000, batch:   148/  187, ite: 7312] train loss: 0.186234, tar: 0.018762 
l0: 0.014132, l1: 0.013843, l2: 0.016567, l3: 0.014154, l4: 0.021708, l5: 0.026345, l6: 0.026256

[epoch:  78/100000, batch:   150/  187, ite: 7313] train loss: 0.186193, tar: 0.018759 
l0: 0.015874, l1: 0.017234, l2: 0.016381, l3: 0.019987, l4: 0.019117, l5: 0.016741, l6: 0.020373

[epoch:  78/100000, batch:   152/  187, ite: 7314] train loss: 0.186147, tar: 0.018756 
l0: 0.012883, l1: 0.012428, l2: 0.014210, l3: 0.017871, l4: 0.034048, l5: 0.033875, l6: 0.023310

[epoch:  78/100000, batch:   154/  187, ite: 7315] train loss: 0.186119, tar: 0.018752 
l0: 0.013631, l1: 0.013474, l2: 0.012384, l3: 0.013099, l4: 0.024621, l5: 0.031624, l6: 0.036543

[epoch:  78/100000, batch:   156/  187, ite: 7316] train loss: 0.186088, tar: 0.018748 
l0: 0.011183, l1: 0.011850, l2: 0.011492, l3: 0.012881, l4: 0.021713, l5: 0.023291, l6: 0.025228

[epoch:  78/100000, batch:   158/  187, ite: 7317] train loss: 0.186036, tar: 0.018742 
l0: 0.024065, l1: 0.024350, l2: 0.025046, l3: 0.026352, l4: 0.038232, l5: 0.039434, l6: 0.043259

[epoch:  78/100000, batch:   160/  187, ite: 7318] train loss: 0.186062, tar: 0.018746 
l0: 0.012087, l1: 0.012751, l2: 0.014780, l3: 0.013356, l4: 0.014557, l5: 0.017014, l6: 0.024155

[epoch:  78/100000, batch:   162/  187, ite: 7319] train loss: 0.186003, tar: 0.018741 
l0: 0.017609, l1: 0.015831, l2: 0.025872, l3: 0.035357, l4: 0.029004, l5: 0.030251, l6: 0.035767

[epoch:  78/100000, batch:   164/  187, ite: 7320] train loss: 0.186006, tar: 0.018740 
l0: 0.010215, l1: 0.010044, l2: 0.012062, l3: 0.014420, l4: 0.020326, l5: 0.022969, l6: 0.024671

[epoch:  78/100000, batch:   166/  187, ite: 7321] train loss: 0.185952, tar: 0.018734 
l0: 0.012107, l1: 0.011392, l2: 0.013069, l3: 0.014850, l4: 0.017393, l5: 0.021837, l6: 0.023796

[epoch:  78/100000, batch:   168/  187, ite: 7322] train loss: 0.185898, tar: 0.018729 
l0: 0.011701, l1: 0.011853, l2: 0.013449, l3: 0.013330, l4: 0.033436, l5: 0.028269, l6: 0.026402

[epoch:  78/100000, batch:   170/  187, ite: 7323] train loss: 0.185862, tar: 0.018724 
l0: 0.020964, l1: 0.021355, l2: 0.024893, l3: 0.022365, l4: 0.033403, l5: 0.030964, l6: 0.027310

[epoch:  78/100000, batch:   172/  187, ite: 7324] train loss: 0.185859, tar: 0.018725 
l0: 0.012825, l1: 0.014355, l2: 0.013528, l3: 0.013221, l4: 0.028202, l5: 0.028949, l6: 0.026296

[epoch:  78/100000, batch:   174/  187, ite: 7325] train loss: 0.185822, tar: 0.018721 
l0: 0.011940, l1: 0.012259, l2: 0.013701, l3: 0.014173, l4: 0.025500, l5: 0.025471, l6: 0.034488

[epoch:  78/100000, batch:   176/  187, ite: 7326] train loss: 0.185786, tar: 0.018716 
l0: 0.006753, l1: 0.006762, l2: 0.008788, l3: 0.008305, l4: 0.014045, l5: 0.016828, l6: 0.017646

[epoch:  78/100000, batch:   178/  187, ite: 7327] train loss: 0.185705, tar: 0.018707 
l0: 0.004749, l1: 0.005174, l2: 0.005312, l3: 0.005534, l4: 0.011824, l5: 0.013624, l6: 0.016020

[epoch:  78/100000, batch:   180/  187, ite: 7328] train loss: 0.185612, tar: 0.018696 
l0: 0.006942, l1: 0.007194, l2: 0.007340, l3: 0.009928, l4: 0.017246, l5: 0.016732, l6: 0.017959

[epoch:  78/100000, batch:   182/  187, ite: 7329] train loss: 0.185536, tar: 0.018687 
l0: 0.011739, l1: 0.011010, l2: 0.013723, l3: 0.017478, l4: 0.019114, l5: 0.018162, l6: 0.022493

[epoch:  78/100000, batch:   184/  187, ite: 7330] train loss: 0.185482, tar: 0.018682 
l0: 0.011422, l1: 0.010437, l2: 0.018017, l3: 0.026703, l4: 0.023912, l5: 0.022209, l6: 0.021215

[epoch:  78/100000, batch:   186/  187, ite: 7331] train loss: 0.185443, tar: 0.018677 
l0: 0.022841, l1: 0.021007, l2: 0.027919, l3: 0.030689, l4: 0.051021, l5: 0.060863, l6: 0.046396

[epoch:  78/100000, batch:   188/  187, ite: 7332] train loss: 0.185499, tar: 0.018680 
l0: 0.015836, l1: 0.015540, l2: 0.018265, l3: 0.020410, l4: 0.022548, l5: 0.020658, l6: 0.019664

[epoch:  79/100000, batch:     2/  187, ite: 7333] train loss: 0.185460, tar: 0.018678 
l0: 0.006669, l1: 0.006598, l2: 0.010428, l3: 0.012499, l4: 0.024659, l5: 0.016508, l6: 0.016068

[epoch:  79/100000, batch:     4/  187, ite: 7334] train loss: 0.185391, tar: 0.018669 
l0: 0.010628, l1: 0.012161, l2: 0.011368, l3: 0.010983, l4: 0.018880, l5: 0.017747, l6: 0.020168

[epoch:  79/100000, batch:     6/  187, ite: 7335] train loss: 0.185328, tar: 0.018663 
l0: 0.013420, l1: 0.014698, l2: 0.012643, l3: 0.013423, l4: 0.025497, l5: 0.026618, l6: 0.022279

[epoch:  79/100000, batch:     8/  187, ite: 7336] train loss: 0.185286, tar: 0.018659 
l0: 0.013934, l1: 0.013647, l2: 0.015084, l3: 0.018139, l4: 0.035302, l5: 0.031637, l6: 0.032903

[epoch:  79/100000, batch:    10/  187, ite: 7337] train loss: 0.185267, tar: 0.018655 
l0: 0.008508, l1: 0.008607, l2: 0.009532, l3: 0.009931, l4: 0.017996, l5: 0.020447, l6: 0.020393

[epoch:  79/100000, batch:    12/  187, ite: 7338] train loss: 0.185200, tar: 0.018648 
l0: 0.015767, l1: 0.016630, l2: 0.015221, l3: 0.016052, l4: 0.013613, l5: 0.016151, l6: 0.018055

[epoch:  79/100000, batch:    14/  187, ite: 7339] train loss: 0.185145, tar: 0.018646 
l0: 0.008966, l1: 0.010425, l2: 0.011287, l3: 0.009035, l4: 0.013008, l5: 0.012449, l6: 0.011864

[epoch:  79/100000, batch:    16/  187, ite: 7340] train loss: 0.185065, tar: 0.018638 
l0: 0.011888, l1: 0.015383, l2: 0.022532, l3: 0.012721, l4: 0.025078, l5: 0.020309, l6: 0.010044

[epoch:  79/100000, batch:    18/  187, ite: 7341] train loss: 0.185015, tar: 0.018633 
l0: 0.007486, l1: 0.007956, l2: 0.007840, l3: 0.013733, l4: 0.017057, l5: 0.024104, l6: 0.027597

[epoch:  79/100000, batch:    20/  187, ite: 7342] train loss: 0.184955, tar: 0.018625 
l0: 0.008021, l1: 0.007494, l2: 0.009201, l3: 0.010095, l4: 0.013328, l5: 0.016509, l6: 0.019890

[epoch:  79/100000, batch:    22/  187, ite: 7343] train loss: 0.184881, tar: 0.018617 
l0: 0.013077, l1: 0.014112, l2: 0.013526, l3: 0.013528, l4: 0.017076, l5: 0.017595, l6: 0.019925

[epoch:  79/100000, batch:    24/  187, ite: 7344] train loss: 0.184824, tar: 0.018613 
l0: 0.011415, l1: 0.011957, l2: 0.011929, l3: 0.012478, l4: 0.017607, l5: 0.014131, l6: 0.018449

[epoch:  79/100000, batch:    26/  187, ite: 7345] train loss: 0.184760, tar: 0.018608 
l0: 0.015509, l1: 0.015180, l2: 0.018141, l3: 0.021190, l4: 0.025936, l5: 0.028600, l6: 0.030943

[epoch:  79/100000, batch:    28/  187, ite: 7346] train loss: 0.184738, tar: 0.018605 
l0: 0.014617, l1: 0.013877, l2: 0.018964, l3: 0.023132, l4: 0.041344, l5: 0.032981, l6: 0.035520

[epoch:  79/100000, batch:    30/  187, ite: 7347] train loss: 0.184735, tar: 0.018602 
l0: 0.017080, l1: 0.019247, l2: 0.019279, l3: 0.011290, l4: 0.028211, l5: 0.025362, l6: 0.024824

[epoch:  79/100000, batch:    32/  187, ite: 7348] train loss: 0.184705, tar: 0.018601 
l0: 0.015572, l1: 0.017066, l2: 0.016728, l3: 0.016432, l4: 0.030252, l5: 0.029435, l6: 0.025611

[epoch:  79/100000, batch:    34/  187, ite: 7349] train loss: 0.184680, tar: 0.018599 
l0: 0.011033, l1: 0.011679, l2: 0.013819, l3: 0.013840, l4: 0.021267, l5: 0.018017, l6: 0.019474

[epoch:  79/100000, batch:    36/  187, ite: 7350] train loss: 0.184624, tar: 0.018593 
l0: 0.009778, l1: 0.010610, l2: 0.013564, l3: 0.013776, l4: 0.019658, l5: 0.017285, l6: 0.020701

[epoch:  79/100000, batch:    38/  187, ite: 7351] train loss: 0.184566, tar: 0.018587 
l0: 0.005660, l1: 0.006035, l2: 0.006793, l3: 0.007346, l4: 0.018651, l5: 0.016937, l6: 0.014479

[epoch:  79/100000, batch:    40/  187, ite: 7352] train loss: 0.184485, tar: 0.018577 
l0: 0.009534, l1: 0.010350, l2: 0.010225, l3: 0.012917, l4: 0.019479, l5: 0.021580, l6: 0.025015

[epoch:  79/100000, batch:    42/  187, ite: 7353] train loss: 0.184430, tar: 0.018571 
l0: 0.006142, l1: 0.006779, l2: 0.006362, l3: 0.006331, l4: 0.009127, l5: 0.009653, l6: 0.010216

[epoch:  79/100000, batch:    44/  187, ite: 7354] train loss: 0.184334, tar: 0.018561 
l0: 0.011611, l1: 0.010343, l2: 0.019036, l3: 0.018584, l4: 0.013798, l5: 0.016205, l6: 0.015417

[epoch:  79/100000, batch:    46/  187, ite: 7355] train loss: 0.184275, tar: 0.018556 
l0: 0.011090, l1: 0.011795, l2: 0.018597, l3: 0.013500, l4: 0.012970, l5: 0.014431, l6: 0.016228

[epoch:  79/100000, batch:    48/  187, ite: 7356] train loss: 0.184212, tar: 0.018551 
l0: 0.008165, l1: 0.008014, l2: 0.009073, l3: 0.010493, l4: 0.019450, l5: 0.018530, l6: 0.018165

[epoch:  79/100000, batch:    50/  187, ite: 7357] train loss: 0.184144, tar: 0.018543 
l0: 0.009749, l1: 0.008521, l2: 0.009190, l3: 0.011020, l4: 0.029815, l5: 0.036581, l6: 0.042112

[epoch:  79/100000, batch:    52/  187, ite: 7358] train loss: 0.184117, tar: 0.018537 
l0: 0.014709, l1: 0.014054, l2: 0.018150, l3: 0.017532, l4: 0.021200, l5: 0.019969, l6: 0.022137

[epoch:  79/100000, batch:    54/  187, ite: 7359] train loss: 0.184075, tar: 0.018534 
l0: 0.010675, l1: 0.010056, l2: 0.009494, l3: 0.012725, l4: 0.015986, l5: 0.016032, l6: 0.019055

[epoch:  79/100000, batch:    56/  187, ite: 7360] train loss: 0.184009, tar: 0.018528 
l0: 0.029208, l1: 0.029545, l2: 0.032975, l3: 0.029747, l4: 0.038361, l5: 0.043079, l6: 0.051992

[epoch:  79/100000, batch:    58/  187, ite: 7361] train loss: 0.184061, tar: 0.018536 
l0: 0.129958, l1: 0.143856, l2: 0.190595, l3: 0.122838, l4: 0.075136, l5: 0.060239, l6: 0.051391

[epoch:  79/100000, batch:    60/  187, ite: 7362] train loss: 0.184494, tar: 0.018618 
l0: 0.013457, l1: 0.013823, l2: 0.013506, l3: 0.015008, l4: 0.016980, l5: 0.019089, l6: 0.022297

[epoch:  79/100000, batch:    62/  187, ite: 7363] train loss: 0.184443, tar: 0.018614 
l0: 0.009138, l1: 0.011542, l2: 0.010610, l3: 0.010944, l4: 0.018168, l5: 0.017207, l6: 0.012688

[epoch:  79/100000, batch:    64/  187, ite: 7364] train loss: 0.184374, tar: 0.018607 
l0: 0.026484, l1: 0.045063, l2: 0.039003, l3: 0.024553, l4: 0.031676, l5: 0.032604, l6: 0.037267

[epoch:  79/100000, batch:    66/  187, ite: 7365] train loss: 0.184412, tar: 0.018613 
l0: 0.015593, l1: 0.016174, l2: 0.014458, l3: 0.019896, l4: 0.028854, l5: 0.032529, l6: 0.029645

[epoch:  79/100000, batch:    68/  187, ite: 7366] train loss: 0.184392, tar: 0.018611 
l0: 0.017368, l1: 0.020540, l2: 0.023202, l3: 0.028441, l4: 0.030850, l5: 0.031717, l6: 0.033409

[epoch:  79/100000, batch:    70/  187, ite: 7367] train loss: 0.184393, tar: 0.018610 
l0: 0.016624, l1: 0.018330, l2: 0.022198, l3: 0.022759, l4: 0.027637, l5: 0.024567, l6: 0.019522

[epoch:  79/100000, batch:    72/  187, ite: 7368] train loss: 0.184369, tar: 0.018608 
l0: 0.069299, l1: 0.081480, l2: 0.099877, l3: 0.096481, l4: 0.192473, l5: 0.097901, l6: 0.100093

[epoch:  79/100000, batch:    74/  187, ite: 7369] train loss: 0.184773, tar: 0.018645 
l0: 0.022402, l1: 0.018919, l2: 0.028987, l3: 0.030941, l4: 0.045259, l5: 0.051750, l6: 0.051139

[epoch:  79/100000, batch:    76/  187, ite: 7370] train loss: 0.184820, tar: 0.018648 
l0: 0.023766, l1: 0.034701, l2: 0.064858, l3: 0.050006, l4: 0.050345, l5: 0.026937, l6: 0.017170

[epoch:  79/100000, batch:    78/  187, ite: 7371] train loss: 0.184881, tar: 0.018652 
l0: 0.028613, l1: 0.026251, l2: 0.036800, l3: 0.047337, l4: 0.034913, l5: 0.036796, l6: 0.037147

[epoch:  79/100000, batch:    80/  187, ite: 7372] train loss: 0.184927, tar: 0.018659 
l0: 0.032871, l1: 0.037387, l2: 0.070602, l3: 0.065344, l4: 0.061387, l5: 0.037841, l6: 0.028525

[epoch:  79/100000, batch:    82/  187, ite: 7373] train loss: 0.185035, tar: 0.018669 
l0: 0.046001, l1: 0.053442, l2: 0.067761, l3: 0.068651, l4: 0.091041, l5: 0.058651, l6: 0.044617

[epoch:  79/100000, batch:    84/  187, ite: 7374] train loss: 0.185214, tar: 0.018689 
l0: 0.038284, l1: 0.037207, l2: 0.053360, l3: 0.056490, l4: 0.059946, l5: 0.054066, l6: 0.046635

[epoch:  79/100000, batch:    86/  187, ite: 7375] train loss: 0.185330, tar: 0.018703 
l0: 0.007449, l1: 0.008042, l2: 0.013880, l3: 0.014189, l4: 0.022613, l5: 0.022039, l6: 0.015951

[epoch:  79/100000, batch:    88/  187, ite: 7376] train loss: 0.185271, tar: 0.018695 
l0: 0.026582, l1: 0.034007, l2: 0.028189, l3: 0.025432, l4: 0.028939, l5: 0.027761, l6: 0.031139

[epoch:  79/100000, batch:    90/  187, ite: 7377] train loss: 0.185284, tar: 0.018701 
l0: 0.015486, l1: 0.018902, l2: 0.017563, l3: 0.015520, l4: 0.022932, l5: 0.033619, l6: 0.035005

[epoch:  79/100000, batch:    92/  187, ite: 7378] train loss: 0.185265, tar: 0.018699 
l0: 0.030818, l1: 0.034262, l2: 0.044239, l3: 0.039732, l4: 0.045964, l5: 0.053021, l6: 0.048906

[epoch:  79/100000, batch:    94/  187, ite: 7379] train loss: 0.185346, tar: 0.018707 
l0: 0.029261, l1: 0.034761, l2: 0.026048, l3: 0.024000, l4: 0.029801, l5: 0.033573, l6: 0.037280

[epoch:  79/100000, batch:    96/  187, ite: 7380] train loss: 0.185367, tar: 0.018715 
l0: 0.037569, l1: 0.043936, l2: 0.050212, l3: 0.049373, l4: 0.053183, l5: 0.042584, l6: 0.036740

[epoch:  79/100000, batch:    98/  187, ite: 7381] train loss: 0.185460, tar: 0.018729 
l0: 0.040570, l1: 0.038978, l2: 0.058356, l3: 0.050791, l4: 0.053256, l5: 0.074138, l6: 0.058502

[epoch:  79/100000, batch:   100/  187, ite: 7382] train loss: 0.185597, tar: 0.018745 
l0: 0.021071, l1: 0.020772, l2: 0.033013, l3: 0.027352, l4: 0.049908, l5: 0.044186, l6: 0.050449

[epoch:  79/100000, batch:   102/  187, ite: 7383] train loss: 0.185641, tar: 0.018746 
l0: 0.061277, l1: 0.069365, l2: 0.059457, l3: 0.049438, l4: 0.064948, l5: 0.064662, l6: 0.071653

[epoch:  79/100000, batch:   104/  187, ite: 7384] train loss: 0.185825, tar: 0.018777 
l0: 0.029543, l1: 0.026146, l2: 0.038718, l3: 0.045734, l4: 0.071716, l5: 0.074837, l6: 0.103951

[epoch:  79/100000, batch:   106/  187, ite: 7385] train loss: 0.185973, tar: 0.018785 
l0: 0.031626, l1: 0.031042, l2: 0.047895, l3: 0.050782, l4: 0.051374, l5: 0.050901, l6: 0.059742

[epoch:  79/100000, batch:   108/  187, ite: 7386] train loss: 0.186072, tar: 0.018794 
l0: 0.025911, l1: 0.026776, l2: 0.030203, l3: 0.035026, l4: 0.058132, l5: 0.049814, l6: 0.056747

[epoch:  79/100000, batch:   110/  187, ite: 7387] train loss: 0.186142, tar: 0.018799 
l0: 0.025155, l1: 0.024128, l2: 0.028643, l3: 0.039317, l4: 0.053120, l5: 0.041667, l6: 0.042863

[epoch:  79/100000, batch:   112/  187, ite: 7388] train loss: 0.186191, tar: 0.018804 
l0: 0.019515, l1: 0.026846, l2: 0.032842, l3: 0.027060, l4: 0.031858, l5: 0.018916, l6: 0.018478

[epoch:  79/100000, batch:   114/  187, ite: 7389] train loss: 0.186184, tar: 0.018804 
l0: 0.031537, l1: 0.037405, l2: 0.041710, l3: 0.040332, l4: 0.064409, l5: 0.062889, l6: 0.052953

[epoch:  79/100000, batch:   116/  187, ite: 7390] train loss: 0.186288, tar: 0.018813 
l0: 0.030328, l1: 0.034383, l2: 0.028919, l3: 0.026243, l4: 0.041025, l5: 0.045444, l6: 0.038332

[epoch:  79/100000, batch:   118/  187, ite: 7391] train loss: 0.186330, tar: 0.018822 
l0: 0.037241, l1: 0.037621, l2: 0.035744, l3: 0.036858, l4: 0.056697, l5: 0.056070, l6: 0.058406

[epoch:  79/100000, batch:   120/  187, ite: 7392] train loss: 0.186425, tar: 0.018835 
l0: 0.025193, l1: 0.026582, l2: 0.034318, l3: 0.032646, l4: 0.046159, l5: 0.039070, l6: 0.041858

[epoch:  79/100000, batch:   122/  187, ite: 7393] train loss: 0.186468, tar: 0.018839 
l0: 0.030456, l1: 0.041811, l2: 0.041599, l3: 0.027479, l4: 0.027801, l5: 0.033491, l6: 0.021465

[epoch:  79/100000, batch:   124/  187, ite: 7394] train loss: 0.186495, tar: 0.018848 
l0: 0.024626, l1: 0.024083, l2: 0.032534, l3: 0.031656, l4: 0.035931, l5: 0.033192, l6: 0.032429

[epoch:  79/100000, batch:   126/  187, ite: 7395] train loss: 0.186515, tar: 0.018852 
l0: 0.085990, l1: 0.084240, l2: 0.123472, l3: 0.112358, l4: 0.141492, l5: 0.127179, l6: 0.118418

[epoch:  79/100000, batch:   128/  187, ite: 7396] train loss: 0.186949, tar: 0.018900 
l0: 0.020244, l1: 0.019927, l2: 0.022642, l3: 0.028797, l4: 0.026475, l5: 0.023188, l6: 0.041115

[epoch:  79/100000, batch:   130/  187, ite: 7397] train loss: 0.186946, tar: 0.018901 
l0: 0.027545, l1: 0.026936, l2: 0.036542, l3: 0.040516, l4: 0.061148, l5: 0.049269, l6: 0.055423

[epoch:  79/100000, batch:   132/  187, ite: 7398] train loss: 0.187025, tar: 0.018907 
l0: 0.024660, l1: 0.026100, l2: 0.034660, l3: 0.038909, l4: 0.045134, l5: 0.038409, l6: 0.032780

[epoch:  79/100000, batch:   134/  187, ite: 7399] train loss: 0.187063, tar: 0.018911 
l0: 0.037684, l1: 0.042501, l2: 0.048093, l3: 0.050537, l4: 0.056865, l5: 0.060783, l6: 0.081548

[epoch:  79/100000, batch:   136/  187, ite: 7400] train loss: 0.187200, tar: 0.018925 
l0: 0.024012, l1: 0.026181, l2: 0.029709, l3: 0.030534, l4: 0.041183, l5: 0.041556, l6: 0.041144

[epoch:  79/100000, batch:   138/  187, ite: 7401] train loss: 0.187233, tar: 0.018928 
l0: 0.019631, l1: 0.020583, l2: 0.026292, l3: 0.024744, l4: 0.056827, l5: 0.065053, l6: 0.054733

[epoch:  79/100000, batch:   140/  187, ite: 7402] train loss: 0.187291, tar: 0.018929 
l0: 0.024118, l1: 0.024394, l2: 0.029195, l3: 0.028005, l4: 0.057300, l5: 0.060156, l6: 0.048465

[epoch:  79/100000, batch:   142/  187, ite: 7403] train loss: 0.187351, tar: 0.018932 
l0: 0.046232, l1: 0.045429, l2: 0.064481, l3: 0.067578, l4: 0.080530, l5: 0.075051, l6: 0.073330

[epoch:  79/100000, batch:   144/  187, ite: 7404] train loss: 0.187540, tar: 0.018952 
l0: 0.043972, l1: 0.052851, l2: 0.046322, l3: 0.049482, l4: 0.059971, l5: 0.058804, l6: 0.049049

[epoch:  79/100000, batch:   146/  187, ite: 7405] train loss: 0.187663, tar: 0.018970 
l0: 0.026992, l1: 0.030035, l2: 0.043122, l3: 0.043223, l4: 0.050386, l5: 0.039402, l6: 0.038049

[epoch:  79/100000, batch:   148/  187, ite: 7406] train loss: 0.187722, tar: 0.018975 
l0: 0.057205, l1: 0.062767, l2: 0.051042, l3: 0.052539, l4: 0.069112, l5: 0.067943, l6: 0.064147

[epoch:  79/100000, batch:   150/  187, ite: 7407] train loss: 0.187891, tar: 0.019003 
l0: 0.040827, l1: 0.034786, l2: 0.076574, l3: 0.091514, l4: 0.073909, l5: 0.069505, l6: 0.077532

[epoch:  79/100000, batch:   152/  187, ite: 7408] train loss: 0.188087, tar: 0.019018 
l0: 0.022429, l1: 0.026122, l2: 0.045710, l3: 0.049586, l4: 0.035358, l5: 0.028180, l6: 0.022971

[epoch:  79/100000, batch:   154/  187, ite: 7409] train loss: 0.188117, tar: 0.019021 
l0: 0.025630, l1: 0.028297, l2: 0.020679, l3: 0.021893, l4: 0.039381, l5: 0.041902, l6: 0.034349

[epoch:  79/100000, batch:   156/  187, ite: 7410] train loss: 0.188134, tar: 0.019025 
l0: 0.022358, l1: 0.027755, l2: 0.023930, l3: 0.023051, l4: 0.045995, l5: 0.053734, l6: 0.035159

[epoch:  79/100000, batch:   158/  187, ite: 7411] train loss: 0.188165, tar: 0.019028 
l0: 0.012333, l1: 0.013761, l2: 0.023653, l3: 0.024277, l4: 0.050256, l5: 0.054412, l6: 0.042920

[epoch:  79/100000, batch:   160/  187, ite: 7412] train loss: 0.188189, tar: 0.019023 
l0: 0.018901, l1: 0.020003, l2: 0.014599, l3: 0.015072, l4: 0.029018, l5: 0.029486, l6: 0.036658

[epoch:  79/100000, batch:   162/  187, ite: 7413] train loss: 0.188172, tar: 0.019023 
l0: 0.022973, l1: 0.023098, l2: 0.027192, l3: 0.027749, l4: 0.045808, l5: 0.042140, l6: 0.045067

[epoch:  79/100000, batch:   164/  187, ite: 7414] train loss: 0.188204, tar: 0.019026 
l0: 0.022974, l1: 0.020384, l2: 0.043515, l3: 0.048935, l4: 0.062232, l5: 0.061843, l6: 0.054960

[epoch:  79/100000, batch:   166/  187, ite: 7415] train loss: 0.188294, tar: 0.019028 
l0: 0.032350, l1: 0.029310, l2: 0.035077, l3: 0.039527, l4: 0.062977, l5: 0.069903, l6: 0.069365

[epoch:  79/100000, batch:   168/  187, ite: 7416] train loss: 0.188400, tar: 0.019038 
l0: 0.055569, l1: 0.059160, l2: 0.038664, l3: 0.049396, l4: 0.071809, l5: 0.088214, l6: 0.076831

[epoch:  79/100000, batch:   170/  187, ite: 7417] train loss: 0.188577, tar: 0.019064 
l0: 0.039952, l1: 0.037507, l2: 0.045087, l3: 0.050212, l4: 0.059093, l5: 0.072089, l6: 0.068064

[epoch:  79/100000, batch:   172/  187, ite: 7418] train loss: 0.188707, tar: 0.019078 
l0: 0.033448, l1: 0.028954, l2: 0.045853, l3: 0.047124, l4: 0.062516, l5: 0.067334, l6: 0.072649

[epoch:  79/100000, batch:   174/  187, ite: 7419] train loss: 0.188826, tar: 0.019088 
l0: 0.016333, l1: 0.016228, l2: 0.016405, l3: 0.017631, l4: 0.027634, l5: 0.024607, l6: 0.023361

[epoch:  79/100000, batch:   176/  187, ite: 7420] train loss: 0.188793, tar: 0.019086 
l0: 0.024655, l1: 0.023425, l2: 0.036524, l3: 0.039307, l4: 0.057616, l5: 0.057875, l6: 0.058468

[epoch:  79/100000, batch:   178/  187, ite: 7421] train loss: 0.188870, tar: 0.019090 
l0: 0.026231, l1: 0.024414, l2: 0.024496, l3: 0.026081, l4: 0.037123, l5: 0.042192, l6: 0.046008

[epoch:  79/100000, batch:   180/  187, ite: 7422] train loss: 0.188896, tar: 0.019095 
l0: 0.025715, l1: 0.022338, l2: 0.035010, l3: 0.040451, l4: 0.047002, l5: 0.058993, l6: 0.078605

[epoch:  79/100000, batch:   182/  187, ite: 7423] train loss: 0.188980, tar: 0.019100 
l0: 0.042767, l1: 0.043509, l2: 0.042040, l3: 0.050492, l4: 0.073323, l5: 0.079703, l6: 0.076829

[epoch:  79/100000, batch:   184/  187, ite: 7424] train loss: 0.189134, tar: 0.019117 
l0: 0.016736, l1: 0.018182, l2: 0.016503, l3: 0.019104, l4: 0.033751, l5: 0.031806, l6: 0.030867

[epoch:  79/100000, batch:   186/  187, ite: 7425] train loss: 0.189119, tar: 0.019115 
l0: 0.018629, l1: 0.021077, l2: 0.025275, l3: 0.024778, l4: 0.048674, l5: 0.041809, l6: 0.038990

[epoch:  79/100000, batch:   188/  187, ite: 7426] train loss: 0.189140, tar: 0.019115 
l0: 0.010807, l1: 0.011838, l2: 0.011779, l3: 0.014557, l4: 0.036876, l5: 0.038447, l6: 0.041159

[epoch:  80/100000, batch:     2/  187, ite: 7427] train loss: 0.189123, tar: 0.019109 
l0: 0.013152, l1: 0.013152, l2: 0.021097, l3: 0.020988, l4: 0.032633, l5: 0.029061, l6: 0.032675

[epoch:  80/100000, batch:     4/  187, ite: 7428] train loss: 0.189105, tar: 0.019105 
l0: 0.016013, l1: 0.017392, l2: 0.015550, l3: 0.015884, l4: 0.033019, l5: 0.031251, l6: 0.027882

[epoch:  80/100000, batch:     6/  187, ite: 7429] train loss: 0.189082, tar: 0.019102 
l0: 0.037341, l1: 0.037581, l2: 0.031490, l3: 0.034054, l4: 0.068246, l5: 0.062683, l6: 0.071282

[epoch:  80/100000, batch:     8/  187, ite: 7430] train loss: 0.189190, tar: 0.019115 
l0: 0.041843, l1: 0.041962, l2: 0.037453, l3: 0.036591, l4: 0.062130, l5: 0.071048, l6: 0.077320

[epoch:  80/100000, batch:    10/  187, ite: 7431] train loss: 0.189315, tar: 0.019131 
l0: 0.016853, l1: 0.016684, l2: 0.017977, l3: 0.019240, l4: 0.043353, l5: 0.039298, l6: 0.037002

[epoch:  80/100000, batch:    12/  187, ite: 7432] train loss: 0.189316, tar: 0.019130 
l0: 0.024882, l1: 0.023932, l2: 0.030148, l3: 0.034226, l4: 0.046763, l5: 0.047645, l6: 0.058591

[epoch:  80/100000, batch:    14/  187, ite: 7433] train loss: 0.189369, tar: 0.019134 
l0: 0.018023, l1: 0.017692, l2: 0.020296, l3: 0.024184, l4: 0.046833, l5: 0.048258, l6: 0.033413

[epoch:  80/100000, batch:    16/  187, ite: 7434] train loss: 0.189383, tar: 0.019133 
l0: 0.025910, l1: 0.022828, l2: 0.029062, l3: 0.035695, l4: 0.059780, l5: 0.064749, l6: 0.066552

[epoch:  80/100000, batch:    18/  187, ite: 7435] train loss: 0.189463, tar: 0.019138 
l0: 0.017516, l1: 0.018686, l2: 0.016762, l3: 0.020929, l4: 0.036680, l5: 0.030672, l6: 0.030220

[epoch:  80/100000, batch:    20/  187, ite: 7436] train loss: 0.189450, tar: 0.019136 
l0: 0.007774, l1: 0.008343, l2: 0.009674, l3: 0.010406, l4: 0.020971, l5: 0.017339, l6: 0.016364

[epoch:  80/100000, batch:    22/  187, ite: 7437] train loss: 0.189382, tar: 0.019128 
l0: 0.021057, l1: 0.019326, l2: 0.021903, l3: 0.023820, l4: 0.057517, l5: 0.055215, l6: 0.064955

[epoch:  80/100000, batch:    24/  187, ite: 7438] train loss: 0.189434, tar: 0.019130 
l0: 0.036435, l1: 0.036709, l2: 0.036352, l3: 0.032178, l4: 0.063332, l5: 0.073720, l6: 0.068116

[epoch:  80/100000, batch:    26/  187, ite: 7439] train loss: 0.189543, tar: 0.019142 
l0: 0.020983, l1: 0.024898, l2: 0.019294, l3: 0.021294, l4: 0.046197, l5: 0.040383, l6: 0.039063

[epoch:  80/100000, batch:    28/  187, ite: 7440] train loss: 0.189559, tar: 0.019143 
l0: 0.024926, l1: 0.030430, l2: 0.021091, l3: 0.019244, l4: 0.024038, l5: 0.018316, l6: 0.025123

[epoch:  80/100000, batch:    30/  187, ite: 7441] train loss: 0.189540, tar: 0.019147 
l0: 0.027819, l1: 0.029180, l2: 0.029449, l3: 0.027018, l4: 0.034516, l5: 0.050175, l6: 0.042063

[epoch:  80/100000, batch:    32/  187, ite: 7442] train loss: 0.189576, tar: 0.019153 
l0: 0.013867, l1: 0.015310, l2: 0.013803, l3: 0.013962, l4: 0.031111, l5: 0.041857, l6: 0.043512

[epoch:  80/100000, batch:    34/  187, ite: 7443] train loss: 0.189564, tar: 0.019149 
l0: 0.017823, l1: 0.019513, l2: 0.020685, l3: 0.019427, l4: 0.044538, l5: 0.037176, l6: 0.034031

[epoch:  80/100000, batch:    36/  187, ite: 7444] train loss: 0.189567, tar: 0.019149 
l0: 0.011973, l1: 0.013477, l2: 0.012813, l3: 0.011390, l4: 0.016143, l5: 0.016887, l6: 0.017533

[epoch:  80/100000, batch:    38/  187, ite: 7445] train loss: 0.189505, tar: 0.019144 
l0: 0.014052, l1: 0.013852, l2: 0.013251, l3: 0.015245, l4: 0.038092, l5: 0.034932, l6: 0.046200

[epoch:  80/100000, batch:    40/  187, ite: 7446] train loss: 0.189495, tar: 0.019140 
l0: 0.010264, l1: 0.010522, l2: 0.012282, l3: 0.015924, l4: 0.028501, l5: 0.026259, l6: 0.023534

[epoch:  80/100000, batch:    42/  187, ite: 7447] train loss: 0.189452, tar: 0.019134 
l0: 0.068334, l1: 0.073623, l2: 0.089210, l3: 0.086103, l4: 0.060499, l5: 0.053012, l6: 0.052417

[epoch:  80/100000, batch:    44/  187, ite: 7448] train loss: 0.189655, tar: 0.019168 
l0: 0.025922, l1: 0.026346, l2: 0.033385, l3: 0.034036, l4: 0.038383, l5: 0.037007, l6: 0.034233

[epoch:  80/100000, batch:    46/  187, ite: 7449] train loss: 0.189683, tar: 0.019173 
l0: 0.012378, l1: 0.014903, l2: 0.017224, l3: 0.011349, l4: 0.015958, l5: 0.017684, l6: 0.012885

[epoch:  80/100000, batch:    48/  187, ite: 7450] train loss: 0.189622, tar: 0.019168 
l0: 0.010182, l1: 0.012160, l2: 0.013488, l3: 0.012329, l4: 0.025260, l5: 0.028786, l6: 0.019447

[epoch:  80/100000, batch:    50/  187, ite: 7451] train loss: 0.189576, tar: 0.019162 
l0: 0.019522, l1: 0.019118, l2: 0.021299, l3: 0.021722, l4: 0.037864, l5: 0.040860, l6: 0.040222

[epoch:  80/100000, batch:    52/  187, ite: 7452] train loss: 0.189583, tar: 0.019162 
l0: 0.012194, l1: 0.012463, l2: 0.013452, l3: 0.014782, l4: 0.027245, l5: 0.028448, l6: 0.023101

[epoch:  80/100000, batch:    54/  187, ite: 7453] train loss: 0.189543, tar: 0.019157 
l0: 0.020271, l1: 0.018846, l2: 0.017418, l3: 0.019081, l4: 0.029400, l5: 0.031746, l6: 0.035142

[epoch:  80/100000, batch:    56/  187, ite: 7454] train loss: 0.189531, tar: 0.019158 
l0: 0.037726, l1: 0.040778, l2: 0.035026, l3: 0.038872, l4: 0.045983, l5: 0.038367, l6: 0.050950

[epoch:  80/100000, batch:    58/  187, ite: 7455] train loss: 0.189599, tar: 0.019171 
l0: 0.013319, l1: 0.013736, l2: 0.019456, l3: 0.018345, l4: 0.017845, l5: 0.020086, l6: 0.024207

[epoch:  80/100000, batch:    60/  187, ite: 7456] train loss: 0.189556, tar: 0.019167 
l0: 0.019384, l1: 0.021443, l2: 0.022300, l3: 0.020360, l4: 0.037660, l5: 0.041980, l6: 0.046816

[epoch:  80/100000, batch:    62/  187, ite: 7457] train loss: 0.189570, tar: 0.019167 
l0: 0.017213, l1: 0.017258, l2: 0.021182, l3: 0.018948, l4: 0.037872, l5: 0.035073, l6: 0.031046

[epoch:  80/100000, batch:    64/  187, ite: 7458] train loss: 0.189562, tar: 0.019165 
l0: 0.012418, l1: 0.013148, l2: 0.016009, l3: 0.014641, l4: 0.022720, l5: 0.022139, l6: 0.019162

[epoch:  80/100000, batch:    66/  187, ite: 7459] train loss: 0.189515, tar: 0.019161 
l0: 0.008715, l1: 0.008519, l2: 0.009704, l3: 0.010793, l4: 0.019798, l5: 0.013532, l6: 0.013159

[epoch:  80/100000, batch:    68/  187, ite: 7460] train loss: 0.189443, tar: 0.019154 
l0: 0.030388, l1: 0.033011, l2: 0.045465, l3: 0.034555, l4: 0.033609, l5: 0.031661, l6: 0.035884

[epoch:  80/100000, batch:    70/  187, ite: 7461] train loss: 0.189480, tar: 0.019161 
l0: 0.013928, l1: 0.014277, l2: 0.016010, l3: 0.015561, l4: 0.024692, l5: 0.031473, l6: 0.033198

[epoch:  80/100000, batch:    72/  187, ite: 7462] train loss: 0.189453, tar: 0.019158 
l0: 0.011215, l1: 0.011648, l2: 0.012560, l3: 0.012838, l4: 0.015334, l5: 0.014120, l6: 0.014926

[epoch:  80/100000, batch:    74/  187, ite: 7463] train loss: 0.189386, tar: 0.019152 
l0: 0.015200, l1: 0.014170, l2: 0.020828, l3: 0.023157, l4: 0.044257, l5: 0.039186, l6: 0.033466

[epoch:  80/100000, batch:    76/  187, ite: 7464] train loss: 0.189387, tar: 0.019150 
l0: 0.014028, l1: 0.014261, l2: 0.014872, l3: 0.016067, l4: 0.022319, l5: 0.022572, l6: 0.025262

[epoch:  80/100000, batch:    78/  187, ite: 7465] train loss: 0.189346, tar: 0.019146 
l0: 0.015762, l1: 0.015768, l2: 0.020056, l3: 0.018228, l4: 0.019649, l5: 0.020830, l6: 0.021641

[epoch:  80/100000, batch:    80/  187, ite: 7466] train loss: 0.189307, tar: 0.019144 
l0: 0.017456, l1: 0.017351, l2: 0.020769, l3: 0.020757, l4: 0.034511, l5: 0.037812, l6: 0.032833

[epoch:  80/100000, batch:    82/  187, ite: 7467] train loss: 0.189302, tar: 0.019143 
l0: 0.020985, l1: 0.020408, l2: 0.020524, l3: 0.021222, l4: 0.029517, l5: 0.031229, l6: 0.039200

[epoch:  80/100000, batch:    84/  187, ite: 7468] train loss: 0.189297, tar: 0.019144 
l0: 0.040993, l1: 0.039356, l2: 0.037913, l3: 0.037475, l4: 0.060768, l5: 0.064099, l6: 0.072799

[epoch:  80/100000, batch:    86/  187, ite: 7469] train loss: 0.189409, tar: 0.019159 
l0: 0.024211, l1: 0.024723, l2: 0.026017, l3: 0.029409, l4: 0.047892, l5: 0.041161, l6: 0.035039

[epoch:  80/100000, batch:    88/  187, ite: 7470] train loss: 0.189436, tar: 0.019162 
l0: 0.019818, l1: 0.024170, l2: 0.019629, l3: 0.019493, l4: 0.028437, l5: 0.026530, l6: 0.020652

[epoch:  80/100000, batch:    90/  187, ite: 7471] train loss: 0.189415, tar: 0.019163 
l0: 0.022269, l1: 0.024434, l2: 0.024890, l3: 0.024116, l4: 0.046841, l5: 0.038387, l6: 0.032036

[epoch:  80/100000, batch:    92/  187, ite: 7472] train loss: 0.189431, tar: 0.019165 
l0: 0.016755, l1: 0.014078, l2: 0.017504, l3: 0.019808, l4: 0.040044, l5: 0.050950, l6: 0.057680

[epoch:  80/100000, batch:    94/  187, ite: 7473] train loss: 0.189449, tar: 0.019163 
l0: 0.013478, l1: 0.013710, l2: 0.017897, l3: 0.021509, l4: 0.033248, l5: 0.031987, l6: 0.026773

[epoch:  80/100000, batch:    96/  187, ite: 7474] train loss: 0.189428, tar: 0.019159 
l0: 0.015987, l1: 0.016785, l2: 0.018257, l3: 0.018679, l4: 0.026226, l5: 0.025492, l6: 0.025748

[epoch:  80/100000, batch:    98/  187, ite: 7475] train loss: 0.189400, tar: 0.019157 
l0: 0.024864, l1: 0.024721, l2: 0.028889, l3: 0.031972, l4: 0.050188, l5: 0.040748, l6: 0.035160

[epoch:  80/100000, batch:   100/  187, ite: 7476] train loss: 0.189432, tar: 0.019161 
l0: 0.015527, l1: 0.015882, l2: 0.020337, l3: 0.018413, l4: 0.060551, l5: 0.044027, l6: 0.033474

[epoch:  80/100000, batch:   102/  187, ite: 7477] train loss: 0.189444, tar: 0.019159 
l0: 0.012565, l1: 0.014525, l2: 0.012360, l3: 0.011637, l4: 0.015438, l5: 0.015800, l6: 0.015283

[epoch:  80/100000, batch:   104/  187, ite: 7478] train loss: 0.189382, tar: 0.019154 
l0: 0.009684, l1: 0.010031, l2: 0.012647, l3: 0.014585, l4: 0.019789, l5: 0.018895, l6: 0.017326

[epoch:  80/100000, batch:   106/  187, ite: 7479] train loss: 0.189324, tar: 0.019148 
l0: 0.018511, l1: 0.018344, l2: 0.021387, l3: 0.021314, l4: 0.038695, l5: 0.038113, l6: 0.040548

[epoch:  80/100000, batch:   108/  187, ite: 7480] train loss: 0.189329, tar: 0.019147 
l0: 0.013341, l1: 0.012595, l2: 0.017665, l3: 0.017010, l4: 0.040118, l5: 0.030937, l6: 0.030682

[epoch:  80/100000, batch:   110/  187, ite: 7481] train loss: 0.189311, tar: 0.019143 
l0: 0.035914, l1: 0.034817, l2: 0.046675, l3: 0.043615, l4: 0.067149, l5: 0.070849, l6: 0.061186

[epoch:  80/100000, batch:   112/  187, ite: 7482] train loss: 0.189426, tar: 0.019155 
l0: 0.032991, l1: 0.035366, l2: 0.037889, l3: 0.044372, l4: 0.046145, l5: 0.047806, l6: 0.051690

[epoch:  80/100000, batch:   114/  187, ite: 7483] train loss: 0.189498, tar: 0.019164 
l0: 0.017829, l1: 0.019295, l2: 0.020777, l3: 0.024794, l4: 0.035003, l5: 0.037390, l6: 0.037806

[epoch:  80/100000, batch:   116/  187, ite: 7484] train loss: 0.189500, tar: 0.019163 
l0: 0.008926, l1: 0.010133, l2: 0.022150, l3: 0.017463, l4: 0.025926, l5: 0.025277, l6: 0.024286

[epoch:  80/100000, batch:   118/  187, ite: 7485] train loss: 0.189463, tar: 0.019156 
l0: 0.018998, l1: 0.018579, l2: 0.022073, l3: 0.022790, l4: 0.034200, l5: 0.033871, l6: 0.035505

[epoch:  80/100000, batch:   120/  187, ite: 7486] train loss: 0.189461, tar: 0.019156 
l0: 0.012046, l1: 0.011370, l2: 0.015704, l3: 0.015314, l4: 0.022434, l5: 0.020534, l6: 0.024543

[epoch:  80/100000, batch:   122/  187, ite: 7487] train loss: 0.189415, tar: 0.019151 
l0: 0.015680, l1: 0.015146, l2: 0.016437, l3: 0.018605, l4: 0.029280, l5: 0.028014, l6: 0.030509

[epoch:  80/100000, batch:   124/  187, ite: 7488] train loss: 0.189391, tar: 0.019149 
l0: 0.021705, l1: 0.022348, l2: 0.018774, l3: 0.020079, l4: 0.035098, l5: 0.029934, l6: 0.029423

[epoch:  80/100000, batch:   126/  187, ite: 7489] train loss: 0.189383, tar: 0.019151 
l0: 0.014706, l1: 0.015391, l2: 0.017937, l3: 0.016710, l4: 0.031744, l5: 0.025050, l6: 0.027956

[epoch:  80/100000, batch:   128/  187, ite: 7490] train loss: 0.189357, tar: 0.019148 
l0: 0.021739, l1: 0.022572, l2: 0.023554, l3: 0.022703, l4: 0.028296, l5: 0.027107, l6: 0.032914

[epoch:  80/100000, batch:   130/  187, ite: 7491] train loss: 0.189350, tar: 0.019149 
l0: 0.014612, l1: 0.014344, l2: 0.016049, l3: 0.016569, l4: 0.035135, l5: 0.031229, l6: 0.033126

[epoch:  80/100000, batch:   132/  187, ite: 7492] train loss: 0.189331, tar: 0.019146 
l0: 0.031275, l1: 0.031159, l2: 0.034669, l3: 0.036378, l4: 0.036245, l5: 0.041620, l6: 0.048173

[epoch:  80/100000, batch:   134/  187, ite: 7493] train loss: 0.189378, tar: 0.019155 
l0: 0.014528, l1: 0.014303, l2: 0.016143, l3: 0.018827, l4: 0.034005, l5: 0.035513, l6: 0.035013

[epoch:  80/100000, batch:   136/  187, ite: 7494] train loss: 0.189364, tar: 0.019151 
l0: 0.028263, l1: 0.028570, l2: 0.033416, l3: 0.029051, l4: 0.026960, l5: 0.028967, l6: 0.027518

[epoch:  80/100000, batch:   138/  187, ite: 7495] train loss: 0.189372, tar: 0.019158 
l0: 0.012399, l1: 0.012675, l2: 0.016276, l3: 0.020517, l4: 0.026401, l5: 0.029497, l6: 0.024325

[epoch:  80/100000, batch:   140/  187, ite: 7496] train loss: 0.189341, tar: 0.019153 
l0: 0.030351, l1: 0.032609, l2: 0.029483, l3: 0.025917, l4: 0.059934, l5: 0.066958, l6: 0.072811

[epoch:  80/100000, batch:   142/  187, ite: 7497] train loss: 0.189427, tar: 0.019161 
l0: 0.011384, l1: 0.011535, l2: 0.013711, l3: 0.013624, l4: 0.022571, l5: 0.022776, l6: 0.017602

[epoch:  80/100000, batch:   144/  187, ite: 7498] train loss: 0.189376, tar: 0.019155 
l0: 0.017031, l1: 0.015569, l2: 0.021135, l3: 0.022397, l4: 0.032799, l5: 0.034113, l6: 0.032898

[epoch:  80/100000, batch:   146/  187, ite: 7499] train loss: 0.189367, tar: 0.019154 
l0: 0.027642, l1: 0.030476, l2: 0.030557, l3: 0.026475, l4: 0.039597, l5: 0.036702, l6: 0.036316

[epoch:  80/100000, batch:   148/  187, ite: 7500] train loss: 0.189393, tar: 0.019160 
l0: 0.019290, l1: 0.020313, l2: 0.025275, l3: 0.023381, l4: 0.030529, l5: 0.027132, l6: 0.032786

[epoch:  80/100000, batch:   150/  187, ite: 7501] train loss: 0.189385, tar: 0.019160 
l0: 0.013566, l1: 0.015206, l2: 0.012665, l3: 0.011231, l4: 0.014831, l5: 0.016356, l6: 0.018688

[epoch:  80/100000, batch:   152/  187, ite: 7502] train loss: 0.189328, tar: 0.019156 
l0: 0.030067, l1: 0.031551, l2: 0.034070, l3: 0.032338, l4: 0.021527, l5: 0.022169, l6: 0.027616

[epoch:  80/100000, batch:   154/  187, ite: 7503] train loss: 0.189334, tar: 0.019163 
l0: 0.013677, l1: 0.014794, l2: 0.018172, l3: 0.017856, l4: 0.034311, l5: 0.028349, l6: 0.034114

[epoch:  80/100000, batch:   156/  187, ite: 7504] train loss: 0.189316, tar: 0.019160 
l0: 0.022329, l1: 0.021660, l2: 0.033394, l3: 0.033695, l4: 0.029909, l5: 0.022982, l6: 0.031512

[epoch:  80/100000, batch:   158/  187, ite: 7505] train loss: 0.189320, tar: 0.019162 
l0: 0.018227, l1: 0.018074, l2: 0.021724, l3: 0.024525, l4: 0.024732, l5: 0.023540, l6: 0.030571

[epoch:  80/100000, batch:   160/  187, ite: 7506] train loss: 0.189301, tar: 0.019161 
l0: 0.011032, l1: 0.010958, l2: 0.013445, l3: 0.012282, l4: 0.027369, l5: 0.023910, l6: 0.027818

[epoch:  80/100000, batch:   162/  187, ite: 7507] train loss: 0.189260, tar: 0.019156 
l0: 0.020387, l1: 0.021156, l2: 0.020956, l3: 0.023105, l4: 0.034043, l5: 0.029247, l6: 0.036989

[epoch:  80/100000, batch:   164/  187, ite: 7508] train loss: 0.189258, tar: 0.019156 
l0: 0.018841, l1: 0.020336, l2: 0.023112, l3: 0.020835, l4: 0.028009, l5: 0.027526, l6: 0.033163

[epoch:  80/100000, batch:   166/  187, ite: 7509] train loss: 0.189246, tar: 0.019156 
l0: 0.022119, l1: 0.027049, l2: 0.020422, l3: 0.018039, l4: 0.021500, l5: 0.020440, l6: 0.021675

[epoch:  80/100000, batch:   168/  187, ite: 7510] train loss: 0.189221, tar: 0.019158 
l0: 0.013943, l1: 0.015314, l2: 0.016115, l3: 0.014853, l4: 0.022018, l5: 0.026116, l6: 0.026503

[epoch:  80/100000, batch:   170/  187, ite: 7511] train loss: 0.189185, tar: 0.019155 
l0: 0.018143, l1: 0.017826, l2: 0.021626, l3: 0.023568, l4: 0.026381, l5: 0.025257, l6: 0.027941

[epoch:  80/100000, batch:   172/  187, ite: 7512] train loss: 0.189166, tar: 0.019154 
l0: 0.018076, l1: 0.018379, l2: 0.021100, l3: 0.019250, l4: 0.030396, l5: 0.029481, l6: 0.030187

[epoch:  80/100000, batch:   174/  187, ite: 7513] train loss: 0.189151, tar: 0.019153 
l0: 0.014416, l1: 0.014045, l2: 0.022908, l3: 0.023716, l4: 0.026716, l5: 0.024089, l6: 0.025674

[epoch:  80/100000, batch:   176/  187, ite: 7514] train loss: 0.189126, tar: 0.019150 
l0: 0.008446, l1: 0.008816, l2: 0.008785, l3: 0.010657, l4: 0.020273, l5: 0.020028, l6: 0.022391

[epoch:  80/100000, batch:   178/  187, ite: 7515] train loss: 0.189067, tar: 0.019143 
l0: 0.020454, l1: 0.020643, l2: 0.028015, l3: 0.028594, l4: 0.023372, l5: 0.022954, l6: 0.024482

[epoch:  80/100000, batch:   180/  187, ite: 7516] train loss: 0.189054, tar: 0.019144 
l0: 0.023375, l1: 0.022593, l2: 0.035229, l3: 0.039379, l4: 0.040896, l5: 0.034466, l6: 0.034165

[epoch:  80/100000, batch:   182/  187, ite: 7517] train loss: 0.189081, tar: 0.019147 
l0: 0.017450, l1: 0.014708, l2: 0.018515, l3: 0.024762, l4: 0.049815, l5: 0.044622, l6: 0.070715

[epoch:  80/100000, batch:   184/  187, ite: 7518] train loss: 0.189115, tar: 0.019146 
l0: 0.027461, l1: 0.021428, l2: 0.030793, l3: 0.045182, l4: 0.094142, l5: 0.076871, l6: 0.100183

[epoch:  80/100000, batch:   186/  187, ite: 7519] train loss: 0.189251, tar: 0.019151 
l0: 0.016701, l1: 0.015940, l2: 0.020719, l3: 0.018522, l4: 0.034539, l5: 0.043405, l6: 0.050776

[epoch:  80/100000, batch:   188/  187, ite: 7520] train loss: 0.189258, tar: 0.019150 
l0: 0.010807, l1: 0.011373, l2: 0.015455, l3: 0.013799, l4: 0.019925, l5: 0.018089, l6: 0.020299

[epoch:  81/100000, batch:     2/  187, ite: 7521] train loss: 0.189206, tar: 0.019144 
l0: 0.017364, l1: 0.014159, l2: 0.025719, l3: 0.027175, l4: 0.048728, l5: 0.050247, l6: 0.069730

[epoch:  81/100000, batch:     4/  187, ite: 7522] train loss: 0.189248, tar: 0.019143 
l0: 0.011942, l1: 0.011718, l2: 0.017077, l3: 0.019906, l4: 0.035058, l5: 0.040033, l6: 0.041798

[epoch:  81/100000, batch:     6/  187, ite: 7523] train loss: 0.189240, tar: 0.019138 
l0: 0.013342, l1: 0.014096, l2: 0.019217, l3: 0.019306, l4: 0.025220, l5: 0.028014, l6: 0.024717

[epoch:  81/100000, batch:     8/  187, ite: 7524] train loss: 0.189211, tar: 0.019134 
l0: 0.022644, l1: 0.023892, l2: 0.023534, l3: 0.022538, l4: 0.031478, l5: 0.028602, l6: 0.033670

[epoch:  81/100000, batch:    10/  187, ite: 7525] train loss: 0.189209, tar: 0.019137 
l0: 0.019736, l1: 0.023453, l2: 0.018050, l3: 0.016024, l4: 0.030612, l5: 0.032318, l6: 0.031485

[epoch:  81/100000, batch:    12/  187, ite: 7526] train loss: 0.189197, tar: 0.019137 
l0: 0.020020, l1: 0.019115, l2: 0.023616, l3: 0.024653, l4: 0.040756, l5: 0.043427, l6: 0.055924

[epoch:  81/100000, batch:    14/  187, ite: 7527] train loss: 0.189222, tar: 0.019138 
l0: 0.020068, l1: 0.019634, l2: 0.022398, l3: 0.022391, l4: 0.026040, l5: 0.031373, l6: 0.032859

[epoch:  81/100000, batch:    16/  187, ite: 7528] train loss: 0.189213, tar: 0.019138 
l0: 0.018878, l1: 0.018871, l2: 0.024966, l3: 0.025970, l4: 0.031272, l5: 0.031981, l6: 0.029499

[epoch:  81/100000, batch:    18/  187, ite: 7529] train loss: 0.189208, tar: 0.019138 
l0: 0.029966, l1: 0.026683, l2: 0.030741, l3: 0.032675, l4: 0.048464, l5: 0.059906, l6: 0.064419

[epoch:  81/100000, batch:    20/  187, ite: 7530] train loss: 0.189276, tar: 0.019145 
l0: 0.009986, l1: 0.009534, l2: 0.011120, l3: 0.013271, l4: 0.028094, l5: 0.029291, l6: 0.034255

[epoch:  81/100000, batch:    22/  187, ite: 7531] train loss: 0.189240, tar: 0.019139 
l0: 0.018319, l1: 0.019272, l2: 0.021495, l3: 0.021306, l4: 0.022834, l5: 0.025945, l6: 0.026252

[epoch:  81/100000, batch:    24/  187, ite: 7532] train loss: 0.189218, tar: 0.019139 
l0: 0.011875, l1: 0.012459, l2: 0.011941, l3: 0.013057, l4: 0.022459, l5: 0.020863, l6: 0.025267

[epoch:  81/100000, batch:    26/  187, ite: 7533] train loss: 0.189172, tar: 0.019134 
l0: 0.015828, l1: 0.015561, l2: 0.017639, l3: 0.027907, l4: 0.047530, l5: 0.039339, l6: 0.034092

[epoch:  81/100000, batch:    28/  187, ite: 7534] train loss: 0.189178, tar: 0.019132 
l0: 0.014808, l1: 0.014942, l2: 0.020489, l3: 0.021316, l4: 0.037810, l5: 0.033267, l6: 0.029839

[epoch:  81/100000, batch:    30/  187, ite: 7535] train loss: 0.189167, tar: 0.019129 
l0: 0.010421, l1: 0.010418, l2: 0.014133, l3: 0.012187, l4: 0.015123, l5: 0.016145, l6: 0.015782

[epoch:  81/100000, batch:    32/  187, ite: 7536] train loss: 0.189105, tar: 0.019123 
l0: 0.012645, l1: 0.011599, l2: 0.012751, l3: 0.016137, l4: 0.027136, l5: 0.026202, l6: 0.034231

[epoch:  81/100000, batch:    34/  187, ite: 7537] train loss: 0.189073, tar: 0.019119 
l0: 0.031216, l1: 0.033094, l2: 0.034667, l3: 0.032066, l4: 0.030135, l5: 0.034201, l6: 0.031630

[epoch:  81/100000, batch:    36/  187, ite: 7538] train loss: 0.189098, tar: 0.019127 
l0: 0.013543, l1: 0.014090, l2: 0.015408, l3: 0.018222, l4: 0.034480, l5: 0.029540, l6: 0.027531

[epoch:  81/100000, batch:    38/  187, ite: 7539] train loss: 0.189074, tar: 0.019123 
l0: 0.008204, l1: 0.007761, l2: 0.015309, l3: 0.017015, l4: 0.032439, l5: 0.028015, l6: 0.033078

[epoch:  81/100000, batch:    40/  187, ite: 7540] train loss: 0.189044, tar: 0.019116 
l0: 0.013743, l1: 0.013269, l2: 0.017198, l3: 0.017747, l4: 0.027923, l5: 0.029444, l6: 0.027931

[epoch:  81/100000, batch:    42/  187, ite: 7541] train loss: 0.189017, tar: 0.019113 
l0: 0.017726, l1: 0.018813, l2: 0.023036, l3: 0.023558, l4: 0.041682, l5: 0.038037, l6: 0.038943

[epoch:  81/100000, batch:    44/  187, ite: 7542] train loss: 0.189025, tar: 0.019112 
l0: 0.016629, l1: 0.016038, l2: 0.017145, l3: 0.020289, l4: 0.045131, l5: 0.043889, l6: 0.042615

[epoch:  81/100000, batch:    46/  187, ite: 7543] train loss: 0.189033, tar: 0.019110 
l0: 0.022606, l1: 0.026070, l2: 0.018467, l3: 0.020682, l4: 0.034393, l5: 0.028865, l6: 0.028219

[epoch:  81/100000, batch:    48/  187, ite: 7544] train loss: 0.189027, tar: 0.019112 
l0: 0.017812, l1: 0.020059, l2: 0.018460, l3: 0.022840, l4: 0.050738, l5: 0.049451, l6: 0.053768

[epoch:  81/100000, batch:    50/  187, ite: 7545] train loss: 0.189055, tar: 0.019112 
l0: 0.014121, l1: 0.014806, l2: 0.016236, l3: 0.017701, l4: 0.032021, l5: 0.029651, l6: 0.025905

[epoch:  81/100000, batch:    52/  187, ite: 7546] train loss: 0.189030, tar: 0.019108 
l0: 0.014850, l1: 0.015358, l2: 0.015506, l3: 0.017051, l4: 0.024030, l5: 0.028394, l6: 0.027067

[epoch:  81/100000, batch:    54/  187, ite: 7547] train loss: 0.189000, tar: 0.019106 
l0: 0.012159, l1: 0.012255, l2: 0.012385, l3: 0.014809, l4: 0.019694, l5: 0.019922, l6: 0.022038

[epoch:  81/100000, batch:    56/  187, ite: 7548] train loss: 0.188951, tar: 0.019101 
l0: 0.018994, l1: 0.023548, l2: 0.017673, l3: 0.015244, l4: 0.038555, l5: 0.030475, l6: 0.033252

[epoch:  81/100000, batch:    58/  187, ite: 7549] train loss: 0.188944, tar: 0.019101 
l0: 0.013051, l1: 0.013981, l2: 0.016674, l3: 0.015911, l4: 0.023220, l5: 0.023700, l6: 0.021044

[epoch:  81/100000, batch:    60/  187, ite: 7550] train loss: 0.188904, tar: 0.019097 
l0: 0.010439, l1: 0.010232, l2: 0.010059, l3: 0.011250, l4: 0.024366, l5: 0.022558, l6: 0.018671

[epoch:  81/100000, batch:    62/  187, ite: 7551] train loss: 0.188852, tar: 0.019092 
l0: 0.007644, l1: 0.007919, l2: 0.007301, l3: 0.006826, l4: 0.017545, l5: 0.019878, l6: 0.020762

[epoch:  81/100000, batch:    64/  187, ite: 7552] train loss: 0.188787, tar: 0.019084 
l0: 0.018574, l1: 0.016518, l2: 0.023335, l3: 0.022067, l4: 0.035721, l5: 0.042609, l6: 0.038929

[epoch:  81/100000, batch:    66/  187, ite: 7553] train loss: 0.188793, tar: 0.019084 
l0: 0.008163, l1: 0.009451, l2: 0.009883, l3: 0.008848, l4: 0.011082, l5: 0.009967, l6: 0.012323

[epoch:  81/100000, batch:    68/  187, ite: 7554] train loss: 0.188716, tar: 0.019077 
l0: 0.017118, l1: 0.017509, l2: 0.018269, l3: 0.024003, l4: 0.025252, l5: 0.029193, l6: 0.034053

[epoch:  81/100000, batch:    70/  187, ite: 7555] train loss: 0.188701, tar: 0.019076 
l0: 0.040552, l1: 0.038836, l2: 0.046220, l3: 0.052652, l4: 0.078063, l5: 0.078429, l6: 0.072450

[epoch:  81/100000, batch:    72/  187, ite: 7556] train loss: 0.188842, tar: 0.019089 
l0: 0.012966, l1: 0.012786, l2: 0.015877, l3: 0.016788, l4: 0.028151, l5: 0.026645, l6: 0.027656

[epoch:  81/100000, batch:    74/  187, ite: 7557] train loss: 0.188811, tar: 0.019086 
l0: 0.014644, l1: 0.016100, l2: 0.020113, l3: 0.020398, l4: 0.028523, l5: 0.027135, l6: 0.023758

[epoch:  81/100000, batch:    76/  187, ite: 7558] train loss: 0.188786, tar: 0.019083 
l0: 0.022292, l1: 0.021551, l2: 0.022730, l3: 0.026128, l4: 0.034990, l5: 0.038381, l6: 0.036707

[epoch:  81/100000, batch:    78/  187, ite: 7559] train loss: 0.188795, tar: 0.019085 
l0: 0.027229, l1: 0.030676, l2: 0.029905, l3: 0.030251, l4: 0.041180, l5: 0.040845, l6: 0.044725

[epoch:  81/100000, batch:    80/  187, ite: 7560] train loss: 0.188831, tar: 0.019090 
l0: 0.031064, l1: 0.034602, l2: 0.034182, l3: 0.030189, l4: 0.037339, l5: 0.035082, l6: 0.037317

[epoch:  81/100000, batch:    82/  187, ite: 7561] train loss: 0.188864, tar: 0.019098 
l0: 0.012812, l1: 0.013594, l2: 0.014439, l3: 0.013361, l4: 0.025164, l5: 0.022202, l6: 0.024928

[epoch:  81/100000, batch:    84/  187, ite: 7562] train loss: 0.188824, tar: 0.019094 
l0: 0.029579, l1: 0.031008, l2: 0.026869, l3: 0.026754, l4: 0.047684, l5: 0.035730, l6: 0.052619

[epoch:  81/100000, batch:    86/  187, ite: 7563] train loss: 0.188863, tar: 0.019100 
l0: 0.043419, l1: 0.040543, l2: 0.039063, l3: 0.047728, l4: 0.060395, l5: 0.061074, l6: 0.071225

[epoch:  81/100000, batch:    88/  187, ite: 7564] train loss: 0.188975, tar: 0.019116 
l0: 0.014267, l1: 0.013258, l2: 0.017923, l3: 0.018936, l4: 0.030639, l5: 0.032252, l6: 0.031415

[epoch:  81/100000, batch:    90/  187, ite: 7565] train loss: 0.188955, tar: 0.019113 
l0: 0.017093, l1: 0.017876, l2: 0.016706, l3: 0.017904, l4: 0.027500, l5: 0.026033, l6: 0.035006

[epoch:  81/100000, batch:    92/  187, ite: 7566] train loss: 0.188936, tar: 0.019111 
l0: 0.013242, l1: 0.013495, l2: 0.018788, l3: 0.018900, l4: 0.040549, l5: 0.037501, l6: 0.033739

[epoch:  81/100000, batch:    94/  187, ite: 7567] train loss: 0.188928, tar: 0.019108 
l0: 0.022504, l1: 0.022990, l2: 0.026265, l3: 0.021172, l4: 0.033004, l5: 0.036614, l6: 0.024120

[epoch:  81/100000, batch:    96/  187, ite: 7568] train loss: 0.188926, tar: 0.019110 
l0: 0.013856, l1: 0.014445, l2: 0.014541, l3: 0.014452, l4: 0.022621, l5: 0.022235, l6: 0.021705

[epoch:  81/100000, batch:    98/  187, ite: 7569] train loss: 0.188885, tar: 0.019107 
l0: 0.015083, l1: 0.016519, l2: 0.020531, l3: 0.020071, l4: 0.041953, l5: 0.029218, l6: 0.020145

[epoch:  81/100000, batch:   100/  187, ite: 7570] train loss: 0.188869, tar: 0.019104 
l0: 0.017463, l1: 0.019141, l2: 0.023786, l3: 0.021948, l4: 0.021792, l5: 0.021264, l6: 0.019758

[epoch:  81/100000, batch:   102/  187, ite: 7571] train loss: 0.188841, tar: 0.019103 
l0: 0.008818, l1: 0.008937, l2: 0.009435, l3: 0.011959, l4: 0.018462, l5: 0.017488, l6: 0.021248

[epoch:  81/100000, batch:   104/  187, ite: 7572] train loss: 0.188782, tar: 0.019096 
l0: 0.032484, l1: 0.036538, l2: 0.032697, l3: 0.029082, l4: 0.034031, l5: 0.035862, l6: 0.032327

[epoch:  81/100000, batch:   106/  187, ite: 7573] train loss: 0.188810, tar: 0.019105 
l0: 0.035515, l1: 0.040011, l2: 0.039536, l3: 0.034101, l4: 0.052668, l5: 0.051174, l6: 0.047290

[epoch:  81/100000, batch:   108/  187, ite: 7574] train loss: 0.188881, tar: 0.019115 
l0: 0.013653, l1: 0.013991, l2: 0.012532, l3: 0.013616, l4: 0.029082, l5: 0.029590, l6: 0.041812

[epoch:  81/100000, batch:   110/  187, ite: 7575] train loss: 0.188859, tar: 0.019112 
l0: 0.013335, l1: 0.013354, l2: 0.014008, l3: 0.013300, l4: 0.021763, l5: 0.021854, l6: 0.020179

[epoch:  81/100000, batch:   112/  187, ite: 7576] train loss: 0.188814, tar: 0.019108 
l0: 0.020641, l1: 0.022429, l2: 0.022696, l3: 0.022924, l4: 0.028113, l5: 0.021905, l6: 0.019695

[epoch:  81/100000, batch:   114/  187, ite: 7577] train loss: 0.188794, tar: 0.019109 
l0: 0.020080, l1: 0.020200, l2: 0.024821, l3: 0.024068, l4: 0.023032, l5: 0.019621, l6: 0.024630

[epoch:  81/100000, batch:   116/  187, ite: 7578] train loss: 0.188774, tar: 0.019110 
l0: 0.012591, l1: 0.013977, l2: 0.018207, l3: 0.015956, l4: 0.025430, l5: 0.030441, l6: 0.031508

[epoch:  81/100000, batch:   118/  187, ite: 7579] train loss: 0.188748, tar: 0.019106 
l0: 0.023765, l1: 0.025634, l2: 0.027472, l3: 0.025690, l4: 0.024248, l5: 0.025129, l6: 0.020236

[epoch:  81/100000, batch:   120/  187, ite: 7580] train loss: 0.188738, tar: 0.019109 
l0: 0.017467, l1: 0.017797, l2: 0.022742, l3: 0.020776, l4: 0.023250, l5: 0.023221, l6: 0.021449

[epoch:  81/100000, batch:   122/  187, ite: 7581] train loss: 0.188711, tar: 0.019108 
l0: 0.022174, l1: 0.021984, l2: 0.024753, l3: 0.025157, l4: 0.034342, l5: 0.032662, l6: 0.032572

[epoch:  81/100000, batch:   124/  187, ite: 7582] train loss: 0.188714, tar: 0.019109 
l0: 0.012905, l1: 0.012796, l2: 0.016757, l3: 0.014973, l4: 0.023514, l5: 0.022855, l6: 0.029471

[epoch:  81/100000, batch:   126/  187, ite: 7583] train loss: 0.188679, tar: 0.019106 
l0: 0.015972, l1: 0.016519, l2: 0.017002, l3: 0.016910, l4: 0.021854, l5: 0.023002, l6: 0.021984

[epoch:  81/100000, batch:   128/  187, ite: 7584] train loss: 0.188644, tar: 0.019104 
l0: 0.024015, l1: 0.022472, l2: 0.028170, l3: 0.033115, l4: 0.084663, l5: 0.075179, l6: 0.071126

[epoch:  81/100000, batch:   130/  187, ite: 7585] train loss: 0.188739, tar: 0.019107 
l0: 0.020994, l1: 0.023228, l2: 0.023856, l3: 0.024734, l4: 0.041433, l5: 0.038542, l6: 0.041451

[epoch:  81/100000, batch:   132/  187, ite: 7586] train loss: 0.188755, tar: 0.019108 
l0: 0.010188, l1: 0.011492, l2: 0.014712, l3: 0.012838, l4: 0.020556, l5: 0.022270, l6: 0.019471

[epoch:  81/100000, batch:   134/  187, ite: 7587] train loss: 0.188706, tar: 0.019102 
l0: 0.022822, l1: 0.025073, l2: 0.025085, l3: 0.024988, l4: 0.029340, l5: 0.026989, l6: 0.025079

[epoch:  81/100000, batch:   136/  187, ite: 7588] train loss: 0.188700, tar: 0.019105 
l0: 0.009993, l1: 0.009801, l2: 0.013829, l3: 0.012669, l4: 0.025576, l5: 0.025235, l6: 0.024604

[epoch:  81/100000, batch:   138/  187, ite: 7589] train loss: 0.188658, tar: 0.019099 
l0: 0.012035, l1: 0.014028, l2: 0.011058, l3: 0.011619, l4: 0.020965, l5: 0.016657, l6: 0.024173

[epoch:  81/100000, batch:   140/  187, ite: 7590] train loss: 0.188609, tar: 0.019094 
l0: 0.009871, l1: 0.010404, l2: 0.011962, l3: 0.012306, l4: 0.021575, l5: 0.019524, l6: 0.017968

[epoch:  81/100000, batch:   142/  187, ite: 7591] train loss: 0.188556, tar: 0.019089 
l0: 0.014438, l1: 0.018147, l2: 0.014310, l3: 0.013345, l4: 0.024249, l5: 0.021597, l6: 0.020864

[epoch:  81/100000, batch:   144/  187, ite: 7592] train loss: 0.188517, tar: 0.019086 
l0: 0.006580, l1: 0.007406, l2: 0.007918, l3: 0.007083, l4: 0.019271, l5: 0.018932, l6: 0.021696

[epoch:  81/100000, batch:   146/  187, ite: 7593] train loss: 0.188455, tar: 0.019078 
l0: 0.020506, l1: 0.021275, l2: 0.021023, l3: 0.020881, l4: 0.035316, l5: 0.033894, l6: 0.036606

[epoch:  81/100000, batch:   148/  187, ite: 7594] train loss: 0.188455, tar: 0.019079 
l0: 0.013000, l1: 0.012281, l2: 0.024097, l3: 0.022928, l4: 0.027647, l5: 0.025041, l6: 0.029630

[epoch:  81/100000, batch:   150/  187, ite: 7595] train loss: 0.188434, tar: 0.019075 
l0: 0.010853, l1: 0.015843, l2: 0.018233, l3: 0.016003, l4: 0.022006, l5: 0.021763, l6: 0.034598

[epoch:  81/100000, batch:   152/  187, ite: 7596] train loss: 0.188403, tar: 0.019070 
l0: 0.024778, l1: 0.022721, l2: 0.026778, l3: 0.027781, l4: 0.068542, l5: 0.070863, l6: 0.065891

[epoch:  81/100000, batch:   154/  187, ite: 7597] train loss: 0.188478, tar: 0.019073 
l0: 0.019527, l1: 0.030779, l2: 0.024610, l3: 0.015396, l4: 0.023780, l5: 0.022932, l6: 0.018163

[epoch:  81/100000, batch:   156/  187, ite: 7598] train loss: 0.188457, tar: 0.019074 
l0: 0.011972, l1: 0.011518, l2: 0.012388, l3: 0.012543, l4: 0.027553, l5: 0.026092, l6: 0.023869

[epoch:  81/100000, batch:   158/  187, ite: 7599] train loss: 0.188418, tar: 0.019069 
l0: 0.011366, l1: 0.011710, l2: 0.012062, l3: 0.012496, l4: 0.020126, l5: 0.023817, l6: 0.016665

[epoch:  81/100000, batch:   160/  187, ite: 7600] train loss: 0.188368, tar: 0.019064 
l0: 0.009673, l1: 0.010293, l2: 0.011729, l3: 0.011081, l4: 0.018269, l5: 0.018055, l6: 0.022352

[epoch:  81/100000, batch:   162/  187, ite: 7601] train loss: 0.188313, tar: 0.019059 
l0: 0.009454, l1: 0.009690, l2: 0.012339, l3: 0.014631, l4: 0.021201, l5: 0.019301, l6: 0.020297

[epoch:  81/100000, batch:   164/  187, ite: 7602] train loss: 0.188263, tar: 0.019053 
l0: 0.008854, l1: 0.008871, l2: 0.010264, l3: 0.010535, l4: 0.012323, l5: 0.014338, l6: 0.016656

[epoch:  81/100000, batch:   166/  187, ite: 7603] train loss: 0.188196, tar: 0.019046 
l0: 0.010534, l1: 0.010079, l2: 0.011725, l3: 0.013716, l4: 0.022291, l5: 0.027095, l6: 0.031492

[epoch:  81/100000, batch:   168/  187, ite: 7604] train loss: 0.188158, tar: 0.019041 
l0: 0.011935, l1: 0.012735, l2: 0.011583, l3: 0.015177, l4: 0.034200, l5: 0.037026, l6: 0.030528

[epoch:  81/100000, batch:   170/  187, ite: 7605] train loss: 0.188136, tar: 0.019036 
l0: 0.020097, l1: 0.019608, l2: 0.019643, l3: 0.020858, l4: 0.033220, l5: 0.032481, l6: 0.040077

[epoch:  81/100000, batch:   172/  187, ite: 7606] train loss: 0.188135, tar: 0.019037 
l0: 0.018165, l1: 0.017806, l2: 0.019269, l3: 0.022405, l4: 0.040897, l5: 0.040445, l6: 0.037191

[epoch:  81/100000, batch:   174/  187, ite: 7607] train loss: 0.188140, tar: 0.019037 
l0: 0.012212, l1: 0.012766, l2: 0.013928, l3: 0.016896, l4: 0.033674, l5: 0.022214, l6: 0.024095

[epoch:  81/100000, batch:   176/  187, ite: 7608] train loss: 0.188107, tar: 0.019032 
l0: 0.010649, l1: 0.013161, l2: 0.007598, l3: 0.007755, l4: 0.010799, l5: 0.012428, l6: 0.013946

[epoch:  81/100000, batch:   178/  187, ite: 7609] train loss: 0.188038, tar: 0.019027 
l0: 0.010684, l1: 0.011667, l2: 0.012509, l3: 0.012060, l4: 0.027512, l5: 0.026803, l6: 0.032002

[epoch:  81/100000, batch:   180/  187, ite: 7610] train loss: 0.188004, tar: 0.019022 
l0: 0.019350, l1: 0.022376, l2: 0.023786, l3: 0.021295, l4: 0.028778, l5: 0.022019, l6: 0.024793

[epoch:  81/100000, batch:   182/  187, ite: 7611] train loss: 0.187988, tar: 0.019022 
l0: 0.011273, l1: 0.011980, l2: 0.015260, l3: 0.013279, l4: 0.025138, l5: 0.024239, l6: 0.021927

[epoch:  81/100000, batch:   184/  187, ite: 7612] train loss: 0.187948, tar: 0.019017 
l0: 0.010376, l1: 0.011744, l2: 0.012184, l3: 0.012258, l4: 0.018386, l5: 0.021270, l6: 0.020637

[epoch:  81/100000, batch:   186/  187, ite: 7613] train loss: 0.187897, tar: 0.019012 
l0: 0.004022, l1: 0.004859, l2: 0.011009, l3: 0.010202, l4: 0.008509, l5: 0.005550, l6: 0.006397

[epoch:  81/100000, batch:   188/  187, ite: 7614] train loss: 0.187812, tar: 0.019003 
l0: 0.007930, l1: 0.009412, l2: 0.008905, l3: 0.009192, l4: 0.017394, l5: 0.014045, l6: 0.013449

[epoch:  82/100000, batch:     2/  187, ite: 7615] train loss: 0.187746, tar: 0.018996 
l0: 0.010358, l1: 0.010416, l2: 0.016699, l3: 0.016557, l4: 0.017474, l5: 0.017714, l6: 0.014908

[epoch:  82/100000, batch:     4/  187, ite: 7616] train loss: 0.187694, tar: 0.018990 
l0: 0.015128, l1: 0.015460, l2: 0.018824, l3: 0.018326, l4: 0.021523, l5: 0.017535, l6: 0.021503

[epoch:  82/100000, batch:     6/  187, ite: 7617] train loss: 0.187657, tar: 0.018988 
l0: 0.014189, l1: 0.015846, l2: 0.015892, l3: 0.015081, l4: 0.033040, l5: 0.034722, l6: 0.032440

[epoch:  82/100000, batch:     8/  187, ite: 7618] train loss: 0.187641, tar: 0.018985 
l0: 0.026161, l1: 0.025129, l2: 0.034076, l3: 0.040038, l4: 0.039952, l5: 0.040565, l6: 0.034263

[epoch:  82/100000, batch:    10/  187, ite: 7619] train loss: 0.187673, tar: 0.018990 
l0: 0.013353, l1: 0.013352, l2: 0.018262, l3: 0.017203, l4: 0.023167, l5: 0.020879, l6: 0.028503

[epoch:  82/100000, batch:    12/  187, ite: 7620] train loss: 0.187641, tar: 0.018986 
l0: 0.013000, l1: 0.014168, l2: 0.015515, l3: 0.011604, l4: 0.024155, l5: 0.019240, l6: 0.018558

[epoch:  82/100000, batch:    14/  187, ite: 7621] train loss: 0.187597, tar: 0.018982 
l0: 0.016267, l1: 0.016774, l2: 0.015795, l3: 0.015935, l4: 0.031647, l5: 0.025576, l6: 0.033051

[epoch:  82/100000, batch:    16/  187, ite: 7622] train loss: 0.187577, tar: 0.018981 
l0: 0.013905, l1: 0.015178, l2: 0.012097, l3: 0.011367, l4: 0.018071, l5: 0.023387, l6: 0.017490

[epoch:  82/100000, batch:    18/  187, ite: 7623] train loss: 0.187530, tar: 0.018978 
l0: 0.011930, l1: 0.012530, l2: 0.012396, l3: 0.012727, l4: 0.021169, l5: 0.019454, l6: 0.022810

[epoch:  82/100000, batch:    20/  187, ite: 7624] train loss: 0.187484, tar: 0.018973 
l0: 0.010499, l1: 0.010773, l2: 0.013204, l3: 0.013748, l4: 0.027802, l5: 0.027275, l6: 0.027587

[epoch:  82/100000, batch:    22/  187, ite: 7625] train loss: 0.187449, tar: 0.018968 
l0: 0.010479, l1: 0.010239, l2: 0.012322, l3: 0.010785, l4: 0.018712, l5: 0.019607, l6: 0.019555

[epoch:  82/100000, batch:    24/  187, ite: 7626] train loss: 0.187396, tar: 0.018963 
l0: 0.032928, l1: 0.036234, l2: 0.034059, l3: 0.031891, l4: 0.029784, l5: 0.026352, l6: 0.034348

[epoch:  82/100000, batch:    26/  187, ite: 7627] train loss: 0.187420, tar: 0.018971 
l0: 0.013588, l1: 0.015375, l2: 0.019110, l3: 0.014387, l4: 0.028769, l5: 0.028753, l6: 0.027013

[epoch:  82/100000, batch:    28/  187, ite: 7628] train loss: 0.187395, tar: 0.018968 
l0: 0.010703, l1: 0.011256, l2: 0.008142, l3: 0.010701, l4: 0.022392, l5: 0.024416, l6: 0.021607

[epoch:  82/100000, batch:    30/  187, ite: 7629] train loss: 0.187347, tar: 0.018963 
l0: 0.023955, l1: 0.024051, l2: 0.033891, l3: 0.036863, l4: 0.036504, l5: 0.035407, l6: 0.049425

[epoch:  82/100000, batch:    32/  187, ite: 7630] train loss: 0.187379, tar: 0.018966 
l0: 0.026839, l1: 0.030352, l2: 0.030880, l3: 0.026824, l4: 0.040922, l5: 0.033436, l6: 0.034713

[epoch:  82/100000, batch:    34/  187, ite: 7631] train loss: 0.187402, tar: 0.018971 
l0: 0.010547, l1: 0.010837, l2: 0.011640, l3: 0.011737, l4: 0.028291, l5: 0.029938, l6: 0.023130

[epoch:  82/100000, batch:    36/  187, ite: 7632] train loss: 0.187364, tar: 0.018966 
l0: 0.026467, l1: 0.029184, l2: 0.032451, l3: 0.030044, l4: 0.051425, l5: 0.042851, l6: 0.047196

[epoch:  82/100000, batch:    38/  187, ite: 7633] train loss: 0.187408, tar: 0.018970 
l0: 0.017052, l1: 0.014483, l2: 0.017842, l3: 0.020517, l4: 0.036819, l5: 0.038758, l6: 0.048119

[epoch:  82/100000, batch:    40/  187, ite: 7634] train loss: 0.187412, tar: 0.018969 
l0: 0.012434, l1: 0.012892, l2: 0.016296, l3: 0.017626, l4: 0.030469, l5: 0.024852, l6: 0.025127

[epoch:  82/100000, batch:    42/  187, ite: 7635] train loss: 0.187383, tar: 0.018965 
l0: 0.011319, l1: 0.011451, l2: 0.015275, l3: 0.014836, l4: 0.021850, l5: 0.022963, l6: 0.020818

[epoch:  82/100000, batch:    44/  187, ite: 7636] train loss: 0.187341, tar: 0.018960 
l0: 0.012604, l1: 0.013594, l2: 0.019037, l3: 0.015470, l4: 0.017276, l5: 0.016430, l6: 0.019311

[epoch:  82/100000, batch:    46/  187, ite: 7637] train loss: 0.187296, tar: 0.018957 
l0: 0.008214, l1: 0.009134, l2: 0.008484, l3: 0.010742, l4: 0.029203, l5: 0.027278, l6: 0.025104

[epoch:  82/100000, batch:    48/  187, ite: 7638] train loss: 0.187254, tar: 0.018950 
l0: 0.020335, l1: 0.021063, l2: 0.022009, l3: 0.022108, l4: 0.031168, l5: 0.032939, l6: 0.034114

[epoch:  82/100000, batch:    50/  187, ite: 7639] train loss: 0.187252, tar: 0.018951 
l0: 0.013410, l1: 0.014733, l2: 0.014350, l3: 0.017117, l4: 0.014866, l5: 0.016596, l6: 0.020553

[epoch:  82/100000, batch:    52/  187, ite: 7640] train loss: 0.187205, tar: 0.018947 
l0: 0.017821, l1: 0.017758, l2: 0.021925, l3: 0.020858, l4: 0.032817, l5: 0.029896, l6: 0.034374

[epoch:  82/100000, batch:    54/  187, ite: 7641] train loss: 0.187198, tar: 0.018947 
l0: 0.014184, l1: 0.014441, l2: 0.014947, l3: 0.015239, l4: 0.027331, l5: 0.022087, l6: 0.025612

[epoch:  82/100000, batch:    56/  187, ite: 7642] train loss: 0.187166, tar: 0.018944 
l0: 0.012295, l1: 0.011482, l2: 0.017215, l3: 0.020685, l4: 0.027661, l5: 0.023626, l6: 0.030372

[epoch:  82/100000, batch:    58/  187, ite: 7643] train loss: 0.187139, tar: 0.018940 
l0: 0.010964, l1: 0.010896, l2: 0.016261, l3: 0.021451, l4: 0.028216, l5: 0.023862, l6: 0.024155

[epoch:  82/100000, batch:    60/  187, ite: 7644] train loss: 0.187108, tar: 0.018935 
l0: 0.009082, l1: 0.009358, l2: 0.010182, l3: 0.011785, l4: 0.010579, l5: 0.010729, l6: 0.009924

[epoch:  82/100000, batch:    62/  187, ite: 7645] train loss: 0.187038, tar: 0.018929 
l0: 0.029331, l1: 0.027337, l2: 0.030457, l3: 0.031349, l4: 0.045825, l5: 0.060844, l6: 0.038222

[epoch:  82/100000, batch:    64/  187, ite: 7646] train loss: 0.187084, tar: 0.018935 
l0: 0.023208, l1: 0.022188, l2: 0.026125, l3: 0.029945, l4: 0.042600, l5: 0.035212, l6: 0.037551

[epoch:  82/100000, batch:    66/  187, ite: 7647] train loss: 0.187102, tar: 0.018938 
l0: 0.011005, l1: 0.011830, l2: 0.015690, l3: 0.015833, l4: 0.020098, l5: 0.016555, l6: 0.017047

[epoch:  82/100000, batch:    68/  187, ite: 7648] train loss: 0.187054, tar: 0.018933 
l0: 0.029226, l1: 0.027110, l2: 0.030667, l3: 0.034429, l4: 0.041519, l5: 0.045474, l6: 0.058697

[epoch:  82/100000, batch:    70/  187, ite: 7649] train loss: 0.187103, tar: 0.018939 
l0: 0.014408, l1: 0.015568, l2: 0.014474, l3: 0.014739, l4: 0.028733, l5: 0.026550, l6: 0.026468

[epoch:  82/100000, batch:    72/  187, ite: 7650] train loss: 0.187075, tar: 0.018937 
l0: 0.018385, l1: 0.017693, l2: 0.023051, l3: 0.028003, l4: 0.030616, l5: 0.035298, l6: 0.032339

[epoch:  82/100000, batch:    74/  187, ite: 7651] train loss: 0.187074, tar: 0.018936 
l0: 0.008327, l1: 0.007818, l2: 0.011181, l3: 0.010903, l4: 0.010266, l5: 0.012909, l6: 0.015318

[epoch:  82/100000, batch:    76/  187, ite: 7652] train loss: 0.187007, tar: 0.018930 
l0: 0.030941, l1: 0.032148, l2: 0.038683, l3: 0.040718, l4: 0.028007, l5: 0.029494, l6: 0.029757

[epoch:  82/100000, batch:    78/  187, ite: 7653] train loss: 0.187033, tar: 0.018937 
l0: 0.015468, l1: 0.014435, l2: 0.013616, l3: 0.017738, l4: 0.033824, l5: 0.031795, l6: 0.050962

[epoch:  82/100000, batch:    80/  187, ite: 7654] train loss: 0.187027, tar: 0.018935 
l0: 0.009987, l1: 0.010759, l2: 0.014994, l3: 0.014906, l4: 0.019301, l5: 0.020443, l6: 0.019734

[epoch:  82/100000, batch:    82/  187, ite: 7655] train loss: 0.186981, tar: 0.018930 
l0: 0.008386, l1: 0.008093, l2: 0.016903, l3: 0.014298, l4: 0.024512, l5: 0.025652, l6: 0.020032

[epoch:  82/100000, batch:    84/  187, ite: 7656] train loss: 0.186939, tar: 0.018923 
l0: 0.011953, l1: 0.013600, l2: 0.011036, l3: 0.011193, l4: 0.018229, l5: 0.019041, l6: 0.020096

[epoch:  82/100000, batch:    86/  187, ite: 7657] train loss: 0.186890, tar: 0.018919 
l0: 0.015723, l1: 0.016333, l2: 0.021528, l3: 0.017888, l4: 0.025660, l5: 0.022919, l6: 0.023029

[epoch:  82/100000, batch:    88/  187, ite: 7658] train loss: 0.186863, tar: 0.018917 
l0: 0.020392, l1: 0.020062, l2: 0.020828, l3: 0.022582, l4: 0.033316, l5: 0.029670, l6: 0.036561

[epoch:  82/100000, batch:    90/  187, ite: 7659] train loss: 0.186861, tar: 0.018918 
l0: 0.013530, l1: 0.014380, l2: 0.012365, l3: 0.014743, l4: 0.035863, l5: 0.027128, l6: 0.025178

[epoch:  82/100000, batch:    92/  187, ite: 7660] train loss: 0.186835, tar: 0.018915 
l0: 0.016693, l1: 0.019039, l2: 0.015292, l3: 0.016111, l4: 0.028106, l5: 0.026411, l6: 0.031810

[epoch:  82/100000, batch:    94/  187, ite: 7661] train loss: 0.186815, tar: 0.018913 
l0: 0.019626, l1: 0.021172, l2: 0.021828, l3: 0.018913, l4: 0.027037, l5: 0.027959, l6: 0.024184

[epoch:  82/100000, batch:    96/  187, ite: 7662] train loss: 0.186799, tar: 0.018914 
l0: 0.015030, l1: 0.015900, l2: 0.017983, l3: 0.017530, l4: 0.024303, l5: 0.025284, l6: 0.023851

[epoch:  82/100000, batch:    98/  187, ite: 7663] train loss: 0.186771, tar: 0.018912 
l0: 0.013598, l1: 0.013795, l2: 0.014323, l3: 0.013591, l4: 0.023961, l5: 0.027454, l6: 0.025206

[epoch:  82/100000, batch:   100/  187, ite: 7664] train loss: 0.186738, tar: 0.018908 
l0: 0.010174, l1: 0.011465, l2: 0.012634, l3: 0.012320, l4: 0.018899, l5: 0.018267, l6: 0.022387

[epoch:  82/100000, batch:   102/  187, ite: 7665] train loss: 0.186689, tar: 0.018903 
l0: 0.016647, l1: 0.016618, l2: 0.020380, l3: 0.023556, l4: 0.039612, l5: 0.031423, l6: 0.029603

[epoch:  82/100000, batch:   104/  187, ite: 7666] train loss: 0.186684, tar: 0.018902 
l0: 0.020865, l1: 0.022988, l2: 0.020081, l3: 0.019269, l4: 0.021091, l5: 0.021655, l6: 0.021830

[epoch:  82/100000, batch:   106/  187, ite: 7667] train loss: 0.186661, tar: 0.018903 
l0: 0.012870, l1: 0.013468, l2: 0.016360, l3: 0.016046, l4: 0.024904, l5: 0.023851, l6: 0.028080

[epoch:  82/100000, batch:   108/  187, ite: 7668] train loss: 0.186630, tar: 0.018899 
l0: 0.008593, l1: 0.009770, l2: 0.010992, l3: 0.013553, l4: 0.026669, l5: 0.021638, l6: 0.020017

[epoch:  82/100000, batch:   110/  187, ite: 7669] train loss: 0.186585, tar: 0.018893 
l0: 0.008052, l1: 0.009950, l2: 0.008846, l3: 0.010754, l4: 0.020079, l5: 0.023705, l6: 0.025388

[epoch:  82/100000, batch:   112/  187, ite: 7670] train loss: 0.186537, tar: 0.018887 
l0: 0.007860, l1: 0.007343, l2: 0.012431, l3: 0.011013, l4: 0.022118, l5: 0.025369, l6: 0.028099

[epoch:  82/100000, batch:   114/  187, ite: 7671] train loss: 0.186494, tar: 0.018880 
l0: 0.011467, l1: 0.011272, l2: 0.017829, l3: 0.016367, l4: 0.031232, l5: 0.030852, l6: 0.025131

[epoch:  82/100000, batch:   116/  187, ite: 7672] train loss: 0.186469, tar: 0.018876 
l0: 0.010684, l1: 0.010344, l2: 0.012816, l3: 0.014252, l4: 0.021128, l5: 0.019887, l6: 0.024664

[epoch:  82/100000, batch:   118/  187, ite: 7673] train loss: 0.186425, tar: 0.018871 
l0: 0.014777, l1: 0.014621, l2: 0.014582, l3: 0.015059, l4: 0.026786, l5: 0.028428, l6: 0.034310

[epoch:  82/100000, batch:   120/  187, ite: 7674] train loss: 0.186403, tar: 0.018868 
l0: 0.018802, l1: 0.018815, l2: 0.022258, l3: 0.023655, l4: 0.047064, l5: 0.041851, l6: 0.039053

[epoch:  82/100000, batch:   122/  187, ite: 7675] train loss: 0.186417, tar: 0.018868 
l0: 0.016805, l1: 0.016741, l2: 0.020086, l3: 0.019907, l4: 0.029302, l5: 0.031229, l6: 0.041824

[epoch:  82/100000, batch:   124/  187, ite: 7676] train loss: 0.186411, tar: 0.018867 
l0: 0.015932, l1: 0.017859, l2: 0.019958, l3: 0.019002, l4: 0.037323, l5: 0.029099, l6: 0.026645

[epoch:  82/100000, batch:   126/  187, ite: 7677] train loss: 0.186399, tar: 0.018865 
l0: 0.015424, l1: 0.013861, l2: 0.019794, l3: 0.025124, l4: 0.035877, l5: 0.027585, l6: 0.038207

[epoch:  82/100000, batch:   128/  187, ite: 7678] train loss: 0.186393, tar: 0.018863 
l0: 0.013857, l1: 0.013137, l2: 0.020417, l3: 0.021801, l4: 0.034575, l5: 0.031624, l6: 0.023530

[epoch:  82/100000, batch:   130/  187, ite: 7679] train loss: 0.186376, tar: 0.018860 
l0: 0.023564, l1: 0.021990, l2: 0.026855, l3: 0.032231, l4: 0.055827, l5: 0.046720, l6: 0.043325

[epoch:  82/100000, batch:   132/  187, ite: 7680] train loss: 0.186414, tar: 0.018863 
l0: 0.011131, l1: 0.012607, l2: 0.011656, l3: 0.011868, l4: 0.021286, l5: 0.021637, l6: 0.025003

[epoch:  82/100000, batch:   134/  187, ite: 7681] train loss: 0.186372, tar: 0.018858 
l0: 0.012465, l1: 0.013454, l2: 0.013742, l3: 0.014127, l4: 0.037650, l5: 0.031273, l6: 0.029311

[epoch:  82/100000, batch:   136/  187, ite: 7682] train loss: 0.186352, tar: 0.018855 
l0: 0.007385, l1: 0.007505, l2: 0.008274, l3: 0.009582, l4: 0.031855, l5: 0.025093, l6: 0.021633

[epoch:  82/100000, batch:   138/  187, ite: 7683] train loss: 0.186307, tar: 0.018848 
l0: 0.010152, l1: 0.009686, l2: 0.011931, l3: 0.012321, l4: 0.034934, l5: 0.026682, l6: 0.025188

[epoch:  82/100000, batch:   140/  187, ite: 7684] train loss: 0.186274, tar: 0.018843 
l0: 0.009919, l1: 0.010330, l2: 0.015606, l3: 0.012752, l4: 0.020025, l5: 0.016740, l6: 0.014276

[epoch:  82/100000, batch:   142/  187, ite: 7685] train loss: 0.186223, tar: 0.018837 
l0: 0.008103, l1: 0.008542, l2: 0.010107, l3: 0.009109, l4: 0.013328, l5: 0.013822, l6: 0.011109

[epoch:  82/100000, batch:   144/  187, ite: 7686] train loss: 0.186156, tar: 0.018831 
l0: 0.011403, l1: 0.012469, l2: 0.013433, l3: 0.013972, l4: 0.018035, l5: 0.017774, l6: 0.021062

[epoch:  82/100000, batch:   146/  187, ite: 7687] train loss: 0.186110, tar: 0.018827 
l0: 0.010847, l1: 0.011040, l2: 0.011627, l3: 0.011771, l4: 0.025190, l5: 0.023761, l6: 0.019847

[epoch:  82/100000, batch:   148/  187, ite: 7688] train loss: 0.186067, tar: 0.018822 
l0: 0.009374, l1: 0.010384, l2: 0.010557, l3: 0.011024, l4: 0.022119, l5: 0.024047, l6: 0.021318

[epoch:  82/100000, batch:   150/  187, ite: 7689] train loss: 0.186022, tar: 0.018816 
l0: 0.013294, l1: 0.013937, l2: 0.017212, l3: 0.020660, l4: 0.029480, l5: 0.034882, l6: 0.025237

[epoch:  82/100000, batch:   152/  187, ite: 7690] train loss: 0.186003, tar: 0.018813 
l0: 0.013985, l1: 0.014955, l2: 0.015914, l3: 0.015257, l4: 0.027883, l5: 0.025865, l6: 0.028719

[epoch:  82/100000, batch:   154/  187, ite: 7691] train loss: 0.185977, tar: 0.018810 
l0: 0.007476, l1: 0.009531, l2: 0.009143, l3: 0.007671, l4: 0.013784, l5: 0.014263, l6: 0.009985

[epoch:  82/100000, batch:   156/  187, ite: 7692] train loss: 0.185910, tar: 0.018803 
l0: 0.028735, l1: 0.030126, l2: 0.024503, l3: 0.025798, l4: 0.027773, l5: 0.027445, l6: 0.032168

[epoch:  82/100000, batch:   158/  187, ite: 7693] train loss: 0.185916, tar: 0.018809 
l0: 0.016623, l1: 0.017495, l2: 0.020672, l3: 0.020895, l4: 0.015876, l5: 0.012753, l6: 0.015864

[epoch:  82/100000, batch:   160/  187, ite: 7694] train loss: 0.185877, tar: 0.018808 
l0: 0.005920, l1: 0.006176, l2: 0.007830, l3: 0.008323, l4: 0.015085, l5: 0.015293, l6: 0.013634

[epoch:  82/100000, batch:   162/  187, ite: 7695] train loss: 0.185810, tar: 0.018800 
l0: 0.014070, l1: 0.015130, l2: 0.011426, l3: 0.012419, l4: 0.021388, l5: 0.025281, l6: 0.026748

[epoch:  82/100000, batch:   164/  187, ite: 7696] train loss: 0.185775, tar: 0.018798 
l0: 0.008760, l1: 0.007855, l2: 0.009843, l3: 0.012823, l4: 0.023816, l5: 0.027457, l6: 0.028292

[epoch:  82/100000, batch:   166/  187, ite: 7697] train loss: 0.185736, tar: 0.018792 
l0: 0.006064, l1: 0.006401, l2: 0.006972, l3: 0.007490, l4: 0.009828, l5: 0.007544, l6: 0.013657

[epoch:  82/100000, batch:   168/  187, ite: 7698] train loss: 0.185661, tar: 0.018784 
l0: 0.020260, l1: 0.021550, l2: 0.019308, l3: 0.020720, l4: 0.044590, l5: 0.042214, l6: 0.032465

[epoch:  82/100000, batch:   170/  187, ite: 7699] train loss: 0.185670, tar: 0.018785 
l0: 0.015740, l1: 0.016203, l2: 0.019782, l3: 0.020808, l4: 0.048308, l5: 0.029809, l6: 0.027486

[epoch:  82/100000, batch:   172/  187, ite: 7700] train loss: 0.185665, tar: 0.018783 
l0: 0.014685, l1: 0.015828, l2: 0.021331, l3: 0.020376, l4: 0.030396, l5: 0.028136, l6: 0.024577

[epoch:  82/100000, batch:   174/  187, ite: 7701] train loss: 0.185648, tar: 0.018781 
l0: 0.013188, l1: 0.014075, l2: 0.011549, l3: 0.011924, l4: 0.019653, l5: 0.015400, l6: 0.015654

[epoch:  82/100000, batch:   176/  187, ite: 7702] train loss: 0.185598, tar: 0.018778 
l0: 0.012041, l1: 0.012514, l2: 0.017047, l3: 0.017822, l4: 0.017222, l5: 0.016922, l6: 0.014364

[epoch:  82/100000, batch:   178/  187, ite: 7703] train loss: 0.185553, tar: 0.018774 
l0: 0.011512, l1: 0.010851, l2: 0.020414, l3: 0.020391, l4: 0.020645, l5: 0.019833, l6: 0.015991

[epoch:  82/100000, batch:   180/  187, ite: 7704] train loss: 0.185514, tar: 0.018769 
l0: 0.008851, l1: 0.008763, l2: 0.010947, l3: 0.010383, l4: 0.016905, l5: 0.016924, l6: 0.018413

[epoch:  82/100000, batch:   182/  187, ite: 7705] train loss: 0.185459, tar: 0.018764 
l0: 0.007755, l1: 0.014909, l2: 0.013805, l3: 0.007550, l4: 0.011029, l5: 0.014899, l6: 0.019337

[epoch:  82/100000, batch:   184/  187, ite: 7706] train loss: 0.185402, tar: 0.018757 
l0: 0.018200, l1: 0.019314, l2: 0.016668, l3: 0.016112, l4: 0.029645, l5: 0.029536, l6: 0.029639

[epoch:  82/100000, batch:   186/  187, ite: 7707] train loss: 0.185387, tar: 0.018757 
l0: 0.011923, l1: 0.012439, l2: 0.016164, l3: 0.017081, l4: 0.027564, l5: 0.028650, l6: 0.035674

[epoch:  82/100000, batch:   188/  187, ite: 7708] train loss: 0.185366, tar: 0.018753 
l0: 0.004515, l1: 0.005885, l2: 0.006857, l3: 0.003940, l4: 0.008415, l5: 0.006692, l6: 0.009651

[epoch:  83/100000, batch:     2/  187, ite: 7709] train loss: 0.185284, tar: 0.018744 
l0: 0.014373, l1: 0.016302, l2: 0.012839, l3: 0.012962, l4: 0.018907, l5: 0.018516, l6: 0.025499

[epoch:  83/100000, batch:     4/  187, ite: 7710] train loss: 0.185246, tar: 0.018742 
l0: 0.010720, l1: 0.010269, l2: 0.014634, l3: 0.016714, l4: 0.017049, l5: 0.021337, l6: 0.023288

[epoch:  83/100000, batch:     6/  187, ite: 7711] train loss: 0.185204, tar: 0.018737 
l0: 0.008193, l1: 0.008687, l2: 0.009376, l3: 0.009893, l4: 0.026968, l5: 0.023076, l6: 0.030597

[epoch:  83/100000, batch:     8/  187, ite: 7712] train loss: 0.185164, tar: 0.018731 
l0: 0.008498, l1: 0.010707, l2: 0.007823, l3: 0.008243, l4: 0.020957, l5: 0.016609, l6: 0.017333

[epoch:  83/100000, batch:    10/  187, ite: 7713] train loss: 0.185109, tar: 0.018725 
l0: 0.011090, l1: 0.011228, l2: 0.017639, l3: 0.016982, l4: 0.017899, l5: 0.014103, l6: 0.017746

[epoch:  83/100000, batch:    12/  187, ite: 7714] train loss: 0.185063, tar: 0.018721 
l0: 0.022999, l1: 0.021788, l2: 0.021122, l3: 0.022064, l4: 0.032323, l5: 0.036234, l6: 0.036748

[epoch:  83/100000, batch:    14/  187, ite: 7715] train loss: 0.185068, tar: 0.018723 
l0: 0.006903, l1: 0.006775, l2: 0.010714, l3: 0.010614, l4: 0.017515, l5: 0.016271, l6: 0.014902

[epoch:  83/100000, batch:    16/  187, ite: 7716] train loss: 0.185009, tar: 0.018716 
l0: 0.007839, l1: 0.009735, l2: 0.008471, l3: 0.008933, l4: 0.016212, l5: 0.018786, l6: 0.018344

[epoch:  83/100000, batch:    18/  187, ite: 7717] train loss: 0.184952, tar: 0.018710 
l0: 0.009534, l1: 0.011425, l2: 0.008502, l3: 0.008666, l4: 0.016839, l5: 0.014950, l6: 0.012385

[epoch:  83/100000, batch:    20/  187, ite: 7718] train loss: 0.184892, tar: 0.018705 
l0: 0.012268, l1: 0.011871, l2: 0.015055, l3: 0.016195, l4: 0.024047, l5: 0.027813, l6: 0.027296

[epoch:  83/100000, batch:    22/  187, ite: 7719] train loss: 0.184863, tar: 0.018701 
l0: 0.005698, l1: 0.006106, l2: 0.007798, l3: 0.007351, l4: 0.011891, l5: 0.013204, l6: 0.014511

[epoch:  83/100000, batch:    24/  187, ite: 7720] train loss: 0.184794, tar: 0.018693 
l0: 0.005727, l1: 0.006041, l2: 0.006886, l3: 0.008080, l4: 0.014095, l5: 0.011299, l6: 0.012667

[epoch:  83/100000, batch:    26/  187, ite: 7721] train loss: 0.184725, tar: 0.018686 
l0: 0.009193, l1: 0.009880, l2: 0.011332, l3: 0.011021, l4: 0.026237, l5: 0.032801, l6: 0.048436

[epoch:  83/100000, batch:    28/  187, ite: 7722] train loss: 0.184704, tar: 0.018680 
l0: 0.016538, l1: 0.016912, l2: 0.017876, l3: 0.016801, l4: 0.033390, l5: 0.034076, l6: 0.031970

[epoch:  83/100000, batch:    30/  187, ite: 7723] train loss: 0.184694, tar: 0.018679 
l0: 0.015503, l1: 0.014129, l2: 0.019949, l3: 0.022814, l4: 0.022183, l5: 0.025406, l6: 0.030044

[epoch:  83/100000, batch:    32/  187, ite: 7724] train loss: 0.184674, tar: 0.018677 
l0: 0.015019, l1: 0.015737, l2: 0.012993, l3: 0.013818, l4: 0.015804, l5: 0.015898, l6: 0.016022

[epoch:  83/100000, batch:    34/  187, ite: 7725] train loss: 0.184628, tar: 0.018675 
l0: 0.009962, l1: 0.009351, l2: 0.008697, l3: 0.010618, l4: 0.030871, l5: 0.029645, l6: 0.031118

[epoch:  83/100000, batch:    36/  187, ite: 7726] train loss: 0.184596, tar: 0.018670 
l0: 0.009554, l1: 0.009385, l2: 0.013781, l3: 0.013013, l4: 0.014231, l5: 0.013827, l6: 0.017191

[epoch:  83/100000, batch:    38/  187, ite: 7727] train loss: 0.184542, tar: 0.018665 
l0: 0.016291, l1: 0.016118, l2: 0.014487, l3: 0.016006, l4: 0.023495, l5: 0.022172, l6: 0.031577

[epoch:  83/100000, batch:    40/  187, ite: 7728] train loss: 0.184516, tar: 0.018663 
l0: 0.012373, l1: 0.013579, l2: 0.014542, l3: 0.015714, l4: 0.018894, l5: 0.016638, l6: 0.019329

[epoch:  83/100000, batch:    42/  187, ite: 7729] train loss: 0.184474, tar: 0.018660 
l0: 0.017238, l1: 0.018787, l2: 0.018310, l3: 0.016926, l4: 0.030261, l5: 0.025021, l6: 0.026786

[epoch:  83/100000, batch:    44/  187, ite: 7730] train loss: 0.184456, tar: 0.018659 
l0: 0.013346, l1: 0.014584, l2: 0.013415, l3: 0.013443, l4: 0.022950, l5: 0.021126, l6: 0.022818

[epoch:  83/100000, batch:    46/  187, ite: 7731] train loss: 0.184420, tar: 0.018656 
l0: 0.023132, l1: 0.026290, l2: 0.026293, l3: 0.024657, l4: 0.031376, l5: 0.023158, l6: 0.028666

[epoch:  83/100000, batch:    48/  187, ite: 7732] train loss: 0.184419, tar: 0.018658 
l0: 0.007023, l1: 0.007220, l2: 0.009474, l3: 0.009299, l4: 0.022220, l5: 0.021839, l6: 0.026628

[epoch:  83/100000, batch:    50/  187, ite: 7733] train loss: 0.184373, tar: 0.018652 
l0: 0.004303, l1: 0.004571, l2: 0.005314, l3: 0.005425, l4: 0.008382, l5: 0.008022, l6: 0.011712

[epoch:  83/100000, batch:    52/  187, ite: 7734] train loss: 0.184294, tar: 0.018643 
l0: 0.014852, l1: 0.014804, l2: 0.016475, l3: 0.016231, l4: 0.024515, l5: 0.022927, l6: 0.024853

[epoch:  83/100000, batch:    54/  187, ite: 7735] train loss: 0.184265, tar: 0.018641 
l0: 0.009285, l1: 0.011165, l2: 0.011467, l3: 0.008679, l4: 0.018201, l5: 0.017358, l6: 0.020181

[epoch:  83/100000, batch:    56/  187, ite: 7736] train loss: 0.184215, tar: 0.018636 
l0: 0.011961, l1: 0.011474, l2: 0.012947, l3: 0.014905, l4: 0.021646, l5: 0.021865, l6: 0.015957

[epoch:  83/100000, batch:    58/  187, ite: 7737] train loss: 0.184172, tar: 0.018632 
l0: 0.013941, l1: 0.014109, l2: 0.014840, l3: 0.016286, l4: 0.019282, l5: 0.018140, l6: 0.019662

[epoch:  83/100000, batch:    60/  187, ite: 7738] train loss: 0.184133, tar: 0.018629 
l0: 0.010945, l1: 0.011447, l2: 0.015969, l3: 0.015180, l4: 0.021664, l5: 0.016771, l6: 0.014665

[epoch:  83/100000, batch:    62/  187, ite: 7739] train loss: 0.184089, tar: 0.018625 
l0: 0.010780, l1: 0.011139, l2: 0.011113, l3: 0.012409, l4: 0.024668, l5: 0.024368, l6: 0.020808

[epoch:  83/100000, batch:    64/  187, ite: 7740] train loss: 0.184049, tar: 0.018620 
l0: 0.005830, l1: 0.005382, l2: 0.005222, l3: 0.005334, l4: 0.013074, l5: 0.013375, l6: 0.024818

[epoch:  83/100000, batch:    66/  187, ite: 7741] train loss: 0.183985, tar: 0.018613 
l0: 0.016402, l1: 0.017758, l2: 0.018924, l3: 0.018865, l4: 0.023877, l5: 0.022811, l6: 0.023815

[epoch:  83/100000, batch:    68/  187, ite: 7742] train loss: 0.183961, tar: 0.018612 
l0: 0.007782, l1: 0.008500, l2: 0.009161, l3: 0.010112, l4: 0.016478, l5: 0.014324, l6: 0.016296

[epoch:  83/100000, batch:    70/  187, ite: 7743] train loss: 0.183903, tar: 0.018605 
l0: 0.015255, l1: 0.013940, l2: 0.019503, l3: 0.021547, l4: 0.021622, l5: 0.022713, l6: 0.023818

[epoch:  83/100000, batch:    72/  187, ite: 7744] train loss: 0.183877, tar: 0.018604 
l0: 0.012718, l1: 0.012799, l2: 0.012753, l3: 0.012695, l4: 0.019882, l5: 0.023487, l6: 0.023499

[epoch:  83/100000, batch:    74/  187, ite: 7745] train loss: 0.183839, tar: 0.018600 
l0: 0.009780, l1: 0.009297, l2: 0.011145, l3: 0.011420, l4: 0.012881, l5: 0.017814, l6: 0.014443

[epoch:  83/100000, batch:    76/  187, ite: 7746] train loss: 0.183784, tar: 0.018595 
l0: 0.018318, l1: 0.019923, l2: 0.019357, l3: 0.018477, l4: 0.031079, l5: 0.023272, l6: 0.028464

[epoch:  83/100000, batch:    78/  187, ite: 7747] train loss: 0.183770, tar: 0.018595 
l0: 0.013838, l1: 0.013331, l2: 0.013761, l3: 0.015094, l4: 0.027466, l5: 0.025940, l6: 0.031725

[epoch:  83/100000, batch:    80/  187, ite: 7748] train loss: 0.183745, tar: 0.018592 
l0: 0.016114, l1: 0.016823, l2: 0.017185, l3: 0.019075, l4: 0.030085, l5: 0.032697, l6: 0.037950

[epoch:  83/100000, batch:    82/  187, ite: 7749] train loss: 0.183737, tar: 0.018591 
l0: 0.007146, l1: 0.008643, l2: 0.008007, l3: 0.007764, l4: 0.023183, l5: 0.022382, l6: 0.017812

[epoch:  83/100000, batch:    84/  187, ite: 7750] train loss: 0.183687, tar: 0.018584 
l0: 0.014792, l1: 0.014485, l2: 0.018972, l3: 0.020371, l4: 0.034328, l5: 0.033071, l6: 0.029043

[epoch:  83/100000, batch:    86/  187, ite: 7751] train loss: 0.183676, tar: 0.018582 
l0: 0.009771, l1: 0.010420, l2: 0.009240, l3: 0.008962, l4: 0.013970, l5: 0.015501, l6: 0.021070

[epoch:  83/100000, batch:    88/  187, ite: 7752] train loss: 0.183622, tar: 0.018577 
l0: 0.011245, l1: 0.010190, l2: 0.013067, l3: 0.014675, l4: 0.019007, l5: 0.018627, l6: 0.020467

[epoch:  83/100000, batch:    90/  187, ite: 7753] train loss: 0.183578, tar: 0.018573 
l0: 0.014566, l1: 0.012862, l2: 0.020827, l3: 0.016059, l4: 0.027219, l5: 0.037005, l6: 0.045906

[epoch:  83/100000, batch:    92/  187, ite: 7754] train loss: 0.183573, tar: 0.018571 
l0: 0.012369, l1: 0.012560, l2: 0.012051, l3: 0.012570, l4: 0.021148, l5: 0.023989, l6: 0.031363

[epoch:  83/100000, batch:    94/  187, ite: 7755] train loss: 0.183540, tar: 0.018567 
l0: 0.007829, l1: 0.007711, l2: 0.008343, l3: 0.009902, l4: 0.013549, l5: 0.014681, l6: 0.019757

[epoch:  83/100000, batch:    96/  187, ite: 7756] train loss: 0.183482, tar: 0.018561 
l0: 0.017357, l1: 0.019468, l2: 0.019541, l3: 0.018427, l4: 0.020769, l5: 0.019626, l6: 0.019199

[epoch:  83/100000, batch:    98/  187, ite: 7757] train loss: 0.183454, tar: 0.018560 
l0: 0.012141, l1: 0.011819, l2: 0.013339, l3: 0.012515, l4: 0.023010, l5: 0.021757, l6: 0.019374

[epoch:  83/100000, batch:   100/  187, ite: 7758] train loss: 0.183415, tar: 0.018557 
l0: 0.009437, l1: 0.009013, l2: 0.012036, l3: 0.012938, l4: 0.021367, l5: 0.017113, l6: 0.012548

[epoch:  83/100000, batch:   102/  187, ite: 7759] train loss: 0.183364, tar: 0.018551 
l0: 0.013917, l1: 0.013905, l2: 0.019297, l3: 0.018208, l4: 0.021260, l5: 0.021950, l6: 0.023163

[epoch:  83/100000, batch:   104/  187, ite: 7760] train loss: 0.183335, tar: 0.018549 
l0: 0.007931, l1: 0.006968, l2: 0.011742, l3: 0.011557, l4: 0.018899, l5: 0.019144, l6: 0.031497

[epoch:  83/100000, batch:   106/  187, ite: 7761] train loss: 0.183292, tar: 0.018543 
l0: 0.009755, l1: 0.009760, l2: 0.011009, l3: 0.010155, l4: 0.026617, l5: 0.028605, l6: 0.019434

[epoch:  83/100000, batch:   108/  187, ite: 7762] train loss: 0.183253, tar: 0.018538 
l0: 0.008587, l1: 0.008910, l2: 0.009366, l3: 0.010020, l4: 0.016442, l5: 0.015158, l6: 0.015191

[epoch:  83/100000, batch:   110/  187, ite: 7763] train loss: 0.183197, tar: 0.018532 
l0: 0.012295, l1: 0.011840, l2: 0.012135, l3: 0.014339, l4: 0.020329, l5: 0.020369, l6: 0.029028

[epoch:  83/100000, batch:   112/  187, ite: 7764] train loss: 0.183161, tar: 0.018529 
l0: 0.012864, l1: 0.012202, l2: 0.014196, l3: 0.014877, l4: 0.028503, l5: 0.025210, l6: 0.030399

[epoch:  83/100000, batch:   114/  187, ite: 7765] train loss: 0.183136, tar: 0.018525 
l0: 0.011410, l1: 0.010656, l2: 0.013820, l3: 0.014404, l4: 0.028260, l5: 0.027739, l6: 0.029113

[epoch:  83/100000, batch:   116/  187, ite: 7766] train loss: 0.183109, tar: 0.018521 
l0: 0.006571, l1: 0.006240, l2: 0.010180, l3: 0.012469, l4: 0.020100, l5: 0.016738, l6: 0.015938

[epoch:  83/100000, batch:   118/  187, ite: 7767] train loss: 0.183055, tar: 0.018515 
l0: 0.008486, l1: 0.008344, l2: 0.009920, l3: 0.010255, l4: 0.021924, l5: 0.019740, l6: 0.017731

[epoch:  83/100000, batch:   120/  187, ite: 7768] train loss: 0.183006, tar: 0.018509 
l0: 0.008666, l1: 0.008750, l2: 0.012852, l3: 0.014354, l4: 0.022657, l5: 0.019831, l6: 0.017804

[epoch:  83/100000, batch:   122/  187, ite: 7769] train loss: 0.182962, tar: 0.018503 
l0: 0.013811, l1: 0.013282, l2: 0.015953, l3: 0.018862, l4: 0.030765, l5: 0.027636, l6: 0.026421

[epoch:  83/100000, batch:   124/  187, ite: 7770] train loss: 0.182941, tar: 0.018501 
l0: 0.007358, l1: 0.007113, l2: 0.008539, l3: 0.010164, l4: 0.023638, l5: 0.024191, l6: 0.023820

[epoch:  83/100000, batch:   126/  187, ite: 7771] train loss: 0.182897, tar: 0.018494 
l0: 0.018392, l1: 0.017498, l2: 0.018926, l3: 0.020829, l4: 0.018056, l5: 0.017281, l6: 0.023089

[epoch:  83/100000, batch:   128/  187, ite: 7772] train loss: 0.182870, tar: 0.018494 
l0: 0.018573, l1: 0.019464, l2: 0.022664, l3: 0.023542, l4: 0.030119, l5: 0.029681, l6: 0.031053

[epoch:  83/100000, batch:   130/  187, ite: 7773] train loss: 0.182865, tar: 0.018494 
l0: 0.011895, l1: 0.012220, l2: 0.013139, l3: 0.013964, l4: 0.023292, l5: 0.021903, l6: 0.031995

[epoch:  83/100000, batch:   132/  187, ite: 7774] train loss: 0.182835, tar: 0.018491 
l0: 0.008741, l1: 0.009860, l2: 0.008709, l3: 0.008158, l4: 0.014971, l5: 0.014590, l6: 0.013532

[epoch:  83/100000, batch:   134/  187, ite: 7775] train loss: 0.182776, tar: 0.018485 
l0: 0.008037, l1: 0.008025, l2: 0.009712, l3: 0.009582, l4: 0.014150, l5: 0.020004, l6: 0.021213

[epoch:  83/100000, batch:   136/  187, ite: 7776] train loss: 0.182724, tar: 0.018479 
l0: 0.007657, l1: 0.012252, l2: 0.010462, l3: 0.007371, l4: 0.025634, l5: 0.028271, l6: 0.033527

[epoch:  83/100000, batch:   138/  187, ite: 7777] train loss: 0.182692, tar: 0.018473 
l0: 0.019824, l1: 0.017942, l2: 0.025747, l3: 0.026729, l4: 0.034403, l5: 0.030606, l6: 0.034176

[epoch:  83/100000, batch:   140/  187, ite: 7778] train loss: 0.182696, tar: 0.018474 
l0: 0.012389, l1: 0.011651, l2: 0.012575, l3: 0.014920, l4: 0.030036, l5: 0.024380, l6: 0.023218

[epoch:  83/100000, batch:   142/  187, ite: 7779] train loss: 0.182665, tar: 0.018471 
l0: 0.014802, l1: 0.016240, l2: 0.018627, l3: 0.018566, l4: 0.029090, l5: 0.023972, l6: 0.020885

[epoch:  83/100000, batch:   144/  187, ite: 7780] train loss: 0.182643, tar: 0.018468 
l0: 0.008817, l1: 0.008734, l2: 0.012264, l3: 0.011875, l4: 0.018380, l5: 0.016464, l6: 0.013819

[epoch:  83/100000, batch:   146/  187, ite: 7781] train loss: 0.182591, tar: 0.018463 
l0: 0.012074, l1: 0.011830, l2: 0.014844, l3: 0.017023, l4: 0.028711, l5: 0.032490, l6: 0.035577

[epoch:  83/100000, batch:   148/  187, ite: 7782] train loss: 0.182574, tar: 0.018459 
l0: 0.027927, l1: 0.028334, l2: 0.030687, l3: 0.029377, l4: 0.039025, l5: 0.045509, l6: 0.039469

[epoch:  83/100000, batch:   150/  187, ite: 7783] train loss: 0.182606, tar: 0.018465 
l0: 0.007352, l1: 0.007957, l2: 0.008598, l3: 0.009975, l4: 0.023315, l5: 0.023651, l6: 0.024878

[epoch:  83/100000, batch:   152/  187, ite: 7784] train loss: 0.182563, tar: 0.018459 
l0: 0.008437, l1: 0.009386, l2: 0.009611, l3: 0.009256, l4: 0.017243, l5: 0.018720, l6: 0.018356

[epoch:  83/100000, batch:   154/  187, ite: 7785] train loss: 0.182512, tar: 0.018453 
l0: 0.018360, l1: 0.020867, l2: 0.018345, l3: 0.016742, l4: 0.025508, l5: 0.021974, l6: 0.021334

[epoch:  83/100000, batch:   156/  187, ite: 7786] train loss: 0.182490, tar: 0.018453 
l0: 0.011476, l1: 0.011104, l2: 0.011441, l3: 0.011459, l4: 0.023085, l5: 0.022412, l6: 0.023066

[epoch:  83/100000, batch:   158/  187, ite: 7787] train loss: 0.182452, tar: 0.018449 
l0: 0.010138, l1: 0.010159, l2: 0.012596, l3: 0.019159, l4: 0.024377, l5: 0.023615, l6: 0.020673

[epoch:  83/100000, batch:   160/  187, ite: 7788] train loss: 0.182417, tar: 0.018444 
l0: 0.017220, l1: 0.018721, l2: 0.018908, l3: 0.017191, l4: 0.027570, l5: 0.021626, l6: 0.032007

[epoch:  83/100000, batch:   162/  187, ite: 7789] train loss: 0.182401, tar: 0.018444 
l0: 0.015528, l1: 0.016001, l2: 0.015359, l3: 0.016454, l4: 0.021010, l5: 0.018228, l6: 0.021056

[epoch:  83/100000, batch:   164/  187, ite: 7790] train loss: 0.182368, tar: 0.018442 
l0: 0.014851, l1: 0.013989, l2: 0.014981, l3: 0.018296, l4: 0.035155, l5: 0.033170, l6: 0.041886

[epoch:  83/100000, batch:   166/  187, ite: 7791] train loss: 0.182362, tar: 0.018440 
l0: 0.010491, l1: 0.011627, l2: 0.011564, l3: 0.012579, l4: 0.013503, l5: 0.016864, l6: 0.018662

[epoch:  83/100000, batch:   168/  187, ite: 7792] train loss: 0.182314, tar: 0.018436 
l0: 0.014186, l1: 0.013949, l2: 0.015468, l3: 0.014752, l4: 0.024057, l5: 0.024428, l6: 0.021604

[epoch:  83/100000, batch:   170/  187, ite: 7793] train loss: 0.182284, tar: 0.018433 
l0: 0.015263, l1: 0.014872, l2: 0.020972, l3: 0.025196, l4: 0.034211, l5: 0.031841, l6: 0.028067

[epoch:  83/100000, batch:   172/  187, ite: 7794] train loss: 0.182277, tar: 0.018431 
l0: 0.007933, l1: 0.008970, l2: 0.009115, l3: 0.009645, l4: 0.023886, l5: 0.022399, l6: 0.016717

[epoch:  83/100000, batch:   174/  187, ite: 7795] train loss: 0.182231, tar: 0.018426 
l0: 0.013195, l1: 0.013358, l2: 0.015011, l3: 0.015714, l4: 0.020573, l5: 0.020050, l6: 0.023000

[epoch:  83/100000, batch:   176/  187, ite: 7796] train loss: 0.182196, tar: 0.018423 
l0: 0.016744, l1: 0.016387, l2: 0.016465, l3: 0.016569, l4: 0.033517, l5: 0.034165, l6: 0.029024

[epoch:  83/100000, batch:   178/  187, ite: 7797] train loss: 0.182186, tar: 0.018422 
l0: 0.011146, l1: 0.010540, l2: 0.015601, l3: 0.017693, l4: 0.036695, l5: 0.032043, l6: 0.031967

[epoch:  83/100000, batch:   180/  187, ite: 7798] train loss: 0.182171, tar: 0.018418 
l0: 0.007619, l1: 0.007739, l2: 0.008920, l3: 0.009205, l4: 0.015968, l5: 0.012346, l6: 0.013093

[epoch:  83/100000, batch:   182/  187, ite: 7799] train loss: 0.182111, tar: 0.018412 
l0: 0.010967, l1: 0.011258, l2: 0.012697, l3: 0.014329, l4: 0.023385, l5: 0.019866, l6: 0.022968

[epoch:  83/100000, batch:   184/  187, ite: 7800] train loss: 0.182074, tar: 0.018408 
l0: 0.013285, l1: 0.012876, l2: 0.019282, l3: 0.019509, l4: 0.031203, l5: 0.033249, l6: 0.021856

[epoch:  83/100000, batch:   186/  187, ite: 7801] train loss: 0.182057, tar: 0.018405 
l0: 0.015319, l1: 0.016685, l2: 0.017800, l3: 0.016417, l4: 0.019580, l5: 0.019180, l6: 0.021239

[epoch:  83/100000, batch:   188/  187, ite: 7802] train loss: 0.182026, tar: 0.018403 
l0: 0.008535, l1: 0.008600, l2: 0.010703, l3: 0.013348, l4: 0.017102, l5: 0.015839, l6: 0.019662

[epoch:  84/100000, batch:     2/  187, ite: 7803] train loss: 0.181977, tar: 0.018398 
l0: 0.007196, l1: 0.007311, l2: 0.007507, l3: 0.008348, l4: 0.018769, l5: 0.019012, l6: 0.017737

[epoch:  84/100000, batch:     4/  187, ite: 7804] train loss: 0.181924, tar: 0.018391 
l0: 0.004372, l1: 0.004121, l2: 0.004427, l3: 0.005925, l4: 0.007249, l5: 0.007072, l6: 0.009151

[epoch:  84/100000, batch:     6/  187, ite: 7805] train loss: 0.181847, tar: 0.018384 
l0: 0.027813, l1: 0.027123, l2: 0.027415, l3: 0.033073, l4: 0.028801, l5: 0.026451, l6: 0.037309

[epoch:  84/100000, batch:     8/  187, ite: 7806] train loss: 0.181861, tar: 0.018389 
l0: 0.007660, l1: 0.008064, l2: 0.010141, l3: 0.009397, l4: 0.021493, l5: 0.016555, l6: 0.016152

[epoch:  84/100000, batch:    10/  187, ite: 7807] train loss: 0.181810, tar: 0.018383 
l0: 0.006139, l1: 0.006844, l2: 0.007280, l3: 0.005994, l4: 0.012687, l5: 0.012055, l6: 0.012148

[epoch:  84/100000, batch:    12/  187, ite: 7808] train loss: 0.181744, tar: 0.018376 
l0: 0.005603, l1: 0.006879, l2: 0.005055, l3: 0.008484, l4: 0.015008, l5: 0.016897, l6: 0.017361

[epoch:  84/100000, batch:    14/  187, ite: 7809] train loss: 0.181686, tar: 0.018369 
l0: 0.009240, l1: 0.009534, l2: 0.011770, l3: 0.010995, l4: 0.025227, l5: 0.025034, l6: 0.034064

[epoch:  84/100000, batch:    16/  187, ite: 7810] train loss: 0.181655, tar: 0.018364 
l0: 0.011422, l1: 0.011798, l2: 0.014549, l3: 0.017052, l4: 0.027160, l5: 0.022901, l6: 0.023101

[epoch:  84/100000, batch:    18/  187, ite: 7811] train loss: 0.181625, tar: 0.018360 
l0: 0.009124, l1: 0.008475, l2: 0.009024, l3: 0.010027, l4: 0.014818, l5: 0.016173, l6: 0.021202

[epoch:  84/100000, batch:    20/  187, ite: 7812] train loss: 0.181574, tar: 0.018355 
l0: 0.005490, l1: 0.005365, l2: 0.008125, l3: 0.007973, l4: 0.021387, l5: 0.018710, l6: 0.016545

[epoch:  84/100000, batch:    22/  187, ite: 7813] train loss: 0.181520, tar: 0.018348 
l0: 0.017531, l1: 0.016581, l2: 0.029648, l3: 0.024600, l4: 0.030532, l5: 0.025059, l6: 0.024198

[epoch:  84/100000, batch:    24/  187, ite: 7814] train loss: 0.181512, tar: 0.018348 
l0: 0.009526, l1: 0.009125, l2: 0.010237, l3: 0.011310, l4: 0.021170, l5: 0.021488, l6: 0.023199

[epoch:  84/100000, batch:    26/  187, ite: 7815] train loss: 0.181471, tar: 0.018343 
l0: 0.015585, l1: 0.016425, l2: 0.016762, l3: 0.019710, l4: 0.038468, l5: 0.027792, l6: 0.030588

[epoch:  84/100000, batch:    28/  187, ite: 7816] train loss: 0.181462, tar: 0.018341 
l0: 0.012169, l1: 0.012584, l2: 0.011813, l3: 0.013384, l4: 0.023333, l5: 0.023653, l6: 0.026339

[epoch:  84/100000, batch:    30/  187, ite: 7817] train loss: 0.181430, tar: 0.018338 
l0: 0.015215, l1: 0.015217, l2: 0.017784, l3: 0.016486, l4: 0.020438, l5: 0.020313, l6: 0.021312

[epoch:  84/100000, batch:    32/  187, ite: 7818] train loss: 0.181400, tar: 0.018336 
l0: 0.011223, l1: 0.011261, l2: 0.015221, l3: 0.014640, l4: 0.022755, l5: 0.021236, l6: 0.023292

[epoch:  84/100000, batch:    34/  187, ite: 7819] train loss: 0.181366, tar: 0.018332 
l0: 0.012725, l1: 0.011885, l2: 0.015584, l3: 0.016572, l4: 0.019332, l5: 0.018117, l6: 0.019810

[epoch:  84/100000, batch:    36/  187, ite: 7820] train loss: 0.181329, tar: 0.018329 
l0: 0.010126, l1: 0.011785, l2: 0.010540, l3: 0.011609, l4: 0.021403, l5: 0.019024, l6: 0.016046

[epoch:  84/100000, batch:    38/  187, ite: 7821] train loss: 0.181285, tar: 0.018325 
l0: 0.007556, l1: 0.008274, l2: 0.011028, l3: 0.012531, l4: 0.014298, l5: 0.012452, l6: 0.015829

[epoch:  84/100000, batch:    40/  187, ite: 7822] train loss: 0.181230, tar: 0.018319 
l0: 0.010130, l1: 0.010587, l2: 0.010914, l3: 0.010316, l4: 0.019561, l5: 0.020344, l6: 0.020568

[epoch:  84/100000, batch:    42/  187, ite: 7823] train loss: 0.181187, tar: 0.018314 
l0: 0.005930, l1: 0.005460, l2: 0.009833, l3: 0.009079, l4: 0.015375, l5: 0.019114, l6: 0.017297

[epoch:  84/100000, batch:    44/  187, ite: 7824] train loss: 0.181132, tar: 0.018307 
l0: 0.006806, l1: 0.006548, l2: 0.007618, l3: 0.007129, l4: 0.020252, l5: 0.023539, l6: 0.021236

[epoch:  84/100000, batch:    46/  187, ite: 7825] train loss: 0.181084, tar: 0.018301 
l0: 0.009817, l1: 0.009259, l2: 0.010737, l3: 0.011030, l4: 0.019845, l5: 0.019506, l6: 0.019765

[epoch:  84/100000, batch:    48/  187, ite: 7826] train loss: 0.181040, tar: 0.018296 
l0: 0.008785, l1: 0.008707, l2: 0.010219, l3: 0.013335, l4: 0.016320, l5: 0.017129, l6: 0.015320

[epoch:  84/100000, batch:    50/  187, ite: 7827] train loss: 0.180990, tar: 0.018291 
l0: 0.012525, l1: 0.013780, l2: 0.011778, l3: 0.011481, l4: 0.026221, l5: 0.023207, l6: 0.025516

[epoch:  84/100000, batch:    52/  187, ite: 7828] train loss: 0.180959, tar: 0.018288 
l0: 0.007025, l1: 0.007441, l2: 0.008781, l3: 0.009249, l4: 0.016057, l5: 0.013551, l6: 0.015777

[epoch:  84/100000, batch:    54/  187, ite: 7829] train loss: 0.180903, tar: 0.018282 
l0: 0.012967, l1: 0.012838, l2: 0.016473, l3: 0.014154, l4: 0.030785, l5: 0.033025, l6: 0.027479

[epoch:  84/100000, batch:    56/  187, ite: 7830] train loss: 0.180885, tar: 0.018279 
l0: 0.011662, l1: 0.011368, l2: 0.014071, l3: 0.017314, l4: 0.019103, l5: 0.016714, l6: 0.017356

[epoch:  84/100000, batch:    58/  187, ite: 7831] train loss: 0.180844, tar: 0.018275 
l0: 0.019940, l1: 0.021908, l2: 0.021934, l3: 0.021637, l4: 0.030045, l5: 0.029007, l6: 0.026666

[epoch:  84/100000, batch:    60/  187, ite: 7832] train loss: 0.180839, tar: 0.018276 
l0: 0.009466, l1: 0.009943, l2: 0.010596, l3: 0.012809, l4: 0.028210, l5: 0.022942, l6: 0.022062

[epoch:  84/100000, batch:    62/  187, ite: 7833] train loss: 0.180804, tar: 0.018271 
l0: 0.012351, l1: 0.013803, l2: 0.012553, l3: 0.010965, l4: 0.023528, l5: 0.014988, l6: 0.015009

[epoch:  84/100000, batch:    64/  187, ite: 7834] train loss: 0.180762, tar: 0.018268 
l0: 0.011409, l1: 0.010795, l2: 0.014073, l3: 0.015763, l4: 0.032342, l5: 0.032045, l6: 0.023635

[epoch:  84/100000, batch:    66/  187, ite: 7835] train loss: 0.180739, tar: 0.018264 
l0: 0.010718, l1: 0.012036, l2: 0.013088, l3: 0.012702, l4: 0.019503, l5: 0.023151, l6: 0.020689

[epoch:  84/100000, batch:    68/  187, ite: 7836] train loss: 0.180702, tar: 0.018260 
l0: 0.007950, l1: 0.007501, l2: 0.009887, l3: 0.010384, l4: 0.014073, l5: 0.013962, l6: 0.017857

[epoch:  84/100000, batch:    70/  187, ite: 7837] train loss: 0.180648, tar: 0.018255 
l0: 0.011285, l1: 0.011367, l2: 0.011728, l3: 0.012023, l4: 0.018351, l5: 0.016760, l6: 0.015655

[epoch:  84/100000, batch:    72/  187, ite: 7838] train loss: 0.180602, tar: 0.018251 
l0: 0.010079, l1: 0.010487, l2: 0.012741, l3: 0.012868, l4: 0.015758, l5: 0.016106, l6: 0.020608

[epoch:  84/100000, batch:    74/  187, ite: 7839] train loss: 0.180558, tar: 0.018247 
l0: 0.011309, l1: 0.010880, l2: 0.011369, l3: 0.012403, l4: 0.032160, l5: 0.028670, l6: 0.022879

[epoch:  84/100000, batch:    76/  187, ite: 7840] train loss: 0.180530, tar: 0.018243 
l0: 0.015733, l1: 0.016086, l2: 0.017984, l3: 0.017652, l4: 0.019495, l5: 0.019835, l6: 0.025972

[epoch:  84/100000, batch:    78/  187, ite: 7841] train loss: 0.180504, tar: 0.018241 
l0: 0.020583, l1: 0.021260, l2: 0.027573, l3: 0.027298, l4: 0.034283, l5: 0.028461, l6: 0.030056

[epoch:  84/100000, batch:    80/  187, ite: 7842] train loss: 0.180509, tar: 0.018243 
l0: 0.016536, l1: 0.016384, l2: 0.014603, l3: 0.014959, l4: 0.022130, l5: 0.028092, l6: 0.037659

[epoch:  84/100000, batch:    82/  187, ite: 7843] train loss: 0.180493, tar: 0.018242 
l0: 0.011619, l1: 0.012931, l2: 0.012362, l3: 0.012418, l4: 0.022937, l5: 0.022421, l6: 0.025517

[epoch:  84/100000, batch:    84/  187, ite: 7844] train loss: 0.180460, tar: 0.018238 
l0: 0.009121, l1: 0.008942, l2: 0.011695, l3: 0.011223, l4: 0.033114, l5: 0.033850, l6: 0.034204

[epoch:  84/100000, batch:    86/  187, ite: 7845] train loss: 0.180439, tar: 0.018233 
l0: 0.010318, l1: 0.010750, l2: 0.010003, l3: 0.010046, l4: 0.019650, l5: 0.019591, l6: 0.022740

[epoch:  84/100000, batch:    88/  187, ite: 7846] train loss: 0.180397, tar: 0.018229 
l0: 0.014482, l1: 0.014750, l2: 0.016472, l3: 0.023478, l4: 0.029175, l5: 0.026551, l6: 0.028514

[epoch:  84/100000, batch:    90/  187, ite: 7847] train loss: 0.180383, tar: 0.018227 
l0: 0.010786, l1: 0.011247, l2: 0.010956, l3: 0.012169, l4: 0.018306, l5: 0.018784, l6: 0.021911

[epoch:  84/100000, batch:    92/  187, ite: 7848] train loss: 0.180342, tar: 0.018223 
l0: 0.013351, l1: 0.013430, l2: 0.012494, l3: 0.010840, l4: 0.032424, l5: 0.037117, l6: 0.046329

[epoch:  84/100000, batch:    94/  187, ite: 7849] train loss: 0.180334, tar: 0.018220 
l0: 0.007065, l1: 0.007149, l2: 0.011040, l3: 0.012195, l4: 0.018464, l5: 0.015632, l6: 0.017621

[epoch:  84/100000, batch:    96/  187, ite: 7850] train loss: 0.180285, tar: 0.018214 
l0: 0.025271, l1: 0.025106, l2: 0.035433, l3: 0.027283, l4: 0.031834, l5: 0.033141, l6: 0.035902

[epoch:  84/100000, batch:    98/  187, ite: 7851] train loss: 0.180303, tar: 0.018218 
l0: 0.012795, l1: 0.012051, l2: 0.014640, l3: 0.015037, l4: 0.015387, l5: 0.017188, l6: 0.020341

[epoch:  84/100000, batch:   100/  187, ite: 7852] train loss: 0.180263, tar: 0.018215 
l0: 0.007923, l1: 0.007579, l2: 0.009559, l3: 0.011566, l4: 0.022138, l5: 0.018712, l6: 0.019437

[epoch:  84/100000, batch:   102/  187, ite: 7853] train loss: 0.180218, tar: 0.018210 
l0: 0.010509, l1: 0.009906, l2: 0.013956, l3: 0.014888, l4: 0.021508, l5: 0.019019, l6: 0.020584

[epoch:  84/100000, batch:   104/  187, ite: 7854] train loss: 0.180181, tar: 0.018205 
l0: 0.011527, l1: 0.010021, l2: 0.011712, l3: 0.011221, l4: 0.015117, l5: 0.021760, l6: 0.025789

[epoch:  84/100000, batch:   106/  187, ite: 7855] train loss: 0.180141, tar: 0.018202 
l0: 0.019317, l1: 0.017850, l2: 0.020279, l3: 0.024032, l4: 0.038988, l5: 0.034772, l6: 0.044101

[epoch:  84/100000, batch:   108/  187, ite: 7856] train loss: 0.180152, tar: 0.018202 
l0: 0.015125, l1: 0.015199, l2: 0.013437, l3: 0.015546, l4: 0.024215, l5: 0.020088, l6: 0.031239

[epoch:  84/100000, batch:   110/  187, ite: 7857] train loss: 0.180127, tar: 0.018201 
l0: 0.025018, l1: 0.023271, l2: 0.026248, l3: 0.029496, l4: 0.053605, l5: 0.047637, l6: 0.084190

[epoch:  84/100000, batch:   112/  187, ite: 7858] train loss: 0.180186, tar: 0.018204 
l0: 0.007442, l1: 0.008249, l2: 0.008897, l3: 0.008566, l4: 0.014738, l5: 0.012796, l6: 0.013962

[epoch:  84/100000, batch:   114/  187, ite: 7859] train loss: 0.180129, tar: 0.018199 
l0: 0.009314, l1: 0.011065, l2: 0.011454, l3: 0.011246, l4: 0.017914, l5: 0.015337, l6: 0.018648

[epoch:  84/100000, batch:   116/  187, ite: 7860] train loss: 0.180084, tar: 0.018194 
l0: 0.009756, l1: 0.010121, l2: 0.011406, l3: 0.012672, l4: 0.018499, l5: 0.024945, l6: 0.022744

[epoch:  84/100000, batch:   118/  187, ite: 7861] train loss: 0.180046, tar: 0.018189 
l0: 0.014983, l1: 0.013838, l2: 0.021619, l3: 0.021386, l4: 0.025551, l5: 0.024170, l6: 0.024670

[epoch:  84/100000, batch:   120/  187, ite: 7862] train loss: 0.180028, tar: 0.018188 
l0: 0.014846, l1: 0.013666, l2: 0.023256, l3: 0.026922, l4: 0.023290, l5: 0.020818, l6: 0.017076

[epoch:  84/100000, batch:   122/  187, ite: 7863] train loss: 0.180006, tar: 0.018186 
l0: 0.008461, l1: 0.010436, l2: 0.008939, l3: 0.008346, l4: 0.014637, l5: 0.011924, l6: 0.011669

[epoch:  84/100000, batch:   124/  187, ite: 7864] train loss: 0.179950, tar: 0.018181 
l0: 0.013781, l1: 0.013944, l2: 0.016981, l3: 0.017660, l4: 0.033858, l5: 0.033307, l6: 0.024339

[epoch:  84/100000, batch:   126/  187, ite: 7865] train loss: 0.179936, tar: 0.018178 
l0: 0.024533, l1: 0.022679, l2: 0.029802, l3: 0.028230, l4: 0.026271, l5: 0.029313, l6: 0.036269

[epoch:  84/100000, batch:   128/  187, ite: 7866] train loss: 0.179945, tar: 0.018182 
l0: 0.009714, l1: 0.009446, l2: 0.011834, l3: 0.013924, l4: 0.026422, l5: 0.022436, l6: 0.031984

[epoch:  84/100000, batch:   130/  187, ite: 7867] train loss: 0.179916, tar: 0.018177 
l0: 0.008350, l1: 0.008034, l2: 0.011188, l3: 0.014592, l4: 0.017103, l5: 0.017163, l6: 0.019755

[epoch:  84/100000, batch:   132/  187, ite: 7868] train loss: 0.179871, tar: 0.018172 
l0: 0.010458, l1: 0.009837, l2: 0.009178, l3: 0.011549, l4: 0.019334, l5: 0.023049, l6: 0.029037

[epoch:  84/100000, batch:   134/  187, ite: 7869] train loss: 0.179835, tar: 0.018168 
l0: 0.006980, l1: 0.006931, l2: 0.007733, l3: 0.009103, l4: 0.013685, l5: 0.015167, l6: 0.019713

[epoch:  84/100000, batch:   136/  187, ite: 7870] train loss: 0.179781, tar: 0.018162 
l0: 0.009165, l1: 0.009745, l2: 0.012563, l3: 0.009474, l4: 0.014942, l5: 0.015391, l6: 0.014519

[epoch:  84/100000, batch:   138/  187, ite: 7871] train loss: 0.179731, tar: 0.018157 
l0: 0.019959, l1: 0.020382, l2: 0.019315, l3: 0.016847, l4: 0.028548, l5: 0.028935, l6: 0.031937

[epoch:  84/100000, batch:   140/  187, ite: 7872] train loss: 0.179724, tar: 0.018158 
l0: 0.011984, l1: 0.013233, l2: 0.015052, l3: 0.013591, l4: 0.013152, l5: 0.013748, l6: 0.017310

[epoch:  84/100000, batch:   142/  187, ite: 7873] train loss: 0.179680, tar: 0.018155 
l0: 0.012378, l1: 0.013645, l2: 0.014878, l3: 0.013771, l4: 0.018803, l5: 0.017623, l6: 0.019261

[epoch:  84/100000, batch:   144/  187, ite: 7874] train loss: 0.179643, tar: 0.018151 
l0: 0.005496, l1: 0.005599, l2: 0.006053, l3: 0.007515, l4: 0.009162, l5: 0.010739, l6: 0.013964

[epoch:  84/100000, batch:   146/  187, ite: 7875] train loss: 0.179578, tar: 0.018145 
l0: 0.010781, l1: 0.011003, l2: 0.010375, l3: 0.012572, l4: 0.015965, l5: 0.019154, l6: 0.023841

[epoch:  84/100000, batch:   148/  187, ite: 7876] train loss: 0.179538, tar: 0.018141 
l0: 0.008084, l1: 0.008638, l2: 0.006933, l3: 0.008427, l4: 0.018760, l5: 0.016853, l6: 0.018982

[epoch:  84/100000, batch:   150/  187, ite: 7877] train loss: 0.179489, tar: 0.018135 
l0: 0.009443, l1: 0.010181, l2: 0.008430, l3: 0.008871, l4: 0.012818, l5: 0.013128, l6: 0.021371

[epoch:  84/100000, batch:   152/  187, ite: 7878] train loss: 0.179438, tar: 0.018131 
l0: 0.014980, l1: 0.014566, l2: 0.018169, l3: 0.019877, l4: 0.032468, l5: 0.028241, l6: 0.031626

[epoch:  84/100000, batch:   154/  187, ite: 7879] train loss: 0.179427, tar: 0.018129 
l0: 0.015062, l1: 0.016733, l2: 0.015365, l3: 0.014361, l4: 0.026333, l5: 0.025402, l6: 0.031889

[epoch:  84/100000, batch:   156/  187, ite: 7880] train loss: 0.179409, tar: 0.018127 
l0: 0.011189, l1: 0.011565, l2: 0.013318, l3: 0.014569, l4: 0.019362, l5: 0.018037, l6: 0.023300

[epoch:  84/100000, batch:   158/  187, ite: 7881] train loss: 0.179373, tar: 0.018124 
l0: 0.013572, l1: 0.012874, l2: 0.012715, l3: 0.015550, l4: 0.022610, l5: 0.023033, l6: 0.026301

[epoch:  84/100000, batch:   160/  187, ite: 7882] train loss: 0.179345, tar: 0.018121 
l0: 0.008399, l1: 0.008547, l2: 0.012919, l3: 0.012210, l4: 0.020624, l5: 0.016437, l6: 0.013741

[epoch:  84/100000, batch:   162/  187, ite: 7883] train loss: 0.179299, tar: 0.018116 
l0: 0.007676, l1: 0.007903, l2: 0.009280, l3: 0.008830, l4: 0.014856, l5: 0.014403, l6: 0.018343

[epoch:  84/100000, batch:   164/  187, ite: 7884] train loss: 0.179247, tar: 0.018111 
l0: 0.014913, l1: 0.016050, l2: 0.015433, l3: 0.014415, l4: 0.018407, l5: 0.018222, l6: 0.017781

[epoch:  84/100000, batch:   166/  187, ite: 7885] train loss: 0.179213, tar: 0.018109 
l0: 0.006850, l1: 0.008939, l2: 0.007300, l3: 0.007399, l4: 0.030114, l5: 0.030031, l6: 0.026741

[epoch:  84/100000, batch:   168/  187, ite: 7886] train loss: 0.179180, tar: 0.018103 
l0: 0.008532, l1: 0.010060, l2: 0.008609, l3: 0.009038, l4: 0.014833, l5: 0.013589, l6: 0.015121

[epoch:  84/100000, batch:   170/  187, ite: 7887] train loss: 0.179128, tar: 0.018098 
l0: 0.013683, l1: 0.013901, l2: 0.017300, l3: 0.015504, l4: 0.022950, l5: 0.020098, l6: 0.020840

[epoch:  84/100000, batch:   172/  187, ite: 7888] train loss: 0.179099, tar: 0.018096 
l0: 0.007326, l1: 0.007456, l2: 0.010651, l3: 0.008871, l4: 0.015709, l5: 0.014876, l6: 0.015543

[epoch:  84/100000, batch:   174/  187, ite: 7889] train loss: 0.179046, tar: 0.018090 
l0: 0.014691, l1: 0.013927, l2: 0.013206, l3: 0.014467, l4: 0.024068, l5: 0.030074, l6: 0.024973

[epoch:  84/100000, batch:   176/  187, ite: 7890] train loss: 0.179023, tar: 0.018088 
l0: 0.013759, l1: 0.012942, l2: 0.015508, l3: 0.018093, l4: 0.031316, l5: 0.031800, l6: 0.031932

[epoch:  84/100000, batch:   178/  187, ite: 7891] train loss: 0.179011, tar: 0.018086 
l0: 0.008891, l1: 0.008822, l2: 0.013392, l3: 0.012761, l4: 0.014606, l5: 0.015857, l6: 0.015960

[epoch:  84/100000, batch:   180/  187, ite: 7892] train loss: 0.178964, tar: 0.018081 
l0: 0.011744, l1: 0.011871, l2: 0.016361, l3: 0.015368, l4: 0.025703, l5: 0.025994, l6: 0.025542

[epoch:  84/100000, batch:   182/  187, ite: 7893] train loss: 0.178939, tar: 0.018078 
l0: 0.010390, l1: 0.011512, l2: 0.010790, l3: 0.011529, l4: 0.021053, l5: 0.020601, l6: 0.018783

[epoch:  84/100000, batch:   184/  187, ite: 7894] train loss: 0.178900, tar: 0.018074 
l0: 0.017163, l1: 0.018340, l2: 0.018606, l3: 0.017377, l4: 0.028447, l5: 0.026233, l6: 0.022096

[epoch:  84/100000, batch:   186/  187, ite: 7895] train loss: 0.178884, tar: 0.018073 
l0: 0.012063, l1: 0.013906, l2: 0.007674, l3: 0.007303, l4: 0.015142, l5: 0.018793, l6: 0.018429

[epoch:  84/100000, batch:   188/  187, ite: 7896] train loss: 0.178839, tar: 0.018070 
l0: 0.009956, l1: 0.008722, l2: 0.013504, l3: 0.013872, l4: 0.037532, l5: 0.032528, l6: 0.033490

[epoch:  85/100000, batch:     2/  187, ite: 7897] train loss: 0.178823, tar: 0.018066 
l0: 0.008775, l1: 0.008857, l2: 0.011722, l3: 0.012513, l4: 0.024221, l5: 0.027599, l6: 0.021156

[epoch:  85/100000, batch:     4/  187, ite: 7898] train loss: 0.178790, tar: 0.018061 
l0: 0.015097, l1: 0.015110, l2: 0.015137, l3: 0.016655, l4: 0.020496, l5: 0.024189, l6: 0.025717

[epoch:  85/100000, batch:     6/  187, ite: 7899] train loss: 0.178765, tar: 0.018059 
l0: 0.007030, l1: 0.006671, l2: 0.009644, l3: 0.010306, l4: 0.013994, l5: 0.017896, l6: 0.023215

[epoch:  85/100000, batch:     8/  187, ite: 7900] train loss: 0.178718, tar: 0.018053 
l0: 0.006125, l1: 0.007071, l2: 0.006855, l3: 0.006929, l4: 0.011445, l5: 0.009185, l6: 0.008320

[epoch:  85/100000, batch:    10/  187, ite: 7901] train loss: 0.178653, tar: 0.018047 
l0: 0.009146, l1: 0.009486, l2: 0.009907, l3: 0.008896, l4: 0.012627, l5: 0.012821, l6: 0.016414

[epoch:  85/100000, batch:    12/  187, ite: 7902] train loss: 0.178601, tar: 0.018042 
l0: 0.008064, l1: 0.008829, l2: 0.008322, l3: 0.008505, l4: 0.017593, l5: 0.017870, l6: 0.017685

[epoch:  85/100000, batch:    14/  187, ite: 7903] train loss: 0.178553, tar: 0.018037 
l0: 0.006307, l1: 0.006839, l2: 0.009455, l3: 0.006878, l4: 0.013320, l5: 0.012120, l6: 0.011963

[epoch:  85/100000, batch:    16/  187, ite: 7904] train loss: 0.178494, tar: 0.018031 
l0: 0.007839, l1: 0.008300, l2: 0.007885, l3: 0.009207, l4: 0.020751, l5: 0.016360, l6: 0.017767

[epoch:  85/100000, batch:    18/  187, ite: 7905] train loss: 0.178447, tar: 0.018026 
l0: 0.008337, l1: 0.007766, l2: 0.009267, l3: 0.011913, l4: 0.025546, l5: 0.025350, l6: 0.022549

[epoch:  85/100000, batch:    20/  187, ite: 7906] train loss: 0.178411, tar: 0.018021 
l0: 0.010228, l1: 0.011125, l2: 0.012181, l3: 0.010432, l4: 0.017561, l5: 0.015020, l6: 0.015842

[epoch:  85/100000, batch:    22/  187, ite: 7907] train loss: 0.178366, tar: 0.018016 
l0: 0.011551, l1: 0.011214, l2: 0.013464, l3: 0.014355, l4: 0.022558, l5: 0.022441, l6: 0.025517

[epoch:  85/100000, batch:    24/  187, ite: 7908] train loss: 0.178336, tar: 0.018013 
l0: 0.007941, l1: 0.007804, l2: 0.010848, l3: 0.008386, l4: 0.015024, l5: 0.014678, l6: 0.012625

[epoch:  85/100000, batch:    26/  187, ite: 7909] train loss: 0.178283, tar: 0.018008 
l0: 0.011033, l1: 0.012474, l2: 0.010561, l3: 0.011232, l4: 0.021625, l5: 0.020424, l6: 0.021697

[epoch:  85/100000, batch:    28/  187, ite: 7910] train loss: 0.178247, tar: 0.018004 
l0: 0.009050, l1: 0.009945, l2: 0.010261, l3: 0.009313, l4: 0.017778, l5: 0.013957, l6: 0.014845

[epoch:  85/100000, batch:    30/  187, ite: 7911] train loss: 0.178198, tar: 0.017999 
l0: 0.016847, l1: 0.016701, l2: 0.018387, l3: 0.019004, l4: 0.039280, l5: 0.036333, l6: 0.035312

[epoch:  85/100000, batch:    32/  187, ite: 7912] train loss: 0.178200, tar: 0.017999 
l0: 0.013111, l1: 0.014624, l2: 0.015634, l3: 0.010147, l4: 0.020456, l5: 0.017366, l6: 0.015331

[epoch:  85/100000, batch:    34/  187, ite: 7913] train loss: 0.178163, tar: 0.017996 
l0: 0.017784, l1: 0.017437, l2: 0.021191, l3: 0.022344, l4: 0.033243, l5: 0.033579, l6: 0.031559

[epoch:  85/100000, batch:    36/  187, ite: 7914] train loss: 0.178162, tar: 0.017996 
l0: 0.016242, l1: 0.016416, l2: 0.014777, l3: 0.016771, l4: 0.027572, l5: 0.023414, l6: 0.035311

[epoch:  85/100000, batch:    38/  187, ite: 7915] train loss: 0.178148, tar: 0.017995 
l0: 0.017452, l1: 0.018122, l2: 0.017186, l3: 0.017619, l4: 0.021133, l5: 0.018819, l6: 0.024292

[epoch:  85/100000, batch:    40/  187, ite: 7916] train loss: 0.178125, tar: 0.017995 
l0: 0.007019, l1: 0.008050, l2: 0.007036, l3: 0.007916, l4: 0.010086, l5: 0.009316, l6: 0.014128

[epoch:  85/100000, batch:    42/  187, ite: 7917] train loss: 0.178065, tar: 0.017989 
l0: 0.006771, l1: 0.006909, l2: 0.007420, l3: 0.008826, l4: 0.012949, l5: 0.011136, l6: 0.010647

[epoch:  85/100000, batch:    44/  187, ite: 7918] train loss: 0.178006, tar: 0.017983 
l0: 0.014344, l1: 0.014668, l2: 0.012318, l3: 0.014901, l4: 0.017532, l5: 0.015675, l6: 0.017218

[epoch:  85/100000, batch:    46/  187, ite: 7919] train loss: 0.177969, tar: 0.017982 
l0: 0.016265, l1: 0.017264, l2: 0.018407, l3: 0.018057, l4: 0.025639, l5: 0.022309, l6: 0.024449

[epoch:  85/100000, batch:    48/  187, ite: 7920] train loss: 0.177950, tar: 0.017981 
l0: 0.012353, l1: 0.012276, l2: 0.016537, l3: 0.013705, l4: 0.020844, l5: 0.024283, l6: 0.022847

[epoch:  85/100000, batch:    50/  187, ite: 7921] train loss: 0.177922, tar: 0.017978 
l0: 0.008765, l1: 0.009177, l2: 0.008310, l3: 0.008638, l4: 0.037133, l5: 0.037267, l6: 0.031772

[epoch:  85/100000, batch:    52/  187, ite: 7922] train loss: 0.177903, tar: 0.017973 
l0: 0.011277, l1: 0.012487, l2: 0.010716, l3: 0.011333, l4: 0.016935, l5: 0.016376, l6: 0.017674

[epoch:  85/100000, batch:    54/  187, ite: 7923] train loss: 0.177860, tar: 0.017969 
l0: 0.009607, l1: 0.010280, l2: 0.010265, l3: 0.010683, l4: 0.021194, l5: 0.020281, l6: 0.023866

[epoch:  85/100000, batch:    56/  187, ite: 7924] train loss: 0.177823, tar: 0.017965 
l0: 0.008963, l1: 0.011028, l2: 0.010337, l3: 0.008897, l4: 0.017431, l5: 0.012223, l6: 0.008610

[epoch:  85/100000, batch:    58/  187, ite: 7925] train loss: 0.177771, tar: 0.017960 
l0: 0.005777, l1: 0.006244, l2: 0.007189, l3: 0.006169, l4: 0.010169, l5: 0.009084, l6: 0.013527

[epoch:  85/100000, batch:    60/  187, ite: 7926] train loss: 0.177709, tar: 0.017954 
l0: 0.010384, l1: 0.010610, l2: 0.010880, l3: 0.011186, l4: 0.020690, l5: 0.016660, l6: 0.020115

[epoch:  85/100000, batch:    62/  187, ite: 7927] train loss: 0.177669, tar: 0.017950 
l0: 0.013907, l1: 0.013531, l2: 0.019258, l3: 0.017932, l4: 0.014844, l5: 0.015116, l6: 0.016955

[epoch:  85/100000, batch:    64/  187, ite: 7928] train loss: 0.177635, tar: 0.017948 
l0: 0.010967, l1: 0.011800, l2: 0.009630, l3: 0.009984, l4: 0.015266, l5: 0.012107, l6: 0.013178

[epoch:  85/100000, batch:    66/  187, ite: 7929] train loss: 0.177585, tar: 0.017944 
l0: 0.013185, l1: 0.015058, l2: 0.015563, l3: 0.013292, l4: 0.017484, l5: 0.015428, l6: 0.015602

[epoch:  85/100000, batch:    68/  187, ite: 7930] train loss: 0.177548, tar: 0.017942 
l0: 0.016346, l1: 0.018945, l2: 0.019159, l3: 0.018436, l4: 0.027014, l5: 0.029954, l6: 0.032206

[epoch:  85/100000, batch:    70/  187, ite: 7931] train loss: 0.177540, tar: 0.017941 
l0: 0.019051, l1: 0.019717, l2: 0.027060, l3: 0.025611, l4: 0.039217, l5: 0.037683, l6: 0.025396

[epoch:  85/100000, batch:    72/  187, ite: 7932] train loss: 0.177549, tar: 0.017942 
l0: 0.009774, l1: 0.009460, l2: 0.012255, l3: 0.014239, l4: 0.021887, l5: 0.020671, l6: 0.016848

[epoch:  85/100000, batch:    74/  187, ite: 7933] train loss: 0.177511, tar: 0.017938 
l0: 0.026576, l1: 0.027685, l2: 0.033137, l3: 0.028101, l4: 0.030237, l5: 0.026765, l6: 0.028188

[epoch:  85/100000, batch:    76/  187, ite: 7934] train loss: 0.177523, tar: 0.017942 
l0: 0.006739, l1: 0.006620, l2: 0.010012, l3: 0.011497, l4: 0.014549, l5: 0.010250, l6: 0.011125

[epoch:  85/100000, batch:    78/  187, ite: 7935] train loss: 0.177468, tar: 0.017936 
l0: 0.011719, l1: 0.011479, l2: 0.013992, l3: 0.015779, l4: 0.023490, l5: 0.024040, l6: 0.020382

[epoch:  85/100000, batch:    80/  187, ite: 7936] train loss: 0.177439, tar: 0.017933 
l0: 0.012582, l1: 0.012126, l2: 0.014835, l3: 0.014421, l4: 0.025046, l5: 0.021505, l6: 0.024565

[epoch:  85/100000, batch:    82/  187, ite: 7937] train loss: 0.177412, tar: 0.017930 
l0: 0.009229, l1: 0.009165, l2: 0.010346, l3: 0.010440, l4: 0.021191, l5: 0.020998, l6: 0.023149

[epoch:  85/100000, batch:    84/  187, ite: 7938] train loss: 0.177374, tar: 0.017926 
l0: 0.004825, l1: 0.005717, l2: 0.007291, l3: 0.009490, l4: 0.011081, l5: 0.009653, l6: 0.010660

[epoch:  85/100000, batch:    86/  187, ite: 7939] train loss: 0.177313, tar: 0.017919 
l0: 0.007289, l1: 0.008686, l2: 0.008871, l3: 0.008006, l4: 0.016084, l5: 0.015915, l6: 0.016008

[epoch:  85/100000, batch:    88/  187, ite: 7940] train loss: 0.177263, tar: 0.017913 
l0: 0.013066, l1: 0.013978, l2: 0.014900, l3: 0.018798, l4: 0.021577, l5: 0.021973, l6: 0.023375

[epoch:  85/100000, batch:    90/  187, ite: 7941] train loss: 0.177238, tar: 0.017911 
l0: 0.030733, l1: 0.031316, l2: 0.033277, l3: 0.035107, l4: 0.024283, l5: 0.023578, l6: 0.024633

[epoch:  85/100000, batch:    92/  187, ite: 7942] train loss: 0.177251, tar: 0.017918 
l0: 0.006006, l1: 0.006384, l2: 0.008601, l3: 0.008449, l4: 0.010351, l5: 0.010274, l6: 0.011354

[epoch:  85/100000, batch:    94/  187, ite: 7943] train loss: 0.177191, tar: 0.017911 
l0: 0.010170, l1: 0.011507, l2: 0.010131, l3: 0.010109, l4: 0.020497, l5: 0.019389, l6: 0.020240

[epoch:  85/100000, batch:    96/  187, ite: 7944] train loss: 0.177153, tar: 0.017907 
l0: 0.010044, l1: 0.009679, l2: 0.011081, l3: 0.010837, l4: 0.021348, l5: 0.021281, l6: 0.024192

[epoch:  85/100000, batch:    98/  187, ite: 7945] train loss: 0.177117, tar: 0.017903 
l0: 0.011130, l1: 0.010954, l2: 0.013259, l3: 0.015525, l4: 0.023012, l5: 0.023176, l6: 0.024057

[epoch:  85/100000, batch:   100/  187, ite: 7946] train loss: 0.177088, tar: 0.017900 
l0: 0.007545, l1: 0.008944, l2: 0.007413, l3: 0.007597, l4: 0.010229, l5: 0.007846, l6: 0.008371

[epoch:  85/100000, batch:   102/  187, ite: 7947] train loss: 0.177027, tar: 0.017895 
l0: 0.014174, l1: 0.012957, l2: 0.021218, l3: 0.022057, l4: 0.032074, l5: 0.025111, l6: 0.026713

[epoch:  85/100000, batch:   104/  187, ite: 7948] train loss: 0.177016, tar: 0.017893 
l0: 0.005222, l1: 0.005980, l2: 0.005728, l3: 0.006046, l4: 0.009034, l5: 0.008399, l6: 0.013294

[epoch:  85/100000, batch:   106/  187, ite: 7949] train loss: 0.176952, tar: 0.017886 
l0: 0.016630, l1: 0.017956, l2: 0.019574, l3: 0.018867, l4: 0.019016, l5: 0.017325, l6: 0.016133

[epoch:  85/100000, batch:   108/  187, ite: 7950] train loss: 0.176926, tar: 0.017886 
l0: 0.009120, l1: 0.008865, l2: 0.012104, l3: 0.010498, l4: 0.021818, l5: 0.022010, l6: 0.020524

[epoch:  85/100000, batch:   110/  187, ite: 7951] train loss: 0.176889, tar: 0.017881 
l0: 0.025268, l1: 0.025079, l2: 0.030435, l3: 0.032977, l4: 0.023937, l5: 0.025209, l6: 0.024167

[epoch:  85/100000, batch:   112/  187, ite: 7952] train loss: 0.176894, tar: 0.017885 
l0: 0.010385, l1: 0.009646, l2: 0.010192, l3: 0.010459, l4: 0.019879, l5: 0.020824, l6: 0.019308

[epoch:  85/100000, batch:   114/  187, ite: 7953] train loss: 0.176855, tar: 0.017881 
l0: 0.005827, l1: 0.006862, l2: 0.009477, l3: 0.007022, l4: 0.016413, l5: 0.010873, l6: 0.010291

[epoch:  85/100000, batch:   116/  187, ite: 7954] train loss: 0.176799, tar: 0.017875 
l0: 0.010858, l1: 0.010790, l2: 0.012508, l3: 0.013456, l4: 0.020511, l5: 0.018055, l6: 0.019783

[epoch:  85/100000, batch:   118/  187, ite: 7955] train loss: 0.176763, tar: 0.017871 
l0: 0.012012, l1: 0.011820, l2: 0.015404, l3: 0.014515, l4: 0.014969, l5: 0.015208, l6: 0.016332

[epoch:  85/100000, batch:   120/  187, ite: 7956] train loss: 0.176724, tar: 0.017868 
l0: 0.011069, l1: 0.012404, l2: 0.013055, l3: 0.013523, l4: 0.019351, l5: 0.016303, l6: 0.015317

[epoch:  85/100000, batch:   122/  187, ite: 7957] train loss: 0.176685, tar: 0.017865 
l0: 0.010748, l1: 0.011625, l2: 0.013519, l3: 0.011448, l4: 0.018457, l5: 0.020628, l6: 0.028102

[epoch:  85/100000, batch:   124/  187, ite: 7958] train loss: 0.176653, tar: 0.017861 
l0: 0.010496, l1: 0.011053, l2: 0.012754, l3: 0.011167, l4: 0.016942, l5: 0.017503, l6: 0.019384

[epoch:  85/100000, batch:   126/  187, ite: 7959] train loss: 0.176614, tar: 0.017857 
l0: 0.010541, l1: 0.010867, l2: 0.011655, l3: 0.011357, l4: 0.022386, l5: 0.018282, l6: 0.015270

[epoch:  85/100000, batch:   128/  187, ite: 7960] train loss: 0.176575, tar: 0.017854 
l0: 0.005373, l1: 0.005435, l2: 0.008353, l3: 0.007912, l4: 0.016190, l5: 0.011815, l6: 0.011302

[epoch:  85/100000, batch:   130/  187, ite: 7961] train loss: 0.176519, tar: 0.017847 
l0: 0.011069, l1: 0.012121, l2: 0.012134, l3: 0.012208, l4: 0.017251, l5: 0.016454, l6: 0.015407

[epoch:  85/100000, batch:   132/  187, ite: 7962] train loss: 0.176478, tar: 0.017844 
l0: 0.006216, l1: 0.006054, l2: 0.006394, l3: 0.007147, l4: 0.013312, l5: 0.014858, l6: 0.019990

[epoch:  85/100000, batch:   134/  187, ite: 7963] train loss: 0.176426, tar: 0.017838 
l0: 0.010340, l1: 0.009833, l2: 0.012925, l3: 0.012503, l4: 0.015207, l5: 0.017107, l6: 0.015751

[epoch:  85/100000, batch:   136/  187, ite: 7964] train loss: 0.176383, tar: 0.017834 
l0: 0.008073, l1: 0.007573, l2: 0.008895, l3: 0.010315, l4: 0.015676, l5: 0.016596, l6: 0.021458

[epoch:  85/100000, batch:   138/  187, ite: 7965] train loss: 0.176339, tar: 0.017829 
l0: 0.010688, l1: 0.009680, l2: 0.014026, l3: 0.017187, l4: 0.031999, l5: 0.025153, l6: 0.030380

[epoch:  85/100000, batch:   140/  187, ite: 7966] train loss: 0.176320, tar: 0.017826 
l0: 0.011398, l1: 0.011535, l2: 0.012111, l3: 0.013858, l4: 0.019026, l5: 0.016164, l6: 0.015755

[epoch:  85/100000, batch:   142/  187, ite: 7967] train loss: 0.176281, tar: 0.017822 
l0: 0.006518, l1: 0.007466, l2: 0.007676, l3: 0.006713, l4: 0.011654, l5: 0.011833, l6: 0.014716

[epoch:  85/100000, batch:   144/  187, ite: 7968] train loss: 0.176225, tar: 0.017817 
l0: 0.017378, l1: 0.016893, l2: 0.019397, l3: 0.020835, l4: 0.041701, l5: 0.035838, l6: 0.036993

[epoch:  85/100000, batch:   146/  187, ite: 7969] train loss: 0.176232, tar: 0.017816 
l0: 0.012632, l1: 0.014570, l2: 0.014590, l3: 0.014905, l4: 0.025590, l5: 0.019245, l6: 0.019541

[epoch:  85/100000, batch:   148/  187, ite: 7970] train loss: 0.176204, tar: 0.017814 
l0: 0.011977, l1: 0.012866, l2: 0.012109, l3: 0.011010, l4: 0.019819, l5: 0.022452, l6: 0.023891

[epoch:  85/100000, batch:   150/  187, ite: 7971] train loss: 0.176172, tar: 0.017811 
l0: 0.011583, l1: 0.010973, l2: 0.013234, l3: 0.014792, l4: 0.014528, l5: 0.017177, l6: 0.015904

[epoch:  85/100000, batch:   152/  187, ite: 7972] train loss: 0.176133, tar: 0.017808 
l0: 0.011813, l1: 0.012507, l2: 0.014174, l3: 0.014707, l4: 0.025756, l5: 0.021507, l6: 0.017052

[epoch:  85/100000, batch:   154/  187, ite: 7973] train loss: 0.176103, tar: 0.017804 
l0: 0.007472, l1: 0.007208, l2: 0.010821, l3: 0.012363, l4: 0.012145, l5: 0.010870, l6: 0.011215

[epoch:  85/100000, batch:   156/  187, ite: 7974] train loss: 0.176050, tar: 0.017799 
l0: 0.010527, l1: 0.011538, l2: 0.012138, l3: 0.011541, l4: 0.015398, l5: 0.014912, l6: 0.023313

[epoch:  85/100000, batch:   158/  187, ite: 7975] train loss: 0.176011, tar: 0.017796 
l0: 0.008804, l1: 0.008945, l2: 0.009545, l3: 0.010494, l4: 0.023564, l5: 0.021018, l6: 0.021168

[epoch:  85/100000, batch:   160/  187, ite: 7976] train loss: 0.175975, tar: 0.017791 
l0: 0.008524, l1: 0.008718, l2: 0.011358, l3: 0.012104, l4: 0.016591, l5: 0.017524, l6: 0.017288

[epoch:  85/100000, batch:   162/  187, ite: 7977] train loss: 0.175932, tar: 0.017786 
l0: 0.016767, l1: 0.016998, l2: 0.015832, l3: 0.017180, l4: 0.024112, l5: 0.025057, l6: 0.024626

[epoch:  85/100000, batch:   164/  187, ite: 7978] train loss: 0.175914, tar: 0.017786 
l0: 0.016022, l1: 0.016282, l2: 0.021798, l3: 0.024185, l4: 0.033262, l5: 0.030424, l6: 0.027511

[epoch:  85/100000, batch:   166/  187, ite: 7979] train loss: 0.175911, tar: 0.017785 
l0: 0.008132, l1: 0.008616, l2: 0.013273, l3: 0.010868, l4: 0.024415, l5: 0.017787, l6: 0.011787

[epoch:  85/100000, batch:   168/  187, ite: 7980] train loss: 0.175870, tar: 0.017780 
l0: 0.010489, l1: 0.011026, l2: 0.013871, l3: 0.014155, l4: 0.020666, l5: 0.017392, l6: 0.013607

[epoch:  85/100000, batch:   170/  187, ite: 7981] train loss: 0.175833, tar: 0.017776 
l0: 0.010386, l1: 0.009375, l2: 0.011435, l3: 0.014383, l4: 0.022734, l5: 0.021682, l6: 0.026265

[epoch:  85/100000, batch:   172/  187, ite: 7982] train loss: 0.175803, tar: 0.017773 
l0: 0.014894, l1: 0.015038, l2: 0.016187, l3: 0.019723, l4: 0.035522, l5: 0.032066, l6: 0.036348

[epoch:  85/100000, batch:   174/  187, ite: 7983] train loss: 0.175800, tar: 0.017771 
l0: 0.027214, l1: 0.027200, l2: 0.026815, l3: 0.028972, l4: 0.051558, l5: 0.051467, l6: 0.046918

[epoch:  85/100000, batch:   176/  187, ite: 7984] train loss: 0.175842, tar: 0.017776 
l0: 0.004964, l1: 0.005394, l2: 0.005676, l3: 0.005894, l4: 0.008905, l5: 0.007807, l6: 0.007207

[epoch:  85/100000, batch:   178/  187, ite: 7985] train loss: 0.175777, tar: 0.017770 
l0: 0.006662, l1: 0.007373, l2: 0.007513, l3: 0.008794, l4: 0.013281, l5: 0.011501, l6: 0.010638

[epoch:  85/100000, batch:   180/  187, ite: 7986] train loss: 0.175721, tar: 0.017764 
l0: 0.012942, l1: 0.012704, l2: 0.017213, l3: 0.017557, l4: 0.025504, l5: 0.020438, l6: 0.019963

[epoch:  85/100000, batch:   182/  187, ite: 7987] train loss: 0.175696, tar: 0.017761 
l0: 0.009407, l1: 0.009254, l2: 0.012847, l3: 0.014277, l4: 0.015446, l5: 0.015071, l6: 0.014322

[epoch:  85/100000, batch:   184/  187, ite: 7988] train loss: 0.175653, tar: 0.017757 
l0: 0.022044, l1: 0.024806, l2: 0.021896, l3: 0.020298, l4: 0.012853, l5: 0.016758, l6: 0.016868

[epoch:  85/100000, batch:   186/  187, ite: 7989] train loss: 0.175633, tar: 0.017759 
l0: 0.008775, l1: 0.010191, l2: 0.010238, l3: 0.008104, l4: 0.017776, l5: 0.016111, l6: 0.015680

[epoch:  85/100000, batch:   188/  187, ite: 7990] train loss: 0.175589, tar: 0.017755 
l0: 0.010830, l1: 0.011245, l2: 0.013281, l3: 0.013872, l4: 0.021728, l5: 0.019135, l6: 0.026134

[epoch:  86/100000, batch:     2/  187, ite: 7991] train loss: 0.175559, tar: 0.017751 
l0: 0.011161, l1: 0.010415, l2: 0.016467, l3: 0.018080, l4: 0.036472, l5: 0.034146, l6: 0.026406

[epoch:  86/100000, batch:     4/  187, ite: 7992] train loss: 0.175548, tar: 0.017748 
l0: 0.009080, l1: 0.009552, l2: 0.008883, l3: 0.008936, l4: 0.014921, l5: 0.014193, l6: 0.022548

[epoch:  86/100000, batch:     6/  187, ite: 7993] train loss: 0.175504, tar: 0.017744 
l0: 0.004127, l1: 0.004612, l2: 0.005542, l3: 0.005832, l4: 0.008773, l5: 0.009005, l6: 0.009552

[epoch:  86/100000, batch:     8/  187, ite: 7994] train loss: 0.175440, tar: 0.017737 
l0: 0.017122, l1: 0.017862, l2: 0.014604, l3: 0.014195, l4: 0.027621, l5: 0.024448, l6: 0.028320

[epoch:  86/100000, batch:    10/  187, ite: 7995] train loss: 0.175424, tar: 0.017737 
l0: 0.009139, l1: 0.008597, l2: 0.011104, l3: 0.012576, l4: 0.021962, l5: 0.019034, l6: 0.016577

[epoch:  86/100000, batch:    12/  187, ite: 7996] train loss: 0.175386, tar: 0.017732 
l0: 0.010037, l1: 0.011285, l2: 0.010398, l3: 0.009850, l4: 0.018148, l5: 0.015110, l6: 0.017214

[epoch:  86/100000, batch:    14/  187, ite: 7997] train loss: 0.175344, tar: 0.017728 
l0: 0.011588, l1: 0.012091, l2: 0.013515, l3: 0.014132, l4: 0.018879, l5: 0.018885, l6: 0.019022

[epoch:  86/100000, batch:    16/  187, ite: 7998] train loss: 0.175310, tar: 0.017725 
l0: 0.008453, l1: 0.009523, l2: 0.007763, l3: 0.008484, l4: 0.010014, l5: 0.010953, l6: 0.010161

[epoch:  86/100000, batch:    18/  187, ite: 7999] train loss: 0.175255, tar: 0.017721 
l0: 0.011298, l1: 0.011972, l2: 0.011461, l3: 0.011955, l4: 0.017481, l5: 0.016497, l6: 0.021197

[epoch:  86/100000, batch:    20/  187, ite: 8000] train loss: 0.175219, tar: 0.017718 
l0: 0.021752, l1: 0.021369, l2: 0.027699, l3: 0.032480, l4: 0.062759, l5: 0.051099, l6: 0.046436

[epoch:  86/100000, batch:    22/  187, ite: 8001] train loss: 0.263594, tar: 0.021752 
l0: 0.008685, l1: 0.009163, l2: 0.011044, l3: 0.011342, l4: 0.014478, l5: 0.009860, l6: 0.010507

[epoch:  86/100000, batch:    24/  187, ite: 8002] train loss: 0.169337, tar: 0.015219 
l0: 0.008165, l1: 0.008348, l2: 0.010006, l3: 0.010397, l4: 0.017174, l5: 0.018478, l6: 0.020574

[epoch:  86/100000, batch:    26/  187, ite: 8003] train loss: 0.143938, tar: 0.012868 
l0: 0.020297, l1: 0.020991, l2: 0.025316, l3: 0.023113, l4: 0.023920, l5: 0.020571, l6: 0.023845

[epoch:  86/100000, batch:    28/  187, ite: 8004] train loss: 0.147467, tar: 0.014725 
l0: 0.010521, l1: 0.012154, l2: 0.009250, l3: 0.008435, l4: 0.011540, l5: 0.012957, l6: 0.013193

[epoch:  86/100000, batch:    30/  187, ite: 8005] train loss: 0.133584, tar: 0.013884 
l0: 0.009884, l1: 0.009148, l2: 0.016420, l3: 0.017091, l4: 0.022576, l5: 0.021783, l6: 0.031959

[epoch:  86/100000, batch:    32/  187, ite: 8006] train loss: 0.132796, tar: 0.013217 
l0: 0.006144, l1: 0.006599, l2: 0.006728, l3: 0.009257, l4: 0.012599, l5: 0.014676, l6: 0.012994

[epoch:  86/100000, batch:    34/  187, ite: 8007] train loss: 0.123682, tar: 0.012207 
l0: 0.017119, l1: 0.017350, l2: 0.018894, l3: 0.018851, l4: 0.021661, l5: 0.019777, l6: 0.021792

[epoch:  86/100000, batch:    36/  187, ite: 8008] train loss: 0.125152, tar: 0.012821 
l0: 0.012481, l1: 0.012907, l2: 0.012306, l3: 0.014380, l4: 0.021525, l5: 0.022237, l6: 0.014905

[epoch:  86/100000, batch:    38/  187, ite: 8009] train loss: 0.123551, tar: 0.012783 
l0: 0.015002, l1: 0.014539, l2: 0.018148, l3: 0.018847, l4: 0.030940, l5: 0.028043, l6: 0.021760

[epoch:  86/100000, batch:    40/  187, ite: 8010] train loss: 0.125924, tar: 0.013005 
l0: 0.010285, l1: 0.011643, l2: 0.009836, l3: 0.009976, l4: 0.018367, l5: 0.018619, l6: 0.020887

[epoch:  86/100000, batch:    42/  187, ite: 8011] train loss: 0.123532, tar: 0.012758 
l0: 0.007219, l1: 0.007439, l2: 0.010459, l3: 0.009328, l4: 0.010171, l5: 0.009531, l6: 0.010043

[epoch:  86/100000, batch:    44/  187, ite: 8012] train loss: 0.118587, tar: 0.012296 
l0: 0.008006, l1: 0.008311, l2: 0.009545, l3: 0.009847, l4: 0.017757, l5: 0.016658, l6: 0.024302

[epoch:  86/100000, batch:    46/  187, ite: 8013] train loss: 0.116728, tar: 0.011966 
l0: 0.012625, l1: 0.012188, l2: 0.016548, l3: 0.018022, l4: 0.028207, l5: 0.030841, l6: 0.024686

[epoch:  86/100000, batch:    48/  187, ite: 8014] train loss: 0.118613, tar: 0.012013 
l0: 0.007178, l1: 0.007626, l2: 0.008371, l3: 0.008166, l4: 0.017726, l5: 0.015234, l6: 0.016712

[epoch:  86/100000, batch:    50/  187, ite: 8015] train loss: 0.116107, tar: 0.011691 
l0: 0.012385, l1: 0.013683, l2: 0.013667, l3: 0.013981, l4: 0.017627, l5: 0.017269, l6: 0.016904

[epoch:  86/100000, batch:    52/  187, ite: 8016] train loss: 0.115445, tar: 0.011734 
l0: 0.009749, l1: 0.009390, l2: 0.010506, l3: 0.012639, l4: 0.024483, l5: 0.023289, l6: 0.018397

[epoch:  86/100000, batch:    54/  187, ite: 8017] train loss: 0.115033, tar: 0.011617 
l0: 0.008369, l1: 0.008881, l2: 0.012379, l3: 0.011676, l4: 0.019820, l5: 0.015275, l6: 0.014056

[epoch:  86/100000, batch:    56/  187, ite: 8018] train loss: 0.113668, tar: 0.011437 
l0: 0.011674, l1: 0.012191, l2: 0.013712, l3: 0.012551, l4: 0.022408, l5: 0.022798, l6: 0.021088

[epoch:  86/100000, batch:    58/  187, ite: 8019] train loss: 0.113813, tar: 0.011449 
l0: 0.015922, l1: 0.016484, l2: 0.019663, l3: 0.018825, l4: 0.016254, l5: 0.014004, l6: 0.011597

[epoch:  86/100000, batch:    60/  187, ite: 8020] train loss: 0.113760, tar: 0.011673 
l0: 0.010345, l1: 0.011578, l2: 0.011487, l3: 0.010724, l4: 0.012017, l5: 0.014550, l6: 0.013073

[epoch:  86/100000, batch:    62/  187, ite: 8021] train loss: 0.112332, tar: 0.011610 
l0: 0.019304, l1: 0.018906, l2: 0.019890, l3: 0.018844, l4: 0.030583, l5: 0.033275, l6: 0.032173

[epoch:  86/100000, batch:    64/  187, ite: 8022] train loss: 0.115088, tar: 0.011960 
l0: 0.013532, l1: 0.013093, l2: 0.015852, l3: 0.016200, l4: 0.034381, l5: 0.032619, l6: 0.030623

[epoch:  86/100000, batch:    66/  187, ite: 8023] train loss: 0.116880, tar: 0.012028 
l0: 0.013233, l1: 0.013216, l2: 0.015987, l3: 0.016388, l4: 0.025261, l5: 0.024723, l6: 0.020726

[epoch:  86/100000, batch:    68/  187, ite: 8024] train loss: 0.117407, tar: 0.012078 
l0: 0.009581, l1: 0.010211, l2: 0.009769, l3: 0.011437, l4: 0.020755, l5: 0.019320, l6: 0.017622

[epoch:  86/100000, batch:    70/  187, ite: 8025] train loss: 0.116659, tar: 0.011978 
l0: 0.006502, l1: 0.007206, l2: 0.008406, l3: 0.007092, l4: 0.011969, l5: 0.009503, l6: 0.017237

[epoch:  86/100000, batch:    72/  187, ite: 8026] train loss: 0.114784, tar: 0.011768 
l0: 0.012460, l1: 0.012734, l2: 0.018228, l3: 0.017251, l4: 0.021336, l5: 0.016134, l6: 0.014582

[epoch:  86/100000, batch:    74/  187, ite: 8027] train loss: 0.114708, tar: 0.011793 
l0: 0.013637, l1: 0.015995, l2: 0.015831, l3: 0.015691, l4: 0.016832, l5: 0.015959, l6: 0.015399

[epoch:  86/100000, batch:    76/  187, ite: 8028] train loss: 0.114516, tar: 0.011859 
l0: 0.014968, l1: 0.016559, l2: 0.015945, l3: 0.017507, l4: 0.024686, l5: 0.019887, l6: 0.023293

[epoch:  86/100000, batch:    78/  187, ite: 8029] train loss: 0.115148, tar: 0.011966 
l0: 0.011983, l1: 0.012949, l2: 0.013645, l3: 0.015806, l4: 0.024628, l5: 0.021991, l6: 0.024260

[epoch:  86/100000, batch:    80/  187, ite: 8030] train loss: 0.115485, tar: 0.011967 
l0: 0.006557, l1: 0.005276, l2: 0.010581, l3: 0.012827, l4: 0.020804, l5: 0.024501, l6: 0.018130

[epoch:  86/100000, batch:    82/  187, ite: 8031] train loss: 0.114943, tar: 0.011792 
l0: 0.005822, l1: 0.005556, l2: 0.006390, l3: 0.006418, l4: 0.017465, l5: 0.021356, l6: 0.012285

[epoch:  86/100000, batch:    84/  187, ite: 8032] train loss: 0.113704, tar: 0.011606 
l0: 0.010807, l1: 0.011227, l2: 0.011859, l3: 0.011914, l4: 0.016723, l5: 0.016896, l6: 0.018941

[epoch:  86/100000, batch:    86/  187, ite: 8033] train loss: 0.113239, tar: 0.011582 
l0: 0.010602, l1: 0.011319, l2: 0.011278, l3: 0.012538, l4: 0.014340, l5: 0.014710, l6: 0.014218

[epoch:  86/100000, batch:    88/  187, ite: 8034] train loss: 0.112527, tar: 0.011553 
l0: 0.015387, l1: 0.014337, l2: 0.018957, l3: 0.020717, l4: 0.044508, l5: 0.037239, l6: 0.049127

[epoch:  86/100000, batch:    90/  187, ite: 8035] train loss: 0.115034, tar: 0.011662 
l0: 0.007019, l1: 0.006928, l2: 0.008752, l3: 0.010412, l4: 0.009747, l5: 0.008951, l6: 0.008766

[epoch:  86/100000, batch:    92/  187, ite: 8036] train loss: 0.113521, tar: 0.011533 
l0: 0.015414, l1: 0.015791, l2: 0.015845, l3: 0.015949, l4: 0.035359, l5: 0.032150, l6: 0.029289

[epoch:  86/100000, batch:    94/  187, ite: 8037] train loss: 0.114772, tar: 0.011638 
l0: 0.007856, l1: 0.008509, l2: 0.009470, l3: 0.008248, l4: 0.015210, l5: 0.012391, l6: 0.013012

[epoch:  86/100000, batch:    96/  187, ite: 8038] train loss: 0.113717, tar: 0.011539 
l0: 0.009918, l1: 0.009648, l2: 0.012883, l3: 0.014474, l4: 0.025567, l5: 0.022457, l6: 0.026642

[epoch:  86/100000, batch:    98/  187, ite: 8039] train loss: 0.113919, tar: 0.011497 
l0: 0.010851, l1: 0.012533, l2: 0.008812, l3: 0.008144, l4: 0.010419, l5: 0.010690, l6: 0.011770

[epoch:  86/100000, batch:   100/  187, ite: 8040] train loss: 0.112901, tar: 0.011481 
l0: 0.013304, l1: 0.014595, l2: 0.011944, l3: 0.011980, l4: 0.015089, l5: 0.018481, l6: 0.023074

[epoch:  86/100000, batch:   102/  187, ite: 8041] train loss: 0.112793, tar: 0.011525 
l0: 0.008173, l1: 0.008597, l2: 0.009865, l3: 0.010108, l4: 0.022111, l5: 0.023580, l6: 0.019923

[epoch:  86/100000, batch:   104/  187, ite: 8042] train loss: 0.112545, tar: 0.011446 
l0: 0.010312, l1: 0.010083, l2: 0.013340, l3: 0.016589, l4: 0.024043, l5: 0.026986, l6: 0.028013

[epoch:  86/100000, batch:   106/  187, ite: 8043] train loss: 0.112936, tar: 0.011419 
l0: 0.008177, l1: 0.008339, l2: 0.008718, l3: 0.008489, l4: 0.019890, l5: 0.019525, l6: 0.022834

[epoch:  86/100000, batch:   108/  187, ite: 8044] train loss: 0.112550, tar: 0.011346 
l0: 0.006571, l1: 0.007220, l2: 0.007425, l3: 0.007287, l4: 0.014469, l5: 0.013512, l6: 0.009500

[epoch:  86/100000, batch:   110/  187, ite: 8045] train loss: 0.111516, tar: 0.011239 
l0: 0.009292, l1: 0.009948, l2: 0.009682, l3: 0.010127, l4: 0.017035, l5: 0.017772, l6: 0.013905

[epoch:  86/100000, batch:   112/  187, ite: 8046] train loss: 0.110999, tar: 0.011197 
l0: 0.007437, l1: 0.007814, l2: 0.010991, l3: 0.009489, l4: 0.020260, l5: 0.029314, l6: 0.034382

[epoch:  86/100000, batch:   114/  187, ite: 8047] train loss: 0.111184, tar: 0.011117 
l0: 0.011529, l1: 0.011746, l2: 0.013243, l3: 0.019248, l4: 0.019250, l5: 0.018412, l6: 0.020903

[epoch:  86/100000, batch:   116/  187, ite: 8048] train loss: 0.111249, tar: 0.011126 
l0: 0.007234, l1: 0.007226, l2: 0.008457, l3: 0.009610, l4: 0.020858, l5: 0.019362, l6: 0.015697

[epoch:  86/100000, batch:   118/  187, ite: 8049] train loss: 0.110784, tar: 0.011046 
l0: 0.005869, l1: 0.006025, l2: 0.007957, l3: 0.006062, l4: 0.009111, l5: 0.009698, l6: 0.009755

[epoch:  86/100000, batch:   120/  187, ite: 8050] train loss: 0.109658, tar: 0.010943 
l0: 0.006505, l1: 0.008057, l2: 0.006701, l3: 0.005868, l4: 0.008634, l5: 0.008274, l6: 0.007844

[epoch:  86/100000, batch:   122/  187, ite: 8051] train loss: 0.108525, tar: 0.010856 
l0: 0.010582, l1: 0.008897, l2: 0.012102, l3: 0.012942, l4: 0.028948, l5: 0.033243, l6: 0.035724

[epoch:  86/100000, batch:   124/  187, ite: 8052] train loss: 0.109177, tar: 0.010850 
l0: 0.018573, l1: 0.016533, l2: 0.020060, l3: 0.022657, l4: 0.030315, l5: 0.033248, l6: 0.035179

[epoch:  86/100000, batch:   126/  187, ite: 8053] train loss: 0.110449, tar: 0.010996 
l0: 0.008338, l1: 0.007686, l2: 0.012298, l3: 0.013430, l4: 0.026793, l5: 0.023407, l6: 0.023818

[epoch:  86/100000, batch:   128/  187, ite: 8054] train loss: 0.110547, tar: 0.010947 
l0: 0.014435, l1: 0.015550, l2: 0.013767, l3: 0.014816, l4: 0.019092, l5: 0.020599, l6: 0.020735

[epoch:  86/100000, batch:   130/  187, ite: 8055] train loss: 0.110701, tar: 0.011010 
l0: 0.014174, l1: 0.011922, l2: 0.013991, l3: 0.016230, l4: 0.023348, l5: 0.028727, l6: 0.029981

[epoch:  86/100000, batch:   132/  187, ite: 8056] train loss: 0.111195, tar: 0.011067 
l0: 0.017229, l1: 0.016392, l2: 0.022403, l3: 0.021744, l4: 0.033485, l5: 0.034113, l6: 0.029441

[epoch:  86/100000, batch:   134/  187, ite: 8057] train loss: 0.112311, tar: 0.011175 
l0: 0.011574, l1: 0.011837, l2: 0.012411, l3: 0.012720, l4: 0.022824, l5: 0.020558, l6: 0.021554

[epoch:  86/100000, batch:   136/  187, ite: 8058] train loss: 0.112331, tar: 0.011182 
l0: 0.021939, l1: 0.022257, l2: 0.023195, l3: 0.024113, l4: 0.048061, l5: 0.039419, l6: 0.030923

[epoch:  86/100000, batch:   138/  187, ite: 8059] train loss: 0.113985, tar: 0.011364 
l0: 0.014379, l1: 0.016327, l2: 0.019160, l3: 0.019375, l4: 0.022292, l5: 0.018474, l6: 0.022012

[epoch:  86/100000, batch:   140/  187, ite: 8060] train loss: 0.114286, tar: 0.011414 
l0: 0.012076, l1: 0.012241, l2: 0.012806, l3: 0.014586, l4: 0.028580, l5: 0.024055, l6: 0.038382

[epoch:  86/100000, batch:   142/  187, ite: 8061] train loss: 0.114752, tar: 0.011425 
l0: 0.014847, l1: 0.014630, l2: 0.015953, l3: 0.015427, l4: 0.026818, l5: 0.024049, l6: 0.035709

[epoch:  86/100000, batch:   144/  187, ite: 8062] train loss: 0.115279, tar: 0.011480 
l0: 0.012726, l1: 0.014370, l2: 0.011620, l3: 0.013566, l4: 0.038213, l5: 0.026687, l6: 0.023252

[epoch:  86/100000, batch:   146/  187, ite: 8063] train loss: 0.115678, tar: 0.011500 
l0: 0.005387, l1: 0.005793, l2: 0.007323, l3: 0.007720, l4: 0.015255, l5: 0.012823, l6: 0.013217

[epoch:  86/100000, batch:   148/  187, ite: 8064] train loss: 0.114926, tar: 0.011405 
l0: 0.007444, l1: 0.008944, l2: 0.009319, l3: 0.010274, l4: 0.018558, l5: 0.015392, l6: 0.016409

[epoch:  86/100000, batch:   150/  187, ite: 8065] train loss: 0.114486, tar: 0.011344 
l0: 0.014819, l1: 0.014493, l2: 0.018360, l3: 0.023677, l4: 0.024917, l5: 0.024161, l6: 0.026723

[epoch:  86/100000, batch:   152/  187, ite: 8066] train loss: 0.114981, tar: 0.011396 
l0: 0.012750, l1: 0.014297, l2: 0.013674, l3: 0.013260, l4: 0.022900, l5: 0.019954, l6: 0.019948

[epoch:  86/100000, batch:   154/  187, ite: 8067] train loss: 0.115008, tar: 0.011417 
l0: 0.009110, l1: 0.009160, l2: 0.010329, l3: 0.019778, l4: 0.031828, l5: 0.029955, l6: 0.016931

[epoch:  86/100000, batch:   156/  187, ite: 8068] train loss: 0.115185, tar: 0.011383 
l0: 0.013372, l1: 0.012130, l2: 0.015024, l3: 0.014313, l4: 0.022218, l5: 0.022893, l6: 0.021584

[epoch:  86/100000, batch:   158/  187, ite: 8069] train loss: 0.115277, tar: 0.011412 
l0: 0.007922, l1: 0.008771, l2: 0.007899, l3: 0.007635, l4: 0.013251, l5: 0.014166, l6: 0.015004

[epoch:  86/100000, batch:   160/  187, ite: 8070] train loss: 0.114697, tar: 0.011362 
l0: 0.014564, l1: 0.014365, l2: 0.014395, l3: 0.015936, l4: 0.023513, l5: 0.023183, l6: 0.023957

[epoch:  86/100000, batch:   162/  187, ite: 8071] train loss: 0.114911, tar: 0.011407 
l0: 0.008985, l1: 0.010334, l2: 0.008208, l3: 0.009123, l4: 0.013750, l5: 0.012952, l6: 0.014806

[epoch:  86/100000, batch:   164/  187, ite: 8072] train loss: 0.114401, tar: 0.011373 
l0: 0.014271, l1: 0.012829, l2: 0.016839, l3: 0.021586, l4: 0.040793, l5: 0.038250, l6: 0.040828

[epoch:  86/100000, batch:   166/  187, ite: 8073] train loss: 0.115373, tar: 0.011413 
l0: 0.010914, l1: 0.010662, l2: 0.012274, l3: 0.012902, l4: 0.022685, l5: 0.024713, l6: 0.018651

[epoch:  86/100000, batch:   168/  187, ite: 8074] train loss: 0.115339, tar: 0.011406 
l0: 0.011870, l1: 0.011104, l2: 0.013606, l3: 0.015197, l4: 0.026036, l5: 0.024906, l6: 0.029955

[epoch:  86/100000, batch:   170/  187, ite: 8075] train loss: 0.115570, tar: 0.011412 
l0: 0.009089, l1: 0.009886, l2: 0.011302, l3: 0.010937, l4: 0.018937, l5: 0.017383, l6: 0.018862

[epoch:  86/100000, batch:   172/  187, ite: 8076] train loss: 0.115317, tar: 0.011382 
l0: 0.007154, l1: 0.007131, l2: 0.006596, l3: 0.009143, l4: 0.020573, l5: 0.016170, l6: 0.017034

[epoch:  86/100000, batch:   174/  187, ite: 8077] train loss: 0.114908, tar: 0.011327 
l0: 0.006329, l1: 0.006076, l2: 0.006705, l3: 0.008234, l4: 0.018444, l5: 0.017803, l6: 0.015209

[epoch:  86/100000, batch:   176/  187, ite: 8078] train loss: 0.114445, tar: 0.011263 
l0: 0.012443, l1: 0.012036, l2: 0.013830, l3: 0.016799, l4: 0.026535, l5: 0.024102, l6: 0.026116

[epoch:  86/100000, batch:   178/  187, ite: 8079] train loss: 0.114666, tar: 0.011278 
l0: 0.019294, l1: 0.016491, l2: 0.018769, l3: 0.025335, l4: 0.039885, l5: 0.043123, l6: 0.043660

[epoch:  86/100000, batch:   180/  187, ite: 8080] train loss: 0.115814, tar: 0.011378 
l0: 0.004985, l1: 0.005673, l2: 0.004886, l3: 0.005947, l4: 0.013200, l5: 0.017269, l6: 0.020725

[epoch:  86/100000, batch:   182/  187, ite: 8081] train loss: 0.115282, tar: 0.011299 
l0: 0.008594, l1: 0.008479, l2: 0.008283, l3: 0.009377, l4: 0.027146, l5: 0.025575, l6: 0.023466

[epoch:  86/100000, batch:   184/  187, ite: 8082] train loss: 0.115229, tar: 0.011266 
l0: 0.013049, l1: 0.014488, l2: 0.012624, l3: 0.012543, l4: 0.015090, l5: 0.014919, l6: 0.013368

[epoch:  86/100000, batch:   186/  187, ite: 8083] train loss: 0.114998, tar: 0.011287 
l0: 0.003700, l1: 0.003436, l2: 0.005377, l3: 0.004462, l4: 0.013004, l5: 0.010973, l6: 0.008533

[epoch:  86/100000, batch:   188/  187, ite: 8084] train loss: 0.114218, tar: 0.011197 
l0: 0.004356, l1: 0.004911, l2: 0.004660, l3: 0.005497, l4: 0.019923, l5: 0.014317, l6: 0.012453

[epoch:  87/100000, batch:     2/  187, ite: 8085] train loss: 0.113652, tar: 0.011117 
l0: 0.007951, l1: 0.008142, l2: 0.007793, l3: 0.008674, l4: 0.011190, l5: 0.012007, l6: 0.010092

[epoch:  87/100000, batch:     4/  187, ite: 8086] train loss: 0.113096, tar: 0.011080 
l0: 0.007604, l1: 0.007370, l2: 0.009082, l3: 0.009028, l4: 0.016218, l5: 0.016017, l6: 0.011994

[epoch:  87/100000, batch:     6/  187, ite: 8087] train loss: 0.112685, tar: 0.011040 
l0: 0.013105, l1: 0.014093, l2: 0.015995, l3: 0.016895, l4: 0.014819, l5: 0.014743, l6: 0.013996

[epoch:  87/100000, batch:     8/  187, ite: 8088] train loss: 0.112582, tar: 0.011063 
l0: 0.009285, l1: 0.009432, l2: 0.011078, l3: 0.011451, l4: 0.019216, l5: 0.016229, l6: 0.019007

[epoch:  87/100000, batch:    10/  187, ite: 8089] train loss: 0.112393, tar: 0.011043 
l0: 0.013137, l1: 0.011666, l2: 0.010666, l3: 0.013444, l4: 0.029429, l5: 0.031281, l6: 0.035797

[epoch:  87/100000, batch:    12/  187, ite: 8090] train loss: 0.112760, tar: 0.011067 
l0: 0.010898, l1: 0.010035, l2: 0.012158, l3: 0.014514, l4: 0.031252, l5: 0.033094, l6: 0.033972

[epoch:  87/100000, batch:    14/  187, ite: 8091] train loss: 0.113124, tar: 0.011065 
l0: 0.020272, l1: 0.019528, l2: 0.025644, l3: 0.025929, l4: 0.046808, l5: 0.044408, l6: 0.064419

[epoch:  87/100000, batch:    16/  187, ite: 8092] train loss: 0.114579, tar: 0.011165 
l0: 0.019197, l1: 0.017638, l2: 0.020810, l3: 0.023718, l4: 0.038751, l5: 0.038458, l6: 0.043497

[epoch:  87/100000, batch:    18/  187, ite: 8093] train loss: 0.115520, tar: 0.011251 
l0: 0.013304, l1: 0.016083, l2: 0.017769, l3: 0.010588, l4: 0.010817, l5: 0.012950, l6: 0.013974

[epoch:  87/100000, batch:    20/  187, ite: 8094] train loss: 0.115307, tar: 0.011273 
l0: 0.017923, l1: 0.020119, l2: 0.018320, l3: 0.017616, l4: 0.032165, l5: 0.028594, l6: 0.028164

[epoch:  87/100000, batch:    22/  187, ite: 8095] train loss: 0.115808, tar: 0.011343 
l0: 0.008690, l1: 0.009528, l2: 0.016805, l3: 0.016025, l4: 0.024832, l5: 0.024186, l6: 0.019618

[epoch:  87/100000, batch:    24/  187, ite: 8096] train loss: 0.115848, tar: 0.011315 
l0: 0.007158, l1: 0.006354, l2: 0.008026, l3: 0.011541, l4: 0.024147, l5: 0.023564, l6: 0.021305

[epoch:  87/100000, batch:    26/  187, ite: 8097] train loss: 0.115706, tar: 0.011273 
l0: 0.007090, l1: 0.007142, l2: 0.006988, l3: 0.007300, l4: 0.008440, l5: 0.009335, l6: 0.010213

[epoch:  87/100000, batch:    28/  187, ite: 8098] train loss: 0.115102, tar: 0.011230 
l0: 0.016634, l1: 0.016184, l2: 0.018234, l3: 0.022027, l4: 0.021372, l5: 0.025049, l6: 0.024948

[epoch:  87/100000, batch:    30/  187, ite: 8099] train loss: 0.115399, tar: 0.011284 
l0: 0.005432, l1: 0.005689, l2: 0.005773, l3: 0.007630, l4: 0.014915, l5: 0.013016, l6: 0.014005

[epoch:  87/100000, batch:    32/  187, ite: 8100] train loss: 0.114909, tar: 0.011226 
l0: 0.010615, l1: 0.010732, l2: 0.011324, l3: 0.011521, l4: 0.015211, l5: 0.015471, l6: 0.020369

[epoch:  87/100000, batch:    34/  187, ite: 8101] train loss: 0.114715, tar: 0.011220 
l0: 0.018999, l1: 0.018427, l2: 0.015953, l3: 0.017482, l4: 0.025594, l5: 0.025144, l6: 0.031498

[epoch:  87/100000, batch:    36/  187, ite: 8102] train loss: 0.115091, tar: 0.011296 
l0: 0.015658, l1: 0.016778, l2: 0.018930, l3: 0.016836, l4: 0.021330, l5: 0.018486, l6: 0.019036

[epoch:  87/100000, batch:    38/  187, ite: 8103] train loss: 0.115207, tar: 0.011338 
l0: 0.010143, l1: 0.010621, l2: 0.011551, l3: 0.012797, l4: 0.019820, l5: 0.021230, l6: 0.019750

[epoch:  87/100000, batch:    40/  187, ite: 8104] train loss: 0.115118, tar: 0.011327 
l0: 0.008107, l1: 0.008294, l2: 0.010549, l3: 0.010887, l4: 0.027881, l5: 0.026936, l6: 0.021163

[epoch:  87/100000, batch:    42/  187, ite: 8105] train loss: 0.115105, tar: 0.011296 
l0: 0.006621, l1: 0.007578, l2: 0.008327, l3: 0.007852, l4: 0.018405, l5: 0.020159, l6: 0.015079

[epoch:  87/100000, batch:    44/  187, ite: 8106] train loss: 0.114812, tar: 0.011252 
l0: 0.010922, l1: 0.011137, l2: 0.012069, l3: 0.011767, l4: 0.025817, l5: 0.024901, l6: 0.026671

[epoch:  87/100000, batch:    46/  187, ite: 8107] train loss: 0.114891, tar: 0.011249 
l0: 0.012745, l1: 0.013338, l2: 0.016963, l3: 0.016333, l4: 0.021875, l5: 0.023199, l6: 0.018568

[epoch:  87/100000, batch:    48/  187, ite: 8108] train loss: 0.114967, tar: 0.011263 
l0: 0.012486, l1: 0.013216, l2: 0.011779, l3: 0.012796, l4: 0.022424, l5: 0.018067, l6: 0.020529

[epoch:  87/100000, batch:    50/  187, ite: 8109] train loss: 0.114933, tar: 0.011274 
l0: 0.015571, l1: 0.014657, l2: 0.017818, l3: 0.018774, l4: 0.026158, l5: 0.027292, l6: 0.032767

[epoch:  87/100000, batch:    52/  187, ite: 8110] train loss: 0.115279, tar: 0.011313 
l0: 0.006845, l1: 0.007203, l2: 0.009296, l3: 0.007001, l4: 0.012232, l5: 0.011624, l6: 0.010690

[epoch:  87/100000, batch:    54/  187, ite: 8111] train loss: 0.114825, tar: 0.011273 
l0: 0.008257, l1: 0.008314, l2: 0.009422, l3: 0.009472, l4: 0.015463, l5: 0.016602, l6: 0.016933

[epoch:  87/100000, batch:    56/  187, ite: 8112] train loss: 0.114554, tar: 0.011246 
l0: 0.012942, l1: 0.013970, l2: 0.014692, l3: 0.017490, l4: 0.034824, l5: 0.025515, l6: 0.021849

[epoch:  87/100000, batch:    58/  187, ite: 8113] train loss: 0.114791, tar: 0.011261 
l0: 0.011108, l1: 0.012113, l2: 0.013265, l3: 0.012816, l4: 0.013888, l5: 0.011462, l6: 0.012313

[epoch:  87/100000, batch:    60/  187, ite: 8114] train loss: 0.114547, tar: 0.011260 
l0: 0.008784, l1: 0.008699, l2: 0.009024, l3: 0.010174, l4: 0.024244, l5: 0.022153, l6: 0.021489

[epoch:  87/100000, batch:    62/  187, ite: 8115] train loss: 0.114460, tar: 0.011238 
l0: 0.014942, l1: 0.015426, l2: 0.017505, l3: 0.016257, l4: 0.038684, l5: 0.030392, l6: 0.031416

[epoch:  87/100000, batch:    64/  187, ite: 8116] train loss: 0.114892, tar: 0.011270 
l0: 0.027164, l1: 0.027980, l2: 0.028392, l3: 0.026116, l4: 0.037397, l5: 0.033215, l6: 0.039254

[epoch:  87/100000, batch:    66/  187, ite: 8117] train loss: 0.115787, tar: 0.011406 
l0: 0.013574, l1: 0.013447, l2: 0.012589, l3: 0.012946, l4: 0.021071, l5: 0.022581, l6: 0.021944

[epoch:  87/100000, batch:    68/  187, ite: 8118] train loss: 0.115807, tar: 0.011424 
l0: 0.015005, l1: 0.016484, l2: 0.015171, l3: 0.014345, l4: 0.015162, l5: 0.015269, l6: 0.014916

[epoch:  87/100000, batch:    70/  187, ite: 8119] train loss: 0.115727, tar: 0.011454 
l0: 0.032239, l1: 0.033846, l2: 0.034135, l3: 0.034101, l4: 0.029448, l5: 0.025986, l6: 0.023856

[epoch:  87/100000, batch:    72/  187, ite: 8120] train loss: 0.116543, tar: 0.011628 
l0: 0.014232, l1: 0.015573, l2: 0.018260, l3: 0.017331, l4: 0.018652, l5: 0.012392, l6: 0.014382

[epoch:  87/100000, batch:    74/  187, ite: 8121] train loss: 0.116496, tar: 0.011649 
l0: 0.020145, l1: 0.018955, l2: 0.028606, l3: 0.029323, l4: 0.022899, l5: 0.021046, l6: 0.020342

[epoch:  87/100000, batch:    76/  187, ite: 8122] train loss: 0.116863, tar: 0.011719 
l0: 0.007534, l1: 0.008091, l2: 0.010566, l3: 0.008263, l4: 0.021597, l5: 0.018771, l6: 0.024209

[epoch:  87/100000, batch:    78/  187, ite: 8123] train loss: 0.116718, tar: 0.011685 
l0: 0.010917, l1: 0.011136, l2: 0.013768, l3: 0.013925, l4: 0.017006, l5: 0.014050, l6: 0.015389

[epoch:  87/100000, batch:    80/  187, ite: 8124] train loss: 0.116552, tar: 0.011679 
l0: 0.013692, l1: 0.015070, l2: 0.013710, l3: 0.014173, l4: 0.023251, l5: 0.019704, l6: 0.020393

[epoch:  87/100000, batch:    82/  187, ite: 8125] train loss: 0.116580, tar: 0.011695 
l0: 0.007604, l1: 0.009926, l2: 0.008687, l3: 0.007884, l4: 0.023596, l5: 0.022690, l6: 0.016085

[epoch:  87/100000, batch:    84/  187, ite: 8126] train loss: 0.116420, tar: 0.011662 
l0: 0.010688, l1: 0.010021, l2: 0.015708, l3: 0.015417, l4: 0.018552, l5: 0.018910, l6: 0.021048

[epoch:  87/100000, batch:    86/  187, ite: 8127] train loss: 0.116373, tar: 0.011655 
l0: 0.008589, l1: 0.009442, l2: 0.009208, l3: 0.009022, l4: 0.011954, l5: 0.012152, l6: 0.016576

[epoch:  87/100000, batch:    88/  187, ite: 8128] train loss: 0.116064, tar: 0.011631 
l0: 0.011763, l1: 0.012207, l2: 0.014311, l3: 0.014223, l4: 0.019212, l5: 0.018987, l6: 0.024703

[epoch:  87/100000, batch:    90/  187, ite: 8129] train loss: 0.116059, tar: 0.011632 
l0: 0.011436, l1: 0.011834, l2: 0.013105, l3: 0.013536, l4: 0.014730, l5: 0.014462, l6: 0.021790

[epoch:  87/100000, batch:    92/  187, ite: 8130] train loss: 0.115943, tar: 0.011630 
l0: 0.006232, l1: 0.006404, l2: 0.006079, l3: 0.006278, l4: 0.017492, l5: 0.018094, l6: 0.020231

[epoch:  87/100000, batch:    94/  187, ite: 8131] train loss: 0.115675, tar: 0.011589 
l0: 0.012579, l1: 0.013789, l2: 0.015456, l3: 0.013432, l4: 0.018227, l5: 0.015748, l6: 0.016352

[epoch:  87/100000, batch:    96/  187, ite: 8132] train loss: 0.115598, tar: 0.011596 
l0: 0.008496, l1: 0.009678, l2: 0.011318, l3: 0.010230, l4: 0.017161, l5: 0.013549, l6: 0.013272

[epoch:  87/100000, batch:    98/  187, ite: 8133] train loss: 0.115358, tar: 0.011573 
l0: 0.009940, l1: 0.010388, l2: 0.011083, l3: 0.011484, l4: 0.021120, l5: 0.019033, l6: 0.017379

[epoch:  87/100000, batch:   100/  187, ite: 8134] train loss: 0.115247, tar: 0.011561 
l0: 0.021996, l1: 0.021946, l2: 0.022484, l3: 0.022876, l4: 0.037148, l5: 0.038123, l6: 0.040912

[epoch:  87/100000, batch:   102/  187, ite: 8135] train loss: 0.115915, tar: 0.011638 
l0: 0.011873, l1: 0.012936, l2: 0.012973, l3: 0.012138, l4: 0.017936, l5: 0.018467, l6: 0.023262

[epoch:  87/100000, batch:   104/  187, ite: 8136] train loss: 0.115869, tar: 0.011640 
l0: 0.007493, l1: 0.007728, l2: 0.008097, l3: 0.008749, l4: 0.016267, l5: 0.015855, l6: 0.013541

[epoch:  87/100000, batch:   106/  187, ite: 8137] train loss: 0.115590, tar: 0.011610 
l0: 0.011422, l1: 0.011918, l2: 0.013837, l3: 0.014630, l4: 0.017965, l5: 0.017970, l6: 0.023172

[epoch:  87/100000, batch:   108/  187, ite: 8138] train loss: 0.115556, tar: 0.011608 
l0: 0.005885, l1: 0.006302, l2: 0.008316, l3: 0.009485, l4: 0.016965, l5: 0.016130, l6: 0.012271

[epoch:  87/100000, batch:   110/  187, ite: 8139] train loss: 0.115267, tar: 0.011567 
l0: 0.012387, l1: 0.013935, l2: 0.021213, l3: 0.021343, l4: 0.023393, l5: 0.022535, l6: 0.021567

[epoch:  87/100000, batch:   112/  187, ite: 8140] train loss: 0.115418, tar: 0.011573 
l0: 0.013089, l1: 0.015172, l2: 0.015174, l3: 0.014917, l4: 0.020197, l5: 0.016839, l6: 0.021525

[epoch:  87/100000, batch:   114/  187, ite: 8141] train loss: 0.115429, tar: 0.011584 
l0: 0.007655, l1: 0.008321, l2: 0.008227, l3: 0.010491, l4: 0.021004, l5: 0.024099, l6: 0.019161

[epoch:  87/100000, batch:   116/  187, ite: 8142] train loss: 0.115313, tar: 0.011556 
l0: 0.017628, l1: 0.017586, l2: 0.018253, l3: 0.018156, l4: 0.020574, l5: 0.019183, l6: 0.019604

[epoch:  87/100000, batch:   118/  187, ite: 8143] train loss: 0.115422, tar: 0.011599 
l0: 0.011858, l1: 0.013169, l2: 0.009594, l3: 0.009577, l4: 0.014594, l5: 0.012361, l6: 0.019805

[epoch:  87/100000, batch:   120/  187, ite: 8144] train loss: 0.115252, tar: 0.011600 
l0: 0.015142, l1: 0.012940, l2: 0.017859, l3: 0.020872, l4: 0.028746, l5: 0.029189, l6: 0.036294

[epoch:  87/100000, batch:   122/  187, ite: 8145] train loss: 0.115568, tar: 0.011625 
l0: 0.009008, l1: 0.008977, l2: 0.009400, l3: 0.009498, l4: 0.016886, l5: 0.018071, l6: 0.017744

[epoch:  87/100000, batch:   124/  187, ite: 8146] train loss: 0.115390, tar: 0.011607 
l0: 0.009844, l1: 0.010614, l2: 0.008621, l3: 0.010188, l4: 0.022409, l5: 0.019526, l6: 0.013592

[epoch:  87/100000, batch:   126/  187, ite: 8147] train loss: 0.115250, tar: 0.011595 
l0: 0.012750, l1: 0.012486, l2: 0.011904, l3: 0.013497, l4: 0.011240, l5: 0.012057, l6: 0.013140

[epoch:  87/100000, batch:   128/  187, ite: 8148] train loss: 0.115060, tar: 0.011603 
l0: 0.011983, l1: 0.012335, l2: 0.011986, l3: 0.013325, l4: 0.024523, l5: 0.024093, l6: 0.021412

[epoch:  87/100000, batch:   130/  187, ite: 8149] train loss: 0.115091, tar: 0.011605 
l0: 0.018914, l1: 0.021720, l2: 0.018366, l3: 0.021187, l4: 0.037217, l5: 0.025910, l6: 0.022278

[epoch:  87/100000, batch:   132/  187, ite: 8150] train loss: 0.115427, tar: 0.011654 
l0: 0.017498, l1: 0.016038, l2: 0.017859, l3: 0.021826, l4: 0.043569, l5: 0.039949, l6: 0.033560

[epoch:  87/100000, batch:   134/  187, ite: 8151] train loss: 0.115923, tar: 0.011693 
l0: 0.007091, l1: 0.006775, l2: 0.011221, l3: 0.011079, l4: 0.011735, l5: 0.009579, l6: 0.008210

[epoch:  87/100000, batch:   136/  187, ite: 8152] train loss: 0.115593, tar: 0.011662 
l0: 0.010537, l1: 0.009988, l2: 0.012179, l3: 0.012730, l4: 0.018602, l5: 0.018865, l6: 0.022800

[epoch:  87/100000, batch:   138/  187, ite: 8153] train loss: 0.115528, tar: 0.011655 
l0: 0.012198, l1: 0.013360, l2: 0.014083, l3: 0.012492, l4: 0.018940, l5: 0.020873, l6: 0.025986

[epoch:  87/100000, batch:   140/  187, ite: 8154] train loss: 0.115543, tar: 0.011659 
l0: 0.012679, l1: 0.012851, l2: 0.013959, l3: 0.014356, l4: 0.016989, l5: 0.019464, l6: 0.018980

[epoch:  87/100000, batch:   142/  187, ite: 8155] train loss: 0.115503, tar: 0.011665 
l0: 0.016530, l1: 0.016805, l2: 0.018706, l3: 0.020504, l4: 0.031038, l5: 0.029314, l6: 0.034106

[epoch:  87/100000, batch:   144/  187, ite: 8156] train loss: 0.115833, tar: 0.011696 
l0: 0.005332, l1: 0.005319, l2: 0.007270, l3: 0.007537, l4: 0.010621, l5: 0.009604, l6: 0.009717

[epoch:  87/100000, batch:   146/  187, ite: 8157] train loss: 0.115448, tar: 0.011656 
l0: 0.013221, l1: 0.012462, l2: 0.013079, l3: 0.015454, l4: 0.032898, l5: 0.032145, l6: 0.035286

[epoch:  87/100000, batch:   148/  187, ite: 8158] train loss: 0.115696, tar: 0.011666 
l0: 0.017749, l1: 0.017567, l2: 0.017825, l3: 0.019529, l4: 0.031316, l5: 0.031939, l6: 0.032110

[epoch:  87/100000, batch:   150/  187, ite: 8159] train loss: 0.116025, tar: 0.011704 
l0: 0.009077, l1: 0.009254, l2: 0.012800, l3: 0.013892, l4: 0.022133, l5: 0.017050, l6: 0.017665

[epoch:  87/100000, batch:   152/  187, ite: 8160] train loss: 0.115936, tar: 0.011688 
l0: 0.017117, l1: 0.015427, l2: 0.020175, l3: 0.021004, l4: 0.031835, l5: 0.034935, l6: 0.036525

[epoch:  87/100000, batch:   154/  187, ite: 8161] train loss: 0.116316, tar: 0.011721 
l0: 0.014515, l1: 0.013928, l2: 0.017164, l3: 0.016725, l4: 0.015423, l5: 0.018198, l6: 0.020773

[epoch:  87/100000, batch:   156/  187, ite: 8162] train loss: 0.116318, tar: 0.011738 
l0: 0.012716, l1: 0.014185, l2: 0.011034, l3: 0.011435, l4: 0.024177, l5: 0.021177, l6: 0.017709

[epoch:  87/100000, batch:   158/  187, ite: 8163] train loss: 0.116295, tar: 0.011744 
l0: 0.006941, l1: 0.009565, l2: 0.008366, l3: 0.004850, l4: 0.015001, l5: 0.014424, l6: 0.014833

[epoch:  87/100000, batch:   160/  187, ite: 8164] train loss: 0.116037, tar: 0.011715 
l0: 0.013573, l1: 0.012085, l2: 0.016968, l3: 0.017670, l4: 0.023561, l5: 0.024783, l6: 0.030378

[epoch:  87/100000, batch:   162/  187, ite: 8165] train loss: 0.116176, tar: 0.011726 
l0: 0.014264, l1: 0.016106, l2: 0.014864, l3: 0.014897, l4: 0.027928, l5: 0.025423, l6: 0.028437

[epoch:  87/100000, batch:   164/  187, ite: 8166] train loss: 0.116331, tar: 0.011742 
l0: 0.005927, l1: 0.006202, l2: 0.006350, l3: 0.007678, l4: 0.010902, l5: 0.011137, l6: 0.013702

[epoch:  87/100000, batch:   166/  187, ite: 8167] train loss: 0.116005, tar: 0.011707 
l0: 0.017964, l1: 0.017740, l2: 0.022224, l3: 0.022568, l4: 0.032497, l5: 0.032460, l6: 0.034029

[epoch:  87/100000, batch:   168/  187, ite: 8168] train loss: 0.116383, tar: 0.011744 
l0: 0.011480, l1: 0.010657, l2: 0.011132, l3: 0.013726, l4: 0.031746, l5: 0.025709, l6: 0.036433

[epoch:  87/100000, batch:   170/  187, ite: 8169] train loss: 0.116528, tar: 0.011743 
l0: 0.008894, l1: 0.008292, l2: 0.010149, l3: 0.012465, l4: 0.030252, l5: 0.028278, l6: 0.026616

[epoch:  87/100000, batch:   172/  187, ite: 8170] train loss: 0.116577, tar: 0.011726 
l0: 0.005751, l1: 0.006318, l2: 0.006517, l3: 0.007007, l4: 0.015196, l5: 0.015048, l6: 0.013470

[epoch:  87/100000, batch:   174/  187, ite: 8171] train loss: 0.116301, tar: 0.011691 
l0: 0.013970, l1: 0.014988, l2: 0.016685, l3: 0.017670, l4: 0.022399, l5: 0.017629, l6: 0.021055

[epoch:  87/100000, batch:   176/  187, ite: 8172] train loss: 0.116348, tar: 0.011704 
l0: 0.009463, l1: 0.010101, l2: 0.010405, l3: 0.010141, l4: 0.014830, l5: 0.016587, l6: 0.018602

[epoch:  87/100000, batch:   178/  187, ite: 8173] train loss: 0.116196, tar: 0.011691 
l0: 0.007931, l1: 0.007897, l2: 0.009294, l3: 0.012506, l4: 0.017705, l5: 0.020617, l6: 0.018255

[epoch:  87/100000, batch:   180/  187, ite: 8174] train loss: 0.116070, tar: 0.011670 
l0: 0.008760, l1: 0.008204, l2: 0.010555, l3: 0.010243, l4: 0.016633, l5: 0.016164, l6: 0.021859

[epoch:  87/100000, batch:   182/  187, ite: 8175] train loss: 0.115935, tar: 0.011653 
l0: 0.008348, l1: 0.008974, l2: 0.009885, l3: 0.010093, l4: 0.015914, l5: 0.014655, l6: 0.015996

[epoch:  87/100000, batch:   184/  187, ite: 8176] train loss: 0.115753, tar: 0.011634 
l0: 0.009511, l1: 0.010239, l2: 0.010121, l3: 0.010484, l4: 0.016203, l5: 0.015203, l6: 0.017488

[epoch:  87/100000, batch:   186/  187, ite: 8177] train loss: 0.115603, tar: 0.011622 
l0: 0.012636, l1: 0.013351, l2: 0.012120, l3: 0.012941, l4: 0.016249, l5: 0.013576, l6: 0.015664

[epoch:  87/100000, batch:   188/  187, ite: 8178] train loss: 0.115496, tar: 0.011628 
l0: 0.009162, l1: 0.009130, l2: 0.010613, l3: 0.011478, l4: 0.014220, l5: 0.014777, l6: 0.012490

[epoch:  88/100000, batch:     2/  187, ite: 8179] train loss: 0.115308, tar: 0.011614 
l0: 0.009494, l1: 0.009900, l2: 0.012890, l3: 0.012950, l4: 0.026434, l5: 0.023845, l6: 0.020418

[epoch:  88/100000, batch:     4/  187, ite: 8180] train loss: 0.115311, tar: 0.011602 
l0: 0.008702, l1: 0.010282, l2: 0.009791, l3: 0.009317, l4: 0.017500, l5: 0.013983, l6: 0.017197

[epoch:  88/100000, batch:     6/  187, ite: 8181] train loss: 0.115154, tar: 0.011586 
l0: 0.012299, l1: 0.012746, l2: 0.014599, l3: 0.016390, l4: 0.019032, l5: 0.019685, l6: 0.022315

[epoch:  88/100000, batch:     8/  187, ite: 8182] train loss: 0.115164, tar: 0.011590 
l0: 0.014403, l1: 0.014805, l2: 0.020138, l3: 0.020216, l4: 0.028023, l5: 0.029448, l6: 0.021077

[epoch:  88/100000, batch:    10/  187, ite: 8183] train loss: 0.115344, tar: 0.011606 
l0: 0.007307, l1: 0.007342, l2: 0.008680, l3: 0.009629, l4: 0.020048, l5: 0.017496, l6: 0.017594

[epoch:  88/100000, batch:    12/  187, ite: 8184] train loss: 0.115196, tar: 0.011582 
l0: 0.010322, l1: 0.010815, l2: 0.013256, l3: 0.013070, l4: 0.031251, l5: 0.026226, l6: 0.029809

[epoch:  88/100000, batch:    14/  187, ite: 8185] train loss: 0.115302, tar: 0.011575 
l0: 0.009973, l1: 0.009984, l2: 0.010921, l3: 0.012935, l4: 0.034617, l5: 0.031162, l6: 0.027062

[epoch:  88/100000, batch:    16/  187, ite: 8186] train loss: 0.115417, tar: 0.011567 
l0: 0.017549, l1: 0.016448, l2: 0.019762, l3: 0.021788, l4: 0.036970, l5: 0.035915, l6: 0.037874

[epoch:  88/100000, batch:    18/  187, ite: 8187] train loss: 0.115796, tar: 0.011599 
l0: 0.009298, l1: 0.009777, l2: 0.011135, l3: 0.010930, l4: 0.018127, l5: 0.014633, l6: 0.016945

[epoch:  88/100000, batch:    20/  187, ite: 8188] train loss: 0.115663, tar: 0.011587 
l0: 0.009707, l1: 0.009065, l2: 0.012331, l3: 0.014317, l4: 0.035995, l5: 0.029909, l6: 0.028684

[epoch:  88/100000, batch:    22/  187, ite: 8189] train loss: 0.115792, tar: 0.011577 
l0: 0.018427, l1: 0.018341, l2: 0.017465, l3: 0.019492, l4: 0.037829, l5: 0.031793, l6: 0.030407

[epoch:  88/100000, batch:    24/  187, ite: 8190] train loss: 0.116097, tar: 0.011613 
l0: 0.008768, l1: 0.010219, l2: 0.009110, l3: 0.009812, l4: 0.016275, l5: 0.014989, l6: 0.015401

[epoch:  88/100000, batch:    26/  187, ite: 8191] train loss: 0.115932, tar: 0.011598 
l0: 0.009762, l1: 0.009357, l2: 0.013552, l3: 0.013788, l4: 0.020170, l5: 0.020348, l6: 0.019445

[epoch:  88/100000, batch:    28/  187, ite: 8192] train loss: 0.115882, tar: 0.011588 
l0: 0.016417, l1: 0.015882, l2: 0.018832, l3: 0.019624, l4: 0.021097, l5: 0.023039, l6: 0.019876

[epoch:  88/100000, batch:    30/  187, ite: 8193] train loss: 0.115980, tar: 0.011613 
l0: 0.007693, l1: 0.008538, l2: 0.008489, l3: 0.007648, l4: 0.012376, l5: 0.015793, l6: 0.022668

[epoch:  88/100000, batch:    32/  187, ite: 8194] train loss: 0.115811, tar: 0.011593 
l0: 0.007449, l1: 0.007180, l2: 0.010461, l3: 0.011203, l4: 0.020199, l5: 0.016029, l6: 0.017453

[epoch:  88/100000, batch:    34/  187, ite: 8195] train loss: 0.115679, tar: 0.011572 
l0: 0.010244, l1: 0.009660, l2: 0.012191, l3: 0.010211, l4: 0.016771, l5: 0.015393, l6: 0.017315

[epoch:  88/100000, batch:    36/  187, ite: 8196] train loss: 0.115557, tar: 0.011565 
l0: 0.014887, l1: 0.015881, l2: 0.015857, l3: 0.015962, l4: 0.025549, l5: 0.022242, l6: 0.021620

[epoch:  88/100000, batch:    38/  187, ite: 8197] train loss: 0.115640, tar: 0.011582 
l0: 0.008621, l1: 0.008239, l2: 0.011782, l3: 0.011260, l4: 0.013612, l5: 0.013571, l6: 0.018908

[epoch:  88/100000, batch:    40/  187, ite: 8198] train loss: 0.115491, tar: 0.011567 
l0: 0.018052, l1: 0.017244, l2: 0.022528, l3: 0.023865, l4: 0.040045, l5: 0.034987, l6: 0.034594

[epoch:  88/100000, batch:    42/  187, ite: 8199] train loss: 0.115872, tar: 0.011600 
l0: 0.009424, l1: 0.009397, l2: 0.010648, l3: 0.011773, l4: 0.016987, l5: 0.014846, l6: 0.016826

[epoch:  88/100000, batch:    44/  187, ite: 8200] train loss: 0.115742, tar: 0.011589 
l0: 0.014314, l1: 0.015229, l2: 0.019551, l3: 0.021240, l4: 0.024466, l5: 0.027101, l6: 0.023937

[epoch:  88/100000, batch:    46/  187, ite: 8201] train loss: 0.115891, tar: 0.011602 
l0: 0.007648, l1: 0.007087, l2: 0.008459, l3: 0.010016, l4: 0.017451, l5: 0.017981, l6: 0.019572

[epoch:  88/100000, batch:    48/  187, ite: 8202] train loss: 0.115754, tar: 0.011583 
l0: 0.008069, l1: 0.008130, l2: 0.009890, l3: 0.011025, l4: 0.018527, l5: 0.017235, l6: 0.016857

[epoch:  88/100000, batch:    50/  187, ite: 8203] train loss: 0.115626, tar: 0.011565 
l0: 0.005193, l1: 0.007491, l2: 0.012615, l3: 0.006644, l4: 0.008286, l5: 0.011785, l6: 0.008918

[epoch:  88/100000, batch:    52/  187, ite: 8204] train loss: 0.115358, tar: 0.011534 
l0: 0.006576, l1: 0.007065, l2: 0.008280, l3: 0.008508, l4: 0.024723, l5: 0.017720, l6: 0.016739

[epoch:  88/100000, batch:    54/  187, ite: 8205] train loss: 0.115233, tar: 0.011510 
l0: 0.008693, l1: 0.009266, l2: 0.008566, l3: 0.009486, l4: 0.020518, l5: 0.021152, l6: 0.027018

[epoch:  88/100000, batch:    56/  187, ite: 8206] train loss: 0.115181, tar: 0.011496 
l0: 0.008946, l1: 0.009505, l2: 0.009553, l3: 0.009005, l4: 0.016731, l5: 0.012566, l6: 0.014347

[epoch:  88/100000, batch:    58/  187, ite: 8207] train loss: 0.115015, tar: 0.011484 
l0: 0.007312, l1: 0.007694, l2: 0.007520, l3: 0.007158, l4: 0.011521, l5: 0.012700, l6: 0.011552

[epoch:  88/100000, batch:    60/  187, ite: 8208] train loss: 0.114776, tar: 0.011464 
l0: 0.009680, l1: 0.010466, l2: 0.009534, l3: 0.008919, l4: 0.022398, l5: 0.022198, l6: 0.021691

[epoch:  88/100000, batch:    62/  187, ite: 8209] train loss: 0.114729, tar: 0.011455 
l0: 0.006316, l1: 0.006588, l2: 0.007759, l3: 0.008259, l4: 0.019639, l5: 0.023486, l6: 0.021388

[epoch:  88/100000, batch:    64/  187, ite: 8210] train loss: 0.114628, tar: 0.011431 
l0: 0.006491, l1: 0.006448, l2: 0.007196, l3: 0.007329, l4: 0.014227, l5: 0.016157, l6: 0.015791

[epoch:  88/100000, batch:    66/  187, ite: 8211] train loss: 0.114433, tar: 0.011407 
l0: 0.013923, l1: 0.013991, l2: 0.016481, l3: 0.016177, l4: 0.023664, l5: 0.024418, l6: 0.024626

[epoch:  88/100000, batch:    68/  187, ite: 8212] train loss: 0.114522, tar: 0.011419 
l0: 0.022097, l1: 0.020533, l2: 0.023477, l3: 0.025188, l4: 0.041673, l5: 0.041938, l6: 0.041991

[epoch:  88/100000, batch:    70/  187, ite: 8213] train loss: 0.115003, tar: 0.011469 
l0: 0.009315, l1: 0.008743, l2: 0.011627, l3: 0.012422, l4: 0.012767, l5: 0.012140, l6: 0.014103

[epoch:  88/100000, batch:    72/  187, ite: 8214] train loss: 0.114845, tar: 0.011459 
l0: 0.014791, l1: 0.015736, l2: 0.017119, l3: 0.018283, l4: 0.025390, l5: 0.023092, l6: 0.019668

[epoch:  88/100000, batch:    74/  187, ite: 8215] train loss: 0.114934, tar: 0.011475 
l0: 0.011946, l1: 0.012251, l2: 0.011256, l3: 0.009724, l4: 0.013707, l5: 0.019002, l6: 0.016803

[epoch:  88/100000, batch:    76/  187, ite: 8216] train loss: 0.114840, tar: 0.011477 
l0: 0.009286, l1: 0.009142, l2: 0.012036, l3: 0.011124, l4: 0.013314, l5: 0.017213, l6: 0.016677

[epoch:  88/100000, batch:    78/  187, ite: 8217] train loss: 0.114720, tar: 0.011467 
l0: 0.011366, l1: 0.011511, l2: 0.012656, l3: 0.014823, l4: 0.028251, l5: 0.028545, l6: 0.021532

[epoch:  88/100000, batch:    80/  187, ite: 8218] train loss: 0.114784, tar: 0.011466 
l0: 0.010389, l1: 0.011652, l2: 0.011257, l3: 0.010155, l4: 0.013308, l5: 0.011651, l6: 0.015620

[epoch:  88/100000, batch:    82/  187, ite: 8219] train loss: 0.114644, tar: 0.011462 
l0: 0.009807, l1: 0.009377, l2: 0.010638, l3: 0.012810, l4: 0.020963, l5: 0.020078, l6: 0.019918

[epoch:  88/100000, batch:    84/  187, ite: 8220] train loss: 0.114594, tar: 0.011454 
l0: 0.007926, l1: 0.008854, l2: 0.009229, l3: 0.008480, l4: 0.017187, l5: 0.015263, l6: 0.013007

[epoch:  88/100000, batch:    86/  187, ite: 8221] train loss: 0.114437, tar: 0.011438 
l0: 0.006695, l1: 0.008002, l2: 0.007464, l3: 0.006888, l4: 0.018793, l5: 0.015670, l6: 0.015905

[epoch:  88/100000, batch:    88/  187, ite: 8222] train loss: 0.114279, tar: 0.011417 
l0: 0.014596, l1: 0.015195, l2: 0.017699, l3: 0.013757, l4: 0.019056, l5: 0.021347, l6: 0.026023

[epoch:  88/100000, batch:    90/  187, ite: 8223] train loss: 0.114339, tar: 0.011431 
l0: 0.008418, l1: 0.009050, l2: 0.012974, l3: 0.012348, l4: 0.019909, l5: 0.013269, l6: 0.010560

[epoch:  88/100000, batch:    92/  187, ite: 8224] train loss: 0.114215, tar: 0.011417 
l0: 0.006201, l1: 0.006886, l2: 0.006367, l3: 0.006560, l4: 0.011223, l5: 0.011990, l6: 0.012534

[epoch:  88/100000, batch:    94/  187, ite: 8225] train loss: 0.113982, tar: 0.011394 
l0: 0.022814, l1: 0.022125, l2: 0.020496, l3: 0.021731, l4: 0.038159, l5: 0.046256, l6: 0.044195

[epoch:  88/100000, batch:    96/  187, ite: 8226] train loss: 0.114432, tar: 0.011445 
l0: 0.007377, l1: 0.007195, l2: 0.009117, l3: 0.010235, l4: 0.017235, l5: 0.014305, l6: 0.016633

[epoch:  88/100000, batch:    98/  187, ite: 8227] train loss: 0.114290, tar: 0.011427 
l0: 0.006567, l1: 0.007592, l2: 0.006390, l3: 0.007005, l4: 0.017313, l5: 0.012981, l6: 0.015046

[epoch:  88/100000, batch:   100/  187, ite: 8228] train loss: 0.114108, tar: 0.011406 
l0: 0.008901, l1: 0.009538, l2: 0.010210, l3: 0.009078, l4: 0.011290, l5: 0.011589, l6: 0.012728

[epoch:  88/100000, batch:   102/  187, ite: 8229] train loss: 0.113930, tar: 0.011395 
l0: 0.008972, l1: 0.007989, l2: 0.011208, l3: 0.011251, l4: 0.019643, l5: 0.020306, l6: 0.027849

[epoch:  88/100000, batch:   104/  187, ite: 8230] train loss: 0.113901, tar: 0.011384 
l0: 0.005134, l1: 0.005467, l2: 0.006494, l3: 0.006928, l4: 0.009450, l5: 0.010676, l6: 0.009081

[epoch:  88/100000, batch:   106/  187, ite: 8231] train loss: 0.113638, tar: 0.011357 
l0: 0.008177, l1: 0.007848, l2: 0.009713, l3: 0.009597, l4: 0.018257, l5: 0.021994, l6: 0.022025

[epoch:  88/100000, batch:   108/  187, ite: 8232] train loss: 0.113569, tar: 0.011343 
l0: 0.012053, l1: 0.011269, l2: 0.012368, l3: 0.013968, l4: 0.033008, l5: 0.032905, l6: 0.034401

[epoch:  88/100000, batch:   110/  187, ite: 8233] train loss: 0.113726, tar: 0.011346 
l0: 0.009822, l1: 0.009900, l2: 0.015036, l3: 0.018069, l4: 0.017213, l5: 0.019317, l6: 0.019966

[epoch:  88/100000, batch:   112/  187, ite: 8234] train loss: 0.113707, tar: 0.011340 
l0: 0.007582, l1: 0.008743, l2: 0.009744, l3: 0.009908, l4: 0.016749, l5: 0.015625, l6: 0.014239

[epoch:  88/100000, batch:   114/  187, ite: 8235] train loss: 0.113574, tar: 0.011324 
l0: 0.018627, l1: 0.018251, l2: 0.018386, l3: 0.017138, l4: 0.018830, l5: 0.022608, l6: 0.027575

[epoch:  88/100000, batch:   116/  187, ite: 8236] train loss: 0.113692, tar: 0.011355 
l0: 0.013389, l1: 0.015562, l2: 0.016014, l3: 0.014675, l4: 0.026132, l5: 0.018225, l6: 0.019665

[epoch:  88/100000, batch:   118/  187, ite: 8237] train loss: 0.113734, tar: 0.011363 
l0: 0.011293, l1: 0.011526, l2: 0.011704, l3: 0.011067, l4: 0.016222, l5: 0.018664, l6: 0.019490

[epoch:  88/100000, batch:   120/  187, ite: 8238] train loss: 0.113677, tar: 0.011363 
l0: 0.019189, l1: 0.017422, l2: 0.020784, l3: 0.021027, l4: 0.058307, l5: 0.051921, l6: 0.041453

[epoch:  88/100000, batch:   122/  187, ite: 8239] train loss: 0.114164, tar: 0.011396 
l0: 0.006037, l1: 0.006167, l2: 0.006677, l3: 0.006803, l4: 0.010495, l5: 0.011024, l6: 0.012710

[epoch:  88/100000, batch:   124/  187, ite: 8240] train loss: 0.113938, tar: 0.011374 
l0: 0.008515, l1: 0.008966, l2: 0.009729, l3: 0.009637, l4: 0.019227, l5: 0.016621, l6: 0.016813

[epoch:  88/100000, batch:   126/  187, ite: 8241] train loss: 0.113836, tar: 0.011362 
l0: 0.004994, l1: 0.005469, l2: 0.006467, l3: 0.006641, l4: 0.009852, l5: 0.009294, l6: 0.011320

[epoch:  88/100000, batch:   128/  187, ite: 8242] train loss: 0.113589, tar: 0.011335 
l0: 0.006470, l1: 0.006871, l2: 0.010015, l3: 0.010552, l4: 0.014426, l5: 0.012954, l6: 0.013883

[epoch:  88/100000, batch:   130/  187, ite: 8243] train loss: 0.113431, tar: 0.011315 
l0: 0.007459, l1: 0.008032, l2: 0.008818, l3: 0.011102, l4: 0.014599, l5: 0.015328, l6: 0.015021

[epoch:  88/100000, batch:   132/  187, ite: 8244] train loss: 0.113296, tar: 0.011300 
l0: 0.008898, l1: 0.008168, l2: 0.010660, l3: 0.011731, l4: 0.021089, l5: 0.019219, l6: 0.024464

[epoch:  88/100000, batch:   134/  187, ite: 8245] train loss: 0.113259, tar: 0.011290 
l0: 0.005745, l1: 0.005273, l2: 0.006812, l3: 0.008038, l4: 0.015569, l5: 0.019352, l6: 0.023053

[epoch:  88/100000, batch:   136/  187, ite: 8246] train loss: 0.113139, tar: 0.011267 
l0: 0.006716, l1: 0.007758, l2: 0.007305, l3: 0.007513, l4: 0.019704, l5: 0.020584, l6: 0.025265

[epoch:  88/100000, batch:   138/  187, ite: 8247] train loss: 0.113065, tar: 0.011249 
l0: 0.012002, l1: 0.011655, l2: 0.014564, l3: 0.014331, l4: 0.015258, l5: 0.019825, l6: 0.027587

[epoch:  88/100000, batch:   140/  187, ite: 8248] train loss: 0.113074, tar: 0.011252 
l0: 0.015068, l1: 0.015384, l2: 0.017418, l3: 0.017549, l4: 0.023576, l5: 0.022804, l6: 0.028178

[epoch:  88/100000, batch:   142/  187, ite: 8249] train loss: 0.113182, tar: 0.011267 
l0: 0.009873, l1: 0.009911, l2: 0.012612, l3: 0.014226, l4: 0.029724, l5: 0.024254, l6: 0.023116

[epoch:  88/100000, batch:   144/  187, ite: 8250] train loss: 0.113224, tar: 0.011262 
l0: 0.007242, l1: 0.007675, l2: 0.011932, l3: 0.009714, l4: 0.016252, l5: 0.011665, l6: 0.012770

[epoch:  88/100000, batch:   146/  187, ite: 8251] train loss: 0.113080, tar: 0.011246 
l0: 0.007386, l1: 0.007171, l2: 0.008213, l3: 0.008358, l4: 0.017839, l5: 0.020210, l6: 0.019006

[epoch:  88/100000, batch:   148/  187, ite: 8252] train loss: 0.112982, tar: 0.011230 
l0: 0.006132, l1: 0.006040, l2: 0.006112, l3: 0.007883, l4: 0.012620, l5: 0.013389, l6: 0.011650

[epoch:  88/100000, batch:   150/  187, ite: 8253] train loss: 0.112787, tar: 0.011210 
l0: 0.010475, l1: 0.010125, l2: 0.011790, l3: 0.012203, l4: 0.017381, l5: 0.015759, l6: 0.019685

[epoch:  88/100000, batch:   152/  187, ite: 8254] train loss: 0.112727, tar: 0.011207 
l0: 0.008795, l1: 0.009778, l2: 0.010168, l3: 0.011442, l4: 0.022448, l5: 0.019728, l6: 0.021953

[epoch:  88/100000, batch:   154/  187, ite: 8255] train loss: 0.112694, tar: 0.011198 
l0: 0.011753, l1: 0.011111, l2: 0.013816, l3: 0.015435, l4: 0.021124, l5: 0.020451, l6: 0.020411

[epoch:  88/100000, batch:   156/  187, ite: 8256] train loss: 0.112699, tar: 0.011200 
l0: 0.006513, l1: 0.007678, l2: 0.007828, l3: 0.007023, l4: 0.015120, l5: 0.013112, l6: 0.014083

[epoch:  88/100000, batch:   158/  187, ite: 8257] train loss: 0.112539, tar: 0.011182 
l0: 0.009625, l1: 0.010156, l2: 0.011344, l3: 0.012133, l4: 0.012930, l5: 0.017132, l6: 0.017724

[epoch:  88/100000, batch:   160/  187, ite: 8258] train loss: 0.112455, tar: 0.011176 
l0: 0.009163, l1: 0.009763, l2: 0.010896, l3: 0.013628, l4: 0.032349, l5: 0.021786, l6: 0.020615

[epoch:  88/100000, batch:   162/  187, ite: 8259] train loss: 0.112477, tar: 0.011168 
l0: 0.015733, l1: 0.015014, l2: 0.018583, l3: 0.019572, l4: 0.024608, l5: 0.022857, l6: 0.029738

[epoch:  88/100000, batch:   164/  187, ite: 8260] train loss: 0.112607, tar: 0.011185 
l0: 0.005721, l1: 0.005647, l2: 0.005930, l3: 0.007458, l4: 0.016325, l5: 0.015474, l6: 0.018273

[epoch:  88/100000, batch:   166/  187, ite: 8261] train loss: 0.112462, tar: 0.011164 
l0: 0.006205, l1: 0.018128, l2: 0.016509, l3: 0.006008, l4: 0.005092, l5: 0.005272, l6: 0.005793

[epoch:  88/100000, batch:   168/  187, ite: 8262] train loss: 0.112273, tar: 0.011146 
l0: 0.011225, l1: 0.011962, l2: 0.015198, l3: 0.012838, l4: 0.019916, l5: 0.021045, l6: 0.023916

[epoch:  88/100000, batch:   170/  187, ite: 8263] train loss: 0.112288, tar: 0.011146 
l0: 0.010937, l1: 0.010743, l2: 0.011254, l3: 0.013422, l4: 0.016169, l5: 0.018974, l6: 0.028480

[epoch:  88/100000, batch:   172/  187, ite: 8264] train loss: 0.112279, tar: 0.011145 
l0: 0.016837, l1: 0.017237, l2: 0.017339, l3: 0.015509, l4: 0.020413, l5: 0.024056, l6: 0.029024

[epoch:  88/100000, batch:   174/  187, ite: 8265] train loss: 0.112385, tar: 0.011167 
l0: 0.007613, l1: 0.007643, l2: 0.008335, l3: 0.010288, l4: 0.026759, l5: 0.022948, l6: 0.022391

[epoch:  88/100000, batch:   176/  187, ite: 8266] train loss: 0.112361, tar: 0.011153 
l0: 0.006272, l1: 0.006359, l2: 0.005597, l3: 0.007264, l4: 0.020776, l5: 0.016415, l6: 0.017647

[epoch:  88/100000, batch:   178/  187, ite: 8267] train loss: 0.112241, tar: 0.011135 
l0: 0.007970, l1: 0.008570, l2: 0.010537, l3: 0.010158, l4: 0.012113, l5: 0.010662, l6: 0.010041

[epoch:  88/100000, batch:   180/  187, ite: 8268] train loss: 0.112084, tar: 0.011123 
l0: 0.005065, l1: 0.004639, l2: 0.009599, l3: 0.009023, l4: 0.009911, l5: 0.012197, l6: 0.013323

[epoch:  88/100000, batch:   182/  187, ite: 8269] train loss: 0.111904, tar: 0.011101 
l0: 0.007448, l1: 0.007425, l2: 0.009388, l3: 0.009901, l4: 0.016395, l5: 0.014093, l6: 0.014258

[epoch:  88/100000, batch:   184/  187, ite: 8270] train loss: 0.111782, tar: 0.011087 
l0: 0.011756, l1: 0.011583, l2: 0.011123, l3: 0.011572, l4: 0.023727, l5: 0.019643, l6: 0.030149

[epoch:  88/100000, batch:   186/  187, ite: 8271] train loss: 0.111811, tar: 0.011090 
l0: 0.012641, l1: 0.012826, l2: 0.018309, l3: 0.013463, l4: 0.033642, l5: 0.029617, l6: 0.027012

[epoch:  88/100000, batch:   188/  187, ite: 8272] train loss: 0.111942, tar: 0.011095 
l0: 0.006975, l1: 0.007344, l2: 0.007082, l3: 0.006577, l4: 0.018029, l5: 0.015652, l6: 0.015365

[epoch:  89/100000, batch:     2/  187, ite: 8273] train loss: 0.111814, tar: 0.011080 
l0: 0.011157, l1: 0.010376, l2: 0.013125, l3: 0.013739, l4: 0.018884, l5: 0.019165, l6: 0.021983

[epoch:  89/100000, batch:     4/  187, ite: 8274] train loss: 0.111802, tar: 0.011080 
l0: 0.004913, l1: 0.005044, l2: 0.006421, l3: 0.008367, l4: 0.017178, l5: 0.015341, l6: 0.013036

[epoch:  89/100000, batch:     6/  187, ite: 8275] train loss: 0.111651, tar: 0.011058 
l0: 0.009426, l1: 0.010130, l2: 0.010404, l3: 0.010899, l4: 0.021076, l5: 0.022182, l6: 0.020849

[epoch:  89/100000, batch:     8/  187, ite: 8276] train loss: 0.111626, tar: 0.011052 
l0: 0.002609, l1: 0.002492, l2: 0.003266, l3: 0.002971, l4: 0.009940, l5: 0.009496, l6: 0.007634

[epoch:  89/100000, batch:    10/  187, ite: 8277] train loss: 0.111362, tar: 0.011022 
l0: 0.013933, l1: 0.011014, l2: 0.021222, l3: 0.023994, l4: 0.025142, l5: 0.027633, l6: 0.022860

[epoch:  89/100000, batch:    12/  187, ite: 8278] train loss: 0.111486, tar: 0.011032 
l0: 0.006831, l1: 0.006421, l2: 0.006276, l3: 0.008293, l4: 0.014801, l5: 0.013901, l6: 0.015916

[epoch:  89/100000, batch:    14/  187, ite: 8279] train loss: 0.111346, tar: 0.011017 
l0: 0.013302, l1: 0.014746, l2: 0.014396, l3: 0.015876, l4: 0.026363, l5: 0.026979, l6: 0.027179

[epoch:  89/100000, batch:    16/  187, ite: 8280] train loss: 0.111444, tar: 0.011025 
l0: 0.007399, l1: 0.008261, l2: 0.010509, l3: 0.010076, l4: 0.017606, l5: 0.016255, l6: 0.014096

[epoch:  89/100000, batch:    18/  187, ite: 8281] train loss: 0.111347, tar: 0.011012 
l0: 0.010301, l1: 0.010739, l2: 0.011522, l3: 0.011302, l4: 0.018984, l5: 0.016797, l6: 0.022427

[epoch:  89/100000, batch:    20/  187, ite: 8282] train loss: 0.111314, tar: 0.011010 
l0: 0.016652, l1: 0.016503, l2: 0.021050, l3: 0.020944, l4: 0.017745, l5: 0.017908, l6: 0.019189

[epoch:  89/100000, batch:    22/  187, ite: 8283] train loss: 0.111380, tar: 0.011030 
l0: 0.008410, l1: 0.008924, l2: 0.010071, l3: 0.012181, l4: 0.019362, l5: 0.013076, l6: 0.016143

[epoch:  89/100000, batch:    24/  187, ite: 8284] train loss: 0.111299, tar: 0.011020 
l0: 0.003264, l1: 0.003455, l2: 0.003203, l3: 0.004383, l4: 0.008008, l5: 0.009001, l6: 0.007998

[epoch:  89/100000, batch:    26/  187, ite: 8285] train loss: 0.111046, tar: 0.010993 
l0: 0.010132, l1: 0.009915, l2: 0.009909, l3: 0.010768, l4: 0.013591, l5: 0.013281, l6: 0.015727

[epoch:  89/100000, batch:    28/  187, ite: 8286] train loss: 0.110949, tar: 0.010990 
l0: 0.016347, l1: 0.014775, l2: 0.016654, l3: 0.023434, l4: 0.041789, l5: 0.038686, l6: 0.031304

[epoch:  89/100000, batch:    30/  187, ite: 8287] train loss: 0.111200, tar: 0.011009 
l0: 0.006793, l1: 0.006454, l2: 0.012838, l3: 0.014252, l4: 0.013039, l5: 0.013925, l6: 0.013188

[epoch:  89/100000, batch:    32/  187, ite: 8288] train loss: 0.111093, tar: 0.010994 
l0: 0.003597, l1: 0.003119, l2: 0.007661, l3: 0.005278, l4: 0.006120, l5: 0.007364, l6: 0.008896

[epoch:  89/100000, batch:    34/  187, ite: 8289] train loss: 0.110854, tar: 0.010969 
l0: 0.006435, l1: 0.006497, l2: 0.008242, l3: 0.011381, l4: 0.016625, l5: 0.015085, l6: 0.016152

[epoch:  89/100000, batch:    36/  187, ite: 8290] train loss: 0.110750, tar: 0.010953 
l0: 0.009159, l1: 0.008956, l2: 0.009127, l3: 0.010214, l4: 0.018608, l5: 0.018123, l6: 0.018546

[epoch:  89/100000, batch:    38/  187, ite: 8291] train loss: 0.110688, tar: 0.010947 
l0: 0.009969, l1: 0.009840, l2: 0.011172, l3: 0.011015, l4: 0.018736, l5: 0.018315, l6: 0.018380

[epoch:  89/100000, batch:    40/  187, ite: 8292] train loss: 0.110642, tar: 0.010944 
l0: 0.013523, l1: 0.015211, l2: 0.018640, l3: 0.014871, l4: 0.023924, l5: 0.019802, l6: 0.019592

[epoch:  89/100000, batch:    42/  187, ite: 8293] train loss: 0.110693, tar: 0.010952 
l0: 0.004937, l1: 0.004736, l2: 0.006544, l3: 0.005185, l4: 0.012704, l5: 0.014622, l6: 0.012379

[epoch:  89/100000, batch:    44/  187, ite: 8294] train loss: 0.110524, tar: 0.010932 
l0: 0.007607, l1: 0.008391, l2: 0.008846, l3: 0.006297, l4: 0.009442, l5: 0.009361, l6: 0.009534

[epoch:  89/100000, batch:    46/  187, ite: 8295] train loss: 0.110351, tar: 0.010921 
l0: 0.009677, l1: 0.010687, l2: 0.009403, l3: 0.009816, l4: 0.013108, l5: 0.010711, l6: 0.009685

[epoch:  89/100000, batch:    48/  187, ite: 8296] train loss: 0.110226, tar: 0.010916 
l0: 0.014592, l1: 0.016669, l2: 0.015623, l3: 0.014851, l4: 0.033746, l5: 0.033469, l6: 0.034509

[epoch:  89/100000, batch:    50/  187, ite: 8297] train loss: 0.110405, tar: 0.010929 
l0: 0.008742, l1: 0.009306, l2: 0.011035, l3: 0.012425, l4: 0.011908, l5: 0.011440, l6: 0.016753

[epoch:  89/100000, batch:    52/  187, ite: 8298] train loss: 0.110308, tar: 0.010921 
l0: 0.010409, l1: 0.011660, l2: 0.009038, l3: 0.008343, l4: 0.012538, l5: 0.012936, l6: 0.016177

[epoch:  89/100000, batch:    54/  187, ite: 8299] train loss: 0.110210, tar: 0.010920 
l0: 0.013091, l1: 0.014415, l2: 0.016564, l3: 0.017980, l4: 0.015495, l5: 0.013445, l6: 0.015377

[epoch:  89/100000, batch:    56/  187, ite: 8300] train loss: 0.110198, tar: 0.010927 
l0: 0.007883, l1: 0.008523, l2: 0.008636, l3: 0.009625, l4: 0.021813, l5: 0.019267, l6: 0.020819

[epoch:  89/100000, batch:    58/  187, ite: 8301] train loss: 0.110152, tar: 0.010917 
l0: 0.007942, l1: 0.008963, l2: 0.011958, l3: 0.008048, l4: 0.011779, l5: 0.015280, l6: 0.017820

[epoch:  89/100000, batch:    60/  187, ite: 8302] train loss: 0.110058, tar: 0.010907 
l0: 0.008457, l1: 0.008096, l2: 0.011798, l3: 0.011350, l4: 0.012257, l5: 0.011145, l6: 0.014309

[epoch:  89/100000, batch:    62/  187, ite: 8303] train loss: 0.109951, tar: 0.010899 
l0: 0.004815, l1: 0.004935, l2: 0.008107, l3: 0.007754, l4: 0.028199, l5: 0.022193, l6: 0.016853

[epoch:  89/100000, batch:    64/  187, ite: 8304] train loss: 0.109894, tar: 0.010879 
l0: 0.009580, l1: 0.009920, l2: 0.009856, l3: 0.011359, l4: 0.016485, l5: 0.017143, l6: 0.015936

[epoch:  89/100000, batch:    66/  187, ite: 8305] train loss: 0.109830, tar: 0.010875 
l0: 0.008729, l1: 0.008757, l2: 0.014290, l3: 0.013700, l4: 0.018898, l5: 0.020243, l6: 0.017518

[epoch:  89/100000, batch:    68/  187, ite: 8306] train loss: 0.109805, tar: 0.010868 
l0: 0.007843, l1: 0.007967, l2: 0.009661, l3: 0.009351, l4: 0.012548, l5: 0.012742, l6: 0.013173

[epoch:  89/100000, batch:    70/  187, ite: 8307] train loss: 0.109686, tar: 0.010858 
l0: 0.009029, l1: 0.010467, l2: 0.010464, l3: 0.010085, l4: 0.022969, l5: 0.020036, l6: 0.021257

[epoch:  89/100000, batch:    72/  187, ite: 8308] train loss: 0.109669, tar: 0.010852 
l0: 0.018550, l1: 0.017007, l2: 0.020873, l3: 0.025829, l4: 0.039259, l5: 0.037838, l6: 0.033876

[epoch:  89/100000, batch:    74/  187, ite: 8309] train loss: 0.109939, tar: 0.010877 
l0: 0.009118, l1: 0.009212, l2: 0.010236, l3: 0.008557, l4: 0.016568, l5: 0.019107, l6: 0.019036

[epoch:  89/100000, batch:    76/  187, ite: 8310] train loss: 0.109881, tar: 0.010871 
l0: 0.007029, l1: 0.007820, l2: 0.007812, l3: 0.008555, l4: 0.012919, l5: 0.010630, l6: 0.009304

[epoch:  89/100000, batch:    78/  187, ite: 8311] train loss: 0.109733, tar: 0.010859 
l0: 0.007660, l1: 0.008728, l2: 0.009547, l3: 0.010550, l4: 0.021170, l5: 0.012950, l6: 0.014477

[epoch:  89/100000, batch:    80/  187, ite: 8312] train loss: 0.109654, tar: 0.010848 
l0: 0.006528, l1: 0.006279, l2: 0.010228, l3: 0.011076, l4: 0.012362, l5: 0.011656, l6: 0.010108

[epoch:  89/100000, batch:    82/  187, ite: 8313] train loss: 0.109522, tar: 0.010835 
l0: 0.007247, l1: 0.007318, l2: 0.010229, l3: 0.010200, l4: 0.015390, l5: 0.015445, l6: 0.013616

[epoch:  89/100000, batch:    84/  187, ite: 8314] train loss: 0.109426, tar: 0.010823 
l0: 0.006086, l1: 0.005964, l2: 0.007930, l3: 0.006068, l4: 0.017882, l5: 0.020260, l6: 0.017523

[epoch:  89/100000, batch:    86/  187, ite: 8315] train loss: 0.109338, tar: 0.010808 
l0: 0.009813, l1: 0.010532, l2: 0.008679, l3: 0.009364, l4: 0.013049, l5: 0.013274, l6: 0.015167

[epoch:  89/100000, batch:    88/  187, ite: 8316] train loss: 0.109245, tar: 0.010805 
l0: 0.013910, l1: 0.015131, l2: 0.015408, l3: 0.015264, l4: 0.018728, l5: 0.018894, l6: 0.018776

[epoch:  89/100000, batch:    90/  187, ite: 8317] train loss: 0.109267, tar: 0.010815 
l0: 0.007218, l1: 0.007882, l2: 0.009145, l3: 0.008744, l4: 0.019631, l5: 0.018835, l6: 0.021102

[epoch:  89/100000, batch:    92/  187, ite: 8318] train loss: 0.109214, tar: 0.010804 
l0: 0.008567, l1: 0.009408, l2: 0.007446, l3: 0.007912, l4: 0.018300, l5: 0.021614, l6: 0.013506

[epoch:  89/100000, batch:    94/  187, ite: 8319] train loss: 0.109144, tar: 0.010797 
l0: 0.007012, l1: 0.006820, l2: 0.010951, l3: 0.010985, l4: 0.021058, l5: 0.016497, l6: 0.017490

[epoch:  89/100000, batch:    96/  187, ite: 8320] train loss: 0.109086, tar: 0.010785 
l0: 0.007220, l1: 0.006928, l2: 0.007038, l3: 0.008160, l4: 0.015918, l5: 0.014567, l6: 0.014568

[epoch:  89/100000, batch:    98/  187, ite: 8321] train loss: 0.108978, tar: 0.010774 
l0: 0.010606, l1: 0.010695, l2: 0.016667, l3: 0.016485, l4: 0.025877, l5: 0.018141, l6: 0.019117

[epoch:  89/100000, batch:   100/  187, ite: 8322] train loss: 0.109005, tar: 0.010773 
l0: 0.005850, l1: 0.006369, l2: 0.006320, l3: 0.006788, l4: 0.010338, l5: 0.011111, l6: 0.013179

[epoch:  89/100000, batch:   102/  187, ite: 8323] train loss: 0.108853, tar: 0.010758 
l0: 0.016377, l1: 0.016396, l2: 0.017030, l3: 0.015314, l4: 0.059911, l5: 0.061512, l6: 0.052220

[epoch:  89/100000, batch:   104/  187, ite: 8324] train loss: 0.109254, tar: 0.010775 
l0: 0.007770, l1: 0.008019, l2: 0.007028, l3: 0.005976, l4: 0.023756, l5: 0.025774, l6: 0.030328

[epoch:  89/100000, batch:   106/  187, ite: 8325] train loss: 0.109252, tar: 0.010766 
l0: 0.014640, l1: 0.014916, l2: 0.017018, l3: 0.018321, l4: 0.024234, l5: 0.020724, l6: 0.028464

[epoch:  89/100000, batch:   108/  187, ite: 8326] train loss: 0.109341, tar: 0.010778 
l0: 0.009705, l1: 0.009232, l2: 0.011966, l3: 0.011652, l4: 0.021712, l5: 0.019911, l6: 0.018008

[epoch:  89/100000, batch:   110/  187, ite: 8327] train loss: 0.109320, tar: 0.010775 
l0: 0.005725, l1: 0.006120, l2: 0.007051, l3: 0.006862, l4: 0.012338, l5: 0.012845, l6: 0.016503

[epoch:  89/100000, batch:   112/  187, ite: 8328] train loss: 0.109192, tar: 0.010759 
l0: 0.009795, l1: 0.010308, l2: 0.011993, l3: 0.012138, l4: 0.019168, l5: 0.016713, l6: 0.015185

[epoch:  89/100000, batch:   114/  187, ite: 8329] train loss: 0.109150, tar: 0.010756 
l0: 0.010544, l1: 0.010733, l2: 0.009206, l3: 0.009566, l4: 0.017630, l5: 0.019486, l6: 0.021228

[epoch:  89/100000, batch:   116/  187, ite: 8330] train loss: 0.109117, tar: 0.010756 
l0: 0.010667, l1: 0.010973, l2: 0.010413, l3: 0.010826, l4: 0.013755, l5: 0.014101, l6: 0.021180

[epoch:  89/100000, batch:   118/  187, ite: 8331] train loss: 0.109065, tar: 0.010755 
l0: 0.021056, l1: 0.022229, l2: 0.020456, l3: 0.020970, l4: 0.023688, l5: 0.026071, l6: 0.026312

[epoch:  89/100000, batch:   120/  187, ite: 8332] train loss: 0.109221, tar: 0.010786 
l0: 0.013487, l1: 0.012590, l2: 0.012570, l3: 0.013536, l4: 0.024566, l5: 0.027169, l6: 0.032660

[epoch:  89/100000, batch:   122/  187, ite: 8333] train loss: 0.109303, tar: 0.010794 
l0: 0.009115, l1: 0.009925, l2: 0.012280, l3: 0.012062, l4: 0.027439, l5: 0.019947, l6: 0.017679

[epoch:  89/100000, batch:   124/  187, ite: 8334] train loss: 0.109300, tar: 0.010789 
l0: 0.011255, l1: 0.011840, l2: 0.010224, l3: 0.011763, l4: 0.013270, l5: 0.014783, l6: 0.015011

[epoch:  89/100000, batch:   126/  187, ite: 8335] train loss: 0.109237, tar: 0.010791 
l0: 0.006958, l1: 0.007097, l2: 0.008848, l3: 0.008907, l4: 0.016996, l5: 0.015502, l6: 0.018126

[epoch:  89/100000, batch:   128/  187, ite: 8336] train loss: 0.109158, tar: 0.010779 
l0: 0.013389, l1: 0.012805, l2: 0.012695, l3: 0.014218, l4: 0.025290, l5: 0.029042, l6: 0.023150

[epoch:  89/100000, batch:   130/  187, ite: 8337] train loss: 0.109221, tar: 0.010787 
l0: 0.008558, l1: 0.009446, l2: 0.008353, l3: 0.008083, l4: 0.015947, l5: 0.016603, l6: 0.021606

[epoch:  89/100000, batch:   132/  187, ite: 8338] train loss: 0.109160, tar: 0.010781 
l0: 0.008647, l1: 0.009237, l2: 0.008673, l3: 0.007771, l4: 0.011868, l5: 0.016292, l6: 0.013926

[epoch:  89/100000, batch:   134/  187, ite: 8339] train loss: 0.109064, tar: 0.010774 
l0: 0.028592, l1: 0.024897, l2: 0.039310, l3: 0.041276, l4: 0.039077, l5: 0.038795, l6: 0.041962

[epoch:  89/100000, batch:   136/  187, ite: 8340] train loss: 0.109490, tar: 0.010827 
l0: 0.014672, l1: 0.015800, l2: 0.016472, l3: 0.017070, l4: 0.021698, l5: 0.021469, l6: 0.019630

[epoch:  89/100000, batch:   138/  187, ite: 8341] train loss: 0.109540, tar: 0.010838 
l0: 0.012984, l1: 0.014407, l2: 0.015163, l3: 0.013846, l4: 0.025230, l5: 0.024053, l6: 0.023016

[epoch:  89/100000, batch:   140/  187, ite: 8342] train loss: 0.109596, tar: 0.010844 
l0: 0.018111, l1: 0.017835, l2: 0.022188, l3: 0.021125, l4: 0.021968, l5: 0.026175, l6: 0.025739

[epoch:  89/100000, batch:   142/  187, ite: 8343] train loss: 0.109723, tar: 0.010865 
l0: 0.013559, l1: 0.015763, l2: 0.011944, l3: 0.010454, l4: 0.016735, l5: 0.017212, l6: 0.015332

[epoch:  89/100000, batch:   144/  187, ite: 8344] train loss: 0.109698, tar: 0.010873 
l0: 0.010623, l1: 0.011698, l2: 0.011833, l3: 0.011823, l4: 0.009923, l5: 0.010405, l6: 0.008426

[epoch:  89/100000, batch:   146/  187, ite: 8345] train loss: 0.109597, tar: 0.010872 
l0: 0.020662, l1: 0.020971, l2: 0.027913, l3: 0.025911, l4: 0.031895, l5: 0.028115, l6: 0.026459

[epoch:  89/100000, batch:   148/  187, ite: 8346] train loss: 0.109806, tar: 0.010901 
l0: 0.019859, l1: 0.019245, l2: 0.021859, l3: 0.019313, l4: 0.029342, l5: 0.033049, l6: 0.036522

[epoch:  89/100000, batch:   150/  187, ite: 8347] train loss: 0.110006, tar: 0.010927 
l0: 0.009113, l1: 0.009507, l2: 0.010332, l3: 0.010222, l4: 0.025931, l5: 0.025002, l6: 0.021112

[epoch:  89/100000, batch:   152/  187, ite: 8348] train loss: 0.110009, tar: 0.010921 
l0: 0.011777, l1: 0.010931, l2: 0.012702, l3: 0.014346, l4: 0.022797, l5: 0.019703, l6: 0.023670

[epoch:  89/100000, batch:   154/  187, ite: 8349] train loss: 0.110026, tar: 0.010924 
l0: 0.014052, l1: 0.012970, l2: 0.015740, l3: 0.020582, l4: 0.027580, l5: 0.026441, l6: 0.026266

[epoch:  89/100000, batch:   156/  187, ite: 8350] train loss: 0.110122, tar: 0.010933 
l0: 0.017865, l1: 0.019524, l2: 0.016155, l3: 0.018022, l4: 0.017120, l5: 0.014477, l6: 0.019951

[epoch:  89/100000, batch:   158/  187, ite: 8351] train loss: 0.110159, tar: 0.010953 
l0: 0.016084, l1: 0.016105, l2: 0.018306, l3: 0.017667, l4: 0.016487, l5: 0.015275, l6: 0.017061

[epoch:  89/100000, batch:   160/  187, ite: 8352] train loss: 0.110178, tar: 0.010967 
l0: 0.012825, l1: 0.012921, l2: 0.013218, l3: 0.015184, l4: 0.026183, l5: 0.029942, l6: 0.024147

[epoch:  89/100000, batch:   162/  187, ite: 8353] train loss: 0.110247, tar: 0.010972 
l0: 0.011391, l1: 0.012613, l2: 0.014586, l3: 0.015677, l4: 0.018402, l5: 0.017673, l6: 0.022537

[epoch:  89/100000, batch:   164/  187, ite: 8354] train loss: 0.110255, tar: 0.010974 
l0: 0.012989, l1: 0.013672, l2: 0.014412, l3: 0.015750, l4: 0.023115, l5: 0.018916, l6: 0.017936

[epoch:  89/100000, batch:   166/  187, ite: 8355] train loss: 0.110273, tar: 0.010979 
l0: 0.008734, l1: 0.008669, l2: 0.010480, l3: 0.010779, l4: 0.023790, l5: 0.025226, l6: 0.028756

[epoch:  89/100000, batch:   168/  187, ite: 8356] train loss: 0.110290, tar: 0.010973 
l0: 0.007888, l1: 0.008552, l2: 0.010307, l3: 0.011465, l4: 0.013230, l5: 0.009536, l6: 0.012082

[epoch:  89/100000, batch:   170/  187, ite: 8357] train loss: 0.110186, tar: 0.010964 
l0: 0.008681, l1: 0.009786, l2: 0.008856, l3: 0.008366, l4: 0.017514, l5: 0.016356, l6: 0.014076

[epoch:  89/100000, batch:   172/  187, ite: 8358] train loss: 0.110112, tar: 0.010958 
l0: 0.008156, l1: 0.010009, l2: 0.009143, l3: 0.007867, l4: 0.016435, l5: 0.016744, l6: 0.020724

[epoch:  89/100000, batch:   174/  187, ite: 8359] train loss: 0.110053, tar: 0.010950 
l0: 0.008944, l1: 0.010099, l2: 0.009927, l3: 0.010939, l4: 0.022910, l5: 0.017742, l6: 0.020193

[epoch:  89/100000, batch:   176/  187, ite: 8360] train loss: 0.110027, tar: 0.010945 
l0: 0.003752, l1: 0.004328, l2: 0.006312, l3: 0.005486, l4: 0.012949, l5: 0.010074, l6: 0.010232

[epoch:  89/100000, batch:   178/  187, ite: 8361] train loss: 0.109870, tar: 0.010925 
l0: 0.011574, l1: 0.012102, l2: 0.012530, l3: 0.014382, l4: 0.019805, l5: 0.020164, l6: 0.024615

[epoch:  89/100000, batch:   180/  187, ite: 8362] train loss: 0.109884, tar: 0.010926 
l0: 0.013390, l1: 0.013401, l2: 0.015007, l3: 0.014539, l4: 0.022616, l5: 0.023081, l6: 0.023794

[epoch:  89/100000, batch:   182/  187, ite: 8363] train loss: 0.109928, tar: 0.010933 
l0: 0.011573, l1: 0.012701, l2: 0.011346, l3: 0.011413, l4: 0.015076, l5: 0.015183, l6: 0.012727

[epoch:  89/100000, batch:   184/  187, ite: 8364] train loss: 0.109874, tar: 0.010935 
l0: 0.009635, l1: 0.009850, l2: 0.013638, l3: 0.014160, l4: 0.019780, l5: 0.019715, l6: 0.018398

[epoch:  89/100000, batch:   186/  187, ite: 8365] train loss: 0.109861, tar: 0.010931 
l0: 0.013984, l1: 0.014773, l2: 0.015409, l3: 0.015098, l4: 0.018594, l5: 0.020685, l6: 0.025710

[epoch:  89/100000, batch:   188/  187, ite: 8366] train loss: 0.109900, tar: 0.010940 
l0: 0.010007, l1: 0.010864, l2: 0.010775, l3: 0.012223, l4: 0.018332, l5: 0.017262, l6: 0.018629

[epoch:  90/100000, batch:     2/  187, ite: 8367] train loss: 0.109868, tar: 0.010937 
l0: 0.005367, l1: 0.005486, l2: 0.005576, l3: 0.006182, l4: 0.012209, l5: 0.012290, l6: 0.012038

[epoch:  90/100000, batch:     4/  187, ite: 8368] train loss: 0.109730, tar: 0.010922 
l0: 0.006293, l1: 0.006618, l2: 0.006937, l3: 0.007575, l4: 0.007721, l5: 0.009523, l6: 0.011369

[epoch:  90/100000, batch:     6/  187, ite: 8369] train loss: 0.109585, tar: 0.010909 
l0: 0.014333, l1: 0.012268, l2: 0.019379, l3: 0.019320, l4: 0.027264, l5: 0.036856, l6: 0.035900

[epoch:  90/100000, batch:     8/  187, ite: 8370] train loss: 0.109735, tar: 0.010919 
l0: 0.011631, l1: 0.012857, l2: 0.011292, l3: 0.010596, l4: 0.020254, l5: 0.018854, l6: 0.020521

[epoch:  90/100000, batch:    10/  187, ite: 8371] train loss: 0.109725, tar: 0.010921 
l0: 0.019668, l1: 0.023155, l2: 0.020675, l3: 0.011731, l4: 0.011162, l5: 0.011307, l6: 0.011602

[epoch:  90/100000, batch:    12/  187, ite: 8372] train loss: 0.109724, tar: 0.010944 
l0: 0.016153, l1: 0.016339, l2: 0.017686, l3: 0.018005, l4: 0.028678, l5: 0.026236, l6: 0.025379

[epoch:  90/100000, batch:    14/  187, ite: 8373] train loss: 0.109828, tar: 0.010958 
l0: 0.009633, l1: 0.010137, l2: 0.010157, l3: 0.011132, l4: 0.019708, l5: 0.018382, l6: 0.018809

[epoch:  90/100000, batch:    16/  187, ite: 8374] train loss: 0.109796, tar: 0.010955 
l0: 0.010977, l1: 0.012817, l2: 0.010009, l3: 0.008951, l4: 0.012225, l5: 0.009399, l6: 0.012232

[epoch:  90/100000, batch:    18/  187, ite: 8375] train loss: 0.109708, tar: 0.010955 
l0: 0.008077, l1: 0.007908, l2: 0.010369, l3: 0.009484, l4: 0.023307, l5: 0.017736, l6: 0.019574

[epoch:  90/100000, batch:    20/  187, ite: 8376] train loss: 0.109672, tar: 0.010947 
l0: 0.017771, l1: 0.018058, l2: 0.018269, l3: 0.018464, l4: 0.023544, l5: 0.026915, l6: 0.032413

[epoch:  90/100000, batch:    22/  187, ite: 8377] train loss: 0.109794, tar: 0.010965 
l0: 0.016650, l1: 0.018513, l2: 0.018032, l3: 0.017971, l4: 0.023011, l5: 0.021778, l6: 0.020348

[epoch:  90/100000, batch:    24/  187, ite: 8378] train loss: 0.109864, tar: 0.010980 
l0: 0.008251, l1: 0.008689, l2: 0.008143, l3: 0.008475, l4: 0.016522, l5: 0.017303, l6: 0.019125

[epoch:  90/100000, batch:    26/  187, ite: 8379] train loss: 0.109802, tar: 0.010973 
l0: 0.005464, l1: 0.006248, l2: 0.007012, l3: 0.005956, l4: 0.013680, l5: 0.012236, l6: 0.011035

[epoch:  90/100000, batch:    28/  187, ite: 8380] train loss: 0.109676, tar: 0.010958 
l0: 0.007284, l1: 0.007012, l2: 0.009274, l3: 0.012404, l4: 0.010843, l5: 0.012602, l6: 0.016529

[epoch:  90/100000, batch:    30/  187, ite: 8381] train loss: 0.109587, tar: 0.010949 
l0: 0.010408, l1: 0.011207, l2: 0.010433, l3: 0.010583, l4: 0.017447, l5: 0.013700, l6: 0.012870

[epoch:  90/100000, batch:    32/  187, ite: 8382] train loss: 0.109527, tar: 0.010947 
l0: 0.010485, l1: 0.010208, l2: 0.012311, l3: 0.013305, l4: 0.024592, l5: 0.024467, l6: 0.024916

[epoch:  90/100000, batch:    34/  187, ite: 8383] train loss: 0.109555, tar: 0.010946 
l0: 0.032307, l1: 0.033659, l2: 0.031882, l3: 0.028876, l4: 0.038425, l5: 0.037381, l6: 0.042626

[epoch:  90/100000, batch:    36/  187, ite: 8384] train loss: 0.109908, tar: 0.011002 
l0: 0.008371, l1: 0.008590, l2: 0.010164, l3: 0.010892, l4: 0.013786, l5: 0.013666, l6: 0.015586

[epoch:  90/100000, batch:    38/  187, ite: 8385] train loss: 0.109833, tar: 0.010995 
l0: 0.010900, l1: 0.011988, l2: 0.011711, l3: 0.010975, l4: 0.020595, l5: 0.017821, l6: 0.017310

[epoch:  90/100000, batch:    40/  187, ite: 8386] train loss: 0.109811, tar: 0.010995 
l0: 0.015527, l1: 0.016395, l2: 0.015503, l3: 0.015846, l4: 0.017555, l5: 0.018324, l6: 0.016255

[epoch:  90/100000, batch:    42/  187, ite: 8387] train loss: 0.109826, tar: 0.011006 
l0: 0.007658, l1: 0.007612, l2: 0.008096, l3: 0.008853, l4: 0.010016, l5: 0.010547, l6: 0.010688

[epoch:  90/100000, batch:    44/  187, ite: 8388] train loss: 0.109706, tar: 0.010998 
l0: 0.007658, l1: 0.008388, l2: 0.008152, l3: 0.008031, l4: 0.012147, l5: 0.011477, l6: 0.012807

[epoch:  90/100000, batch:    46/  187, ite: 8389] train loss: 0.109601, tar: 0.010989 
l0: 0.005108, l1: 0.005259, l2: 0.006147, l3: 0.007613, l4: 0.008934, l5: 0.008600, l6: 0.011709

[epoch:  90/100000, batch:    48/  187, ite: 8390] train loss: 0.109456, tar: 0.010974 
l0: 0.008969, l1: 0.009885, l2: 0.009136, l3: 0.009747, l4: 0.011890, l5: 0.011752, l6: 0.014726

[epoch:  90/100000, batch:    50/  187, ite: 8391] train loss: 0.109371, tar: 0.010969 
l0: 0.008451, l1: 0.008235, l2: 0.009504, l3: 0.010486, l4: 0.015471, l5: 0.014246, l6: 0.015860

[epoch:  90/100000, batch:    52/  187, ite: 8392] train loss: 0.109302, tar: 0.010963 
l0: 0.014798, l1: 0.014456, l2: 0.022609, l3: 0.024101, l4: 0.018648, l5: 0.016449, l6: 0.016996

[epoch:  90/100000, batch:    54/  187, ite: 8393] train loss: 0.109350, tar: 0.010972 
l0: 0.012194, l1: 0.012327, l2: 0.012284, l3: 0.014899, l4: 0.019050, l5: 0.017212, l6: 0.017943

[epoch:  90/100000, batch:    56/  187, ite: 8394] train loss: 0.109341, tar: 0.010975 
l0: 0.009948, l1: 0.011786, l2: 0.014022, l3: 0.010373, l4: 0.013457, l5: 0.012337, l6: 0.011146

[epoch:  90/100000, batch:    58/  187, ite: 8395] train loss: 0.109274, tar: 0.010973 
l0: 0.008949, l1: 0.009889, l2: 0.009338, l3: 0.008899, l4: 0.016976, l5: 0.013417, l6: 0.009719

[epoch:  90/100000, batch:    60/  187, ite: 8396] train loss: 0.109193, tar: 0.010968 
l0: 0.007709, l1: 0.007496, l2: 0.008745, l3: 0.011561, l4: 0.023182, l5: 0.018584, l6: 0.019409

[epoch:  90/100000, batch:    62/  187, ite: 8397] train loss: 0.109162, tar: 0.010960 
l0: 0.009544, l1: 0.008986, l2: 0.012282, l3: 0.016410, l4: 0.029318, l5: 0.022388, l6: 0.022886

[epoch:  90/100000, batch:    64/  187, ite: 8398] train loss: 0.109194, tar: 0.010956 
l0: 0.010027, l1: 0.009536, l2: 0.010689, l3: 0.011079, l4: 0.021838, l5: 0.022901, l6: 0.022526

[epoch:  90/100000, batch:    66/  187, ite: 8399] train loss: 0.109192, tar: 0.010954 
l0: 0.008265, l1: 0.008785, l2: 0.009036, l3: 0.008744, l4: 0.008966, l5: 0.010084, l6: 0.010030

[epoch:  90/100000, batch:    68/  187, ite: 8400] train loss: 0.109079, tar: 0.010947 
l0: 0.010140, l1: 0.009485, l2: 0.012029, l3: 0.012930, l4: 0.021167, l5: 0.021658, l6: 0.028034

[epoch:  90/100000, batch:    70/  187, ite: 8401] train loss: 0.109095, tar: 0.010945 
l0: 0.005085, l1: 0.005886, l2: 0.004489, l3: 0.004496, l4: 0.007198, l5: 0.008618, l6: 0.007935

[epoch:  90/100000, batch:    72/  187, ite: 8402] train loss: 0.108932, tar: 0.010930 
l0: 0.006400, l1: 0.007464, l2: 0.007963, l3: 0.006952, l4: 0.013851, l5: 0.013957, l6: 0.014408

[epoch:  90/100000, batch:    74/  187, ite: 8403] train loss: 0.108838, tar: 0.010919 
l0: 0.013987, l1: 0.015741, l2: 0.015113, l3: 0.013516, l4: 0.015218, l5: 0.016707, l6: 0.017654

[epoch:  90/100000, batch:    76/  187, ite: 8404] train loss: 0.108836, tar: 0.010927 
l0: 0.017342, l1: 0.017420, l2: 0.020143, l3: 0.021325, l4: 0.023997, l5: 0.022239, l6: 0.020648

[epoch:  90/100000, batch:    78/  187, ite: 8405] train loss: 0.108920, tar: 0.010943 
l0: 0.005448, l1: 0.006086, l2: 0.005281, l3: 0.004938, l4: 0.010449, l5: 0.008822, l6: 0.010309

[epoch:  90/100000, batch:    80/  187, ite: 8406] train loss: 0.108779, tar: 0.010929 
l0: 0.012626, l1: 0.014108, l2: 0.013696, l3: 0.012023, l4: 0.016243, l5: 0.016284, l6: 0.018049

[epoch:  90/100000, batch:    82/  187, ite: 8407] train loss: 0.108765, tar: 0.010933 
l0: 0.004660, l1: 0.005216, l2: 0.007774, l3: 0.008541, l4: 0.011443, l5: 0.012486, l6: 0.016373

[epoch:  90/100000, batch:    84/  187, ite: 8408] train loss: 0.108661, tar: 0.010918 
l0: 0.012953, l1: 0.013438, l2: 0.014565, l3: 0.014355, l4: 0.024620, l5: 0.020162, l6: 0.024031

[epoch:  90/100000, batch:    86/  187, ite: 8409] train loss: 0.108699, tar: 0.010923 
l0: 0.009911, l1: 0.008869, l2: 0.016595, l3: 0.020732, l4: 0.021193, l5: 0.021035, l6: 0.016092

[epoch:  90/100000, batch:    88/  187, ite: 8410] train loss: 0.108713, tar: 0.010920 
l0: 0.007247, l1: 0.006475, l2: 0.008101, l3: 0.009992, l4: 0.013761, l5: 0.014490, l6: 0.011880

[epoch:  90/100000, batch:    90/  187, ite: 8411] train loss: 0.108623, tar: 0.010911 
l0: 0.012836, l1: 0.013231, l2: 0.014871, l3: 0.015486, l4: 0.015870, l5: 0.016315, l6: 0.016017

[epoch:  90/100000, batch:    92/  187, ite: 8412] train loss: 0.108614, tar: 0.010916 
l0: 0.012500, l1: 0.011221, l2: 0.017466, l3: 0.016099, l4: 0.019722, l5: 0.020328, l6: 0.018416

[epoch:  90/100000, batch:    94/  187, ite: 8413] train loss: 0.108631, tar: 0.010920 
l0: 0.010943, l1: 0.011350, l2: 0.014986, l3: 0.014230, l4: 0.024197, l5: 0.015656, l6: 0.015001

[epoch:  90/100000, batch:    96/  187, ite: 8414] train loss: 0.108625, tar: 0.010920 
l0: 0.011079, l1: 0.012239, l2: 0.012705, l3: 0.012175, l4: 0.015756, l5: 0.015507, l6: 0.015595

[epoch:  90/100000, batch:    98/  187, ite: 8415] train loss: 0.108593, tar: 0.010920 
l0: 0.007888, l1: 0.008247, l2: 0.009388, l3: 0.009955, l4: 0.015984, l5: 0.017496, l6: 0.017678

[epoch:  90/100000, batch:   100/  187, ite: 8416] train loss: 0.108540, tar: 0.010913 
l0: 0.016447, l1: 0.017572, l2: 0.014758, l3: 0.016447, l4: 0.019538, l5: 0.020687, l6: 0.022203

[epoch:  90/100000, batch:   102/  187, ite: 8417] train loss: 0.108586, tar: 0.010926 
l0: 0.007688, l1: 0.007401, l2: 0.009950, l3: 0.011976, l4: 0.015843, l5: 0.013012, l6: 0.016157

[epoch:  90/100000, batch:   104/  187, ite: 8418] train loss: 0.108522, tar: 0.010919 
l0: 0.008709, l1: 0.009789, l2: 0.009069, l3: 0.009191, l4: 0.011975, l5: 0.012965, l6: 0.012454

[epoch:  90/100000, batch:   106/  187, ite: 8419] train loss: 0.108440, tar: 0.010913 
l0: 0.009684, l1: 0.009729, l2: 0.011658, l3: 0.011717, l4: 0.017275, l5: 0.014633, l6: 0.017108

[epoch:  90/100000, batch:   108/  187, ite: 8420] train loss: 0.108401, tar: 0.010910 
l0: 0.019583, l1: 0.021620, l2: 0.020742, l3: 0.022578, l4: 0.035515, l5: 0.021138, l6: 0.024085

[epoch:  90/100000, batch:   110/  187, ite: 8421] train loss: 0.108536, tar: 0.010931 
l0: 0.012020, l1: 0.010798, l2: 0.012727, l3: 0.017568, l4: 0.019850, l5: 0.021852, l6: 0.018282

[epoch:  90/100000, batch:   112/  187, ite: 8422] train loss: 0.108546, tar: 0.010934 
l0: 0.012478, l1: 0.012735, l2: 0.015868, l3: 0.014562, l4: 0.018452, l5: 0.020273, l6: 0.016367

[epoch:  90/100000, batch:   114/  187, ite: 8423] train loss: 0.108552, tar: 0.010937 
l0: 0.014775, l1: 0.015001, l2: 0.017567, l3: 0.017342, l4: 0.016703, l5: 0.016372, l6: 0.016766

[epoch:  90/100000, batch:   116/  187, ite: 8424] train loss: 0.108566, tar: 0.010946 
l0: 0.006719, l1: 0.006940, l2: 0.007007, l3: 0.005580, l4: 0.013996, l5: 0.012220, l6: 0.010890

[epoch:  90/100000, batch:   118/  187, ite: 8425] train loss: 0.108459, tar: 0.010936 
l0: 0.016248, l1: 0.018014, l2: 0.017517, l3: 0.017327, l4: 0.020995, l5: 0.018835, l6: 0.024116

[epoch:  90/100000, batch:   120/  187, ite: 8426] train loss: 0.108517, tar: 0.010949 
l0: 0.014971, l1: 0.015466, l2: 0.014626, l3: 0.015318, l4: 0.031882, l5: 0.030790, l6: 0.030562

[epoch:  90/100000, batch:   122/  187, ite: 8427] train loss: 0.108623, tar: 0.010958 
l0: 0.017410, l1: 0.016969, l2: 0.017278, l3: 0.019384, l4: 0.020492, l5: 0.023035, l6: 0.027056

[epoch:  90/100000, batch:   124/  187, ite: 8428] train loss: 0.108700, tar: 0.010973 
l0: 0.013338, l1: 0.013995, l2: 0.012941, l3: 0.013908, l4: 0.022294, l5: 0.024618, l6: 0.031930

[epoch:  90/100000, batch:   126/  187, ite: 8429] train loss: 0.108756, tar: 0.010979 
l0: 0.009864, l1: 0.010726, l2: 0.012460, l3: 0.010705, l4: 0.012307, l5: 0.011794, l6: 0.012784

[epoch:  90/100000, batch:   128/  187, ite: 8430] train loss: 0.108691, tar: 0.010976 
l0: 0.010046, l1: 0.010730, l2: 0.010279, l3: 0.012482, l4: 0.022586, l5: 0.022388, l6: 0.016422

[epoch:  90/100000, batch:   130/  187, ite: 8431] train loss: 0.108682, tar: 0.010974 
l0: 0.010275, l1: 0.009453, l2: 0.011836, l3: 0.013048, l4: 0.025237, l5: 0.027824, l6: 0.034502

[epoch:  90/100000, batch:   132/  187, ite: 8432] train loss: 0.108737, tar: 0.010972 
l0: 0.012659, l1: 0.013519, l2: 0.012750, l3: 0.011877, l4: 0.018015, l5: 0.021162, l6: 0.025466

[epoch:  90/100000, batch:   134/  187, ite: 8433] train loss: 0.108752, tar: 0.010976 
l0: 0.011240, l1: 0.011540, l2: 0.014535, l3: 0.012449, l4: 0.015338, l5: 0.017942, l6: 0.017740

[epoch:  90/100000, batch:   136/  187, ite: 8434] train loss: 0.108734, tar: 0.010977 
l0: 0.009048, l1: 0.009630, l2: 0.012460, l3: 0.011774, l4: 0.020276, l5: 0.017698, l6: 0.016346

[epoch:  90/100000, batch:   138/  187, ite: 8435] train loss: 0.108707, tar: 0.010972 
l0: 0.011029, l1: 0.011873, l2: 0.015437, l3: 0.014970, l4: 0.017080, l5: 0.013538, l6: 0.011688

[epoch:  90/100000, batch:   140/  187, ite: 8436] train loss: 0.108677, tar: 0.010973 
l0: 0.009061, l1: 0.009225, l2: 0.008993, l3: 0.010270, l4: 0.013200, l5: 0.013768, l6: 0.014682

[epoch:  90/100000, batch:   142/  187, ite: 8437] train loss: 0.108610, tar: 0.010968 
l0: 0.009550, l1: 0.009572, l2: 0.017963, l3: 0.017969, l4: 0.016885, l5: 0.018059, l6: 0.016966

[epoch:  90/100000, batch:   144/  187, ite: 8438] train loss: 0.108606, tar: 0.010965 
l0: 0.013823, l1: 0.012178, l2: 0.013352, l3: 0.017609, l4: 0.038224, l5: 0.041120, l6: 0.042330

[epoch:  90/100000, batch:   146/  187, ite: 8439] train loss: 0.108766, tar: 0.010971 
l0: 0.010106, l1: 0.010235, l2: 0.011636, l3: 0.013642, l4: 0.022117, l5: 0.018692, l6: 0.017971

[epoch:  90/100000, batch:   148/  187, ite: 8440] train loss: 0.108756, tar: 0.010970 
l0: 0.010831, l1: 0.011560, l2: 0.010333, l3: 0.010584, l4: 0.013019, l5: 0.013104, l6: 0.019317

[epoch:  90/100000, batch:   150/  187, ite: 8441] train loss: 0.108710, tar: 0.010969 
l0: 0.012356, l1: 0.013532, l2: 0.014446, l3: 0.011769, l4: 0.012254, l5: 0.010326, l6: 0.012269

[epoch:  90/100000, batch:   152/  187, ite: 8442] train loss: 0.108661, tar: 0.010972 
l0: 0.011973, l1: 0.013258, l2: 0.013991, l3: 0.014430, l4: 0.026491, l5: 0.020168, l6: 0.021788

[epoch:  90/100000, batch:   154/  187, ite: 8443] train loss: 0.108691, tar: 0.010975 
l0: 0.009370, l1: 0.009894, l2: 0.012161, l3: 0.011241, l4: 0.020586, l5: 0.016823, l6: 0.016592

[epoch:  90/100000, batch:   156/  187, ite: 8444] train loss: 0.108664, tar: 0.010971 
l0: 0.008766, l1: 0.008749, l2: 0.009014, l3: 0.009214, l4: 0.013482, l5: 0.016811, l6: 0.017619

[epoch:  90/100000, batch:   158/  187, ite: 8445] train loss: 0.108608, tar: 0.010966 
l0: 0.013931, l1: 0.013929, l2: 0.017251, l3: 0.022330, l4: 0.030100, l5: 0.033000, l6: 0.024069

[epoch:  90/100000, batch:   160/  187, ite: 8446] train loss: 0.108711, tar: 0.010973 
l0: 0.015091, l1: 0.016328, l2: 0.017058, l3: 0.016676, l4: 0.020612, l5: 0.020992, l6: 0.027191

[epoch:  90/100000, batch:   162/  187, ite: 8447] train loss: 0.108768, tar: 0.010982 
l0: 0.011691, l1: 0.011580, l2: 0.016614, l3: 0.016472, l4: 0.016810, l5: 0.015950, l6: 0.016597

[epoch:  90/100000, batch:   164/  187, ite: 8448] train loss: 0.108761, tar: 0.010983 
l0: 0.015335, l1: 0.014436, l2: 0.015752, l3: 0.016767, l4: 0.022518, l5: 0.024777, l6: 0.022426

[epoch:  90/100000, batch:   166/  187, ite: 8449] train loss: 0.108813, tar: 0.010993 
l0: 0.010016, l1: 0.009748, l2: 0.010066, l3: 0.011577, l4: 0.016660, l5: 0.016387, l6: 0.017563

[epoch:  90/100000, batch:   168/  187, ite: 8450] train loss: 0.108775, tar: 0.010991 
l0: 0.010958, l1: 0.012222, l2: 0.008712, l3: 0.010099, l4: 0.029067, l5: 0.027356, l6: 0.024917

[epoch:  90/100000, batch:   170/  187, ite: 8451] train loss: 0.108808, tar: 0.010991 
l0: 0.013955, l1: 0.013890, l2: 0.012370, l3: 0.015322, l4: 0.023756, l5: 0.017933, l6: 0.019754

[epoch:  90/100000, batch:   172/  187, ite: 8452] train loss: 0.108826, tar: 0.010997 
l0: 0.010691, l1: 0.011196, l2: 0.011465, l3: 0.013299, l4: 0.017622, l5: 0.015704, l6: 0.016605

[epoch:  90/100000, batch:   174/  187, ite: 8453] train loss: 0.108799, tar: 0.010997 
l0: 0.009232, l1: 0.009702, l2: 0.009152, l3: 0.009020, l4: 0.022198, l5: 0.025075, l6: 0.023948

[epoch:  90/100000, batch:   176/  187, ite: 8454] train loss: 0.108798, tar: 0.010993 
l0: 0.029395, l1: 0.027624, l2: 0.031986, l3: 0.033852, l4: 0.034919, l5: 0.038488, l6: 0.033658

[epoch:  90/100000, batch:   178/  187, ite: 8455] train loss: 0.109064, tar: 0.011033 
l0: 0.006293, l1: 0.005948, l2: 0.006005, l3: 0.008015, l4: 0.014763, l5: 0.014613, l6: 0.012377

[epoch:  90/100000, batch:   180/  187, ite: 8456] train loss: 0.108974, tar: 0.011023 
l0: 0.004473, l1: 0.004399, l2: 0.006255, l3: 0.005732, l4: 0.012856, l5: 0.009327, l6: 0.009585

[epoch:  90/100000, batch:   182/  187, ite: 8457] train loss: 0.108851, tar: 0.011009 
l0: 0.005908, l1: 0.005620, l2: 0.007263, l3: 0.008820, l4: 0.023506, l5: 0.023333, l6: 0.023132

[epoch:  90/100000, batch:   184/  187, ite: 8458] train loss: 0.108826, tar: 0.010997 
l0: 0.012761, l1: 0.014547, l2: 0.012349, l3: 0.014226, l4: 0.021517, l5: 0.022701, l6: 0.017799

[epoch:  90/100000, batch:   186/  187, ite: 8459] train loss: 0.108841, tar: 0.011001 
l0: 0.009507, l1: 0.008914, l2: 0.010778, l3: 0.015991, l4: 0.048829, l5: 0.047117, l6: 0.029532

[epoch:  90/100000, batch:   188/  187, ite: 8460] train loss: 0.108976, tar: 0.010998 
l0: 0.012337, l1: 0.012340, l2: 0.014598, l3: 0.014113, l4: 0.021812, l5: 0.020762, l6: 0.026119

[epoch:  91/100000, batch:     2/  187, ite: 8461] train loss: 0.109004, tar: 0.011001 
l0: 0.009771, l1: 0.010386, l2: 0.010313, l3: 0.010952, l4: 0.024459, l5: 0.019643, l6: 0.018910

[epoch:  91/100000, batch:     4/  187, ite: 8462] train loss: 0.108994, tar: 0.010998 
l0: 0.007886, l1: 0.008545, l2: 0.012007, l3: 0.009402, l4: 0.013497, l5: 0.014952, l6: 0.025961

[epoch:  91/100000, batch:     6/  187, ite: 8463] train loss: 0.108958, tar: 0.010992 
l0: 0.011864, l1: 0.012385, l2: 0.013591, l3: 0.014563, l4: 0.026742, l5: 0.018276, l6: 0.024186

[epoch:  91/100000, batch:     8/  187, ite: 8464] train loss: 0.108985, tar: 0.010993 
l0: 0.010103, l1: 0.010127, l2: 0.010768, l3: 0.010638, l4: 0.020374, l5: 0.021075, l6: 0.029851

[epoch:  91/100000, batch:    10/  187, ite: 8465] train loss: 0.108994, tar: 0.010992 
l0: 0.009964, l1: 0.009979, l2: 0.010605, l3: 0.012381, l4: 0.016764, l5: 0.016910, l6: 0.020395

[epoch:  91/100000, batch:    12/  187, ite: 8466] train loss: 0.108968, tar: 0.010989 
l0: 0.009624, l1: 0.010204, l2: 0.012744, l3: 0.010661, l4: 0.018384, l5: 0.016916, l6: 0.016445

[epoch:  91/100000, batch:    14/  187, ite: 8467] train loss: 0.108938, tar: 0.010986 
l0: 0.010408, l1: 0.010521, l2: 0.011820, l3: 0.010210, l4: 0.025078, l5: 0.025740, l6: 0.023294

[epoch:  91/100000, batch:    16/  187, ite: 8468] train loss: 0.108956, tar: 0.010985 
l0: 0.011129, l1: 0.012213, l2: 0.013692, l3: 0.013449, l4: 0.019272, l5: 0.016294, l6: 0.019682

[epoch:  91/100000, batch:    18/  187, ite: 8469] train loss: 0.108949, tar: 0.010986 
l0: 0.014613, l1: 0.015628, l2: 0.014604, l3: 0.015603, l4: 0.014928, l5: 0.014782, l6: 0.015146

[epoch:  91/100000, batch:    20/  187, ite: 8470] train loss: 0.108941, tar: 0.010993 
l0: 0.013281, l1: 0.014123, l2: 0.015725, l3: 0.012085, l4: 0.013245, l5: 0.014903, l6: 0.018124

[epoch:  91/100000, batch:    22/  187, ite: 8471] train loss: 0.108925, tar: 0.010998 
l0: 0.010401, l1: 0.010747, l2: 0.009193, l3: 0.009804, l4: 0.014025, l5: 0.014767, l6: 0.012341

[epoch:  91/100000, batch:    24/  187, ite: 8472] train loss: 0.108867, tar: 0.010997 
l0: 0.017167, l1: 0.017642, l2: 0.017255, l3: 0.020204, l4: 0.016454, l5: 0.014698, l6: 0.021154

[epoch:  91/100000, batch:    26/  187, ite: 8473] train loss: 0.108900, tar: 0.011010 
l0: 0.011369, l1: 0.012003, l2: 0.015597, l3: 0.014218, l4: 0.017288, l5: 0.016513, l6: 0.018370

[epoch:  91/100000, batch:    28/  187, ite: 8474] train loss: 0.108892, tar: 0.011011 
l0: 0.008674, l1: 0.008649, l2: 0.009226, l3: 0.008200, l4: 0.015483, l5: 0.015407, l6: 0.016560

[epoch:  91/100000, batch:    30/  187, ite: 8475] train loss: 0.108836, tar: 0.011006 
l0: 0.012604, l1: 0.013833, l2: 0.010394, l3: 0.012901, l4: 0.015612, l5: 0.013026, l6: 0.017815

[epoch:  91/100000, batch:    32/  187, ite: 8476] train loss: 0.108810, tar: 0.011009 
l0: 0.012300, l1: 0.014172, l2: 0.014471, l3: 0.017008, l4: 0.028925, l5: 0.023212, l6: 0.017764

[epoch:  91/100000, batch:    34/  187, ite: 8477] train loss: 0.108849, tar: 0.011012 
l0: 0.008251, l1: 0.007621, l2: 0.007750, l3: 0.009643, l4: 0.016085, l5: 0.014975, l6: 0.017454

[epoch:  91/100000, batch:    36/  187, ite: 8478] train loss: 0.108793, tar: 0.011006 
l0: 0.008847, l1: 0.007964, l2: 0.009157, l3: 0.012459, l4: 0.017938, l5: 0.021549, l6: 0.026224

[epoch:  91/100000, batch:    38/  187, ite: 8479] train loss: 0.108783, tar: 0.011001 
l0: 0.005597, l1: 0.005886, l2: 0.005290, l3: 0.005327, l4: 0.013826, l5: 0.012751, l6: 0.009305

[epoch:  91/100000, batch:    40/  187, ite: 8480] train loss: 0.108677, tar: 0.010990 
l0: 0.006756, l1: 0.006205, l2: 0.006655, l3: 0.008242, l4: 0.015353, l5: 0.016315, l6: 0.013032

[epoch:  91/100000, batch:    42/  187, ite: 8481] train loss: 0.108602, tar: 0.010981 
l0: 0.007842, l1: 0.008085, l2: 0.008066, l3: 0.008237, l4: 0.011194, l5: 0.012666, l6: 0.012965

[epoch:  91/100000, batch:    44/  187, ite: 8482] train loss: 0.108520, tar: 0.010975 
l0: 0.009151, l1: 0.010405, l2: 0.008819, l3: 0.011629, l4: 0.019098, l5: 0.018452, l6: 0.016398

[epoch:  91/100000, batch:    46/  187, ite: 8483] train loss: 0.108490, tar: 0.010971 
l0: 0.009271, l1: 0.009198, l2: 0.011237, l3: 0.011318, l4: 0.027430, l5: 0.027763, l6: 0.023017

[epoch:  91/100000, batch:    48/  187, ite: 8484] train loss: 0.108512, tar: 0.010968 
l0: 0.006191, l1: 0.006187, l2: 0.009626, l3: 0.013646, l4: 0.019559, l5: 0.017731, l6: 0.019211

[epoch:  91/100000, batch:    50/  187, ite: 8485] train loss: 0.108478, tar: 0.010958 
l0: 0.022132, l1: 0.019866, l2: 0.043801, l3: 0.039470, l4: 0.018162, l5: 0.019060, l6: 0.023184

[epoch:  91/100000, batch:    52/  187, ite: 8486] train loss: 0.108637, tar: 0.010981 
l0: 0.009355, l1: 0.008852, l2: 0.009985, l3: 0.010251, l4: 0.029072, l5: 0.024165, l6: 0.027440

[epoch:  91/100000, batch:    54/  187, ite: 8487] train loss: 0.108659, tar: 0.010977 
l0: 0.008935, l1: 0.009483, l2: 0.010262, l3: 0.009910, l4: 0.014799, l5: 0.013896, l6: 0.016012

[epoch:  91/100000, batch:    56/  187, ite: 8488] train loss: 0.108607, tar: 0.010973 
l0: 0.009610, l1: 0.009996, l2: 0.010946, l3: 0.011039, l4: 0.020923, l5: 0.019455, l6: 0.018069

[epoch:  91/100000, batch:    58/  187, ite: 8489] train loss: 0.108589, tar: 0.010970 
l0: 0.025123, l1: 0.023025, l2: 0.028647, l3: 0.033227, l4: 0.029728, l5: 0.033453, l6: 0.031346

[epoch:  91/100000, batch:    60/  187, ite: 8490] train loss: 0.108785, tar: 0.010999 
l0: 0.006948, l1: 0.007607, l2: 0.008036, l3: 0.007696, l4: 0.016925, l5: 0.016348, l6: 0.015645

[epoch:  91/100000, batch:    62/  187, ite: 8491] train loss: 0.108725, tar: 0.010991 
l0: 0.014535, l1: 0.014736, l2: 0.015718, l3: 0.018077, l4: 0.025328, l5: 0.024220, l6: 0.021394

[epoch:  91/100000, batch:    64/  187, ite: 8492] train loss: 0.108776, tar: 0.010998 
l0: 0.007137, l1: 0.007585, l2: 0.009369, l3: 0.008418, l4: 0.013959, l5: 0.013173, l6: 0.015329

[epoch:  91/100000, batch:    66/  187, ite: 8493] train loss: 0.108708, tar: 0.010990 
l0: 0.006247, l1: 0.006698, l2: 0.006494, l3: 0.007243, l4: 0.011496, l5: 0.013199, l6: 0.016307

[epoch:  91/100000, batch:    68/  187, ite: 8494] train loss: 0.108625, tar: 0.010981 
l0: 0.009826, l1: 0.009906, l2: 0.010891, l3: 0.009594, l4: 0.013777, l5: 0.013089, l6: 0.013975

[epoch:  91/100000, batch:    70/  187, ite: 8495] train loss: 0.108569, tar: 0.010979 
l0: 0.014409, l1: 0.014716, l2: 0.016114, l3: 0.019237, l4: 0.028272, l5: 0.019827, l6: 0.018485

[epoch:  91/100000, batch:    72/  187, ite: 8496] train loss: 0.108614, tar: 0.010985 
l0: 0.012118, l1: 0.012410, l2: 0.009589, l3: 0.009170, l4: 0.014283, l5: 0.018799, l6: 0.020427

[epoch:  91/100000, batch:    74/  187, ite: 8497] train loss: 0.108591, tar: 0.010988 
l0: 0.013404, l1: 0.013723, l2: 0.016772, l3: 0.015513, l4: 0.024156, l5: 0.025425, l6: 0.022431

[epoch:  91/100000, batch:    76/  187, ite: 8498] train loss: 0.108636, tar: 0.010993 
l0: 0.006703, l1: 0.008727, l2: 0.009085, l3: 0.007480, l4: 0.014874, l5: 0.012244, l6: 0.012091

[epoch:  91/100000, batch:    78/  187, ite: 8499] train loss: 0.108561, tar: 0.010984 
l0: 0.013005, l1: 0.013626, l2: 0.012312, l3: 0.015766, l4: 0.021081, l5: 0.017339, l6: 0.027642

[epoch:  91/100000, batch:    80/  187, ite: 8500] train loss: 0.108586, tar: 0.010988 
l0: 0.010851, l1: 0.012217, l2: 0.011910, l3: 0.011404, l4: 0.021296, l5: 0.020817, l6: 0.026293

[epoch:  91/100000, batch:    82/  187, ite: 8501] train loss: 0.108598, tar: 0.010988 
l0: 0.008004, l1: 0.008482, l2: 0.013195, l3: 0.013059, l4: 0.019073, l5: 0.017742, l6: 0.017606

[epoch:  91/100000, batch:    84/  187, ite: 8502] train loss: 0.108575, tar: 0.010982 
l0: 0.008309, l1: 0.008937, l2: 0.008992, l3: 0.009267, l4: 0.018558, l5: 0.016805, l6: 0.011651

[epoch:  91/100000, batch:    86/  187, ite: 8503] train loss: 0.108524, tar: 0.010976 
l0: 0.012409, l1: 0.012424, l2: 0.012960, l3: 0.013748, l4: 0.020935, l5: 0.020958, l6: 0.017189

[epoch:  91/100000, batch:    88/  187, ite: 8504] train loss: 0.108528, tar: 0.010979 
l0: 0.010428, l1: 0.009775, l2: 0.011364, l3: 0.011875, l4: 0.015356, l5: 0.016455, l6: 0.020708

[epoch:  91/100000, batch:    90/  187, ite: 8505] train loss: 0.108503, tar: 0.010978 
l0: 0.023229, l1: 0.022159, l2: 0.025126, l3: 0.028927, l4: 0.039110, l5: 0.033775, l6: 0.031504

[epoch:  91/100000, batch:    92/  187, ite: 8506] train loss: 0.108691, tar: 0.011002 
l0: 0.020196, l1: 0.022223, l2: 0.020521, l3: 0.020706, l4: 0.027256, l5: 0.026219, l6: 0.029284

[epoch:  91/100000, batch:    94/  187, ite: 8507] train loss: 0.108805, tar: 0.011021 
l0: 0.016897, l1: 0.012680, l2: 0.016065, l3: 0.023182, l4: 0.039443, l5: 0.045555, l6: 0.048057

[epoch:  91/100000, batch:    96/  187, ite: 8508] train loss: 0.108988, tar: 0.011032 
l0: 0.010118, l1: 0.009672, l2: 0.012124, l3: 0.014131, l4: 0.022474, l5: 0.025321, l6: 0.021325

[epoch:  91/100000, batch:    98/  187, ite: 8509] train loss: 0.109000, tar: 0.011030 
l0: 0.007492, l1: 0.007814, l2: 0.009471, l3: 0.009090, l4: 0.017841, l5: 0.015544, l6: 0.015805

[epoch:  91/100000, batch:   100/  187, ite: 8510] train loss: 0.108950, tar: 0.011023 
l0: 0.009891, l1: 0.010157, l2: 0.011676, l3: 0.013621, l4: 0.020654, l5: 0.018896, l6: 0.016235

[epoch:  91/100000, batch:   102/  187, ite: 8511] train loss: 0.108934, tar: 0.011021 
l0: 0.006716, l1: 0.006235, l2: 0.008183, l3: 0.010065, l4: 0.015324, l5: 0.014068, l6: 0.013553

[epoch:  91/100000, batch:   104/  187, ite: 8512] train loss: 0.108866, tar: 0.011013 
l0: 0.016671, l1: 0.016590, l2: 0.016982, l3: 0.020837, l4: 0.026582, l5: 0.023963, l6: 0.029372

[epoch:  91/100000, batch:   106/  187, ite: 8513] train loss: 0.108948, tar: 0.011024 
l0: 0.014460, l1: 0.014404, l2: 0.017429, l3: 0.018070, l4: 0.031891, l5: 0.032539, l6: 0.028405

[epoch:  91/100000, batch:   108/  187, ite: 8514] train loss: 0.109042, tar: 0.011030 
l0: 0.006883, l1: 0.006821, l2: 0.007653, l3: 0.008861, l4: 0.014984, l5: 0.015403, l6: 0.012408

[epoch:  91/100000, batch:   110/  187, ite: 8515] train loss: 0.108972, tar: 0.011022 
l0: 0.011161, l1: 0.012618, l2: 0.016038, l3: 0.011778, l4: 0.024450, l5: 0.020946, l6: 0.022323

[epoch:  91/100000, batch:   112/  187, ite: 8516] train loss: 0.108992, tar: 0.011023 
l0: 0.016453, l1: 0.015990, l2: 0.017116, l3: 0.017906, l4: 0.019178, l5: 0.020048, l6: 0.024822

[epoch:  91/100000, batch:   114/  187, ite: 8517] train loss: 0.109036, tar: 0.011033 
l0: 0.006208, l1: 0.006575, l2: 0.007006, l3: 0.009479, l4: 0.017352, l5: 0.014211, l6: 0.013077

[epoch:  91/100000, batch:   116/  187, ite: 8518] train loss: 0.108968, tar: 0.011024 
l0: 0.009495, l1: 0.011530, l2: 0.010251, l3: 0.007388, l4: 0.008782, l5: 0.013488, l6: 0.021360

[epoch:  91/100000, batch:   118/  187, ite: 8519] train loss: 0.108917, tar: 0.011021 
l0: 0.012661, l1: 0.014693, l2: 0.013563, l3: 0.017835, l4: 0.024669, l5: 0.024434, l6: 0.024566

[epoch:  91/100000, batch:   120/  187, ite: 8520] train loss: 0.108962, tar: 0.011024 
l0: 0.011470, l1: 0.011482, l2: 0.013463, l3: 0.013292, l4: 0.015537, l5: 0.017324, l6: 0.018019

[epoch:  91/100000, batch:   122/  187, ite: 8521] train loss: 0.108946, tar: 0.011025 
l0: 0.008776, l1: 0.008514, l2: 0.010084, l3: 0.010399, l4: 0.022201, l5: 0.021846, l6: 0.020355

[epoch:  91/100000, batch:   124/  187, ite: 8522] train loss: 0.108933, tar: 0.011021 
l0: 0.015997, l1: 0.017869, l2: 0.017189, l3: 0.016501, l4: 0.015985, l5: 0.017234, l6: 0.019312

[epoch:  91/100000, batch:   126/  187, ite: 8523] train loss: 0.108954, tar: 0.011030 
l0: 0.014158, l1: 0.014323, l2: 0.014559, l3: 0.014599, l4: 0.019900, l5: 0.020167, l6: 0.025604

[epoch:  91/100000, batch:   128/  187, ite: 8524] train loss: 0.108982, tar: 0.011036 
l0: 0.012274, l1: 0.010712, l2: 0.021731, l3: 0.017795, l4: 0.024131, l5: 0.027066, l6: 0.027331

[epoch:  91/100000, batch:   130/  187, ite: 8525] train loss: 0.109043, tar: 0.011039 
l0: 0.022568, l1: 0.022473, l2: 0.022657, l3: 0.024063, l4: 0.043080, l5: 0.041359, l6: 0.042858

[epoch:  91/100000, batch:   132/  187, ite: 8526] train loss: 0.109252, tar: 0.011060 
l0: 0.017490, l1: 0.016341, l2: 0.015714, l3: 0.018170, l4: 0.024779, l5: 0.026590, l6: 0.029344

[epoch:  91/100000, batch:   134/  187, ite: 8527] train loss: 0.109326, tar: 0.011073 
l0: 0.011727, l1: 0.011192, l2: 0.013897, l3: 0.017653, l4: 0.022575, l5: 0.026434, l6: 0.033640

[epoch:  91/100000, batch:   136/  187, ite: 8528] train loss: 0.109379, tar: 0.011074 
l0: 0.006665, l1: 0.007361, l2: 0.007883, l3: 0.008212, l4: 0.009263, l5: 0.008349, l6: 0.010942

[epoch:  91/100000, batch:   138/  187, ite: 8529] train loss: 0.109283, tar: 0.011066 
l0: 0.015958, l1: 0.015383, l2: 0.018192, l3: 0.020458, l4: 0.029576, l5: 0.028558, l6: 0.028541

[epoch:  91/100000, batch:   140/  187, ite: 8530] train loss: 0.109372, tar: 0.011075 
l0: 0.009868, l1: 0.010673, l2: 0.010897, l3: 0.011167, l4: 0.012331, l5: 0.012790, l6: 0.014299

[epoch:  91/100000, batch:   142/  187, ite: 8531] train loss: 0.109321, tar: 0.011072 
l0: 0.014744, l1: 0.015855, l2: 0.016551, l3: 0.013358, l4: 0.026449, l5: 0.025013, l6: 0.020994

[epoch:  91/100000, batch:   144/  187, ite: 8532] train loss: 0.109365, tar: 0.011079 
l0: 0.011881, l1: 0.013579, l2: 0.011923, l3: 0.010734, l4: 0.013497, l5: 0.014537, l6: 0.015914

[epoch:  91/100000, batch:   146/  187, ite: 8533] train loss: 0.109333, tar: 0.011081 
l0: 0.004393, l1: 0.004702, l2: 0.006150, l3: 0.005659, l4: 0.008028, l5: 0.008150, l6: 0.008852

[epoch:  91/100000, batch:   148/  187, ite: 8534] train loss: 0.109214, tar: 0.011068 
l0: 0.010642, l1: 0.012201, l2: 0.010349, l3: 0.008906, l4: 0.018828, l5: 0.017658, l6: 0.020523

[epoch:  91/100000, batch:   150/  187, ite: 8535] train loss: 0.109195, tar: 0.011068 
l0: 0.012043, l1: 0.012719, l2: 0.012999, l3: 0.013860, l4: 0.024230, l5: 0.023105, l6: 0.021778

[epoch:  91/100000, batch:   152/  187, ite: 8536] train loss: 0.109217, tar: 0.011069 
l0: 0.010300, l1: 0.010066, l2: 0.010330, l3: 0.011141, l4: 0.017186, l5: 0.018466, l6: 0.019957

[epoch:  91/100000, batch:   154/  187, ite: 8537] train loss: 0.109195, tar: 0.011068 
l0: 0.009349, l1: 0.008957, l2: 0.013220, l3: 0.012466, l4: 0.016054, l5: 0.019622, l6: 0.020508

[epoch:  91/100000, batch:   156/  187, ite: 8538] train loss: 0.109178, tar: 0.011065 
l0: 0.007124, l1: 0.008013, l2: 0.008439, l3: 0.009230, l4: 0.023132, l5: 0.021615, l6: 0.016901

[epoch:  91/100000, batch:   158/  187, ite: 8539] train loss: 0.109151, tar: 0.011057 
l0: 0.013947, l1: 0.015208, l2: 0.010572, l3: 0.010415, l4: 0.024396, l5: 0.025598, l6: 0.030861

[epoch:  91/100000, batch:   160/  187, ite: 8540] train loss: 0.109191, tar: 0.011063 
l0: 0.017981, l1: 0.017912, l2: 0.020306, l3: 0.022932, l4: 0.038229, l5: 0.032804, l6: 0.037014

[epoch:  91/100000, batch:   162/  187, ite: 8541] train loss: 0.109335, tar: 0.011076 
l0: 0.010162, l1: 0.009562, l2: 0.011550, l3: 0.011445, l4: 0.019734, l5: 0.019080, l6: 0.023421

[epoch:  91/100000, batch:   164/  187, ite: 8542] train loss: 0.109327, tar: 0.011074 
l0: 0.013256, l1: 0.013685, l2: 0.013305, l3: 0.016833, l4: 0.027176, l5: 0.025937, l6: 0.029255

[epoch:  91/100000, batch:   166/  187, ite: 8543] train loss: 0.109383, tar: 0.011078 
l0: 0.011279, l1: 0.009843, l2: 0.015483, l3: 0.017202, l4: 0.031331, l5: 0.032263, l6: 0.034167

[epoch:  91/100000, batch:   168/  187, ite: 8544] train loss: 0.109460, tar: 0.011078 
l0: 0.005604, l1: 0.005062, l2: 0.006365, l3: 0.006991, l4: 0.011828, l5: 0.013703, l6: 0.020054

[epoch:  91/100000, batch:   170/  187, ite: 8545] train loss: 0.109387, tar: 0.011068 
l0: 0.011381, l1: 0.012939, l2: 0.010522, l3: 0.011097, l4: 0.019467, l5: 0.017792, l6: 0.018598

[epoch:  91/100000, batch:   172/  187, ite: 8546] train loss: 0.109373, tar: 0.011069 
l0: 0.007319, l1: 0.007957, l2: 0.009288, l3: 0.009596, l4: 0.015676, l5: 0.016161, l6: 0.022924

[epoch:  91/100000, batch:   174/  187, ite: 8547] train loss: 0.109336, tar: 0.011062 
l0: 0.012070, l1: 0.013246, l2: 0.013854, l3: 0.013519, l4: 0.017233, l5: 0.018014, l6: 0.022011

[epoch:  91/100000, batch:   176/  187, ite: 8548] train loss: 0.109337, tar: 0.011064 
l0: 0.020921, l1: 0.020215, l2: 0.023378, l3: 0.028006, l4: 0.027926, l5: 0.027140, l6: 0.032688

[epoch:  91/100000, batch:   178/  187, ite: 8549] train loss: 0.109466, tar: 0.011082 
l0: 0.007115, l1: 0.007756, l2: 0.008032, l3: 0.008639, l4: 0.019517, l5: 0.015615, l6: 0.016273

[epoch:  91/100000, batch:   180/  187, ite: 8550] train loss: 0.109418, tar: 0.011075 
l0: 0.011196, l1: 0.012756, l2: 0.011582, l3: 0.013635, l4: 0.061152, l5: 0.055291, l6: 0.058422

[epoch:  91/100000, batch:   182/  187, ite: 8551] train loss: 0.109626, tar: 0.011075 
l0: 0.018724, l1: 0.018821, l2: 0.019307, l3: 0.020868, l4: 0.026134, l5: 0.023489, l6: 0.024085

[epoch:  91/100000, batch:   184/  187, ite: 8552] train loss: 0.109702, tar: 0.011089 
l0: 0.011125, l1: 0.011878, l2: 0.010161, l3: 0.011827, l4: 0.033746, l5: 0.027192, l6: 0.018385

[epoch:  91/100000, batch:   186/  187, ite: 8553] train loss: 0.109728, tar: 0.011089 
l0: 0.012235, l1: 0.011978, l2: 0.011003, l3: 0.012410, l4: 0.026584, l5: 0.027111, l6: 0.058015

[epoch:  91/100000, batch:   188/  187, ite: 8554] train loss: 0.109818, tar: 0.011091 
l0: 0.013420, l1: 0.014311, l2: 0.015480, l3: 0.014082, l4: 0.022544, l5: 0.022089, l6: 0.022504

[epoch:  92/100000, batch:     2/  187, ite: 8555] train loss: 0.109844, tar: 0.011095 
l0: 0.010923, l1: 0.011775, l2: 0.010346, l3: 0.009334, l4: 0.011122, l5: 0.011038, l6: 0.015237

[epoch:  92/100000, batch:     4/  187, ite: 8556] train loss: 0.109790, tar: 0.011095 
l0: 0.022578, l1: 0.020182, l2: 0.024899, l3: 0.027528, l4: 0.048297, l5: 0.052330, l6: 0.046847

[epoch:  92/100000, batch:     6/  187, ite: 8557] train loss: 0.110029, tar: 0.011115 
l0: 0.008798, l1: 0.009215, l2: 0.009126, l3: 0.008600, l4: 0.024780, l5: 0.020008, l6: 0.017894

[epoch:  92/100000, batch:     8/  187, ite: 8558] train loss: 0.110008, tar: 0.011111 
l0: 0.004376, l1: 0.004425, l2: 0.007291, l3: 0.006682, l4: 0.014276, l5: 0.013725, l6: 0.015100

[epoch:  92/100000, batch:    10/  187, ite: 8559] train loss: 0.109929, tar: 0.011099 
l0: 0.010183, l1: 0.010697, l2: 0.009028, l3: 0.009712, l4: 0.023649, l5: 0.023516, l6: 0.019878

[epoch:  92/100000, batch:    12/  187, ite: 8560] train loss: 0.109923, tar: 0.011097 
l0: 0.010300, l1: 0.010390, l2: 0.010785, l3: 0.011561, l4: 0.010824, l5: 0.008994, l6: 0.011272

[epoch:  92/100000, batch:    14/  187, ite: 8561] train loss: 0.109859, tar: 0.011096 
l0: 0.010407, l1: 0.010442, l2: 0.013293, l3: 0.011927, l4: 0.025615, l5: 0.019186, l6: 0.023032

[epoch:  92/100000, batch:    16/  187, ite: 8562] train loss: 0.109866, tar: 0.011095 
l0: 0.003976, l1: 0.003968, l2: 0.005930, l3: 0.005623, l4: 0.015444, l5: 0.014966, l6: 0.013195

[epoch:  92/100000, batch:    18/  187, ite: 8563] train loss: 0.109783, tar: 0.011082 
l0: 0.012083, l1: 0.011527, l2: 0.014978, l3: 0.014581, l4: 0.032122, l5: 0.036761, l6: 0.029466

[epoch:  92/100000, batch:    20/  187, ite: 8564] train loss: 0.109857, tar: 0.011084 
l0: 0.009219, l1: 0.010163, l2: 0.012140, l3: 0.012596, l4: 0.012840, l5: 0.010242, l6: 0.008752

[epoch:  92/100000, batch:    22/  187, ite: 8565] train loss: 0.109797, tar: 0.011081 
l0: 0.012702, l1: 0.013133, l2: 0.013495, l3: 0.013949, l4: 0.027072, l5: 0.021730, l6: 0.024300

[epoch:  92/100000, batch:    24/  187, ite: 8566] train loss: 0.109827, tar: 0.011083 
l0: 0.010208, l1: 0.012199, l2: 0.009320, l3: 0.008170, l4: 0.011220, l5: 0.009056, l6: 0.010650

[epoch:  92/100000, batch:    26/  187, ite: 8567] train loss: 0.109758, tar: 0.011082 
l0: 0.007517, l1: 0.007856, l2: 0.008493, l3: 0.008604, l4: 0.013640, l5: 0.012257, l6: 0.012001

[epoch:  92/100000, batch:    28/  187, ite: 8568] train loss: 0.109688, tar: 0.011076 
l0: 0.004522, l1: 0.004729, l2: 0.005045, l3: 0.005828, l4: 0.008628, l5: 0.010980, l6: 0.015848

[epoch:  92/100000, batch:    30/  187, ite: 8569] train loss: 0.109593, tar: 0.011064 
l0: 0.008977, l1: 0.008585, l2: 0.009711, l3: 0.010996, l4: 0.026050, l5: 0.026653, l6: 0.025622

[epoch:  92/100000, batch:    32/  187, ite: 8570] train loss: 0.109606, tar: 0.011060 
l0: 0.010921, l1: 0.011645, l2: 0.009448, l3: 0.010522, l4: 0.024051, l5: 0.023377, l6: 0.021700

[epoch:  92/100000, batch:    34/  187, ite: 8571] train loss: 0.109609, tar: 0.011060 
l0: 0.016526, l1: 0.016827, l2: 0.016610, l3: 0.021625, l4: 0.034868, l5: 0.030802, l6: 0.036045

[epoch:  92/100000, batch:    36/  187, ite: 8572] train loss: 0.109721, tar: 0.011070 
l0: 0.006282, l1: 0.006396, l2: 0.008138, l3: 0.008578, l4: 0.018591, l5: 0.020031, l6: 0.015546

[epoch:  92/100000, batch:    38/  187, ite: 8573] train loss: 0.109675, tar: 0.011061 
l0: 0.010782, l1: 0.010187, l2: 0.009346, l3: 0.009809, l4: 0.027870, l5: 0.035392, l6: 0.039721

[epoch:  92/100000, batch:    40/  187, ite: 8574] train loss: 0.109733, tar: 0.011061 
l0: 0.007901, l1: 0.009257, l2: 0.008439, l3: 0.008247, l4: 0.019571, l5: 0.018136, l6: 0.016845

[epoch:  92/100000, batch:    42/  187, ite: 8575] train loss: 0.109696, tar: 0.011055 
l0: 0.005810, l1: 0.005567, l2: 0.006561, l3: 0.007085, l4: 0.013383, l5: 0.015140, l6: 0.017695

[epoch:  92/100000, batch:    44/  187, ite: 8576] train loss: 0.109629, tar: 0.011046 
l0: 0.008506, l1: 0.008891, l2: 0.010901, l3: 0.010833, l4: 0.020597, l5: 0.015072, l6: 0.016348

[epoch:  92/100000, batch:    46/  187, ite: 8577] train loss: 0.109597, tar: 0.011042 
l0: 0.009827, l1: 0.010223, l2: 0.010045, l3: 0.009298, l4: 0.022126, l5: 0.017901, l6: 0.014333

[epoch:  92/100000, batch:    48/  187, ite: 8578] train loss: 0.109570, tar: 0.011040 
l0: 0.009810, l1: 0.010861, l2: 0.009235, l3: 0.010495, l4: 0.019318, l5: 0.017357, l6: 0.018920

[epoch:  92/100000, batch:    50/  187, ite: 8579] train loss: 0.109546, tar: 0.011038 
l0: 0.007771, l1: 0.007938, l2: 0.007386, l3: 0.007880, l4: 0.010919, l5: 0.011276, l6: 0.010910

[epoch:  92/100000, batch:    52/  187, ite: 8580] train loss: 0.109468, tar: 0.011032 
l0: 0.010602, l1: 0.010814, l2: 0.015032, l3: 0.012928, l4: 0.018025, l5: 0.017366, l6: 0.015066

[epoch:  92/100000, batch:    54/  187, ite: 8581] train loss: 0.109451, tar: 0.011031 
l0: 0.012814, l1: 0.012400, l2: 0.015396, l3: 0.014636, l4: 0.016908, l5: 0.018088, l6: 0.019148

[epoch:  92/100000, batch:    56/  187, ite: 8582] train loss: 0.109451, tar: 0.011034 
l0: 0.004543, l1: 0.005050, l2: 0.006015, l3: 0.005218, l4: 0.016259, l5: 0.013587, l6: 0.009950

[epoch:  92/100000, batch:    58/  187, ite: 8583] train loss: 0.109368, tar: 0.011023 
l0: 0.011588, l1: 0.011701, l2: 0.020782, l3: 0.021187, l4: 0.018322, l5: 0.019429, l6: 0.019064

[epoch:  92/100000, batch:    60/  187, ite: 8584] train loss: 0.109389, tar: 0.011024 
l0: 0.021886, l1: 0.020000, l2: 0.022544, l3: 0.023266, l4: 0.042683, l5: 0.039548, l6: 0.054701

[epoch:  92/100000, batch:    62/  187, ite: 8585] train loss: 0.109586, tar: 0.011043 
l0: 0.012380, l1: 0.012815, l2: 0.013331, l3: 0.014112, l4: 0.021738, l5: 0.021924, l6: 0.019268

[epoch:  92/100000, batch:    64/  187, ite: 8586] train loss: 0.109597, tar: 0.011045 
l0: 0.017837, l1: 0.018544, l2: 0.024558, l3: 0.020109, l4: 0.034529, l5: 0.028462, l6: 0.034317

[epoch:  92/100000, batch:    66/  187, ite: 8587] train loss: 0.109714, tar: 0.011057 
l0: 0.013239, l1: 0.014912, l2: 0.013580, l3: 0.013570, l4: 0.018039, l5: 0.017797, l6: 0.023180

[epoch:  92/100000, batch:    68/  187, ite: 8588] train loss: 0.109722, tar: 0.011060 
l0: 0.010176, l1: 0.009072, l2: 0.015063, l3: 0.018655, l4: 0.013329, l5: 0.011471, l6: 0.012596

[epoch:  92/100000, batch:    70/  187, ite: 8589] train loss: 0.109689, tar: 0.011059 
l0: 0.022557, l1: 0.021402, l2: 0.031112, l3: 0.032989, l4: 0.034276, l5: 0.032606, l6: 0.031350

[epoch:  92/100000, batch:    72/  187, ite: 8590] train loss: 0.109852, tar: 0.011078 
l0: 0.009924, l1: 0.010065, l2: 0.014241, l3: 0.011975, l4: 0.011646, l5: 0.012931, l6: 0.015183

[epoch:  92/100000, batch:    74/  187, ite: 8591] train loss: 0.109812, tar: 0.011076 
l0: 0.010364, l1: 0.010825, l2: 0.013387, l3: 0.013136, l4: 0.019074, l5: 0.016960, l6: 0.017115

[epoch:  92/100000, batch:    76/  187, ite: 8592] train loss: 0.109797, tar: 0.011075 
l0: 0.008801, l1: 0.008956, l2: 0.011138, l3: 0.010795, l4: 0.017247, l5: 0.018724, l6: 0.022110

[epoch:  92/100000, batch:    78/  187, ite: 8593] train loss: 0.109777, tar: 0.011071 
l0: 0.009136, l1: 0.008761, l2: 0.011065, l3: 0.011423, l4: 0.022605, l5: 0.030077, l6: 0.033926

[epoch:  92/100000, batch:    80/  187, ite: 8594] train loss: 0.109806, tar: 0.011068 
l0: 0.011350, l1: 0.011779, l2: 0.012456, l3: 0.011460, l4: 0.017768, l5: 0.017283, l6: 0.016343

[epoch:  92/100000, batch:    82/  187, ite: 8595] train loss: 0.109786, tar: 0.011069 
l0: 0.008290, l1: 0.008282, l2: 0.011103, l3: 0.012558, l4: 0.016617, l5: 0.012714, l6: 0.011815

[epoch:  92/100000, batch:    84/  187, ite: 8596] train loss: 0.109739, tar: 0.011064 
l0: 0.012348, l1: 0.011839, l2: 0.014889, l3: 0.014030, l4: 0.019184, l5: 0.022278, l6: 0.019903

[epoch:  92/100000, batch:    86/  187, ite: 8597] train loss: 0.109747, tar: 0.011066 
l0: 0.010659, l1: 0.010323, l2: 0.011956, l3: 0.014361, l4: 0.014283, l5: 0.014834, l6: 0.017446

[epoch:  92/100000, batch:    88/  187, ite: 8598] train loss: 0.109720, tar: 0.011065 
l0: 0.017484, l1: 0.016710, l2: 0.020141, l3: 0.019686, l4: 0.023009, l5: 0.018119, l6: 0.028469

[epoch:  92/100000, batch:    90/  187, ite: 8599] train loss: 0.109777, tar: 0.011076 
l0: 0.020505, l1: 0.021943, l2: 0.022162, l3: 0.022044, l4: 0.027680, l5: 0.025067, l6: 0.035174

[epoch:  92/100000, batch:    92/  187, ite: 8600] train loss: 0.109885, tar: 0.011092 
l0: 0.015790, l1: 0.014819, l2: 0.013796, l3: 0.017185, l4: 0.035462, l5: 0.035346, l6: 0.029124

[epoch:  92/100000, batch:    94/  187, ite: 8601] train loss: 0.109971, tar: 0.011100 
l0: 0.012931, l1: 0.013257, l2: 0.013319, l3: 0.011998, l4: 0.024376, l5: 0.024662, l6: 0.022676

[epoch:  92/100000, batch:    96/  187, ite: 8602] train loss: 0.109993, tar: 0.011103 
l0: 0.011498, l1: 0.013614, l2: 0.009364, l3: 0.010444, l4: 0.014667, l5: 0.014243, l6: 0.014090

[epoch:  92/100000, batch:    98/  187, ite: 8603] train loss: 0.109956, tar: 0.011103 
l0: 0.034358, l1: 0.032090, l2: 0.046502, l3: 0.053089, l4: 0.071433, l5: 0.058802, l6: 0.059575

[epoch:  92/100000, batch:   100/  187, ite: 8604] train loss: 0.110363, tar: 0.011142 
l0: 0.010183, l1: 0.010888, l2: 0.014624, l3: 0.012099, l4: 0.012422, l5: 0.014034, l6: 0.013680

[epoch:  92/100000, batch:   102/  187, ite: 8605] train loss: 0.110326, tar: 0.011140 
l0: 0.010722, l1: 0.010751, l2: 0.012745, l3: 0.013045, l4: 0.018082, l5: 0.019697, l6: 0.015240

[epoch:  92/100000, batch:   104/  187, ite: 8606] train loss: 0.110310, tar: 0.011140 
l0: 0.010694, l1: 0.010832, l2: 0.011898, l3: 0.011167, l4: 0.025529, l5: 0.023869, l6: 0.028903

[epoch:  92/100000, batch:   106/  187, ite: 8607] train loss: 0.110330, tar: 0.011139 
l0: 0.004595, l1: 0.005790, l2: 0.004565, l3: 0.004714, l4: 0.007536, l5: 0.007856, l6: 0.009641

[epoch:  92/100000, batch:   108/  187, ite: 8608] train loss: 0.110222, tar: 0.011128 
l0: 0.014147, l1: 0.014608, l2: 0.018094, l3: 0.016427, l4: 0.012645, l5: 0.012700, l6: 0.015217

[epoch:  92/100000, batch:   110/  187, ite: 8609] train loss: 0.110212, tar: 0.011133 
l0: 0.011068, l1: 0.011783, l2: 0.010783, l3: 0.013155, l4: 0.017517, l5: 0.018034, l6: 0.017954

[epoch:  92/100000, batch:   112/  187, ite: 8610] train loss: 0.110196, tar: 0.011133 
l0: 0.013627, l1: 0.012930, l2: 0.013006, l3: 0.015261, l4: 0.036321, l5: 0.030735, l6: 0.037395

[epoch:  92/100000, batch:   114/  187, ite: 8611] train loss: 0.110276, tar: 0.011137 
l0: 0.024695, l1: 0.024239, l2: 0.025604, l3: 0.027729, l4: 0.038087, l5: 0.038565, l6: 0.039618

[epoch:  92/100000, batch:   116/  187, ite: 8612] train loss: 0.110453, tar: 0.011159 
l0: 0.012561, l1: 0.012271, l2: 0.015590, l3: 0.014968, l4: 0.019185, l5: 0.019069, l6: 0.019593

[epoch:  92/100000, batch:   118/  187, ite: 8613] train loss: 0.110457, tar: 0.011161 
l0: 0.011221, l1: 0.010688, l2: 0.012661, l3: 0.011636, l4: 0.025440, l5: 0.030306, l6: 0.023509

[epoch:  92/100000, batch:   120/  187, ite: 8614] train loss: 0.110482, tar: 0.011162 
l0: 0.009741, l1: 0.009059, l2: 0.010154, l3: 0.010410, l4: 0.027270, l5: 0.031871, l6: 0.037581

[epoch:  92/100000, batch:   122/  187, ite: 8615] train loss: 0.110523, tar: 0.011159 
l0: 0.010908, l1: 0.011253, l2: 0.010953, l3: 0.010683, l4: 0.030405, l5: 0.034405, l6: 0.028900

[epoch:  92/100000, batch:   124/  187, ite: 8616] train loss: 0.110567, tar: 0.011159 
l0: 0.008770, l1: 0.009091, l2: 0.010167, l3: 0.010650, l4: 0.023046, l5: 0.025569, l6: 0.018465

[epoch:  92/100000, batch:   126/  187, ite: 8617] train loss: 0.110559, tar: 0.011155 
l0: 0.007436, l1: 0.009589, l2: 0.009954, l3: 0.012835, l4: 0.016183, l5: 0.012219, l6: 0.013675

[epoch:  92/100000, batch:   128/  187, ite: 8618] train loss: 0.110513, tar: 0.011149 
l0: 0.008727, l1: 0.010207, l2: 0.009110, l3: 0.010058, l4: 0.023031, l5: 0.023388, l6: 0.019067

[epoch:  92/100000, batch:   130/  187, ite: 8619] train loss: 0.110502, tar: 0.011145 
l0: 0.012368, l1: 0.012476, l2: 0.009950, l3: 0.009459, l4: 0.012345, l5: 0.013464, l6: 0.022213

[epoch:  92/100000, batch:   132/  187, ite: 8620] train loss: 0.110472, tar: 0.011147 
l0: 0.020811, l1: 0.021709, l2: 0.021815, l3: 0.022797, l4: 0.017811, l5: 0.019182, l6: 0.018474

[epoch:  92/100000, batch:   134/  187, ite: 8621] train loss: 0.110524, tar: 0.011163 
l0: 0.010987, l1: 0.010940, l2: 0.013487, l3: 0.013324, l4: 0.020664, l5: 0.019307, l6: 0.015567

[epoch:  92/100000, batch:   136/  187, ite: 8622] train loss: 0.110514, tar: 0.011162 
l0: 0.021281, l1: 0.022526, l2: 0.023747, l3: 0.023955, l4: 0.017055, l5: 0.013834, l6: 0.012951

[epoch:  92/100000, batch:   138/  187, ite: 8623] train loss: 0.110554, tar: 0.011179 
l0: 0.009681, l1: 0.009774, l2: 0.010287, l3: 0.010588, l4: 0.026694, l5: 0.023885, l6: 0.021020

[epoch:  92/100000, batch:   140/  187, ite: 8624] train loss: 0.110556, tar: 0.011176 
l0: 0.011755, l1: 0.011363, l2: 0.013842, l3: 0.015153, l4: 0.026548, l5: 0.024245, l6: 0.024702

[epoch:  92/100000, batch:   142/  187, ite: 8625] train loss: 0.110583, tar: 0.011177 
l0: 0.013348, l1: 0.013532, l2: 0.017629, l3: 0.018146, l4: 0.025867, l5: 0.022487, l6: 0.016746

[epoch:  92/100000, batch:   144/  187, ite: 8626] train loss: 0.110611, tar: 0.011181 
l0: 0.014845, l1: 0.017374, l2: 0.015491, l3: 0.013943, l4: 0.026694, l5: 0.021253, l6: 0.019440

[epoch:  92/100000, batch:   146/  187, ite: 8627] train loss: 0.110640, tar: 0.011186 
l0: 0.018331, l1: 0.020830, l2: 0.017207, l3: 0.016163, l4: 0.028373, l5: 0.023566, l6: 0.027186

[epoch:  92/100000, batch:   148/  187, ite: 8628] train loss: 0.110706, tar: 0.011198 
l0: 0.006699, l1: 0.006862, l2: 0.007964, l3: 0.008208, l4: 0.015713, l5: 0.015039, l6: 0.016509

[epoch:  92/100000, batch:   150/  187, ite: 8629] train loss: 0.110652, tar: 0.011191 
l0: 0.006473, l1: 0.006271, l2: 0.007593, l3: 0.009609, l4: 0.014386, l5: 0.015039, l6: 0.014904

[epoch:  92/100000, batch:   152/  187, ite: 8630] train loss: 0.110594, tar: 0.011183 
l0: 0.010298, l1: 0.009997, l2: 0.013325, l3: 0.017805, l4: 0.033787, l5: 0.035791, l6: 0.027473

[epoch:  92/100000, batch:   154/  187, ite: 8631] train loss: 0.110654, tar: 0.011182 
l0: 0.012822, l1: 0.012485, l2: 0.012064, l3: 0.013347, l4: 0.023922, l5: 0.023144, l6: 0.030184

[epoch:  92/100000, batch:   156/  187, ite: 8632] train loss: 0.110682, tar: 0.011184 
l0: 0.013562, l1: 0.013362, l2: 0.015371, l3: 0.015426, l4: 0.028173, l5: 0.029596, l6: 0.027067

[epoch:  92/100000, batch:   158/  187, ite: 8633] train loss: 0.110732, tar: 0.011188 
l0: 0.015560, l1: 0.014408, l2: 0.021681, l3: 0.021932, l4: 0.031756, l5: 0.030279, l6: 0.024500

[epoch:  92/100000, batch:   160/  187, ite: 8634] train loss: 0.110810, tar: 0.011195 
l0: 0.012913, l1: 0.014178, l2: 0.012390, l3: 0.012120, l4: 0.017643, l5: 0.015721, l6: 0.018843

[epoch:  92/100000, batch:   162/  187, ite: 8635] train loss: 0.110799, tar: 0.011198 
l0: 0.011215, l1: 0.012269, l2: 0.013548, l3: 0.013885, l4: 0.018296, l5: 0.017250, l6: 0.019156

[epoch:  92/100000, batch:   164/  187, ite: 8636] train loss: 0.110791, tar: 0.011198 
l0: 0.014244, l1: 0.015391, l2: 0.016177, l3: 0.017152, l4: 0.019660, l5: 0.017390, l6: 0.017806

[epoch:  92/100000, batch:   166/  187, ite: 8637] train loss: 0.110802, tar: 0.011202 
l0: 0.010535, l1: 0.011110, l2: 0.010497, l3: 0.010989, l4: 0.023347, l5: 0.020839, l6: 0.023298

[epoch:  92/100000, batch:   168/  187, ite: 8638] train loss: 0.110801, tar: 0.011201 
l0: 0.015438, l1: 0.015684, l2: 0.016301, l3: 0.016868, l4: 0.020751, l5: 0.020707, l6: 0.026519

[epoch:  92/100000, batch:   170/  187, ite: 8639] train loss: 0.110835, tar: 0.011208 
l0: 0.008529, l1: 0.008594, l2: 0.008123, l3: 0.008549, l4: 0.021542, l5: 0.021382, l6: 0.018537

[epoch:  92/100000, batch:   172/  187, ite: 8640] train loss: 0.110811, tar: 0.011204 
l0: 0.009850, l1: 0.009757, l2: 0.010061, l3: 0.010242, l4: 0.014959, l5: 0.015061, l6: 0.015563

[epoch:  92/100000, batch:   174/  187, ite: 8641] train loss: 0.110771, tar: 0.011202 
l0: 0.009192, l1: 0.009136, l2: 0.012885, l3: 0.011931, l4: 0.016723, l5: 0.015842, l6: 0.019873

[epoch:  92/100000, batch:   176/  187, ite: 8642] train loss: 0.110748, tar: 0.011199 
l0: 0.013288, l1: 0.013564, l2: 0.012216, l3: 0.011536, l4: 0.023531, l5: 0.022828, l6: 0.024037

[epoch:  92/100000, batch:   178/  187, ite: 8643] train loss: 0.110764, tar: 0.011202 
l0: 0.016410, l1: 0.016044, l2: 0.018964, l3: 0.019478, l4: 0.025421, l5: 0.027952, l6: 0.024500

[epoch:  92/100000, batch:   180/  187, ite: 8644] train loss: 0.110823, tar: 0.011210 
l0: 0.013269, l1: 0.011900, l2: 0.020155, l3: 0.021202, l4: 0.030090, l5: 0.032003, l6: 0.033796

[epoch:  92/100000, batch:   182/  187, ite: 8645] train loss: 0.110903, tar: 0.011213 
l0: 0.007393, l1: 0.007418, l2: 0.008928, l3: 0.007511, l4: 0.018078, l5: 0.016287, l6: 0.017308

[epoch:  92/100000, batch:   184/  187, ite: 8646] train loss: 0.110859, tar: 0.011207 
l0: 0.008440, l1: 0.008701, l2: 0.012468, l3: 0.015633, l4: 0.037789, l5: 0.032240, l6: 0.024063

[epoch:  92/100000, batch:   186/  187, ite: 8647] train loss: 0.110903, tar: 0.011203 
l0: 0.003207, l1: 0.003206, l2: 0.003437, l3: 0.003223, l4: 0.005001, l5: 0.005215, l6: 0.008253

[epoch:  92/100000, batch:   188/  187, ite: 8648] train loss: 0.110781, tar: 0.011191 
l0: 0.013770, l1: 0.012379, l2: 0.015659, l3: 0.017088, l4: 0.025877, l5: 0.027678, l6: 0.048282

[epoch:  93/100000, batch:     2/  187, ite: 8649] train loss: 0.110858, tar: 0.011195 
l0: 0.008321, l1: 0.007798, l2: 0.010417, l3: 0.010112, l4: 0.014624, l5: 0.016893, l6: 0.014814

[epoch:  93/100000, batch:     4/  187, ite: 8650] train loss: 0.110815, tar: 0.011190 
l0: 0.012594, l1: 0.012117, l2: 0.016736, l3: 0.015970, l4: 0.017800, l5: 0.017732, l6: 0.024778

[epoch:  93/100000, batch:     6/  187, ite: 8651] train loss: 0.110825, tar: 0.011192 
l0: 0.004756, l1: 0.004896, l2: 0.004196, l3: 0.005831, l4: 0.011805, l5: 0.009959, l6: 0.008564

[epoch:  93/100000, batch:     8/  187, ite: 8652] train loss: 0.110732, tar: 0.011182 
l0: 0.010167, l1: 0.010501, l2: 0.011368, l3: 0.010824, l4: 0.018863, l5: 0.015600, l6: 0.017470

[epoch:  93/100000, batch:    10/  187, ite: 8653] train loss: 0.110708, tar: 0.011181 
l0: 0.008829, l1: 0.008915, l2: 0.009442, l3: 0.010994, l4: 0.019869, l5: 0.021153, l6: 0.019584

[epoch:  93/100000, batch:    12/  187, ite: 8654] train loss: 0.110690, tar: 0.011177 
l0: 0.007413, l1: 0.008415, l2: 0.010035, l3: 0.008525, l4: 0.014521, l5: 0.012768, l6: 0.013638

[epoch:  93/100000, batch:    14/  187, ite: 8655] train loss: 0.110636, tar: 0.011172 
l0: 0.006125, l1: 0.005704, l2: 0.006775, l3: 0.006235, l4: 0.009354, l5: 0.011006, l6: 0.014454

[epoch:  93/100000, batch:    16/  187, ite: 8656] train loss: 0.110558, tar: 0.011164 
l0: 0.007752, l1: 0.007888, l2: 0.010225, l3: 0.010168, l4: 0.015291, l5: 0.012189, l6: 0.015138

[epoch:  93/100000, batch:    18/  187, ite: 8657] train loss: 0.110509, tar: 0.011159 
l0: 0.025940, l1: 0.026855, l2: 0.026865, l3: 0.031067, l4: 0.026462, l5: 0.022697, l6: 0.022595

[epoch:  93/100000, batch:    20/  187, ite: 8658] train loss: 0.110619, tar: 0.011181 
l0: 0.008387, l1: 0.008818, l2: 0.010351, l3: 0.010282, l4: 0.014261, l5: 0.014045, l6: 0.015093

[epoch:  93/100000, batch:    22/  187, ite: 8659] train loss: 0.110574, tar: 0.011177 
l0: 0.004535, l1: 0.003436, l2: 0.010456, l3: 0.013779, l4: 0.010470, l5: 0.010107, l6: 0.013816

[epoch:  93/100000, batch:    24/  187, ite: 8660] train loss: 0.110507, tar: 0.011167 
l0: 0.015579, l1: 0.017110, l2: 0.014437, l3: 0.015232, l4: 0.025556, l5: 0.025100, l6: 0.025807

[epoch:  93/100000, batch:    26/  187, ite: 8661] train loss: 0.110550, tar: 0.011173 
l0: 0.007977, l1: 0.009060, l2: 0.008732, l3: 0.007802, l4: 0.013557, l5: 0.010859, l6: 0.011433

[epoch:  93/100000, batch:    28/  187, ite: 8662] train loss: 0.110488, tar: 0.011169 
l0: 0.013675, l1: 0.015178, l2: 0.015976, l3: 0.012798, l4: 0.019986, l5: 0.019576, l6: 0.019696

[epoch:  93/100000, batch:    30/  187, ite: 8663] train loss: 0.110498, tar: 0.011172 
l0: 0.009649, l1: 0.010153, l2: 0.007144, l3: 0.008828, l4: 0.023958, l5: 0.022142, l6: 0.020717

[epoch:  93/100000, batch:    32/  187, ite: 8664] train loss: 0.110486, tar: 0.011170 
l0: 0.014100, l1: 0.013041, l2: 0.014887, l3: 0.018189, l4: 0.018630, l5: 0.019780, l6: 0.027515

[epoch:  93/100000, batch:    34/  187, ite: 8665] train loss: 0.110509, tar: 0.011175 
l0: 0.011528, l1: 0.012090, l2: 0.011939, l3: 0.012751, l4: 0.017932, l5: 0.017842, l6: 0.018312

[epoch:  93/100000, batch:    36/  187, ite: 8666] train loss: 0.110497, tar: 0.011175 
l0: 0.011484, l1: 0.011950, l2: 0.011711, l3: 0.011049, l4: 0.020631, l5: 0.023561, l6: 0.025871

[epoch:  93/100000, batch:    38/  187, ite: 8667] train loss: 0.110506, tar: 0.011176 
l0: 0.012276, l1: 0.012795, l2: 0.011965, l3: 0.012083, l4: 0.020885, l5: 0.018765, l6: 0.019768

[epoch:  93/100000, batch:    40/  187, ite: 8668] train loss: 0.110503, tar: 0.011177 
l0: 0.014074, l1: 0.013304, l2: 0.015918, l3: 0.015378, l4: 0.011289, l5: 0.014634, l6: 0.015266

[epoch:  93/100000, batch:    42/  187, ite: 8669] train loss: 0.110487, tar: 0.011182 
l0: 0.009918, l1: 0.009497, l2: 0.011258, l3: 0.013545, l4: 0.025315, l5: 0.019938, l6: 0.023424

[epoch:  93/100000, batch:    44/  187, ite: 8670] train loss: 0.110491, tar: 0.011180 
l0: 0.013536, l1: 0.012014, l2: 0.017441, l3: 0.019239, l4: 0.014923, l5: 0.017588, l6: 0.015443

[epoch:  93/100000, batch:    46/  187, ite: 8671] train loss: 0.110490, tar: 0.011183 
l0: 0.013761, l1: 0.013257, l2: 0.012623, l3: 0.014894, l4: 0.018304, l5: 0.018493, l6: 0.018554

[epoch:  93/100000, batch:    48/  187, ite: 8672] train loss: 0.110489, tar: 0.011187 
l0: 0.012983, l1: 0.013267, l2: 0.012067, l3: 0.013381, l4: 0.018949, l5: 0.019689, l6: 0.017726

[epoch:  93/100000, batch:    50/  187, ite: 8673] train loss: 0.110486, tar: 0.011190 
l0: 0.010987, l1: 0.010770, l2: 0.011959, l3: 0.013361, l4: 0.017772, l5: 0.017623, l6: 0.015650

[epoch:  93/100000, batch:    52/  187, ite: 8674] train loss: 0.110467, tar: 0.011189 
l0: 0.008158, l1: 0.007859, l2: 0.009352, l3: 0.009877, l4: 0.015446, l5: 0.013546, l6: 0.015268

[epoch:  93/100000, batch:    54/  187, ite: 8675] train loss: 0.110421, tar: 0.011185 
l0: 0.006529, l1: 0.006919, l2: 0.006704, l3: 0.006696, l4: 0.011991, l5: 0.010609, l6: 0.010903

[epoch:  93/100000, batch:    56/  187, ite: 8676] train loss: 0.110347, tar: 0.011178 
l0: 0.009675, l1: 0.010536, l2: 0.009168, l3: 0.010625, l4: 0.023024, l5: 0.019672, l6: 0.020623

[epoch:  93/100000, batch:    58/  187, ite: 8677] train loss: 0.110337, tar: 0.011176 
l0: 0.006853, l1: 0.006587, l2: 0.010093, l3: 0.010361, l4: 0.029609, l5: 0.027461, l6: 0.026403

[epoch:  93/100000, batch:    60/  187, ite: 8678] train loss: 0.110347, tar: 0.011169 
l0: 0.012051, l1: 0.011996, l2: 0.015135, l3: 0.016864, l4: 0.025949, l5: 0.022602, l6: 0.017815

[epoch:  93/100000, batch:    62/  187, ite: 8679] train loss: 0.110365, tar: 0.011171 
l0: 0.012357, l1: 0.013047, l2: 0.013150, l3: 0.014165, l4: 0.018256, l5: 0.019713, l6: 0.022649

[epoch:  93/100000, batch:    64/  187, ite: 8680] train loss: 0.110369, tar: 0.011172 
l0: 0.007091, l1: 0.007811, l2: 0.007998, l3: 0.010172, l4: 0.014646, l5: 0.013070, l6: 0.013698

[epoch:  93/100000, batch:    66/  187, ite: 8681] train loss: 0.110317, tar: 0.011166 
l0: 0.007966, l1: 0.007992, l2: 0.010768, l3: 0.010544, l4: 0.011812, l5: 0.013520, l6: 0.016880

[epoch:  93/100000, batch:    68/  187, ite: 8682] train loss: 0.110272, tar: 0.011162 
l0: 0.006743, l1: 0.006448, l2: 0.011390, l3: 0.013226, l4: 0.014922, l5: 0.011280, l6: 0.012636

[epoch:  93/100000, batch:    70/  187, ite: 8683] train loss: 0.110222, tar: 0.011155 
l0: 0.014337, l1: 0.015211, l2: 0.015713, l3: 0.016171, l4: 0.021089, l5: 0.018896, l6: 0.015864

[epoch:  93/100000, batch:    72/  187, ite: 8684] train loss: 0.110233, tar: 0.011160 
l0: 0.017925, l1: 0.018566, l2: 0.020912, l3: 0.020719, l4: 0.031467, l5: 0.027288, l6: 0.037272

[epoch:  93/100000, batch:    74/  187, ite: 8685] train loss: 0.110326, tar: 0.011170 
l0: 0.014682, l1: 0.015872, l2: 0.015448, l3: 0.014923, l4: 0.016044, l5: 0.015863, l6: 0.017084

[epoch:  93/100000, batch:    76/  187, ite: 8686] train loss: 0.110325, tar: 0.011175 
l0: 0.011359, l1: 0.010973, l2: 0.013846, l3: 0.013294, l4: 0.015215, l5: 0.017347, l6: 0.020400

[epoch:  93/100000, batch:    78/  187, ite: 8687] train loss: 0.110314, tar: 0.011175 
l0: 0.009084, l1: 0.008883, l2: 0.010469, l3: 0.011106, l4: 0.017197, l5: 0.016336, l6: 0.014469

[epoch:  93/100000, batch:    80/  187, ite: 8688] train loss: 0.110281, tar: 0.011172 
l0: 0.008559, l1: 0.009194, l2: 0.009134, l3: 0.008076, l4: 0.015978, l5: 0.015315, l6: 0.018585

[epoch:  93/100000, batch:    82/  187, ite: 8689] train loss: 0.110244, tar: 0.011168 
l0: 0.017480, l1: 0.018306, l2: 0.017282, l3: 0.018021, l4: 0.023799, l5: 0.026183, l6: 0.024036

[epoch:  93/100000, batch:    84/  187, ite: 8690] train loss: 0.110294, tar: 0.011177 
l0: 0.011019, l1: 0.012809, l2: 0.011870, l3: 0.010697, l4: 0.010290, l5: 0.010203, l6: 0.009617

[epoch:  93/100000, batch:    86/  187, ite: 8691] train loss: 0.110245, tar: 0.011177 
l0: 0.007176, l1: 0.007295, l2: 0.007286, l3: 0.007543, l4: 0.017241, l5: 0.013321, l6: 0.019940

[epoch:  93/100000, batch:    88/  187, ite: 8692] train loss: 0.110202, tar: 0.011171 
l0: 0.015991, l1: 0.014527, l2: 0.020212, l3: 0.024974, l4: 0.030546, l5: 0.031377, l6: 0.026135

[epoch:  93/100000, batch:    90/  187, ite: 8693] train loss: 0.110279, tar: 0.011178 
l0: 0.013514, l1: 0.013404, l2: 0.017993, l3: 0.016456, l4: 0.019473, l5: 0.017449, l6: 0.016067

[epoch:  93/100000, batch:    92/  187, ite: 8694] train loss: 0.110285, tar: 0.011182 
l0: 0.005788, l1: 0.005976, l2: 0.007459, l3: 0.007267, l4: 0.012715, l5: 0.010263, l6: 0.009012

[epoch:  93/100000, batch:    94/  187, ite: 8695] train loss: 0.110210, tar: 0.011174 
l0: 0.010567, l1: 0.016799, l2: 0.015089, l3: 0.010251, l4: 0.014976, l5: 0.007117, l6: 0.007720

[epoch:  93/100000, batch:    96/  187, ite: 8696] train loss: 0.110170, tar: 0.011173 
l0: 0.009890, l1: 0.010233, l2: 0.011857, l3: 0.012346, l4: 0.019008, l5: 0.015968, l6: 0.018124

[epoch:  93/100000, batch:    98/  187, ite: 8697] train loss: 0.110152, tar: 0.011171 
l0: 0.009511, l1: 0.009666, l2: 0.008196, l3: 0.008692, l4: 0.016422, l5: 0.016610, l6: 0.019253

[epoch:  93/100000, batch:   100/  187, ite: 8698] train loss: 0.110121, tar: 0.011169 
l0: 0.018534, l1: 0.020346, l2: 0.017695, l3: 0.018041, l4: 0.024300, l5: 0.023707, l6: 0.026225

[epoch:  93/100000, batch:   102/  187, ite: 8699] train loss: 0.110176, tar: 0.011179 
l0: 0.017547, l1: 0.018856, l2: 0.020352, l3: 0.023083, l4: 0.038817, l5: 0.028316, l6: 0.025516

[epoch:  93/100000, batch:   104/  187, ite: 8700] train loss: 0.110265, tar: 0.011189 
l0: 0.014693, l1: 0.012827, l2: 0.017423, l3: 0.018831, l4: 0.033160, l5: 0.039575, l6: 0.036033

[epoch:  93/100000, batch:   106/  187, ite: 8701] train loss: 0.110354, tar: 0.011194 
l0: 0.012524, l1: 0.012361, l2: 0.016347, l3: 0.016588, l4: 0.029789, l5: 0.028791, l6: 0.025127

[epoch:  93/100000, batch:   108/  187, ite: 8702] train loss: 0.110398, tar: 0.011195 
l0: 0.010418, l1: 0.010716, l2: 0.008427, l3: 0.008228, l4: 0.016469, l5: 0.016984, l6: 0.017808

[epoch:  93/100000, batch:   110/  187, ite: 8703] train loss: 0.110368, tar: 0.011194 
l0: 0.005856, l1: 0.005524, l2: 0.006333, l3: 0.006975, l4: 0.009331, l5: 0.009600, l6: 0.013071

[epoch:  93/100000, batch:   112/  187, ite: 8704] train loss: 0.110292, tar: 0.011187 
l0: 0.015917, l1: 0.014443, l2: 0.024832, l3: 0.026356, l4: 0.021131, l5: 0.022157, l6: 0.026446

[epoch:  93/100000, batch:   114/  187, ite: 8705] train loss: 0.110350, tar: 0.011193 
l0: 0.013690, l1: 0.012694, l2: 0.017472, l3: 0.019128, l4: 0.027622, l5: 0.026047, l6: 0.020311

[epoch:  93/100000, batch:   116/  187, ite: 8706] train loss: 0.110388, tar: 0.011197 
l0: 0.010011, l1: 0.009138, l2: 0.011849, l3: 0.014312, l4: 0.023039, l5: 0.020773, l6: 0.024715

[epoch:  93/100000, batch:   118/  187, ite: 8707] train loss: 0.110393, tar: 0.011195 
l0: 0.007299, l1: 0.006959, l2: 0.010672, l3: 0.011264, l4: 0.017778, l5: 0.015808, l6: 0.014393

[epoch:  93/100000, batch:   120/  187, ite: 8708] train loss: 0.110356, tar: 0.011190 
l0: 0.011758, l1: 0.011523, l2: 0.016080, l3: 0.016170, l4: 0.020551, l5: 0.016489, l6: 0.020213

[epoch:  93/100000, batch:   122/  187, ite: 8709] train loss: 0.110359, tar: 0.011191 
l0: 0.016672, l1: 0.018585, l2: 0.010801, l3: 0.009454, l4: 0.016261, l5: 0.016385, l6: 0.023050

[epoch:  93/100000, batch:   124/  187, ite: 8710] train loss: 0.110360, tar: 0.011198 
l0: 0.003873, l1: 0.004164, l2: 0.004454, l3: 0.004967, l4: 0.007560, l5: 0.009073, l6: 0.014087

[epoch:  93/100000, batch:   126/  187, ite: 8711] train loss: 0.110273, tar: 0.011188 
l0: 0.004785, l1: 0.004932, l2: 0.006743, l3: 0.006814, l4: 0.010504, l5: 0.010544, l6: 0.011344

[epoch:  93/100000, batch:   128/  187, ite: 8712] train loss: 0.110196, tar: 0.011179 
l0: 0.007788, l1: 0.008241, l2: 0.009409, l3: 0.009116, l4: 0.016283, l5: 0.015390, l6: 0.014902

[epoch:  93/100000, batch:   130/  187, ite: 8713] train loss: 0.110155, tar: 0.011174 
l0: 0.012279, l1: 0.013296, l2: 0.014051, l3: 0.013731, l4: 0.018873, l5: 0.016706, l6: 0.015905

[epoch:  93/100000, batch:   132/  187, ite: 8714] train loss: 0.110148, tar: 0.011176 
l0: 0.011983, l1: 0.012742, l2: 0.011770, l3: 0.011041, l4: 0.013440, l5: 0.013235, l6: 0.017624

[epoch:  93/100000, batch:   134/  187, ite: 8715] train loss: 0.110122, tar: 0.011177 
l0: 0.009908, l1: 0.011200, l2: 0.011474, l3: 0.011673, l4: 0.015723, l5: 0.014824, l6: 0.015613

[epoch:  93/100000, batch:   136/  187, ite: 8716] train loss: 0.110095, tar: 0.011175 
l0: 0.008600, l1: 0.008907, l2: 0.007547, l3: 0.007476, l4: 0.019367, l5: 0.018366, l6: 0.017171

[epoch:  93/100000, batch:   138/  187, ite: 8717] train loss: 0.110063, tar: 0.011172 
l0: 0.010245, l1: 0.009849, l2: 0.013464, l3: 0.015185, l4: 0.017242, l5: 0.015479, l6: 0.018068

[epoch:  93/100000, batch:   140/  187, ite: 8718] train loss: 0.110048, tar: 0.011170 
l0: 0.014330, l1: 0.013328, l2: 0.016561, l3: 0.017422, l4: 0.025770, l5: 0.025742, l6: 0.032929

[epoch:  93/100000, batch:   142/  187, ite: 8719] train loss: 0.110099, tar: 0.011175 
l0: 0.010040, l1: 0.011518, l2: 0.010628, l3: 0.012675, l4: 0.021684, l5: 0.019411, l6: 0.016683

[epoch:  93/100000, batch:   144/  187, ite: 8720] train loss: 0.110088, tar: 0.011173 
l0: 0.005175, l1: 0.005253, l2: 0.006321, l3: 0.006590, l4: 0.010928, l5: 0.011107, l6: 0.008623

[epoch:  93/100000, batch:   146/  187, ite: 8721] train loss: 0.110010, tar: 0.011165 
l0: 0.007357, l1: 0.007895, l2: 0.008876, l3: 0.009192, l4: 0.018221, l5: 0.013762, l6: 0.012004

[epoch:  93/100000, batch:   148/  187, ite: 8722] train loss: 0.109965, tar: 0.011160 
l0: 0.009651, l1: 0.010248, l2: 0.012169, l3: 0.012083, l4: 0.028124, l5: 0.026534, l6: 0.015952

[epoch:  93/100000, batch:   150/  187, ite: 8723] train loss: 0.109972, tar: 0.011157 
l0: 0.005830, l1: 0.006633, l2: 0.005550, l3: 0.005848, l4: 0.012027, l5: 0.010383, l6: 0.011794

[epoch:  93/100000, batch:   152/  187, ite: 8724] train loss: 0.109900, tar: 0.011150 
l0: 0.016002, l1: 0.016819, l2: 0.013812, l3: 0.013707, l4: 0.014814, l5: 0.013613, l6: 0.020830

[epoch:  93/100000, batch:   154/  187, ite: 8725] train loss: 0.109900, tar: 0.011157 
l0: 0.011005, l1: 0.011190, l2: 0.012929, l3: 0.013906, l4: 0.022398, l5: 0.026284, l6: 0.035093

[epoch:  93/100000, batch:   156/  187, ite: 8726] train loss: 0.109931, tar: 0.011157 
l0: 0.011686, l1: 0.010610, l2: 0.012957, l3: 0.014779, l4: 0.028599, l5: 0.026525, l6: 0.030850

[epoch:  93/100000, batch:   158/  187, ite: 8727] train loss: 0.109967, tar: 0.011157 
l0: 0.015082, l1: 0.014682, l2: 0.016226, l3: 0.022124, l4: 0.054678, l5: 0.036716, l6: 0.028713

[epoch:  93/100000, batch:   160/  187, ite: 8728] train loss: 0.110075, tar: 0.011163 
l0: 0.012973, l1: 0.013813, l2: 0.015262, l3: 0.013970, l4: 0.016397, l5: 0.017033, l6: 0.018190

[epoch:  93/100000, batch:   162/  187, ite: 8729] train loss: 0.110071, tar: 0.011165 
l0: 0.008630, l1: 0.009601, l2: 0.010766, l3: 0.009822, l4: 0.014993, l5: 0.012109, l6: 0.012874

[epoch:  93/100000, batch:   164/  187, ite: 8730] train loss: 0.110028, tar: 0.011162 
l0: 0.006913, l1: 0.006874, l2: 0.009450, l3: 0.008570, l4: 0.013682, l5: 0.013943, l6: 0.015424

[epoch:  93/100000, batch:   166/  187, ite: 8731] train loss: 0.109980, tar: 0.011156 
l0: 0.022234, l1: 0.017902, l2: 0.022048, l3: 0.028717, l4: 0.063221, l5: 0.064963, l6: 0.074784

[epoch:  93/100000, batch:   168/  187, ite: 8732] train loss: 0.110231, tar: 0.011171 
l0: 0.011481, l1: 0.011664, l2: 0.012373, l3: 0.015118, l4: 0.018456, l5: 0.020221, l6: 0.020581

[epoch:  93/100000, batch:   170/  187, ite: 8733] train loss: 0.110231, tar: 0.011171 
l0: 0.007360, l1: 0.007445, l2: 0.008008, l3: 0.008197, l4: 0.011781, l5: 0.011500, l6: 0.013126

[epoch:  93/100000, batch:   172/  187, ite: 8734] train loss: 0.110173, tar: 0.011166 
l0: 0.007162, l1: 0.008342, l2: 0.009475, l3: 0.008790, l4: 0.015029, l5: 0.015222, l6: 0.012525

[epoch:  93/100000, batch:   174/  187, ite: 8735] train loss: 0.110127, tar: 0.011161 
l0: 0.012298, l1: 0.012878, l2: 0.012782, l3: 0.014589, l4: 0.015545, l5: 0.012846, l6: 0.014595

[epoch:  93/100000, batch:   176/  187, ite: 8736] train loss: 0.110107, tar: 0.011162 
l0: 0.007140, l1: 0.006766, l2: 0.008588, l3: 0.010909, l4: 0.014153, l5: 0.012723, l6: 0.013850

[epoch:  93/100000, batch:   178/  187, ite: 8737] train loss: 0.110058, tar: 0.011157 
l0: 0.010977, l1: 0.010052, l2: 0.018218, l3: 0.014253, l4: 0.019172, l5: 0.020596, l6: 0.019114

[epoch:  93/100000, batch:   180/  187, ite: 8738] train loss: 0.110061, tar: 0.011157 
l0: 0.007852, l1: 0.007585, l2: 0.008594, l3: 0.008938, l4: 0.012709, l5: 0.012064, l6: 0.014741

[epoch:  93/100000, batch:   182/  187, ite: 8739] train loss: 0.110011, tar: 0.011152 
l0: 0.007652, l1: 0.008246, l2: 0.008253, l3: 0.009362, l4: 0.018331, l5: 0.019141, l6: 0.012791

[epoch:  93/100000, batch:   184/  187, ite: 8740] train loss: 0.109975, tar: 0.011147 
l0: 0.006114, l1: 0.006284, l2: 0.008761, l3: 0.009131, l4: 0.015654, l5: 0.014458, l6: 0.017637

[epoch:  93/100000, batch:   186/  187, ite: 8741] train loss: 0.109932, tar: 0.011141 
l0: 0.021588, l1: 0.023926, l2: 0.024343, l3: 0.022187, l4: 0.036652, l5: 0.033567, l6: 0.027986

[epoch:  93/100000, batch:   188/  187, ite: 8742] train loss: 0.110040, tar: 0.011155 
l0: 0.006874, l1: 0.005910, l2: 0.008142, l3: 0.010161, l4: 0.020329, l5: 0.019710, l6: 0.017546

[epoch:  94/100000, batch:     2/  187, ite: 8743] train loss: 0.110011, tar: 0.011149 
l0: 0.014379, l1: 0.014504, l2: 0.017992, l3: 0.020400, l4: 0.020670, l5: 0.023366, l6: 0.020112

[epoch:  94/100000, batch:     4/  187, ite: 8744] train loss: 0.110040, tar: 0.011153 
l0: 0.008215, l1: 0.008552, l2: 0.008513, l3: 0.009563, l4: 0.016578, l5: 0.014901, l6: 0.016035

[epoch:  94/100000, batch:     6/  187, ite: 8745] train loss: 0.110003, tar: 0.011149 
l0: 0.007189, l1: 0.008546, l2: 0.007811, l3: 0.008356, l4: 0.013020, l5: 0.013227, l6: 0.015902

[epoch:  94/100000, batch:     8/  187, ite: 8746] train loss: 0.109955, tar: 0.011144 
l0: 0.004785, l1: 0.004948, l2: 0.003885, l3: 0.008229, l4: 0.021220, l5: 0.023977, l6: 0.020949

[epoch:  94/100000, batch:    10/  187, ite: 8747] train loss: 0.109925, tar: 0.011136 
l0: 0.010123, l1: 0.010688, l2: 0.011009, l3: 0.011306, l4: 0.024850, l5: 0.018982, l6: 0.015647

[epoch:  94/100000, batch:    12/  187, ite: 8748] train loss: 0.109916, tar: 0.011134 
l0: 0.026134, l1: 0.024113, l2: 0.028649, l3: 0.024968, l4: 0.031962, l5: 0.041843, l6: 0.039359

[epoch:  94/100000, batch:    14/  187, ite: 8749] train loss: 0.110059, tar: 0.011154 
l0: 0.012513, l1: 0.012542, l2: 0.012900, l3: 0.012491, l4: 0.025453, l5: 0.029969, l6: 0.032118

[epoch:  94/100000, batch:    16/  187, ite: 8750] train loss: 0.110096, tar: 0.011156 
l0: 0.010965, l1: 0.010240, l2: 0.011591, l3: 0.013538, l4: 0.019276, l5: 0.017590, l6: 0.018895

[epoch:  94/100000, batch:    18/  187, ite: 8751] train loss: 0.110085, tar: 0.011156 
l0: 0.014920, l1: 0.018111, l2: 0.016542, l3: 0.013051, l4: 0.017468, l5: 0.013682, l6: 0.013402

[epoch:  94/100000, batch:    20/  187, ite: 8752] train loss: 0.110081, tar: 0.011161 
l0: 0.009205, l1: 0.009270, l2: 0.011651, l3: 0.011427, l4: 0.018357, l5: 0.016494, l6: 0.014415

[epoch:  94/100000, batch:    22/  187, ite: 8753] train loss: 0.110056, tar: 0.011158 
l0: 0.014218, l1: 0.013659, l2: 0.013822, l3: 0.015950, l4: 0.025600, l5: 0.027477, l6: 0.040669

[epoch:  94/100000, batch:    24/  187, ite: 8754] train loss: 0.110111, tar: 0.011162 
l0: 0.010749, l1: 0.010122, l2: 0.016473, l3: 0.014917, l4: 0.031319, l5: 0.035779, l6: 0.036416

[epoch:  94/100000, batch:    26/  187, ite: 8755] train loss: 0.110171, tar: 0.011162 
l0: 0.007613, l1: 0.007537, l2: 0.012245, l3: 0.010313, l4: 0.019341, l5: 0.017313, l6: 0.013467

[epoch:  94/100000, batch:    28/  187, ite: 8756] train loss: 0.110142, tar: 0.011157 
l0: 0.006775, l1: 0.007207, l2: 0.008619, l3: 0.008374, l4: 0.019141, l5: 0.015341, l6: 0.012744

[epoch:  94/100000, batch:    30/  187, ite: 8757] train loss: 0.110099, tar: 0.011151 
l0: 0.010628, l1: 0.010643, l2: 0.013065, l3: 0.018899, l4: 0.025530, l5: 0.021653, l6: 0.019411

[epoch:  94/100000, batch:    32/  187, ite: 8758] train loss: 0.110112, tar: 0.011151 
l0: 0.011939, l1: 0.012342, l2: 0.012666, l3: 0.015606, l4: 0.025634, l5: 0.023632, l6: 0.026199

[epoch:  94/100000, batch:    34/  187, ite: 8759] train loss: 0.110136, tar: 0.011152 
l0: 0.012202, l1: 0.011422, l2: 0.014401, l3: 0.015685, l4: 0.025215, l5: 0.021496, l6: 0.024942

[epoch:  94/100000, batch:    36/  187, ite: 8760] train loss: 0.110156, tar: 0.011153 
l0: 0.013123, l1: 0.015414, l2: 0.013506, l3: 0.014112, l4: 0.023514, l5: 0.018267, l6: 0.016319

[epoch:  94/100000, batch:    38/  187, ite: 8761] train loss: 0.110161, tar: 0.011156 
l0: 0.013962, l1: 0.013861, l2: 0.014051, l3: 0.016540, l4: 0.030424, l5: 0.033698, l6: 0.028290

[epoch:  94/100000, batch:    40/  187, ite: 8762] train loss: 0.110215, tar: 0.011159 
l0: 0.016870, l1: 0.019964, l2: 0.019071, l3: 0.018788, l4: 0.019586, l5: 0.022023, l6: 0.014391

[epoch:  94/100000, batch:    42/  187, ite: 8763] train loss: 0.110241, tar: 0.011167 
l0: 0.010404, l1: 0.010844, l2: 0.014255, l3: 0.012323, l4: 0.014438, l5: 0.015471, l6: 0.016696

[epoch:  94/100000, batch:    44/  187, ite: 8764] train loss: 0.110221, tar: 0.011166 
l0: 0.007677, l1: 0.007699, l2: 0.009957, l3: 0.008549, l4: 0.016263, l5: 0.013731, l6: 0.012253

[epoch:  94/100000, batch:    46/  187, ite: 8765] train loss: 0.110176, tar: 0.011161 
l0: 0.008379, l1: 0.008839, l2: 0.009764, l3: 0.011993, l4: 0.018769, l5: 0.015508, l6: 0.017932

[epoch:  94/100000, batch:    48/  187, ite: 8766] train loss: 0.110151, tar: 0.011158 
l0: 0.015863, l1: 0.015394, l2: 0.015750, l3: 0.016442, l4: 0.028906, l5: 0.029606, l6: 0.040139

[epoch:  94/100000, batch:    50/  187, ite: 8767] train loss: 0.110219, tar: 0.011164 
l0: 0.014963, l1: 0.015107, l2: 0.017502, l3: 0.017629, l4: 0.021107, l5: 0.020922, l6: 0.022291

[epoch:  94/100000, batch:    52/  187, ite: 8768] train loss: 0.110244, tar: 0.011169 
l0: 0.005269, l1: 0.005034, l2: 0.006572, l3: 0.008346, l4: 0.012211, l5: 0.008734, l6: 0.009435

[epoch:  94/100000, batch:    54/  187, ite: 8769] train loss: 0.110173, tar: 0.011161 
l0: 0.006403, l1: 0.006859, l2: 0.008369, l3: 0.008874, l4: 0.014023, l5: 0.014413, l6: 0.015443

[epoch:  94/100000, batch:    56/  187, ite: 8770] train loss: 0.110127, tar: 0.011155 
l0: 0.012935, l1: 0.014233, l2: 0.014736, l3: 0.013651, l4: 0.019085, l5: 0.017023, l6: 0.018677

[epoch:  94/100000, batch:    58/  187, ite: 8771] train loss: 0.110127, tar: 0.011157 
l0: 0.010165, l1: 0.010565, l2: 0.012873, l3: 0.012874, l4: 0.020828, l5: 0.021128, l6: 0.019210

[epoch:  94/100000, batch:    60/  187, ite: 8772] train loss: 0.110124, tar: 0.011156 
l0: 0.020668, l1: 0.020732, l2: 0.018852, l3: 0.020806, l4: 0.039918, l5: 0.039055, l6: 0.038292

[epoch:  94/100000, batch:    62/  187, ite: 8773] train loss: 0.110238, tar: 0.011168 
l0: 0.012435, l1: 0.012470, l2: 0.012900, l3: 0.013493, l4: 0.020213, l5: 0.017480, l6: 0.023182

[epoch:  94/100000, batch:    64/  187, ite: 8774] train loss: 0.110240, tar: 0.011170 
l0: 0.012398, l1: 0.013271, l2: 0.010909, l3: 0.011137, l4: 0.014743, l5: 0.013132, l6: 0.015092

[epoch:  94/100000, batch:    66/  187, ite: 8775] train loss: 0.110215, tar: 0.011171 
l0: 0.012425, l1: 0.012375, l2: 0.011981, l3: 0.012765, l4: 0.023667, l5: 0.024236, l6: 0.022286

[epoch:  94/100000, batch:    68/  187, ite: 8776] train loss: 0.110227, tar: 0.011173 
l0: 0.005192, l1: 0.005539, l2: 0.005634, l3: 0.006014, l4: 0.011979, l5: 0.009842, l6: 0.013577

[epoch:  94/100000, batch:    70/  187, ite: 8777] train loss: 0.110160, tar: 0.011165 
l0: 0.008521, l1: 0.008263, l2: 0.009534, l3: 0.009832, l4: 0.021214, l5: 0.021473, l6: 0.021668

[epoch:  94/100000, batch:    72/  187, ite: 8778] train loss: 0.110148, tar: 0.011162 
l0: 0.011569, l1: 0.011227, l2: 0.010930, l3: 0.011671, l4: 0.024420, l5: 0.027034, l6: 0.030973

[epoch:  94/100000, batch:    74/  187, ite: 8779] train loss: 0.110170, tar: 0.011162 
l0: 0.008073, l1: 0.008575, l2: 0.005838, l3: 0.006816, l4: 0.010502, l5: 0.011553, l6: 0.015831

[epoch:  94/100000, batch:    76/  187, ite: 8780] train loss: 0.110115, tar: 0.011158 
l0: 0.011150, l1: 0.011471, l2: 0.012299, l3: 0.012041, l4: 0.015799, l5: 0.015534, l6: 0.019378

[epoch:  94/100000, batch:    78/  187, ite: 8781] train loss: 0.110099, tar: 0.011158 
l0: 0.011391, l1: 0.012926, l2: 0.010005, l3: 0.009415, l4: 0.013992, l5: 0.013501, l6: 0.014275

[epoch:  94/100000, batch:    80/  187, ite: 8782] train loss: 0.110068, tar: 0.011159 
l0: 0.010407, l1: 0.010487, l2: 0.010410, l3: 0.009730, l4: 0.022147, l5: 0.022224, l6: 0.031051

[epoch:  94/100000, batch:    82/  187, ite: 8783] train loss: 0.110076, tar: 0.011158 
l0: 0.010360, l1: 0.010945, l2: 0.011186, l3: 0.010487, l4: 0.021766, l5: 0.020455, l6: 0.019492

[epoch:  94/100000, batch:    84/  187, ite: 8784] train loss: 0.110069, tar: 0.011157 
l0: 0.005793, l1: 0.006043, l2: 0.007536, l3: 0.007425, l4: 0.011527, l5: 0.010349, l6: 0.010766

[epoch:  94/100000, batch:    86/  187, ite: 8785] train loss: 0.110005, tar: 0.011150 
l0: 0.009068, l1: 0.009922, l2: 0.009005, l3: 0.008068, l4: 0.015564, l5: 0.011490, l6: 0.014780

[epoch:  94/100000, batch:    88/  187, ite: 8786] train loss: 0.109964, tar: 0.011147 
l0: 0.010738, l1: 0.011265, l2: 0.011174, l3: 0.012036, l4: 0.027557, l5: 0.021668, l6: 0.019446

[epoch:  94/100000, batch:    90/  187, ite: 8787] train loss: 0.109969, tar: 0.011147 
l0: 0.014021, l1: 0.014051, l2: 0.016622, l3: 0.016711, l4: 0.018089, l5: 0.016138, l6: 0.017743

[epoch:  94/100000, batch:    92/  187, ite: 8788] train loss: 0.109973, tar: 0.011150 
l0: 0.012211, l1: 0.011951, l2: 0.010161, l3: 0.011076, l4: 0.024215, l5: 0.025627, l6: 0.029548

[epoch:  94/100000, batch:    94/  187, ite: 8789] train loss: 0.109992, tar: 0.011152 
l0: 0.005453, l1: 0.005242, l2: 0.006193, l3: 0.006992, l4: 0.013742, l5: 0.014555, l6: 0.027342

[epoch:  94/100000, batch:    96/  187, ite: 8790] train loss: 0.109953, tar: 0.011144 
l0: 0.020314, l1: 0.020777, l2: 0.025054, l3: 0.025784, l4: 0.032149, l5: 0.037293, l6: 0.028310

[epoch:  94/100000, batch:    98/  187, ite: 8791] train loss: 0.110054, tar: 0.011156 
l0: 0.010205, l1: 0.011091, l2: 0.011536, l3: 0.011653, l4: 0.018489, l5: 0.015986, l6: 0.016631

[epoch:  94/100000, batch:   100/  187, ite: 8792] train loss: 0.110036, tar: 0.011155 
l0: 0.011456, l1: 0.010054, l2: 0.016778, l3: 0.023357, l4: 0.023349, l5: 0.022671, l6: 0.014632

[epoch:  94/100000, batch:   102/  187, ite: 8793] train loss: 0.110051, tar: 0.011155 
l0: 0.007787, l1: 0.007703, l2: 0.008418, l3: 0.008424, l4: 0.014549, l5: 0.016169, l6: 0.013940

[epoch:  94/100000, batch:   104/  187, ite: 8794] train loss: 0.110010, tar: 0.011151 
l0: 0.012450, l1: 0.013577, l2: 0.014335, l3: 0.015390, l4: 0.018051, l5: 0.018402, l6: 0.020105

[epoch:  94/100000, batch:   106/  187, ite: 8795] train loss: 0.110012, tar: 0.011153 
l0: 0.019097, l1: 0.018302, l2: 0.021822, l3: 0.021794, l4: 0.030514, l5: 0.027131, l6: 0.026677

[epoch:  94/100000, batch:   108/  187, ite: 8796] train loss: 0.110082, tar: 0.011163 
l0: 0.009585, l1: 0.009986, l2: 0.010449, l3: 0.011583, l4: 0.023818, l5: 0.020767, l6: 0.016703

[epoch:  94/100000, batch:   110/  187, ite: 8797] train loss: 0.110073, tar: 0.011161 
l0: 0.011811, l1: 0.010994, l2: 0.016037, l3: 0.016681, l4: 0.019126, l5: 0.019242, l6: 0.021243

[epoch:  94/100000, batch:   112/  187, ite: 8798] train loss: 0.110079, tar: 0.011161 
l0: 0.012671, l1: 0.013801, l2: 0.013511, l3: 0.012539, l4: 0.024778, l5: 0.024311, l6: 0.022770

[epoch:  94/100000, batch:   114/  187, ite: 8799] train loss: 0.110097, tar: 0.011163 
l0: 0.011448, l1: 0.010966, l2: 0.021997, l3: 0.017565, l4: 0.022327, l5: 0.024584, l6: 0.027150

[epoch:  94/100000, batch:   116/  187, ite: 8800] train loss: 0.110130, tar: 0.011164 
l0: 0.006784, l1: 0.007239, l2: 0.007984, l3: 0.007548, l4: 0.022575, l5: 0.023399, l6: 0.017348

[epoch:  94/100000, batch:   118/  187, ite: 8801] train loss: 0.110108, tar: 0.011158 
l0: 0.005567, l1: 0.006376, l2: 0.004789, l3: 0.005006, l4: 0.006252, l5: 0.007332, l6: 0.007808

[epoch:  94/100000, batch:   120/  187, ite: 8802] train loss: 0.110025, tar: 0.011151 
l0: 0.014139, l1: 0.013988, l2: 0.020002, l3: 0.020573, l4: 0.013682, l5: 0.014331, l6: 0.014535

[epoch:  94/100000, batch:   122/  187, ite: 8803] train loss: 0.110026, tar: 0.011155 
l0: 0.009086, l1: 0.009594, l2: 0.011921, l3: 0.011249, l4: 0.016053, l5: 0.018382, l6: 0.018542

[epoch:  94/100000, batch:   124/  187, ite: 8804] train loss: 0.110007, tar: 0.011152 
l0: 0.012527, l1: 0.013100, l2: 0.012595, l3: 0.012730, l4: 0.024009, l5: 0.025922, l6: 0.030856

[epoch:  94/100000, batch:   126/  187, ite: 8805] train loss: 0.110034, tar: 0.011154 
l0: 0.009611, l1: 0.011285, l2: 0.008114, l3: 0.007851, l4: 0.012416, l5: 0.010973, l6: 0.013874

[epoch:  94/100000, batch:   128/  187, ite: 8806] train loss: 0.109990, tar: 0.011152 
l0: 0.009957, l1: 0.010196, l2: 0.011995, l3: 0.013716, l4: 0.017209, l5: 0.015098, l6: 0.014399

[epoch:  94/100000, batch:   130/  187, ite: 8807] train loss: 0.109968, tar: 0.011151 
l0: 0.015417, l1: 0.015688, l2: 0.019128, l3: 0.019293, l4: 0.019733, l5: 0.019039, l6: 0.022674

[epoch:  94/100000, batch:   132/  187, ite: 8808] train loss: 0.109994, tar: 0.011156 
l0: 0.011176, l1: 0.010827, l2: 0.011608, l3: 0.014147, l4: 0.027520, l5: 0.023186, l6: 0.023848

[epoch:  94/100000, batch:   134/  187, ite: 8809] train loss: 0.110009, tar: 0.011156 
l0: 0.008619, l1: 0.008704, l2: 0.010405, l3: 0.012583, l4: 0.018719, l5: 0.015758, l6: 0.014811

[epoch:  94/100000, batch:   136/  187, ite: 8810] train loss: 0.109984, tar: 0.011153 
l0: 0.009180, l1: 0.009456, l2: 0.010410, l3: 0.010926, l4: 0.020510, l5: 0.018309, l6: 0.019368

[epoch:  94/100000, batch:   138/  187, ite: 8811] train loss: 0.109969, tar: 0.011150 
l0: 0.010346, l1: 0.011087, l2: 0.011854, l3: 0.011402, l4: 0.016589, l5: 0.016916, l6: 0.018017

[epoch:  94/100000, batch:   140/  187, ite: 8812] train loss: 0.109952, tar: 0.011149 
l0: 0.007534, l1: 0.007524, l2: 0.008295, l3: 0.008408, l4: 0.021263, l5: 0.017919, l6: 0.016397

[epoch:  94/100000, batch:   142/  187, ite: 8813] train loss: 0.109925, tar: 0.011145 
l0: 0.013041, l1: 0.012240, l2: 0.013028, l3: 0.014964, l4: 0.017048, l5: 0.018179, l6: 0.021814

[epoch:  94/100000, batch:   144/  187, ite: 8814] train loss: 0.109925, tar: 0.011147 
l0: 0.002449, l1: 0.002536, l2: 0.003016, l3: 0.002563, l4: 0.003507, l5: 0.003418, l6: 0.005826

[epoch:  94/100000, batch:   146/  187, ite: 8815] train loss: 0.109819, tar: 0.011137 
l0: 0.009781, l1: 0.010394, l2: 0.012508, l3: 0.012030, l4: 0.044231, l5: 0.037367, l6: 0.039294

[epoch:  94/100000, batch:   148/  187, ite: 8816] train loss: 0.109887, tar: 0.011135 
l0: 0.006251, l1: 0.005938, l2: 0.007812, l3: 0.009091, l4: 0.017739, l5: 0.014542, l6: 0.018487

[epoch:  94/100000, batch:   150/  187, ite: 8817] train loss: 0.109850, tar: 0.011129 
l0: 0.009610, l1: 0.010302, l2: 0.010719, l3: 0.011295, l4: 0.013393, l5: 0.013060, l6: 0.015069

[epoch:  94/100000, batch:   152/  187, ite: 8818] train loss: 0.109818, tar: 0.011127 
l0: 0.028371, l1: 0.029270, l2: 0.032134, l3: 0.030678, l4: 0.028062, l5: 0.026548, l6: 0.027282

[epoch:  94/100000, batch:   154/  187, ite: 8819] train loss: 0.109931, tar: 0.011148 
l0: 0.015566, l1: 0.015095, l2: 0.017084, l3: 0.019289, l4: 0.025653, l5: 0.029133, l6: 0.020742

[epoch:  94/100000, batch:   156/  187, ite: 8820] train loss: 0.109971, tar: 0.011154 
l0: 0.006911, l1: 0.006826, l2: 0.007114, l3: 0.007258, l4: 0.018093, l5: 0.023786, l6: 0.019402

[epoch:  94/100000, batch:   158/  187, ite: 8821] train loss: 0.109946, tar: 0.011148 
l0: 0.007978, l1: 0.008415, l2: 0.008435, l3: 0.008181, l4: 0.013466, l5: 0.014513, l6: 0.014254

[epoch:  94/100000, batch:   160/  187, ite: 8822] train loss: 0.109904, tar: 0.011145 
l0: 0.006553, l1: 0.006853, l2: 0.008965, l3: 0.009827, l4: 0.019018, l5: 0.018358, l6: 0.018931

[epoch:  94/100000, batch:   162/  187, ite: 8823] train loss: 0.109878, tar: 0.011139 
l0: 0.009492, l1: 0.010196, l2: 0.010554, l3: 0.010377, l4: 0.017971, l5: 0.013914, l6: 0.015535

[epoch:  94/100000, batch:   164/  187, ite: 8824] train loss: 0.109851, tar: 0.011137 
l0: 0.010235, l1: 0.011806, l2: 0.009784, l3: 0.009506, l4: 0.021779, l5: 0.022028, l6: 0.019034

[epoch:  94/100000, batch:   166/  187, ite: 8825] train loss: 0.109844, tar: 0.011136 
l0: 0.011921, l1: 0.011737, l2: 0.013762, l3: 0.013568, l4: 0.014682, l5: 0.016860, l6: 0.016000

[epoch:  94/100000, batch:   168/  187, ite: 8826] train loss: 0.109831, tar: 0.011137 
l0: 0.013200, l1: 0.014166, l2: 0.013604, l3: 0.013937, l4: 0.015579, l5: 0.013521, l6: 0.014583

[epoch:  94/100000, batch:   170/  187, ite: 8827] train loss: 0.109817, tar: 0.011139 
l0: 0.007021, l1: 0.006759, l2: 0.007433, l3: 0.007665, l4: 0.014315, l5: 0.018185, l6: 0.021239

[epoch:  94/100000, batch:   172/  187, ite: 8828] train loss: 0.109784, tar: 0.011134 
l0: 0.012106, l1: 0.011754, l2: 0.010353, l3: 0.011111, l4: 0.025683, l5: 0.035019, l6: 0.032735

[epoch:  94/100000, batch:   174/  187, ite: 8829] train loss: 0.109819, tar: 0.011136 
l0: 0.010522, l1: 0.010099, l2: 0.012388, l3: 0.013068, l4: 0.014673, l5: 0.017703, l6: 0.013796

[epoch:  94/100000, batch:   176/  187, ite: 8830] train loss: 0.109798, tar: 0.011135 
l0: 0.010030, l1: 0.009108, l2: 0.011313, l3: 0.014210, l4: 0.032155, l5: 0.023571, l6: 0.029724

[epoch:  94/100000, batch:   178/  187, ite: 8831] train loss: 0.109822, tar: 0.011134 
l0: 0.005331, l1: 0.006108, l2: 0.005704, l3: 0.005452, l4: 0.009741, l5: 0.009213, l6: 0.013114

[epoch:  94/100000, batch:   180/  187, ite: 8832] train loss: 0.109756, tar: 0.011127 
l0: 0.007895, l1: 0.008489, l2: 0.009614, l3: 0.008181, l4: 0.016929, l5: 0.012628, l6: 0.016929

[epoch:  94/100000, batch:   182/  187, ite: 8833] train loss: 0.109721, tar: 0.011123 
l0: 0.011759, l1: 0.011215, l2: 0.014704, l3: 0.014597, l4: 0.022113, l5: 0.019509, l6: 0.022139

[epoch:  94/100000, batch:   184/  187, ite: 8834] train loss: 0.109729, tar: 0.011123 
l0: 0.006392, l1: 0.006576, l2: 0.006829, l3: 0.006904, l4: 0.010837, l5: 0.010273, l6: 0.014393

[epoch:  94/100000, batch:   186/  187, ite: 8835] train loss: 0.109672, tar: 0.011118 
l0: 0.008636, l1: 0.008985, l2: 0.009430, l3: 0.009578, l4: 0.015178, l5: 0.013345, l6: 0.012433

[epoch:  94/100000, batch:   188/  187, ite: 8836] train loss: 0.109633, tar: 0.011115 
l0: 0.014528, l1: 0.015672, l2: 0.013032, l3: 0.011562, l4: 0.018202, l5: 0.020007, l6: 0.022535

[epoch:  95/100000, batch:     2/  187, ite: 8837] train loss: 0.109641, tar: 0.011119 
l0: 0.010698, l1: 0.012385, l2: 0.010642, l3: 0.009851, l4: 0.016853, l5: 0.017069, l6: 0.016827

[epoch:  95/100000, batch:     4/  187, ite: 8838] train loss: 0.109622, tar: 0.011118 
l0: 0.008226, l1: 0.009404, l2: 0.008311, l3: 0.008680, l4: 0.015255, l5: 0.013519, l6: 0.015180

[epoch:  95/100000, batch:     6/  187, ite: 8839] train loss: 0.109585, tar: 0.011115 
l0: 0.006683, l1: 0.007010, l2: 0.010556, l3: 0.009459, l4: 0.025609, l5: 0.020821, l6: 0.020957

[epoch:  95/100000, batch:     8/  187, ite: 8840] train loss: 0.109575, tar: 0.011110 
l0: 0.015690, l1: 0.014524, l2: 0.013624, l3: 0.015897, l4: 0.025713, l5: 0.023811, l6: 0.030874

[epoch:  95/100000, batch:    10/  187, ite: 8841] train loss: 0.109611, tar: 0.011115 
l0: 0.005918, l1: 0.006177, l2: 0.005767, l3: 0.005809, l4: 0.010306, l5: 0.009322, l6: 0.010775

[epoch:  95/100000, batch:    12/  187, ite: 8842] train loss: 0.109545, tar: 0.011109 
l0: 0.011988, l1: 0.013100, l2: 0.011421, l3: 0.012975, l4: 0.013381, l5: 0.012214, l6: 0.011845

[epoch:  95/100000, batch:    14/  187, ite: 8843] train loss: 0.109519, tar: 0.011110 
l0: 0.010959, l1: 0.010710, l2: 0.012436, l3: 0.013415, l4: 0.024589, l5: 0.021659, l6: 0.020912

[epoch:  95/100000, batch:    16/  187, ite: 8844] train loss: 0.109525, tar: 0.011110 
l0: 0.010475, l1: 0.009992, l2: 0.009165, l3: 0.008093, l4: 0.013141, l5: 0.015717, l6: 0.015160

[epoch:  95/100000, batch:    18/  187, ite: 8845] train loss: 0.109492, tar: 0.011109 
l0: 0.010959, l1: 0.010859, l2: 0.012121, l3: 0.010411, l4: 0.019805, l5: 0.017900, l6: 0.018401

[epoch:  95/100000, batch:    20/  187, ite: 8846] train loss: 0.109481, tar: 0.011109 
l0: 0.010043, l1: 0.009835, l2: 0.012444, l3: 0.012285, l4: 0.018495, l5: 0.018932, l6: 0.020360

[epoch:  95/100000, batch:    22/  187, ite: 8847] train loss: 0.109473, tar: 0.011108 
l0: 0.007756, l1: 0.008065, l2: 0.008673, l3: 0.009095, l4: 0.011982, l5: 0.012618, l6: 0.013040

[epoch:  95/100000, batch:    24/  187, ite: 8848] train loss: 0.109428, tar: 0.011104 
l0: 0.014488, l1: 0.015660, l2: 0.014040, l3: 0.015595, l4: 0.021491, l5: 0.020748, l6: 0.024917

[epoch:  95/100000, batch:    26/  187, ite: 8849] train loss: 0.109448, tar: 0.011108 
l0: 0.009535, l1: 0.008249, l2: 0.015604, l3: 0.016570, l4: 0.016057, l5: 0.018439, l6: 0.015284

[epoch:  95/100000, batch:    28/  187, ite: 8850] train loss: 0.109437, tar: 0.011106 
l0: 0.007403, l1: 0.007316, l2: 0.007700, l3: 0.008086, l4: 0.014653, l5: 0.016259, l6: 0.015065

[epoch:  95/100000, batch:    30/  187, ite: 8851] train loss: 0.109398, tar: 0.011101 
l0: 0.008377, l1: 0.008955, l2: 0.008987, l3: 0.010433, l4: 0.008676, l5: 0.010278, l6: 0.008754

[epoch:  95/100000, batch:    32/  187, ite: 8852] train loss: 0.109345, tar: 0.011098 
l0: 0.004723, l1: 0.004883, l2: 0.006132, l3: 0.004569, l4: 0.010979, l5: 0.009609, l6: 0.006858

[epoch:  95/100000, batch:    34/  187, ite: 8853] train loss: 0.109273, tar: 0.011091 
l0: 0.009745, l1: 0.010703, l2: 0.011003, l3: 0.011268, l4: 0.024219, l5: 0.023112, l6: 0.015821

[epoch:  95/100000, batch:    36/  187, ite: 8854] train loss: 0.109269, tar: 0.011089 
l0: 0.007924, l1: 0.008403, l2: 0.009594, l3: 0.011231, l4: 0.020458, l5: 0.014782, l6: 0.015674

[epoch:  95/100000, batch:    38/  187, ite: 8855] train loss: 0.109244, tar: 0.011085 
l0: 0.009030, l1: 0.009094, l2: 0.008542, l3: 0.006947, l4: 0.009808, l5: 0.013522, l6: 0.012943

[epoch:  95/100000, batch:    40/  187, ite: 8856] train loss: 0.109199, tar: 0.011083 
l0: 0.006558, l1: 0.006927, l2: 0.006723, l3: 0.006968, l4: 0.009667, l5: 0.010131, l6: 0.011562

[epoch:  95/100000, batch:    42/  187, ite: 8857] train loss: 0.109139, tar: 0.011078 
l0: 0.007865, l1: 0.008000, l2: 0.009015, l3: 0.010105, l4: 0.020226, l5: 0.017358, l6: 0.015216

[epoch:  95/100000, batch:    44/  187, ite: 8858] train loss: 0.109115, tar: 0.011074 
l0: 0.017533, l1: 0.017760, l2: 0.018755, l3: 0.019407, l4: 0.019422, l5: 0.013868, l6: 0.017910

[epoch:  95/100000, batch:    46/  187, ite: 8859] train loss: 0.109133, tar: 0.011082 
l0: 0.011784, l1: 0.012973, l2: 0.012544, l3: 0.010796, l4: 0.014873, l5: 0.013319, l6: 0.015613

[epoch:  95/100000, batch:    48/  187, ite: 8860] train loss: 0.109113, tar: 0.011082 
l0: 0.012503, l1: 0.012248, l2: 0.011756, l3: 0.013538, l4: 0.019460, l5: 0.019296, l6: 0.017261

[epoch:  95/100000, batch:    50/  187, ite: 8861] train loss: 0.109109, tar: 0.011084 
l0: 0.007049, l1: 0.006748, l2: 0.007883, l3: 0.008205, l4: 0.020234, l5: 0.020276, l6: 0.019312

[epoch:  95/100000, batch:    52/  187, ite: 8862] train loss: 0.109087, tar: 0.011079 
l0: 0.005661, l1: 0.005339, l2: 0.006666, l3: 0.010408, l4: 0.032474, l5: 0.032214, l6: 0.039502

[epoch:  95/100000, batch:    54/  187, ite: 8863] train loss: 0.109113, tar: 0.011073 
l0: 0.010920, l1: 0.010948, l2: 0.012117, l3: 0.012089, l4: 0.019775, l5: 0.018677, l6: 0.024640

[epoch:  95/100000, batch:    56/  187, ite: 8864] train loss: 0.109113, tar: 0.011073 
l0: 0.018320, l1: 0.018664, l2: 0.017276, l3: 0.017053, l4: 0.017310, l5: 0.020126, l6: 0.021837

[epoch:  95/100000, batch:    58/  187, ite: 8865] train loss: 0.109138, tar: 0.011081 
l0: 0.011596, l1: 0.011666, l2: 0.014615, l3: 0.012891, l4: 0.019767, l5: 0.018501, l6: 0.019542

[epoch:  95/100000, batch:    60/  187, ite: 8866] train loss: 0.109138, tar: 0.011082 
l0: 0.009446, l1: 0.009171, l2: 0.010725, l3: 0.011302, l4: 0.015019, l5: 0.014764, l6: 0.020973

[epoch:  95/100000, batch:    62/  187, ite: 8867] train loss: 0.109117, tar: 0.011080 
l0: 0.006237, l1: 0.006623, l2: 0.008356, l3: 0.007031, l4: 0.009458, l5: 0.010243, l6: 0.009580

[epoch:  95/100000, batch:    64/  187, ite: 8868] train loss: 0.109058, tar: 0.011074 
l0: 0.011016, l1: 0.009835, l2: 0.011893, l3: 0.015288, l4: 0.015273, l5: 0.016183, l6: 0.023751

[epoch:  95/100000, batch:    66/  187, ite: 8869] train loss: 0.109051, tar: 0.011074 
l0: 0.008643, l1: 0.009354, l2: 0.011101, l3: 0.012872, l4: 0.015770, l5: 0.013293, l6: 0.011767

[epoch:  95/100000, batch:    68/  187, ite: 8870] train loss: 0.109021, tar: 0.011072 
l0: 0.006593, l1: 0.006514, l2: 0.008418, l3: 0.008564, l4: 0.012337, l5: 0.010264, l6: 0.012704

[epoch:  95/100000, batch:    70/  187, ite: 8871] train loss: 0.108971, tar: 0.011066 
l0: 0.011226, l1: 0.010899, l2: 0.012689, l3: 0.013210, l4: 0.018677, l5: 0.018954, l6: 0.022240

[epoch:  95/100000, batch:    72/  187, ite: 8872] train loss: 0.108970, tar: 0.011067 
l0: 0.004811, l1: 0.005381, l2: 0.006191, l3: 0.005762, l4: 0.007562, l5: 0.007483, l6: 0.007224

[epoch:  95/100000, batch:    74/  187, ite: 8873] train loss: 0.108896, tar: 0.011059 
l0: 0.010400, l1: 0.010587, l2: 0.012492, l3: 0.012326, l4: 0.014372, l5: 0.015075, l6: 0.016942

[epoch:  95/100000, batch:    76/  187, ite: 8874] train loss: 0.108876, tar: 0.011059 
l0: 0.013268, l1: 0.013219, l2: 0.011074, l3: 0.012718, l4: 0.020512, l5: 0.021187, l6: 0.022790

[epoch:  95/100000, batch:    78/  187, ite: 8875] train loss: 0.108883, tar: 0.011061 
l0: 0.012607, l1: 0.012550, l2: 0.014211, l3: 0.014626, l4: 0.020944, l5: 0.023885, l6: 0.026421

[epoch:  95/100000, batch:    80/  187, ite: 8876] train loss: 0.108902, tar: 0.011063 
l0: 0.008810, l1: 0.010134, l2: 0.010442, l3: 0.011630, l4: 0.018461, l5: 0.017195, l6: 0.019825

[epoch:  95/100000, batch:    82/  187, ite: 8877] train loss: 0.108888, tar: 0.011060 
l0: 0.011126, l1: 0.011418, l2: 0.011867, l3: 0.012133, l4: 0.014178, l5: 0.016474, l6: 0.020134

[epoch:  95/100000, batch:    84/  187, ite: 8878] train loss: 0.108875, tar: 0.011060 
l0: 0.007418, l1: 0.007427, l2: 0.007853, l3: 0.008442, l4: 0.015833, l5: 0.015319, l6: 0.013544

[epoch:  95/100000, batch:    86/  187, ite: 8879] train loss: 0.108837, tar: 0.011056 
l0: 0.012646, l1: 0.012365, l2: 0.013397, l3: 0.013119, l4: 0.031639, l5: 0.033061, l6: 0.033173

[epoch:  95/100000, batch:    88/  187, ite: 8880] train loss: 0.108883, tar: 0.011058 
l0: 0.012108, l1: 0.012585, l2: 0.014432, l3: 0.013639, l4: 0.017085, l5: 0.014802, l6: 0.020663

[epoch:  95/100000, batch:    90/  187, ite: 8881] train loss: 0.108879, tar: 0.011059 
l0: 0.007330, l1: 0.007535, l2: 0.007115, l3: 0.007877, l4: 0.014296, l5: 0.019110, l6: 0.022347

[epoch:  95/100000, batch:    92/  187, ite: 8882] train loss: 0.108853, tar: 0.011055 
l0: 0.017229, l1: 0.015883, l2: 0.023837, l3: 0.025220, l4: 0.029469, l5: 0.027337, l6: 0.029863

[epoch:  95/100000, batch:    94/  187, ite: 8883] train loss: 0.108921, tar: 0.011062 
l0: 0.012902, l1: 0.012452, l2: 0.014384, l3: 0.013899, l4: 0.015077, l5: 0.021118, l6: 0.018102

[epoch:  95/100000, batch:    96/  187, ite: 8884] train loss: 0.108919, tar: 0.011064 
l0: 0.007582, l1: 0.007726, l2: 0.008067, l3: 0.008627, l4: 0.014518, l5: 0.012974, l6: 0.014127

[epoch:  95/100000, batch:    98/  187, ite: 8885] train loss: 0.108880, tar: 0.011060 
l0: 0.013520, l1: 0.013578, l2: 0.013877, l3: 0.014587, l4: 0.017129, l5: 0.015858, l6: 0.019549

[epoch:  95/100000, batch:   100/  187, ite: 8886] train loss: 0.108879, tar: 0.011063 
l0: 0.010211, l1: 0.010363, l2: 0.010493, l3: 0.010442, l4: 0.013231, l5: 0.011625, l6: 0.015811

[epoch:  95/100000, batch:   102/  187, ite: 8887] train loss: 0.108849, tar: 0.011062 
l0: 0.010718, l1: 0.011981, l2: 0.010966, l3: 0.010094, l4: 0.015620, l5: 0.013761, l6: 0.015070

[epoch:  95/100000, batch:   104/  187, ite: 8888] train loss: 0.108825, tar: 0.011062 
l0: 0.012250, l1: 0.013052, l2: 0.013681, l3: 0.012965, l4: 0.025459, l5: 0.026487, l6: 0.023427

[epoch:  95/100000, batch:   106/  187, ite: 8889] train loss: 0.108846, tar: 0.011063 
l0: 0.004536, l1: 0.004724, l2: 0.005210, l3: 0.005284, l4: 0.013186, l5: 0.011559, l6: 0.013167

[epoch:  95/100000, batch:   108/  187, ite: 8890] train loss: 0.108789, tar: 0.011056 
l0: 0.007710, l1: 0.007737, l2: 0.008303, l3: 0.008867, l4: 0.018852, l5: 0.018357, l6: 0.018987

[epoch:  95/100000, batch:   110/  187, ite: 8891] train loss: 0.108766, tar: 0.011052 
l0: 0.006168, l1: 0.006589, l2: 0.006311, l3: 0.007411, l4: 0.015010, l5: 0.012821, l6: 0.011550

[epoch:  95/100000, batch:   112/  187, ite: 8892] train loss: 0.108718, tar: 0.011046 
l0: 0.007546, l1: 0.007863, l2: 0.008107, l3: 0.008227, l4: 0.015130, l5: 0.014992, l6: 0.018526

[epoch:  95/100000, batch:   114/  187, ite: 8893] train loss: 0.108686, tar: 0.011043 
l0: 0.007689, l1: 0.008051, l2: 0.008739, l3: 0.014878, l4: 0.022928, l5: 0.015398, l6: 0.013781

[epoch:  95/100000, batch:   116/  187, ite: 8894] train loss: 0.108667, tar: 0.011039 
l0: 0.009536, l1: 0.009412, l2: 0.009901, l3: 0.009949, l4: 0.015587, l5: 0.018523, l6: 0.020920

[epoch:  95/100000, batch:   118/  187, ite: 8895] train loss: 0.108651, tar: 0.011037 
l0: 0.007269, l1: 0.008131, l2: 0.008166, l3: 0.010784, l4: 0.027638, l5: 0.021601, l6: 0.023952

[epoch:  95/100000, batch:   120/  187, ite: 8896] train loss: 0.108649, tar: 0.011033 
l0: 0.008550, l1: 0.008561, l2: 0.010463, l3: 0.012209, l4: 0.013238, l5: 0.010418, l6: 0.015691

[epoch:  95/100000, batch:   122/  187, ite: 8897] train loss: 0.108616, tar: 0.011030 
l0: 0.010362, l1: 0.009368, l2: 0.011314, l3: 0.011225, l4: 0.028353, l5: 0.033303, l6: 0.028670

[epoch:  95/100000, batch:   124/  187, ite: 8898] train loss: 0.108643, tar: 0.011029 
l0: 0.016259, l1: 0.015908, l2: 0.018504, l3: 0.021047, l4: 0.029512, l5: 0.023059, l6: 0.027057

[epoch:  95/100000, batch:   126/  187, ite: 8899] train loss: 0.108691, tar: 0.011035 
l0: 0.004068, l1: 0.003829, l2: 0.003518, l3: 0.004924, l4: 0.010708, l5: 0.010057, l6: 0.010326

[epoch:  95/100000, batch:   128/  187, ite: 8900] train loss: 0.108623, tar: 0.011027 
l0: 0.008901, l1: 0.009330, l2: 0.007771, l3: 0.009990, l4: 0.014125, l5: 0.014184, l6: 0.015356

[epoch:  95/100000, batch:   130/  187, ite: 8901] train loss: 0.108590, tar: 0.011025 
l0: 0.016387, l1: 0.015988, l2: 0.017730, l3: 0.022761, l4: 0.028494, l5: 0.022441, l6: 0.024920

[epoch:  95/100000, batch:   132/  187, ite: 8902] train loss: 0.108635, tar: 0.011031 
l0: 0.008552, l1: 0.008100, l2: 0.008690, l3: 0.008425, l4: 0.015608, l5: 0.018145, l6: 0.019810

[epoch:  95/100000, batch:   134/  187, ite: 8903] train loss: 0.108611, tar: 0.011028 
l0: 0.008971, l1: 0.009243, l2: 0.008842, l3: 0.010806, l4: 0.018604, l5: 0.016089, l6: 0.016742

[epoch:  95/100000, batch:   136/  187, ite: 8904] train loss: 0.108590, tar: 0.011026 
l0: 0.009110, l1: 0.009927, l2: 0.009293, l3: 0.009257, l4: 0.012205, l5: 0.013104, l6: 0.014217

[epoch:  95/100000, batch:   138/  187, ite: 8905] train loss: 0.108555, tar: 0.011024 
l0: 0.006346, l1: 0.006086, l2: 0.006597, l3: 0.007193, l4: 0.016641, l5: 0.015510, l6: 0.016309

[epoch:  95/100000, batch:   140/  187, ite: 8906] train loss: 0.108518, tar: 0.011019 
l0: 0.010787, l1: 0.011334, l2: 0.011815, l3: 0.010723, l4: 0.014445, l5: 0.014042, l6: 0.017651

[epoch:  95/100000, batch:   142/  187, ite: 8907] train loss: 0.108498, tar: 0.011018 
l0: 0.009842, l1: 0.010966, l2: 0.010253, l3: 0.011290, l4: 0.016582, l5: 0.012537, l6: 0.015987

[epoch:  95/100000, batch:   144/  187, ite: 8908] train loss: 0.108475, tar: 0.011017 
l0: 0.013199, l1: 0.012462, l2: 0.014146, l3: 0.014267, l4: 0.021364, l5: 0.022184, l6: 0.031246

[epoch:  95/100000, batch:   146/  187, ite: 8909] train loss: 0.108497, tar: 0.011020 
l0: 0.008617, l1: 0.008061, l2: 0.015355, l3: 0.013795, l4: 0.023290, l5: 0.020595, l6: 0.024996

[epoch:  95/100000, batch:   148/  187, ite: 8910] train loss: 0.108504, tar: 0.011017 
l0: 0.008167, l1: 0.008128, l2: 0.007352, l3: 0.007199, l4: 0.013361, l5: 0.011985, l6: 0.014779

[epoch:  95/100000, batch:   150/  187, ite: 8911] train loss: 0.108463, tar: 0.011014 
l0: 0.012671, l1: 0.012703, l2: 0.015414, l3: 0.015210, l4: 0.023198, l5: 0.017364, l6: 0.020803

[epoch:  95/100000, batch:   152/  187, ite: 8912] train loss: 0.108473, tar: 0.011016 
l0: 0.007222, l1: 0.009635, l2: 0.006075, l3: 0.004504, l4: 0.007894, l5: 0.006414, l6: 0.005332

[epoch:  95/100000, batch:   154/  187, ite: 8913] train loss: 0.108406, tar: 0.011011 
l0: 0.005045, l1: 0.005021, l2: 0.006413, l3: 0.008205, l4: 0.022344, l5: 0.017408, l6: 0.014048

[epoch:  95/100000, batch:   156/  187, ite: 8914] train loss: 0.108373, tar: 0.011005 
l0: 0.011281, l1: 0.010599, l2: 0.012614, l3: 0.014405, l4: 0.017574, l5: 0.019138, l6: 0.022301

[epoch:  95/100000, batch:   158/  187, ite: 8915] train loss: 0.108372, tar: 0.011005 
l0: 0.012858, l1: 0.011959, l2: 0.014209, l3: 0.014383, l4: 0.037757, l5: 0.036684, l6: 0.036274

[epoch:  95/100000, batch:   160/  187, ite: 8916] train loss: 0.108433, tar: 0.011007 
l0: 0.008378, l1: 0.008248, l2: 0.008025, l3: 0.008790, l4: 0.014685, l5: 0.015683, l6: 0.014278

[epoch:  95/100000, batch:   162/  187, ite: 8917] train loss: 0.108400, tar: 0.011004 
l0: 0.010490, l1: 0.012029, l2: 0.012008, l3: 0.012665, l4: 0.026087, l5: 0.025465, l6: 0.022740

[epoch:  95/100000, batch:   164/  187, ite: 8918] train loss: 0.108414, tar: 0.011004 
l0: 0.012167, l1: 0.011584, l2: 0.016728, l3: 0.014665, l4: 0.021403, l5: 0.019883, l6: 0.024768

[epoch:  95/100000, batch:   166/  187, ite: 8919] train loss: 0.108428, tar: 0.011005 
l0: 0.008938, l1: 0.009104, l2: 0.010465, l3: 0.010051, l4: 0.010861, l5: 0.012694, l6: 0.012360

[epoch:  95/100000, batch:   168/  187, ite: 8920] train loss: 0.108391, tar: 0.011003 
l0: 0.013255, l1: 0.014124, l2: 0.011001, l3: 0.012086, l4: 0.024033, l5: 0.025327, l6: 0.031456

[epoch:  95/100000, batch:   170/  187, ite: 8921] train loss: 0.108416, tar: 0.011005 
l0: 0.013823, l1: 0.014471, l2: 0.014542, l3: 0.015063, l4: 0.026992, l5: 0.022854, l6: 0.026093

[epoch:  95/100000, batch:   172/  187, ite: 8922] train loss: 0.108444, tar: 0.011008 
l0: 0.006848, l1: 0.006869, l2: 0.008605, l3: 0.008966, l4: 0.013362, l5: 0.014080, l6: 0.014040

[epoch:  95/100000, batch:   174/  187, ite: 8923] train loss: 0.108405, tar: 0.011004 
l0: 0.009201, l1: 0.008630, l2: 0.009751, l3: 0.010559, l4: 0.015655, l5: 0.017756, l6: 0.022283

[epoch:  95/100000, batch:   176/  187, ite: 8924] train loss: 0.108389, tar: 0.011002 
l0: 0.023876, l1: 0.026037, l2: 0.034734, l3: 0.021438, l4: 0.024313, l5: 0.025218, l6: 0.025050

[epoch:  95/100000, batch:   178/  187, ite: 8925] train loss: 0.108468, tar: 0.011016 
l0: 0.024737, l1: 0.022248, l2: 0.022096, l3: 0.026755, l4: 0.022449, l5: 0.027403, l6: 0.033335

[epoch:  95/100000, batch:   180/  187, ite: 8926] train loss: 0.108544, tar: 0.011031 
l0: 0.009501, l1: 0.010579, l2: 0.009727, l3: 0.009478, l4: 0.011081, l5: 0.009153, l6: 0.013171

[epoch:  95/100000, batch:   182/  187, ite: 8927] train loss: 0.108505, tar: 0.011029 
l0: 0.014535, l1: 0.014515, l2: 0.011360, l3: 0.012971, l4: 0.020828, l5: 0.024920, l6: 0.034501

[epoch:  95/100000, batch:   184/  187, ite: 8928] train loss: 0.108532, tar: 0.011033 
l0: 0.007394, l1: 0.007442, l2: 0.009311, l3: 0.009598, l4: 0.022882, l5: 0.017067, l6: 0.019746

[epoch:  95/100000, batch:   186/  187, ite: 8929] train loss: 0.108516, tar: 0.011029 
l0: 0.009414, l1: 0.010082, l2: 0.023328, l3: 0.023928, l4: 0.036718, l5: 0.025396, l6: 0.017600

[epoch:  95/100000, batch:   188/  187, ite: 8930] train loss: 0.108557, tar: 0.011027 
l0: 0.012641, l1: 0.012295, l2: 0.014386, l3: 0.015360, l4: 0.036279, l5: 0.032732, l6: 0.031846

[epoch:  96/100000, batch:     2/  187, ite: 8931] train loss: 0.108607, tar: 0.011029 
l0: 0.014015, l1: 0.013926, l2: 0.015831, l3: 0.014618, l4: 0.023031, l5: 0.022864, l6: 0.026960

[epoch:  96/100000, batch:     4/  187, ite: 8932] train loss: 0.108631, tar: 0.011032 
l0: 0.012610, l1: 0.012107, l2: 0.011808, l3: 0.013392, l4: 0.021780, l5: 0.025822, l6: 0.028266

[epoch:  96/100000, batch:     6/  187, ite: 8933] train loss: 0.108650, tar: 0.011034 
l0: 0.008158, l1: 0.008520, l2: 0.009493, l3: 0.008800, l4: 0.012401, l5: 0.009903, l6: 0.012112

[epoch:  96/100000, batch:     8/  187, ite: 8934] train loss: 0.108608, tar: 0.011031 
l0: 0.020758, l1: 0.023334, l2: 0.021439, l3: 0.020994, l4: 0.032893, l5: 0.027077, l6: 0.022835

[epoch:  96/100000, batch:    10/  187, ite: 8935] train loss: 0.108673, tar: 0.011041 
l0: 0.014081, l1: 0.014834, l2: 0.014757, l3: 0.016778, l4: 0.027940, l5: 0.028405, l6: 0.020669

[epoch:  96/100000, batch:    12/  187, ite: 8936] train loss: 0.108704, tar: 0.011044 
l0: 0.006364, l1: 0.009381, l2: 0.006991, l3: 0.008114, l4: 0.020383, l5: 0.017005, l6: 0.018689

[epoch:  96/100000, batch:    14/  187, ite: 8937] train loss: 0.108680, tar: 0.011039 
l0: 0.022137, l1: 0.021346, l2: 0.038270, l3: 0.034681, l4: 0.017738, l5: 0.015895, l6: 0.016103

[epoch:  96/100000, batch:    16/  187, ite: 8938] train loss: 0.108742, tar: 0.011051 
l0: 0.012437, l1: 0.013153, l2: 0.013228, l3: 0.012494, l4: 0.019619, l5: 0.019627, l6: 0.020614

[epoch:  96/100000, batch:    18/  187, ite: 8939] train loss: 0.108744, tar: 0.011053 
l0: 0.013918, l1: 0.015398, l2: 0.015899, l3: 0.015644, l4: 0.033231, l5: 0.032122, l6: 0.034220

[epoch:  96/100000, batch:    20/  187, ite: 8940] train loss: 0.108799, tar: 0.011056 
l0: 0.009129, l1: 0.009842, l2: 0.010729, l3: 0.011355, l4: 0.019075, l5: 0.017637, l6: 0.018954

[epoch:  96/100000, batch:    22/  187, ite: 8941] train loss: 0.108786, tar: 0.011054 
l0: 0.010639, l1: 0.010825, l2: 0.011009, l3: 0.010290, l4: 0.018303, l5: 0.022163, l6: 0.022837

[epoch:  96/100000, batch:    24/  187, ite: 8942] train loss: 0.108783, tar: 0.011053 
l0: 0.014723, l1: 0.015606, l2: 0.016063, l3: 0.017017, l4: 0.029347, l5: 0.031591, l6: 0.041481

[epoch:  96/100000, batch:    26/  187, ite: 8943] train loss: 0.108844, tar: 0.011057 
l0: 0.006989, l1: 0.007592, l2: 0.007321, l3: 0.007567, l4: 0.017323, l5: 0.016590, l6: 0.014122

[epoch:  96/100000, batch:    28/  187, ite: 8944] train loss: 0.108811, tar: 0.011053 
l0: 0.011515, l1: 0.011377, l2: 0.015621, l3: 0.015515, l4: 0.028682, l5: 0.028898, l6: 0.024608

[epoch:  96/100000, batch:    30/  187, ite: 8945] train loss: 0.108840, tar: 0.011053 
l0: 0.007810, l1: 0.008562, l2: 0.009428, l3: 0.008156, l4: 0.012599, l5: 0.013135, l6: 0.015798

[epoch:  96/100000, batch:    32/  187, ite: 8946] train loss: 0.108804, tar: 0.011050 
l0: 0.008997, l1: 0.009669, l2: 0.011011, l3: 0.008323, l4: 0.024604, l5: 0.020020, l6: 0.014382

[epoch:  96/100000, batch:    34/  187, ite: 8947] train loss: 0.108792, tar: 0.011048 
l0: 0.008747, l1: 0.010120, l2: 0.008751, l3: 0.009150, l4: 0.015387, l5: 0.013476, l6: 0.012414

[epoch:  96/100000, batch:    36/  187, ite: 8948] train loss: 0.108760, tar: 0.011045 
l0: 0.014036, l1: 0.013033, l2: 0.015230, l3: 0.017433, l4: 0.023939, l5: 0.027633, l6: 0.033376

[epoch:  96/100000, batch:    38/  187, ite: 8949] train loss: 0.108797, tar: 0.011048 
l0: 0.014966, l1: 0.016058, l2: 0.015870, l3: 0.016178, l4: 0.015271, l5: 0.012615, l6: 0.013954

[epoch:  96/100000, batch:    40/  187, ite: 8950] train loss: 0.108793, tar: 0.011053 
l0: 0.020655, l1: 0.021031, l2: 0.025091, l3: 0.025339, l4: 0.025445, l5: 0.027508, l6: 0.027948

[epoch:  96/100000, batch:    42/  187, ite: 8951] train loss: 0.108861, tar: 0.011063 
l0: 0.008636, l1: 0.009647, l2: 0.008846, l3: 0.008975, l4: 0.019712, l5: 0.017307, l6: 0.016141

[epoch:  96/100000, batch:    44/  187, ite: 8952] train loss: 0.108840, tar: 0.011060 
l0: 0.009629, l1: 0.010219, l2: 0.009390, l3: 0.010368, l4: 0.018048, l5: 0.017665, l6: 0.019747

[epoch:  96/100000, batch:    46/  187, ite: 8953] train loss: 0.108826, tar: 0.011059 
l0: 0.010377, l1: 0.010953, l2: 0.011974, l3: 0.012179, l4: 0.022005, l5: 0.016425, l6: 0.018423

[epoch:  96/100000, batch:    48/  187, ite: 8954] train loss: 0.108819, tar: 0.011058 
l0: 0.006295, l1: 0.005988, l2: 0.007233, l3: 0.007345, l4: 0.011416, l5: 0.016124, l6: 0.018528

[epoch:  96/100000, batch:    50/  187, ite: 8955] train loss: 0.108781, tar: 0.011053 
l0: 0.008202, l1: 0.008756, l2: 0.011413, l3: 0.009884, l4: 0.014315, l5: 0.012590, l6: 0.010136

[epoch:  96/100000, batch:    52/  187, ite: 8956] train loss: 0.108746, tar: 0.011050 
l0: 0.008041, l1: 0.011179, l2: 0.016703, l3: 0.008625, l4: 0.009500, l5: 0.008796, l6: 0.010021

[epoch:  96/100000, batch:    54/  187, ite: 8957] train loss: 0.108709, tar: 0.011047 
l0: 0.006966, l1: 0.007805, l2: 0.007460, l3: 0.007194, l4: 0.013562, l5: 0.011562, l6: 0.015247

[epoch:  96/100000, batch:    56/  187, ite: 8958] train loss: 0.108668, tar: 0.011042 
l0: 0.008368, l1: 0.009441, l2: 0.008972, l3: 0.008823, l4: 0.014392, l5: 0.013890, l6: 0.012950

[epoch:  96/100000, batch:    58/  187, ite: 8959] train loss: 0.108635, tar: 0.011040 
l0: 0.014223, l1: 0.016119, l2: 0.015882, l3: 0.015279, l4: 0.020746, l5: 0.022336, l6: 0.023120

[epoch:  96/100000, batch:    60/  187, ite: 8960] train loss: 0.108655, tar: 0.011043 
l0: 0.008707, l1: 0.010927, l2: 0.008278, l3: 0.008501, l4: 0.011238, l5: 0.013297, l6: 0.016992

[epoch:  96/100000, batch:    62/  187, ite: 8961] train loss: 0.108623, tar: 0.011041 
l0: 0.011495, l1: 0.011167, l2: 0.014225, l3: 0.014022, l4: 0.021660, l5: 0.023986, l6: 0.022453

[epoch:  96/100000, batch:    64/  187, ite: 8962] train loss: 0.108634, tar: 0.011041 
l0: 0.019723, l1: 0.021502, l2: 0.023725, l3: 0.019030, l4: 0.029326, l5: 0.025159, l6: 0.022709

[epoch:  96/100000, batch:    66/  187, ite: 8963] train loss: 0.108688, tar: 0.011050 
l0: 0.009879, l1: 0.010583, l2: 0.013121, l3: 0.014053, l4: 0.014069, l5: 0.014331, l6: 0.012459

[epoch:  96/100000, batch:    68/  187, ite: 8964] train loss: 0.108667, tar: 0.011049 
l0: 0.008942, l1: 0.009270, l2: 0.010607, l3: 0.009709, l4: 0.022225, l5: 0.022252, l6: 0.017275

[epoch:  96/100000, batch:    70/  187, ite: 8965] train loss: 0.108659, tar: 0.011047 
l0: 0.008464, l1: 0.009682, l2: 0.008724, l3: 0.008557, l4: 0.015829, l5: 0.012481, l6: 0.012776

[epoch:  96/100000, batch:    72/  187, ite: 8966] train loss: 0.108625, tar: 0.011044 
l0: 0.006308, l1: 0.006482, l2: 0.006898, l3: 0.006946, l4: 0.014453, l5: 0.014757, l6: 0.015852

[epoch:  96/100000, batch:    74/  187, ite: 8967] train loss: 0.108587, tar: 0.011039 
l0: 0.007791, l1: 0.008655, l2: 0.008973, l3: 0.008131, l4: 0.011119, l5: 0.007542, l6: 0.008657

[epoch:  96/100000, batch:    76/  187, ite: 8968] train loss: 0.108538, tar: 0.011036 
l0: 0.011000, l1: 0.012703, l2: 0.012851, l3: 0.012622, l4: 0.019850, l5: 0.019293, l6: 0.017635

[epoch:  96/100000, batch:    78/  187, ite: 8969] train loss: 0.108535, tar: 0.011036 
l0: 0.009138, l1: 0.009363, l2: 0.009649, l3: 0.010890, l4: 0.022791, l5: 0.019052, l6: 0.017368

[epoch:  96/100000, batch:    80/  187, ite: 8970] train loss: 0.108525, tar: 0.011034 
l0: 0.007561, l1: 0.007631, l2: 0.009163, l3: 0.009237, l4: 0.014612, l5: 0.012481, l6: 0.012529

[epoch:  96/100000, batch:    82/  187, ite: 8971] train loss: 0.108488, tar: 0.011030 
l0: 0.012575, l1: 0.013027, l2: 0.013495, l3: 0.012921, l4: 0.017723, l5: 0.018249, l6: 0.017921

[epoch:  96/100000, batch:    84/  187, ite: 8972] train loss: 0.108486, tar: 0.011032 
l0: 0.012732, l1: 0.012193, l2: 0.015435, l3: 0.014398, l4: 0.016528, l5: 0.014513, l6: 0.019830

[epoch:  96/100000, batch:    86/  187, ite: 8973] train loss: 0.108483, tar: 0.011033 
l0: 0.011074, l1: 0.012895, l2: 0.009612, l3: 0.010169, l4: 0.026050, l5: 0.018574, l6: 0.017298

[epoch:  96/100000, batch:    88/  187, ite: 8974] train loss: 0.108480, tar: 0.011034 
l0: 0.016999, l1: 0.015843, l2: 0.022423, l3: 0.020052, l4: 0.012620, l5: 0.018926, l6: 0.022286

[epoch:  96/100000, batch:    90/  187, ite: 8975] train loss: 0.108501, tar: 0.011040 
l0: 0.013911, l1: 0.011226, l2: 0.020506, l3: 0.025178, l4: 0.011623, l5: 0.016632, l6: 0.024117

[epoch:  96/100000, batch:    92/  187, ite: 8976] train loss: 0.108516, tar: 0.011043 
l0: 0.004584, l1: 0.005048, l2: 0.006209, l3: 0.005443, l4: 0.015511, l5: 0.010856, l6: 0.007721

[epoch:  96/100000, batch:    94/  187, ite: 8977] train loss: 0.108462, tar: 0.011036 
l0: 0.011635, l1: 0.012172, l2: 0.015141, l3: 0.012954, l4: 0.014445, l5: 0.015045, l6: 0.016878

[epoch:  96/100000, batch:    96/  187, ite: 8978] train loss: 0.108451, tar: 0.011037 
l0: 0.010479, l1: 0.012261, l2: 0.008173, l3: 0.007898, l4: 0.012885, l5: 0.011584, l6: 0.020007

[epoch:  96/100000, batch:    98/  187, ite: 8979] train loss: 0.108426, tar: 0.011036 
l0: 0.012974, l1: 0.014858, l2: 0.016410, l3: 0.013068, l4: 0.024086, l5: 0.023732, l6: 0.020792

[epoch:  96/100000, batch:   100/  187, ite: 8980] train loss: 0.108443, tar: 0.011038 
l0: 0.007271, l1: 0.008020, l2: 0.009693, l3: 0.009154, l4: 0.011040, l5: 0.010868, l6: 0.014999

[epoch:  96/100000, batch:   102/  187, ite: 8981] train loss: 0.108405, tar: 0.011034 
l0: 0.006546, l1: 0.007242, l2: 0.007544, l3: 0.007176, l4: 0.009202, l5: 0.012149, l6: 0.010871

[epoch:  96/100000, batch:   104/  187, ite: 8982] train loss: 0.108357, tar: 0.011030 
l0: 0.010553, l1: 0.011491, l2: 0.011177, l3: 0.012729, l4: 0.010896, l5: 0.009521, l6: 0.010852

[epoch:  96/100000, batch:   106/  187, ite: 8983] train loss: 0.108325, tar: 0.011029 
l0: 0.006586, l1: 0.006811, l2: 0.007188, l3: 0.007194, l4: 0.016252, l5: 0.016454, l6: 0.021181

[epoch:  96/100000, batch:   108/  187, ite: 8984] train loss: 0.108298, tar: 0.011025 
l0: 0.014069, l1: 0.014190, l2: 0.012592, l3: 0.015362, l4: 0.024967, l5: 0.022452, l6: 0.023696

[epoch:  96/100000, batch:   110/  187, ite: 8985] train loss: 0.108317, tar: 0.011028 
l0: 0.008509, l1: 0.008593, l2: 0.009844, l3: 0.010061, l4: 0.019398, l5: 0.016900, l6: 0.025015

[epoch:  96/100000, batch:   112/  187, ite: 8986] train loss: 0.108307, tar: 0.011025 
l0: 0.005620, l1: 0.005839, l2: 0.006496, l3: 0.006232, l4: 0.012629, l5: 0.011781, l6: 0.012600

[epoch:  96/100000, batch:   114/  187, ite: 8987] train loss: 0.108259, tar: 0.011020 
l0: 0.014406, l1: 0.013932, l2: 0.015785, l3: 0.016011, l4: 0.029268, l5: 0.035064, l6: 0.030464

[epoch:  96/100000, batch:   116/  187, ite: 8988] train loss: 0.108307, tar: 0.011023 
l0: 0.011195, l1: 0.010853, l2: 0.016539, l3: 0.018392, l4: 0.026736, l5: 0.025918, l6: 0.015449

[epoch:  96/100000, batch:   118/  187, ite: 8989] train loss: 0.108324, tar: 0.011023 
l0: 0.011873, l1: 0.012677, l2: 0.013238, l3: 0.013138, l4: 0.018148, l5: 0.016152, l6: 0.014899

[epoch:  96/100000, batch:   120/  187, ite: 8990] train loss: 0.108315, tar: 0.011024 
l0: 0.012244, l1: 0.012783, l2: 0.013197, l3: 0.013297, l4: 0.017012, l5: 0.018012, l6: 0.017676

[epoch:  96/100000, batch:   122/  187, ite: 8991] train loss: 0.108311, tar: 0.011025 
l0: 0.014333, l1: 0.015676, l2: 0.012134, l3: 0.011337, l4: 0.021859, l5: 0.022239, l6: 0.022862

[epoch:  96/100000, batch:   124/  187, ite: 8992] train loss: 0.108323, tar: 0.011029 
l0: 0.011782, l1: 0.011084, l2: 0.023045, l3: 0.020094, l4: 0.020632, l5: 0.016554, l6: 0.014832

[epoch:  96/100000, batch:   126/  187, ite: 8993] train loss: 0.108333, tar: 0.011029 
l0: 0.029335, l1: 0.030359, l2: 0.034959, l3: 0.038680, l4: 0.085135, l5: 0.069615, l6: 0.070945

[epoch:  96/100000, batch:   128/  187, ite: 8994] train loss: 0.108585, tar: 0.011048 
l0: 0.009964, l1: 0.010270, l2: 0.011259, l3: 0.010817, l4: 0.012565, l5: 0.014493, l6: 0.014533

[epoch:  96/100000, batch:   130/  187, ite: 8995] train loss: 0.108561, tar: 0.011047 
l0: 0.009441, l1: 0.009258, l2: 0.008114, l3: 0.007822, l4: 0.018677, l5: 0.023979, l6: 0.035585

[epoch:  96/100000, batch:   132/  187, ite: 8996] train loss: 0.108565, tar: 0.011045 
l0: 0.008500, l1: 0.009033, l2: 0.009216, l3: 0.011035, l4: 0.016188, l5: 0.016017, l6: 0.015484

[epoch:  96/100000, batch:   134/  187, ite: 8997] train loss: 0.108542, tar: 0.011043 
l0: 0.007858, l1: 0.008927, l2: 0.008743, l3: 0.009530, l4: 0.015743, l5: 0.013961, l6: 0.011729

[epoch:  96/100000, batch:   136/  187, ite: 8998] train loss: 0.108510, tar: 0.011039 
l0: 0.024335, l1: 0.023012, l2: 0.029506, l3: 0.035240, l4: 0.035707, l5: 0.033131, l6: 0.036339

[epoch:  96/100000, batch:   138/  187, ite: 8999] train loss: 0.108619, tar: 0.011053 
l0: 0.009462, l1: 0.009391, l2: 0.011146, l3: 0.011569, l4: 0.031902, l5: 0.026564, l6: 0.022218

[epoch:  96/100000, batch:   140/  187, ite: 9000] train loss: 0.108632, tar: 0.011051 
l0: 0.012704, l1: 0.011584, l2: 0.016046, l3: 0.019597, l4: 0.051534, l5: 0.038271, l6: 0.034267

[epoch:  96/100000, batch:   142/  187, ite: 9001] train loss: 0.108707, tar: 0.011053 
l0: 0.011939, l1: 0.012744, l2: 0.014625, l3: 0.013285, l4: 0.021065, l5: 0.016610, l6: 0.016569

[epoch:  96/100000, batch:   144/  187, ite: 9002] train loss: 0.108706, tar: 0.011054 
l0: 0.012703, l1: 0.011927, l2: 0.012685, l3: 0.015449, l4: 0.038227, l5: 0.032378, l6: 0.030453

[epoch:  96/100000, batch:   146/  187, ite: 9003] train loss: 0.108751, tar: 0.011055 
l0: 0.009133, l1: 0.008804, l2: 0.008402, l3: 0.009761, l4: 0.022215, l5: 0.019625, l6: 0.025097

[epoch:  96/100000, batch:   148/  187, ite: 9004] train loss: 0.108745, tar: 0.011053 
l0: 0.007664, l1: 0.007797, l2: 0.009002, l3: 0.008418, l4: 0.011541, l5: 0.011929, l6: 0.010455

[epoch:  96/100000, batch:   150/  187, ite: 9005] train loss: 0.108703, tar: 0.011050 
l0: 0.016488, l1: 0.016733, l2: 0.020714, l3: 0.019603, l4: 0.028116, l5: 0.032027, l6: 0.018544

[epoch:  96/100000, batch:   152/  187, ite: 9006] train loss: 0.108746, tar: 0.011055 
l0: 0.021593, l1: 0.018676, l2: 0.025666, l3: 0.030581, l4: 0.050120, l5: 0.055342, l6: 0.054064

[epoch:  96/100000, batch:   154/  187, ite: 9007] train loss: 0.108893, tar: 0.011066 
l0: 0.025726, l1: 0.024195, l2: 0.023618, l3: 0.025279, l4: 0.052058, l5: 0.048777, l6: 0.050690

[epoch:  96/100000, batch:   156/  187, ite: 9008] train loss: 0.109033, tar: 0.011080 
l0: 0.009665, l1: 0.010558, l2: 0.010280, l3: 0.010919, l4: 0.015512, l5: 0.018596, l6: 0.016058

[epoch:  96/100000, batch:   158/  187, ite: 9009] train loss: 0.109016, tar: 0.011079 
l0: 0.010781, l1: 0.010063, l2: 0.008654, l3: 0.008267, l4: 0.021613, l5: 0.024390, l6: 0.030194

[epoch:  96/100000, batch:   160/  187, ite: 9010] train loss: 0.109021, tar: 0.011079 
l0: 0.008390, l1: 0.008336, l2: 0.008303, l3: 0.008601, l4: 0.016142, l5: 0.017373, l6: 0.016265

[epoch:  96/100000, batch:   162/  187, ite: 9011] train loss: 0.108995, tar: 0.011076 
l0: 0.016528, l1: 0.014877, l2: 0.014643, l3: 0.018208, l4: 0.038713, l5: 0.042040, l6: 0.062282

[epoch:  96/100000, batch:   164/  187, ite: 9012] train loss: 0.109092, tar: 0.011081 
l0: 0.014120, l1: 0.014325, l2: 0.014908, l3: 0.014897, l4: 0.031848, l5: 0.033517, l6: 0.033619

[epoch:  96/100000, batch:   166/  187, ite: 9013] train loss: 0.109140, tar: 0.011084 
l0: 0.010237, l1: 0.010779, l2: 0.011407, l3: 0.010357, l4: 0.029702, l5: 0.034250, l6: 0.035706

[epoch:  96/100000, batch:   168/  187, ite: 9014] train loss: 0.109173, tar: 0.011084 
l0: 0.008117, l1: 0.008212, l2: 0.010671, l3: 0.010613, l4: 0.022461, l5: 0.018071, l6: 0.025715

[epoch:  96/100000, batch:   170/  187, ite: 9015] train loss: 0.109168, tar: 0.011081 
l0: 0.013302, l1: 0.013441, l2: 0.014893, l3: 0.015877, l4: 0.022416, l5: 0.019055, l6: 0.025420

[epoch:  96/100000, batch:   172/  187, ite: 9016] train loss: 0.109183, tar: 0.011083 
l0: 0.011832, l1: 0.012541, l2: 0.012289, l3: 0.013961, l4: 0.025148, l5: 0.027087, l6: 0.029029

[epoch:  96/100000, batch:   174/  187, ite: 9017] train loss: 0.109205, tar: 0.011084 
l0: 0.018925, l1: 0.018418, l2: 0.021049, l3: 0.022083, l4: 0.026728, l5: 0.027550, l6: 0.025849

[epoch:  96/100000, batch:   176/  187, ite: 9018] train loss: 0.109255, tar: 0.011091 
l0: 0.011747, l1: 0.011373, l2: 0.012416, l3: 0.013774, l4: 0.036446, l5: 0.038793, l6: 0.031723

[epoch:  96/100000, batch:   178/  187, ite: 9019] train loss: 0.109302, tar: 0.011092 
l0: 0.008996, l1: 0.008652, l2: 0.012936, l3: 0.014419, l4: 0.015936, l5: 0.014348, l6: 0.015311

[epoch:  96/100000, batch:   180/  187, ite: 9020] train loss: 0.109283, tar: 0.011090 
l0: 0.017516, l1: 0.019572, l2: 0.017484, l3: 0.018413, l4: 0.027937, l5: 0.022834, l6: 0.029995

[epoch:  96/100000, batch:   182/  187, ite: 9021] train loss: 0.109327, tar: 0.011096 
l0: 0.010561, l1: 0.010577, l2: 0.013254, l3: 0.013283, l4: 0.024840, l5: 0.027708, l6: 0.020642

[epoch:  96/100000, batch:   184/  187, ite: 9022] train loss: 0.109338, tar: 0.011096 
l0: 0.014146, l1: 0.014821, l2: 0.015328, l3: 0.015177, l4: 0.036779, l5: 0.037388, l6: 0.037800

[epoch:  96/100000, batch:   186/  187, ite: 9023] train loss: 0.109399, tar: 0.011099 
l0: 0.009661, l1: 0.010865, l2: 0.019925, l3: 0.015573, l4: 0.025713, l5: 0.024492, l6: 0.021934

[epoch:  96/100000, batch:   188/  187, ite: 9024] train loss: 0.109417, tar: 0.011097 
l0: 0.012130, l1: 0.010662, l2: 0.013320, l3: 0.016440, l4: 0.032663, l5: 0.032409, l6: 0.034041

[epoch:  97/100000, batch:     2/  187, ite: 9025] train loss: 0.109458, tar: 0.011098 
l0: 0.022119, l1: 0.022244, l2: 0.022600, l3: 0.021884, l4: 0.039825, l5: 0.040025, l6: 0.042308

[epoch:  97/100000, batch:     4/  187, ite: 9026] train loss: 0.109557, tar: 0.011109 
l0: 0.009168, l1: 0.008368, l2: 0.008478, l3: 0.008938, l4: 0.027711, l5: 0.033089, l6: 0.042460

[epoch:  97/100000, batch:     6/  187, ite: 9027] train loss: 0.109585, tar: 0.011107 
l0: 0.013149, l1: 0.013586, l2: 0.012737, l3: 0.014239, l4: 0.022623, l5: 0.027290, l6: 0.027442

[epoch:  97/100000, batch:     8/  187, ite: 9028] train loss: 0.109606, tar: 0.011109 
l0: 0.009672, l1: 0.009475, l2: 0.016012, l3: 0.015331, l4: 0.019729, l5: 0.018874, l6: 0.017234

[epoch:  97/100000, batch:    10/  187, ite: 9029] train loss: 0.109603, tar: 0.011108 
l0: 0.011910, l1: 0.010527, l2: 0.015004, l3: 0.017574, l4: 0.025668, l5: 0.028438, l6: 0.032809

[epoch:  97/100000, batch:    12/  187, ite: 9030] train loss: 0.109634, tar: 0.011108 
l0: 0.015598, l1: 0.015745, l2: 0.017265, l3: 0.018290, l4: 0.020583, l5: 0.019115, l6: 0.018969

[epoch:  97/100000, batch:    14/  187, ite: 9031] train loss: 0.109650, tar: 0.011113 
l0: 0.009375, l1: 0.008981, l2: 0.012921, l3: 0.012832, l4: 0.022466, l5: 0.021992, l6: 0.021628

[epoch:  97/100000, batch:    16/  187, ite: 9032] train loss: 0.109650, tar: 0.011111 
l0: 0.007523, l1: 0.007663, l2: 0.008141, l3: 0.010140, l4: 0.019004, l5: 0.020424, l6: 0.018074

[epoch:  97/100000, batch:    18/  187, ite: 9033] train loss: 0.109632, tar: 0.011108 
l0: 0.014528, l1: 0.013405, l2: 0.020837, l3: 0.024282, l4: 0.027726, l5: 0.029811, l6: 0.039690

[epoch:  97/100000, batch:    20/  187, ite: 9034] train loss: 0.109691, tar: 0.011111 
l0: 0.012533, l1: 0.012462, l2: 0.014796, l3: 0.015871, l4: 0.018038, l5: 0.017913, l6: 0.019286

[epoch:  97/100000, batch:    22/  187, ite: 9035] train loss: 0.109692, tar: 0.011112 
l0: 0.011748, l1: 0.011433, l2: 0.012627, l3: 0.011519, l4: 0.023727, l5: 0.022580, l6: 0.032590

[epoch:  97/100000, batch:    24/  187, ite: 9036] train loss: 0.109708, tar: 0.011113 
l0: 0.015832, l1: 0.016169, l2: 0.016662, l3: 0.017108, l4: 0.022265, l5: 0.024752, l6: 0.028677

[epoch:  97/100000, batch:    26/  187, ite: 9037] train loss: 0.109739, tar: 0.011118 
l0: 0.011734, l1: 0.013174, l2: 0.009784, l3: 0.009153, l4: 0.015431, l5: 0.012978, l6: 0.017628

[epoch:  97/100000, batch:    28/  187, ite: 9038] train loss: 0.109719, tar: 0.011118 
l0: 0.007221, l1: 0.007696, l2: 0.007617, l3: 0.009964, l4: 0.012629, l5: 0.013141, l6: 0.014705

[epoch:  97/100000, batch:    30/  187, ite: 9039] train loss: 0.109684, tar: 0.011114 
l0: 0.013875, l1: 0.014461, l2: 0.020084, l3: 0.022450, l4: 0.022612, l5: 0.020662, l6: 0.025853

[epoch:  97/100000, batch:    32/  187, ite: 9040] train loss: 0.109713, tar: 0.011117 
l0: 0.010929, l1: 0.010076, l2: 0.013790, l3: 0.014263, l4: 0.018991, l5: 0.019506, l6: 0.023027

[epoch:  97/100000, batch:    34/  187, ite: 9041] train loss: 0.109714, tar: 0.011117 
l0: 0.010766, l1: 0.011776, l2: 0.012468, l3: 0.011832, l4: 0.020910, l5: 0.024659, l6: 0.020541

[epoch:  97/100000, batch:    36/  187, ite: 9042] train loss: 0.109717, tar: 0.011117 
l0: 0.013229, l1: 0.013671, l2: 0.017455, l3: 0.014647, l4: 0.016635, l5: 0.015537, l6: 0.020313

[epoch:  97/100000, batch:    38/  187, ite: 9043] train loss: 0.109719, tar: 0.011119 
l0: 0.009639, l1: 0.009920, l2: 0.011408, l3: 0.011143, l4: 0.042496, l5: 0.045255, l6: 0.049585

[epoch:  97/100000, batch:    40/  187, ite: 9044] train loss: 0.109786, tar: 0.011117 
l0: 0.017162, l1: 0.018519, l2: 0.016755, l3: 0.017158, l4: 0.015893, l5: 0.020828, l6: 0.018407

[epoch:  97/100000, batch:    42/  187, ite: 9045] train loss: 0.109800, tar: 0.011123 
l0: 0.015386, l1: 0.016260, l2: 0.017818, l3: 0.015451, l4: 0.022325, l5: 0.023110, l6: 0.027454

[epoch:  97/100000, batch:    44/  187, ite: 9046] train loss: 0.109827, tar: 0.011127 
l0: 0.009180, l1: 0.007879, l2: 0.016336, l3: 0.015686, l4: 0.024089, l5: 0.023390, l6: 0.026587

[epoch:  97/100000, batch:    46/  187, ite: 9047] train loss: 0.109839, tar: 0.011125 
l0: 0.009654, l1: 0.009884, l2: 0.011436, l3: 0.012954, l4: 0.014971, l5: 0.012134, l6: 0.012439

[epoch:  97/100000, batch:    48/  187, ite: 9048] train loss: 0.109814, tar: 0.011124 
l0: 0.012187, l1: 0.011945, l2: 0.015534, l3: 0.016310, l4: 0.029034, l5: 0.032361, l6: 0.026113

[epoch:  97/100000, batch:    50/  187, ite: 9049] train loss: 0.109846, tar: 0.011125 
l0: 0.010868, l1: 0.010542, l2: 0.020300, l3: 0.018631, l4: 0.017473, l5: 0.017419, l6: 0.020028

[epoch:  97/100000, batch:    52/  187, ite: 9050] train loss: 0.109851, tar: 0.011124 
l0: 0.005899, l1: 0.005897, l2: 0.006880, l3: 0.006809, l4: 0.014721, l5: 0.019384, l6: 0.016513

[epoch:  97/100000, batch:    54/  187, ite: 9051] train loss: 0.109819, tar: 0.011120 
l0: 0.012194, l1: 0.011764, l2: 0.015744, l3: 0.016892, l4: 0.033904, l5: 0.031354, l6: 0.040484

[epoch:  97/100000, batch:    56/  187, ite: 9052] train loss: 0.109869, tar: 0.011121 
l0: 0.009753, l1: 0.010950, l2: 0.008581, l3: 0.008879, l4: 0.016939, l5: 0.016048, l6: 0.021614

[epoch:  97/100000, batch:    58/  187, ite: 9053] train loss: 0.109853, tar: 0.011119 
l0: 0.013586, l1: 0.013388, l2: 0.014742, l3: 0.020034, l4: 0.035681, l5: 0.026969, l6: 0.026337

[epoch:  97/100000, batch:    60/  187, ite: 9054] train loss: 0.109892, tar: 0.011122 
l0: 0.007025, l1: 0.007066, l2: 0.008088, l3: 0.008162, l4: 0.014929, l5: 0.017333, l6: 0.015602

[epoch:  97/100000, batch:    62/  187, ite: 9055] train loss: 0.109862, tar: 0.011118 
l0: 0.008038, l1: 0.008456, l2: 0.010635, l3: 0.010650, l4: 0.030656, l5: 0.027345, l6: 0.023010

[epoch:  97/100000, batch:    64/  187, ite: 9056] train loss: 0.109870, tar: 0.011115 
l0: 0.014665, l1: 0.013738, l2: 0.018046, l3: 0.019491, l4: 0.027247, l5: 0.023009, l6: 0.028124

[epoch:  97/100000, batch:    66/  187, ite: 9057] train loss: 0.109903, tar: 0.011118 
l0: 0.020242, l1: 0.021280, l2: 0.020083, l3: 0.021701, l4: 0.032532, l5: 0.029779, l6: 0.030970

[epoch:  97/100000, batch:    68/  187, ite: 9058] train loss: 0.109966, tar: 0.011127 
l0: 0.016171, l1: 0.017749, l2: 0.012659, l3: 0.014483, l4: 0.027332, l5: 0.029999, l6: 0.027513

[epoch:  97/100000, batch:    70/  187, ite: 9059] train loss: 0.110000, tar: 0.011132 
l0: 0.009108, l1: 0.009120, l2: 0.009967, l3: 0.012111, l4: 0.031510, l5: 0.026687, l6: 0.025864

[epoch:  97/100000, batch:    72/  187, ite: 9060] train loss: 0.110013, tar: 0.011130 
l0: 0.004825, l1: 0.005440, l2: 0.008304, l3: 0.008029, l4: 0.013115, l5: 0.013172, l6: 0.009728

[epoch:  97/100000, batch:    74/  187, ite: 9061] train loss: 0.109969, tar: 0.011124 
l0: 0.006330, l1: 0.007232, l2: 0.013593, l3: 0.011116, l4: 0.015308, l5: 0.010132, l6: 0.009222

[epoch:  97/100000, batch:    76/  187, ite: 9062] train loss: 0.109934, tar: 0.011119 
l0: 0.011088, l1: 0.011418, l2: 0.014696, l3: 0.013922, l4: 0.025590, l5: 0.024651, l6: 0.024745

[epoch:  97/100000, batch:    78/  187, ite: 9063] train loss: 0.109949, tar: 0.011119 
l0: 0.012857, l1: 0.010527, l2: 0.012857, l3: 0.017795, l4: 0.046627, l5: 0.051183, l6: 0.066528

[epoch:  97/100000, batch:    80/  187, ite: 9064] train loss: 0.110051, tar: 0.011121 
l0: 0.012462, l1: 0.012969, l2: 0.011600, l3: 0.010780, l4: 0.017094, l5: 0.017418, l6: 0.018842

[epoch:  97/100000, batch:    82/  187, ite: 9065] train loss: 0.110043, tar: 0.011122 
l0: 0.012467, l1: 0.012525, l2: 0.011326, l3: 0.012294, l4: 0.021005, l5: 0.024549, l6: 0.021748

[epoch:  97/100000, batch:    84/  187, ite: 9066] train loss: 0.110048, tar: 0.011123 
l0: 0.011430, l1: 0.012235, l2: 0.012117, l3: 0.011012, l4: 0.021078, l5: 0.020074, l6: 0.022619

[epoch:  97/100000, batch:    86/  187, ite: 9067] train loss: 0.110049, tar: 0.011124 
l0: 0.011847, l1: 0.011005, l2: 0.013787, l3: 0.016186, l4: 0.030608, l5: 0.033516, l6: 0.031435

[epoch:  97/100000, batch:    88/  187, ite: 9068] train loss: 0.110084, tar: 0.011124 
l0: 0.007249, l1: 0.007806, l2: 0.009756, l3: 0.010229, l4: 0.016251, l5: 0.014238, l6: 0.018579

[epoch:  97/100000, batch:    90/  187, ite: 9069] train loss: 0.110060, tar: 0.011121 
l0: 0.013119, l1: 0.013213, l2: 0.014032, l3: 0.018328, l4: 0.031247, l5: 0.029393, l6: 0.032638

[epoch:  97/100000, batch:    92/  187, ite: 9070] train loss: 0.110099, tar: 0.011122 
l0: 0.011225, l1: 0.010903, l2: 0.014492, l3: 0.013524, l4: 0.015473, l5: 0.015117, l6: 0.015893

[epoch:  97/100000, batch:    94/  187, ite: 9071] train loss: 0.110087, tar: 0.011123 
l0: 0.010228, l1: 0.011434, l2: 0.011077, l3: 0.013898, l4: 0.022302, l5: 0.018164, l6: 0.014811

[epoch:  97/100000, batch:    96/  187, ite: 9072] train loss: 0.110079, tar: 0.011122 
l0: 0.008735, l1: 0.010014, l2: 0.008072, l3: 0.007704, l4: 0.017862, l5: 0.015154, l6: 0.014721

[epoch:  97/100000, batch:    98/  187, ite: 9073] train loss: 0.110053, tar: 0.011120 
l0: 0.014552, l1: 0.013248, l2: 0.022694, l3: 0.022706, l4: 0.041867, l5: 0.039810, l6: 0.046671

[epoch:  97/100000, batch:   100/  187, ite: 9074] train loss: 0.110138, tar: 0.011123 
l0: 0.010845, l1: 0.011585, l2: 0.010288, l3: 0.014148, l4: 0.024115, l5: 0.019890, l6: 0.014708

[epoch:  97/100000, batch:   102/  187, ite: 9075] train loss: 0.110134, tar: 0.011122 
l0: 0.012440, l1: 0.013004, l2: 0.014435, l3: 0.015329, l4: 0.026208, l5: 0.028377, l6: 0.025427

[epoch:  97/100000, batch:   104/  187, ite: 9076] train loss: 0.110157, tar: 0.011124 
l0: 0.010063, l1: 0.010116, l2: 0.012978, l3: 0.012496, l4: 0.021973, l5: 0.018644, l6: 0.022984

[epoch:  97/100000, batch:   106/  187, ite: 9077] train loss: 0.110157, tar: 0.011123 
l0: 0.007780, l1: 0.007211, l2: 0.006872, l3: 0.008099, l4: 0.025855, l5: 0.035557, l6: 0.040816

[epoch:  97/100000, batch:   108/  187, ite: 9078] train loss: 0.110177, tar: 0.011120 
l0: 0.007611, l1: 0.007167, l2: 0.011716, l3: 0.011855, l4: 0.029298, l5: 0.025530, l6: 0.031723

[epoch:  97/100000, batch:   110/  187, ite: 9079] train loss: 0.110191, tar: 0.011116 
l0: 0.004888, l1: 0.005306, l2: 0.005466, l3: 0.005672, l4: 0.010919, l5: 0.012498, l6: 0.015328

[epoch:  97/100000, batch:   112/  187, ite: 9080] train loss: 0.110144, tar: 0.011111 
l0: 0.012064, l1: 0.012077, l2: 0.012453, l3: 0.014380, l4: 0.019802, l5: 0.022683, l6: 0.021888

[epoch:  97/100000, batch:   114/  187, ite: 9081] train loss: 0.110149, tar: 0.011111 
l0: 0.017192, l1: 0.018021, l2: 0.015133, l3: 0.015135, l4: 0.031235, l5: 0.027055, l6: 0.029544

[epoch:  97/100000, batch:   116/  187, ite: 9082] train loss: 0.110189, tar: 0.011117 
l0: 0.018978, l1: 0.013601, l2: 0.016499, l3: 0.025325, l4: 0.090899, l5: 0.105097, l6: 0.125714

[epoch:  97/100000, batch:   118/  187, ite: 9083] train loss: 0.110453, tar: 0.011124 
l0: 0.008459, l1: 0.008084, l2: 0.010367, l3: 0.010890, l4: 0.015658, l5: 0.018809, l6: 0.022343

[epoch:  97/100000, batch:   120/  187, ite: 9084] train loss: 0.110438, tar: 0.011122 
l0: 0.008554, l1: 0.008773, l2: 0.009906, l3: 0.010372, l4: 0.016638, l5: 0.016847, l6: 0.019124

[epoch:  97/100000, batch:   122/  187, ite: 9085] train loss: 0.110420, tar: 0.011120 
l0: 0.014230, l1: 0.014447, l2: 0.014411, l3: 0.018955, l4: 0.027705, l5: 0.028914, l6: 0.029413

[epoch:  97/100000, batch:   124/  187, ite: 9086] train loss: 0.110454, tar: 0.011122 
l0: 0.006232, l1: 0.006026, l2: 0.007419, l3: 0.007786, l4: 0.012760, l5: 0.013800, l6: 0.013739

[epoch:  97/100000, batch:   126/  187, ite: 9087] train loss: 0.110415, tar: 0.011118 
l0: 0.012339, l1: 0.012051, l2: 0.018489, l3: 0.020198, l4: 0.019742, l5: 0.024271, l6: 0.025763

[epoch:  97/100000, batch:   128/  187, ite: 9088] train loss: 0.110436, tar: 0.011119 
l0: 0.010639, l1: 0.010588, l2: 0.010317, l3: 0.013846, l4: 0.023434, l5: 0.020043, l6: 0.022855

[epoch:  97/100000, batch:   130/  187, ite: 9089] train loss: 0.110437, tar: 0.011119 
l0: 0.011789, l1: 0.012111, l2: 0.010579, l3: 0.011825, l4: 0.016962, l5: 0.015620, l6: 0.015094

[epoch:  97/100000, batch:   132/  187, ite: 9090] train loss: 0.110422, tar: 0.011119 
l0: 0.014650, l1: 0.016555, l2: 0.011120, l3: 0.014498, l4: 0.026655, l5: 0.022168, l6: 0.030602

[epoch:  97/100000, batch:   134/  187, ite: 9091] train loss: 0.110446, tar: 0.011122 
l0: 0.008088, l1: 0.007516, l2: 0.008658, l3: 0.010396, l4: 0.019181, l5: 0.017832, l6: 0.019599

[epoch:  97/100000, batch:   136/  187, ite: 9092] train loss: 0.110428, tar: 0.011120 
l0: 0.014379, l1: 0.014638, l2: 0.018414, l3: 0.022045, l4: 0.025061, l5: 0.027351, l6: 0.032176

[epoch:  97/100000, batch:   138/  187, ite: 9093] train loss: 0.110468, tar: 0.011123 
l0: 0.015769, l1: 0.016006, l2: 0.016822, l3: 0.019133, l4: 0.029134, l5: 0.025878, l6: 0.028893

[epoch:  97/100000, batch:   140/  187, ite: 9094] train loss: 0.110506, tar: 0.011127 
l0: 0.016268, l1: 0.017110, l2: 0.019557, l3: 0.017671, l4: 0.024703, l5: 0.025103, l6: 0.034977

[epoch:  97/100000, batch:   142/  187, ite: 9095] train loss: 0.110547, tar: 0.011132 
l0: 0.028637, l1: 0.028625, l2: 0.026493, l3: 0.027566, l4: 0.028607, l5: 0.035992, l6: 0.039108

[epoch:  97/100000, batch:   144/  187, ite: 9096] train loss: 0.110642, tar: 0.011148 
l0: 0.014664, l1: 0.016043, l2: 0.017530, l3: 0.019171, l4: 0.034483, l5: 0.036433, l6: 0.041216

[epoch:  97/100000, batch:   146/  187, ite: 9097] train loss: 0.110705, tar: 0.011151 
l0: 0.017981, l1: 0.017831, l2: 0.019437, l3: 0.017897, l4: 0.027334, l5: 0.036964, l6: 0.038953

[epoch:  97/100000, batch:   148/  187, ite: 9098] train loss: 0.110765, tar: 0.011157 
l0: 0.024855, l1: 0.029097, l2: 0.026967, l3: 0.025341, l4: 0.021294, l5: 0.018575, l6: 0.017413

[epoch:  97/100000, batch:   150/  187, ite: 9099] train loss: 0.110813, tar: 0.011169 
l0: 0.013706, l1: 0.013159, l2: 0.017559, l3: 0.019510, l4: 0.025833, l5: 0.023876, l6: 0.019708

[epoch:  97/100000, batch:   152/  187, ite: 9100] train loss: 0.110833, tar: 0.011172 
l0: 0.009472, l1: 0.010118, l2: 0.010070, l3: 0.012891, l4: 0.026146, l5: 0.025968, l6: 0.035540

[epoch:  97/100000, batch:   154/  187, ite: 9101] train loss: 0.110851, tar: 0.011170 
l0: 0.004766, l1: 0.004863, l2: 0.009448, l3: 0.006201, l4: 0.011754, l5: 0.017239, l6: 0.022710

[epoch:  97/100000, batch:   156/  187, ite: 9102] train loss: 0.110820, tar: 0.011164 
l0: 0.013334, l1: 0.013186, l2: 0.013817, l3: 0.012572, l4: 0.022750, l5: 0.023623, l6: 0.023619

[epoch:  97/100000, batch:   158/  187, ite: 9103] train loss: 0.110831, tar: 0.011166 
l0: 0.011354, l1: 0.011132, l2: 0.013023, l3: 0.013747, l4: 0.025972, l5: 0.025690, l6: 0.023533

[epoch:  97/100000, batch:   160/  187, ite: 9104] train loss: 0.110843, tar: 0.011167 
l0: 0.009179, l1: 0.008314, l2: 0.011105, l3: 0.011500, l4: 0.016721, l5: 0.022040, l6: 0.016951

[epoch:  97/100000, batch:   162/  187, ite: 9105] train loss: 0.110830, tar: 0.011165 
l0: 0.015153, l1: 0.013999, l2: 0.016164, l3: 0.019152, l4: 0.031284, l5: 0.036757, l6: 0.043865

[epoch:  97/100000, batch:   164/  187, ite: 9106] train loss: 0.110889, tar: 0.011168 
l0: 0.010074, l1: 0.010035, l2: 0.009641, l3: 0.011109, l4: 0.030658, l5: 0.028730, l6: 0.026155

[epoch:  97/100000, batch:   166/  187, ite: 9107] train loss: 0.110903, tar: 0.011167 
l0: 0.019139, l1: 0.020613, l2: 0.018762, l3: 0.019715, l4: 0.032776, l5: 0.031693, l6: 0.031367

[epoch:  97/100000, batch:   168/  187, ite: 9108] train loss: 0.110960, tar: 0.011175 
l0: 0.009482, l1: 0.010877, l2: 0.011967, l3: 0.011696, l4: 0.020287, l5: 0.016291, l6: 0.014720

[epoch:  97/100000, batch:   170/  187, ite: 9109] train loss: 0.110946, tar: 0.011173 
l0: 0.017786, l1: 0.018016, l2: 0.022566, l3: 0.020510, l4: 0.039805, l5: 0.041785, l6: 0.037708

[epoch:  97/100000, batch:   172/  187, ite: 9110] train loss: 0.111024, tar: 0.011179 
l0: 0.009776, l1: 0.009113, l2: 0.012175, l3: 0.013313, l4: 0.028968, l5: 0.028669, l6: 0.029969

[epoch:  97/100000, batch:   174/  187, ite: 9111] train loss: 0.111043, tar: 0.011178 
l0: 0.011260, l1: 0.011366, l2: 0.012036, l3: 0.013733, l4: 0.031969, l5: 0.034952, l6: 0.044023

[epoch:  97/100000, batch:   176/  187, ite: 9112] train loss: 0.111087, tar: 0.011178 
l0: 0.011365, l1: 0.010919, l2: 0.015342, l3: 0.015102, l4: 0.020558, l5: 0.019482, l6: 0.028715

[epoch:  97/100000, batch:   178/  187, ite: 9113] train loss: 0.111096, tar: 0.011178 
l0: 0.011647, l1: 0.010814, l2: 0.015209, l3: 0.016254, l4: 0.017766, l5: 0.019451, l6: 0.023383

[epoch:  97/100000, batch:   180/  187, ite: 9114] train loss: 0.111099, tar: 0.011178 
l0: 0.012987, l1: 0.012289, l2: 0.013667, l3: 0.015445, l4: 0.044458, l5: 0.048637, l6: 0.048050

[epoch:  97/100000, batch:   182/  187, ite: 9115] train loss: 0.111175, tar: 0.011180 
l0: 0.007309, l1: 0.007195, l2: 0.008444, l3: 0.009325, l4: 0.017132, l5: 0.019817, l6: 0.019726

[epoch:  97/100000, batch:   184/  187, ite: 9116] train loss: 0.111155, tar: 0.011177 
l0: 0.013209, l1: 0.013178, l2: 0.014442, l3: 0.013266, l4: 0.022452, l5: 0.027098, l6: 0.038788

[epoch:  97/100000, batch:   186/  187, ite: 9117] train loss: 0.111183, tar: 0.011178 
l0: 0.005535, l1: 0.006092, l2: 0.014932, l3: 0.011033, l4: 0.014886, l5: 0.012002, l6: 0.013243

[epoch:  97/100000, batch:   188/  187, ite: 9118] train loss: 0.111153, tar: 0.011173 
l0: 0.025527, l1: 0.024821, l2: 0.024474, l3: 0.029748, l4: 0.015841, l5: 0.016053, l6: 0.018999

[epoch:  98/100000, batch:     2/  187, ite: 9119] train loss: 0.111193, tar: 0.011186 
l0: 0.010822, l1: 0.010549, l2: 0.013973, l3: 0.016171, l4: 0.015798, l5: 0.015565, l6: 0.012997

[epoch:  98/100000, batch:     4/  187, ite: 9120] train loss: 0.111179, tar: 0.011186 
l0: 0.010917, l1: 0.010336, l2: 0.013034, l3: 0.011856, l4: 0.016872, l5: 0.020603, l6: 0.017008

[epoch:  98/100000, batch:     6/  187, ite: 9121] train loss: 0.111169, tar: 0.011186 
l0: 0.011878, l1: 0.012153, l2: 0.012607, l3: 0.011958, l4: 0.021617, l5: 0.021964, l6: 0.027555

[epoch:  98/100000, batch:     8/  187, ite: 9122] train loss: 0.111177, tar: 0.011186 
l0: 0.017669, l1: 0.019235, l2: 0.016434, l3: 0.016952, l4: 0.028845, l5: 0.027687, l6: 0.026906

[epoch:  98/100000, batch:    10/  187, ite: 9123] train loss: 0.111215, tar: 0.011192 
l0: 0.010104, l1: 0.010701, l2: 0.011126, l3: 0.009759, l4: 0.021149, l5: 0.020112, l6: 0.020105

[epoch:  98/100000, batch:    12/  187, ite: 9124] train loss: 0.111208, tar: 0.011191 
l0: 0.012137, l1: 0.011941, l2: 0.014040, l3: 0.014248, l4: 0.018613, l5: 0.020197, l6: 0.017800

[epoch:  98/100000, batch:    14/  187, ite: 9125] train loss: 0.111206, tar: 0.011192 
l0: 0.016921, l1: 0.019591, l2: 0.017042, l3: 0.019211, l4: 0.022435, l5: 0.021062, l6: 0.026302

[epoch:  98/100000, batch:    16/  187, ite: 9126] train loss: 0.111234, tar: 0.011197 
l0: 0.017321, l1: 0.016704, l2: 0.020615, l3: 0.022712, l4: 0.021444, l5: 0.021269, l6: 0.020199

[epoch:  98/100000, batch:    18/  187, ite: 9127] train loss: 0.111259, tar: 0.011202 
l0: 0.009665, l1: 0.010687, l2: 0.010199, l3: 0.010786, l4: 0.023544, l5: 0.020912, l6: 0.019581

[epoch:  98/100000, batch:    20/  187, ite: 9128] train loss: 0.111254, tar: 0.011201 
l0: 0.014273, l1: 0.014306, l2: 0.018991, l3: 0.019825, l4: 0.020519, l5: 0.020272, l6: 0.022379

[epoch:  98/100000, batch:    22/  187, ite: 9129] train loss: 0.111271, tar: 0.011204 
l0: 0.012863, l1: 0.013367, l2: 0.016969, l3: 0.014417, l4: 0.026332, l5: 0.025608, l6: 0.029368

[epoch:  98/100000, batch:    24/  187, ite: 9130] train loss: 0.111296, tar: 0.011205 
l0: 0.010595, l1: 0.010453, l2: 0.015553, l3: 0.014515, l4: 0.029335, l5: 0.025617, l6: 0.028886

[epoch:  98/100000, batch:    26/  187, ite: 9131] train loss: 0.111317, tar: 0.011205 
l0: 0.008022, l1: 0.007570, l2: 0.010546, l3: 0.010385, l4: 0.010015, l5: 0.010613, l6: 0.015262

[epoch:  98/100000, batch:    28/  187, ite: 9132] train loss: 0.111282, tar: 0.011202 
l0: 0.007692, l1: 0.008482, l2: 0.008260, l3: 0.009919, l4: 0.010943, l5: 0.013865, l6: 0.014259

[epoch:  98/100000, batch:    30/  187, ite: 9133] train loss: 0.111249, tar: 0.011199 
l0: 0.016118, l1: 0.018539, l2: 0.013643, l3: 0.014131, l4: 0.011529, l5: 0.012550, l6: 0.011714

[epoch:  98/100000, batch:    32/  187, ite: 9134] train loss: 0.111237, tar: 0.011203 
l0: 0.008003, l1: 0.007743, l2: 0.009473, l3: 0.011778, l4: 0.018500, l5: 0.017985, l6: 0.018727

[epoch:  98/100000, batch:    34/  187, ite: 9135] train loss: 0.111221, tar: 0.011200 
l0: 0.011827, l1: 0.012927, l2: 0.013651, l3: 0.012143, l4: 0.024385, l5: 0.020705, l6: 0.023901

[epoch:  98/100000, batch:    36/  187, ite: 9136] train loss: 0.111228, tar: 0.011201 
l0: 0.009354, l1: 0.009598, l2: 0.010309, l3: 0.011517, l4: 0.022214, l5: 0.022501, l6: 0.024075

[epoch:  98/100000, batch:    38/  187, ite: 9137] train loss: 0.111226, tar: 0.011199 
l0: 0.009709, l1: 0.009150, l2: 0.013406, l3: 0.013780, l4: 0.020360, l5: 0.022426, l6: 0.022722

[epoch:  98/100000, batch:    40/  187, ite: 9138] train loss: 0.111227, tar: 0.011198 
l0: 0.013199, l1: 0.013787, l2: 0.013752, l3: 0.014011, l4: 0.025613, l5: 0.023324, l6: 0.022327

[epoch:  98/100000, batch:    42/  187, ite: 9139] train loss: 0.111240, tar: 0.011200 
l0: 0.010123, l1: 0.010645, l2: 0.010636, l3: 0.011634, l4: 0.015905, l5: 0.014504, l6: 0.012281

[epoch:  98/100000, batch:    44/  187, ite: 9140] train loss: 0.111217, tar: 0.011199 
l0: 0.012335, l1: 0.013152, l2: 0.016209, l3: 0.015060, l4: 0.020154, l5: 0.018395, l6: 0.018740

[epoch:  98/100000, batch:    46/  187, ite: 9141] train loss: 0.111220, tar: 0.011200 
l0: 0.021832, l1: 0.020816, l2: 0.019606, l3: 0.030185, l4: 0.046853, l5: 0.042043, l6: 0.046446

[epoch:  98/100000, batch:    48/  187, ite: 9142] train loss: 0.111322, tar: 0.011209 
l0: 0.013056, l1: 0.013821, l2: 0.014094, l3: 0.012939, l4: 0.024921, l5: 0.022146, l6: 0.020693

[epoch:  98/100000, batch:    50/  187, ite: 9143] train loss: 0.111331, tar: 0.011211 
l0: 0.013833, l1: 0.013712, l2: 0.017203, l3: 0.018944, l4: 0.023886, l5: 0.025280, l6: 0.033987

[epoch:  98/100000, batch:    52/  187, ite: 9144] train loss: 0.111362, tar: 0.011213 
l0: 0.015205, l1: 0.016478, l2: 0.018128, l3: 0.018659, l4: 0.019350, l5: 0.020647, l6: 0.022922

[epoch:  98/100000, batch:    54/  187, ite: 9145] train loss: 0.111379, tar: 0.011216 
l0: 0.009754, l1: 0.010309, l2: 0.013614, l3: 0.012662, l4: 0.020862, l5: 0.018822, l6: 0.020150

[epoch:  98/100000, batch:    56/  187, ite: 9146] train loss: 0.111375, tar: 0.011215 
l0: 0.010883, l1: 0.009836, l2: 0.012734, l3: 0.015552, l4: 0.033133, l5: 0.035434, l6: 0.038129

[epoch:  98/100000, batch:    58/  187, ite: 9147] train loss: 0.111414, tar: 0.011215 
l0: 0.010783, l1: 0.010991, l2: 0.011825, l3: 0.012218, l4: 0.021094, l5: 0.019089, l6: 0.015605

[epoch:  98/100000, batch:    60/  187, ite: 9148] train loss: 0.111405, tar: 0.011214 
l0: 0.019161, l1: 0.020188, l2: 0.018391, l3: 0.019358, l4: 0.027701, l5: 0.028186, l6: 0.032558

[epoch:  98/100000, batch:    62/  187, ite: 9149] train loss: 0.111452, tar: 0.011221 
l0: 0.009175, l1: 0.010281, l2: 0.009825, l3: 0.009898, l4: 0.015937, l5: 0.017762, l6: 0.028202

[epoch:  98/100000, batch:    64/  187, ite: 9150] train loss: 0.111443, tar: 0.011220 
l0: 0.010505, l1: 0.010701, l2: 0.013704, l3: 0.013740, l4: 0.018138, l5: 0.017724, l6: 0.021245

[epoch:  98/100000, batch:    66/  187, ite: 9151] train loss: 0.111438, tar: 0.011219 
l0: 0.011252, l1: 0.011480, l2: 0.011066, l3: 0.012959, l4: 0.014919, l5: 0.014962, l6: 0.013925

[epoch:  98/100000, batch:    68/  187, ite: 9152] train loss: 0.111420, tar: 0.011219 
l0: 0.020562, l1: 0.020432, l2: 0.024874, l3: 0.025529, l4: 0.023030, l5: 0.022441, l6: 0.029069

[epoch:  98/100000, batch:    70/  187, ite: 9153] train loss: 0.111467, tar: 0.011227 
l0: 0.008409, l1: 0.007335, l2: 0.014581, l3: 0.014247, l4: 0.029773, l5: 0.027553, l6: 0.030132

[epoch:  98/100000, batch:    72/  187, ite: 9154] train loss: 0.111485, tar: 0.011225 
l0: 0.010110, l1: 0.010709, l2: 0.010833, l3: 0.010712, l4: 0.021939, l5: 0.015844, l6: 0.015822

[epoch:  98/100000, batch:    74/  187, ite: 9155] train loss: 0.111472, tar: 0.011224 
l0: 0.008773, l1: 0.014598, l2: 0.008837, l3: 0.005110, l4: 0.006589, l5: 0.007328, l6: 0.005536

[epoch:  98/100000, batch:    76/  187, ite: 9156] train loss: 0.111424, tar: 0.011222 
l0: 0.004790, l1: 0.005134, l2: 0.004882, l3: 0.004996, l4: 0.009104, l5: 0.007009, l6: 0.010828

[epoch:  98/100000, batch:    78/  187, ite: 9157] train loss: 0.111369, tar: 0.011216 
l0: 0.011394, l1: 0.011414, l2: 0.011605, l3: 0.012987, l4: 0.024152, l5: 0.021655, l6: 0.028533

[epoch:  98/100000, batch:    80/  187, ite: 9158] train loss: 0.111377, tar: 0.011216 
l0: 0.014789, l1: 0.015390, l2: 0.017010, l3: 0.016065, l4: 0.023945, l5: 0.023170, l6: 0.019266

[epoch:  98/100000, batch:    82/  187, ite: 9159] train loss: 0.111393, tar: 0.011219 
l0: 0.015747, l1: 0.016144, l2: 0.020977, l3: 0.019460, l4: 0.033885, l5: 0.026359, l6: 0.033566

[epoch:  98/100000, batch:    84/  187, ite: 9160] train loss: 0.111440, tar: 0.011223 
l0: 0.006550, l1: 0.006107, l2: 0.010016, l3: 0.007725, l4: 0.010669, l5: 0.015848, l6: 0.015884

[epoch:  98/100000, batch:    86/  187, ite: 9161] train loss: 0.111407, tar: 0.011219 
l0: 0.024781, l1: 0.027558, l2: 0.032760, l3: 0.032544, l4: 0.035375, l5: 0.032720, l6: 0.024945

[epoch:  98/100000, batch:    88/  187, ite: 9162] train loss: 0.111493, tar: 0.011231 
l0: 0.006531, l1: 0.006564, l2: 0.007468, l3: 0.012770, l4: 0.016852, l5: 0.013450, l6: 0.011240

[epoch:  98/100000, batch:    90/  187, ite: 9163] train loss: 0.111461, tar: 0.011227 
l0: 0.008858, l1: 0.009930, l2: 0.010695, l3: 0.010142, l4: 0.012868, l5: 0.013685, l6: 0.012297

[epoch:  98/100000, batch:    92/  187, ite: 9164] train loss: 0.111433, tar: 0.011225 
l0: 0.008013, l1: 0.008933, l2: 0.010348, l3: 0.009287, l4: 0.013493, l5: 0.011911, l6: 0.015849

[epoch:  98/100000, batch:    94/  187, ite: 9165] train loss: 0.111404, tar: 0.011222 
l0: 0.016335, l1: 0.017758, l2: 0.018986, l3: 0.017153, l4: 0.020725, l5: 0.018940, l6: 0.013419

[epoch:  98/100000, batch:    96/  187, ite: 9166] train loss: 0.111414, tar: 0.011226 
l0: 0.018886, l1: 0.019499, l2: 0.013575, l3: 0.015245, l4: 0.031731, l5: 0.035262, l6: 0.035703

[epoch:  98/100000, batch:    98/  187, ite: 9167] train loss: 0.111464, tar: 0.011233 
l0: 0.013005, l1: 0.012771, l2: 0.021236, l3: 0.019835, l4: 0.020948, l5: 0.019622, l6: 0.019247

[epoch:  98/100000, batch:   100/  187, ite: 9168] train loss: 0.111477, tar: 0.011234 
l0: 0.015192, l1: 0.014888, l2: 0.016355, l3: 0.016407, l4: 0.017013, l5: 0.019331, l6: 0.019182

[epoch:  98/100000, batch:   102/  187, ite: 9169] train loss: 0.111483, tar: 0.011238 
l0: 0.017198, l1: 0.017537, l2: 0.018486, l3: 0.019963, l4: 0.023493, l5: 0.027589, l6: 0.031075

[epoch:  98/100000, batch:   104/  187, ite: 9170] train loss: 0.111521, tar: 0.011243 
l0: 0.010916, l1: 0.010621, l2: 0.013846, l3: 0.013197, l4: 0.029127, l5: 0.029118, l6: 0.026066

[epoch:  98/100000, batch:   106/  187, ite: 9171] train loss: 0.111539, tar: 0.011243 
l0: 0.008217, l1: 0.007504, l2: 0.009068, l3: 0.009689, l4: 0.018090, l5: 0.020483, l6: 0.023663

[epoch:  98/100000, batch:   108/  187, ite: 9172] train loss: 0.111526, tar: 0.011240 
l0: 0.010860, l1: 0.009930, l2: 0.011719, l3: 0.016577, l4: 0.019701, l5: 0.018917, l6: 0.024749

[epoch:  98/100000, batch:   110/  187, ite: 9173] train loss: 0.111527, tar: 0.011240 
l0: 0.016344, l1: 0.018594, l2: 0.019979, l3: 0.020543, l4: 0.021396, l5: 0.018337, l6: 0.017694

[epoch:  98/100000, batch:   112/  187, ite: 9174] train loss: 0.111545, tar: 0.011244 
l0: 0.016234, l1: 0.016935, l2: 0.019046, l3: 0.018434, l4: 0.021853, l5: 0.021936, l6: 0.027323

[epoch:  98/100000, batch:   114/  187, ite: 9175] train loss: 0.111571, tar: 0.011248 
l0: 0.006369, l1: 0.005804, l2: 0.006516, l3: 0.007759, l4: 0.023505, l5: 0.025810, l6: 0.020675

[epoch:  98/100000, batch:   116/  187, ite: 9176] train loss: 0.111558, tar: 0.011244 
l0: 0.011596, l1: 0.013552, l2: 0.016640, l3: 0.010275, l4: 0.020488, l5: 0.017092, l6: 0.025749

[epoch:  98/100000, batch:   118/  187, ite: 9177] train loss: 0.111561, tar: 0.011244 
l0: 0.007783, l1: 0.009316, l2: 0.009968, l3: 0.008696, l4: 0.014123, l5: 0.013338, l6: 0.012025

[epoch:  98/100000, batch:   120/  187, ite: 9178] train loss: 0.111530, tar: 0.011242 
l0: 0.007409, l1: 0.008742, l2: 0.009348, l3: 0.012733, l4: 0.016655, l5: 0.015896, l6: 0.023305

[epoch:  98/100000, batch:   122/  187, ite: 9179] train loss: 0.111516, tar: 0.011238 
l0: 0.007578, l1: 0.006703, l2: 0.008793, l3: 0.009472, l4: 0.018738, l5: 0.021209, l6: 0.033902

[epoch:  98/100000, batch:   124/  187, ite: 9180] train loss: 0.111511, tar: 0.011235 
l0: 0.085188, l1: 0.070973, l2: 0.090697, l3: 0.091457, l4: 0.091366, l5: 0.121500, l6: 0.161601

[epoch:  98/100000, batch:   126/  187, ite: 9181] train loss: 0.112020, tar: 0.011298 
l0: 0.010333, l1: 0.010781, l2: 0.012427, l3: 0.013012, l4: 0.026473, l5: 0.024532, l6: 0.018428

[epoch:  98/100000, batch:   128/  187, ite: 9182] train loss: 0.112024, tar: 0.011297 
l0: 0.015144, l1: 0.016301, l2: 0.012433, l3: 0.014282, l4: 0.014189, l5: 0.014279, l6: 0.015609

[epoch:  98/100000, batch:   130/  187, ite: 9183] train loss: 0.112016, tar: 0.011300 
l0: 0.013209, l1: 0.013861, l2: 0.016369, l3: 0.017329, l4: 0.017806, l5: 0.018435, l6: 0.017949

[epoch:  98/100000, batch:   132/  187, ite: 9184] train loss: 0.112018, tar: 0.011302 
l0: 0.011910, l1: 0.013364, l2: 0.012056, l3: 0.011446, l4: 0.020239, l5: 0.018772, l6: 0.018813

[epoch:  98/100000, batch:   134/  187, ite: 9185] train loss: 0.112013, tar: 0.011302 
l0: 0.033155, l1: 0.038475, l2: 0.044522, l3: 0.045751, l4: 0.022173, l5: 0.017618, l6: 0.019312

[epoch:  98/100000, batch:   136/  187, ite: 9186] train loss: 0.112105, tar: 0.011321 
l0: 0.014580, l1: 0.014924, l2: 0.019223, l3: 0.017948, l4: 0.028050, l5: 0.030968, l6: 0.020454

[epoch:  98/100000, batch:   138/  187, ite: 9187] train loss: 0.112134, tar: 0.011324 
l0: 0.047325, l1: 0.051505, l2: 0.063635, l3: 0.056835, l4: 0.045199, l5: 0.047122, l6: 0.035436

[epoch:  98/100000, batch:   140/  187, ite: 9188] train loss: 0.112332, tar: 0.011354 
l0: 0.037304, l1: 0.037284, l2: 0.046308, l3: 0.049291, l4: 0.053768, l5: 0.066275, l6: 0.055123

[epoch:  98/100000, batch:   142/  187, ite: 9189] train loss: 0.112528, tar: 0.011376 
l0: 0.016818, l1: 0.018114, l2: 0.014784, l3: 0.018306, l4: 0.033807, l5: 0.030881, l6: 0.029179

[epoch:  98/100000, batch:   144/  187, ite: 9190] train loss: 0.112569, tar: 0.011380 
l0: 0.022124, l1: 0.022841, l2: 0.037974, l3: 0.040279, l4: 0.025759, l5: 0.020025, l6: 0.019595

[epoch:  98/100000, batch:   146/  187, ite: 9191] train loss: 0.112633, tar: 0.011389 
l0: 0.032607, l1: 0.033866, l2: 0.033088, l3: 0.042484, l4: 0.048497, l5: 0.042062, l6: 0.041467

[epoch:  98/100000, batch:   148/  187, ite: 9192] train loss: 0.112769, tar: 0.011407 
l0: 0.012616, l1: 0.013360, l2: 0.015477, l3: 0.016285, l4: 0.028010, l5: 0.023210, l6: 0.013636

[epoch:  98/100000, batch:   150/  187, ite: 9193] train loss: 0.112777, tar: 0.011408 
l0: 0.043175, l1: 0.047030, l2: 0.047700, l3: 0.051616, l4: 0.023973, l5: 0.022712, l6: 0.034950

[epoch:  98/100000, batch:   152/  187, ite: 9194] train loss: 0.112909, tar: 0.011435 
l0: 0.171413, l1: 0.171400, l2: 0.227521, l3: 0.262729, l4: 0.080316, l5: 0.074361, l6: 0.081296

[epoch:  98/100000, batch:   154/  187, ite: 9195] train loss: 0.113710, tar: 0.011569 
l0: 0.027470, l1: 0.030273, l2: 0.037775, l3: 0.034931, l4: 0.026988, l5: 0.022098, l6: 0.023196

[epoch:  98/100000, batch:   156/  187, ite: 9196] train loss: 0.113784, tar: 0.011582 
l0: 0.030996, l1: 0.034456, l2: 0.051855, l3: 0.045666, l4: 0.033770, l5: 0.026230, l6: 0.029513

[epoch:  98/100000, batch:   158/  187, ite: 9197] train loss: 0.113900, tar: 0.011598 
l0: 0.021273, l1: 0.023080, l2: 0.023693, l3: 0.024313, l4: 0.049470, l5: 0.047157, l6: 0.029484

[epoch:  98/100000, batch:   160/  187, ite: 9198] train loss: 0.113987, tar: 0.011606 
l0: 0.015054, l1: 0.018195, l2: 0.019535, l3: 0.019175, l4: 0.016599, l5: 0.023456, l6: 0.019255

[epoch:  98/100000, batch:   162/  187, ite: 9199] train loss: 0.114002, tar: 0.011609 
l0: 0.043655, l1: 0.040915, l2: 0.042855, l3: 0.052726, l4: 0.060125, l5: 0.073125, l6: 0.076225

[epoch:  98/100000, batch:   164/  187, ite: 9200] train loss: 0.114231, tar: 0.011636 
l0: 0.031473, l1: 0.032330, l2: 0.034607, l3: 0.039572, l4: 0.037910, l5: 0.041786, l6: 0.035594

[epoch:  98/100000, batch:   166/  187, ite: 9201] train loss: 0.114347, tar: 0.011652 
l0: 0.037346, l1: 0.036692, l2: 0.039901, l3: 0.043733, l4: 0.029866, l5: 0.036458, l6: 0.036270

[epoch:  98/100000, batch:   168/  187, ite: 9202] train loss: 0.114468, tar: 0.011674 
l0: 0.047428, l1: 0.051184, l2: 0.053108, l3: 0.064867, l4: 0.021931, l5: 0.031174, l6: 0.025277

[epoch:  98/100000, batch:   170/  187, ite: 9203] train loss: 0.114618, tar: 0.011703 
l0: 0.020744, l1: 0.023108, l2: 0.025013, l3: 0.025438, l4: 0.028827, l5: 0.033368, l6: 0.037128

[epoch:  98/100000, batch:   172/  187, ite: 9204] train loss: 0.114684, tar: 0.011711 
l0: 0.022757, l1: 0.029412, l2: 0.035493, l3: 0.034337, l4: 0.039385, l5: 0.040950, l6: 0.027428

[epoch:  98/100000, batch:   174/  187, ite: 9205] train loss: 0.114780, tar: 0.011720 
l0: 0.030267, l1: 0.037013, l2: 0.049801, l3: 0.042694, l4: 0.034431, l5: 0.035870, l6: 0.025928

[epoch:  98/100000, batch:   176/  187, ite: 9206] train loss: 0.114897, tar: 0.011735 
l0: 0.014898, l1: 0.013788, l2: 0.025026, l3: 0.030691, l4: 0.033230, l5: 0.041008, l6: 0.033867

[epoch:  98/100000, batch:   178/  187, ite: 9207] train loss: 0.114961, tar: 0.011738 
l0: 0.027861, l1: 0.026217, l2: 0.032704, l3: 0.035960, l4: 0.054885, l5: 0.078567, l6: 0.052506

[epoch:  98/100000, batch:   180/  187, ite: 9208] train loss: 0.115121, tar: 0.011751 
l0: 0.069412, l1: 0.077564, l2: 0.079896, l3: 0.076720, l4: 0.067979, l5: 0.096378, l6: 0.072061

[epoch:  98/100000, batch:   182/  187, ite: 9209] train loss: 0.115473, tar: 0.011799 
l0: 0.014218, l1: 0.015161, l2: 0.018181, l3: 0.017827, l4: 0.017037, l5: 0.016310, l6: 0.015210

[epoch:  98/100000, batch:   184/  187, ite: 9210] train loss: 0.115472, tar: 0.011801 
l0: 0.018493, l1: 0.021113, l2: 0.021796, l3: 0.021824, l4: 0.030948, l5: 0.025571, l6: 0.026014

[epoch:  98/100000, batch:   186/  187, ite: 9211] train loss: 0.115513, tar: 0.011807 
l0: 0.016048, l1: 0.017159, l2: 0.023933, l3: 0.019511, l4: 0.051179, l5: 0.040796, l6: 0.019198

[epoch:  98/100000, batch:   188/  187, ite: 9212] train loss: 0.115573, tar: 0.011810 
l0: 0.029002, l1: 0.035284, l2: 0.032182, l3: 0.038647, l4: 0.035558, l5: 0.028147, l6: 0.021268

[epoch:  99/100000, batch:     2/  187, ite: 9213] train loss: 0.115659, tar: 0.011824 
l0: 0.016817, l1: 0.020770, l2: 0.027057, l3: 0.030992, l4: 0.025014, l5: 0.014651, l6: 0.013764

[epoch:  99/100000, batch:     4/  187, ite: 9214] train loss: 0.115686, tar: 0.011828 
l0: 0.019111, l1: 0.021972, l2: 0.024910, l3: 0.023894, l4: 0.033577, l5: 0.032093, l6: 0.020922

[epoch:  99/100000, batch:     6/  187, ite: 9215] train loss: 0.115736, tar: 0.011834 
l0: 0.015755, l1: 0.016336, l2: 0.023346, l3: 0.027934, l4: 0.032703, l5: 0.027755, l6: 0.025642

[epoch:  99/100000, batch:     8/  187, ite: 9216] train loss: 0.115781, tar: 0.011838 
l0: 0.041111, l1: 0.041037, l2: 0.037705, l3: 0.043251, l4: 0.059638, l5: 0.065266, l6: 0.073180

[epoch:  99/100000, batch:    10/  187, ite: 9217] train loss: 0.115982, tar: 0.011862 
l0: 0.019970, l1: 0.018415, l2: 0.036171, l3: 0.040042, l4: 0.054273, l5: 0.068136, l6: 0.056654

[epoch:  99/100000, batch:    12/  187, ite: 9218] train loss: 0.116128, tar: 0.011868 
l0: 0.013944, l1: 0.015714, l2: 0.015989, l3: 0.018054, l4: 0.027680, l5: 0.024317, l6: 0.018326

[epoch:  99/100000, batch:    14/  187, ite: 9219] train loss: 0.116143, tar: 0.011870 
l0: 0.012972, l1: 0.013596, l2: 0.016310, l3: 0.017898, l4: 0.023160, l5: 0.020677, l6: 0.026923

[epoch:  99/100000, batch:    16/  187, ite: 9220] train loss: 0.116155, tar: 0.011871 
l0: 0.017300, l1: 0.020242, l2: 0.018903, l3: 0.016757, l4: 0.029048, l5: 0.026724, l6: 0.022715

[epoch:  99/100000, batch:    18/  187, ite: 9221] train loss: 0.116185, tar: 0.011875 
l0: 0.055668, l1: 0.049577, l2: 0.056253, l3: 0.061960, l4: 0.094382, l5: 0.106175, l6: 0.109386

[epoch:  99/100000, batch:    20/  187, ite: 9222] train loss: 0.116526, tar: 0.011911 
l0: 0.013293, l1: 0.014978, l2: 0.013632, l3: 0.012820, l4: 0.019246, l5: 0.019629, l6: 0.030709

[epoch:  99/100000, batch:    22/  187, ite: 9223] train loss: 0.116532, tar: 0.011912 
l0: 0.025777, l1: 0.027402, l2: 0.024835, l3: 0.030174, l4: 0.032421, l5: 0.039476, l6: 0.038889

[epoch:  99/100000, batch:    24/  187, ite: 9224] train loss: 0.116616, tar: 0.011924 
l0: 0.011441, l1: 0.012172, l2: 0.019106, l3: 0.019315, l4: 0.019784, l5: 0.017573, l6: 0.016523

[epoch:  99/100000, batch:    26/  187, ite: 9225] train loss: 0.116615, tar: 0.011923 
l0: 0.073101, l1: 0.074146, l2: 0.089618, l3: 0.097750, l4: 0.120934, l5: 0.125134, l6: 0.147657

[epoch:  99/100000, batch:    28/  187, ite: 9226] train loss: 0.117114, tar: 0.011973 
l0: 0.020383, l1: 0.020981, l2: 0.024401, l3: 0.032884, l4: 0.036457, l5: 0.030345, l6: 0.027024

[epoch:  99/100000, batch:    30/  187, ite: 9227] train loss: 0.117176, tar: 0.011980 
l0: 0.038879, l1: 0.043677, l2: 0.054344, l3: 0.053609, l4: 0.062309, l5: 0.055393, l6: 0.050283

[epoch:  99/100000, batch:    32/  187, ite: 9228] train loss: 0.117372, tar: 0.012002 
l0: 0.025196, l1: 0.023886, l2: 0.028244, l3: 0.038766, l4: 0.052172, l5: 0.043413, l6: 0.055338

[epoch:  99/100000, batch:    34/  187, ite: 9229] train loss: 0.117494, tar: 0.012013 
l0: 0.019396, l1: 0.018146, l2: 0.025389, l3: 0.027595, l4: 0.042190, l5: 0.033995, l6: 0.037783

[epoch:  99/100000, batch:    36/  187, ite: 9230] train loss: 0.117565, tar: 0.012019 
l0: 0.018779, l1: 0.019467, l2: 0.018937, l3: 0.021844, l4: 0.032515, l5: 0.028679, l6: 0.025732

[epoch:  99/100000, batch:    38/  187, ite: 9231] train loss: 0.117604, tar: 0.012024 
l0: 0.026912, l1: 0.029878, l2: 0.030776, l3: 0.033184, l4: 0.039768, l5: 0.030647, l6: 0.044150

[epoch:  99/100000, batch:    40/  187, ite: 9232] train loss: 0.117700, tar: 0.012036 
l0: 0.029984, l1: 0.041787, l2: 0.046821, l3: 0.039454, l4: 0.045183, l5: 0.034439, l6: 0.038649

[epoch:  99/100000, batch:    42/  187, ite: 9233] train loss: 0.117828, tar: 0.012051 
l0: 0.036404, l1: 0.032773, l2: 0.039189, l3: 0.039502, l4: 0.047258, l5: 0.061756, l6: 0.071253

[epoch:  99/100000, batch:    44/  187, ite: 9234] train loss: 0.117999, tar: 0.012070 
l0: 0.014400, l1: 0.014574, l2: 0.019977, l3: 0.021311, l4: 0.030910, l5: 0.025963, l6: 0.031696

[epoch:  99/100000, batch:    46/  187, ite: 9235] train loss: 0.118032, tar: 0.012072 
l0: 0.015657, l1: 0.017547, l2: 0.019154, l3: 0.018879, l4: 0.027559, l5: 0.022819, l6: 0.023391

[epoch:  99/100000, batch:    48/  187, ite: 9236] train loss: 0.118054, tar: 0.012075 
l0: 0.023311, l1: 0.028990, l2: 0.026278, l3: 0.028315, l4: 0.044087, l5: 0.043440, l6: 0.055167

[epoch:  99/100000, batch:    50/  187, ite: 9237] train loss: 0.118160, tar: 0.012084 
l0: 0.053204, l1: 0.058350, l2: 0.063536, l3: 0.057913, l4: 0.056095, l5: 0.058681, l6: 0.088443

[epoch:  99/100000, batch:    52/  187, ite: 9238] train loss: 0.118417, tar: 0.012118 
l0: 0.014573, l1: 0.013881, l2: 0.017735, l3: 0.017992, l4: 0.033306, l5: 0.039809, l6: 0.056787

[epoch:  99/100000, batch:    54/  187, ite: 9239] train loss: 0.118478, tar: 0.012120 
l0: 0.017374, l1: 0.017158, l2: 0.023588, l3: 0.028269, l4: 0.032125, l5: 0.028682, l6: 0.027550

[epoch:  99/100000, batch:    56/  187, ite: 9240] train loss: 0.118523, tar: 0.012124 
l0: 0.015698, l1: 0.017022, l2: 0.025630, l3: 0.024692, l4: 0.034852, l5: 0.032854, l6: 0.035632

[epoch:  99/100000, batch:    58/  187, ite: 9241] train loss: 0.118578, tar: 0.012127 
l0: 0.019443, l1: 0.020023, l2: 0.043621, l3: 0.036790, l4: 0.042193, l5: 0.033963, l6: 0.030561

[epoch:  99/100000, batch:    60/  187, ite: 9242] train loss: 0.118665, tar: 0.012133 
l0: 0.041922, l1: 0.044080, l2: 0.038903, l3: 0.039328, l4: 0.051221, l5: 0.057573, l6: 0.064287

[epoch:  99/100000, batch:    62/  187, ite: 9243] train loss: 0.118841, tar: 0.012157 
l0: 0.016050, l1: 0.014129, l2: 0.023120, l3: 0.024451, l4: 0.043200, l5: 0.049707, l6: 0.057602

[epoch:  99/100000, batch:    64/  187, ite: 9244] train loss: 0.118929, tar: 0.012160 
l0: 0.017991, l1: 0.016690, l2: 0.019637, l3: 0.020834, l4: 0.030341, l5: 0.037011, l6: 0.036868

[epoch:  99/100000, batch:    66/  187, ite: 9245] train loss: 0.118977, tar: 0.012164 
l0: 0.020690, l1: 0.023476, l2: 0.024659, l3: 0.028634, l4: 0.034981, l5: 0.029193, l6: 0.034528

[epoch:  99/100000, batch:    68/  187, ite: 9246] train loss: 0.119039, tar: 0.012171 
l0: 0.022034, l1: 0.021684, l2: 0.037725, l3: 0.042378, l4: 0.031561, l5: 0.031049, l6: 0.029261

[epoch:  99/100000, batch:    70/  187, ite: 9247] train loss: 0.119117, tar: 0.012179 
l0: 0.013455, l1: 0.018389, l2: 0.018170, l3: 0.021252, l4: 0.017639, l5: 0.014252, l6: 0.011343

[epoch:  99/100000, batch:    72/  187, ite: 9248] train loss: 0.119113, tar: 0.012180 
l0: 0.055102, l1: 0.068442, l2: 0.029129, l3: 0.025943, l4: 0.039894, l5: 0.058538, l6: 0.064821

[epoch:  99/100000, batch:    74/  187, ite: 9249] train loss: 0.119291, tar: 0.012214 
l0: 0.037017, l1: 0.043698, l2: 0.041791, l3: 0.037731, l4: 0.045665, l5: 0.046348, l6: 0.029916

[epoch:  99/100000, batch:    76/  187, ite: 9250] train loss: 0.119422, tar: 0.012234 
l0: 0.013379, l1: 0.013298, l2: 0.011443, l3: 0.012421, l4: 0.017408, l5: 0.027949, l6: 0.022181

[epoch:  99/100000, batch:    78/  187, ite: 9251] train loss: 0.119421, tar: 0.012235 
l0: 0.029548, l1: 0.028445, l2: 0.038273, l3: 0.034729, l4: 0.054977, l5: 0.056153, l6: 0.048712

[epoch:  99/100000, batch:    80/  187, ite: 9252] train loss: 0.119558, tar: 0.012249 
l0: 0.031888, l1: 0.038076, l2: 0.036217, l3: 0.034581, l4: 0.046872, l5: 0.039336, l6: 0.035414

[epoch:  99/100000, batch:    82/  187, ite: 9253] train loss: 0.119672, tar: 0.012265 
l0: 0.021132, l1: 0.022355, l2: 0.019791, l3: 0.020735, l4: 0.025516, l5: 0.027186, l6: 0.030005

[epoch:  99/100000, batch:    84/  187, ite: 9254] train loss: 0.119709, tar: 0.012272 
l0: 0.017691, l1: 0.017285, l2: 0.019615, l3: 0.018323, l4: 0.030573, l5: 0.030666, l6: 0.034616

[epoch:  99/100000, batch:    86/  187, ite: 9255] train loss: 0.119748, tar: 0.012276 
l0: 0.015735, l1: 0.015298, l2: 0.012786, l3: 0.014815, l4: 0.025414, l5: 0.030267, l6: 0.029624

[epoch:  99/100000, batch:    88/  187, ite: 9256] train loss: 0.119767, tar: 0.012279 
l0: 0.044266, l1: 0.041777, l2: 0.027752, l3: 0.029305, l4: 0.056826, l5: 0.071209, l6: 0.071304

[epoch:  99/100000, batch:    90/  187, ite: 9257] train loss: 0.119945, tar: 0.012304 
l0: 0.019668, l1: 0.019400, l2: 0.025871, l3: 0.026638, l4: 0.034831, l5: 0.039338, l6: 0.043450

[epoch:  99/100000, batch:    92/  187, ite: 9258] train loss: 0.120016, tar: 0.012310 
l0: 0.011805, l1: 0.013012, l2: 0.016120, l3: 0.017952, l4: 0.019421, l5: 0.016847, l6: 0.019580

[epoch:  99/100000, batch:    94/  187, ite: 9259] train loss: 0.120011, tar: 0.012310 
l0: 0.015606, l1: 0.016548, l2: 0.018312, l3: 0.018025, l4: 0.025814, l5: 0.027456, l6: 0.030364

[epoch:  99/100000, batch:    96/  187, ite: 9260] train loss: 0.120037, tar: 0.012312 
l0: 0.024714, l1: 0.029286, l2: 0.024697, l3: 0.022685, l4: 0.037264, l5: 0.031221, l6: 0.020304

[epoch:  99/100000, batch:    98/  187, ite: 9261] train loss: 0.120092, tar: 0.012322 
l0: 0.016279, l1: 0.018057, l2: 0.018178, l3: 0.016980, l4: 0.021608, l5: 0.021432, l6: 0.025843

[epoch:  99/100000, batch:   100/  187, ite: 9262] train loss: 0.120107, tar: 0.012325 
l0: 0.026862, l1: 0.032659, l2: 0.030831, l3: 0.026933, l4: 0.041659, l5: 0.037172, l6: 0.043834

[epoch:  99/100000, batch:   102/  187, ite: 9263] train loss: 0.120202, tar: 0.012337 
l0: 0.022368, l1: 0.017481, l2: 0.026990, l3: 0.028712, l4: 0.039845, l5: 0.057683, l6: 0.068819

[epoch:  99/100000, batch:   104/  187, ite: 9264] train loss: 0.120314, tar: 0.012345 
l0: 0.017583, l1: 0.018759, l2: 0.020488, l3: 0.022301, l4: 0.037317, l5: 0.029631, l6: 0.028101

[epoch:  99/100000, batch:   106/  187, ite: 9265] train loss: 0.120357, tar: 0.012349 
l0: 0.008834, l1: 0.009572, l2: 0.009759, l3: 0.009438, l4: 0.010784, l5: 0.010616, l6: 0.015848

[epoch:  99/100000, batch:   108/  187, ite: 9266] train loss: 0.120321, tar: 0.012346 
l0: 0.029040, l1: 0.027100, l2: 0.034634, l3: 0.037859, l4: 0.051381, l5: 0.055737, l6: 0.045757

[epoch:  99/100000, batch:   110/  187, ite: 9267] train loss: 0.120448, tar: 0.012359 
l0: 0.018603, l1: 0.018302, l2: 0.021457, l3: 0.024398, l4: 0.029013, l5: 0.030781, l6: 0.028427

[epoch:  99/100000, batch:   112/  187, ite: 9268] train loss: 0.120488, tar: 0.012364 
l0: 0.017115, l1: 0.017139, l2: 0.020328, l3: 0.020349, l4: 0.027201, l5: 0.027731, l6: 0.033062

[epoch:  99/100000, batch:   114/  187, ite: 9269] train loss: 0.120521, tar: 0.012368 
l0: 0.022937, l1: 0.023699, l2: 0.020948, l3: 0.021442, l4: 0.031760, l5: 0.038009, l6: 0.040056

[epoch:  99/100000, batch:   116/  187, ite: 9270] train loss: 0.120583, tar: 0.012376 
l0: 0.019787, l1: 0.020272, l2: 0.019077, l3: 0.019896, l4: 0.030189, l5: 0.025528, l6: 0.040102

[epoch:  99/100000, batch:   118/  187, ite: 9271] train loss: 0.120625, tar: 0.012382 
l0: 0.018013, l1: 0.015550, l2: 0.018150, l3: 0.019782, l4: 0.033385, l5: 0.042761, l6: 0.042107

[epoch:  99/100000, batch:   120/  187, ite: 9272] train loss: 0.120680, tar: 0.012387 
l0: 0.021784, l1: 0.024923, l2: 0.026452, l3: 0.027918, l4: 0.034520, l5: 0.033681, l6: 0.028594

[epoch:  99/100000, batch:   122/  187, ite: 9273] train loss: 0.120740, tar: 0.012394 
l0: 0.016137, l1: 0.017690, l2: 0.018105, l3: 0.018430, l4: 0.023200, l5: 0.017957, l6: 0.020944

[epoch:  99/100000, batch:   124/  187, ite: 9274] train loss: 0.120750, tar: 0.012397 
l0: 0.033699, l1: 0.033538, l2: 0.040334, l3: 0.046947, l4: 0.058288, l5: 0.050089, l6: 0.045593

[epoch:  99/100000, batch:   126/  187, ite: 9275] train loss: 0.120897, tar: 0.012414 
l0: 0.014618, l1: 0.014487, l2: 0.016711, l3: 0.018575, l4: 0.027165, l5: 0.023903, l6: 0.033520

[epoch:  99/100000, batch:   128/  187, ite: 9276] train loss: 0.120919, tar: 0.012415 
l0: 0.017416, l1: 0.016154, l2: 0.019984, l3: 0.021627, l4: 0.040344, l5: 0.037850, l6: 0.048615

[epoch:  99/100000, batch:   130/  187, ite: 9277] train loss: 0.120982, tar: 0.012419 
l0: 0.019714, l1: 0.020402, l2: 0.020125, l3: 0.022625, l4: 0.032671, l5: 0.037909, l6: 0.046446

[epoch:  99/100000, batch:   132/  187, ite: 9278] train loss: 0.121044, tar: 0.012425 
l0: 0.033707, l1: 0.031974, l2: 0.036653, l3: 0.042806, l4: 0.046292, l5: 0.043220, l6: 0.048138

[epoch:  99/100000, batch:   134/  187, ite: 9279] train loss: 0.121171, tar: 0.012442 
l0: 0.015349, l1: 0.015873, l2: 0.019668, l3: 0.021343, l4: 0.024180, l5: 0.019182, l6: 0.018091

[epoch:  99/100000, batch:   136/  187, ite: 9280] train loss: 0.121180, tar: 0.012444 
l0: 0.013096, l1: 0.013446, l2: 0.016569, l3: 0.018548, l4: 0.038057, l5: 0.033435, l6: 0.023180

[epoch:  99/100000, batch:   138/  187, ite: 9281] train loss: 0.121208, tar: 0.012444 
l0: 0.031264, l1: 0.030784, l2: 0.033579, l3: 0.031911, l4: 0.037444, l5: 0.043040, l6: 0.044481

[epoch:  99/100000, batch:   140/  187, ite: 9282] train loss: 0.121310, tar: 0.012459 
l0: 0.025350, l1: 0.030440, l2: 0.024502, l3: 0.024615, l4: 0.027314, l5: 0.029366, l6: 0.030344

[epoch:  99/100000, batch:   142/  187, ite: 9283] train loss: 0.121365, tar: 0.012469 
l0: 0.026296, l1: 0.026129, l2: 0.028396, l3: 0.029622, l4: 0.038961, l5: 0.040492, l6: 0.047735

[epoch:  99/100000, batch:   144/  187, ite: 9284] train loss: 0.121456, tar: 0.012480 
l0: 0.031510, l1: 0.031775, l2: 0.025214, l3: 0.031217, l4: 0.085455, l5: 0.069307, l6: 0.071394

[epoch:  99/100000, batch:   146/  187, ite: 9285] train loss: 0.121630, tar: 0.012495 
l0: 0.018562, l1: 0.019828, l2: 0.017606, l3: 0.020991, l4: 0.020115, l5: 0.019788, l6: 0.023539

[epoch:  99/100000, batch:   148/  187, ite: 9286] train loss: 0.121645, tar: 0.012499 
l0: 0.010572, l1: 0.012444, l2: 0.013409, l3: 0.012806, l4: 0.013195, l5: 0.013712, l6: 0.013580

[epoch:  99/100000, batch:   150/  187, ite: 9287] train loss: 0.121620, tar: 0.012498 
l0: 0.007401, l1: 0.010055, l2: 0.011067, l3: 0.012783, l4: 0.021513, l5: 0.018497, l6: 0.020999

[epoch:  99/100000, batch:   152/  187, ite: 9288] train loss: 0.121605, tar: 0.012494 
l0: 0.020402, l1: 0.022138, l2: 0.027218, l3: 0.032381, l4: 0.048672, l5: 0.033800, l6: 0.020848

[epoch:  99/100000, batch:   154/  187, ite: 9289] train loss: 0.121670, tar: 0.012500 
l0: 0.067881, l1: 0.074243, l2: 0.080125, l3: 0.078374, l4: 0.082563, l5: 0.074366, l6: 0.060315

[epoch:  99/100000, batch:   156/  187, ite: 9290] train loss: 0.121977, tar: 0.012543 
l0: 0.011871, l1: 0.012502, l2: 0.016812, l3: 0.016097, l4: 0.017267, l5: 0.015790, l6: 0.027793

[epoch:  99/100000, batch:   158/  187, ite: 9291] train loss: 0.121975, tar: 0.012543 
l0: 0.030303, l1: 0.034268, l2: 0.031795, l3: 0.028944, l4: 0.037913, l5: 0.031126, l6: 0.035314

[epoch:  99/100000, batch:   160/  187, ite: 9292] train loss: 0.122058, tar: 0.012556 
l0: 0.020327, l1: 0.021470, l2: 0.026976, l3: 0.029141, l4: 0.040666, l5: 0.034685, l6: 0.041542

[epoch:  99/100000, batch:   162/  187, ite: 9293] train loss: 0.122130, tar: 0.012562 
l0: 0.018125, l1: 0.017746, l2: 0.022551, l3: 0.023674, l4: 0.027381, l5: 0.026520, l6: 0.029713

[epoch:  99/100000, batch:   164/  187, ite: 9294] train loss: 0.122163, tar: 0.012567 
l0: 0.018483, l1: 0.018623, l2: 0.021771, l3: 0.022591, l4: 0.040343, l5: 0.047277, l6: 0.033964

[epoch:  99/100000, batch:   166/  187, ite: 9295] train loss: 0.122226, tar: 0.012571 
l0: 0.019864, l1: 0.020756, l2: 0.025094, l3: 0.024254, l4: 0.032378, l5: 0.026559, l6: 0.033379

[epoch:  99/100000, batch:   168/  187, ite: 9296] train loss: 0.122272, tar: 0.012577 
l0: 0.019389, l1: 0.020745, l2: 0.021186, l3: 0.021342, l4: 0.021946, l5: 0.021129, l6: 0.020951

[epoch:  99/100000, batch:   170/  187, ite: 9297] train loss: 0.122291, tar: 0.012582 
l0: 0.010729, l1: 0.010619, l2: 0.012692, l3: 0.013440, l4: 0.030268, l5: 0.025224, l6: 0.024753

[epoch:  99/100000, batch:   172/  187, ite: 9298] train loss: 0.122295, tar: 0.012581 
l0: 0.021317, l1: 0.020999, l2: 0.024699, l3: 0.029231, l4: 0.028839, l5: 0.029404, l6: 0.035345

[epoch:  99/100000, batch:   174/  187, ite: 9299] train loss: 0.122347, tar: 0.012587 
l0: 0.013993, l1: 0.014167, l2: 0.014557, l3: 0.015987, l4: 0.030354, l5: 0.026590, l6: 0.021219

[epoch:  99/100000, batch:   176/  187, ite: 9300] train loss: 0.122358, tar: 0.012588 
l0: 0.025722, l1: 0.028538, l2: 0.030711, l3: 0.029536, l4: 0.028598, l5: 0.025659, l6: 0.026558

[epoch:  99/100000, batch:   178/  187, ite: 9301] train loss: 0.122414, tar: 0.012598 
l0: 0.016441, l1: 0.016850, l2: 0.019009, l3: 0.018941, l4: 0.035166, l5: 0.029614, l6: 0.037124

[epoch:  99/100000, batch:   180/  187, ite: 9302] train loss: 0.122453, tar: 0.012601 
l0: 0.025113, l1: 0.024756, l2: 0.031976, l3: 0.033648, l4: 0.051883, l5: 0.048554, l6: 0.041883

[epoch:  99/100000, batch:   182/  187, ite: 9303] train loss: 0.122557, tar: 0.012611 
l0: 0.011907, l1: 0.011191, l2: 0.013498, l3: 0.015025, l4: 0.030527, l5: 0.026611, l6: 0.029409

[epoch:  99/100000, batch:   184/  187, ite: 9304] train loss: 0.122569, tar: 0.012610 
l0: 0.013892, l1: 0.015012, l2: 0.015275, l3: 0.016214, l4: 0.016227, l5: 0.015688, l6: 0.017476

[epoch:  99/100000, batch:   186/  187, ite: 9305] train loss: 0.122559, tar: 0.012611 
l0: 0.018101, l1: 0.017504, l2: 0.022932, l3: 0.020754, l4: 0.028754, l5: 0.028168, l6: 0.033600

[epoch:  99/100000, batch:   188/  187, ite: 9306] train loss: 0.122596, tar: 0.012616 
l0: 0.025706, l1: 0.026209, l2: 0.028471, l3: 0.032590, l4: 0.032276, l5: 0.029218, l6: 0.028692

[epoch: 100/100000, batch:     2/  187, ite: 9307] train loss: 0.122657, tar: 0.012626 
l0: 0.012230, l1: 0.012556, l2: 0.015182, l3: 0.013181, l4: 0.018483, l5: 0.018032, l6: 0.018702

[epoch: 100/100000, batch:     4/  187, ite: 9308] train loss: 0.122646, tar: 0.012625 
l0: 0.009822, l1: 0.009642, l2: 0.011200, l3: 0.010508, l4: 0.015029, l5: 0.016752, l6: 0.015731

[epoch: 100/100000, batch:     6/  187, ite: 9309] train loss: 0.122620, tar: 0.012623 
l0: 0.018265, l1: 0.020598, l2: 0.015145, l3: 0.015172, l4: 0.020272, l5: 0.021116, l6: 0.020640

[epoch: 100/100000, batch:     8/  187, ite: 9310] train loss: 0.122627, tar: 0.012628 
l0: 0.018715, l1: 0.019802, l2: 0.021646, l3: 0.020436, l4: 0.026211, l5: 0.023789, l6: 0.029305

[epoch: 100/100000, batch:    10/  187, ite: 9311] train loss: 0.122655, tar: 0.012632 
l0: 0.033351, l1: 0.039657, l2: 0.050627, l3: 0.040696, l4: 0.024980, l5: 0.024002, l6: 0.024076

[epoch: 100/100000, batch:    12/  187, ite: 9312] train loss: 0.122743, tar: 0.012648 
l0: 0.026703, l1: 0.025849, l2: 0.029628, l3: 0.030366, l4: 0.035602, l5: 0.036267, l6: 0.042416

[epoch: 100/100000, batch:    14/  187, ite: 9313] train loss: 0.122822, tar: 0.012659 
l0: 0.012600, l1: 0.012646, l2: 0.013428, l3: 0.014540, l4: 0.016669, l5: 0.016136, l6: 0.020539

[epoch: 100/100000, batch:    16/  187, ite: 9314] train loss: 0.122810, tar: 0.012659 
l0: 0.010980, l1: 0.012165, l2: 0.017237, l3: 0.016813, l4: 0.020847, l5: 0.013362, l6: 0.014767

[epoch: 100/100000, batch:    18/  187, ite: 9315] train loss: 0.122797, tar: 0.012657 
l0: 0.009230, l1: 0.009992, l2: 0.010217, l3: 0.010830, l4: 0.020901, l5: 0.017028, l6: 0.013436

[epoch: 100/100000, batch:    20/  187, ite: 9316] train loss: 0.122773, tar: 0.012655 
l0: 0.010380, l1: 0.010913, l2: 0.010276, l3: 0.011123, l4: 0.014111, l5: 0.012917, l6: 0.009546

[epoch: 100/100000, batch:    22/  187, ite: 9317] train loss: 0.122740, tar: 0.012653 
l0: 0.014228, l1: 0.014106, l2: 0.015429, l3: 0.014583, l4: 0.022579, l5: 0.020263, l6: 0.023916

[epoch: 100/100000, batch:    24/  187, ite: 9318] train loss: 0.122742, tar: 0.012654 
l0: 0.010082, l1: 0.009902, l2: 0.011799, l3: 0.012101, l4: 0.022752, l5: 0.020687, l6: 0.016475

[epoch: 100/100000, batch:    26/  187, ite: 9319] train loss: 0.122728, tar: 0.012652 
l0: 0.011859, l1: 0.012606, l2: 0.012848, l3: 0.012626, l4: 0.021940, l5: 0.022893, l6: 0.020647

[epoch: 100/100000, batch:    28/  187, ite: 9320] train loss: 0.122722, tar: 0.012652 
l0: 0.014817, l1: 0.017156, l2: 0.017761, l3: 0.015540, l4: 0.021347, l5: 0.020418, l6: 0.021799

[epoch: 100/100000, batch:    30/  187, ite: 9321] train loss: 0.122727, tar: 0.012653 
l0: 0.017863, l1: 0.021288, l2: 0.016767, l3: 0.016191, l4: 0.040546, l5: 0.031389, l6: 0.030969

[epoch: 100/100000, batch:    32/  187, ite: 9322] train loss: 0.122766, tar: 0.012657 
l0: 0.009189, l1: 0.009508, l2: 0.009645, l3: 0.010799, l4: 0.017806, l5: 0.014692, l6: 0.018244

[epoch: 100/100000, batch:    34/  187, ite: 9323] train loss: 0.122741, tar: 0.012655 
l0: 0.009875, l1: 0.010173, l2: 0.014977, l3: 0.014101, l4: 0.014747, l5: 0.016668, l6: 0.016926

[epoch: 100/100000, batch:    36/  187, ite: 9324] train loss: 0.122722, tar: 0.012653 
l0: 0.009195, l1: 0.010117, l2: 0.011942, l3: 0.011414, l4: 0.021203, l5: 0.020867, l6: 0.015790

[epoch: 100/100000, batch:    38/  187, ite: 9325] train loss: 0.122706, tar: 0.012650 
l0: 0.009904, l1: 0.009276, l2: 0.009360, l3: 0.010409, l4: 0.020462, l5: 0.021275, l6: 0.020993

[epoch: 100/100000, batch:    40/  187, ite: 9326] train loss: 0.122690, tar: 0.012648 
l0: 0.010222, l1: 0.009697, l2: 0.015332, l3: 0.014809, l4: 0.014778, l5: 0.018727, l6: 0.013625

[epoch: 100/100000, batch:    42/  187, ite: 9327] train loss: 0.122671, tar: 0.012646 
l0: 0.022148, l1: 0.025827, l2: 0.023470, l3: 0.021287, l4: 0.040075, l5: 0.031801, l6: 0.022686

[epoch: 100/100000, batch:    44/  187, ite: 9328] train loss: 0.122719, tar: 0.012653 
l0: 0.013208, l1: 0.012925, l2: 0.014340, l3: 0.013395, l4: 0.024251, l5: 0.026607, l6: 0.022689

[epoch: 100/100000, batch:    46/  187, ite: 9329] train loss: 0.122723, tar: 0.012654 
l0: 0.012600, l1: 0.013836, l2: 0.015536, l3: 0.015834, l4: 0.018888, l5: 0.017530, l6: 0.019970

[epoch: 100/100000, batch:    48/  187, ite: 9330] train loss: 0.122716, tar: 0.012654 
l0: 0.007647, l1: 0.007699, l2: 0.008835, l3: 0.008036, l4: 0.014432, l5: 0.012846, l6: 0.011758

[epoch: 100/100000, batch:    50/  187, ite: 9331] train loss: 0.122678, tar: 0.012650 
l0: 0.018114, l1: 0.015434, l2: 0.017925, l3: 0.022739, l4: 0.028065, l5: 0.038616, l6: 0.036803

[epoch: 100/100000, batch:    52/  187, ite: 9332] train loss: 0.122719, tar: 0.012654 
l0: 0.008656, l1: 0.008508, l2: 0.010514, l3: 0.009813, l4: 0.014890, l5: 0.017406, l6: 0.015846

[epoch: 100/100000, batch:    54/  187, ite: 9333] train loss: 0.122691, tar: 0.012651 
l0: 0.020395, l1: 0.022369, l2: 0.026301, l3: 0.031942, l4: 0.035556, l5: 0.034707, l6: 0.037259

[epoch: 100/100000, batch:    56/  187, ite: 9334] train loss: 0.122756, tar: 0.012657 
l0: 0.008083, l1: 0.008524, l2: 0.009748, l3: 0.008450, l4: 0.014718, l5: 0.016495, l6: 0.015573

[epoch: 100/100000, batch:    58/  187, ite: 9335] train loss: 0.122725, tar: 0.012653 
l0: 0.009387, l1: 0.010506, l2: 0.009229, l3: 0.008327, l4: 0.013776, l5: 0.013433, l6: 0.015064

[epoch: 100/100000, batch:    60/  187, ite: 9336] train loss: 0.122693, tar: 0.012651 
l0: 0.013690, l1: 0.014481, l2: 0.017045, l3: 0.013646, l4: 0.024395, l5: 0.024291, l6: 0.027866

[epoch: 100/100000, batch:    62/  187, ite: 9337] train loss: 0.122702, tar: 0.012652 
l0: 0.015206, l1: 0.016073, l2: 0.018614, l3: 0.021230, l4: 0.022257, l5: 0.017874, l6: 0.021342

[epoch: 100/100000, batch:    64/  187, ite: 9338] train loss: 0.122709, tar: 0.012654 
l0: 0.010263, l1: 0.010086, l2: 0.011566, l3: 0.011969, l4: 0.027608, l5: 0.018924, l6: 0.021940

[epoch: 100/100000, batch:    66/  187, ite: 9339] train loss: 0.122702, tar: 0.012652 
l0: 0.014283, l1: 0.014101, l2: 0.014024, l3: 0.013578, l4: 0.021876, l5: 0.024543, l6: 0.023700

[epoch: 100/100000, batch:    68/  187, ite: 9340] train loss: 0.122704, tar: 0.012653 
l0: 0.015367, l1: 0.014915, l2: 0.015904, l3: 0.015648, l4: 0.041265, l5: 0.034394, l6: 0.030694

[epoch: 100/100000, batch:    70/  187, ite: 9341] train loss: 0.122738, tar: 0.012655 
l0: 0.008710, l1: 0.009039, l2: 0.008967, l3: 0.010032, l4: 0.024958, l5: 0.019548, l6: 0.017395

[epoch: 100/100000, batch:    72/  187, ite: 9342] train loss: 0.122720, tar: 0.012652 
l0: 0.012362, l1: 0.012871, l2: 0.014033, l3: 0.014162, l4: 0.024891, l5: 0.022403, l6: 0.021156

[epoch: 100/100000, batch:    74/  187, ite: 9343] train loss: 0.122720, tar: 0.012652 
l0: 0.015254, l1: 0.016705, l2: 0.014129, l3: 0.014001, l4: 0.024140, l5: 0.023203, l6: 0.026375

[epoch: 100/100000, batch:    76/  187, ite: 9344] train loss: 0.122728, tar: 0.012654 
l0: 0.013430, l1: 0.013169, l2: 0.013593, l3: 0.020015, l4: 0.030906, l5: 0.024486, l6: 0.019875

[epoch: 100/100000, batch:    78/  187, ite: 9345] train loss: 0.122737, tar: 0.012654 
l0: 0.014203, l1: 0.015929, l2: 0.019043, l3: 0.018945, l4: 0.020445, l5: 0.016837, l6: 0.014991

[epoch: 100/100000, batch:    80/  187, ite: 9346] train loss: 0.122736, tar: 0.012655 
l0: 0.012458, l1: 0.013823, l2: 0.015063, l3: 0.014414, l4: 0.016843, l5: 0.016857, l6: 0.017503

[epoch: 100/100000, batch:    82/  187, ite: 9347] train loss: 0.122724, tar: 0.012655 
l0: 0.011974, l1: 0.011711, l2: 0.012148, l3: 0.013468, l4: 0.016660, l5: 0.014152, l6: 0.017002

[epoch: 100/100000, batch:    84/  187, ite: 9348] train loss: 0.122705, tar: 0.012655 
l0: 0.010830, l1: 0.010139, l2: 0.015795, l3: 0.016045, l4: 0.015406, l5: 0.017347, l6: 0.018276

[epoch: 100/100000, batch:    86/  187, ite: 9349] train loss: 0.122691, tar: 0.012653 
l0: 0.027162, l1: 0.021127, l2: 0.031556, l3: 0.043805, l4: 0.089508, l5: 0.080274, l6: 0.090477

[epoch: 100/100000, batch:    88/  187, ite: 9350] train loss: 0.122884, tar: 0.012664 
l0: 0.019845, l1: 0.020060, l2: 0.026280, l3: 0.024323, l4: 0.044202, l5: 0.034090, l6: 0.032675

[epoch: 100/100000, batch:    90/  187, ite: 9351] train loss: 0.122943, tar: 0.012670 
l0: 0.012605, l1: 0.013752, l2: 0.012900, l3: 0.012707, l4: 0.024709, l5: 0.023668, l6: 0.025627

[epoch: 100/100000, batch:    92/  187, ite: 9352] train loss: 0.122945, tar: 0.012670 
l0: 0.008584, l1: 0.010018, l2: 0.010913, l3: 0.009208, l4: 0.013301, l5: 0.010427, l6: 0.011216

[epoch: 100/100000, batch:    94/  187, ite: 9353] train loss: 0.122908, tar: 0.012666 
l0: 0.009224, l1: 0.009274, l2: 0.012294, l3: 0.012345, l4: 0.020953, l5: 0.016901, l6: 0.023474

[epoch: 100/100000, batch:    96/  187, ite: 9354] train loss: 0.122895, tar: 0.012664 
l0: 0.014480, l1: 0.014998, l2: 0.018528, l3: 0.019523, l4: 0.020861, l5: 0.018357, l6: 0.016965

[epoch: 100/100000, batch:    98/  187, ite: 9355] train loss: 0.122895, tar: 0.012665 
l0: 0.038847, l1: 0.040516, l2: 0.037635, l3: 0.044728, l4: 0.045288, l5: 0.036282, l6: 0.041112

[epoch: 100/100000, batch:   100/  187, ite: 9356] train loss: 0.123014, tar: 0.012685 
l0: 0.018294, l1: 0.017850, l2: 0.028186, l3: 0.028813, l4: 0.030024, l5: 0.023328, l6: 0.028612

[epoch: 100/100000, batch:   102/  187, ite: 9357] train loss: 0.123053, tar: 0.012689 
l0: 0.016863, l1: 0.017354, l2: 0.016419, l3: 0.017866, l4: 0.030473, l5: 0.025748, l6: 0.025436

[epoch: 100/100000, batch:   104/  187, ite: 9358] train loss: 0.123073, tar: 0.012692 
l0: 0.009739, l1: 0.011465, l2: 0.013395, l3: 0.013609, l4: 0.017084, l5: 0.008868, l6: 0.011209

[epoch: 100/100000, batch:   106/  187, ite: 9359] train loss: 0.123045, tar: 0.012690 
l0: 0.011625, l1: 0.012082, l2: 0.014162, l3: 0.018046, l4: 0.030930, l5: 0.025938, l6: 0.023927

[epoch: 100/100000, batch:   108/  187, ite: 9360] train loss: 0.123055, tar: 0.012689 
l0: 0.007819, l1: 0.007068, l2: 0.010485, l3: 0.011258, l4: 0.022337, l5: 0.026827, l6: 0.024639

[epoch: 100/100000, batch:   110/  187, ite: 9361] train loss: 0.123046, tar: 0.012685 
l0: 0.012936, l1: 0.013834, l2: 0.013807, l3: 0.018469, l4: 0.030226, l5: 0.031145, l6: 0.017701

[epoch: 100/100000, batch:   112/  187, ite: 9362] train loss: 0.123057, tar: 0.012685 
l0: 0.022287, l1: 0.024774, l2: 0.035439, l3: 0.034966, l4: 0.022981, l5: 0.020764, l6: 0.022963

[epoch: 100/100000, batch:   114/  187, ite: 9363] train loss: 0.123102, tar: 0.012692 
l0: 0.015625, l1: 0.016815, l2: 0.014921, l3: 0.014505, l4: 0.021769, l5: 0.022178, l6: 0.019225

[epoch: 100/100000, batch:   116/  187, ite: 9364] train loss: 0.123103, tar: 0.012695 
l0: 0.012911, l1: 0.012456, l2: 0.018419, l3: 0.020872, l4: 0.039243, l5: 0.032054, l6: 0.032166

[epoch: 100/100000, batch:   118/  187, ite: 9365] train loss: 0.123136, tar: 0.012695 
l0: 0.014462, l1: 0.014048, l2: 0.017868, l3: 0.018688, l4: 0.027657, l5: 0.026324, l6: 0.031278

[epoch: 100/100000, batch:   120/  187, ite: 9366] train loss: 0.123156, tar: 0.012696 
l0: 0.008759, l1: 0.011030, l2: 0.011715, l3: 0.011913, l4: 0.019319, l5: 0.016288, l6: 0.012271

[epoch: 100/100000, batch:   122/  187, ite: 9367] train loss: 0.123133, tar: 0.012693 
l0: 0.013470, l1: 0.014064, l2: 0.019433, l3: 0.018888, l4: 0.025491, l5: 0.024670, l6: 0.021715

[epoch: 100/100000, batch:   124/  187, ite: 9368] train loss: 0.123143, tar: 0.012694 
l0: 0.018561, l1: 0.019221, l2: 0.023842, l3: 0.020920, l4: 0.033490, l5: 0.032805, l6: 0.040651

[epoch: 100/100000, batch:   126/  187, ite: 9369] train loss: 0.123192, tar: 0.012698 
l0: 0.012505, l1: 0.012075, l2: 0.017105, l3: 0.018486, l4: 0.033407, l5: 0.028191, l6: 0.028336

[epoch: 100/100000, batch:   128/  187, ite: 9370] train loss: 0.123211, tar: 0.012698 
l0: 0.019527, l1: 0.016942, l2: 0.020457, l3: 0.023242, l4: 0.052017, l5: 0.047250, l6: 0.058091

[epoch: 100/100000, batch:   130/  187, ite: 9371] train loss: 0.123295, tar: 0.012703 
l0: 0.011152, l1: 0.013453, l2: 0.013824, l3: 0.013540, l4: 0.016717, l5: 0.015155, l6: 0.016463

[epoch: 100/100000, batch:   132/  187, ite: 9372] train loss: 0.123278, tar: 0.012702 
l0: 0.026129, l1: 0.024123, l2: 0.030871, l3: 0.031271, l4: 0.043073, l5: 0.040591, l6: 0.048370

[epoch: 100/100000, batch:   134/  187, ite: 9373] train loss: 0.123366, tar: 0.012712 
l0: 0.012169, l1: 0.011743, l2: 0.014100, l3: 0.015912, l4: 0.020699, l5: 0.021449, l6: 0.028417

[epoch: 100/100000, batch:   136/  187, ite: 9374] train loss: 0.123367, tar: 0.012711 
l0: 0.016275, l1: 0.018346, l2: 0.015838, l3: 0.016820, l4: 0.019593, l5: 0.023304, l6: 0.018901

[epoch: 100/100000, batch:   138/  187, ite: 9375] train loss: 0.123371, tar: 0.012714 
l0: 0.015094, l1: 0.013977, l2: 0.015469, l3: 0.019462, l4: 0.027010, l5: 0.043191, l6: 0.036798

[epoch: 100/100000, batch:   140/  187, ite: 9376] train loss: 0.123406, tar: 0.012715 
l0: 0.013877, l1: 0.014751, l2: 0.014417, l3: 0.016246, l4: 0.024985, l5: 0.021461, l6: 0.025158

[epoch: 100/100000, batch:   142/  187, ite: 9377] train loss: 0.123411, tar: 0.012716 
l0: 0.016430, l1: 0.015952, l2: 0.017201, l3: 0.017458, l4: 0.025461, l5: 0.023231, l6: 0.028710

[epoch: 100/100000, batch:   144/  187, ite: 9378] train loss: 0.123427, tar: 0.012719 
l0: 0.020644, l1: 0.017639, l2: 0.019200, l3: 0.019906, l4: 0.053234, l5: 0.053228, l6: 0.052961

[epoch: 100/100000, batch:   146/  187, ite: 9379] train loss: 0.123509, tar: 0.012725 
l0: 0.023498, l1: 0.024444, l2: 0.022855, l3: 0.025914, l4: 0.027440, l5: 0.027323, l6: 0.031749

[epoch: 100/100000, batch:   148/  187, ite: 9380] train loss: 0.123552, tar: 0.012733 
l0: 0.017168, l1: 0.018214, l2: 0.017975, l3: 0.021358, l4: 0.024531, l5: 0.017072, l6: 0.021822

[epoch: 100/100000, batch:   150/  187, ite: 9381] train loss: 0.123563, tar: 0.012736 
l0: 0.011138, l1: 0.010764, l2: 0.010477, l3: 0.010734, l4: 0.030502, l5: 0.025423, l6: 0.034307

[epoch: 100/100000, batch:   152/  187, ite: 9382] train loss: 0.123570, tar: 0.012735 
l0: 0.020063, l1: 0.020012, l2: 0.017762, l3: 0.023480, l4: 0.032055, l5: 0.028723, l6: 0.034430

[epoch: 100/100000, batch:   154/  187, ite: 9383] train loss: 0.123608, tar: 0.012740 
l0: 0.006380, l1: 0.006257, l2: 0.008517, l3: 0.009556, l4: 0.013602, l5: 0.014949, l6: 0.019329

[epoch: 100/100000, batch:   156/  187, ite: 9384] train loss: 0.123576, tar: 0.012735 
l0: 0.020591, l1: 0.018856, l2: 0.025259, l3: 0.030456, l4: 0.040597, l5: 0.042615, l6: 0.048178

[epoch: 100/100000, batch:   158/  187, ite: 9385] train loss: 0.123650, tar: 0.012741 
l0: 0.007618, l1: 0.007889, l2: 0.008168, l3: 0.010077, l4: 0.012549, l5: 0.014718, l6: 0.013222

[epoch: 100/100000, batch:   160/  187, ite: 9386] train loss: 0.123614, tar: 0.012737 
l0: 0.007789, l1: 0.008104, l2: 0.009161, l3: 0.009613, l4: 0.020447, l5: 0.012358, l6: 0.012623

[epoch: 100/100000, batch:   162/  187, ite: 9387] train loss: 0.123583, tar: 0.012734 
l0: 0.015056, l1: 0.013959, l2: 0.013656, l3: 0.018125, l4: 0.029953, l5: 0.030196, l6: 0.039371

[epoch: 100/100000, batch:   164/  187, ite: 9388] train loss: 0.123609, tar: 0.012735 
l0: 0.016913, l1: 0.016970, l2: 0.017817, l3: 0.018725, l4: 0.041890, l5: 0.047050, l6: 0.030803

[epoch: 100/100000, batch:   166/  187, ite: 9389] train loss: 0.123657, tar: 0.012738 
l0: 0.010437, l1: 0.009612, l2: 0.020063, l3: 0.022210, l4: 0.022004, l5: 0.019191, l6: 0.024828

[epoch: 100/100000, batch:   168/  187, ite: 9390] train loss: 0.123661, tar: 0.012737 
l0: 0.012597, l1: 0.013278, l2: 0.012287, l3: 0.014287, l4: 0.037388, l5: 0.033475, l6: 0.030128

[epoch: 100/100000, batch:   170/  187, ite: 9391] train loss: 0.123682, tar: 0.012737 
l0: 0.018811, l1: 0.019844, l2: 0.022218, l3: 0.025399, l4: 0.033441, l5: 0.027908, l6: 0.028582

[epoch: 100/100000, batch:   172/  187, ite: 9392] train loss: 0.123720, tar: 0.012741 
l0: 0.016481, l1: 0.018124, l2: 0.020847, l3: 0.016077, l4: 0.021583, l5: 0.022054, l6: 0.027995

[epoch: 100/100000, batch:   174/  187, ite: 9393] train loss: 0.123734, tar: 0.012744 
l0: 0.018644, l1: 0.018502, l2: 0.025615, l3: 0.022177, l4: 0.038687, l5: 0.035938, l6: 0.036836

[epoch: 100/100000, batch:   176/  187, ite: 9394] train loss: 0.123786, tar: 0.012748 
l0: 0.010504, l1: 0.010803, l2: 0.011036, l3: 0.012855, l4: 0.021480, l5: 0.015938, l6: 0.015402

[epoch: 100/100000, batch:   178/  187, ite: 9395] train loss: 0.123767, tar: 0.012746 
l0: 0.010247, l1: 0.010248, l2: 0.010523, l3: 0.011146, l4: 0.019637, l5: 0.017847, l6: 0.016511

[epoch: 100/100000, batch:   180/  187, ite: 9396] train loss: 0.123748, tar: 0.012745 
l0: 0.008763, l1: 0.009544, l2: 0.007565, l3: 0.009394, l4: 0.010697, l5: 0.009497, l6: 0.013901

[epoch: 100/100000, batch:   182/  187, ite: 9397] train loss: 0.123709, tar: 0.012742 
l0: 0.009036, l1: 0.010148, l2: 0.015737, l3: 0.013016, l4: 0.018036, l5: 0.012451, l6: 0.013577

[epoch: 100/100000, batch:   184/  187, ite: 9398] train loss: 0.123686, tar: 0.012739 
l0: 0.010078, l1: 0.010119, l2: 0.010695, l3: 0.011502, l4: 0.021181, l5: 0.025614, l6: 0.028470

[epoch: 100/100000, batch:   186/  187, ite: 9399] train loss: 0.123682, tar: 0.012737 
l0: 0.021601, l1: 0.022208, l2: 0.022413, l3: 0.018827, l4: 0.022648, l5: 0.020360, l6: 0.023715

[epoch: 100/100000, batch:   188/  187, ite: 9400] train loss: 0.123702, tar: 0.012743 
l0: 0.014732, l1: 0.014953, l2: 0.013837, l3: 0.018283, l4: 0.018936, l5: 0.017006, l6: 0.015511

[epoch: 101/100000, batch:     2/  187, ite: 9401] train loss: 0.123694, tar: 0.012745 
l0: 0.011501, l1: 0.011125, l2: 0.014018, l3: 0.013073, l4: 0.021441, l5: 0.022961, l6: 0.033214

[epoch: 101/100000, batch:     4/  187, ite: 9402] train loss: 0.123697, tar: 0.012744 
l0: 0.010672, l1: 0.010876, l2: 0.010476, l3: 0.009620, l4: 0.017205, l5: 0.016111, l6: 0.021586

[epoch: 101/100000, batch:     6/  187, ite: 9403] train loss: 0.123678, tar: 0.012743 
l0: 0.020439, l1: 0.022039, l2: 0.021242, l3: 0.024214, l4: 0.037542, l5: 0.030531, l6: 0.039663

[epoch: 101/100000, batch:     8/  187, ite: 9404] train loss: 0.123729, tar: 0.012748 
l0: 0.014313, l1: 0.014975, l2: 0.016581, l3: 0.016352, l4: 0.024303, l5: 0.020910, l6: 0.024051

[epoch: 101/100000, batch:    10/  187, ite: 9405] train loss: 0.123734, tar: 0.012749 
l0: 0.005520, l1: 0.004555, l2: 0.008904, l3: 0.009280, l4: 0.020333, l5: 0.019816, l6: 0.024993

[epoch: 101/100000, batch:    12/  187, ite: 9406] train loss: 0.123713, tar: 0.012744 
l0: 0.007450, l1: 0.007826, l2: 0.008043, l3: 0.007609, l4: 0.013763, l5: 0.012949, l6: 0.013101

[epoch: 101/100000, batch:    14/  187, ite: 9407] train loss: 0.123675, tar: 0.012740 
l0: 0.019702, l1: 0.020301, l2: 0.015450, l3: 0.017795, l4: 0.035666, l5: 0.033124, l6: 0.029359

[epoch: 101/100000, batch:    16/  187, ite: 9408] train loss: 0.123709, tar: 0.012745 
l0: 0.008827, l1: 0.009100, l2: 0.011584, l3: 0.011347, l4: 0.014329, l5: 0.013825, l6: 0.017614

[epoch: 101/100000, batch:    18/  187, ite: 9409] train loss: 0.123683, tar: 0.012742 
l0: 0.007324, l1: 0.007426, l2: 0.008853, l3: 0.007634, l4: 0.014367, l5: 0.021152, l6: 0.021193

[epoch: 101/100000, batch:    20/  187, ite: 9410] train loss: 0.123657, tar: 0.012739 
l0: 0.019886, l1: 0.019230, l2: 0.019914, l3: 0.022195, l4: 0.031096, l5: 0.031305, l6: 0.026976

[epoch: 101/100000, batch:    22/  187, ite: 9411] train loss: 0.123691, tar: 0.012744 
l0: 0.007936, l1: 0.008685, l2: 0.011390, l3: 0.010657, l4: 0.019806, l5: 0.016435, l6: 0.014983

[epoch: 101/100000, batch:    24/  187, ite: 9412] train loss: 0.123667, tar: 0.012740 
l0: 0.004504, l1: 0.005458, l2: 0.006657, l3: 0.004810, l4: 0.010460, l5: 0.008955, l6: 0.010809

[epoch: 101/100000, batch:    26/  187, ite: 9413] train loss: 0.123616, tar: 0.012734 
l0: 0.017972, l1: 0.020851, l2: 0.020991, l3: 0.016615, l4: 0.020948, l5: 0.016692, l6: 0.021759

[epoch: 101/100000, batch:    28/  187, ite: 9414] train loss: 0.123624, tar: 0.012738 
l0: 0.006238, l1: 0.006052, l2: 0.007985, l3: 0.007905, l4: 0.012167, l5: 0.014772, l6: 0.016446

[epoch: 101/100000, batch:    30/  187, ite: 9415] train loss: 0.123588, tar: 0.012733 
l0: 0.010295, l1: 0.009542, l2: 0.012456, l3: 0.012367, l4: 0.024698, l5: 0.021170, l6: 0.023832

[epoch: 101/100000, batch:    32/  187, ite: 9416] train loss: 0.123581, tar: 0.012732 
l0: 0.014160, l1: 0.014412, l2: 0.016999, l3: 0.015805, l4: 0.019069, l5: 0.017417, l6: 0.021327

[epoch: 101/100000, batch:    34/  187, ite: 9417] train loss: 0.123578, tar: 0.012733 
l0: 0.010738, l1: 0.011066, l2: 0.012082, l3: 0.010814, l4: 0.024091, l5: 0.025523, l6: 0.018995

[epoch: 101/100000, batch:    36/  187, ite: 9418] train loss: 0.123571, tar: 0.012731 
l0: 0.008404, l1: 0.008172, l2: 0.013437, l3: 0.012090, l4: 0.023111, l5: 0.016732, l6: 0.020494

[epoch: 101/100000, batch:    38/  187, ite: 9419] train loss: 0.123556, tar: 0.012728 
l0: 0.010768, l1: 0.017789, l2: 0.015181, l3: 0.012386, l4: 0.019244, l5: 0.021761, l6: 0.010711

[epoch: 101/100000, batch:    40/  187, ite: 9420] train loss: 0.123545, tar: 0.012727 
l0: 0.017013, l1: 0.019841, l2: 0.020699, l3: 0.019059, l4: 0.022041, l5: 0.018947, l6: 0.018025

[epoch: 101/100000, batch:    42/  187, ite: 9421] train loss: 0.123553, tar: 0.012730 
l0: 0.017627, l1: 0.018269, l2: 0.020046, l3: 0.022743, l4: 0.022660, l5: 0.025014, l6: 0.029040

[epoch: 101/100000, batch:    44/  187, ite: 9422] train loss: 0.123576, tar: 0.012733 
l0: 0.007985, l1: 0.008162, l2: 0.010405, l3: 0.012403, l4: 0.019256, l5: 0.014572, l6: 0.014847

[epoch: 101/100000, batch:    46/  187, ite: 9423] train loss: 0.123550, tar: 0.012730 
l0: 0.010929, l1: 0.011034, l2: 0.010817, l3: 0.011127, l4: 0.014911, l5: 0.015396, l6: 0.015724

[epoch: 101/100000, batch:    48/  187, ite: 9424] train loss: 0.123527, tar: 0.012729 
l0: 0.014300, l1: 0.015244, l2: 0.012944, l3: 0.014435, l4: 0.017711, l5: 0.018814, l6: 0.019719

[epoch: 101/100000, batch:    50/  187, ite: 9425] train loss: 0.123519, tar: 0.012730 
l0: 0.009173, l1: 0.009122, l2: 0.009891, l3: 0.009693, l4: 0.014809, l5: 0.018838, l6: 0.013385

[epoch: 101/100000, batch:    52/  187, ite: 9426] train loss: 0.123492, tar: 0.012727 
l0: 0.007703, l1: 0.007725, l2: 0.008780, l3: 0.008252, l4: 0.018683, l5: 0.015386, l6: 0.021755

[epoch: 101/100000, batch:    54/  187, ite: 9427] train loss: 0.123468, tar: 0.012724 
l0: 0.006826, l1: 0.007964, l2: 0.009811, l3: 0.008713, l4: 0.009585, l5: 0.008152, l6: 0.005234

[epoch: 101/100000, batch:    56/  187, ite: 9428] train loss: 0.123421, tar: 0.012720 
l0: 0.013319, l1: 0.011744, l2: 0.012609, l3: 0.016550, l4: 0.022653, l5: 0.028749, l6: 0.037597

[epoch: 101/100000, batch:    58/  187, ite: 9429] train loss: 0.123435, tar: 0.012720 
l0: 0.008487, l1: 0.007735, l2: 0.009591, l3: 0.011148, l4: 0.019178, l5: 0.020704, l6: 0.018148

[epoch: 101/100000, batch:    60/  187, ite: 9430] train loss: 0.123415, tar: 0.012717 
l0: 0.019976, l1: 0.020966, l2: 0.024984, l3: 0.020951, l4: 0.045241, l5: 0.041357, l6: 0.039088

[epoch: 101/100000, batch:    62/  187, ite: 9431] train loss: 0.123477, tar: 0.012722 
l0: 0.014753, l1: 0.013850, l2: 0.015960, l3: 0.018483, l4: 0.024437, l5: 0.028943, l6: 0.022093

[epoch: 101/100000, batch:    64/  187, ite: 9432] train loss: 0.123487, tar: 0.012724 
l0: 0.010987, l1: 0.010644, l2: 0.015906, l3: 0.018046, l4: 0.020276, l5: 0.020718, l6: 0.020302

[epoch: 101/100000, batch:    66/  187, ite: 9433] train loss: 0.123483, tar: 0.012722 
l0: 0.023361, l1: 0.025421, l2: 0.025066, l3: 0.024659, l4: 0.046858, l5: 0.038419, l6: 0.043039

[epoch: 101/100000, batch:    68/  187, ite: 9434] train loss: 0.123555, tar: 0.012730 
l0: 0.012099, l1: 0.014646, l2: 0.010750, l3: 0.009038, l4: 0.025620, l5: 0.022840, l6: 0.019750

[epoch: 101/100000, batch:    70/  187, ite: 9435] train loss: 0.123549, tar: 0.012729 
l0: 0.014138, l1: 0.014303, l2: 0.016361, l3: 0.017639, l4: 0.033356, l5: 0.032167, l6: 0.028096

[epoch: 101/100000, batch:    72/  187, ite: 9436] train loss: 0.123571, tar: 0.012730 
l0: 0.007080, l1: 0.008614, l2: 0.010376, l3: 0.008261, l4: 0.008181, l5: 0.007483, l6: 0.007293

[epoch: 101/100000, batch:    74/  187, ite: 9437] train loss: 0.123525, tar: 0.012727 
l0: 0.016435, l1: 0.020720, l2: 0.013049, l3: 0.013109, l4: 0.022667, l5: 0.018141, l6: 0.019886

[epoch: 101/100000, batch:    76/  187, ite: 9438] train loss: 0.123526, tar: 0.012729 
l0: 0.013105, l1: 0.015535, l2: 0.011867, l3: 0.011092, l4: 0.015874, l5: 0.013656, l6: 0.014946

[epoch: 101/100000, batch:    78/  187, ite: 9439] train loss: 0.123507, tar: 0.012729 
l0: 0.008917, l1: 0.009666, l2: 0.009842, l3: 0.009961, l4: 0.014480, l5: 0.012572, l6: 0.012473

[epoch: 101/100000, batch:    80/  187, ite: 9440] train loss: 0.123475, tar: 0.012727 
l0: 0.015283, l1: 0.016030, l2: 0.016243, l3: 0.015060, l4: 0.021567, l5: 0.022123, l6: 0.020998

[epoch: 101/100000, batch:    82/  187, ite: 9441] train loss: 0.123478, tar: 0.012728 
l0: 0.009476, l1: 0.009633, l2: 0.009601, l3: 0.009546, l4: 0.013204, l5: 0.011238, l6: 0.012908

[epoch: 101/100000, batch:    84/  187, ite: 9442] train loss: 0.123444, tar: 0.012726 
l0: 0.010063, l1: 0.010209, l2: 0.014527, l3: 0.014218, l4: 0.025772, l5: 0.021439, l6: 0.020086

[epoch: 101/100000, batch:    86/  187, ite: 9443] train loss: 0.123439, tar: 0.012724 
l0: 0.009732, l1: 0.010397, l2: 0.010466, l3: 0.010262, l4: 0.017445, l5: 0.015238, l6: 0.015882

[epoch: 101/100000, batch:    88/  187, ite: 9444] train loss: 0.123416, tar: 0.012722 
l0: 0.013784, l1: 0.015925, l2: 0.015827, l3: 0.014011, l4: 0.017302, l5: 0.017480, l6: 0.015100

[epoch: 101/100000, batch:    90/  187, ite: 9445] train loss: 0.123406, tar: 0.012723 
l0: 0.010939, l1: 0.010930, l2: 0.010389, l3: 0.011519, l4: 0.019369, l5: 0.016781, l6: 0.014155

[epoch: 101/100000, batch:    92/  187, ite: 9446] train loss: 0.123386, tar: 0.012722 
l0: 0.007425, l1: 0.007566, l2: 0.009825, l3: 0.011341, l4: 0.015367, l5: 0.011998, l6: 0.010369

[epoch: 101/100000, batch:    94/  187, ite: 9447] train loss: 0.123352, tar: 0.012718 
l0: 0.013621, l1: 0.012515, l2: 0.012331, l3: 0.015686, l4: 0.026660, l5: 0.027385, l6: 0.024819

[epoch: 101/100000, batch:    96/  187, ite: 9448] train loss: 0.123358, tar: 0.012719 
l0: 0.013270, l1: 0.013140, l2: 0.012142, l3: 0.012637, l4: 0.013597, l5: 0.014998, l6: 0.019251

[epoch: 101/100000, batch:    98/  187, ite: 9449] train loss: 0.123342, tar: 0.012719 
l0: 0.007598, l1: 0.008122, l2: 0.008740, l3: 0.008571, l4: 0.012790, l5: 0.011545, l6: 0.010310

[epoch: 101/100000, batch:   100/  187, ite: 9450] train loss: 0.123303, tar: 0.012716 
l0: 0.007894, l1: 0.006969, l2: 0.008548, l3: 0.008950, l4: 0.017775, l5: 0.019888, l6: 0.021720

[epoch: 101/100000, batch:   102/  187, ite: 9451] train loss: 0.123281, tar: 0.012712 
l0: 0.010137, l1: 0.009539, l2: 0.010736, l3: 0.011253, l4: 0.020135, l5: 0.021137, l6: 0.025900

[epoch: 101/100000, batch:   104/  187, ite: 9452] train loss: 0.123271, tar: 0.012711 
l0: 0.010997, l1: 0.012102, l2: 0.012253, l3: 0.012249, l4: 0.010057, l5: 0.010056, l6: 0.010642

[epoch: 101/100000, batch:   106/  187, ite: 9453] train loss: 0.123241, tar: 0.012709 
l0: 0.013216, l1: 0.014659, l2: 0.014471, l3: 0.013877, l4: 0.019498, l5: 0.014671, l6: 0.019541

[epoch: 101/100000, batch:   108/  187, ite: 9454] train loss: 0.123231, tar: 0.012710 
l0: 0.005890, l1: 0.005606, l2: 0.005816, l3: 0.006219, l4: 0.015726, l5: 0.015417, l6: 0.017977

[epoch: 101/100000, batch:   110/  187, ite: 9455] train loss: 0.123197, tar: 0.012705 
l0: 0.015521, l1: 0.016112, l2: 0.017955, l3: 0.017492, l4: 0.019771, l5: 0.020224, l6: 0.019437

[epoch: 101/100000, batch:   112/  187, ite: 9456] train loss: 0.123199, tar: 0.012707 
l0: 0.013901, l1: 0.014452, l2: 0.015331, l3: 0.016578, l4: 0.018067, l5: 0.018000, l6: 0.018404

[epoch: 101/100000, batch:   114/  187, ite: 9457] train loss: 0.123193, tar: 0.012708 
l0: 0.032299, l1: 0.038659, l2: 0.058262, l3: 0.038271, l4: 0.030540, l5: 0.021973, l6: 0.018050

[epoch: 101/100000, batch:   116/  187, ite: 9458] train loss: 0.123272, tar: 0.012721 
l0: 0.012520, l1: 0.013422, l2: 0.015643, l3: 0.014767, l4: 0.017344, l5: 0.015660, l6: 0.016360

[epoch: 101/100000, batch:   118/  187, ite: 9459] train loss: 0.123260, tar: 0.012721 
l0: 0.010591, l1: 0.010857, l2: 0.013659, l3: 0.011734, l4: 0.027931, l5: 0.023476, l6: 0.020500

[epoch: 101/100000, batch:   120/  187, ite: 9460] train loss: 0.123257, tar: 0.012720 
l0: 0.009544, l1: 0.009647, l2: 0.011613, l3: 0.012132, l4: 0.014130, l5: 0.012959, l6: 0.013365

[epoch: 101/100000, batch:   122/  187, ite: 9461] train loss: 0.123229, tar: 0.012717 
l0: 0.008890, l1: 0.008338, l2: 0.009282, l3: 0.009579, l4: 0.016630, l5: 0.016314, l6: 0.025859

[epoch: 101/100000, batch:   124/  187, ite: 9462] train loss: 0.123210, tar: 0.012715 
l0: 0.015828, l1: 0.017492, l2: 0.015959, l3: 0.019584, l4: 0.023840, l5: 0.021094, l6: 0.022234

[epoch: 101/100000, batch:   126/  187, ite: 9463] train loss: 0.123219, tar: 0.012717 
l0: 0.014364, l1: 0.016619, l2: 0.013310, l3: 0.014242, l4: 0.020216, l5: 0.020757, l6: 0.019475

[epoch: 101/100000, batch:   128/  187, ite: 9464] train loss: 0.123216, tar: 0.012718 
l0: 0.015214, l1: 0.014666, l2: 0.015519, l3: 0.014059, l4: 0.026631, l5: 0.026250, l6: 0.031928

[epoch: 101/100000, batch:   130/  187, ite: 9465] train loss: 0.123230, tar: 0.012720 
l0: 0.009062, l1: 0.009475, l2: 0.011773, l3: 0.012121, l4: 0.016841, l5: 0.015482, l6: 0.017496

[epoch: 101/100000, batch:   132/  187, ite: 9466] train loss: 0.123209, tar: 0.012717 
l0: 0.013403, l1: 0.012720, l2: 0.013952, l3: 0.015072, l4: 0.021947, l5: 0.024340, l6: 0.025615

[epoch: 101/100000, batch:   134/  187, ite: 9467] train loss: 0.123212, tar: 0.012718 
l0: 0.009037, l1: 0.009338, l2: 0.012486, l3: 0.013967, l4: 0.016983, l5: 0.015825, l6: 0.015172

[epoch: 101/100000, batch:   136/  187, ite: 9468] train loss: 0.123191, tar: 0.012715 
l0: 0.010060, l1: 0.010778, l2: 0.010370, l3: 0.009209, l4: 0.016707, l5: 0.014840, l6: 0.017513

[epoch: 101/100000, batch:   138/  187, ite: 9469] train loss: 0.123168, tar: 0.012713 
l0: 0.008503, l1: 0.008461, l2: 0.012234, l3: 0.012544, l4: 0.019966, l5: 0.017843, l6: 0.018380

[epoch: 101/100000, batch:   140/  187, ite: 9470] train loss: 0.123151, tar: 0.012711 
l0: 0.008730, l1: 0.009209, l2: 0.008944, l3: 0.010430, l4: 0.011677, l5: 0.010137, l6: 0.012872

[epoch: 101/100000, batch:   142/  187, ite: 9471] train loss: 0.123116, tar: 0.012708 
l0: 0.013869, l1: 0.014378, l2: 0.013195, l3: 0.014209, l4: 0.026211, l5: 0.021206, l6: 0.028070

[epoch: 101/100000, batch:   144/  187, ite: 9472] train loss: 0.123122, tar: 0.012709 
l0: 0.021092, l1: 0.022089, l2: 0.021818, l3: 0.022216, l4: 0.039315, l5: 0.032171, l6: 0.028885

[epoch: 101/100000, batch:   146/  187, ite: 9473] train loss: 0.123165, tar: 0.012714 
l0: 0.011581, l1: 0.010461, l2: 0.011605, l3: 0.011661, l4: 0.023787, l5: 0.025473, l6: 0.028629

[epoch: 101/100000, batch:   148/  187, ite: 9474] train loss: 0.123165, tar: 0.012714 
l0: 0.008726, l1: 0.009830, l2: 0.009918, l3: 0.007694, l4: 0.017309, l5: 0.011987, l6: 0.013616

[epoch: 101/100000, batch:   150/  187, ite: 9475] train loss: 0.123136, tar: 0.012711 
l0: 0.011812, l1: 0.013038, l2: 0.018545, l3: 0.013223, l4: 0.019572, l5: 0.019450, l6: 0.017329

[epoch: 101/100000, batch:   152/  187, ite: 9476] train loss: 0.123129, tar: 0.012710 
l0: 0.012061, l1: 0.011759, l2: 0.011603, l3: 0.012587, l4: 0.030413, l5: 0.029467, l6: 0.026773

[epoch: 101/100000, batch:   154/  187, ite: 9477] train loss: 0.123137, tar: 0.012710 
l0: 0.016846, l1: 0.016371, l2: 0.019260, l3: 0.023107, l4: 0.037934, l5: 0.029393, l6: 0.031361

[epoch: 101/100000, batch:   156/  187, ite: 9478] train loss: 0.123171, tar: 0.012713 
l0: 0.010903, l1: 0.011492, l2: 0.013538, l3: 0.012519, l4: 0.014961, l5: 0.014036, l6: 0.012648

[epoch: 101/100000, batch:   158/  187, ite: 9479] train loss: 0.123149, tar: 0.012711 
l0: 0.009571, l1: 0.009641, l2: 0.011674, l3: 0.012187, l4: 0.017933, l5: 0.016162, l6: 0.017143

[epoch: 101/100000, batch:   160/  187, ite: 9480] train loss: 0.123129, tar: 0.012709 
l0: 0.010222, l1: 0.009972, l2: 0.012947, l3: 0.013644, l4: 0.016424, l5: 0.013362, l6: 0.021480

[epoch: 101/100000, batch:   162/  187, ite: 9481] train loss: 0.123112, tar: 0.012708 
l0: 0.008520, l1: 0.008213, l2: 0.008670, l3: 0.008725, l4: 0.015987, l5: 0.017864, l6: 0.019348

[epoch: 101/100000, batch:   164/  187, ite: 9482] train loss: 0.123088, tar: 0.012705 
l0: 0.011588, l1: 0.011683, l2: 0.013900, l3: 0.013759, l4: 0.032307, l5: 0.026046, l6: 0.024549

[epoch: 101/100000, batch:   166/  187, ite: 9483] train loss: 0.123095, tar: 0.012704 
l0: 0.014674, l1: 0.016919, l2: 0.016013, l3: 0.013587, l4: 0.020308, l5: 0.015476, l6: 0.016710

[epoch: 101/100000, batch:   168/  187, ite: 9484] train loss: 0.123089, tar: 0.012705 
l0: 0.009504, l1: 0.010732, l2: 0.011106, l3: 0.012111, l4: 0.014564, l5: 0.011775, l6: 0.013895

[epoch: 101/100000, batch:   170/  187, ite: 9485] train loss: 0.123063, tar: 0.012703 
l0: 0.009882, l1: 0.010017, l2: 0.014472, l3: 0.013043, l4: 0.018556, l5: 0.020436, l6: 0.019571

[epoch: 101/100000, batch:   172/  187, ite: 9486] train loss: 0.123051, tar: 0.012701 
l0: 0.018119, l1: 0.018315, l2: 0.016345, l3: 0.019025, l4: 0.027125, l5: 0.025320, l6: 0.021568

[epoch: 101/100000, batch:   174/  187, ite: 9487] train loss: 0.123066, tar: 0.012705 
l0: 0.006831, l1: 0.007221, l2: 0.007160, l3: 0.007056, l4: 0.016807, l5: 0.016227, l6: 0.016316

[epoch: 101/100000, batch:   176/  187, ite: 9488] train loss: 0.123036, tar: 0.012701 
l0: 0.009248, l1: 0.008212, l2: 0.011584, l3: 0.012554, l4: 0.021637, l5: 0.017888, l6: 0.026215

[epoch: 101/100000, batch:   178/  187, ite: 9489] train loss: 0.123025, tar: 0.012699 
l0: 0.011563, l1: 0.013006, l2: 0.013487, l3: 0.013229, l4: 0.026515, l5: 0.026166, l6: 0.021298

[epoch: 101/100000, batch:   180/  187, ite: 9490] train loss: 0.123027, tar: 0.012698 
l0: 0.009962, l1: 0.010345, l2: 0.010522, l3: 0.009733, l4: 0.014848, l5: 0.014193, l6: 0.017701

[epoch: 101/100000, batch:   182/  187, ite: 9491] train loss: 0.123003, tar: 0.012696 
l0: 0.006193, l1: 0.040746, l2: 0.037050, l3: 0.007179, l4: 0.014795, l5: 0.012761, l6: 0.016517

[epoch: 101/100000, batch:   184/  187, ite: 9492] train loss: 0.123011, tar: 0.012692 
l0: 0.008961, l1: 0.010091, l2: 0.009811, l3: 0.010433, l4: 0.019008, l5: 0.012620, l6: 0.013790

[epoch: 101/100000, batch:   186/  187, ite: 9493] train loss: 0.122985, tar: 0.012689 
l0: 0.016864, l1: 0.017118, l2: 0.020065, l3: 0.020178, l4: 0.021857, l5: 0.021642, l6: 0.023551

[epoch: 101/100000, batch:   188/  187, ite: 9494] train loss: 0.122998, tar: 0.012692 
l0: 0.010713, l1: 0.011288, l2: 0.011182, l3: 0.013282, l4: 0.014328, l5: 0.017854, l6: 0.018821

[epoch: 102/100000, batch:     2/  187, ite: 9495] train loss: 0.122981, tar: 0.012691 
l0: 0.014254, l1: 0.017569, l2: 0.015294, l3: 0.014963, l4: 0.019594, l5: 0.014776, l6: 0.016547

[epoch: 102/100000, batch:     4/  187, ite: 9496] train loss: 0.122974, tar: 0.012692 
l0: 0.007842, l1: 0.008982, l2: 0.011038, l3: 0.007853, l4: 0.009732, l5: 0.009431, l6: 0.010469

[epoch: 102/100000, batch:     6/  187, ite: 9497] train loss: 0.122935, tar: 0.012688 
l0: 0.021344, l1: 0.022321, l2: 0.025584, l3: 0.026786, l4: 0.023590, l5: 0.024909, l6: 0.023426

[epoch: 102/100000, batch:     8/  187, ite: 9498] train loss: 0.122965, tar: 0.012694 
l0: 0.014712, l1: 0.017574, l2: 0.016376, l3: 0.016417, l4: 0.024923, l5: 0.021637, l6: 0.026791

[epoch: 102/100000, batch:    10/  187, ite: 9499] train loss: 0.122976, tar: 0.012696 
l0: 0.006959, l1: 0.006472, l2: 0.007816, l3: 0.007207, l4: 0.011098, l5: 0.010747, l6: 0.012133

[epoch: 102/100000, batch:    12/  187, ite: 9500] train loss: 0.122935, tar: 0.012692 
l0: 0.007985, l1: 0.008400, l2: 0.008958, l3: 0.007152, l4: 0.013685, l5: 0.017514, l6: 0.016982

[epoch: 102/100000, batch:    14/  187, ite: 9501] train loss: 0.122907, tar: 0.012689 
l0: 0.006348, l1: 0.006997, l2: 0.007831, l3: 0.011000, l4: 0.012547, l5: 0.011702, l6: 0.008655

[epoch: 102/100000, batch:    16/  187, ite: 9502] train loss: 0.122869, tar: 0.012684 
l0: 0.007241, l1: 0.008601, l2: 0.008949, l3: 0.009341, l4: 0.010956, l5: 0.010759, l6: 0.010974

[epoch: 102/100000, batch:    18/  187, ite: 9503] train loss: 0.122831, tar: 0.012681 
l0: 0.019489, l1: 0.017701, l2: 0.017521, l3: 0.020217, l4: 0.032211, l5: 0.032825, l6: 0.033790

[epoch: 102/100000, batch:    20/  187, ite: 9504] train loss: 0.122865, tar: 0.012685 
l0: 0.013914, l1: 0.014981, l2: 0.017672, l3: 0.013560, l4: 0.022353, l5: 0.018889, l6: 0.020245

[epoch: 102/100000, batch:    22/  187, ite: 9505] train loss: 0.122864, tar: 0.012686 
l0: 0.004763, l1: 0.005056, l2: 0.004693, l3: 0.004321, l4: 0.015189, l5: 0.012563, l6: 0.010125

[epoch: 102/100000, batch:    24/  187, ite: 9506] train loss: 0.122821, tar: 0.012681 
l0: 0.005721, l1: 0.007536, l2: 0.006380, l3: 0.005705, l4: 0.005869, l5: 0.005421, l6: 0.005225

[epoch: 102/100000, batch:    26/  187, ite: 9507] train loss: 0.122767, tar: 0.012676 
l0: 0.007124, l1: 0.008174, l2: 0.009267, l3: 0.008992, l4: 0.013585, l5: 0.010552, l6: 0.010924

[epoch: 102/100000, batch:    28/  187, ite: 9508] train loss: 0.122731, tar: 0.012673 
l0: 0.031914, l1: 0.033682, l2: 0.036731, l3: 0.030757, l4: 0.037582, l5: 0.036832, l6: 0.035981

[epoch: 102/100000, batch:    30/  187, ite: 9509] train loss: 0.122811, tar: 0.012685 
l0: 0.020886, l1: 0.021587, l2: 0.019577, l3: 0.020526, l4: 0.048677, l5: 0.036328, l6: 0.036450

[epoch: 102/100000, batch:    32/  187, ite: 9510] train loss: 0.122865, tar: 0.012691 
l0: 0.015984, l1: 0.012400, l2: 0.015158, l3: 0.021299, l4: 0.045632, l5: 0.049421, l6: 0.046904

[epoch: 102/100000, batch:    34/  187, ite: 9511] train loss: 0.122920, tar: 0.012693 
l0: 0.010899, l1: 0.011952, l2: 0.011595, l3: 0.011798, l4: 0.016692, l5: 0.014571, l6: 0.016175

[epoch: 102/100000, batch:    36/  187, ite: 9512] train loss: 0.122901, tar: 0.012692 
l0: 0.019199, l1: 0.021129, l2: 0.018523, l3: 0.025493, l4: 0.024134, l5: 0.018926, l6: 0.016744

[epoch: 102/100000, batch:    38/  187, ite: 9513] train loss: 0.122915, tar: 0.012696 
l0: 0.008410, l1: 0.011674, l2: 0.012732, l3: 0.010183, l4: 0.011547, l5: 0.010381, l6: 0.008676

[epoch: 102/100000, batch:    40/  187, ite: 9514] train loss: 0.122882, tar: 0.012693 
l0: 0.015202, l1: 0.016755, l2: 0.015840, l3: 0.015702, l4: 0.022877, l5: 0.022072, l6: 0.029808

[epoch: 102/100000, batch:    42/  187, ite: 9515] train loss: 0.122893, tar: 0.012695 
l0: 0.008781, l1: 0.009811, l2: 0.010207, l3: 0.009360, l4: 0.012618, l5: 0.012305, l6: 0.014182

[epoch: 102/100000, batch:    44/  187, ite: 9516] train loss: 0.122862, tar: 0.012692 
l0: 0.013267, l1: 0.014800, l2: 0.013475, l3: 0.011739, l4: 0.019291, l5: 0.019143, l6: 0.019883

[epoch: 102/100000, batch:    46/  187, ite: 9517] train loss: 0.122855, tar: 0.012693 
l0: 0.010673, l1: 0.012233, l2: 0.011140, l3: 0.011723, l4: 0.018418, l5: 0.020058, l6: 0.017255

[epoch: 102/100000, batch:    48/  187, ite: 9518] train loss: 0.122841, tar: 0.012691 
l0: 0.008711, l1: 0.008551, l2: 0.011147, l3: 0.013080, l4: 0.030205, l5: 0.025378, l6: 0.019983

[epoch: 102/100000, batch:    50/  187, ite: 9519] train loss: 0.122837, tar: 0.012689 
l0: 0.012092, l1: 0.011607, l2: 0.013720, l3: 0.014466, l4: 0.014410, l5: 0.017103, l6: 0.020452

[epoch: 102/100000, batch:    52/  187, ite: 9520] train loss: 0.122825, tar: 0.012688 
l0: 0.009653, l1: 0.009699, l2: 0.010919, l3: 0.010992, l4: 0.017417, l5: 0.015816, l6: 0.015261

[epoch: 102/100000, batch:    54/  187, ite: 9521] train loss: 0.122803, tar: 0.012686 
l0: 0.008406, l1: 0.009263, l2: 0.009943, l3: 0.009116, l4: 0.013753, l5: 0.013420, l6: 0.016776

[epoch: 102/100000, batch:    56/  187, ite: 9522] train loss: 0.122775, tar: 0.012684 
l0: 0.009492, l1: 0.009442, l2: 0.009133, l3: 0.008446, l4: 0.013756, l5: 0.017536, l6: 0.017341

[epoch: 102/100000, batch:    58/  187, ite: 9523] train loss: 0.122751, tar: 0.012681 
l0: 0.012065, l1: 0.011634, l2: 0.013741, l3: 0.013438, l4: 0.023938, l5: 0.025083, l6: 0.022643

[epoch: 102/100000, batch:    60/  187, ite: 9524] train loss: 0.122750, tar: 0.012681 
l0: 0.010650, l1: 0.011031, l2: 0.012164, l3: 0.012112, l4: 0.016886, l5: 0.017099, l6: 0.017828

[epoch: 102/100000, batch:    62/  187, ite: 9525] train loss: 0.122734, tar: 0.012680 
l0: 0.005550, l1: 0.006455, l2: 0.007452, l3: 0.005385, l4: 0.011021, l5: 0.008846, l6: 0.010586

[epoch: 102/100000, batch:    64/  187, ite: 9526] train loss: 0.122690, tar: 0.012675 
l0: 0.013504, l1: 0.015083, l2: 0.014228, l3: 0.014877, l4: 0.027137, l5: 0.018635, l6: 0.021566

[epoch: 102/100000, batch:    66/  187, ite: 9527] train loss: 0.122691, tar: 0.012676 
l0: 0.007958, l1: 0.007448, l2: 0.009724, l3: 0.010672, l4: 0.027212, l5: 0.030872, l6: 0.034979

[epoch: 102/100000, batch:    68/  187, ite: 9528] train loss: 0.122695, tar: 0.012672 
l0: 0.016000, l1: 0.018239, l2: 0.018669, l3: 0.018976, l4: 0.018808, l5: 0.017648, l6: 0.017716

[epoch: 102/100000, batch:    70/  187, ite: 9529] train loss: 0.122698, tar: 0.012675 
l0: 0.013089, l1: 0.013033, l2: 0.016340, l3: 0.016105, l4: 0.031762, l5: 0.031079, l6: 0.035439

[epoch: 102/100000, batch:    72/  187, ite: 9530] train loss: 0.122720, tar: 0.012675 
l0: 0.016294, l1: 0.016590, l2: 0.019348, l3: 0.020260, l4: 0.033656, l5: 0.029779, l6: 0.027378

[epoch: 102/100000, batch:    74/  187, ite: 9531] train loss: 0.122746, tar: 0.012677 
l0: 0.015958, l1: 0.014231, l2: 0.018288, l3: 0.019670, l4: 0.033184, l5: 0.035358, l6: 0.036245

[epoch: 102/100000, batch:    76/  187, ite: 9532] train loss: 0.122779, tar: 0.012679 
l0: 0.009285, l1: 0.009721, l2: 0.010417, l3: 0.010223, l4: 0.022296, l5: 0.016932, l6: 0.020338

[epoch: 102/100000, batch:    78/  187, ite: 9533] train loss: 0.122764, tar: 0.012677 
l0: 0.008603, l1: 0.008601, l2: 0.009500, l3: 0.009183, l4: 0.012026, l5: 0.012779, l6: 0.013977

[epoch: 102/100000, batch:    80/  187, ite: 9534] train loss: 0.122732, tar: 0.012675 
l0: 0.010920, l1: 0.010914, l2: 0.012473, l3: 0.014046, l4: 0.012587, l5: 0.012173, l6: 0.013333

[epoch: 102/100000, batch:    82/  187, ite: 9535] train loss: 0.122709, tar: 0.012673 
l0: 0.006605, l1: 0.006994, l2: 0.009578, l3: 0.011646, l4: 0.015234, l5: 0.013878, l6: 0.016069

[epoch: 102/100000, batch:    84/  187, ite: 9536] train loss: 0.122681, tar: 0.012669 
l0: 0.010200, l1: 0.011789, l2: 0.012071, l3: 0.012355, l4: 0.020566, l5: 0.018905, l6: 0.018809

[epoch: 102/100000, batch:    86/  187, ite: 9537] train loss: 0.122669, tar: 0.012668 
l0: 0.007285, l1: 0.007221, l2: 0.007433, l3: 0.011984, l4: 0.011780, l5: 0.008547, l6: 0.012898

[epoch: 102/100000, batch:    88/  187, ite: 9538] train loss: 0.122633, tar: 0.012664 
l0: 0.015348, l1: 0.015147, l2: 0.015910, l3: 0.015797, l4: 0.028171, l5: 0.027529, l6: 0.027625

[epoch: 102/100000, batch:    90/  187, ite: 9539] train loss: 0.122648, tar: 0.012666 
l0: 0.007241, l1: 0.007301, l2: 0.008289, l3: 0.007873, l4: 0.014707, l5: 0.010100, l6: 0.015802

[epoch: 102/100000, batch:    92/  187, ite: 9540] train loss: 0.122615, tar: 0.012663 
l0: 0.006329, l1: 0.006970, l2: 0.006315, l3: 0.006981, l4: 0.008197, l5: 0.008606, l6: 0.008210

[epoch: 102/100000, batch:    94/  187, ite: 9541] train loss: 0.122569, tar: 0.012658 
l0: 0.008756, l1: 0.009142, l2: 0.010514, l3: 0.010600, l4: 0.011899, l5: 0.010678, l6: 0.012441

[epoch: 102/100000, batch:    96/  187, ite: 9542] train loss: 0.122537, tar: 0.012656 
l0: 0.006970, l1: 0.006658, l2: 0.007704, l3: 0.008689, l4: 0.020902, l5: 0.018890, l6: 0.018976

[epoch: 102/100000, batch:    98/  187, ite: 9543] train loss: 0.122515, tar: 0.012652 
l0: 0.016029, l1: 0.016969, l2: 0.017592, l3: 0.018630, l4: 0.024319, l5: 0.021156, l6: 0.019642

[epoch: 102/100000, batch:   100/  187, ite: 9544] train loss: 0.122523, tar: 0.012654 
l0: 0.007531, l1: 0.007648, l2: 0.006440, l3: 0.010124, l4: 0.018094, l5: 0.017392, l6: 0.017912

[epoch: 102/100000, batch:   102/  187, ite: 9545] train loss: 0.122499, tar: 0.012651 
l0: 0.008621, l1: 0.008432, l2: 0.009662, l3: 0.009471, l4: 0.015689, l5: 0.014678, l6: 0.019350

[epoch: 102/100000, batch:   104/  187, ite: 9546] train loss: 0.122475, tar: 0.012649 
l0: 0.007241, l1: 0.008125, l2: 0.010302, l3: 0.008142, l4: 0.014278, l5: 0.012276, l6: 0.011655

[epoch: 102/100000, batch:   106/  187, ite: 9547] train loss: 0.122442, tar: 0.012645 
l0: 0.012645, l1: 0.012154, l2: 0.013939, l3: 0.013248, l4: 0.020634, l5: 0.024431, l6: 0.020610

[epoch: 102/100000, batch:   108/  187, ite: 9548] train loss: 0.122439, tar: 0.012645 
l0: 0.009196, l1: 0.009596, l2: 0.010190, l3: 0.010586, l4: 0.024255, l5: 0.021343, l6: 0.020675

[epoch: 102/100000, batch:   110/  187, ite: 9549] train loss: 0.122429, tar: 0.012643 
l0: 0.006296, l1: 0.005817, l2: 0.006301, l3: 0.007111, l4: 0.011168, l5: 0.011801, l6: 0.011404

[epoch: 102/100000, batch:   112/  187, ite: 9550] train loss: 0.122388, tar: 0.012639 
l0: 0.015941, l1: 0.014431, l2: 0.017766, l3: 0.020742, l4: 0.026191, l5: 0.029203, l6: 0.030871

[epoch: 102/100000, batch:   114/  187, ite: 9551] train loss: 0.122409, tar: 0.012641 
l0: 0.007792, l1: 0.008408, l2: 0.009927, l3: 0.008305, l4: 0.019112, l5: 0.016880, l6: 0.013903

[epoch: 102/100000, batch:   116/  187, ite: 9552] train loss: 0.122385, tar: 0.012638 
l0: 0.017416, l1: 0.020462, l2: 0.018238, l3: 0.015405, l4: 0.017940, l5: 0.013937, l6: 0.012515

[epoch: 102/100000, batch:   118/  187, ite: 9553] train loss: 0.122381, tar: 0.012641 
l0: 0.026785, l1: 0.033155, l2: 0.037644, l3: 0.026438, l4: 0.031123, l5: 0.025160, l6: 0.027828

[epoch: 102/100000, batch:   120/  187, ite: 9554] train loss: 0.122436, tar: 0.012650 
l0: 0.009632, l1: 0.010300, l2: 0.010176, l3: 0.013138, l4: 0.019666, l5: 0.019383, l6: 0.016399

[epoch: 102/100000, batch:   122/  187, ite: 9555] train loss: 0.122421, tar: 0.012648 
l0: 0.011083, l1: 0.011803, l2: 0.010470, l3: 0.010346, l4: 0.017661, l5: 0.017145, l6: 0.018423

[epoch: 102/100000, batch:   124/  187, ite: 9556] train loss: 0.122404, tar: 0.012647 
l0: 0.009826, l1: 0.010838, l2: 0.009314, l3: 0.008243, l4: 0.013734, l5: 0.013070, l6: 0.018721

[epoch: 102/100000, batch:   126/  187, ite: 9557] train loss: 0.122379, tar: 0.012645 
l0: 0.013649, l1: 0.013752, l2: 0.014249, l3: 0.016358, l4: 0.020039, l5: 0.017159, l6: 0.019130

[epoch: 102/100000, batch:   128/  187, ite: 9558] train loss: 0.122374, tar: 0.012646 
l0: 0.010590, l1: 0.011848, l2: 0.011341, l3: 0.012233, l4: 0.019063, l5: 0.016147, l6: 0.017444

[epoch: 102/100000, batch:   130/  187, ite: 9559] train loss: 0.122359, tar: 0.012644 
l0: 0.010484, l1: 0.009311, l2: 0.010774, l3: 0.011224, l4: 0.017416, l5: 0.026096, l6: 0.031072

[epoch: 102/100000, batch:   132/  187, ite: 9560] train loss: 0.122355, tar: 0.012643 
l0: 0.009288, l1: 0.009426, l2: 0.009577, l3: 0.010577, l4: 0.018880, l5: 0.017065, l6: 0.014477

[epoch: 102/100000, batch:   134/  187, ite: 9561] train loss: 0.122334, tar: 0.012641 
l0: 0.011836, l1: 0.011299, l2: 0.015300, l3: 0.015183, l4: 0.021893, l5: 0.020645, l6: 0.023828

[epoch: 102/100000, batch:   136/  187, ite: 9562] train loss: 0.122333, tar: 0.012640 
l0: 0.010360, l1: 0.010665, l2: 0.012717, l3: 0.012418, l4: 0.017719, l5: 0.015214, l6: 0.014437

[epoch: 102/100000, batch:   138/  187, ite: 9563] train loss: 0.122314, tar: 0.012639 
l0: 0.011158, l1: 0.011800, l2: 0.011376, l3: 0.013309, l4: 0.036123, l5: 0.028130, l6: 0.022879

[epoch: 102/100000, batch:   140/  187, ite: 9564] train loss: 0.122322, tar: 0.012638 
l0: 0.012218, l1: 0.012718, l2: 0.011830, l3: 0.011359, l4: 0.017055, l5: 0.016531, l6: 0.020881

[epoch: 102/100000, batch:   142/  187, ite: 9565] train loss: 0.122309, tar: 0.012638 
l0: 0.004163, l1: 0.003879, l2: 0.005132, l3: 0.005832, l4: 0.011724, l5: 0.009805, l6: 0.014029

[epoch: 102/100000, batch:   144/  187, ite: 9566] train loss: 0.122266, tar: 0.012632 
l0: 0.012021, l1: 0.012821, l2: 0.014379, l3: 0.019982, l4: 0.013709, l5: 0.013246, l6: 0.017675

[epoch: 102/100000, batch:   146/  187, ite: 9567] train loss: 0.122254, tar: 0.012632 
l0: 0.013264, l1: 0.013477, l2: 0.013773, l3: 0.013683, l4: 0.020110, l5: 0.019606, l6: 0.015959

[epoch: 102/100000, batch:   148/  187, ite: 9568] train loss: 0.122247, tar: 0.012632 
l0: 0.010447, l1: 0.010224, l2: 0.010362, l3: 0.011325, l4: 0.021268, l5: 0.025219, l6: 0.026132

[epoch: 102/100000, batch:   150/  187, ite: 9569] train loss: 0.122242, tar: 0.012631 
l0: 0.009237, l1: 0.009763, l2: 0.010971, l3: 0.010404, l4: 0.020881, l5: 0.017880, l6: 0.012757

[epoch: 102/100000, batch:   152/  187, ite: 9570] train loss: 0.122223, tar: 0.012629 
l0: 0.006530, l1: 0.006562, l2: 0.006748, l3: 0.007412, l4: 0.017236, l5: 0.018203, l6: 0.022640

[epoch: 102/100000, batch:   154/  187, ite: 9571] train loss: 0.122199, tar: 0.012625 
l0: 0.004003, l1: 0.004221, l2: 0.004557, l3: 0.004875, l4: 0.007813, l5: 0.006674, l6: 0.006914

[epoch: 102/100000, batch:   156/  187, ite: 9572] train loss: 0.122146, tar: 0.012619 
l0: 0.016940, l1: 0.015416, l2: 0.022117, l3: 0.020880, l4: 0.023565, l5: 0.030246, l6: 0.024165

[epoch: 102/100000, batch:   158/  187, ite: 9573] train loss: 0.122166, tar: 0.012622 
l0: 0.006299, l1: 0.006670, l2: 0.007294, l3: 0.008093, l4: 0.012871, l5: 0.010142, l6: 0.012644

[epoch: 102/100000, batch:   160/  187, ite: 9574] train loss: 0.122129, tar: 0.012618 
l0: 0.007124, l1: 0.007509, l2: 0.008686, l3: 0.009791, l4: 0.014279, l5: 0.013441, l6: 0.013119

[epoch: 102/100000, batch:   162/  187, ite: 9575] train loss: 0.122099, tar: 0.012615 
l0: 0.016276, l1: 0.012912, l2: 0.021475, l3: 0.025924, l4: 0.024264, l5: 0.030819, l6: 0.035947

[epoch: 102/100000, batch:   164/  187, ite: 9576] train loss: 0.122127, tar: 0.012617 
l0: 0.007790, l1: 0.008027, l2: 0.007823, l3: 0.007456, l4: 0.014396, l5: 0.014402, l6: 0.011907

[epoch: 102/100000, batch:   166/  187, ite: 9577] train loss: 0.122095, tar: 0.012614 
l0: 0.012035, l1: 0.011305, l2: 0.011843, l3: 0.013285, l4: 0.028011, l5: 0.027295, l6: 0.024548

[epoch: 102/100000, batch:   168/  187, ite: 9578] train loss: 0.122099, tar: 0.012614 
l0: 0.008820, l1: 0.009252, l2: 0.009895, l3: 0.010682, l4: 0.012575, l5: 0.014289, l6: 0.011804

[epoch: 102/100000, batch:   170/  187, ite: 9579] train loss: 0.122071, tar: 0.012611 
l0: 0.007454, l1: 0.007406, l2: 0.008209, l3: 0.008088, l4: 0.016574, l5: 0.014817, l6: 0.017858

[epoch: 102/100000, batch:   172/  187, ite: 9580] train loss: 0.122045, tar: 0.012608 
l0: 0.014653, l1: 0.016212, l2: 0.019921, l3: 0.019060, l4: 0.022131, l5: 0.018409, l6: 0.015751

[epoch: 102/100000, batch:   174/  187, ite: 9581] train loss: 0.122047, tar: 0.012609 
l0: 0.009384, l1: 0.008949, l2: 0.009978, l3: 0.011814, l4: 0.022664, l5: 0.020896, l6: 0.031772

[epoch: 102/100000, batch:   176/  187, ite: 9582] train loss: 0.122043, tar: 0.012607 
l0: 0.005198, l1: 0.005582, l2: 0.006217, l3: 0.007345, l4: 0.019347, l5: 0.016886, l6: 0.015848

[epoch: 102/100000, batch:   178/  187, ite: 9583] train loss: 0.122014, tar: 0.012602 
l0: 0.005892, l1: 0.005459, l2: 0.007957, l3: 0.008081, l4: 0.012749, l5: 0.012068, l6: 0.009921

[epoch: 102/100000, batch:   180/  187, ite: 9584] train loss: 0.121977, tar: 0.012598 
l0: 0.021545, l1: 0.022803, l2: 0.022312, l3: 0.023150, l4: 0.031428, l5: 0.028253, l6: 0.028859

[epoch: 102/100000, batch:   182/  187, ite: 9585] train loss: 0.122012, tar: 0.012604 
l0: 0.012936, l1: 0.014196, l2: 0.015717, l3: 0.014101, l4: 0.021514, l5: 0.016707, l6: 0.015445

[epoch: 102/100000, batch:   184/  187, ite: 9586] train loss: 0.122005, tar: 0.012604 
l0: 0.016444, l1: 0.016884, l2: 0.022335, l3: 0.020060, l4: 0.021439, l5: 0.018522, l6: 0.022167

[epoch: 102/100000, batch:   186/  187, ite: 9587] train loss: 0.122015, tar: 0.012606 
l0: 0.014222, l1: 0.014473, l2: 0.014623, l3: 0.018307, l4: 0.021348, l5: 0.020801, l6: 0.023730

[epoch: 102/100000, batch:   188/  187, ite: 9588] train loss: 0.122018, tar: 0.012608 
l0: 0.002866, l1: 0.005121, l2: 0.005501, l3: 0.003996, l4: 0.009003, l5: 0.011338, l6: 0.012560

[epoch: 103/100000, batch:     2/  187, ite: 9589] train loss: 0.121973, tar: 0.012601 
l0: 0.008940, l1: 0.009583, l2: 0.010251, l3: 0.010378, l4: 0.017730, l5: 0.014900, l6: 0.016427

[epoch: 103/100000, batch:     4/  187, ite: 9590] train loss: 0.121952, tar: 0.012599 
l0: 0.005119, l1: 0.004953, l2: 0.007398, l3: 0.008344, l4: 0.012736, l5: 0.010764, l6: 0.011207

[epoch: 103/100000, batch:     6/  187, ite: 9591] train loss: 0.121913, tar: 0.012594 
l0: 0.011235, l1: 0.011705, l2: 0.011993, l3: 0.013807, l4: 0.017006, l5: 0.017215, l6: 0.018510

[epoch: 103/100000, batch:     8/  187, ite: 9592] train loss: 0.121901, tar: 0.012594 
l0: 0.011756, l1: 0.011894, l2: 0.013640, l3: 0.013079, l4: 0.020705, l5: 0.019648, l6: 0.024317

[epoch: 103/100000, batch:    10/  187, ite: 9593] train loss: 0.121896, tar: 0.012593 
l0: 0.009433, l1: 0.009502, l2: 0.010974, l3: 0.014852, l4: 0.016824, l5: 0.014665, l6: 0.014325

[epoch: 103/100000, batch:    12/  187, ite: 9594] train loss: 0.121877, tar: 0.012591 
l0: 0.011138, l1: 0.011197, l2: 0.015738, l3: 0.014568, l4: 0.020152, l5: 0.019441, l6: 0.018972

[epoch: 103/100000, batch:    14/  187, ite: 9595] train loss: 0.121870, tar: 0.012590 
l0: 0.019878, l1: 0.019784, l2: 0.019761, l3: 0.023314, l4: 0.028905, l5: 0.026624, l6: 0.032494

[epoch: 103/100000, batch:    16/  187, ite: 9596] train loss: 0.121901, tar: 0.012595 
l0: 0.017053, l1: 0.018825, l2: 0.014757, l3: 0.013763, l4: 0.018499, l5: 0.019135, l6: 0.016293

[epoch: 103/100000, batch:    18/  187, ite: 9597] train loss: 0.121898, tar: 0.012597 
l0: 0.010402, l1: 0.011157, l2: 0.010487, l3: 0.011529, l4: 0.018234, l5: 0.015780, l6: 0.015940

[epoch: 103/100000, batch:    20/  187, ite: 9598] train loss: 0.121881, tar: 0.012596 
l0: 0.008425, l1: 0.014990, l2: 0.016417, l3: 0.011817, l4: 0.009524, l5: 0.011345, l6: 0.014198

[epoch: 103/100000, batch:    22/  187, ite: 9599] train loss: 0.121859, tar: 0.012593 
l0: 0.010828, l1: 0.011878, l2: 0.013873, l3: 0.012277, l4: 0.014764, l5: 0.014337, l6: 0.016017

[epoch: 103/100000, batch:    24/  187, ite: 9600] train loss: 0.121841, tar: 0.012592 
l0: 0.007301, l1: 0.008169, l2: 0.007366, l3: 0.007280, l4: 0.013259, l5: 0.010817, l6: 0.012786

[epoch: 103/100000, batch:    26/  187, ite: 9601] train loss: 0.121807, tar: 0.012589 
l0: 0.032786, l1: 0.038676, l2: 0.053838, l3: 0.043202, l4: 0.031455, l5: 0.023962, l6: 0.021244

[epoch: 103/100000, batch:    28/  187, ite: 9602] train loss: 0.121884, tar: 0.012602 
l0: 0.016066, l1: 0.017270, l2: 0.016922, l3: 0.016485, l4: 0.019536, l5: 0.018235, l6: 0.018360

[epoch: 103/100000, batch:    30/  187, ite: 9603] train loss: 0.121884, tar: 0.012604 
l0: 0.015254, l1: 0.015767, l2: 0.015818, l3: 0.017258, l4: 0.018207, l5: 0.016791, l6: 0.017537

[epoch: 103/100000, batch:    32/  187, ite: 9604] train loss: 0.121881, tar: 0.012605 
l0: 0.010910, l1: 0.010404, l2: 0.012185, l3: 0.012688, l4: 0.019767, l5: 0.017171, l6: 0.018572

[epoch: 103/100000, batch:    34/  187, ite: 9605] train loss: 0.121869, tar: 0.012604 
l0: 0.006071, l1: 0.005632, l2: 0.006885, l3: 0.009500, l4: 0.019735, l5: 0.015631, l6: 0.017627

[epoch: 103/100000, batch:    36/  187, ite: 9606] train loss: 0.121843, tar: 0.012600 
l0: 0.005665, l1: 0.005512, l2: 0.007703, l3: 0.007771, l4: 0.010964, l5: 0.009561, l6: 0.010706

[epoch: 103/100000, batch:    38/  187, ite: 9607] train loss: 0.121803, tar: 0.012596 
l0: 0.004484, l1: 0.004332, l2: 0.005404, l3: 0.006300, l4: 0.008706, l5: 0.008735, l6: 0.012640

[epoch: 103/100000, batch:    40/  187, ite: 9608] train loss: 0.121759, tar: 0.012591 
l0: 0.010278, l1: 0.011055, l2: 0.013512, l3: 0.013384, l4: 0.018069, l5: 0.017251, l6: 0.020783

[epoch: 103/100000, batch:    42/  187, ite: 9609] train loss: 0.121748, tar: 0.012590 
l0: 0.008237, l1: 0.009050, l2: 0.008744, l3: 0.006870, l4: 0.012097, l5: 0.011359, l6: 0.013779

[epoch: 103/100000, batch:    44/  187, ite: 9610] train loss: 0.121716, tar: 0.012587 
l0: 0.019208, l1: 0.019155, l2: 0.022736, l3: 0.022576, l4: 0.029712, l5: 0.026420, l6: 0.023005

[epoch: 103/100000, batch:    46/  187, ite: 9611] train loss: 0.121742, tar: 0.012591 
l0: 0.005571, l1: 0.007768, l2: 0.005857, l3: 0.005656, l4: 0.013700, l5: 0.011394, l6: 0.012523

[epoch: 103/100000, batch:    48/  187, ite: 9612] train loss: 0.121705, tar: 0.012587 
l0: 0.006423, l1: 0.007177, l2: 0.007759, l3: 0.008177, l4: 0.015588, l5: 0.010503, l6: 0.010775

[epoch: 103/100000, batch:    50/  187, ite: 9613] train loss: 0.121671, tar: 0.012583 
l0: 0.009159, l1: 0.008918, l2: 0.010893, l3: 0.010442, l4: 0.015194, l5: 0.017684, l6: 0.017425

[epoch: 103/100000, batch:    52/  187, ite: 9614] train loss: 0.121651, tar: 0.012581 
l0: 0.008898, l1: 0.009833, l2: 0.009931, l3: 0.010443, l4: 0.019273, l5: 0.015722, l6: 0.017682

[epoch: 103/100000, batch:    54/  187, ite: 9615] train loss: 0.121632, tar: 0.012578 
l0: 0.011863, l1: 0.011768, l2: 0.009219, l3: 0.012016, l4: 0.019561, l5: 0.017750, l6: 0.021329

[epoch: 103/100000, batch:    56/  187, ite: 9616] train loss: 0.121621, tar: 0.012578 
l0: 0.012901, l1: 0.011418, l2: 0.015177, l3: 0.018603, l4: 0.022071, l5: 0.021109, l6: 0.035261

[epoch: 103/100000, batch:    58/  187, ite: 9617] train loss: 0.121630, tar: 0.012578 
l0: 0.006746, l1: 0.007300, l2: 0.008135, l3: 0.007668, l4: 0.013184, l5: 0.014426, l6: 0.012596

[epoch: 103/100000, batch:    60/  187, ite: 9618] train loss: 0.121599, tar: 0.012575 
l0: 0.008969, l1: 0.009091, l2: 0.011286, l3: 0.010767, l4: 0.017468, l5: 0.017739, l6: 0.016958

[epoch: 103/100000, batch:    62/  187, ite: 9619] train loss: 0.121580, tar: 0.012572 
l0: 0.007610, l1: 0.008399, l2: 0.009860, l3: 0.009300, l4: 0.015643, l5: 0.014757, l6: 0.014368

[epoch: 103/100000, batch:    64/  187, ite: 9620] train loss: 0.121555, tar: 0.012569 
l0: 0.009018, l1: 0.008993, l2: 0.008187, l3: 0.008056, l4: 0.016141, l5: 0.015753, l6: 0.017283

[epoch: 103/100000, batch:    66/  187, ite: 9621] train loss: 0.121531, tar: 0.012567 
l0: 0.009835, l1: 0.011169, l2: 0.009389, l3: 0.008996, l4: 0.011167, l5: 0.010190, l6: 0.013255

[epoch: 103/100000, batch:    68/  187, ite: 9622] train loss: 0.121502, tar: 0.012565 
l0: 0.009914, l1: 0.010420, l2: 0.010574, l3: 0.011239, l4: 0.013526, l5: 0.012288, l6: 0.013470

[epoch: 103/100000, batch:    70/  187, ite: 9623] train loss: 0.121477, tar: 0.012564 
l0: 0.009337, l1: 0.010416, l2: 0.010008, l3: 0.009642, l4: 0.014609, l5: 0.013964, l6: 0.014075

[epoch: 103/100000, batch:    72/  187, ite: 9624] train loss: 0.121453, tar: 0.012562 
l0: 0.005374, l1: 0.005524, l2: 0.005722, l3: 0.006191, l4: 0.009459, l5: 0.007856, l6: 0.008309

[epoch: 103/100000, batch:    74/  187, ite: 9625] train loss: 0.121408, tar: 0.012557 
l0: 0.009672, l1: 0.011836, l2: 0.010011, l3: 0.009619, l4: 0.015337, l5: 0.011401, l6: 0.011050

[epoch: 103/100000, batch:    76/  187, ite: 9626] train loss: 0.121382, tar: 0.012556 
l0: 0.009451, l1: 0.011217, l2: 0.008604, l3: 0.008473, l4: 0.012444, l5: 0.011468, l6: 0.016047

[epoch: 103/100000, batch:    78/  187, ite: 9627] train loss: 0.121355, tar: 0.012554 
l0: 0.004703, l1: 0.004928, l2: 0.004759, l3: 0.005596, l4: 0.012231, l5: 0.011436, l6: 0.011441

[epoch: 103/100000, batch:    80/  187, ite: 9628] train loss: 0.121314, tar: 0.012549 
l0: 0.002167, l1: 0.002710, l2: 0.002696, l3: 0.002879, l4: 0.005734, l5: 0.009291, l6: 0.011244

[epoch: 103/100000, batch:    82/  187, ite: 9629] train loss: 0.121262, tar: 0.012542 
l0: 0.011312, l1: 0.011463, l2: 0.012655, l3: 0.013234, l4: 0.016821, l5: 0.018407, l6: 0.015894

[epoch: 103/100000, batch:    84/  187, ite: 9630] train loss: 0.121249, tar: 0.012542 
l0: 0.012030, l1: 0.012227, l2: 0.011506, l3: 0.011862, l4: 0.028497, l5: 0.021930, l6: 0.024358

[epoch: 103/100000, batch:    86/  187, ite: 9631] train loss: 0.121250, tar: 0.012541 
l0: 0.008539, l1: 0.008488, l2: 0.009692, l3: 0.008578, l4: 0.013069, l5: 0.014266, l6: 0.018859

[epoch: 103/100000, batch:    88/  187, ite: 9632] train loss: 0.121226, tar: 0.012539 
l0: 0.009210, l1: 0.008704, l2: 0.011436, l3: 0.011946, l4: 0.017858, l5: 0.019454, l6: 0.020498

[epoch: 103/100000, batch:    90/  187, ite: 9633] train loss: 0.121212, tar: 0.012537 
l0: 0.009009, l1: 0.007490, l2: 0.013312, l3: 0.012803, l4: 0.038612, l5: 0.031842, l6: 0.027709

[epoch: 103/100000, batch:    92/  187, ite: 9634] train loss: 0.121224, tar: 0.012535 
l0: 0.009384, l1: 0.010399, l2: 0.010642, l3: 0.011833, l4: 0.018055, l5: 0.021736, l6: 0.020009

[epoch: 103/100000, batch:    94/  187, ite: 9635] train loss: 0.121212, tar: 0.012533 
l0: 0.008908, l1: 0.010037, l2: 0.008836, l3: 0.011307, l4: 0.017253, l5: 0.016192, l6: 0.014711

[epoch: 103/100000, batch:    96/  187, ite: 9636] train loss: 0.121192, tar: 0.012531 
l0: 0.005607, l1: 0.005413, l2: 0.006392, l3: 0.006832, l4: 0.015631, l5: 0.015543, l6: 0.014933

[epoch: 103/100000, batch:    98/  187, ite: 9637] train loss: 0.121160, tar: 0.012526 
l0: 0.006697, l1: 0.007571, l2: 0.008034, l3: 0.008297, l4: 0.008103, l5: 0.007436, l6: 0.010662

[epoch: 103/100000, batch:   100/  187, ite: 9638] train loss: 0.121121, tar: 0.012523 
l0: 0.007678, l1: 0.008173, l2: 0.008007, l3: 0.008839, l4: 0.012788, l5: 0.011540, l6: 0.010567

[epoch: 103/100000, batch:   102/  187, ite: 9639] train loss: 0.121089, tar: 0.012520 
l0: 0.006904, l1: 0.006860, l2: 0.008789, l3: 0.008289, l4: 0.008846, l5: 0.008667, l6: 0.013749

[epoch: 103/100000, batch:   104/  187, ite: 9640] train loss: 0.121053, tar: 0.012516 
l0: 0.012175, l1: 0.013080, l2: 0.017227, l3: 0.016157, l4: 0.020084, l5: 0.018291, l6: 0.015453

[epoch: 103/100000, batch:   106/  187, ite: 9641] train loss: 0.121047, tar: 0.012516 
l0: 0.006628, l1: 0.007213, l2: 0.007700, l3: 0.007723, l4: 0.010329, l5: 0.008930, l6: 0.010183

[epoch: 103/100000, batch:   108/  187, ite: 9642] train loss: 0.121009, tar: 0.012513 
l0: 0.009305, l1: 0.008972, l2: 0.010772, l3: 0.010472, l4: 0.016288, l5: 0.017386, l6: 0.015706

[epoch: 103/100000, batch:   110/  187, ite: 9643] train loss: 0.120990, tar: 0.012511 
l0: 0.012075, l1: 0.012317, l2: 0.012836, l3: 0.014632, l4: 0.025541, l5: 0.020594, l6: 0.020142

[epoch: 103/100000, batch:   112/  187, ite: 9644] train loss: 0.120988, tar: 0.012510 
l0: 0.008472, l1: 0.008760, l2: 0.010987, l3: 0.011424, l4: 0.011940, l5: 0.013455, l6: 0.014337

[epoch: 103/100000, batch:   114/  187, ite: 9645] train loss: 0.120963, tar: 0.012508 
l0: 0.010604, l1: 0.010717, l2: 0.009168, l3: 0.009112, l4: 0.023843, l5: 0.022025, l6: 0.025820

[epoch: 103/100000, batch:   116/  187, ite: 9646] train loss: 0.120957, tar: 0.012507 
l0: 0.006397, l1: 0.006015, l2: 0.008781, l3: 0.010500, l4: 0.019884, l5: 0.016824, l6: 0.019114

[epoch: 103/100000, batch:   118/  187, ite: 9647] train loss: 0.120937, tar: 0.012503 
l0: 0.010460, l1: 0.010721, l2: 0.012484, l3: 0.012253, l4: 0.012969, l5: 0.014160, l6: 0.017522

[epoch: 103/100000, batch:   120/  187, ite: 9648] train loss: 0.120918, tar: 0.012502 
l0: 0.010878, l1: 0.011151, l2: 0.011149, l3: 0.011390, l4: 0.010504, l5: 0.011612, l6: 0.013313

[epoch: 103/100000, batch:   122/  187, ite: 9649] train loss: 0.120893, tar: 0.012501 
l0: 0.006679, l1: 0.007353, l2: 0.008093, l3: 0.007174, l4: 0.011943, l5: 0.009091, l6: 0.013105

[epoch: 103/100000, batch:   124/  187, ite: 9650] train loss: 0.120859, tar: 0.012497 
l0: 0.009639, l1: 0.009981, l2: 0.010069, l3: 0.010557, l4: 0.018795, l5: 0.016970, l6: 0.017401

[epoch: 103/100000, batch:   126/  187, ite: 9651] train loss: 0.120842, tar: 0.012496 
l0: 0.006321, l1: 0.006767, l2: 0.008678, l3: 0.008414, l4: 0.009804, l5: 0.007697, l6: 0.009592

[epoch: 103/100000, batch:   128/  187, ite: 9652] train loss: 0.120803, tar: 0.012492 
l0: 0.003803, l1: 0.003943, l2: 0.004961, l3: 0.005299, l4: 0.012022, l5: 0.014233, l6: 0.012444

[epoch: 103/100000, batch:   130/  187, ite: 9653] train loss: 0.120765, tar: 0.012487 
l0: 0.011481, l1: 0.010559, l2: 0.012321, l3: 0.012113, l4: 0.019798, l5: 0.021552, l6: 0.019195

[epoch: 103/100000, batch:   132/  187, ite: 9654] train loss: 0.120756, tar: 0.012486 
l0: 0.006521, l1: 0.007303, l2: 0.008576, l3: 0.007992, l4: 0.011204, l5: 0.010065, l6: 0.011979

[epoch: 103/100000, batch:   134/  187, ite: 9655] train loss: 0.120722, tar: 0.012482 
l0: 0.010897, l1: 0.010037, l2: 0.011783, l3: 0.013421, l4: 0.019843, l5: 0.025403, l6: 0.020415

[epoch: 103/100000, batch:   136/  187, ite: 9656] train loss: 0.120716, tar: 0.012481 
l0: 0.012548, l1: 0.013598, l2: 0.015975, l3: 0.014417, l4: 0.024066, l5: 0.020927, l6: 0.019535

[epoch: 103/100000, batch:   138/  187, ite: 9657] train loss: 0.120717, tar: 0.012481 
l0: 0.007378, l1: 0.007733, l2: 0.008497, l3: 0.007750, l4: 0.023478, l5: 0.019885, l6: 0.026487

[epoch: 103/100000, batch:   140/  187, ite: 9658] train loss: 0.120705, tar: 0.012478 
l0: 0.010603, l1: 0.010692, l2: 0.009978, l3: 0.011242, l4: 0.015044, l5: 0.015499, l6: 0.026920

[epoch: 103/100000, batch:   142/  187, ite: 9659] train loss: 0.120692, tar: 0.012477 
l0: 0.007436, l1: 0.008222, l2: 0.009163, l3: 0.009823, l4: 0.017958, l5: 0.012428, l6: 0.014209

[epoch: 103/100000, batch:   144/  187, ite: 9660] train loss: 0.120667, tar: 0.012474 
l0: 0.010101, l1: 0.008871, l2: 0.011887, l3: 0.015683, l4: 0.041846, l5: 0.041353, l6: 0.040189

[epoch: 103/100000, batch:   146/  187, ite: 9661] train loss: 0.120697, tar: 0.012473 
l0: 0.007434, l1: 0.007340, l2: 0.008737, l3: 0.009344, l4: 0.013528, l5: 0.012648, l6: 0.012983

[epoch: 103/100000, batch:   148/  187, ite: 9662] train loss: 0.120668, tar: 0.012470 
l0: 0.008092, l1: 0.009310, l2: 0.008705, l3: 0.008244, l4: 0.013066, l5: 0.013510, l6: 0.013168

[epoch: 103/100000, batch:   150/  187, ite: 9663] train loss: 0.120640, tar: 0.012467 
l0: 0.016900, l1: 0.017869, l2: 0.013875, l3: 0.013936, l4: 0.017018, l5: 0.019219, l6: 0.018338

[epoch: 103/100000, batch:   152/  187, ite: 9664] train loss: 0.120638, tar: 0.012470 
l0: 0.011192, l1: 0.011530, l2: 0.013159, l3: 0.014805, l4: 0.021382, l5: 0.019828, l6: 0.016640

[epoch: 103/100000, batch:   154/  187, ite: 9665] train loss: 0.120630, tar: 0.012469 
l0: 0.004506, l1: 0.005356, l2: 0.006370, l3: 0.006946, l4: 0.011235, l5: 0.010296, l6: 0.011284

[epoch: 103/100000, batch:   156/  187, ite: 9666] train loss: 0.120592, tar: 0.012464 
l0: 0.009241, l1: 0.009679, l2: 0.009712, l3: 0.009746, l4: 0.014088, l5: 0.011752, l6: 0.011584

[epoch: 103/100000, batch:   158/  187, ite: 9667] train loss: 0.120565, tar: 0.012462 
l0: 0.010912, l1: 0.010908, l2: 0.012870, l3: 0.012337, l4: 0.016108, l5: 0.015706, l6: 0.015857

[epoch: 103/100000, batch:   160/  187, ite: 9668] train loss: 0.120549, tar: 0.012461 
l0: 0.010855, l1: 0.010319, l2: 0.013584, l3: 0.014612, l4: 0.021640, l5: 0.018513, l6: 0.019934

[epoch: 103/100000, batch:   162/  187, ite: 9669] train loss: 0.120543, tar: 0.012460 
l0: 0.009348, l1: 0.011053, l2: 0.015350, l3: 0.011359, l4: 0.007854, l5: 0.006259, l6: 0.005360

[epoch: 103/100000, batch:   164/  187, ite: 9670] train loss: 0.120510, tar: 0.012459 
l0: 0.008987, l1: 0.008673, l2: 0.010897, l3: 0.024630, l4: 0.030071, l5: 0.029128, l6: 0.025641

[epoch: 103/100000, batch:   166/  187, ite: 9671] train loss: 0.120521, tar: 0.012457 
l0: 0.014359, l1: 0.015289, l2: 0.016200, l3: 0.016327, l4: 0.026248, l5: 0.022435, l6: 0.023156

[epoch: 103/100000, batch:   168/  187, ite: 9672] train loss: 0.120529, tar: 0.012458 
l0: 0.006135, l1: 0.006146, l2: 0.007132, l3: 0.007013, l4: 0.013470, l5: 0.011732, l6: 0.013028

[epoch: 103/100000, batch:   170/  187, ite: 9673] train loss: 0.120495, tar: 0.012454 
l0: 0.009023, l1: 0.009054, l2: 0.009976, l3: 0.011138, l4: 0.020443, l5: 0.017068, l6: 0.020003

[epoch: 103/100000, batch:   172/  187, ite: 9674] train loss: 0.120481, tar: 0.012452 
l0: 0.002769, l1: 0.003105, l2: 0.003496, l3: 0.003876, l4: 0.005787, l5: 0.004059, l6: 0.003281

[epoch: 103/100000, batch:   174/  187, ite: 9675] train loss: 0.120425, tar: 0.012446 
l0: 0.007839, l1: 0.007915, l2: 0.009648, l3: 0.008636, l4: 0.013685, l5: 0.013897, l6: 0.015586

[epoch: 103/100000, batch:   176/  187, ite: 9676] train loss: 0.120399, tar: 0.012443 
l0: 0.008817, l1: 0.009250, l2: 0.011942, l3: 0.011931, l4: 0.015974, l5: 0.018029, l6: 0.013709

[epoch: 103/100000, batch:   178/  187, ite: 9677] train loss: 0.120381, tar: 0.012441 
l0: 0.014458, l1: 0.013074, l2: 0.015096, l3: 0.016146, l4: 0.021351, l5: 0.024362, l6: 0.030613

[epoch: 103/100000, batch:   180/  187, ite: 9678] train loss: 0.120390, tar: 0.012442 
l0: 0.009188, l1: 0.008252, l2: 0.008351, l3: 0.010324, l4: 0.018240, l5: 0.019172, l6: 0.020826

[epoch: 103/100000, batch:   182/  187, ite: 9679] train loss: 0.120374, tar: 0.012440 
l0: 0.007172, l1: 0.007575, l2: 0.009160, l3: 0.009206, l4: 0.012796, l5: 0.016978, l6: 0.015262

[epoch: 103/100000, batch:   184/  187, ite: 9680] train loss: 0.120349, tar: 0.012437 
l0: 0.012756, l1: 0.012409, l2: 0.015165, l3: 0.015987, l4: 0.027725, l5: 0.026469, l6: 0.021296

[epoch: 103/100000, batch:   186/  187, ite: 9681] train loss: 0.120356, tar: 0.012437 
l0: 0.007959, l1: 0.008029, l2: 0.009499, l3: 0.009612, l4: 0.015143, l5: 0.012767, l6: 0.013746

[epoch: 103/100000, batch:   188/  187, ite: 9682] train loss: 0.120330, tar: 0.012435 
l0: 0.004668, l1: 0.004894, l2: 0.004787, l3: 0.004821, l4: 0.010634, l5: 0.009358, l6: 0.011163

[epoch: 104/100000, batch:     2/  187, ite: 9683] train loss: 0.120288, tar: 0.012430 
l0: 0.007198, l1: 0.007505, l2: 0.009040, l3: 0.008772, l4: 0.021813, l5: 0.017782, l6: 0.017027

[epoch: 104/100000, batch:     4/  187, ite: 9684] train loss: 0.120270, tar: 0.012427 
l0: 0.007244, l1: 0.007422, l2: 0.011342, l3: 0.013905, l4: 0.019451, l5: 0.018708, l6: 0.023351

[epoch: 104/100000, batch:     6/  187, ite: 9685] train loss: 0.120259, tar: 0.012424 
l0: 0.012095, l1: 0.011520, l2: 0.010262, l3: 0.012170, l4: 0.016730, l5: 0.018943, l6: 0.018024

[epoch: 104/100000, batch:     8/  187, ite: 9686] train loss: 0.120247, tar: 0.012424 
l0: 0.005120, l1: 0.005421, l2: 0.006055, l3: 0.006190, l4: 0.014937, l5: 0.011033, l6: 0.013306

[epoch: 104/100000, batch:    10/  187, ite: 9687] train loss: 0.120212, tar: 0.012419 
l0: 0.010692, l1: 0.013230, l2: 0.009492, l3: 0.009278, l4: 0.011650, l5: 0.010775, l6: 0.013684

[epoch: 104/100000, batch:    12/  187, ite: 9688] train loss: 0.120187, tar: 0.012418 
l0: 0.007566, l1: 0.007879, l2: 0.008150, l3: 0.008014, l4: 0.013791, l5: 0.013777, l6: 0.013632

[epoch: 104/100000, batch:    14/  187, ite: 9689] train loss: 0.120159, tar: 0.012416 
l0: 0.004132, l1: 0.004343, l2: 0.005329, l3: 0.003873, l4: 0.010502, l5: 0.006724, l6: 0.009012

[epoch: 104/100000, batch:    16/  187, ite: 9690] train loss: 0.120114, tar: 0.012411 
l0: 0.005844, l1: 0.006675, l2: 0.005702, l3: 0.007212, l4: 0.009139, l5: 0.007094, l6: 0.008166

[epoch: 104/100000, batch:    18/  187, ite: 9691] train loss: 0.120073, tar: 0.012407 
l0: 0.007019, l1: 0.006929, l2: 0.007095, l3: 0.006755, l4: 0.013849, l5: 0.013350, l6: 0.013405

[epoch: 104/100000, batch:    20/  187, ite: 9692] train loss: 0.120042, tar: 0.012404 
l0: 0.011094, l1: 0.012840, l2: 0.013573, l3: 0.012704, l4: 0.013163, l5: 0.012580, l6: 0.010904

[epoch: 104/100000, batch:    22/  187, ite: 9693] train loss: 0.120023, tar: 0.012403 
l0: 0.011408, l1: 0.009495, l2: 0.014808, l3: 0.016290, l4: 0.032083, l5: 0.030772, l6: 0.028511

[epoch: 104/100000, batch:    24/  187, ite: 9694] train loss: 0.120036, tar: 0.012402 
l0: 0.008250, l1: 0.008233, l2: 0.009823, l3: 0.010143, l4: 0.015317, l5: 0.012154, l6: 0.014216

[epoch: 104/100000, batch:    26/  187, ite: 9695] train loss: 0.120012, tar: 0.012400 
l0: 0.004587, l1: 0.005080, l2: 0.006564, l3: 0.005987, l4: 0.007916, l5: 0.006357, l6: 0.005985

[epoch: 104/100000, batch:    28/  187, ite: 9696] train loss: 0.119966, tar: 0.012395 
l0: 0.011097, l1: 0.011421, l2: 0.011766, l3: 0.011261, l4: 0.025008, l5: 0.023760, l6: 0.021739

[epoch: 104/100000, batch:    30/  187, ite: 9697] train loss: 0.119964, tar: 0.012394 
l0: 0.005461, l1: 0.006122, l2: 0.007105, l3: 0.005961, l4: 0.012045, l5: 0.013153, l6: 0.014334

[epoch: 104/100000, batch:    32/  187, ite: 9698] train loss: 0.119931, tar: 0.012390 
l0: 0.016252, l1: 0.015822, l2: 0.018332, l3: 0.020193, l4: 0.026971, l5: 0.023508, l6: 0.021050

[epoch: 104/100000, batch:    34/  187, ite: 9699] train loss: 0.119944, tar: 0.012393 
l0: 0.011989, l1: 0.012019, l2: 0.014557, l3: 0.015264, l4: 0.025966, l5: 0.024678, l6: 0.020810

[epoch: 104/100000, batch:    36/  187, ite: 9700] train loss: 0.119947, tar: 0.012392 
l0: 0.003788, l1: 0.004155, l2: 0.004983, l3: 0.004389, l4: 0.007991, l5: 0.005294, l6: 0.005303

[epoch: 104/100000, batch:    38/  187, ite: 9701] train loss: 0.119898, tar: 0.012387 
l0: 0.007187, l1: 0.007033, l2: 0.011147, l3: 0.010442, l4: 0.012463, l5: 0.010930, l6: 0.011825

[epoch: 104/100000, batch:    40/  187, ite: 9702] train loss: 0.119869, tar: 0.012384 
l0: 0.012926, l1: 0.013364, l2: 0.012385, l3: 0.013664, l4: 0.015705, l5: 0.016306, l6: 0.016341

[epoch: 104/100000, batch:    42/  187, ite: 9703] train loss: 0.119858, tar: 0.012385 
l0: 0.007966, l1: 0.008059, l2: 0.009036, l3: 0.008357, l4: 0.011764, l5: 0.011403, l6: 0.013392

[epoch: 104/100000, batch:    44/  187, ite: 9704] train loss: 0.119828, tar: 0.012382 
l0: 0.005390, l1: 0.005427, l2: 0.005521, l3: 0.005512, l4: 0.013706, l5: 0.013906, l6: 0.015793

[epoch: 104/100000, batch:    46/  187, ite: 9705] train loss: 0.119796, tar: 0.012378 
l0: 0.008266, l1: 0.008915, l2: 0.011598, l3: 0.011291, l4: 0.014861, l5: 0.012114, l6: 0.012989

[epoch: 104/100000, batch:    48/  187, ite: 9706] train loss: 0.119773, tar: 0.012375 
l0: 0.006514, l1: 0.007109, l2: 0.007611, l3: 0.007979, l4: 0.010379, l5: 0.008901, l6: 0.008942

[epoch: 104/100000, batch:    50/  187, ite: 9707] train loss: 0.119737, tar: 0.012372 
l0: 0.010261, l1: 0.010963, l2: 0.010255, l3: 0.011978, l4: 0.017602, l5: 0.013794, l6: 0.014491

[epoch: 104/100000, batch:    52/  187, ite: 9708] train loss: 0.119719, tar: 0.012371 
l0: 0.006563, l1: 0.006972, l2: 0.006797, l3: 0.006882, l4: 0.013100, l5: 0.012036, l6: 0.015246

[epoch: 104/100000, batch:    54/  187, ite: 9709] train loss: 0.119688, tar: 0.012367 
l0: 0.014468, l1: 0.014836, l2: 0.012413, l3: 0.012379, l4: 0.016267, l5: 0.015504, l6: 0.018329

[epoch: 104/100000, batch:    56/  187, ite: 9710] train loss: 0.119679, tar: 0.012369 
l0: 0.010077, l1: 0.010410, l2: 0.008402, l3: 0.008521, l4: 0.015223, l5: 0.015178, l6: 0.016234

[epoch: 104/100000, batch:    58/  187, ite: 9711] train loss: 0.119658, tar: 0.012367 
l0: 0.003783, l1: 0.003989, l2: 0.003842, l3: 0.003473, l4: 0.005006, l5: 0.005942, l6: 0.004761

[epoch: 104/100000, batch:    60/  187, ite: 9712] train loss: 0.119606, tar: 0.012362 
l0: 0.008800, l1: 0.008350, l2: 0.013847, l3: 0.015914, l4: 0.018311, l5: 0.015774, l6: 0.012830

[epoch: 104/100000, batch:    62/  187, ite: 9713] train loss: 0.119591, tar: 0.012360 
l0: 0.012407, l1: 0.014237, l2: 0.014309, l3: 0.012538, l4: 0.022326, l5: 0.017582, l6: 0.019719

[epoch: 104/100000, batch:    64/  187, ite: 9714] train loss: 0.119588, tar: 0.012360 
l0: 0.003914, l1: 0.003802, l2: 0.004353, l3: 0.004589, l4: 0.008056, l5: 0.009550, l6: 0.010846

[epoch: 104/100000, batch:    66/  187, ite: 9715] train loss: 0.119544, tar: 0.012355 
l0: 0.014775, l1: 0.015979, l2: 0.018281, l3: 0.015835, l4: 0.022605, l5: 0.018177, l6: 0.018158

[epoch: 104/100000, batch:    68/  187, ite: 9716] train loss: 0.119547, tar: 0.012357 
l0: 0.010471, l1: 0.010908, l2: 0.011100, l3: 0.010819, l4: 0.017602, l5: 0.012791, l6: 0.014189

[epoch: 104/100000, batch:    70/  187, ite: 9717] train loss: 0.119528, tar: 0.012356 
l0: 0.003861, l1: 0.003816, l2: 0.004885, l3: 0.004896, l4: 0.012548, l5: 0.010693, l6: 0.013037

[epoch: 104/100000, batch:    72/  187, ite: 9718] train loss: 0.119490, tar: 0.012351 
l0: 0.007819, l1: 0.008216, l2: 0.007877, l3: 0.008074, l4: 0.011471, l5: 0.011836, l6: 0.010773

[epoch: 104/100000, batch:    74/  187, ite: 9719] train loss: 0.119459, tar: 0.012348 
l0: 0.009415, l1: 0.010082, l2: 0.010647, l3: 0.011861, l4: 0.012880, l5: 0.013116, l6: 0.011914

[epoch: 104/100000, batch:    76/  187, ite: 9720] train loss: 0.119436, tar: 0.012346 
l0: 0.007484, l1: 0.007687, l2: 0.009241, l3: 0.009632, l4: 0.014315, l5: 0.012633, l6: 0.014270

[epoch: 104/100000, batch:    78/  187, ite: 9721] train loss: 0.119410, tar: 0.012343 
l0: 0.008774, l1: 0.008552, l2: 0.009771, l3: 0.009057, l4: 0.029050, l5: 0.031622, l6: 0.029130

[epoch: 104/100000, batch:    80/  187, ite: 9722] train loss: 0.119414, tar: 0.012341 
l0: 0.004784, l1: 0.005185, l2: 0.004940, l3: 0.005984, l4: 0.008849, l5: 0.008973, l6: 0.009652

[epoch: 104/100000, batch:    82/  187, ite: 9723] train loss: 0.119373, tar: 0.012337 
l0: 0.010198, l1: 0.010492, l2: 0.010626, l3: 0.011164, l4: 0.023018, l5: 0.021622, l6: 0.022443

[epoch: 104/100000, batch:    84/  187, ite: 9724] train loss: 0.119367, tar: 0.012336 
l0: 0.015965, l1: 0.017883, l2: 0.013635, l3: 0.013456, l4: 0.016412, l5: 0.015853, l6: 0.016571

[epoch: 104/100000, batch:    86/  187, ite: 9725] train loss: 0.119362, tar: 0.012338 
l0: 0.007005, l1: 0.007197, l2: 0.006406, l3: 0.006562, l4: 0.014056, l5: 0.013356, l6: 0.011660

[epoch: 104/100000, batch:    88/  187, ite: 9726] train loss: 0.119331, tar: 0.012335 
l0: 0.007271, l1: 0.008033, l2: 0.011985, l3: 0.010133, l4: 0.017395, l5: 0.014914, l6: 0.016563

[epoch: 104/100000, batch:    90/  187, ite: 9727] train loss: 0.119312, tar: 0.012332 
l0: 0.009331, l1: 0.008986, l2: 0.010515, l3: 0.011625, l4: 0.015023, l5: 0.015394, l6: 0.017247

[epoch: 104/100000, batch:    92/  187, ite: 9728] train loss: 0.119294, tar: 0.012330 
l0: 0.006950, l1: 0.007232, l2: 0.007660, l3: 0.008319, l4: 0.017826, l5: 0.018291, l6: 0.016683

[epoch: 104/100000, batch:    94/  187, ite: 9729] train loss: 0.119273, tar: 0.012327 
l0: 0.008692, l1: 0.008326, l2: 0.008993, l3: 0.010233, l4: 0.027540, l5: 0.027113, l6: 0.030337

[epoch: 104/100000, batch:    96/  187, ite: 9730] train loss: 0.119274, tar: 0.012325 
l0: 0.008882, l1: 0.009052, l2: 0.009620, l3: 0.009796, l4: 0.014851, l5: 0.013380, l6: 0.012349

[epoch: 104/100000, batch:    98/  187, ite: 9731] train loss: 0.119250, tar: 0.012323 
l0: 0.009515, l1: 0.007446, l2: 0.012798, l3: 0.015800, l4: 0.032026, l5: 0.037967, l6: 0.035383

[epoch: 104/100000, batch:   100/  187, ite: 9732] train loss: 0.119268, tar: 0.012321 
l0: 0.006265, l1: 0.005921, l2: 0.008244, l3: 0.008711, l4: 0.020146, l5: 0.018084, l6: 0.018280

[epoch: 104/100000, batch:   102/  187, ite: 9733] train loss: 0.119249, tar: 0.012318 
l0: 0.012025, l1: 0.011607, l2: 0.014963, l3: 0.015294, l4: 0.021780, l5: 0.015206, l6: 0.021134

[epoch: 104/100000, batch:   104/  187, ite: 9734] train loss: 0.119244, tar: 0.012318 
l0: 0.009406, l1: 0.009736, l2: 0.010864, l3: 0.010699, l4: 0.018524, l5: 0.017003, l6: 0.017055

[epoch: 104/100000, batch:   106/  187, ite: 9735] train loss: 0.119230, tar: 0.012316 
l0: 0.009796, l1: 0.011332, l2: 0.011184, l3: 0.011190, l4: 0.009208, l5: 0.008171, l6: 0.008776

[epoch: 104/100000, batch:   108/  187, ite: 9736] train loss: 0.119201, tar: 0.012315 
l0: 0.007509, l1: 0.007392, l2: 0.009235, l3: 0.010444, l4: 0.018554, l5: 0.018387, l6: 0.014757

[epoch: 104/100000, batch:   110/  187, ite: 9737] train loss: 0.119182, tar: 0.012312 
l0: 0.011476, l1: 0.011503, l2: 0.010753, l3: 0.011103, l4: 0.019309, l5: 0.019721, l6: 0.017753

[epoch: 104/100000, batch:   112/  187, ite: 9738] train loss: 0.119172, tar: 0.012311 
l0: 0.004940, l1: 0.005188, l2: 0.005955, l3: 0.005020, l4: 0.012258, l5: 0.010396, l6: 0.009345

[epoch: 104/100000, batch:   114/  187, ite: 9739] train loss: 0.119134, tar: 0.012307 
l0: 0.009236, l1: 0.010725, l2: 0.010768, l3: 0.010368, l4: 0.012880, l5: 0.012873, l6: 0.015139

[epoch: 104/100000, batch:   116/  187, ite: 9740] train loss: 0.119113, tar: 0.012305 
l0: 0.009608, l1: 0.010560, l2: 0.010848, l3: 0.011318, l4: 0.018464, l5: 0.017978, l6: 0.023029

[epoch: 104/100000, batch:   118/  187, ite: 9741] train loss: 0.119103, tar: 0.012304 
l0: 0.008643, l1: 0.009149, l2: 0.009114, l3: 0.009493, l4: 0.016105, l5: 0.015207, l6: 0.012258

[epoch: 104/100000, batch:   120/  187, ite: 9742] train loss: 0.119080, tar: 0.012302 
l0: 0.006267, l1: 0.006644, l2: 0.006250, l3: 0.006005, l4: 0.010208, l5: 0.012088, l6: 0.009672

[epoch: 104/100000, batch:   122/  187, ite: 9743] train loss: 0.119045, tar: 0.012298 
l0: 0.010043, l1: 0.011066, l2: 0.011456, l3: 0.011601, l4: 0.012934, l5: 0.010606, l6: 0.014493

[epoch: 104/100000, batch:   124/  187, ite: 9744] train loss: 0.119024, tar: 0.012297 
l0: 0.009846, l1: 0.009271, l2: 0.011121, l3: 0.011364, l4: 0.016066, l5: 0.017046, l6: 0.021450

[epoch: 104/100000, batch:   126/  187, ite: 9745] train loss: 0.119010, tar: 0.012295 
l0: 0.007607, l1: 0.006818, l2: 0.008091, l3: 0.009989, l4: 0.011992, l5: 0.014440, l6: 0.012972

[epoch: 104/100000, batch:   128/  187, ite: 9746] train loss: 0.118983, tar: 0.012293 
l0: 0.010102, l1: 0.010748, l2: 0.011037, l3: 0.010162, l4: 0.013359, l5: 0.014353, l6: 0.014845

[epoch: 104/100000, batch:   130/  187, ite: 9747] train loss: 0.118964, tar: 0.012292 
l0: 0.011854, l1: 0.011849, l2: 0.013058, l3: 0.013709, l4: 0.017278, l5: 0.016446, l6: 0.014870

[epoch: 104/100000, batch:   132/  187, ite: 9748] train loss: 0.118952, tar: 0.012291 
l0: 0.012686, l1: 0.012778, l2: 0.013709, l3: 0.014339, l4: 0.018837, l5: 0.018762, l6: 0.018511

[epoch: 104/100000, batch:   134/  187, ite: 9749] train loss: 0.118947, tar: 0.012291 
l0: 0.005853, l1: 0.006761, l2: 0.007642, l3: 0.007619, l4: 0.012184, l5: 0.010008, l6: 0.013910

[epoch: 104/100000, batch:   136/  187, ite: 9750] train loss: 0.118916, tar: 0.012288 
l0: 0.007603, l1: 0.006574, l2: 0.008172, l3: 0.008362, l4: 0.014665, l5: 0.018423, l6: 0.021071

[epoch: 104/100000, batch:   138/  187, ite: 9751] train loss: 0.118896, tar: 0.012285 
l0: 0.009109, l1: 0.010224, l2: 0.009250, l3: 0.010077, l4: 0.010751, l5: 0.011532, l6: 0.016985

[epoch: 104/100000, batch:   140/  187, ite: 9752] train loss: 0.118873, tar: 0.012283 
l0: 0.009148, l1: 0.009446, l2: 0.009918, l3: 0.010731, l4: 0.016024, l5: 0.016172, l6: 0.017060

[epoch: 104/100000, batch:   142/  187, ite: 9753] train loss: 0.118855, tar: 0.012282 
l0: 0.010964, l1: 0.011971, l2: 0.013560, l3: 0.012849, l4: 0.011884, l5: 0.010898, l6: 0.013357

[epoch: 104/100000, batch:   144/  187, ite: 9754] train loss: 0.118836, tar: 0.012281 
l0: 0.007235, l1: 0.007727, l2: 0.007922, l3: 0.008602, l4: 0.017045, l5: 0.013539, l6: 0.011851

[epoch: 104/100000, batch:   146/  187, ite: 9755] train loss: 0.118811, tar: 0.012278 
l0: 0.010964, l1: 0.011340, l2: 0.012675, l3: 0.013035, l4: 0.018088, l5: 0.015173, l6: 0.017300

[epoch: 104/100000, batch:   148/  187, ite: 9756] train loss: 0.118799, tar: 0.012277 
l0: 0.005027, l1: 0.005636, l2: 0.005413, l3: 0.004793, l4: 0.007338, l5: 0.007852, l6: 0.014083

[epoch: 104/100000, batch:   150/  187, ite: 9757] train loss: 0.118760, tar: 0.012273 
l0: 0.010099, l1: 0.010876, l2: 0.010032, l3: 0.009777, l4: 0.017086, l5: 0.011698, l6: 0.014296

[epoch: 104/100000, batch:   152/  187, ite: 9758] train loss: 0.118740, tar: 0.012272 
l0: 0.023463, l1: 0.027781, l2: 0.022462, l3: 0.020320, l4: 0.025808, l5: 0.020463, l6: 0.029329

[epoch: 104/100000, batch:   154/  187, ite: 9759] train loss: 0.118769, tar: 0.012278 
l0: 0.009971, l1: 0.009101, l2: 0.013638, l3: 0.012308, l4: 0.020780, l5: 0.020241, l6: 0.020355

[epoch: 104/100000, batch:   156/  187, ite: 9760] train loss: 0.118762, tar: 0.012277 
l0: 0.006167, l1: 0.004948, l2: 0.007821, l3: 0.008482, l4: 0.014758, l5: 0.017481, l6: 0.022478

[epoch: 104/100000, batch:   158/  187, ite: 9761] train loss: 0.118741, tar: 0.012273 
l0: 0.007451, l1: 0.007421, l2: 0.008791, l3: 0.009074, l4: 0.012507, l5: 0.012645, l6: 0.016719

[epoch: 104/100000, batch:   160/  187, ite: 9762] train loss: 0.118716, tar: 0.012271 
l0: 0.005717, l1: 0.006408, l2: 0.007538, l3: 0.005433, l4: 0.006446, l5: 0.006728, l6: 0.006283

[epoch: 104/100000, batch:   162/  187, ite: 9763] train loss: 0.118674, tar: 0.012267 
l0: 0.008219, l1: 0.009697, l2: 0.007836, l3: 0.009009, l4: 0.016152, l5: 0.012828, l6: 0.012799

[epoch: 104/100000, batch:   164/  187, ite: 9764] train loss: 0.118650, tar: 0.012265 
l0: 0.005695, l1: 0.005847, l2: 0.006619, l3: 0.007155, l4: 0.008618, l5: 0.007905, l6: 0.009484

[epoch: 104/100000, batch:   166/  187, ite: 9765] train loss: 0.118612, tar: 0.012261 
l0: 0.007349, l1: 0.006531, l2: 0.006571, l3: 0.008370, l4: 0.015066, l5: 0.013469, l6: 0.013565

[epoch: 104/100000, batch:   168/  187, ite: 9766] train loss: 0.118585, tar: 0.012258 
l0: 0.010011, l1: 0.011191, l2: 0.008217, l3: 0.007938, l4: 0.017536, l5: 0.014202, l6: 0.014627

[epoch: 104/100000, batch:   170/  187, ite: 9767] train loss: 0.118566, tar: 0.012257 
l0: 0.009588, l1: 0.010316, l2: 0.012467, l3: 0.013296, l4: 0.015659, l5: 0.013266, l6: 0.014084

[epoch: 104/100000, batch:   172/  187, ite: 9768] train loss: 0.118549, tar: 0.012255 
l0: 0.002766, l1: 0.003024, l2: 0.005967, l3: 0.004742, l4: 0.004428, l5: 0.005265, l6: 0.005902

[epoch: 104/100000, batch:   174/  187, ite: 9769] train loss: 0.118500, tar: 0.012250 
l0: 0.009631, l1: 0.009604, l2: 0.012682, l3: 0.012433, l4: 0.018333, l5: 0.017844, l6: 0.019282

[epoch: 104/100000, batch:   176/  187, ite: 9770] train loss: 0.118489, tar: 0.012249 
l0: 0.010003, l1: 0.010432, l2: 0.011316, l3: 0.010691, l4: 0.021530, l5: 0.020437, l6: 0.020683

[epoch: 104/100000, batch:   178/  187, ite: 9771] train loss: 0.118482, tar: 0.012247 
l0: 0.014634, l1: 0.015080, l2: 0.015318, l3: 0.016235, l4: 0.019542, l5: 0.019802, l6: 0.030120

[epoch: 104/100000, batch:   180/  187, ite: 9772] train loss: 0.118489, tar: 0.012249 
l0: 0.009066, l1: 0.007785, l2: 0.010867, l3: 0.010558, l4: 0.013272, l5: 0.017393, l6: 0.023547

[epoch: 104/100000, batch:   182/  187, ite: 9773] train loss: 0.118474, tar: 0.012247 
l0: 0.012824, l1: 0.014752, l2: 0.013034, l3: 0.012655, l4: 0.013945, l5: 0.012956, l6: 0.013475

[epoch: 104/100000, batch:   184/  187, ite: 9774] train loss: 0.118460, tar: 0.012247 
l0: 0.006446, l1: 0.007509, l2: 0.009367, l3: 0.008704, l4: 0.015709, l5: 0.012371, l6: 0.010077

[epoch: 104/100000, batch:   186/  187, ite: 9775] train loss: 0.118433, tar: 0.012244 
l0: 0.011522, l1: 0.012764, l2: 0.013000, l3: 0.011516, l4: 0.012582, l5: 0.012951, l6: 0.014787

[epoch: 104/100000, batch:   188/  187, ite: 9776] train loss: 0.118416, tar: 0.012243 
l0: 0.020776, l1: 0.022030, l2: 0.022913, l3: 0.021623, l4: 0.026737, l5: 0.025855, l6: 0.027623

[epoch: 105/100000, batch:     2/  187, ite: 9777] train loss: 0.118444, tar: 0.012248 
l0: 0.009784, l1: 0.010589, l2: 0.010377, l3: 0.010549, l4: 0.015958, l5: 0.014100, l6: 0.015805

[epoch: 105/100000, batch:     4/  187, ite: 9778] train loss: 0.118426, tar: 0.012247 
l0: 0.010279, l1: 0.011772, l2: 0.011495, l3: 0.011167, l4: 0.012228, l5: 0.010282, l6: 0.008831

[epoch: 105/100000, batch:     6/  187, ite: 9779] train loss: 0.118403, tar: 0.012246 
l0: 0.012205, l1: 0.013008, l2: 0.012150, l3: 0.011519, l4: 0.015077, l5: 0.015490, l6: 0.016434

[epoch: 105/100000, batch:     8/  187, ite: 9780] train loss: 0.118390, tar: 0.012246 
l0: 0.007280, l1: 0.007739, l2: 0.008326, l3: 0.008052, l4: 0.011170, l5: 0.010554, l6: 0.009635

[epoch: 105/100000, batch:    10/  187, ite: 9781] train loss: 0.118359, tar: 0.012243 
l0: 0.007857, l1: 0.007802, l2: 0.007221, l3: 0.006712, l4: 0.016836, l5: 0.014904, l6: 0.014998

[epoch: 105/100000, batch:    12/  187, ite: 9782] train loss: 0.118335, tar: 0.012240 
l0: 0.009949, l1: 0.009562, l2: 0.011637, l3: 0.012945, l4: 0.015666, l5: 0.016334, l6: 0.017684

[epoch: 105/100000, batch:    14/  187, ite: 9783] train loss: 0.118321, tar: 0.012239 
l0: 0.008422, l1: 0.009336, l2: 0.009426, l3: 0.009299, l4: 0.012731, l5: 0.011985, l6: 0.012783

[epoch: 105/100000, batch:    16/  187, ite: 9784] train loss: 0.118296, tar: 0.012237 
l0: 0.010396, l1: 0.010677, l2: 0.012362, l3: 0.011933, l4: 0.014978, l5: 0.015030, l6: 0.017917

[epoch: 105/100000, batch:    18/  187, ite: 9785] train loss: 0.118282, tar: 0.012236 
l0: 0.010336, l1: 0.010160, l2: 0.012803, l3: 0.013194, l4: 0.018349, l5: 0.017463, l6: 0.017382

[epoch: 105/100000, batch:    20/  187, ite: 9786] train loss: 0.118272, tar: 0.012235 
l0: 0.009224, l1: 0.009322, l2: 0.009655, l3: 0.009425, l4: 0.009636, l5: 0.008829, l6: 0.010813

[epoch: 105/100000, batch:    22/  187, ite: 9787] train loss: 0.118243, tar: 0.012233 
l0: 0.009247, l1: 0.008917, l2: 0.010188, l3: 0.010339, l4: 0.016883, l5: 0.018084, l6: 0.020505

[epoch: 105/100000, batch:    24/  187, ite: 9788] train loss: 0.118230, tar: 0.012232 
l0: 0.006096, l1: 0.006315, l2: 0.007189, l3: 0.007437, l4: 0.010958, l5: 0.011073, l6: 0.011113

[epoch: 105/100000, batch:    26/  187, ite: 9789] train loss: 0.118197, tar: 0.012228 
l0: 0.009798, l1: 0.010601, l2: 0.009024, l3: 0.009892, l4: 0.013199, l5: 0.013202, l6: 0.013856

[epoch: 105/100000, batch:    28/  187, ite: 9790] train loss: 0.118176, tar: 0.012227 
l0: 0.004108, l1: 0.004841, l2: 0.006048, l3: 0.005069, l4: 0.010088, l5: 0.005889, l6: 0.005750

[epoch: 105/100000, batch:    30/  187, ite: 9791] train loss: 0.118133, tar: 0.012222 
l0: 0.006620, l1: 0.007218, l2: 0.006693, l3: 0.006626, l4: 0.012326, l5: 0.011584, l6: 0.014772

[epoch: 105/100000, batch:    32/  187, ite: 9792] train loss: 0.118104, tar: 0.012219 
l0: 0.010418, l1: 0.010627, l2: 0.012366, l3: 0.012680, l4: 0.014183, l5: 0.012072, l6: 0.014466

[epoch: 105/100000, batch:    34/  187, ite: 9793] train loss: 0.118086, tar: 0.012218 
l0: 0.009563, l1: 0.009688, l2: 0.011138, l3: 0.013182, l4: 0.014305, l5: 0.010885, l6: 0.012202

[epoch: 105/100000, batch:    36/  187, ite: 9794] train loss: 0.118066, tar: 0.012217 
l0: 0.004432, l1: 0.004577, l2: 0.005303, l3: 0.005763, l4: 0.011471, l5: 0.008990, l6: 0.011239

[epoch: 105/100000, batch:    38/  187, ite: 9795] train loss: 0.118029, tar: 0.012212 
l0: 0.011378, l1: 0.012211, l2: 0.012210, l3: 0.011770, l4: 0.018314, l5: 0.015142, l6: 0.015490

[epoch: 105/100000, batch:    40/  187, ite: 9796] train loss: 0.118017, tar: 0.012212 
l0: 0.006947, l1: 0.008037, l2: 0.007052, l3: 0.007953, l4: 0.010936, l5: 0.010671, l6: 0.010847

[epoch: 105/100000, batch:    42/  187, ite: 9797] train loss: 0.117986, tar: 0.012209 
l0: 0.008348, l1: 0.009999, l2: 0.008922, l3: 0.009252, l4: 0.011629, l5: 0.009051, l6: 0.010268

[epoch: 105/100000, batch:    44/  187, ite: 9798] train loss: 0.117958, tar: 0.012207 
l0: 0.005236, l1: 0.005894, l2: 0.004757, l3: 0.004891, l4: 0.006544, l5: 0.006283, l6: 0.007272

[epoch: 105/100000, batch:    46/  187, ite: 9799] train loss: 0.117915, tar: 0.012203 
l0: 0.004872, l1: 0.005247, l2: 0.005130, l3: 0.005668, l4: 0.009732, l5: 0.008808, l6: 0.009453

[epoch: 105/100000, batch:    48/  187, ite: 9800] train loss: 0.117877, tar: 0.012199 
l0: 0.012466, l1: 0.011774, l2: 0.011502, l3: 0.011604, l4: 0.029267, l5: 0.027210, l6: 0.030488

[epoch: 105/100000, batch:    50/  187, ite: 9801] train loss: 0.117886, tar: 0.012199 
l0: 0.011298, l1: 0.011296, l2: 0.011381, l3: 0.012262, l4: 0.021257, l5: 0.019778, l6: 0.015929

[epoch: 105/100000, batch:    52/  187, ite: 9802] train loss: 0.117878, tar: 0.012198 
l0: 0.007535, l1: 0.007801, l2: 0.009758, l3: 0.010832, l4: 0.019845, l5: 0.017047, l6: 0.011362

[epoch: 105/100000, batch:    54/  187, ite: 9803] train loss: 0.117859, tar: 0.012196 
l0: 0.005973, l1: 0.006066, l2: 0.007083, l3: 0.007694, l4: 0.012276, l5: 0.009116, l6: 0.010789

[epoch: 105/100000, batch:    56/  187, ite: 9804] train loss: 0.117826, tar: 0.012192 
l0: 0.011226, l1: 0.012174, l2: 0.010944, l3: 0.010710, l4: 0.014783, l5: 0.013720, l6: 0.015132

[epoch: 105/100000, batch:    58/  187, ite: 9805] train loss: 0.117810, tar: 0.012192 
l0: 0.006815, l1: 0.006428, l2: 0.007564, l3: 0.007664, l4: 0.010180, l5: 0.010219, l6: 0.011617

[epoch: 105/100000, batch:    60/  187, ite: 9806] train loss: 0.117778, tar: 0.012189 
l0: 0.011608, l1: 0.012910, l2: 0.011890, l3: 0.009926, l4: 0.013073, l5: 0.011087, l6: 0.009386

[epoch: 105/100000, batch:    62/  187, ite: 9807] train loss: 0.117757, tar: 0.012189 
l0: 0.006045, l1: 0.006086, l2: 0.008091, l3: 0.007403, l4: 0.007659, l5: 0.006552, l6: 0.007128

[epoch: 105/100000, batch:    64/  187, ite: 9808] train loss: 0.117719, tar: 0.012185 
l0: 0.010949, l1: 0.010467, l2: 0.011027, l3: 0.011316, l4: 0.015992, l5: 0.015359, l6: 0.019226

[epoch: 105/100000, batch:    66/  187, ite: 9809] train loss: 0.117706, tar: 0.012185 
l0: 0.005691, l1: 0.005790, l2: 0.006643, l3: 0.007027, l4: 0.010557, l5: 0.010512, l6: 0.014269

[epoch: 105/100000, batch:    68/  187, ite: 9810] train loss: 0.117675, tar: 0.012181 
l0: 0.013356, l1: 0.013568, l2: 0.014306, l3: 0.010569, l4: 0.025618, l5: 0.022480, l6: 0.020625

[epoch: 105/100000, batch:    70/  187, ite: 9811] train loss: 0.117676, tar: 0.012182 
l0: 0.010618, l1: 0.010486, l2: 0.009736, l3: 0.010825, l4: 0.014163, l5: 0.012408, l6: 0.019495

[epoch: 105/100000, batch:    72/  187, ite: 9812] train loss: 0.117660, tar: 0.012181 
l0: 0.004449, l1: 0.004409, l2: 0.005491, l3: 0.005584, l4: 0.009886, l5: 0.010457, l6: 0.010990

[epoch: 105/100000, batch:    74/  187, ite: 9813] train loss: 0.117623, tar: 0.012176 
l0: 0.013334, l1: 0.015186, l2: 0.015268, l3: 0.014109, l4: 0.020571, l5: 0.015456, l6: 0.018404

[epoch: 105/100000, batch:    76/  187, ite: 9814] train loss: 0.117620, tar: 0.012177 
l0: 0.012824, l1: 0.012996, l2: 0.013346, l3: 0.014919, l4: 0.019864, l5: 0.020202, l6: 0.018839

[epoch: 105/100000, batch:    78/  187, ite: 9815] train loss: 0.117618, tar: 0.012177 
l0: 0.012348, l1: 0.012372, l2: 0.017787, l3: 0.020796, l4: 0.024285, l5: 0.019289, l6: 0.019292

[epoch: 105/100000, batch:    80/  187, ite: 9816] train loss: 0.117623, tar: 0.012178 
l0: 0.012743, l1: 0.013140, l2: 0.012565, l3: 0.013176, l4: 0.018610, l5: 0.016760, l6: 0.018807

[epoch: 105/100000, batch:    82/  187, ite: 9817] train loss: 0.117616, tar: 0.012178 
l0: 0.007062, l1: 0.007614, l2: 0.007497, l3: 0.005787, l4: 0.010235, l5: 0.012580, l6: 0.009055

[epoch: 105/100000, batch:    84/  187, ite: 9818] train loss: 0.117584, tar: 0.012175 
l0: 0.011599, l1: 0.010772, l2: 0.013001, l3: 0.017840, l4: 0.026655, l5: 0.021987, l6: 0.012983

[epoch: 105/100000, batch:    86/  187, ite: 9819] train loss: 0.117583, tar: 0.012175 
l0: 0.013084, l1: 0.011922, l2: 0.013403, l3: 0.016041, l4: 0.037075, l5: 0.036247, l6: 0.037372

[epoch: 105/100000, batch:    88/  187, ite: 9820] train loss: 0.117609, tar: 0.012175 
l0: 0.009548, l1: 0.009018, l2: 0.012899, l3: 0.014778, l4: 0.019710, l5: 0.018483, l6: 0.015078

[epoch: 105/100000, batch:    90/  187, ite: 9821] train loss: 0.117599, tar: 0.012174 
l0: 0.003795, l1: 0.004027, l2: 0.004455, l3: 0.004998, l4: 0.008916, l5: 0.008182, l6: 0.008467

[epoch: 105/100000, batch:    92/  187, ite: 9822] train loss: 0.117558, tar: 0.012169 
l0: 0.008152, l1: 0.008896, l2: 0.010175, l3: 0.008264, l4: 0.009131, l5: 0.008915, l6: 0.007080

[epoch: 105/100000, batch:    94/  187, ite: 9823] train loss: 0.117527, tar: 0.012167 
l0: 0.008175, l1: 0.008086, l2: 0.009338, l3: 0.009348, l4: 0.016348, l5: 0.015657, l6: 0.019817

[epoch: 105/100000, batch:    96/  187, ite: 9824] train loss: 0.117510, tar: 0.012165 
l0: 0.017089, l1: 0.017980, l2: 0.015847, l3: 0.015961, l4: 0.032685, l5: 0.026519, l6: 0.023685

[epoch: 105/100000, batch:    98/  187, ite: 9825] train loss: 0.117527, tar: 0.012168 
l0: 0.005897, l1: 0.005903, l2: 0.006444, l3: 0.008091, l4: 0.010092, l5: 0.009585, l6: 0.014281

[epoch: 105/100000, batch:   100/  187, ite: 9826] train loss: 0.117496, tar: 0.012164 
l0: 0.010233, l1: 0.012027, l2: 0.014824, l3: 0.010535, l4: 0.018517, l5: 0.016644, l6: 0.013204

[epoch: 105/100000, batch:   102/  187, ite: 9827] train loss: 0.117484, tar: 0.012163 
l0: 0.005765, l1: 0.005631, l2: 0.005917, l3: 0.006117, l4: 0.011837, l5: 0.013119, l6: 0.013688

[epoch: 105/100000, batch:   104/  187, ite: 9828] train loss: 0.117454, tar: 0.012160 
l0: 0.011531, l1: 0.012561, l2: 0.013296, l3: 0.013222, l4: 0.017486, l5: 0.013812, l6: 0.015947

[epoch: 105/100000, batch:   106/  187, ite: 9829] train loss: 0.117443, tar: 0.012159 
l0: 0.003684, l1: 0.004429, l2: 0.005380, l3: 0.004760, l4: 0.010184, l5: 0.009428, l6: 0.008655

[epoch: 105/100000, batch:   108/  187, ite: 9830] train loss: 0.117405, tar: 0.012155 
l0: 0.007348, l1: 0.007222, l2: 0.011159, l3: 0.011004, l4: 0.015210, l5: 0.015267, l6: 0.015593

[epoch: 105/100000, batch:   110/  187, ite: 9831] train loss: 0.117386, tar: 0.012152 
l0: 0.005922, l1: 0.006392, l2: 0.007667, l3: 0.006890, l4: 0.008038, l5: 0.010407, l6: 0.013582

[epoch: 105/100000, batch:   112/  187, ite: 9832] train loss: 0.117354, tar: 0.012149 
l0: 0.009906, l1: 0.010287, l2: 0.010952, l3: 0.010276, l4: 0.014645, l5: 0.015171, l6: 0.013596

[epoch: 105/100000, batch:   114/  187, ite: 9833] train loss: 0.117336, tar: 0.012147 
l0: 0.016110, l1: 0.017832, l2: 0.019074, l3: 0.016960, l4: 0.025034, l5: 0.021255, l6: 0.020205

[epoch: 105/100000, batch:   116/  187, ite: 9834] train loss: 0.117346, tar: 0.012149 
l0: 0.011554, l1: 0.011242, l2: 0.011684, l3: 0.012575, l4: 0.027828, l5: 0.025709, l6: 0.027126

[epoch: 105/100000, batch:   118/  187, ite: 9835] train loss: 0.117352, tar: 0.012149 
l0: 0.008210, l1: 0.008212, l2: 0.008967, l3: 0.010723, l4: 0.019476, l5: 0.017273, l6: 0.015690

[epoch: 105/100000, batch:   120/  187, ite: 9836] train loss: 0.117336, tar: 0.012147 
l0: 0.012548, l1: 0.013072, l2: 0.012426, l3: 0.013780, l4: 0.021243, l5: 0.020415, l6: 0.022841

[epoch: 105/100000, batch:   122/  187, ite: 9837] train loss: 0.117336, tar: 0.012147 
l0: 0.009710, l1: 0.008298, l2: 0.009326, l3: 0.009896, l4: 0.011675, l5: 0.015038, l6: 0.020157

[epoch: 105/100000, batch:   124/  187, ite: 9838] train loss: 0.117318, tar: 0.012146 
l0: 0.005244, l1: 0.005273, l2: 0.005643, l3: 0.007171, l4: 0.008748, l5: 0.012668, l6: 0.013792

[epoch: 105/100000, batch:   126/  187, ite: 9839] train loss: 0.117286, tar: 0.012142 
l0: 0.011717, l1: 0.010800, l2: 0.012232, l3: 0.013820, l4: 0.021992, l5: 0.020017, l6: 0.024462

[epoch: 105/100000, batch:   128/  187, ite: 9840] train loss: 0.117285, tar: 0.012142 
l0: 0.007481, l1: 0.007771, l2: 0.006470, l3: 0.007758, l4: 0.017644, l5: 0.013865, l6: 0.017155

[epoch: 105/100000, batch:   130/  187, ite: 9841] train loss: 0.117263, tar: 0.012139 
l0: 0.009427, l1: 0.009091, l2: 0.009904, l3: 0.010829, l4: 0.025177, l5: 0.021039, l6: 0.025050

[epoch: 105/100000, batch:   132/  187, ite: 9842] train loss: 0.117260, tar: 0.012138 
l0: 0.010522, l1: 0.010810, l2: 0.010828, l3: 0.011355, l4: 0.018049, l5: 0.018573, l6: 0.019144

[epoch: 105/100000, batch:   134/  187, ite: 9843] train loss: 0.117250, tar: 0.012137 
l0: 0.008546, l1: 0.007395, l2: 0.009952, l3: 0.012139, l4: 0.024215, l5: 0.024931, l6: 0.021128

[epoch: 105/100000, batch:   136/  187, ite: 9844] train loss: 0.117245, tar: 0.012135 
l0: 0.008647, l1: 0.009640, l2: 0.009474, l3: 0.009476, l4: 0.019902, l5: 0.016829, l6: 0.016226

[epoch: 105/100000, batch:   138/  187, ite: 9845] train loss: 0.117230, tar: 0.012133 
l0: 0.011248, l1: 0.010685, l2: 0.015020, l3: 0.017272, l4: 0.013781, l5: 0.014749, l6: 0.018032

[epoch: 105/100000, batch:   140/  187, ite: 9846] train loss: 0.117221, tar: 0.012133 
l0: 0.010543, l1: 0.011089, l2: 0.012287, l3: 0.011922, l4: 0.017070, l5: 0.016655, l6: 0.019320

[epoch: 105/100000, batch:   142/  187, ite: 9847] train loss: 0.117212, tar: 0.012132 
l0: 0.006045, l1: 0.006233, l2: 0.007158, l3: 0.007378, l4: 0.014944, l5: 0.011060, l6: 0.010243

[epoch: 105/100000, batch:   144/  187, ite: 9848] train loss: 0.117182, tar: 0.012129 
l0: 0.008121, l1: 0.009762, l2: 0.007822, l3: 0.008256, l4: 0.011472, l5: 0.010812, l6: 0.015516

[epoch: 105/100000, batch:   146/  187, ite: 9849] train loss: 0.117158, tar: 0.012126 
l0: 0.010367, l1: 0.010044, l2: 0.014232, l3: 0.012378, l4: 0.016846, l5: 0.017200, l6: 0.023802

[epoch: 105/100000, batch:   148/  187, ite: 9850] train loss: 0.117151, tar: 0.012125 
l0: 0.011002, l1: 0.011616, l2: 0.010959, l3: 0.010535, l4: 0.016075, l5: 0.015078, l6: 0.017908

[epoch: 105/100000, batch:   150/  187, ite: 9851] train loss: 0.117138, tar: 0.012125 
l0: 0.012043, l1: 0.012980, l2: 0.013285, l3: 0.012160, l4: 0.022409, l5: 0.021752, l6: 0.022706

[epoch: 105/100000, batch:   152/  187, ite: 9852] train loss: 0.117138, tar: 0.012125 
l0: 0.005063, l1: 0.006903, l2: 0.003867, l3: 0.004635, l4: 0.012736, l5: 0.010448, l6: 0.008723

[epoch: 105/100000, batch:   154/  187, ite: 9853] train loss: 0.117103, tar: 0.012121 
l0: 0.018877, l1: 0.018451, l2: 0.020736, l3: 0.022937, l4: 0.044866, l5: 0.032956, l6: 0.026370

[epoch: 105/100000, batch:   156/  187, ite: 9854] train loss: 0.117140, tar: 0.012125 
l0: 0.007390, l1: 0.008268, l2: 0.006798, l3: 0.006116, l4: 0.012060, l5: 0.012787, l6: 0.014462

[epoch: 105/100000, batch:   158/  187, ite: 9855] train loss: 0.117113, tar: 0.012122 
l0: 0.013422, l1: 0.012709, l2: 0.013679, l3: 0.014245, l4: 0.024615, l5: 0.021380, l6: 0.023758

[epoch: 105/100000, batch:   160/  187, ite: 9856] train loss: 0.117117, tar: 0.012123 
l0: 0.006621, l1: 0.006467, l2: 0.009017, l3: 0.009521, l4: 0.012272, l5: 0.011594, l6: 0.011984

[epoch: 105/100000, batch:   162/  187, ite: 9857] train loss: 0.117090, tar: 0.012120 
l0: 0.008098, l1: 0.009220, l2: 0.008175, l3: 0.008147, l4: 0.012703, l5: 0.011533, l6: 0.011352

[epoch: 105/100000, batch:   164/  187, ite: 9858] train loss: 0.117065, tar: 0.012118 
l0: 0.007765, l1: 0.008301, l2: 0.009019, l3: 0.009685, l4: 0.021188, l5: 0.015820, l6: 0.014821

[epoch: 105/100000, batch:   166/  187, ite: 9859] train loss: 0.117048, tar: 0.012115 
l0: 0.007343, l1: 0.007890, l2: 0.009651, l3: 0.008109, l4: 0.011022, l5: 0.012529, l6: 0.012670

[epoch: 105/100000, batch:   168/  187, ite: 9860] train loss: 0.117022, tar: 0.012113 
l0: 0.007698, l1: 0.008056, l2: 0.008641, l3: 0.008449, l4: 0.015374, l5: 0.015807, l6: 0.017444

[epoch: 105/100000, batch:   170/  187, ite: 9861] train loss: 0.117003, tar: 0.012110 
l0: 0.004924, l1: 0.006302, l2: 0.003649, l3: 0.003707, l4: 0.010981, l5: 0.009006, l6: 0.010782

[epoch: 105/100000, batch:   172/  187, ite: 9862] train loss: 0.116967, tar: 0.012106 
l0: 0.010999, l1: 0.012711, l2: 0.015321, l3: 0.013454, l4: 0.013874, l5: 0.012351, l6: 0.019911

[epoch: 105/100000, batch:   174/  187, ite: 9863] train loss: 0.116957, tar: 0.012106 
l0: 0.007857, l1: 0.008057, l2: 0.007947, l3: 0.007849, l4: 0.010445, l5: 0.010839, l6: 0.014870

[epoch: 105/100000, batch:   176/  187, ite: 9864] train loss: 0.116931, tar: 0.012104 
l0: 0.010728, l1: 0.011694, l2: 0.014233, l3: 0.013560, l4: 0.012559, l5: 0.012243, l6: 0.011239

[epoch: 105/100000, batch:   178/  187, ite: 9865] train loss: 0.116914, tar: 0.012103 
l0: 0.009617, l1: 0.009770, l2: 0.010265, l3: 0.009574, l4: 0.011779, l5: 0.009916, l6: 0.013184

[epoch: 105/100000, batch:   180/  187, ite: 9866] train loss: 0.116891, tar: 0.012102 
l0: 0.011576, l1: 0.011782, l2: 0.011019, l3: 0.011347, l4: 0.018093, l5: 0.020153, l6: 0.020899

[epoch: 105/100000, batch:   182/  187, ite: 9867] train loss: 0.116885, tar: 0.012101 
l0: 0.016880, l1: 0.015462, l2: 0.017773, l3: 0.019940, l4: 0.028376, l5: 0.027352, l6: 0.027783

[epoch: 105/100000, batch:   184/  187, ite: 9868] train loss: 0.116905, tar: 0.012104 
l0: 0.007142, l1: 0.007389, l2: 0.008411, l3: 0.009288, l4: 0.016033, l5: 0.012429, l6: 0.013237

[epoch: 105/100000, batch:   186/  187, ite: 9869] train loss: 0.116882, tar: 0.012101 
l0: 0.009718, l1: 0.011155, l2: 0.009121, l3: 0.010816, l4: 0.017003, l5: 0.015028, l6: 0.012461

[epoch: 105/100000, batch:   188/  187, ite: 9870] train loss: 0.116865, tar: 0.012100 
l0: 0.009037, l1: 0.009196, l2: 0.011175, l3: 0.011892, l4: 0.014417, l5: 0.014396, l6: 0.012344

[epoch: 106/100000, batch:     2/  187, ite: 9871] train loss: 0.116846, tar: 0.012098 
l0: 0.003530, l1: 0.003665, l2: 0.006039, l3: 0.006183, l4: 0.012914, l5: 0.010403, l6: 0.009320

[epoch: 106/100000, batch:     4/  187, ite: 9872] train loss: 0.116812, tar: 0.012094 
l0: 0.009092, l1: 0.009559, l2: 0.011995, l3: 0.012723, l4: 0.016239, l5: 0.014850, l6: 0.015888

[epoch: 106/100000, batch:     6/  187, ite: 9873] train loss: 0.116798, tar: 0.012092 
l0: 0.011507, l1: 0.012683, l2: 0.011252, l3: 0.010937, l4: 0.023633, l5: 0.018504, l6: 0.021101

[epoch: 106/100000, batch:     8/  187, ite: 9874] train loss: 0.116794, tar: 0.012092 
l0: 0.015811, l1: 0.015333, l2: 0.015380, l3: 0.014764, l4: 0.018810, l5: 0.018948, l6: 0.026265

[epoch: 106/100000, batch:    10/  187, ite: 9875] train loss: 0.116798, tar: 0.012094 
l0: 0.007282, l1: 0.007228, l2: 0.009013, l3: 0.009298, l4: 0.013916, l5: 0.012171, l6: 0.013511

[epoch: 106/100000, batch:    12/  187, ite: 9876] train loss: 0.116775, tar: 0.012091 
l0: 0.006112, l1: 0.005579, l2: 0.006760, l3: 0.006586, l4: 0.016228, l5: 0.012313, l6: 0.015587

[epoch: 106/100000, batch:    14/  187, ite: 9877] train loss: 0.116749, tar: 0.012088 
l0: 0.005558, l1: 0.005419, l2: 0.005600, l3: 0.006389, l4: 0.014021, l5: 0.012505, l6: 0.015595

[epoch: 106/100000, batch:    16/  187, ite: 9878] train loss: 0.116722, tar: 0.012085 
l0: 0.007805, l1: 0.007622, l2: 0.008555, l3: 0.008468, l4: 0.017196, l5: 0.017256, l6: 0.015905

[epoch: 106/100000, batch:    18/  187, ite: 9879] train loss: 0.116704, tar: 0.012082 
l0: 0.010724, l1: 0.011434, l2: 0.011276, l3: 0.011131, l4: 0.025483, l5: 0.021864, l6: 0.022721

[epoch: 106/100000, batch:    20/  187, ite: 9880] train loss: 0.116703, tar: 0.012082 
l0: 0.024773, l1: 0.022375, l2: 0.023455, l3: 0.024278, l4: 0.043544, l5: 0.046397, l6: 0.052046

[epoch: 106/100000, batch:    22/  187, ite: 9881] train loss: 0.116767, tar: 0.012088 
l0: 0.008258, l1: 0.008015, l2: 0.009092, l3: 0.008632, l4: 0.014275, l5: 0.014582, l6: 0.014345

[epoch: 106/100000, batch:    24/  187, ite: 9882] train loss: 0.116745, tar: 0.012086 
l0: 0.012963, l1: 0.012959, l2: 0.011719, l3: 0.011220, l4: 0.022036, l5: 0.019891, l6: 0.022119

[epoch: 106/100000, batch:    26/  187, ite: 9883] train loss: 0.116743, tar: 0.012087 
l0: 0.007515, l1: 0.007853, l2: 0.007807, l3: 0.006750, l4: 0.012483, l5: 0.011757, l6: 0.013714

[epoch: 106/100000, batch:    28/  187, ite: 9884] train loss: 0.116718, tar: 0.012084 
l0: 0.007924, l1: 0.007028, l2: 0.009043, l3: 0.009790, l4: 0.015280, l5: 0.015541, l6: 0.013816

[epoch: 106/100000, batch:    30/  187, ite: 9885] train loss: 0.116697, tar: 0.012082 
l0: 0.014471, l1: 0.014914, l2: 0.012874, l3: 0.012589, l4: 0.021765, l5: 0.020276, l6: 0.018994

[epoch: 106/100000, batch:    32/  187, ite: 9886] train loss: 0.116697, tar: 0.012083 
l0: 0.013228, l1: 0.013734, l2: 0.013152, l3: 0.014584, l4: 0.014965, l5: 0.011497, l6: 0.011670

[epoch: 106/100000, batch:    34/  187, ite: 9887] train loss: 0.116684, tar: 0.012084 
l0: 0.012259, l1: 0.011707, l2: 0.013851, l3: 0.014849, l4: 0.013468, l5: 0.012647, l6: 0.019410

[epoch: 106/100000, batch:    36/  187, ite: 9888] train loss: 0.116674, tar: 0.012084 
l0: 0.010667, l1: 0.010921, l2: 0.009881, l3: 0.009793, l4: 0.014344, l5: 0.014074, l6: 0.015210

[epoch: 106/100000, batch:    38/  187, ite: 9889] train loss: 0.116658, tar: 0.012083 
l0: 0.008490, l1: 0.008203, l2: 0.011835, l3: 0.010984, l4: 0.027982, l5: 0.022468, l6: 0.019413

[epoch: 106/100000, batch:    40/  187, ite: 9890] train loss: 0.116654, tar: 0.012081 
l0: 0.016278, l1: 0.015872, l2: 0.018715, l3: 0.020073, l4: 0.021431, l5: 0.022795, l6: 0.025517

[epoch: 106/100000, batch:    42/  187, ite: 9891] train loss: 0.116666, tar: 0.012084 
l0: 0.011392, l1: 0.011354, l2: 0.012023, l3: 0.012782, l4: 0.015009, l5: 0.013134, l6: 0.014739

[epoch: 106/100000, batch:    44/  187, ite: 9892] train loss: 0.116652, tar: 0.012083 
l0: 0.012596, l1: 0.011466, l2: 0.011324, l3: 0.015926, l4: 0.031628, l5: 0.026786, l6: 0.032334

[epoch: 106/100000, batch:    46/  187, ite: 9893] train loss: 0.116666, tar: 0.012083 
l0: 0.017918, l1: 0.021362, l2: 0.019521, l3: 0.018612, l4: 0.009661, l5: 0.009791, l6: 0.010647

[epoch: 106/100000, batch:    48/  187, ite: 9894] train loss: 0.116661, tar: 0.012087 
l0: 0.005711, l1: 0.006103, l2: 0.007917, l3: 0.007226, l4: 0.012585, l5: 0.009975, l6: 0.010448

[epoch: 106/100000, batch:    50/  187, ite: 9895] train loss: 0.116631, tar: 0.012083 
l0: 0.009933, l1: 0.009580, l2: 0.013388, l3: 0.012825, l4: 0.013597, l5: 0.012173, l6: 0.014698

[epoch: 106/100000, batch:    52/  187, ite: 9896] train loss: 0.116615, tar: 0.012082 
l0: 0.007368, l1: 0.007329, l2: 0.007998, l3: 0.008214, l4: 0.009001, l5: 0.009914, l6: 0.013449

[epoch: 106/100000, batch:    54/  187, ite: 9897] train loss: 0.116587, tar: 0.012080 
l0: 0.010163, l1: 0.009146, l2: 0.010513, l3: 0.011202, l4: 0.017692, l5: 0.016440, l6: 0.022956

[epoch: 106/100000, batch:    56/  187, ite: 9898] train loss: 0.116577, tar: 0.012079 
l0: 0.009192, l1: 0.009709, l2: 0.012943, l3: 0.012169, l4: 0.019931, l5: 0.016985, l6: 0.019089

[epoch: 106/100000, batch:    58/  187, ite: 9899] train loss: 0.116569, tar: 0.012077 
l0: 0.009176, l1: 0.011318, l2: 0.011657, l3: 0.011435, l4: 0.017314, l5: 0.014735, l6: 0.013694

[epoch: 106/100000, batch:    60/  187, ite: 9900] train loss: 0.116554, tar: 0.012076 
l0: 0.009839, l1: 0.009784, l2: 0.011240, l3: 0.010934, l4: 0.016107, l5: 0.016672, l6: 0.017080

[epoch: 106/100000, batch:    62/  187, ite: 9901] train loss: 0.116541, tar: 0.012074 
l0: 0.004918, l1: 0.005558, l2: 0.006938, l3: 0.005729, l4: 0.007315, l5: 0.007264, l6: 0.008606

[epoch: 106/100000, batch:    64/  187, ite: 9902] train loss: 0.116504, tar: 0.012071 
l0: 0.017268, l1: 0.016769, l2: 0.016748, l3: 0.018570, l4: 0.015391, l5: 0.017158, l6: 0.018014

[epoch: 106/100000, batch:    66/  187, ite: 9903] train loss: 0.116506, tar: 0.012073 
l0: 0.008283, l1: 0.009036, l2: 0.008284, l3: 0.009262, l4: 0.018195, l5: 0.012134, l6: 0.013666

[epoch: 106/100000, batch:    68/  187, ite: 9904] train loss: 0.116486, tar: 0.012071 
l0: 0.007987, l1: 0.007960, l2: 0.008678, l3: 0.009471, l4: 0.014239, l5: 0.011266, l6: 0.013563

[epoch: 106/100000, batch:    70/  187, ite: 9905] train loss: 0.116463, tar: 0.012069 
l0: 0.007296, l1: 0.007462, l2: 0.007334, l3: 0.007659, l4: 0.011113, l5: 0.012469, l6: 0.011182

[epoch: 106/100000, batch:    72/  187, ite: 9906] train loss: 0.116436, tar: 0.012067 
l0: 0.016716, l1: 0.016352, l2: 0.015268, l3: 0.020459, l4: 0.026050, l5: 0.032290, l6: 0.036997

[epoch: 106/100000, batch:    74/  187, ite: 9907] train loss: 0.116461, tar: 0.012069 
l0: 0.005025, l1: 0.005196, l2: 0.006986, l3: 0.007620, l4: 0.018126, l5: 0.010498, l6: 0.008747

[epoch: 106/100000, batch:    76/  187, ite: 9908] train loss: 0.116433, tar: 0.012065 
l0: 0.003697, l1: 0.004405, l2: 0.005660, l3: 0.003676, l4: 0.006360, l5: 0.004600, l6: 0.005152

[epoch: 106/100000, batch:    78/  187, ite: 9909] train loss: 0.116389, tar: 0.012061 
l0: 0.017253, l1: 0.018354, l2: 0.017240, l3: 0.017593, l4: 0.036460, l5: 0.026126, l6: 0.032996

[epoch: 106/100000, batch:    80/  187, ite: 9910] train loss: 0.116415, tar: 0.012064 
l0: 0.024492, l1: 0.025094, l2: 0.028038, l3: 0.027958, l4: 0.020100, l5: 0.021261, l6: 0.019605

[epoch: 106/100000, batch:    82/  187, ite: 9911] train loss: 0.116442, tar: 0.012070 
l0: 0.004057, l1: 0.004624, l2: 0.006656, l3: 0.005158, l4: 0.007403, l5: 0.005573, l6: 0.009144

[epoch: 106/100000, batch:    84/  187, ite: 9912] train loss: 0.116403, tar: 0.012066 
l0: 0.008806, l1: 0.009557, l2: 0.008174, l3: 0.008625, l4: 0.011500, l5: 0.010152, l6: 0.012545

[epoch: 106/100000, batch:    86/  187, ite: 9913] train loss: 0.116378, tar: 0.012064 
l0: 0.009732, l1: 0.010843, l2: 0.011934, l3: 0.011808, l4: 0.019142, l5: 0.015282, l6: 0.016159

[epoch: 106/100000, batch:    88/  187, ite: 9914] train loss: 0.116367, tar: 0.012063 
l0: 0.009614, l1: 0.009552, l2: 0.011031, l3: 0.011430, l4: 0.016308, l5: 0.015483, l6: 0.020799

[epoch: 106/100000, batch:    90/  187, ite: 9915] train loss: 0.116356, tar: 0.012062 
l0: 0.011189, l1: 0.011861, l2: 0.011861, l3: 0.012931, l4: 0.017711, l5: 0.015689, l6: 0.015285

[epoch: 106/100000, batch:    92/  187, ite: 9916] train loss: 0.116345, tar: 0.012061 
l0: 0.007642, l1: 0.007513, l2: 0.008510, l3: 0.010620, l4: 0.015565, l5: 0.012613, l6: 0.016832

[epoch: 106/100000, batch:    94/  187, ite: 9917] train loss: 0.116326, tar: 0.012059 
l0: 0.005737, l1: 0.006146, l2: 0.007296, l3: 0.007516, l4: 0.014738, l5: 0.015989, l6: 0.018084

[epoch: 106/100000, batch:    96/  187, ite: 9918] train loss: 0.116305, tar: 0.012056 
l0: 0.012309, l1: 0.012660, l2: 0.011706, l3: 0.010871, l4: 0.014456, l5: 0.015847, l6: 0.017245

[epoch: 106/100000, batch:    98/  187, ite: 9919] train loss: 0.116294, tar: 0.012056 
l0: 0.006985, l1: 0.007146, l2: 0.007966, l3: 0.007068, l4: 0.011017, l5: 0.009988, l6: 0.014231

[epoch: 106/100000, batch:   100/  187, ite: 9920] train loss: 0.116267, tar: 0.012053 
l0: 0.008638, l1: 0.008710, l2: 0.009087, l3: 0.009341, l4: 0.017140, l5: 0.015304, l6: 0.015870

[epoch: 106/100000, batch:   102/  187, ite: 9921] train loss: 0.116250, tar: 0.012052 
l0: 0.009013, l1: 0.008624, l2: 0.008450, l3: 0.008742, l4: 0.026163, l5: 0.023790, l6: 0.027614

[epoch: 106/100000, batch:   104/  187, ite: 9922] train loss: 0.116248, tar: 0.012050 
l0: 0.008235, l1: 0.007518, l2: 0.009436, l3: 0.010168, l4: 0.015061, l5: 0.012719, l6: 0.016245

[epoch: 106/100000, batch:   106/  187, ite: 9923] train loss: 0.116229, tar: 0.012048 
l0: 0.005842, l1: 0.006142, l2: 0.005829, l3: 0.005658, l4: 0.009789, l5: 0.010728, l6: 0.011846

[epoch: 106/100000, batch:   108/  187, ite: 9924] train loss: 0.116197, tar: 0.012045 
l0: 0.006842, l1: 0.007670, l2: 0.007865, l3: 0.008181, l4: 0.018413, l5: 0.015040, l6: 0.013394

[epoch: 106/100000, batch:   110/  187, ite: 9925] train loss: 0.116177, tar: 0.012042 
l0: 0.007089, l1: 0.007366, l2: 0.007973, l3: 0.008185, l4: 0.013739, l5: 0.012296, l6: 0.012372

[epoch: 106/100000, batch:   112/  187, ite: 9926] train loss: 0.116153, tar: 0.012039 
l0: 0.005828, l1: 0.006133, l2: 0.006729, l3: 0.006988, l4: 0.008786, l5: 0.009154, l6: 0.008056

[epoch: 106/100000, batch:   114/  187, ite: 9927] train loss: 0.116119, tar: 0.012036 
l0: 0.009976, l1: 0.010698, l2: 0.011225, l3: 0.009193, l4: 0.016313, l5: 0.014141, l6: 0.011372

[epoch: 106/100000, batch:   116/  187, ite: 9928] train loss: 0.116102, tar: 0.012035 
l0: 0.007268, l1: 0.007482, l2: 0.007433, l3: 0.008442, l4: 0.015169, l5: 0.012883, l6: 0.012335

[epoch: 106/100000, batch:   118/  187, ite: 9929] train loss: 0.116079, tar: 0.012033 
l0: 0.011798, l1: 0.010532, l2: 0.012355, l3: 0.012530, l4: 0.017618, l5: 0.018616, l6: 0.027024

[epoch: 106/100000, batch:   120/  187, ite: 9930] train loss: 0.116076, tar: 0.012033 
l0: 0.007207, l1: 0.007472, l2: 0.007789, l3: 0.007728, l4: 0.012171, l5: 0.014339, l6: 0.013343

[epoch: 106/100000, batch:   122/  187, ite: 9931] train loss: 0.116052, tar: 0.012030 
l0: 0.007955, l1: 0.007918, l2: 0.008533, l3: 0.009064, l4: 0.012920, l5: 0.013576, l6: 0.014541

[epoch: 106/100000, batch:   124/  187, ite: 9932] train loss: 0.116030, tar: 0.012028 
l0: 0.006908, l1: 0.006831, l2: 0.008103, l3: 0.008038, l4: 0.014188, l5: 0.012286, l6: 0.017314

[epoch: 106/100000, batch:   126/  187, ite: 9933] train loss: 0.116008, tar: 0.012025 
l0: 0.010781, l1: 0.012175, l2: 0.013256, l3: 0.015438, l4: 0.018227, l5: 0.012694, l6: 0.013555

[epoch: 106/100000, batch:   128/  187, ite: 9934] train loss: 0.115998, tar: 0.012025 
l0: 0.007474, l1: 0.007234, l2: 0.012093, l3: 0.009499, l4: 0.011535, l5: 0.011995, l6: 0.012229

[epoch: 106/100000, batch:   130/  187, ite: 9935] train loss: 0.115975, tar: 0.012022 
l0: 0.006182, l1: 0.006259, l2: 0.006788, l3: 0.007622, l4: 0.015783, l5: 0.016882, l6: 0.017312

[epoch: 106/100000, batch:   132/  187, ite: 9936] train loss: 0.115955, tar: 0.012019 
l0: 0.004622, l1: 0.004802, l2: 0.005218, l3: 0.004556, l4: 0.008127, l5: 0.008276, l6: 0.007387

[epoch: 106/100000, batch:   134/  187, ite: 9937] train loss: 0.115918, tar: 0.012016 
l0: 0.006714, l1: 0.006561, l2: 0.008347, l3: 0.008724, l4: 0.014082, l5: 0.014414, l6: 0.012727

[epoch: 106/100000, batch:   136/  187, ite: 9938] train loss: 0.115895, tar: 0.012013 
l0: 0.008683, l1: 0.009713, l2: 0.008868, l3: 0.008457, l4: 0.011766, l5: 0.010962, l6: 0.011767

[epoch: 106/100000, batch:   138/  187, ite: 9939] train loss: 0.115871, tar: 0.012011 
l0: 0.004033, l1: 0.003964, l2: 0.005433, l3: 0.006181, l4: 0.011197, l5: 0.006745, l6: 0.007178

[epoch: 106/100000, batch:   140/  187, ite: 9940] train loss: 0.115834, tar: 0.012007 
l0: 0.008732, l1: 0.008789, l2: 0.010441, l3: 0.010213, l4: 0.016735, l5: 0.012141, l6: 0.012910

[epoch: 106/100000, batch:   142/  187, ite: 9941] train loss: 0.115816, tar: 0.012005 
l0: 0.005863, l1: 0.006699, l2: 0.006731, l3: 0.006511, l4: 0.012705, l5: 0.008682, l6: 0.008765

[epoch: 106/100000, batch:   144/  187, ite: 9942] train loss: 0.115785, tar: 0.012002 
l0: 0.003669, l1: 0.003779, l2: 0.005565, l3: 0.007093, l4: 0.009604, l5: 0.006980, l6: 0.006193

[epoch: 106/100000, batch:   146/  187, ite: 9943] train loss: 0.115748, tar: 0.011998 
l0: 0.010105, l1: 0.011174, l2: 0.013522, l3: 0.011932, l4: 0.014739, l5: 0.013224, l6: 0.012703

[epoch: 106/100000, batch:   148/  187, ite: 9944] train loss: 0.115733, tar: 0.011997 
l0: 0.016036, l1: 0.016304, l2: 0.018426, l3: 0.019653, l4: 0.019306, l5: 0.018639, l6: 0.016766

[epoch: 106/100000, batch:   150/  187, ite: 9945] train loss: 0.115738, tar: 0.011999 
l0: 0.012939, l1: 0.013332, l2: 0.014800, l3: 0.013883, l4: 0.023106, l5: 0.020368, l6: 0.017188

[epoch: 106/100000, batch:   152/  187, ite: 9946] train loss: 0.115738, tar: 0.011999 
l0: 0.018185, l1: 0.018670, l2: 0.023324, l3: 0.020548, l4: 0.023613, l5: 0.020876, l6: 0.019326

[epoch: 106/100000, batch:   154/  187, ite: 9947] train loss: 0.115753, tar: 0.012003 
l0: 0.005165, l1: 0.005236, l2: 0.006683, l3: 0.006422, l4: 0.009758, l5: 0.009471, l6: 0.010385

[epoch: 106/100000, batch:   156/  187, ite: 9948] train loss: 0.115720, tar: 0.011999 
l0: 0.007343, l1: 0.007271, l2: 0.008889, l3: 0.008635, l4: 0.012882, l5: 0.012903, l6: 0.012790

[epoch: 106/100000, batch:   158/  187, ite: 9949] train loss: 0.115697, tar: 0.011997 
l0: 0.016007, l1: 0.016160, l2: 0.021460, l3: 0.020373, l4: 0.020280, l5: 0.016772, l6: 0.022427

[epoch: 106/100000, batch:   160/  187, ite: 9950] train loss: 0.115706, tar: 0.011999 
l0: 0.008930, l1: 0.008720, l2: 0.008050, l3: 0.008327, l4: 0.017575, l5: 0.014340, l6: 0.017599

[epoch: 106/100000, batch:   162/  187, ite: 9951] train loss: 0.115690, tar: 0.011997 
l0: 0.013702, l1: 0.013445, l2: 0.011615, l3: 0.013797, l4: 0.017911, l5: 0.019008, l6: 0.013955

[epoch: 106/100000, batch:   164/  187, ite: 9952] train loss: 0.115684, tar: 0.011998 
l0: 0.008851, l1: 0.009285, l2: 0.009242, l3: 0.009509, l4: 0.011992, l5: 0.010964, l6: 0.013188

[epoch: 106/100000, batch:   166/  187, ite: 9953] train loss: 0.115662, tar: 0.011996 
l0: 0.007151, l1: 0.007379, l2: 0.012158, l3: 0.012100, l4: 0.012786, l5: 0.012230, l6: 0.013679

[epoch: 106/100000, batch:   168/  187, ite: 9954] train loss: 0.115642, tar: 0.011994 
l0: 0.005846, l1: 0.006174, l2: 0.006998, l3: 0.006550, l4: 0.011123, l5: 0.010226, l6: 0.010402

[epoch: 106/100000, batch:   170/  187, ite: 9955] train loss: 0.115612, tar: 0.011991 
l0: 0.005481, l1: 0.005088, l2: 0.006266, l3: 0.006430, l4: 0.010608, l5: 0.011603, l6: 0.013613

[epoch: 106/100000, batch:   172/  187, ite: 9956] train loss: 0.115584, tar: 0.011987 
l0: 0.008413, l1: 0.007796, l2: 0.012082, l3: 0.011895, l4: 0.021112, l5: 0.018445, l6: 0.021058

[epoch: 106/100000, batch:   174/  187, ite: 9957] train loss: 0.115576, tar: 0.011986 
l0: 0.005378, l1: 0.005497, l2: 0.007284, l3: 0.009456, l4: 0.016101, l5: 0.013807, l6: 0.008227

[epoch: 106/100000, batch:   176/  187, ite: 9958] train loss: 0.115551, tar: 0.011982 
l0: 0.003503, l1: 0.003881, l2: 0.004666, l3: 0.003541, l4: 0.007987, l5: 0.006090, l6: 0.004382

[epoch: 106/100000, batch:   178/  187, ite: 9959] train loss: 0.115509, tar: 0.011978 
l0: 0.008296, l1: 0.008520, l2: 0.010204, l3: 0.010431, l4: 0.011134, l5: 0.012255, l6: 0.012984

[epoch: 106/100000, batch:   180/  187, ite: 9960] train loss: 0.115488, tar: 0.011976 
l0: 0.010377, l1: 0.012157, l2: 0.011467, l3: 0.010835, l4: 0.013877, l5: 0.010505, l6: 0.012366

[epoch: 106/100000, batch:   182/  187, ite: 9961] train loss: 0.115470, tar: 0.011975 
l0: 0.004028, l1: 0.004925, l2: 0.005224, l3: 0.003597, l4: 0.005931, l5: 0.004794, l6: 0.004067

[epoch: 106/100000, batch:   184/  187, ite: 9962] train loss: 0.115428, tar: 0.011971 
l0: 0.009236, l1: 0.009205, l2: 0.009629, l3: 0.010039, l4: 0.015928, l5: 0.013370, l6: 0.016767

[epoch: 106/100000, batch:   186/  187, ite: 9963] train loss: 0.115412, tar: 0.011970 
l0: 0.008206, l1: 0.008938, l2: 0.009351, l3: 0.010493, l4: 0.016974, l5: 0.014907, l6: 0.012466

[epoch: 106/100000, batch:   188/  187, ite: 9964] train loss: 0.115395, tar: 0.011968 
l0: 0.004366, l1: 0.004567, l2: 0.004379, l3: 0.005313, l4: 0.007053, l5: 0.007120, l6: 0.007548

[epoch: 107/100000, batch:     2/  187, ite: 9965] train loss: 0.115357, tar: 0.011964 
l0: 0.006779, l1: 0.007483, l2: 0.008763, l3: 0.010310, l4: 0.010790, l5: 0.008208, l6: 0.008235

[epoch: 107/100000, batch:     4/  187, ite: 9966] train loss: 0.115329, tar: 0.011961 
l0: 0.013468, l1: 0.015231, l2: 0.012912, l3: 0.012792, l4: 0.020064, l5: 0.020136, l6: 0.018356

[epoch: 107/100000, batch:     6/  187, ite: 9967] train loss: 0.115328, tar: 0.011962 
l0: 0.008598, l1: 0.007914, l2: 0.009703, l3: 0.013250, l4: 0.014391, l5: 0.012326, l6: 0.012935

[epoch: 107/100000, batch:     8/  187, ite: 9968] train loss: 0.115309, tar: 0.011960 
l0: 0.007921, l1: 0.009064, l2: 0.006001, l3: 0.007908, l4: 0.024246, l5: 0.019267, l6: 0.011497

[epoch: 107/100000, batch:    10/  187, ite: 9969] train loss: 0.115294, tar: 0.011958 
l0: 0.004248, l1: 0.004296, l2: 0.005090, l3: 0.005641, l4: 0.009744, l5: 0.009027, l6: 0.009942

[epoch: 107/100000, batch:    12/  187, ite: 9970] train loss: 0.115260, tar: 0.011954 
l0: 0.007428, l1: 0.008478, l2: 0.009161, l3: 0.008894, l4: 0.012792, l5: 0.012808, l6: 0.015472

[epoch: 107/100000, batch:    14/  187, ite: 9971] train loss: 0.115240, tar: 0.011952 
l0: 0.014519, l1: 0.013397, l2: 0.014964, l3: 0.016656, l4: 0.022326, l5: 0.021088, l6: 0.024779

[epoch: 107/100000, batch:    16/  187, ite: 9972] train loss: 0.115246, tar: 0.011953 
l0: 0.006685, l1: 0.007260, l2: 0.007228, l3: 0.007051, l4: 0.011274, l5: 0.010389, l6: 0.012052

[epoch: 107/100000, batch:    18/  187, ite: 9973] train loss: 0.115219, tar: 0.011951 
l0: 0.004436, l1: 0.004498, l2: 0.005706, l3: 0.005541, l4: 0.008477, l5: 0.007642, l6: 0.009787

[epoch: 107/100000, batch:    20/  187, ite: 9974] train loss: 0.115184, tar: 0.011947 
l0: 0.008682, l1: 0.008449, l2: 0.011119, l3: 0.012590, l4: 0.018052, l5: 0.016110, l6: 0.016817

[epoch: 107/100000, batch:    22/  187, ite: 9975] train loss: 0.115172, tar: 0.011945 
l0: 0.010292, l1: 0.011074, l2: 0.008151, l3: 0.012228, l4: 0.017119, l5: 0.013585, l6: 0.014837

[epoch: 107/100000, batch:    24/  187, ite: 9976] train loss: 0.115158, tar: 0.011944 
l0: 0.004351, l1: 0.004660, l2: 0.003813, l3: 0.004196, l4: 0.007371, l5: 0.007465, l6: 0.006333

[epoch: 107/100000, batch:    26/  187, ite: 9977] train loss: 0.115119, tar: 0.011941 
l0: 0.006164, l1: 0.005739, l2: 0.007290, l3: 0.008031, l4: 0.020205, l5: 0.022273, l6: 0.025446

[epoch: 107/100000, batch:    28/  187, ite: 9978] train loss: 0.115109, tar: 0.011938 
l0: 0.009429, l1: 0.009421, l2: 0.011287, l3: 0.012190, l4: 0.014739, l5: 0.014552, l6: 0.014602

[epoch: 107/100000, batch:    30/  187, ite: 9979] train loss: 0.115094, tar: 0.011936 
l0: 0.007628, l1: 0.007727, l2: 0.010022, l3: 0.009786, l4: 0.011870, l5: 0.011180, l6: 0.011037

[epoch: 107/100000, batch:    32/  187, ite: 9980] train loss: 0.115071, tar: 0.011934 
l0: 0.004995, l1: 0.005946, l2: 0.005626, l3: 0.005517, l4: 0.010268, l5: 0.009830, l6: 0.007428

[epoch: 107/100000, batch:    34/  187, ite: 9981] train loss: 0.115038, tar: 0.011931 
l0: 0.007706, l1: 0.008411, l2: 0.008281, l3: 0.008298, l4: 0.014846, l5: 0.013055, l6: 0.014927

[epoch: 107/100000, batch:    36/  187, ite: 9982] train loss: 0.115018, tar: 0.011929 
l0: 0.007107, l1: 0.007543, l2: 0.007380, l3: 0.008357, l4: 0.016717, l5: 0.016357, l6: 0.016953

[epoch: 107/100000, batch:    38/  187, ite: 9983] train loss: 0.115001, tar: 0.011926 
l0: 0.008199, l1: 0.008493, l2: 0.008338, l3: 0.007772, l4: 0.013050, l5: 0.010995, l6: 0.012861

[epoch: 107/100000, batch:    40/  187, ite: 9984] train loss: 0.114978, tar: 0.011924 
l0: 0.012011, l1: 0.013064, l2: 0.014219, l3: 0.013752, l4: 0.012213, l5: 0.011252, l6: 0.012095

[epoch: 107/100000, batch:    42/  187, ite: 9985] train loss: 0.114965, tar: 0.011924 
l0: 0.013039, l1: 0.013343, l2: 0.012024, l3: 0.012551, l4: 0.012380, l5: 0.013038, l6: 0.017013

[epoch: 107/100000, batch:    44/  187, ite: 9986] train loss: 0.114954, tar: 0.011925 
l0: 0.005873, l1: 0.006263, l2: 0.006961, l3: 0.007462, l4: 0.009355, l5: 0.008227, l6: 0.010056

[epoch: 107/100000, batch:    46/  187, ite: 9987] train loss: 0.114923, tar: 0.011922 
l0: 0.003304, l1: 0.003565, l2: 0.004032, l3: 0.004268, l4: 0.008494, l5: 0.006476, l6: 0.006708

[epoch: 107/100000, batch:    48/  187, ite: 9988] train loss: 0.114884, tar: 0.011918 
l0: 0.008647, l1: 0.009183, l2: 0.008340, l3: 0.009108, l4: 0.013390, l5: 0.012661, l6: 0.013668

[epoch: 107/100000, batch:    50/  187, ite: 9989] train loss: 0.114864, tar: 0.011916 
l0: 0.008426, l1: 0.008412, l2: 0.009994, l3: 0.009572, l4: 0.012279, l5: 0.013309, l6: 0.014019

[epoch: 107/100000, batch:    52/  187, ite: 9990] train loss: 0.114844, tar: 0.011914 
l0: 0.010088, l1: 0.009818, l2: 0.010880, l3: 0.014669, l4: 0.020804, l5: 0.020297, l6: 0.014714

[epoch: 107/100000, batch:    54/  187, ite: 9991] train loss: 0.114838, tar: 0.011913 
l0: 0.005779, l1: 0.007058, l2: 0.005807, l3: 0.006253, l4: 0.008172, l5: 0.006003, l6: 0.007103

[epoch: 107/100000, batch:    56/  187, ite: 9992] train loss: 0.114803, tar: 0.011910 
l0: 0.003421, l1: 0.003464, l2: 0.004282, l3: 0.005170, l4: 0.009031, l5: 0.008649, l6: 0.009321

[epoch: 107/100000, batch:    58/  187, ite: 9993] train loss: 0.114767, tar: 0.011906 
l0: 0.006878, l1: 0.007534, l2: 0.007933, l3: 0.008050, l4: 0.011037, l5: 0.010437, l6: 0.011147

[epoch: 107/100000, batch:    60/  187, ite: 9994] train loss: 0.114741, tar: 0.011903 
l0: 0.004624, l1: 0.004777, l2: 0.004654, l3: 0.006016, l4: 0.010651, l5: 0.007917, l6: 0.007941

[epoch: 107/100000, batch:    62/  187, ite: 9995] train loss: 0.114707, tar: 0.011900 
l0: 0.008772, l1: 0.009544, l2: 0.011121, l3: 0.011133, l4: 0.020165, l5: 0.014920, l6: 0.014386

[epoch: 107/100000, batch:    64/  187, ite: 9996] train loss: 0.114695, tar: 0.011898 
l0: 0.011990, l1: 0.013021, l2: 0.011276, l3: 0.011565, l4: 0.019677, l5: 0.016312, l6: 0.015940

[epoch: 107/100000, batch:    66/  187, ite: 9997] train loss: 0.114687, tar: 0.011898 
l0: 0.007624, l1: 0.008241, l2: 0.007778, l3: 0.007708, l4: 0.012892, l5: 0.010850, l6: 0.012896

[epoch: 107/100000, batch:    68/  187, ite: 9998] train loss: 0.114664, tar: 0.011896 
l0: 0.006344, l1: 0.006566, l2: 0.007846, l3: 0.009446, l4: 0.012467, l5: 0.011199, l6: 0.009510

[epoch: 107/100000, batch:    70/  187, ite: 9999] train loss: 0.114638, tar: 0.011893 
l0: 0.004933, l1: 0.005383, l2: 0.006068, l3: 0.005808, l4: 0.009468, l5: 0.009406, l6: 0.011108

[epoch: 107/100000, batch:    72/  187, ite: 10000] train loss: 0.114607, tar: 0.011890 
l0: 0.005915, l1: 0.005774, l2: 0.006914, l3: 0.008917, l4: 0.015925, l5: 0.012751, l6: 0.011644

[epoch: 107/100000, batch:    74/  187, ite: 10001] train loss: 0.067840, tar: 0.005915 
l0: 0.008260, l1: 0.008480, l2: 0.007845, l3: 0.007811, l4: 0.011411, l5: 0.012343, l6: 0.013613

[epoch: 107/100000, batch:    76/  187, ite: 10002] train loss: 0.068801, tar: 0.007088 
l0: 0.003326, l1: 0.003546, l2: 0.004062, l3: 0.004212, l4: 0.013491, l5: 0.008816, l6: 0.010680

[epoch: 107/100000, batch:    78/  187, ite: 10003] train loss: 0.061911, tar: 0.005834 
l0: 0.010823, l1: 0.010676, l2: 0.010281, l3: 0.011568, l4: 0.018048, l5: 0.018676, l6: 0.018670

[epoch: 107/100000, batch:    80/  187, ite: 10004] train loss: 0.071119, tar: 0.007081 
l0: 0.007035, l1: 0.008013, l2: 0.008130, l3: 0.007350, l4: 0.008433, l5: 0.009595, l6: 0.013727

[epoch: 107/100000, batch:    82/  187, ite: 10005] train loss: 0.069352, tar: 0.007072 
l0: 0.008926, l1: 0.008971, l2: 0.008270, l3: 0.009816, l4: 0.015808, l5: 0.015427, l6: 0.014992

[epoch: 107/100000, batch:    84/  187, ite: 10006] train loss: 0.071495, tar: 0.007381 
l0: 0.004165, l1: 0.004842, l2: 0.013179, l3: 0.007072, l4: 0.003930, l5: 0.004327, l6: 0.003260

[epoch: 107/100000, batch:    86/  187, ite: 10007] train loss: 0.067106, tar: 0.006922 
l0: 0.006612, l1: 0.006901, l2: 0.006997, l3: 0.006771, l4: 0.011891, l5: 0.013247, l6: 0.015467

[epoch: 107/100000, batch:    88/  187, ite: 10008] train loss: 0.067204, tar: 0.006883 
l0: 0.004268, l1: 0.004686, l2: 0.004810, l3: 0.003854, l4: 0.005962, l5: 0.006478, l6: 0.009095

[epoch: 107/100000, batch:    90/  187, ite: 10009] train loss: 0.064087, tar: 0.006592 
l0: 0.006248, l1: 0.007202, l2: 0.006671, l3: 0.006341, l4: 0.009543, l5: 0.009250, l6: 0.011708

[epoch: 107/100000, batch:    92/  187, ite: 10010] train loss: 0.063374, tar: 0.006558 
l0: 0.003840, l1: 0.003613, l2: 0.005076, l3: 0.005572, l4: 0.011477, l5: 0.008658, l6: 0.009472

[epoch: 107/100000, batch:    94/  187, ite: 10011] train loss: 0.061950, tar: 0.006311 
l0: 0.006392, l1: 0.006376, l2: 0.007316, l3: 0.007313, l4: 0.015071, l5: 0.017018, l6: 0.017883

[epoch: 107/100000, batch:    96/  187, ite: 10012] train loss: 0.063235, tar: 0.006317 
l0: 0.007456, l1: 0.008557, l2: 0.007617, l3: 0.006483, l4: 0.011675, l5: 0.009602, l6: 0.012388

[epoch: 107/100000, batch:    98/  187, ite: 10013] train loss: 0.063277, tar: 0.006405 
l0: 0.004431, l1: 0.005156, l2: 0.004745, l3: 0.004159, l4: 0.008593, l5: 0.007840, l6: 0.006805

[epoch: 107/100000, batch:   100/  187, ite: 10014] train loss: 0.061738, tar: 0.006264 
l0: 0.004480, l1: 0.005164, l2: 0.004491, l3: 0.005555, l4: 0.015647, l5: 0.011864, l6: 0.011488

[epoch: 107/100000, batch:   102/  187, ite: 10015] train loss: 0.061534, tar: 0.006145 
l0: 0.012485, l1: 0.012370, l2: 0.014666, l3: 0.015590, l4: 0.030485, l5: 0.026536, l6: 0.019537

[epoch: 107/100000, batch:   104/  187, ite: 10016] train loss: 0.065918, tar: 0.006541 
l0: 0.007731, l1: 0.008335, l2: 0.008375, l3: 0.007771, l4: 0.011176, l5: 0.011114, l6: 0.012146

[epoch: 107/100000, batch:   106/  187, ite: 10017] train loss: 0.065961, tar: 0.006611 
l0: 0.008819, l1: 0.008716, l2: 0.009841, l3: 0.011502, l4: 0.016841, l5: 0.015045, l6: 0.016653

[epoch: 107/100000, batch:   108/  187, ite: 10018] train loss: 0.067153, tar: 0.006734 
l0: 0.007775, l1: 0.008506, l2: 0.007633, l3: 0.008181, l4: 0.009368, l5: 0.009697, l6: 0.009693

[epoch: 107/100000, batch:   110/  187, ite: 10019] train loss: 0.066821, tar: 0.006789 
l0: 0.008350, l1: 0.008413, l2: 0.008926, l3: 0.008181, l4: 0.012583, l5: 0.012674, l6: 0.013476

[epoch: 107/100000, batch:   112/  187, ite: 10020] train loss: 0.067110, tar: 0.006867 
l0: 0.002259, l1: 0.003117, l2: 0.003157, l3: 0.002563, l4: 0.002833, l5: 0.003934, l6: 0.003169

[epoch: 107/100000, batch:   114/  187, ite: 10021] train loss: 0.064916, tar: 0.006647 
l0: 0.004355, l1: 0.004668, l2: 0.004532, l3: 0.004822, l4: 0.013145, l5: 0.012126, l6: 0.010772

[epoch: 107/100000, batch:   116/  187, ite: 10022] train loss: 0.064439, tar: 0.006543 
l0: 0.010079, l1: 0.011034, l2: 0.012464, l3: 0.011427, l4: 0.021903, l5: 0.016336, l6: 0.015284

[epoch: 107/100000, batch:   118/  187, ite: 10023] train loss: 0.065921, tar: 0.006697 
l0: 0.010003, l1: 0.010931, l2: 0.011103, l3: 0.011720, l4: 0.017573, l5: 0.016043, l6: 0.017476

[epoch: 107/100000, batch:   120/  187, ite: 10024] train loss: 0.067126, tar: 0.006835 
l0: 0.005207, l1: 0.005235, l2: 0.005914, l3: 0.006190, l4: 0.008903, l5: 0.008452, l6: 0.009473

[epoch: 107/100000, batch:   122/  187, ite: 10025] train loss: 0.066416, tar: 0.006770 
l0: 0.008595, l1: 0.009067, l2: 0.008032, l3: 0.009559, l4: 0.011716, l5: 0.010703, l6: 0.012271

[epoch: 107/100000, batch:   124/  187, ite: 10026] train loss: 0.066552, tar: 0.006840 
l0: 0.008528, l1: 0.009502, l2: 0.010543, l3: 0.009346, l4: 0.015049, l5: 0.012880, l6: 0.011905

[epoch: 107/100000, batch:   126/  187, ite: 10027] train loss: 0.066967, tar: 0.006902 
l0: 0.003832, l1: 0.003782, l2: 0.004022, l3: 0.004066, l4: 0.008323, l5: 0.007322, l6: 0.010234

[epoch: 107/100000, batch:   128/  187, ite: 10028] train loss: 0.066060, tar: 0.006793 
l0: 0.013519, l1: 0.012887, l2: 0.013872, l3: 0.014883, l4: 0.024802, l5: 0.023892, l6: 0.020699

[epoch: 107/100000, batch:   130/  187, ite: 10029] train loss: 0.068077, tar: 0.007025 
l0: 0.012371, l1: 0.013354, l2: 0.015098, l3: 0.015931, l4: 0.018612, l5: 0.014468, l6: 0.017216

[epoch: 107/100000, batch:   132/  187, ite: 10030] train loss: 0.069376, tar: 0.007203 
l0: 0.008334, l1: 0.009481, l2: 0.009387, l3: 0.009879, l4: 0.014642, l5: 0.009337, l6: 0.005588

[epoch: 107/100000, batch:   134/  187, ite: 10031] train loss: 0.069288, tar: 0.007239 
l0: 0.003155, l1: 0.004079, l2: 0.003638, l3: 0.004224, l4: 0.010321, l5: 0.006681, l6: 0.008760

[epoch: 107/100000, batch:   136/  187, ite: 10032] train loss: 0.068400, tar: 0.007112 
l0: 0.009269, l1: 0.009150, l2: 0.010895, l3: 0.010789, l4: 0.021903, l5: 0.018040, l6: 0.019605

[epoch: 107/100000, batch:   138/  187, ite: 10033] train loss: 0.069347, tar: 0.007177 
l0: 0.010256, l1: 0.010777, l2: 0.011346, l3: 0.011269, l4: 0.014578, l5: 0.013334, l6: 0.015206

[epoch: 107/100000, batch:   140/  187, ite: 10034] train loss: 0.069859, tar: 0.007268 
l0: 0.011436, l1: 0.009415, l2: 0.011840, l3: 0.012787, l4: 0.017968, l5: 0.020715, l6: 0.022670

[epoch: 107/100000, batch:   142/  187, ite: 10035] train loss: 0.070916, tar: 0.007387 
l0: 0.003483, l1: 0.003384, l2: 0.003342, l3: 0.004863, l4: 0.010964, l5: 0.008009, l6: 0.008712

[epoch: 107/100000, batch:   144/  187, ite: 10036] train loss: 0.070133, tar: 0.007278 
l0: 0.005605, l1: 0.006120, l2: 0.006747, l3: 0.006560, l4: 0.013162, l5: 0.011399, l6: 0.013659

[epoch: 107/100000, batch:   146/  187, ite: 10037] train loss: 0.069947, tar: 0.007233 
l0: 0.006192, l1: 0.006731, l2: 0.007311, l3: 0.006901, l4: 0.009590, l5: 0.008699, l6: 0.010150

[epoch: 107/100000, batch:   148/  187, ite: 10038] train loss: 0.069569, tar: 0.007206 
l0: 0.004028, l1: 0.004321, l2: 0.004071, l3: 0.004451, l4: 0.008073, l5: 0.006213, l6: 0.006030

[epoch: 107/100000, batch:   150/  187, ite: 10039] train loss: 0.068739, tar: 0.007124 
l0: 0.013430, l1: 0.014276, l2: 0.015408, l3: 0.015731, l4: 0.019218, l5: 0.016147, l6: 0.013754

[epoch: 107/100000, batch:   152/  187, ite: 10040] train loss: 0.069719, tar: 0.007282 
l0: 0.006483, l1: 0.006095, l2: 0.008162, l3: 0.010480, l4: 0.014278, l5: 0.013436, l6: 0.012965

[epoch: 107/100000, batch:   154/  187, ite: 10041] train loss: 0.069773, tar: 0.007262 
l0: 0.007672, l1: 0.008228, l2: 0.009174, l3: 0.009715, l4: 0.013540, l5: 0.009522, l6: 0.010438

[epoch: 107/100000, batch:   156/  187, ite: 10042] train loss: 0.069737, tar: 0.007272 
l0: 0.012570, l1: 0.012530, l2: 0.013186, l3: 0.013130, l4: 0.017883, l5: 0.018673, l6: 0.021717

[epoch: 107/100000, batch:   158/  187, ite: 10043] train loss: 0.070666, tar: 0.007395 
l0: 0.008878, l1: 0.009483, l2: 0.009073, l3: 0.008490, l4: 0.015147, l5: 0.013928, l6: 0.014080

[epoch: 107/100000, batch:   160/  187, ite: 10044] train loss: 0.070857, tar: 0.007429 
l0: 0.011602, l1: 0.011352, l2: 0.011542, l3: 0.014981, l4: 0.017826, l5: 0.020050, l6: 0.024076

[epoch: 107/100000, batch:   162/  187, ite: 10045] train loss: 0.071759, tar: 0.007522 
l0: 0.008243, l1: 0.008197, l2: 0.010137, l3: 0.010644, l4: 0.014180, l5: 0.012711, l6: 0.012920

[epoch: 107/100000, batch:   164/  187, ite: 10046] train loss: 0.071874, tar: 0.007537 
l0: 0.009421, l1: 0.009298, l2: 0.010749, l3: 0.010303, l4: 0.016038, l5: 0.016381, l6: 0.013129

[epoch: 107/100000, batch:   166/  187, ite: 10047] train loss: 0.072160, tar: 0.007577 
l0: 0.009883, l1: 0.009675, l2: 0.014615, l3: 0.015039, l4: 0.022768, l5: 0.014483, l6: 0.011935

[epoch: 107/100000, batch:   168/  187, ite: 10048] train loss: 0.072706, tar: 0.007625 
l0: 0.011939, l1: 0.011659, l2: 0.016702, l3: 0.014929, l4: 0.016804, l5: 0.014721, l6: 0.014826

[epoch: 107/100000, batch:   170/  187, ite: 10049] train loss: 0.073296, tar: 0.007714 
l0: 0.009783, l1: 0.010237, l2: 0.009429, l3: 0.009406, l4: 0.013932, l5: 0.013892, l6: 0.015678

[epoch: 107/100000, batch:   172/  187, ite: 10050] train loss: 0.073477, tar: 0.007755 
l0: 0.017100, l1: 0.019946, l2: 0.019860, l3: 0.013513, l4: 0.017062, l5: 0.014253, l6: 0.017603

[epoch: 107/100000, batch:   174/  187, ite: 10051] train loss: 0.074376, tar: 0.007938 
l0: 0.011441, l1: 0.012565, l2: 0.011154, l3: 0.011914, l4: 0.015092, l5: 0.014781, l6: 0.015445

[epoch: 107/100000, batch:   176/  187, ite: 10052] train loss: 0.074723, tar: 0.008005 
l0: 0.014404, l1: 0.014761, l2: 0.015963, l3: 0.015214, l4: 0.017446, l5: 0.017879, l6: 0.017692

[epoch: 107/100000, batch:   178/  187, ite: 10053] train loss: 0.075452, tar: 0.008126 
l0: 0.008415, l1: 0.008957, l2: 0.009147, l3: 0.009331, l4: 0.016469, l5: 0.014434, l6: 0.017652

[epoch: 107/100000, batch:   180/  187, ite: 10054] train loss: 0.075617, tar: 0.008132 
l0: 0.006068, l1: 0.006831, l2: 0.007893, l3: 0.007936, l4: 0.009426, l5: 0.008360, l6: 0.010556

[epoch: 107/100000, batch:   182/  187, ite: 10055] train loss: 0.075280, tar: 0.008094 
l0: 0.006797, l1: 0.006771, l2: 0.007151, l3: 0.007132, l4: 0.011570, l5: 0.011872, l6: 0.012499

[epoch: 107/100000, batch:   184/  187, ite: 10056] train loss: 0.075075, tar: 0.008071 
l0: 0.002267, l1: 0.003193, l2: 0.002740, l3: 0.002322, l4: 0.004920, l5: 0.004824, l6: 0.004100

[epoch: 107/100000, batch:   186/  187, ite: 10057] train loss: 0.074185, tar: 0.007969 
l0: 0.011357, l1: 0.012229, l2: 0.013813, l3: 0.011363, l4: 0.015326, l5: 0.014095, l6: 0.015342

[epoch: 107/100000, batch:   188/  187, ite: 10058] train loss: 0.074519, tar: 0.008027 
l0: 0.008307, l1: 0.011323, l2: 0.006667, l3: 0.007220, l4: 0.007581, l5: 0.008488, l6: 0.009744

[epoch: 108/100000, batch:     2/  187, ite: 10059] train loss: 0.074261, tar: 0.008032 
l0: 0.010437, l1: 0.011549, l2: 0.017481, l3: 0.012351, l4: 0.012408, l5: 0.008993, l6: 0.009235

[epoch: 108/100000, batch:     4/  187, ite: 10060] train loss: 0.074398, tar: 0.008072 
l0: 0.017529, l1: 0.018726, l2: 0.019522, l3: 0.016606, l4: 0.019073, l5: 0.017690, l6: 0.017537

[epoch: 108/100000, batch:     6/  187, ite: 10061] train loss: 0.075255, tar: 0.008227 
l0: 0.007033, l1: 0.007773, l2: 0.008230, l3: 0.008435, l4: 0.014296, l5: 0.014234, l6: 0.018376

[epoch: 108/100000, batch:     8/  187, ite: 10062] train loss: 0.075305, tar: 0.008208 
l0: 0.006304, l1: 0.007005, l2: 0.006558, l3: 0.005524, l4: 0.009686, l5: 0.008281, l6: 0.010228

[epoch: 108/100000, batch:    10/  187, ite: 10063] train loss: 0.074961, tar: 0.008178 
l0: 0.016092, l1: 0.014562, l2: 0.015326, l3: 0.018017, l4: 0.027167, l5: 0.026056, l6: 0.027863

[epoch: 108/100000, batch:    12/  187, ite: 10064] train loss: 0.076056, tar: 0.008301 
l0: 0.009637, l1: 0.011503, l2: 0.008424, l3: 0.007490, l4: 0.010006, l5: 0.008840, l6: 0.009138

[epoch: 108/100000, batch:    14/  187, ite: 10065] train loss: 0.075887, tar: 0.008322 
l0: 0.007181, l1: 0.008290, l2: 0.008479, l3: 0.008707, l4: 0.011883, l5: 0.010169, l6: 0.012100

[epoch: 108/100000, batch:    16/  187, ite: 10066] train loss: 0.075749, tar: 0.008305 
l0: 0.011010, l1: 0.011109, l2: 0.014898, l3: 0.012815, l4: 0.021195, l5: 0.019380, l6: 0.017708

[epoch: 108/100000, batch:    18/  187, ite: 10067] train loss: 0.076232, tar: 0.008345 
l0: 0.012624, l1: 0.014092, l2: 0.013494, l3: 0.012568, l4: 0.013701, l5: 0.012631, l6: 0.014221

[epoch: 108/100000, batch:    20/  187, ite: 10068] train loss: 0.076484, tar: 0.008408 
l0: 0.013439, l1: 0.015334, l2: 0.009384, l3: 0.008968, l4: 0.010140, l5: 0.010826, l6: 0.011672

[epoch: 108/100000, batch:    22/  187, ite: 10069] train loss: 0.076531, tar: 0.008481 
l0: 0.010255, l1: 0.010920, l2: 0.010504, l3: 0.009698, l4: 0.018288, l5: 0.015077, l6: 0.018886

[epoch: 108/100000, batch:    24/  187, ite: 10070] train loss: 0.076775, tar: 0.008506 
l0: 0.007814, l1: 0.007462, l2: 0.007951, l3: 0.009222, l4: 0.016658, l5: 0.014023, l6: 0.022214

[epoch: 108/100000, batch:    26/  187, ite: 10071] train loss: 0.076896, tar: 0.008497 
l0: 0.007103, l1: 0.006575, l2: 0.007572, l3: 0.007810, l4: 0.011887, l5: 0.011658, l6: 0.013259

[epoch: 108/100000, batch:    28/  187, ite: 10072] train loss: 0.076743, tar: 0.008477 
l0: 0.004990, l1: 0.005529, l2: 0.004635, l3: 0.005130, l4: 0.007524, l5: 0.006806, l6: 0.010696

[epoch: 108/100000, batch:    30/  187, ite: 10073] train loss: 0.076312, tar: 0.008429 
l0: 0.012253, l1: 0.010638, l2: 0.011029, l3: 0.012747, l4: 0.016487, l5: 0.020975, l6: 0.022563

[epoch: 108/100000, batch:    32/  187, ite: 10074] train loss: 0.076723, tar: 0.008481 
l0: 0.005557, l1: 0.005400, l2: 0.005231, l3: 0.005453, l4: 0.006553, l5: 0.006083, l6: 0.007219

[epoch: 108/100000, batch:    34/  187, ite: 10075] train loss: 0.076253, tar: 0.008442 
l0: 0.008376, l1: 0.007674, l2: 0.013465, l3: 0.015616, l4: 0.013701, l5: 0.012116, l6: 0.013655

[epoch: 108/100000, batch:    36/  187, ite: 10076] train loss: 0.076363, tar: 0.008441 
l0: 0.009110, l1: 0.009534, l2: 0.007936, l3: 0.008166, l4: 0.011843, l5: 0.013145, l6: 0.009282

[epoch: 108/100000, batch:    38/  187, ite: 10077] train loss: 0.076268, tar: 0.008450 
l0: 0.014423, l1: 0.013995, l2: 0.013116, l3: 0.014793, l4: 0.015152, l5: 0.017234, l6: 0.023403

[epoch: 108/100000, batch:    40/  187, ite: 10078] train loss: 0.076727, tar: 0.008526 
l0: 0.010082, l1: 0.012721, l2: 0.013520, l3: 0.011002, l4: 0.019438, l5: 0.016955, l6: 0.015710

[epoch: 108/100000, batch:    42/  187, ite: 10079] train loss: 0.077015, tar: 0.008546 
l0: 0.021045, l1: 0.021887, l2: 0.017533, l3: 0.021059, l4: 0.017646, l5: 0.015894, l6: 0.016607

[epoch: 108/100000, batch:    44/  187, ite: 10080] train loss: 0.077698, tar: 0.008702 
l0: 0.008609, l1: 0.009703, l2: 0.009726, l3: 0.009330, l4: 0.013545, l5: 0.012743, l6: 0.012204

[epoch: 108/100000, batch:    46/  187, ite: 10081] train loss: 0.077675, tar: 0.008701 
l0: 0.008086, l1: 0.008420, l2: 0.007426, l3: 0.008273, l4: 0.009604, l5: 0.009054, l6: 0.008651

[epoch: 108/100000, batch:    48/  187, ite: 10082] train loss: 0.077454, tar: 0.008694 
l0: 0.016921, l1: 0.017106, l2: 0.024495, l3: 0.023800, l4: 0.020444, l5: 0.018793, l6: 0.018315

[epoch: 108/100000, batch:    50/  187, ite: 10083] train loss: 0.078206, tar: 0.008793 
l0: 0.007513, l1: 0.008346, l2: 0.009551, l3: 0.007970, l4: 0.011917, l5: 0.012322, l6: 0.011977

[epoch: 108/100000, batch:    52/  187, ite: 10084] train loss: 0.078103, tar: 0.008778 
l0: 0.004842, l1: 0.005320, l2: 0.005803, l3: 0.005485, l4: 0.012461, l5: 0.008305, l6: 0.007990

[epoch: 108/100000, batch:    54/  187, ite: 10085] train loss: 0.077775, tar: 0.008731 
l0: 0.008133, l1: 0.008234, l2: 0.008605, l3: 0.009201, l4: 0.018391, l5: 0.018793, l6: 0.018088

[epoch: 108/100000, batch:    56/  187, ite: 10086] train loss: 0.077911, tar: 0.008724 
l0: 0.002443, l1: 0.002870, l2: 0.002812, l3: 0.002487, l4: 0.006550, l5: 0.005322, l6: 0.003109

[epoch: 108/100000, batch:    58/  187, ite: 10087] train loss: 0.077309, tar: 0.008652 
l0: 0.004614, l1: 0.004925, l2: 0.004077, l3: 0.004317, l4: 0.007233, l5: 0.007785, l6: 0.008440

[epoch: 108/100000, batch:    60/  187, ite: 10088] train loss: 0.076901, tar: 0.008606 
l0: 0.008933, l1: 0.010399, l2: 0.009409, l3: 0.008825, l4: 0.016259, l5: 0.012606, l6: 0.014239

[epoch: 108/100000, batch:    62/  187, ite: 10089] train loss: 0.076943, tar: 0.008610 
l0: 0.007947, l1: 0.008392, l2: 0.009044, l3: 0.010478, l4: 0.011586, l5: 0.010777, l6: 0.010535

[epoch: 108/100000, batch:    64/  187, ite: 10090] train loss: 0.076853, tar: 0.008603 
l0: 0.010930, l1: 0.010995, l2: 0.012376, l3: 0.011489, l4: 0.015496, l5: 0.014719, l6: 0.018229

[epoch: 108/100000, batch:    66/  187, ite: 10091] train loss: 0.077044, tar: 0.008628 
l0: 0.010223, l1: 0.010053, l2: 0.012462, l3: 0.013566, l4: 0.012063, l5: 0.015170, l6: 0.014235

[epoch: 108/100000, batch:    68/  187, ite: 10092] train loss: 0.077160, tar: 0.008646 
l0: 0.009942, l1: 0.010272, l2: 0.010928, l3: 0.011160, l4: 0.012756, l5: 0.012401, l6: 0.012514

[epoch: 108/100000, batch:    70/  187, ite: 10093] train loss: 0.077190, tar: 0.008659 
l0: 0.008800, l1: 0.008987, l2: 0.010186, l3: 0.011918, l4: 0.014263, l5: 0.011678, l6: 0.012753

[epoch: 108/100000, batch:    72/  187, ite: 10094] train loss: 0.077205, tar: 0.008661 
l0: 0.011592, l1: 0.011006, l2: 0.012147, l3: 0.014831, l4: 0.021497, l5: 0.021329, l6: 0.018937

[epoch: 108/100000, batch:    74/  187, ite: 10095] train loss: 0.077565, tar: 0.008692 
l0: 0.009839, l1: 0.009772, l2: 0.010903, l3: 0.011670, l4: 0.015411, l5: 0.013531, l6: 0.016638

[epoch: 108/100000, batch:    76/  187, ite: 10096] train loss: 0.077671, tar: 0.008704 
l0: 0.005658, l1: 0.005762, l2: 0.007045, l3: 0.007206, l4: 0.013631, l5: 0.010830, l6: 0.009469

[epoch: 108/100000, batch:    78/  187, ite: 10097] train loss: 0.077484, tar: 0.008672 
l0: 0.004114, l1: 0.004456, l2: 0.006175, l3: 0.005176, l4: 0.007790, l5: 0.007378, l6: 0.006320

[epoch: 108/100000, batch:    80/  187, ite: 10098] train loss: 0.077116, tar: 0.008626 
l0: 0.009006, l1: 0.009069, l2: 0.009838, l3: 0.010536, l4: 0.016163, l5: 0.015775, l6: 0.018862

[epoch: 108/100000, batch:    82/  187, ite: 10099] train loss: 0.077239, tar: 0.008630 
l0: 0.011685, l1: 0.012586, l2: 0.012637, l3: 0.012309, l4: 0.020758, l5: 0.018783, l6: 0.019893

[epoch: 108/100000, batch:    84/  187, ite: 10100] train loss: 0.077553, tar: 0.008660 
l0: 0.006205, l1: 0.006206, l2: 0.005964, l3: 0.008702, l4: 0.010594, l5: 0.010040, l6: 0.009829

[epoch: 108/100000, batch:    86/  187, ite: 10101] train loss: 0.077355, tar: 0.008636 
l0: 0.008847, l1: 0.008991, l2: 0.009629, l3: 0.009610, l4: 0.013531, l5: 0.013028, l6: 0.012711

[epoch: 108/100000, batch:    88/  187, ite: 10102] train loss: 0.077345, tar: 0.008638 
l0: 0.006295, l1: 0.007103, l2: 0.007484, l3: 0.006382, l4: 0.008789, l5: 0.006835, l6: 0.010199

[epoch: 108/100000, batch:    90/  187, ite: 10103] train loss: 0.077110, tar: 0.008615 
l0: 0.005170, l1: 0.005750, l2: 0.005510, l3: 0.006300, l4: 0.008542, l5: 0.009254, l6: 0.007607

[epoch: 108/100000, batch:    92/  187, ite: 10104] train loss: 0.076831, tar: 0.008582 
l0: 0.007481, l1: 0.008522, l2: 0.008498, l3: 0.008541, l4: 0.009950, l5: 0.008678, l6: 0.011001

[epoch: 108/100000, batch:    94/  187, ite: 10105] train loss: 0.076696, tar: 0.008572 
l0: 0.007474, l1: 0.007575, l2: 0.008016, l3: 0.009448, l4: 0.014264, l5: 0.011241, l6: 0.013129

[epoch: 108/100000, batch:    96/  187, ite: 10106] train loss: 0.076644, tar: 0.008561 
l0: 0.006902, l1: 0.006262, l2: 0.006723, l3: 0.007948, l4: 0.010082, l5: 0.013870, l6: 0.012537

[epoch: 108/100000, batch:    98/  187, ite: 10107] train loss: 0.076529, tar: 0.008546 
l0: 0.007152, l1: 0.006765, l2: 0.008620, l3: 0.010129, l4: 0.019975, l5: 0.018054, l6: 0.015590

[epoch: 108/100000, batch:   100/  187, ite: 10108] train loss: 0.076619, tar: 0.008533 
l0: 0.004909, l1: 0.004800, l2: 0.005571, l3: 0.006045, l4: 0.010431, l5: 0.008156, l6: 0.008646

[epoch: 108/100000, batch:   102/  187, ite: 10109] train loss: 0.076361, tar: 0.008500 
l0: 0.015062, l1: 0.015939, l2: 0.014432, l3: 0.014853, l4: 0.013146, l5: 0.013847, l6: 0.014201

[epoch: 108/100000, batch:   104/  187, ite: 10110] train loss: 0.076590, tar: 0.008559 
l0: 0.006691, l1: 0.006717, l2: 0.006938, l3: 0.008104, l4: 0.013057, l5: 0.011669, l6: 0.010727

[epoch: 108/100000, batch:   106/  187, ite: 10111] train loss: 0.076476, tar: 0.008542 
l0: 0.012047, l1: 0.012356, l2: 0.012833, l3: 0.012324, l4: 0.011588, l5: 0.012230, l6: 0.014473

[epoch: 108/100000, batch:   108/  187, ite: 10112] train loss: 0.076577, tar: 0.008574 
l0: 0.007527, l1: 0.007972, l2: 0.007903, l3: 0.007959, l4: 0.012559, l5: 0.011978, l6: 0.012561

[epoch: 108/100000, batch:   110/  187, ite: 10113] train loss: 0.076505, tar: 0.008564 
l0: 0.011224, l1: 0.010117, l2: 0.015701, l3: 0.014195, l4: 0.019927, l5: 0.019130, l6: 0.019067

[epoch: 108/100000, batch:   112/  187, ite: 10114] train loss: 0.076793, tar: 0.008588 
l0: 0.004041, l1: 0.004446, l2: 0.004507, l3: 0.005657, l4: 0.006630, l5: 0.006469, l6: 0.005795

[epoch: 108/100000, batch:   114/  187, ite: 10115] train loss: 0.076452, tar: 0.008548 
l0: 0.008363, l1: 0.008265, l2: 0.008710, l3: 0.009138, l4: 0.014696, l5: 0.013683, l6: 0.012860

[epoch: 108/100000, batch:   116/  187, ite: 10116] train loss: 0.076446, tar: 0.008547 
l0: 0.002398, l1: 0.002462, l2: 0.004152, l3: 0.003712, l4: 0.008582, l5: 0.005332, l6: 0.003604

[epoch: 108/100000, batch:   118/  187, ite: 10117] train loss: 0.076051, tar: 0.008494 
l0: 0.016097, l1: 0.014424, l2: 0.014796, l3: 0.015277, l4: 0.021712, l5: 0.024693, l6: 0.029543

[epoch: 108/100000, batch:   120/  187, ite: 10118] train loss: 0.076564, tar: 0.008559 
l0: 0.002901, l1: 0.003324, l2: 0.003252, l3: 0.002905, l4: 0.006846, l5: 0.007311, l6: 0.008588

[epoch: 108/100000, batch:   122/  187, ite: 10119] train loss: 0.076215, tar: 0.008511 
l0: 0.007055, l1: 0.006880, l2: 0.009392, l3: 0.011006, l4: 0.018497, l5: 0.016882, l6: 0.013676

[epoch: 108/100000, batch:   124/  187, ite: 10120] train loss: 0.076275, tar: 0.008499 
l0: 0.014075, l1: 0.012971, l2: 0.015263, l3: 0.015214, l4: 0.026747, l5: 0.029869, l6: 0.037169

[epoch: 108/100000, batch:   126/  187, ite: 10121] train loss: 0.076895, tar: 0.008545 
l0: 0.004432, l1: 0.004522, l2: 0.004510, l3: 0.005562, l4: 0.011515, l5: 0.010096, l6: 0.010323

[epoch: 108/100000, batch:   128/  187, ite: 10122] train loss: 0.076683, tar: 0.008511 
l0: 0.004243, l1: 0.004512, l2: 0.004698, l3: 0.005597, l4: 0.012114, l5: 0.009432, l6: 0.009933

[epoch: 108/100000, batch:   130/  187, ite: 10123] train loss: 0.076470, tar: 0.008477 
l0: 0.006772, l1: 0.006331, l2: 0.008199, l3: 0.008025, l4: 0.014254, l5: 0.014628, l6: 0.017413

[epoch: 108/100000, batch:   132/  187, ite: 10124] train loss: 0.076463, tar: 0.008463 
l0: 0.003896, l1: 0.004243, l2: 0.005005, l3: 0.004259, l4: 0.007349, l5: 0.007903, l6: 0.008569

[epoch: 108/100000, batch:   134/  187, ite: 10125] train loss: 0.076181, tar: 0.008426 
l0: 0.007637, l1: 0.008350, l2: 0.008745, l3: 0.008545, l4: 0.012562, l5: 0.012498, l6: 0.012219

[epoch: 108/100000, batch:   136/  187, ite: 10126] train loss: 0.076137, tar: 0.008420 
l0: 0.010605, l1: 0.011820, l2: 0.015707, l3: 0.013308, l4: 0.020670, l5: 0.014938, l6: 0.018226

[epoch: 108/100000, batch:   138/  187, ite: 10127] train loss: 0.076366, tar: 0.008437 
l0: 0.009768, l1: 0.009626, l2: 0.013333, l3: 0.014574, l4: 0.015290, l5: 0.011699, l6: 0.014124

[epoch: 108/100000, batch:   140/  187, ite: 10128] train loss: 0.076460, tar: 0.008448 
l0: 0.011546, l1: 0.012699, l2: 0.015469, l3: 0.014523, l4: 0.015909, l5: 0.012707, l6: 0.013770

[epoch: 108/100000, batch:   142/  187, ite: 10129] train loss: 0.076616, tar: 0.008472 
l0: 0.006914, l1: 0.007418, l2: 0.005599, l3: 0.005733, l4: 0.011134, l5: 0.010240, l6: 0.012652

[epoch: 108/100000, batch:   144/  187, ite: 10130] train loss: 0.076486, tar: 0.008460 
l0: 0.011421, l1: 0.011824, l2: 0.013595, l3: 0.012430, l4: 0.017156, l5: 0.015900, l6: 0.015569

[epoch: 108/100000, batch:   146/  187, ite: 10131] train loss: 0.076650, tar: 0.008482 
l0: 0.004904, l1: 0.005403, l2: 0.005679, l3: 0.005926, l4: 0.010980, l5: 0.010851, l6: 0.010667

[epoch: 108/100000, batch:   148/  187, ite: 10132] train loss: 0.076481, tar: 0.008455 
l0: 0.008779, l1: 0.008600, l2: 0.009356, l3: 0.009270, l4: 0.011590, l5: 0.014386, l6: 0.014190

[epoch: 108/100000, batch:   150/  187, ite: 10133] train loss: 0.076479, tar: 0.008458 
l0: 0.005483, l1: 0.006118, l2: 0.004857, l3: 0.004822, l4: 0.009818, l5: 0.009917, l6: 0.011802

[epoch: 108/100000, batch:   152/  187, ite: 10134] train loss: 0.076302, tar: 0.008435 
l0: 0.009718, l1: 0.010986, l2: 0.009619, l3: 0.009679, l4: 0.011913, l5: 0.010371, l6: 0.013053

[epoch: 108/100000, batch:   154/  187, ite: 10135] train loss: 0.076295, tar: 0.008445 
l0: 0.006688, l1: 0.006467, l2: 0.007188, l3: 0.006637, l4: 0.015008, l5: 0.015103, l6: 0.013605

[epoch: 108/100000, batch:   156/  187, ite: 10136] train loss: 0.076254, tar: 0.008432 
l0: 0.012753, l1: 0.013025, l2: 0.014076, l3: 0.013166, l4: 0.016050, l5: 0.014502, l6: 0.015923

[epoch: 108/100000, batch:   158/  187, ite: 10137] train loss: 0.076424, tar: 0.008463 
l0: 0.010737, l1: 0.010047, l2: 0.010287, l3: 0.011316, l4: 0.019430, l5: 0.019121, l6: 0.023177

[epoch: 108/100000, batch:   160/  187, ite: 10138] train loss: 0.076624, tar: 0.008480 
l0: 0.015336, l1: 0.017610, l2: 0.016389, l3: 0.016188, l4: 0.037178, l5: 0.035555, l6: 0.024703

[epoch: 108/100000, batch:   162/  187, ite: 10139] train loss: 0.077245, tar: 0.008529 
l0: 0.013384, l1: 0.013561, l2: 0.014545, l3: 0.013788, l4: 0.024376, l5: 0.020138, l6: 0.026462

[epoch: 108/100000, batch:   164/  187, ite: 10140] train loss: 0.077595, tar: 0.008564 
l0: 0.003648, l1: 0.003674, l2: 0.004021, l3: 0.003905, l4: 0.007617, l5: 0.008471, l6: 0.009330

[epoch: 108/100000, batch:   166/  187, ite: 10141] train loss: 0.077334, tar: 0.008529 
l0: 0.007344, l1: 0.008017, l2: 0.006827, l3: 0.007343, l4: 0.011008, l5: 0.010267, l6: 0.011845

[epoch: 108/100000, batch:   168/  187, ite: 10142] train loss: 0.077230, tar: 0.008521 
l0: 0.010930, l1: 0.011276, l2: 0.011600, l3: 0.012831, l4: 0.021104, l5: 0.021386, l6: 0.019899

[epoch: 108/100000, batch:   170/  187, ite: 10143] train loss: 0.077452, tar: 0.008538 
l0: 0.007013, l1: 0.006853, l2: 0.010161, l3: 0.010709, l4: 0.012953, l5: 0.013287, l6: 0.011945

[epoch: 108/100000, batch:   172/  187, ite: 10144] train loss: 0.077421, tar: 0.008527 
l0: 0.010061, l1: 0.009347, l2: 0.013277, l3: 0.013989, l4: 0.008794, l5: 0.009942, l6: 0.010119

[epoch: 108/100000, batch:   174/  187, ite: 10145] train loss: 0.077408, tar: 0.008538 
l0: 0.007247, l1: 0.007670, l2: 0.008584, l3: 0.008341, l4: 0.010953, l5: 0.010713, l6: 0.010658

[epoch: 108/100000, batch:   176/  187, ite: 10146] train loss: 0.077317, tar: 0.008529 
l0: 0.009847, l1: 0.010944, l2: 0.011037, l3: 0.010490, l4: 0.014296, l5: 0.012088, l6: 0.014051

[epoch: 108/100000, batch:   178/  187, ite: 10147] train loss: 0.077354, tar: 0.008538 
l0: 0.015836, l1: 0.016895, l2: 0.016164, l3: 0.017594, l4: 0.025542, l5: 0.020875, l6: 0.016664

[epoch: 108/100000, batch:   180/  187, ite: 10148] train loss: 0.077707, tar: 0.008587 
l0: 0.007329, l1: 0.006901, l2: 0.007851, l3: 0.006564, l4: 0.010020, l5: 0.013093, l6: 0.008212

[epoch: 108/100000, batch:   182/  187, ite: 10149] train loss: 0.077588, tar: 0.008579 
l0: 0.006431, l1: 0.006727, l2: 0.006664, l3: 0.006750, l4: 0.012726, l5: 0.013014, l6: 0.012002

[epoch: 108/100000, batch:   184/  187, ite: 10150] train loss: 0.077499, tar: 0.008564 
l0: 0.007521, l1: 0.007861, l2: 0.008798, l3: 0.009227, l4: 0.014079, l5: 0.012263, l6: 0.013706

[epoch: 108/100000, batch:   186/  187, ite: 10151] train loss: 0.077473, tar: 0.008557 
l0: 0.012235, l1: 0.013849, l2: 0.013412, l3: 0.011962, l4: 0.012535, l5: 0.012406, l6: 0.013598

[epoch: 108/100000, batch:   188/  187, ite: 10152] train loss: 0.077555, tar: 0.008582 
l0: 0.009091, l1: 0.010128, l2: 0.010924, l3: 0.010528, l4: 0.018575, l5: 0.015602, l6: 0.015403

[epoch: 109/100000, batch:     2/  187, ite: 10153] train loss: 0.077638, tar: 0.008585 
l0: 0.006758, l1: 0.006919, l2: 0.007366, l3: 0.008204, l4: 0.010904, l5: 0.009411, l6: 0.010249

[epoch: 109/100000, batch:     4/  187, ite: 10154] train loss: 0.077522, tar: 0.008573 
l0: 0.018985, l1: 0.017357, l2: 0.022081, l3: 0.027240, l4: 0.024743, l5: 0.025044, l6: 0.025049

[epoch: 109/100000, batch:     6/  187, ite: 10155] train loss: 0.078058, tar: 0.008640 
l0: 0.005411, l1: 0.005931, l2: 0.007656, l3: 0.007538, l4: 0.011239, l5: 0.012675, l6: 0.011222

[epoch: 109/100000, batch:     8/  187, ite: 10156] train loss: 0.077953, tar: 0.008619 
l0: 0.010370, l1: 0.010873, l2: 0.014462, l3: 0.013937, l4: 0.017132, l5: 0.015465, l6: 0.016040

[epoch: 109/100000, batch:    10/  187, ite: 10157] train loss: 0.078082, tar: 0.008631 
l0: 0.006877, l1: 0.006790, l2: 0.009250, l3: 0.009487, l4: 0.011317, l5: 0.010948, l6: 0.011246

[epoch: 109/100000, batch:    12/  187, ite: 10158] train loss: 0.078005, tar: 0.008620 
l0: 0.014261, l1: 0.014619, l2: 0.012888, l3: 0.012960, l4: 0.016729, l5: 0.015964, l6: 0.013882

[epoch: 109/100000, batch:    14/  187, ite: 10159] train loss: 0.078152, tar: 0.008655 
l0: 0.008077, l1: 0.009160, l2: 0.009285, l3: 0.009236, l4: 0.013971, l5: 0.012562, l6: 0.014131

[epoch: 109/100000, batch:    16/  187, ite: 10160] train loss: 0.078141, tar: 0.008651 
l0: 0.007858, l1: 0.007918, l2: 0.009508, l3: 0.008920, l4: 0.012402, l5: 0.013558, l6: 0.015419

[epoch: 109/100000, batch:    18/  187, ite: 10161] train loss: 0.078125, tar: 0.008646 
l0: 0.008312, l1: 0.009745, l2: 0.009350, l3: 0.009742, l4: 0.019944, l5: 0.015831, l6: 0.016719

[epoch: 109/100000, batch:    20/  187, ite: 10162] train loss: 0.078196, tar: 0.008644 
l0: 0.005497, l1: 0.006148, l2: 0.006524, l3: 0.006396, l4: 0.010824, l5: 0.009155, l6: 0.012200

[epoch: 109/100000, batch:    22/  187, ite: 10163] train loss: 0.078064, tar: 0.008625 
l0: 0.005215, l1: 0.004094, l2: 0.008095, l3: 0.008931, l4: 0.031448, l5: 0.024415, l6: 0.024967

[epoch: 109/100000, batch:    24/  187, ite: 10164] train loss: 0.078242, tar: 0.008604 
l0: 0.006623, l1: 0.007081, l2: 0.006977, l3: 0.006815, l4: 0.010148, l5: 0.008323, l6: 0.010254

[epoch: 109/100000, batch:    26/  187, ite: 10165] train loss: 0.078108, tar: 0.008592 
l0: 0.014511, l1: 0.015484, l2: 0.013250, l3: 0.013815, l4: 0.019750, l5: 0.018957, l6: 0.019635

[epoch: 109/100000, batch:    28/  187, ite: 10166] train loss: 0.078333, tar: 0.008628 
l0: 0.008574, l1: 0.008209, l2: 0.009750, l3: 0.011380, l4: 0.012776, l5: 0.012489, l6: 0.017419

[epoch: 109/100000, batch:    30/  187, ite: 10167] train loss: 0.078347, tar: 0.008628 
l0: 0.010515, l1: 0.011133, l2: 0.013185, l3: 0.010862, l4: 0.016205, l5: 0.014112, l6: 0.019968

[epoch: 109/100000, batch:    32/  187, ite: 10168] train loss: 0.078452, tar: 0.008639 
l0: 0.006076, l1: 0.007227, l2: 0.007664, l3: 0.007233, l4: 0.011666, l5: 0.007827, l6: 0.008090

[epoch: 109/100000, batch:    34/  187, ite: 10169] train loss: 0.078317, tar: 0.008624 
l0: 0.010681, l1: 0.011080, l2: 0.007750, l3: 0.008004, l4: 0.008995, l5: 0.011385, l6: 0.014817

[epoch: 109/100000, batch:    36/  187, ite: 10170] train loss: 0.078284, tar: 0.008636 
l0: 0.010224, l1: 0.010686, l2: 0.008323, l3: 0.009448, l4: 0.015153, l5: 0.012122, l6: 0.014980

[epoch: 109/100000, batch:    38/  187, ite: 10171] train loss: 0.078300, tar: 0.008645 
l0: 0.004328, l1: 0.004489, l2: 0.004552, l3: 0.004832, l4: 0.012559, l5: 0.007069, l6: 0.011532

[epoch: 109/100000, batch:    40/  187, ite: 10172] train loss: 0.078132, tar: 0.008620 
l0: 0.007206, l1: 0.008101, l2: 0.006880, l3: 0.006675, l4: 0.010301, l5: 0.008021, l6: 0.011718

[epoch: 109/100000, batch:    42/  187, ite: 10173] train loss: 0.078021, tar: 0.008612 
l0: 0.013522, l1: 0.013680, l2: 0.013454, l3: 0.013839, l4: 0.018902, l5: 0.018718, l6: 0.022578

[epoch: 109/100000, batch:    44/  187, ite: 10174] train loss: 0.078231, tar: 0.008640 
l0: 0.003918, l1: 0.003812, l2: 0.004028, l3: 0.003510, l4: 0.017157, l5: 0.013156, l6: 0.016267

[epoch: 109/100000, batch:    46/  187, ite: 10175] train loss: 0.078138, tar: 0.008613 
l0: 0.005978, l1: 0.005899, l2: 0.007823, l3: 0.006156, l4: 0.009341, l5: 0.009969, l6: 0.006601

[epoch: 109/100000, batch:    48/  187, ite: 10176] train loss: 0.077988, tar: 0.008598 
l0: 0.007835, l1: 0.008935, l2: 0.008130, l3: 0.008776, l4: 0.012731, l5: 0.007187, l6: 0.007636

[epoch: 109/100000, batch:    50/  187, ite: 10177] train loss: 0.077893, tar: 0.008594 
l0: 0.007195, l1: 0.007447, l2: 0.008076, l3: 0.008726, l4: 0.015494, l5: 0.013390, l6: 0.012488

[epoch: 109/100000, batch:    52/  187, ite: 10178] train loss: 0.077865, tar: 0.008586 
l0: 0.003905, l1: 0.003573, l2: 0.004627, l3: 0.004987, l4: 0.005705, l5: 0.004968, l6: 0.006697

[epoch: 109/100000, batch:    54/  187, ite: 10179] train loss: 0.077622, tar: 0.008560 
l0: 0.006665, l1: 0.006543, l2: 0.007610, l3: 0.007328, l4: 0.013282, l5: 0.013804, l6: 0.013667

[epoch: 109/100000, batch:    56/  187, ite: 10180] train loss: 0.077574, tar: 0.008549 
l0: 0.008708, l1: 0.008685, l2: 0.011125, l3: 0.011791, l4: 0.015662, l5: 0.014822, l6: 0.015567

[epoch: 109/100000, batch:    58/  187, ite: 10181] train loss: 0.077622, tar: 0.008550 
l0: 0.006017, l1: 0.005877, l2: 0.007835, l3: 0.009988, l4: 0.009925, l5: 0.007795, l6: 0.009626

[epoch: 109/100000, batch:    60/  187, ite: 10182] train loss: 0.077509, tar: 0.008536 
l0: 0.004976, l1: 0.005287, l2: 0.005252, l3: 0.005082, l4: 0.008326, l5: 0.008320, l6: 0.008821

[epoch: 109/100000, batch:    62/  187, ite: 10183] train loss: 0.077337, tar: 0.008517 
l0: 0.004955, l1: 0.005354, l2: 0.007264, l3: 0.007835, l4: 0.009261, l5: 0.008651, l6: 0.009124

[epoch: 109/100000, batch:    64/  187, ite: 10184] train loss: 0.077202, tar: 0.008497 
l0: 0.012730, l1: 0.012078, l2: 0.014076, l3: 0.015426, l4: 0.036532, l5: 0.036734, l6: 0.027390

[epoch: 109/100000, batch:    66/  187, ite: 10185] train loss: 0.077623, tar: 0.008520 
l0: 0.015816, l1: 0.018912, l2: 0.022738, l3: 0.013516, l4: 0.015102, l5: 0.015331, l6: 0.012873

[epoch: 109/100000, batch:    68/  187, ite: 10186] train loss: 0.077820, tar: 0.008559 
l0: 0.008959, l1: 0.009598, l2: 0.011325, l3: 0.010492, l4: 0.012698, l5: 0.013335, l6: 0.013424

[epoch: 109/100000, batch:    70/  187, ite: 10187] train loss: 0.077830, tar: 0.008562 
l0: 0.005583, l1: 0.005634, l2: 0.006044, l3: 0.006260, l4: 0.011384, l5: 0.009973, l6: 0.012302

[epoch: 109/100000, batch:    72/  187, ite: 10188] train loss: 0.077721, tar: 0.008546 
l0: 0.006428, l1: 0.006365, l2: 0.007799, l3: 0.007640, l4: 0.010761, l5: 0.010376, l6: 0.010477

[epoch: 109/100000, batch:    74/  187, ite: 10189] train loss: 0.077626, tar: 0.008535 
l0: 0.009536, l1: 0.008932, l2: 0.008544, l3: 0.010534, l4: 0.015230, l5: 0.015243, l6: 0.016158

[epoch: 109/100000, batch:    76/  187, ite: 10190] train loss: 0.077660, tar: 0.008540 
l0: 0.009293, l1: 0.009536, l2: 0.010655, l3: 0.010512, l4: 0.019437, l5: 0.018153, l6: 0.019955

[epoch: 109/100000, batch:    78/  187, ite: 10191] train loss: 0.077765, tar: 0.008544 
l0: 0.012911, l1: 0.013019, l2: 0.013912, l3: 0.016448, l4: 0.015715, l5: 0.015577, l6: 0.015788

[epoch: 109/100000, batch:    80/  187, ite: 10192] train loss: 0.077898, tar: 0.008567 
l0: 0.007465, l1: 0.007072, l2: 0.010126, l3: 0.009736, l4: 0.018856, l5: 0.017455, l6: 0.018107

[epoch: 109/100000, batch:    82/  187, ite: 10193] train loss: 0.077954, tar: 0.008561 
l0: 0.005265, l1: 0.006786, l2: 0.008925, l3: 0.006775, l4: 0.006698, l5: 0.004545, l6: 0.004827

[epoch: 109/100000, batch:    84/  187, ite: 10194] train loss: 0.077779, tar: 0.008544 
l0: 0.009149, l1: 0.009420, l2: 0.011416, l3: 0.012256, l4: 0.016963, l5: 0.016711, l6: 0.016025

[epoch: 109/100000, batch:    86/  187, ite: 10195] train loss: 0.077851, tar: 0.008547 
l0: 0.005747, l1: 0.005638, l2: 0.009101, l3: 0.007789, l4: 0.008627, l5: 0.009804, l6: 0.007314

[epoch: 109/100000, batch:    88/  187, ite: 10196] train loss: 0.077730, tar: 0.008533 
l0: 0.011229, l1: 0.012470, l2: 0.012790, l3: 0.011825, l4: 0.010510, l5: 0.009042, l6: 0.011174

[epoch: 109/100000, batch:    90/  187, ite: 10197] train loss: 0.077736, tar: 0.008546 
l0: 0.007994, l1: 0.008311, l2: 0.009139, l3: 0.010012, l4: 0.021577, l5: 0.019327, l6: 0.018138

[epoch: 109/100000, batch:    92/  187, ite: 10198] train loss: 0.077821, tar: 0.008544 
l0: 0.006042, l1: 0.005795, l2: 0.006881, l3: 0.008113, l4: 0.013219, l5: 0.011461, l6: 0.012674

[epoch: 109/100000, batch:    94/  187, ite: 10199] train loss: 0.077752, tar: 0.008531 
l0: 0.011251, l1: 0.012309, l2: 0.012931, l3: 0.011736, l4: 0.016150, l5: 0.013256, l6: 0.013810

[epoch: 109/100000, batch:    96/  187, ite: 10200] train loss: 0.077821, tar: 0.008545 
l0: 0.007976, l1: 0.008900, l2: 0.007287, l3: 0.008066, l4: 0.011727, l5: 0.011014, l6: 0.012312

[epoch: 109/100000, batch:    98/  187, ite: 10201] train loss: 0.077768, tar: 0.008542 
l0: 0.004167, l1: 0.004302, l2: 0.004776, l3: 0.004842, l4: 0.003616, l5: 0.003878, l6: 0.004614

[epoch: 109/100000, batch:   100/  187, ite: 10202] train loss: 0.077533, tar: 0.008520 
l0: 0.009822, l1: 0.009283, l2: 0.010797, l3: 0.011027, l4: 0.024726, l5: 0.024355, l6: 0.021121

[epoch: 109/100000, batch:   102/  187, ite: 10203] train loss: 0.077698, tar: 0.008527 
l0: 0.005282, l1: 0.005488, l2: 0.005958, l3: 0.007067, l4: 0.009595, l5: 0.007745, l6: 0.009199

[epoch: 109/100000, batch:   104/  187, ite: 10204] train loss: 0.077564, tar: 0.008511 
l0: 0.006482, l1: 0.007838, l2: 0.005102, l3: 0.004888, l4: 0.008831, l5: 0.008166, l6: 0.007644

[epoch: 109/100000, batch:   106/  187, ite: 10205] train loss: 0.077425, tar: 0.008501 
l0: 0.003971, l1: 0.005609, l2: 0.003239, l3: 0.003184, l4: 0.008044, l5: 0.010522, l6: 0.015482

[epoch: 109/100000, batch:   108/  187, ite: 10206] train loss: 0.077292, tar: 0.008479 
l0: 0.012336, l1: 0.015293, l2: 0.010658, l3: 0.010944, l4: 0.012342, l5: 0.009960, l6: 0.011565

[epoch: 109/100000, batch:   110/  187, ite: 10207] train loss: 0.077320, tar: 0.008497 
l0: 0.007140, l1: 0.007007, l2: 0.009245, l3: 0.009665, l4: 0.010212, l5: 0.011173, l6: 0.012173

[epoch: 109/100000, batch:   112/  187, ite: 10208] train loss: 0.077268, tar: 0.008491 
l0: 0.005830, l1: 0.006218, l2: 0.006495, l3: 0.007070, l4: 0.005818, l5: 0.004681, l6: 0.005246

[epoch: 109/100000, batch:   114/  187, ite: 10209] train loss: 0.077096, tar: 0.008478 
l0: 0.005748, l1: 0.005763, l2: 0.007746, l3: 0.008588, l4: 0.016715, l5: 0.012115, l6: 0.011141

[epoch: 109/100000, batch:   116/  187, ite: 10210] train loss: 0.077052, tar: 0.008465 
l0: 0.012504, l1: 0.013048, l2: 0.009721, l3: 0.011065, l4: 0.015118, l5: 0.016063, l6: 0.017172

[epoch: 109/100000, batch:   118/  187, ite: 10211] train loss: 0.077136, tar: 0.008484 
l0: 0.004485, l1: 0.004363, l2: 0.005397, l3: 0.006457, l4: 0.008041, l5: 0.008650, l6: 0.006015

[epoch: 109/100000, batch:   120/  187, ite: 10212] train loss: 0.076977, tar: 0.008465 
l0: 0.007835, l1: 0.008386, l2: 0.010489, l3: 0.009866, l4: 0.016783, l5: 0.012753, l6: 0.015372

[epoch: 109/100000, batch:   122/  187, ite: 10213] train loss: 0.076998, tar: 0.008462 
l0: 0.006257, l1: 0.006185, l2: 0.005920, l3: 0.006938, l4: 0.012654, l5: 0.011047, l6: 0.013065

[epoch: 109/100000, batch:   124/  187, ite: 10214] train loss: 0.076928, tar: 0.008452 
l0: 0.008150, l1: 0.007417, l2: 0.008560, l3: 0.010183, l4: 0.024320, l5: 0.021495, l6: 0.022647

[epoch: 109/100000, batch:   126/  187, ite: 10215] train loss: 0.077048, tar: 0.008451 
l0: 0.006463, l1: 0.006848, l2: 0.008044, l3: 0.008156, l4: 0.010147, l5: 0.008398, l6: 0.008448

[epoch: 109/100000, batch:   128/  187, ite: 10216] train loss: 0.076953, tar: 0.008442 
l0: 0.008147, l1: 0.008836, l2: 0.008598, l3: 0.008927, l4: 0.016531, l5: 0.012891, l6: 0.016492

[epoch: 109/100000, batch:   130/  187, ite: 10217] train loss: 0.076969, tar: 0.008440 
l0: 0.008014, l1: 0.008821, l2: 0.010543, l3: 0.009946, l4: 0.015408, l5: 0.011243, l6: 0.011723

[epoch: 109/100000, batch:   132/  187, ite: 10218] train loss: 0.076963, tar: 0.008438 
l0: 0.009134, l1: 0.009899, l2: 0.010426, l3: 0.010374, l4: 0.020296, l5: 0.021204, l6: 0.022460

[epoch: 109/100000, batch:   134/  187, ite: 10219] train loss: 0.077086, tar: 0.008441 
l0: 0.014730, l1: 0.015090, l2: 0.014736, l3: 0.013547, l4: 0.018756, l5: 0.018796, l6: 0.019684

[epoch: 109/100000, batch:   136/  187, ite: 10220] train loss: 0.077260, tar: 0.008470 
l0: 0.007636, l1: 0.008912, l2: 0.007421, l3: 0.006842, l4: 0.011300, l5: 0.011175, l6: 0.015112

[epoch: 109/100000, batch:   138/  187, ite: 10221] train loss: 0.077220, tar: 0.008466 
l0: 0.003109, l1: 0.003962, l2: 0.002979, l3: 0.003735, l4: 0.007661, l5: 0.006944, l6: 0.007209

[epoch: 109/100000, batch:   140/  187, ite: 10222] train loss: 0.077032, tar: 0.008442 
l0: 0.006258, l1: 0.006168, l2: 0.007365, l3: 0.006449, l4: 0.010195, l5: 0.011530, l6: 0.013337

[epoch: 109/100000, batch:   142/  187, ite: 10223] train loss: 0.076962, tar: 0.008432 
l0: 0.005624, l1: 0.006200, l2: 0.006500, l3: 0.006408, l4: 0.009541, l5: 0.007862, l6: 0.007305

[epoch: 109/100000, batch:   144/  187, ite: 10224] train loss: 0.076839, tar: 0.008420 
l0: 0.013162, l1: 0.014790, l2: 0.011156, l3: 0.010421, l4: 0.015771, l5: 0.015496, l6: 0.014185

[epoch: 109/100000, batch:   146/  187, ite: 10225] train loss: 0.076919, tar: 0.008441 
l0: 0.007958, l1: 0.008375, l2: 0.009359, l3: 0.009219, l4: 0.011511, l5: 0.010006, l6: 0.011173

[epoch: 109/100000, batch:   148/  187, ite: 10226] train loss: 0.076878, tar: 0.008439 
l0: 0.008835, l1: 0.008928, l2: 0.010407, l3: 0.009833, l4: 0.013104, l5: 0.011310, l6: 0.016336

[epoch: 109/100000, batch:   150/  187, ite: 10227] train loss: 0.076886, tar: 0.008440 
l0: 0.008596, l1: 0.008279, l2: 0.009851, l3: 0.011175, l4: 0.011803, l5: 0.011943, l6: 0.011453

[epoch: 109/100000, batch:   152/  187, ite: 10228] train loss: 0.076870, tar: 0.008441 
l0: 0.008533, l1: 0.009119, l2: 0.009086, l3: 0.009672, l4: 0.014278, l5: 0.012743, l6: 0.015302

[epoch: 109/100000, batch:   154/  187, ite: 10229] train loss: 0.076878, tar: 0.008441 
l0: 0.017341, l1: 0.016788, l2: 0.014990, l3: 0.017932, l4: 0.041015, l5: 0.042547, l6: 0.035538

[epoch: 109/100000, batch:   156/  187, ite: 10230] train loss: 0.077353, tar: 0.008480 
l0: 0.007352, l1: 0.008642, l2: 0.008856, l3: 0.006191, l4: 0.009259, l5: 0.009714, l6: 0.013015

[epoch: 109/100000, batch:   158/  187, ite: 10231] train loss: 0.077291, tar: 0.008475 
l0: 0.006423, l1: 0.006568, l2: 0.007102, l3: 0.007276, l4: 0.014783, l5: 0.016145, l6: 0.017002

[epoch: 109/100000, batch:   160/  187, ite: 10232] train loss: 0.077283, tar: 0.008466 
l0: 0.016336, l1: 0.014347, l2: 0.017069, l3: 0.018199, l4: 0.030141, l5: 0.030308, l6: 0.024771

[epoch: 109/100000, batch:   162/  187, ite: 10233] train loss: 0.077600, tar: 0.008500 
l0: 0.004113, l1: 0.004102, l2: 0.004737, l3: 0.003957, l4: 0.008072, l5: 0.007806, l6: 0.008461

[epoch: 109/100000, batch:   164/  187, ite: 10234] train loss: 0.077444, tar: 0.008481 
l0: 0.008994, l1: 0.009419, l2: 0.010873, l3: 0.011581, l4: 0.018739, l5: 0.018495, l6: 0.015534

[epoch: 109/100000, batch:   166/  187, ite: 10235] train loss: 0.077513, tar: 0.008484 
l0: 0.006480, l1: 0.006563, l2: 0.006933, l3: 0.007310, l4: 0.011187, l5: 0.011835, l6: 0.011005

[epoch: 109/100000, batch:   168/  187, ite: 10236] train loss: 0.077445, tar: 0.008475 
l0: 0.005391, l1: 0.005608, l2: 0.008049, l3: 0.008091, l4: 0.011535, l5: 0.012038, l6: 0.009194

[epoch: 109/100000, batch:   170/  187, ite: 10237] train loss: 0.077371, tar: 0.008462 
l0: 0.006504, l1: 0.005894, l2: 0.008069, l3: 0.009093, l4: 0.009775, l5: 0.010005, l6: 0.015046

[epoch: 109/100000, batch:   172/  187, ite: 10238] train loss: 0.077316, tar: 0.008454 
l0: 0.009558, l1: 0.009226, l2: 0.010106, l3: 0.011551, l4: 0.014986, l5: 0.017882, l6: 0.015482

[epoch: 109/100000, batch:   174/  187, ite: 10239] train loss: 0.077364, tar: 0.008459 
l0: 0.005013, l1: 0.005597, l2: 0.004599, l3: 0.004634, l4: 0.007766, l5: 0.006031, l6: 0.009662

[epoch: 109/100000, batch:   176/  187, ite: 10240] train loss: 0.077222, tar: 0.008444 
l0: 0.004868, l1: 0.004962, l2: 0.005538, l3: 0.006109, l4: 0.011515, l5: 0.010533, l6: 0.010269

[epoch: 109/100000, batch:   178/  187, ite: 10241] train loss: 0.077125, tar: 0.008429 
l0: 0.007772, l1: 0.007541, l2: 0.007355, l3: 0.007126, l4: 0.009994, l5: 0.010614, l6: 0.013193

[epoch: 109/100000, batch:   180/  187, ite: 10242] train loss: 0.077069, tar: 0.008427 
l0: 0.005166, l1: 0.005523, l2: 0.004104, l3: 0.004739, l4: 0.007772, l5: 0.008187, l6: 0.010279

[epoch: 109/100000, batch:   182/  187, ite: 10243] train loss: 0.076940, tar: 0.008413 
l0: 0.011178, l1: 0.010165, l2: 0.014935, l3: 0.015481, l4: 0.013018, l5: 0.015336, l6: 0.015593

[epoch: 109/100000, batch:   184/  187, ite: 10244] train loss: 0.077017, tar: 0.008425 
l0: 0.005996, l1: 0.006107, l2: 0.006871, l3: 0.007260, l4: 0.006629, l5: 0.007769, l6: 0.009241

[epoch: 109/100000, batch:   186/  187, ite: 10245] train loss: 0.076906, tar: 0.008415 
l0: 0.004887, l1: 0.004476, l2: 0.004755, l3: 0.005186, l4: 0.014590, l5: 0.016242, l6: 0.022865

[epoch: 109/100000, batch:   188/  187, ite: 10246] train loss: 0.076890, tar: 0.008400 
l0: 0.005839, l1: 0.006785, l2: 0.006267, l3: 0.005894, l4: 0.008276, l5: 0.008211, l6: 0.008797

[epoch: 110/100000, batch:     2/  187, ite: 10247] train loss: 0.076782, tar: 0.008390 
l0: 0.005309, l1: 0.005775, l2: 0.005824, l3: 0.006053, l4: 0.009212, l5: 0.008939, l6: 0.009821

[epoch: 110/100000, batch:     4/  187, ite: 10248] train loss: 0.076678, tar: 0.008378 
l0: 0.005045, l1: 0.005076, l2: 0.005226, l3: 0.005994, l4: 0.009739, l5: 0.008769, l6: 0.008251

[epoch: 110/100000, batch:     6/  187, ite: 10249] train loss: 0.076563, tar: 0.008364 
l0: 0.011497, l1: 0.011007, l2: 0.012074, l3: 0.011821, l4: 0.019445, l5: 0.017400, l6: 0.022573

[epoch: 110/100000, batch:     8/  187, ite: 10250] train loss: 0.076680, tar: 0.008377 
l0: 0.006497, l1: 0.007447, l2: 0.006168, l3: 0.006241, l4: 0.008427, l5: 0.010032, l6: 0.009647

[epoch: 110/100000, batch:    10/  187, ite: 10251] train loss: 0.076591, tar: 0.008369 
l0: 0.008418, l1: 0.007636, l2: 0.010084, l3: 0.011796, l4: 0.015686, l5: 0.018797, l6: 0.017150

[epoch: 110/100000, batch:    12/  187, ite: 10252] train loss: 0.076643, tar: 0.008369 
l0: 0.007008, l1: 0.007498, l2: 0.007145, l3: 0.007660, l4: 0.018334, l5: 0.015803, l6: 0.014638

[epoch: 110/100000, batch:    14/  187, ite: 10253] train loss: 0.076649, tar: 0.008364 
l0: 0.007176, l1: 0.007649, l2: 0.008599, l3: 0.009195, l4: 0.010037, l5: 0.008842, l6: 0.010423

[epoch: 110/100000, batch:    16/  187, ite: 10254] train loss: 0.076591, tar: 0.008359 
l0: 0.008014, l1: 0.009239, l2: 0.008999, l3: 0.008740, l4: 0.009477, l5: 0.009434, l6: 0.009666

[epoch: 110/100000, batch:    18/  187, ite: 10255] train loss: 0.076539, tar: 0.008358 
l0: 0.004194, l1: 0.004022, l2: 0.004979, l3: 0.005001, l4: 0.009621, l5: 0.009771, l6: 0.019671

[epoch: 110/100000, batch:    20/  187, ite: 10256] train loss: 0.076464, tar: 0.008342 
l0: 0.006785, l1: 0.006308, l2: 0.006740, l3: 0.007536, l4: 0.015416, l5: 0.014837, l6: 0.016300

[epoch: 110/100000, batch:    22/  187, ite: 10257] train loss: 0.076454, tar: 0.008336 
l0: 0.007212, l1: 0.006673, l2: 0.009199, l3: 0.009521, l4: 0.014692, l5: 0.015709, l6: 0.013362

[epoch: 110/100000, batch:    24/  187, ite: 10258] train loss: 0.076454, tar: 0.008331 
l0: 0.007122, l1: 0.006326, l2: 0.008701, l3: 0.008634, l4: 0.015949, l5: 0.013674, l6: 0.012901

[epoch: 110/100000, batch:    26/  187, ite: 10259] train loss: 0.076442, tar: 0.008327 
l0: 0.005558, l1: 0.005288, l2: 0.006005, l3: 0.006912, l4: 0.009089, l5: 0.010006, l6: 0.011908

[epoch: 110/100000, batch:    28/  187, ite: 10260] train loss: 0.076358, tar: 0.008316 
l0: 0.010803, l1: 0.010586, l2: 0.011692, l3: 0.010269, l4: 0.019632, l5: 0.021100, l6: 0.018483

[epoch: 110/100000, batch:    30/  187, ite: 10261] train loss: 0.076459, tar: 0.008325 
l0: 0.011222, l1: 0.012021, l2: 0.012887, l3: 0.011131, l4: 0.017180, l5: 0.015150, l6: 0.019316

[epoch: 110/100000, batch:    32/  187, ite: 10262] train loss: 0.076544, tar: 0.008337 
l0: 0.009363, l1: 0.010095, l2: 0.009802, l3: 0.011048, l4: 0.021900, l5: 0.015072, l6: 0.020606

[epoch: 110/100000, batch:    34/  187, ite: 10263] train loss: 0.076626, tar: 0.008340 
l0: 0.005210, l1: 0.005482, l2: 0.004976, l3: 0.005051, l4: 0.011053, l5: 0.012860, l6: 0.009628

[epoch: 110/100000, batch:    36/  187, ite: 10264] train loss: 0.076541, tar: 0.008329 
l0: 0.011178, l1: 0.011127, l2: 0.010026, l3: 0.011488, l4: 0.011913, l5: 0.010776, l6: 0.014903

[epoch: 110/100000, batch:    38/  187, ite: 10265] train loss: 0.076559, tar: 0.008339 
l0: 0.007303, l1: 0.007243, l2: 0.008218, l3: 0.010574, l4: 0.013729, l5: 0.014133, l6: 0.008778

[epoch: 110/100000, batch:    40/  187, ite: 10266] train loss: 0.076535, tar: 0.008335 
l0: 0.005247, l1: 0.005496, l2: 0.006489, l3: 0.007210, l4: 0.013092, l5: 0.014493, l6: 0.015188

[epoch: 110/100000, batch:    42/  187, ite: 10267] train loss: 0.076500, tar: 0.008324 
l0: 0.006628, l1: 0.006593, l2: 0.006446, l3: 0.006358, l4: 0.008465, l5: 0.009353, l6: 0.010390

[epoch: 110/100000, batch:    44/  187, ite: 10268] train loss: 0.076417, tar: 0.008318 
l0: 0.007343, l1: 0.008183, l2: 0.007875, l3: 0.008175, l4: 0.010609, l5: 0.008442, l6: 0.008752

[epoch: 110/100000, batch:    46/  187, ite: 10269] train loss: 0.076353, tar: 0.008314 
l0: 0.007824, l1: 0.008604, l2: 0.008342, l3: 0.007467, l4: 0.016471, l5: 0.012382, l6: 0.015045

[epoch: 110/100000, batch:    48/  187, ite: 10270] train loss: 0.076352, tar: 0.008312 
l0: 0.008066, l1: 0.009345, l2: 0.008322, l3: 0.009349, l4: 0.014188, l5: 0.011163, l6: 0.012731

[epoch: 110/100000, batch:    50/  187, ite: 10271] train loss: 0.076341, tar: 0.008311 
l0: 0.006328, l1: 0.006515, l2: 0.006232, l3: 0.007893, l4: 0.010397, l5: 0.008869, l6: 0.010877

[epoch: 110/100000, batch:    52/  187, ite: 10272] train loss: 0.076270, tar: 0.008304 
l0: 0.010336, l1: 0.010349, l2: 0.010640, l3: 0.011760, l4: 0.013925, l5: 0.012112, l6: 0.013308

[epoch: 110/100000, batch:    54/  187, ite: 10273] train loss: 0.076293, tar: 0.008311 
l0: 0.009466, l1: 0.009242, l2: 0.010066, l3: 0.011635, l4: 0.020861, l5: 0.016963, l6: 0.024503

[epoch: 110/100000, batch:    56/  187, ite: 10274] train loss: 0.076389, tar: 0.008316 
l0: 0.017352, l1: 0.017417, l2: 0.014216, l3: 0.014831, l4: 0.046058, l5: 0.044881, l6: 0.033838

[epoch: 110/100000, batch:    58/  187, ite: 10275] train loss: 0.076797, tar: 0.008348 
l0: 0.006529, l1: 0.006106, l2: 0.006974, l3: 0.006986, l4: 0.017954, l5: 0.016331, l6: 0.012272

[epoch: 110/100000, batch:    60/  187, ite: 10276] train loss: 0.076784, tar: 0.008342 
l0: 0.019785, l1: 0.017922, l2: 0.016452, l3: 0.016822, l4: 0.034554, l5: 0.033605, l6: 0.040176

[epoch: 110/100000, batch:    62/  187, ite: 10277] train loss: 0.077154, tar: 0.008383 
l0: 0.009901, l1: 0.010382, l2: 0.011068, l3: 0.010761, l4: 0.014554, l5: 0.013655, l6: 0.012563

[epoch: 110/100000, batch:    64/  187, ite: 10278] train loss: 0.077175, tar: 0.008389 
l0: 0.003238, l1: 0.003229, l2: 0.005556, l3: 0.004991, l4: 0.018119, l5: 0.013346, l6: 0.012365

[epoch: 110/100000, batch:    66/  187, ite: 10279] train loss: 0.077116, tar: 0.008370 
l0: 0.086928, l1: 0.073081, l2: 0.105954, l3: 0.107263, l4: 0.113342, l5: 0.105483, l6: 0.141040

[epoch: 110/100000, batch:    68/  187, ite: 10280] train loss: 0.079459, tar: 0.008651 
l0: 0.014702, l1: 0.016390, l2: 0.016758, l3: 0.015156, l4: 0.016284, l5: 0.016587, l6: 0.014579

[epoch: 110/100000, batch:    70/  187, ite: 10281] train loss: 0.079569, tar: 0.008672 
l0: 0.012276, l1: 0.010611, l2: 0.011987, l3: 0.013117, l4: 0.017504, l5: 0.020845, l6: 0.023885

[epoch: 110/100000, batch:    72/  187, ite: 10282] train loss: 0.079678, tar: 0.008685 
l0: 0.019722, l1: 0.015721, l2: 0.022275, l3: 0.024387, l4: 0.035645, l5: 0.042381, l6: 0.056416

[epoch: 110/100000, batch:    74/  187, ite: 10283] train loss: 0.080161, tar: 0.008724 
l0: 0.007426, l1: 0.006956, l2: 0.008901, l3: 0.007681, l4: 0.012930, l5: 0.016810, l6: 0.023215

[epoch: 110/100000, batch:    76/  187, ite: 10284] train loss: 0.080175, tar: 0.008719 
l0: 0.018214, l1: 0.019656, l2: 0.018222, l3: 0.016097, l4: 0.021315, l5: 0.025671, l6: 0.028597

[epoch: 110/100000, batch:    78/  187, ite: 10285] train loss: 0.080412, tar: 0.008753 
l0: 0.032466, l1: 0.027069, l2: 0.038823, l3: 0.058279, l4: 0.084301, l5: 0.073451, l6: 0.066091

[epoch: 110/100000, batch:    80/  187, ite: 10286] train loss: 0.081461, tar: 0.008836 
l0: 0.006242, l1: 0.006700, l2: 0.006461, l3: 0.006955, l4: 0.014575, l5: 0.010084, l6: 0.011659

[epoch: 110/100000, batch:    82/  187, ite: 10287] train loss: 0.081396, tar: 0.008827 
l0: 0.008818, l1: 0.009418, l2: 0.009623, l3: 0.008969, l4: 0.015705, l5: 0.016023, l6: 0.023398

[epoch: 110/100000, batch:    84/  187, ite: 10288] train loss: 0.081432, tar: 0.008827 
l0: 0.015239, l1: 0.015410, l2: 0.015438, l3: 0.018137, l4: 0.036252, l5: 0.029859, l6: 0.033000

[epoch: 110/100000, batch:    86/  187, ite: 10289] train loss: 0.081716, tar: 0.008849 
l0: 0.012105, l1: 0.011538, l2: 0.010930, l3: 0.011941, l4: 0.023512, l5: 0.023201, l6: 0.017205

[epoch: 110/100000, batch:    88/  187, ite: 10290] train loss: 0.081815, tar: 0.008860 
l0: 0.022804, l1: 0.021244, l2: 0.022221, l3: 0.023068, l4: 0.042420, l5: 0.049846, l6: 0.060923

[epoch: 110/100000, batch:    90/  187, ite: 10291] train loss: 0.082367, tar: 0.008908 
l0: 0.028917, l1: 0.024571, l2: 0.039382, l3: 0.083852, l4: 0.155978, l5: 0.100352, l6: 0.093782

[epoch: 110/100000, batch:    92/  187, ite: 10292] train loss: 0.083889, tar: 0.008976 
l0: 0.007398, l1: 0.007308, l2: 0.009334, l3: 0.008603, l4: 0.015687, l5: 0.017296, l6: 0.028042

[epoch: 110/100000, batch:    94/  187, ite: 10293] train loss: 0.083923, tar: 0.008971 
l0: 0.022055, l1: 0.018788, l2: 0.032717, l3: 0.044290, l4: 0.110273, l5: 0.108829, l6: 0.091771

[epoch: 110/100000, batch:    96/  187, ite: 10294] train loss: 0.085095, tar: 0.009016 
l0: 0.017136, l1: 0.017012, l2: 0.039649, l3: 0.045828, l4: 0.035192, l5: 0.040359, l6: 0.045399

[epoch: 110/100000, batch:    98/  187, ite: 10295] train loss: 0.085622, tar: 0.009043 
l0: 0.017210, l1: 0.016275, l2: 0.017243, l3: 0.022037, l4: 0.045092, l5: 0.045905, l6: 0.055949

[epoch: 110/100000, batch:   100/  187, ite: 10296] train loss: 0.086075, tar: 0.009071 
l0: 0.216131, l1: 0.223190, l2: 0.221813, l3: 0.209734, l4: 0.246067, l5: 0.272515, l6: 0.294138

[epoch: 110/100000, batch:   102/  187, ite: 10297] train loss: 0.091454, tar: 0.009768 
l0: 0.017176, l1: 0.016958, l2: 0.023672, l3: 0.022893, l4: 0.024867, l5: 0.024922, l6: 0.024565

[epoch: 110/100000, batch:   104/  187, ite: 10298] train loss: 0.091668, tar: 0.009793 
l0: 0.093942, l1: 0.089981, l2: 0.114542, l3: 0.153138, l4: 0.171663, l5: 0.165156, l6: 0.199794

[epoch: 110/100000, batch:   106/  187, ite: 10299] train loss: 0.094666, tar: 0.010074 
l0: 0.040981, l1: 0.035639, l2: 0.048299, l3: 0.057548, l4: 0.117465, l5: 0.139259, l6: 0.173685

[epoch: 110/100000, batch:   108/  187, ite: 10300] train loss: 0.096393, tar: 0.010177 
l0: 0.032053, l1: 0.029035, l2: 0.033531, l3: 0.047195, l4: 0.183440, l5: 0.182165, l6: 0.217528

[epoch: 110/100000, batch:   110/  187, ite: 10301] train loss: 0.098482, tar: 0.010250 
l0: 0.045045, l1: 0.049901, l2: 0.081790, l3: 0.061611, l4: 0.084646, l5: 0.068547, l6: 0.069204

[epoch: 110/100000, batch:   112/  187, ite: 10302] train loss: 0.099681, tar: 0.010365 
l0: 0.038395, l1: 0.032710, l2: 0.090696, l3: 0.106000, l4: 0.096679, l5: 0.095525, l6: 0.099445

[epoch: 110/100000, batch:   114/  187, ite: 10303] train loss: 0.101199, tar: 0.010458 
l0: 0.032117, l1: 0.028589, l2: 0.042116, l3: 0.051076, l4: 0.045607, l5: 0.048708, l6: 0.065876

[epoch: 110/100000, batch:   116/  187, ite: 10304] train loss: 0.101899, tar: 0.010529 
l0: 0.077507, l1: 0.067840, l2: 0.074450, l3: 0.095958, l4: 0.057740, l5: 0.082057, l6: 0.148234

[epoch: 110/100000, batch:   118/  187, ite: 10305] train loss: 0.103544, tar: 0.010748 
l0: 0.025362, l1: 0.024357, l2: 0.032193, l3: 0.028809, l4: 0.045726, l5: 0.058159, l6: 0.056915

[epoch: 110/100000, batch:   120/  187, ite: 10306] train loss: 0.104093, tar: 0.010796 
l0: 0.050274, l1: 0.045241, l2: 0.054729, l3: 0.058749, l4: 0.058345, l5: 0.079345, l6: 0.077717

[epoch: 110/100000, batch:   122/  187, ite: 10307] train loss: 0.105137, tar: 0.010925 
l0: 0.042812, l1: 0.048828, l2: 0.044979, l3: 0.045125, l4: 0.060095, l5: 0.058754, l6: 0.085005

[epoch: 110/100000, batch:   124/  187, ite: 10308] train loss: 0.106047, tar: 0.011028 
l0: 0.028472, l1: 0.027260, l2: 0.036108, l3: 0.040416, l4: 0.038617, l5: 0.034760, l6: 0.064420

[epoch: 110/100000, batch:   126/  187, ite: 10309] train loss: 0.106578, tar: 0.011085 
l0: 0.062712, l1: 0.063780, l2: 0.054891, l3: 0.060285, l4: 0.105701, l5: 0.124464, l6: 0.187729

[epoch: 110/100000, batch:   128/  187, ite: 10310] train loss: 0.108362, tar: 0.011251 
l0: 0.041950, l1: 0.044172, l2: 0.048551, l3: 0.053678, l4: 0.084579, l5: 0.111146, l6: 0.106623

[epoch: 110/100000, batch:   130/  187, ite: 10311] train loss: 0.109591, tar: 0.011350 
l0: 0.049264, l1: 0.060425, l2: 0.040258, l3: 0.043861, l4: 0.059551, l5: 0.055320, l6: 0.057579

[epoch: 110/100000, batch:   132/  187, ite: 10312] train loss: 0.110414, tar: 0.011472 
l0: 0.026169, l1: 0.023468, l2: 0.034671, l3: 0.042069, l4: 0.046750, l5: 0.049731, l6: 0.065276

[epoch: 110/100000, batch:   134/  187, ite: 10313] train loss: 0.110982, tar: 0.011518 
l0: 0.025638, l1: 0.023891, l2: 0.045620, l3: 0.046889, l4: 0.044404, l5: 0.036432, l6: 0.045292

[epoch: 110/100000, batch:   136/  187, ite: 10314] train loss: 0.111482, tar: 0.011563 
l0: 0.045216, l1: 0.050395, l2: 0.072522, l3: 0.087133, l4: 0.124388, l5: 0.136287, l6: 0.132415

[epoch: 110/100000, batch:   138/  187, ite: 10315] train loss: 0.113187, tar: 0.011670 
l0: 0.047267, l1: 0.045237, l2: 0.048308, l3: 0.065381, l4: 0.093122, l5: 0.098231, l6: 0.137037

[epoch: 110/100000, batch:   140/  187, ite: 10316] train loss: 0.114520, tar: 0.011783 
l0: 0.058971, l1: 0.067554, l2: 0.082965, l3: 0.077774, l4: 0.089845, l5: 0.089038, l6: 0.068730

[epoch: 110/100000, batch:   142/  187, ite: 10317] train loss: 0.115846, tar: 0.011932 
l0: 0.020714, l1: 0.017555, l2: 0.035529, l3: 0.033753, l4: 0.086353, l5: 0.082167, l6: 0.118774

[epoch: 110/100000, batch:   144/  187, ite: 10318] train loss: 0.116724, tar: 0.011959 
l0: 0.031828, l1: 0.032417, l2: 0.048244, l3: 0.057932, l4: 0.084012, l5: 0.055182, l6: 0.083609

[epoch: 110/100000, batch:   146/  187, ite: 10319] train loss: 0.117590, tar: 0.012022 
l0: 0.044687, l1: 0.044773, l2: 0.040364, l3: 0.048595, l4: 0.098365, l5: 0.091042, l6: 0.120393

[epoch: 110/100000, batch:   148/  187, ite: 10320] train loss: 0.118749, tar: 0.012124 
l0: 0.051939, l1: 0.056485, l2: 0.046190, l3: 0.058248, l4: 0.078321, l5: 0.062662, l6: 0.082642

[epoch: 110/100000, batch:   150/  187, ite: 10321] train loss: 0.119738, tar: 0.012248 
l0: 0.017880, l1: 0.013774, l2: 0.028390, l3: 0.033021, l4: 0.037714, l5: 0.043160, l6: 0.051847

[epoch: 110/100000, batch:   152/  187, ite: 10322] train loss: 0.120068, tar: 0.012265 
l0: 0.021574, l1: 0.020344, l2: 0.020760, l3: 0.025923, l4: 0.052582, l5: 0.046987, l6: 0.050267

[epoch: 110/100000, batch:   154/  187, ite: 10323] train loss: 0.120434, tar: 0.012294 
l0: 0.023699, l1: 0.024642, l2: 0.019785, l3: 0.021439, l4: 0.052537, l5: 0.036220, l6: 0.044237

[epoch: 110/100000, batch:   156/  187, ite: 10324] train loss: 0.120749, tar: 0.012329 
l0: 0.022966, l1: 0.018337, l2: 0.033916, l3: 0.037990, l4: 0.045702, l5: 0.042198, l6: 0.037482

[epoch: 110/100000, batch:   158/  187, ite: 10325] train loss: 0.121112, tar: 0.012362 
l0: 0.021746, l1: 0.018611, l2: 0.024380, l3: 0.027353, l4: 0.062784, l5: 0.057079, l6: 0.059760

[epoch: 110/100000, batch:   160/  187, ite: 10326] train loss: 0.121574, tar: 0.012391 
l0: 0.031338, l1: 0.031316, l2: 0.036377, l3: 0.037194, l4: 0.057583, l5: 0.057268, l6: 0.057344

[epoch: 110/100000, batch:   162/  187, ite: 10327] train loss: 0.122145, tar: 0.012449 
l0: 0.039019, l1: 0.039131, l2: 0.054625, l3: 0.066334, l4: 0.083572, l5: 0.083828, l6: 0.073119

[epoch: 110/100000, batch:   164/  187, ite: 10328] train loss: 0.123113, tar: 0.012530 
l0: 0.026877, l1: 0.029548, l2: 0.030601, l3: 0.036395, l4: 0.080014, l5: 0.056954, l6: 0.049635

[epoch: 110/100000, batch:   166/  187, ite: 10329] train loss: 0.123681, tar: 0.012573 
l0: 0.020633, l1: 0.020826, l2: 0.024399, l3: 0.030811, l4: 0.084895, l5: 0.060820, l6: 0.061487

[epoch: 110/100000, batch:   168/  187, ite: 10330] train loss: 0.124227, tar: 0.012598 
l0: 0.029238, l1: 0.034027, l2: 0.036299, l3: 0.041039, l4: 0.061946, l5: 0.040002, l6: 0.039745

[epoch: 110/100000, batch:   170/  187, ite: 10331] train loss: 0.124705, tar: 0.012648 
l0: 0.024785, l1: 0.026245, l2: 0.022210, l3: 0.022756, l4: 0.030598, l5: 0.026321, l6: 0.044512

[epoch: 110/100000, batch:   172/  187, ite: 10332] train loss: 0.124924, tar: 0.012685 
l0: 0.015205, l1: 0.014940, l2: 0.017600, l3: 0.021220, l4: 0.067730, l5: 0.063602, l6: 0.064959

[epoch: 110/100000, batch:   174/  187, ite: 10333] train loss: 0.125345, tar: 0.012692 
l0: 0.029533, l1: 0.029367, l2: 0.029503, l3: 0.031223, l4: 0.045746, l5: 0.056775, l6: 0.045287

[epoch: 110/100000, batch:   176/  187, ite: 10334] train loss: 0.125771, tar: 0.012743 
l0: 0.012677, l1: 0.013851, l2: 0.013001, l3: 0.011014, l4: 0.022382, l5: 0.022077, l6: 0.021033

[epoch: 110/100000, batch:   178/  187, ite: 10335] train loss: 0.125742, tar: 0.012742 
l0: 0.044307, l1: 0.052486, l2: 0.058610, l3: 0.057257, l4: 0.080099, l5: 0.086665, l6: 0.064163

[epoch: 110/100000, batch:   180/  187, ite: 10336] train loss: 0.126688, tar: 0.012836 
l0: 0.017662, l1: 0.021366, l2: 0.023092, l3: 0.027726, l4: 0.043441, l5: 0.029855, l6: 0.030790

[epoch: 110/100000, batch:   182/  187, ite: 10337] train loss: 0.126887, tar: 0.012851 
l0: 0.018311, l1: 0.018759, l2: 0.018593, l3: 0.031686, l4: 0.055651, l5: 0.052205, l6: 0.043770

[epoch: 110/100000, batch:   184/  187, ite: 10338] train loss: 0.127219, tar: 0.012867 
l0: 0.016066, l1: 0.021368, l2: 0.014520, l3: 0.012582, l4: 0.016110, l5: 0.013757, l6: 0.013245

[epoch: 110/100000, batch:   186/  187, ite: 10339] train loss: 0.127161, tar: 0.012876 
l0: 0.023362, l1: 0.024993, l2: 0.022558, l3: 0.021358, l4: 0.020684, l5: 0.023657, l6: 0.025097

[epoch: 110/100000, batch:   188/  187, ite: 10340] train loss: 0.127263, tar: 0.012907 
l0: 0.013578, l1: 0.012921, l2: 0.013646, l3: 0.015368, l4: 0.034538, l5: 0.029293, l6: 0.044127

[epoch: 111/100000, batch:     2/  187, ite: 10341] train loss: 0.127369, tar: 0.012909 
l0: 0.021559, l1: 0.024522, l2: 0.026631, l3: 0.019562, l4: 0.028442, l5: 0.023960, l6: 0.031729

[epoch: 111/100000, batch:     4/  187, ite: 10342] train loss: 0.127512, tar: 0.012934 
l0: 0.020549, l1: 0.021758, l2: 0.019679, l3: 0.023459, l4: 0.036315, l5: 0.033056, l6: 0.035883

[epoch: 111/100000, batch:     6/  187, ite: 10343] train loss: 0.127697, tar: 0.012957 
l0: 0.029519, l1: 0.032279, l2: 0.022601, l3: 0.020035, l4: 0.040368, l5: 0.041232, l6: 0.059930

[epoch: 111/100000, batch:     8/  187, ite: 10344] train loss: 0.128040, tar: 0.013005 
l0: 0.025364, l1: 0.024551, l2: 0.036773, l3: 0.044072, l4: 0.063338, l5: 0.044832, l6: 0.072134

[epoch: 111/100000, batch:    10/  187, ite: 10345] train loss: 0.128571, tar: 0.013041 
l0: 0.020652, l1: 0.018441, l2: 0.025166, l3: 0.038229, l4: 0.066100, l5: 0.071185, l6: 0.054538

[epoch: 111/100000, batch:    12/  187, ite: 10346] train loss: 0.129050, tar: 0.013063 
l0: 0.019240, l1: 0.019736, l2: 0.020048, l3: 0.019793, l4: 0.037018, l5: 0.031322, l6: 0.032827

[epoch: 111/100000, batch:    14/  187, ite: 10347] train loss: 0.129197, tar: 0.013080 
l0: 0.018408, l1: 0.019508, l2: 0.019212, l3: 0.021438, l4: 0.042887, l5: 0.031127, l6: 0.035701

[epoch: 111/100000, batch:    16/  187, ite: 10348] train loss: 0.129367, tar: 0.013096 
l0: 0.025008, l1: 0.025610, l2: 0.026064, l3: 0.031562, l4: 0.038669, l5: 0.034430, l6: 0.052358

[epoch: 111/100000, batch:    18/  187, ite: 10349] train loss: 0.129665, tar: 0.013130 
l0: 0.024750, l1: 0.028427, l2: 0.027724, l3: 0.033452, l4: 0.036729, l5: 0.028367, l6: 0.030738

[epoch: 111/100000, batch:    20/  187, ite: 10350] train loss: 0.129896, tar: 0.013163 
l0: 0.032766, l1: 0.039048, l2: 0.022996, l3: 0.031442, l4: 0.048845, l5: 0.048080, l6: 0.053421

[epoch: 111/100000, batch:    22/  187, ite: 10351] train loss: 0.130313, tar: 0.013219 
l0: 0.022159, l1: 0.021827, l2: 0.017764, l3: 0.018944, l4: 0.036487, l5: 0.041284, l6: 0.037335

[epoch: 111/100000, batch:    24/  187, ite: 10352] train loss: 0.130500, tar: 0.013244 
l0: 0.015900, l1: 0.016103, l2: 0.016343, l3: 0.016466, l4: 0.032112, l5: 0.029452, l6: 0.031651

[epoch: 111/100000, batch:    26/  187, ite: 10353] train loss: 0.130577, tar: 0.013252 
l0: 0.010951, l1: 0.012817, l2: 0.011679, l3: 0.011412, l4: 0.021213, l5: 0.018953, l6: 0.036452

[epoch: 111/100000, batch:    28/  187, ite: 10354] train loss: 0.130557, tar: 0.013245 
l0: 0.021278, l1: 0.019014, l2: 0.026901, l3: 0.035508, l4: 0.048337, l5: 0.055686, l6: 0.056072

[epoch: 111/100000, batch:    30/  187, ite: 10355] train loss: 0.130930, tar: 0.013268 
l0: 0.017316, l1: 0.017624, l2: 0.021846, l3: 0.026829, l4: 0.031013, l5: 0.033498, l6: 0.028871

[epoch: 111/100000, batch:    32/  187, ite: 10356] train loss: 0.131059, tar: 0.013279 
l0: 0.015943, l1: 0.016630, l2: 0.020920, l3: 0.022286, l4: 0.028514, l5: 0.035338, l6: 0.021565

[epoch: 111/100000, batch:    34/  187, ite: 10357] train loss: 0.131144, tar: 0.013287 
l0: 0.017813, l1: 0.017832, l2: 0.024197, l3: 0.027147, l4: 0.027235, l5: 0.033900, l6: 0.020527

[epoch: 111/100000, batch:    36/  187, ite: 10358] train loss: 0.131249, tar: 0.013299 
l0: 0.016150, l1: 0.016896, l2: 0.020042, l3: 0.021805, l4: 0.031088, l5: 0.032492, l6: 0.027513

[epoch: 111/100000, batch:    38/  187, ite: 10359] train loss: 0.131345, tar: 0.013307 
l0: 0.024362, l1: 0.026554, l2: 0.025536, l3: 0.025764, l4: 0.025050, l5: 0.027651, l6: 0.033263

[epoch: 111/100000, batch:    40/  187, ite: 10360] train loss: 0.131503, tar: 0.013338 
l0: 0.022462, l1: 0.022723, l2: 0.019708, l3: 0.023292, l4: 0.062461, l5: 0.066310, l6: 0.079244

[epoch: 111/100000, batch:    42/  187, ite: 10361] train loss: 0.131959, tar: 0.013363 
l0: 0.020355, l1: 0.021293, l2: 0.019707, l3: 0.018583, l4: 0.025816, l5: 0.029007, l6: 0.026791

[epoch: 111/100000, batch:    44/  187, ite: 10362] train loss: 0.132041, tar: 0.013383 
l0: 0.021754, l1: 0.021214, l2: 0.019330, l3: 0.025611, l4: 0.026945, l5: 0.024234, l6: 0.025808

[epoch: 111/100000, batch:    46/  187, ite: 10363] train loss: 0.132132, tar: 0.013406 
l0: 0.019633, l1: 0.020598, l2: 0.019728, l3: 0.020911, l4: 0.041211, l5: 0.035628, l6: 0.035347

[epoch: 111/100000, batch:    48/  187, ite: 10364] train loss: 0.132299, tar: 0.013423 
l0: 0.014404, l1: 0.014365, l2: 0.015905, l3: 0.017468, l4: 0.023311, l5: 0.019953, l6: 0.022287

[epoch: 111/100000, batch:    50/  187, ite: 10365] train loss: 0.132286, tar: 0.013425 
l0: 0.016857, l1: 0.016905, l2: 0.018505, l3: 0.019533, l4: 0.018817, l5: 0.017697, l6: 0.018708

[epoch: 111/100000, batch:    52/  187, ite: 10366] train loss: 0.132272, tar: 0.013435 
l0: 0.016022, l1: 0.017863, l2: 0.013572, l3: 0.016625, l4: 0.031343, l5: 0.032112, l6: 0.032064

[epoch: 111/100000, batch:    54/  187, ite: 10367] train loss: 0.132346, tar: 0.013442 
l0: 0.018529, l1: 0.021405, l2: 0.019085, l3: 0.020639, l4: 0.031036, l5: 0.025959, l6: 0.025279

[epoch: 111/100000, batch:    56/  187, ite: 10368] train loss: 0.132427, tar: 0.013456 
l0: 0.023634, l1: 0.025294, l2: 0.019667, l3: 0.020415, l4: 0.023709, l5: 0.021174, l6: 0.021800

[epoch: 111/100000, batch:    58/  187, ite: 10369] train loss: 0.132490, tar: 0.013483 
l0: 0.018787, l1: 0.017862, l2: 0.018279, l3: 0.020584, l4: 0.025791, l5: 0.026468, l6: 0.040240

[epoch: 111/100000, batch:    60/  187, ite: 10370] train loss: 0.132586, tar: 0.013498 
l0: 0.016254, l1: 0.017411, l2: 0.018975, l3: 0.021198, l4: 0.032238, l5: 0.031890, l6: 0.029101

[epoch: 111/100000, batch:    62/  187, ite: 10371] train loss: 0.132679, tar: 0.013505 
l0: 0.015496, l1: 0.016110, l2: 0.019098, l3: 0.020060, l4: 0.021587, l5: 0.017513, l6: 0.020983

[epoch: 111/100000, batch:    64/  187, ite: 10372] train loss: 0.132674, tar: 0.013510 
l0: 0.017063, l1: 0.017429, l2: 0.019148, l3: 0.018023, l4: 0.039337, l5: 0.037081, l6: 0.040321

[epoch: 111/100000, batch:    66/  187, ite: 10373] train loss: 0.132823, tar: 0.013520 
l0: 0.011525, l1: 0.013873, l2: 0.020355, l3: 0.012557, l4: 0.030501, l5: 0.024818, l6: 0.016544

[epoch: 111/100000, batch:    68/  187, ite: 10374] train loss: 0.132816, tar: 0.013515 
l0: 0.012908, l1: 0.011406, l2: 0.012076, l3: 0.018438, l4: 0.070006, l5: 0.059515, l6: 0.060781

[epoch: 111/100000, batch:    70/  187, ite: 10375] train loss: 0.133116, tar: 0.013513 
l0: 0.015155, l1: 0.015346, l2: 0.013520, l3: 0.015602, l4: 0.024793, l5: 0.022471, l6: 0.025350

[epoch: 111/100000, batch:    72/  187, ite: 10376] train loss: 0.133113, tar: 0.013517 
l0: 0.018761, l1: 0.018969, l2: 0.018008, l3: 0.015550, l4: 0.031555, l5: 0.035567, l6: 0.051011

[epoch: 111/100000, batch:    74/  187, ite: 10377] train loss: 0.133263, tar: 0.013531 
l0: 0.009090, l1: 0.010672, l2: 0.012018, l3: 0.009987, l4: 0.016472, l5: 0.013459, l6: 0.012006

[epoch: 111/100000, batch:    76/  187, ite: 10378] train loss: 0.133132, tar: 0.013520 
l0: 0.007193, l1: 0.008140, l2: 0.011214, l3: 0.013248, l4: 0.010208, l5: 0.011905, l6: 0.009919

[epoch: 111/100000, batch:    78/  187, ite: 10379] train loss: 0.132970, tar: 0.013503 
l0: 0.008455, l1: 0.008679, l2: 0.009273, l3: 0.010619, l4: 0.026114, l5: 0.020282, l6: 0.016851

[epoch: 111/100000, batch:    80/  187, ite: 10380] train loss: 0.132884, tar: 0.013490 
l0: 0.011987, l1: 0.011096, l2: 0.014144, l3: 0.016813, l4: 0.034256, l5: 0.040404, l6: 0.053704

[epoch: 111/100000, batch:    82/  187, ite: 10381] train loss: 0.133014, tar: 0.013486 
l0: 0.015205, l1: 0.016461, l2: 0.018211, l3: 0.014982, l4: 0.021425, l5: 0.018934, l6: 0.022595

[epoch: 111/100000, batch:    84/  187, ite: 10382] train loss: 0.133000, tar: 0.013490 
l0: 0.007752, l1: 0.007965, l2: 0.012749, l3: 0.012171, l4: 0.016798, l5: 0.016800, l6: 0.016172

[epoch: 111/100000, batch:    86/  187, ite: 10383] train loss: 0.132889, tar: 0.013475 
l0: 0.013341, l1: 0.013396, l2: 0.016820, l3: 0.014498, l4: 0.015018, l5: 0.016624, l6: 0.021509

[epoch: 111/100000, batch:    88/  187, ite: 10384] train loss: 0.132833, tar: 0.013475 
l0: 0.016528, l1: 0.018122, l2: 0.021286, l3: 0.019221, l4: 0.038961, l5: 0.029580, l6: 0.029904

[epoch: 111/100000, batch:    90/  187, ite: 10385] train loss: 0.132938, tar: 0.013483 
l0: 0.005835, l1: 0.006089, l2: 0.006170, l3: 0.008040, l4: 0.014796, l5: 0.012150, l6: 0.012255

[epoch: 111/100000, batch:    92/  187, ite: 10386] train loss: 0.132763, tar: 0.013463 
l0: 0.015931, l1: 0.016607, l2: 0.021450, l3: 0.027489, l4: 0.046319, l5: 0.046858, l6: 0.049154

[epoch: 111/100000, batch:    94/  187, ite: 10387] train loss: 0.132999, tar: 0.013469 
l0: 0.034971, l1: 0.034079, l2: 0.028484, l3: 0.027228, l4: 0.032269, l5: 0.040387, l6: 0.050731

[epoch: 111/100000, batch:    96/  187, ite: 10388] train loss: 0.133295, tar: 0.013525 
l0: 0.015548, l1: 0.018509, l2: 0.016057, l3: 0.016444, l4: 0.028944, l5: 0.023064, l6: 0.027056

[epoch: 111/100000, batch:    98/  187, ite: 10389] train loss: 0.133327, tar: 0.013530 
l0: 0.011666, l1: 0.013756, l2: 0.013197, l3: 0.013004, l4: 0.027775, l5: 0.020746, l6: 0.018065

[epoch: 111/100000, batch:   100/  187, ite: 10390] train loss: 0.133288, tar: 0.013525 
l0: 0.012531, l1: 0.013869, l2: 0.012164, l3: 0.012242, l4: 0.014323, l5: 0.015605, l6: 0.019821

[epoch: 111/100000, batch:   102/  187, ite: 10391] train loss: 0.133205, tar: 0.013523 
l0: 0.008656, l1: 0.008954, l2: 0.011433, l3: 0.014462, l4: 0.017460, l5: 0.014066, l6: 0.015429

[epoch: 111/100000, batch:   104/  187, ite: 10392] train loss: 0.133096, tar: 0.013510 
l0: 0.015973, l1: 0.015292, l2: 0.016818, l3: 0.023107, l4: 0.036185, l5: 0.034249, l6: 0.043710

[epoch: 111/100000, batch:   106/  187, ite: 10393] train loss: 0.133228, tar: 0.013516 
l0: 0.016837, l1: 0.017972, l2: 0.016254, l3: 0.018223, l4: 0.025311, l5: 0.026757, l6: 0.029777

[epoch: 111/100000, batch:   108/  187, ite: 10394] train loss: 0.133274, tar: 0.013525 
l0: 0.015198, l1: 0.016346, l2: 0.015311, l3: 0.014527, l4: 0.031368, l5: 0.028288, l6: 0.031211

[epoch: 111/100000, batch:   110/  187, ite: 10395] train loss: 0.133322, tar: 0.013529 
l0: 0.014947, l1: 0.016384, l2: 0.016860, l3: 0.015027, l4: 0.019196, l5: 0.020554, l6: 0.032770

[epoch: 111/100000, batch:   112/  187, ite: 10396] train loss: 0.133328, tar: 0.013533 
l0: 0.013996, l1: 0.012880, l2: 0.015900, l3: 0.020516, l4: 0.026989, l5: 0.028330, l6: 0.023359

[epoch: 111/100000, batch:   114/  187, ite: 10397] train loss: 0.133350, tar: 0.013534 
l0: 0.016422, l1: 0.015480, l2: 0.017281, l3: 0.021703, l4: 0.031786, l5: 0.029637, l6: 0.040579

[epoch: 111/100000, batch:   116/  187, ite: 10398] train loss: 0.133449, tar: 0.013541 
l0: 0.014892, l1: 0.014703, l2: 0.017791, l3: 0.021583, l4: 0.023269, l5: 0.024578, l6: 0.027908

[epoch: 111/100000, batch:   118/  187, ite: 10399] train loss: 0.133477, tar: 0.013544 
l0: 0.015736, l1: 0.015758, l2: 0.017534, l3: 0.019283, l4: 0.018187, l5: 0.019839, l6: 0.019782

[epoch: 111/100000, batch:   120/  187, ite: 10400] train loss: 0.133459, tar: 0.013550 
l0: 0.011421, l1: 0.011691, l2: 0.011339, l3: 0.010135, l4: 0.015170, l5: 0.016397, l6: 0.021474

[epoch: 111/100000, batch:   122/  187, ite: 10401] train loss: 0.133370, tar: 0.013545 
l0: 0.009930, l1: 0.010154, l2: 0.012872, l3: 0.014265, l4: 0.026552, l5: 0.028094, l6: 0.033815

[epoch: 111/100000, batch:   124/  187, ite: 10402] train loss: 0.133375, tar: 0.013536 
l0: 0.015816, l1: 0.015832, l2: 0.015489, l3: 0.011773, l4: 0.028349, l5: 0.032373, l6: 0.046884

[epoch: 111/100000, batch:   126/  187, ite: 10403] train loss: 0.133458, tar: 0.013541 
l0: 0.008258, l1: 0.008994, l2: 0.008447, l3: 0.008450, l4: 0.017118, l5: 0.017771, l6: 0.019168

[epoch: 111/100000, batch:   128/  187, ite: 10404] train loss: 0.133346, tar: 0.013528 
l0: 0.010804, l1: 0.010781, l2: 0.011332, l3: 0.011483, l4: 0.031396, l5: 0.027628, l6: 0.018577

[epoch: 111/100000, batch:   130/  187, ite: 10405] train loss: 0.133318, tar: 0.013521 
l0: 0.042518, l1: 0.049474, l2: 0.049228, l3: 0.036366, l4: 0.069919, l5: 0.065814, l6: 0.038824

[epoch: 111/100000, batch:   132/  187, ite: 10406] train loss: 0.133857, tar: 0.013593 
l0: 0.019805, l1: 0.023269, l2: 0.020162, l3: 0.024841, l4: 0.027789, l5: 0.023826, l6: 0.022824

[epoch: 111/100000, batch:   134/  187, ite: 10407] train loss: 0.133927, tar: 0.013608 
l0: 0.021182, l1: 0.024160, l2: 0.017980, l3: 0.019186, l4: 0.035498, l5: 0.027768, l6: 0.029988

[epoch: 111/100000, batch:   136/  187, ite: 10408] train loss: 0.134030, tar: 0.013627 
l0: 0.019268, l1: 0.022101, l2: 0.019581, l3: 0.021865, l4: 0.040826, l5: 0.029934, l6: 0.035508

[epoch: 111/100000, batch:   138/  187, ite: 10409] train loss: 0.134164, tar: 0.013641 
l0: 0.015016, l1: 0.016231, l2: 0.015055, l3: 0.015160, l4: 0.037582, l5: 0.032839, l6: 0.025930

[epoch: 111/100000, batch:   140/  187, ite: 10410] train loss: 0.134222, tar: 0.013644 
l0: 0.011077, l1: 0.014417, l2: 0.011377, l3: 0.009610, l4: 0.013611, l5: 0.013625, l6: 0.014794

[epoch: 111/100000, batch:   142/  187, ite: 10411] train loss: 0.134111, tar: 0.013638 
l0: 0.006818, l1: 0.007518, l2: 0.008609, l3: 0.007555, l4: 0.018463, l5: 0.016851, l6: 0.023369

[epoch: 111/100000, batch:   144/  187, ite: 10412] train loss: 0.134002, tar: 0.013621 
l0: 0.026281, l1: 0.030790, l2: 0.028343, l3: 0.024502, l4: 0.038054, l5: 0.031747, l6: 0.033468

[epoch: 111/100000, batch:   146/  187, ite: 10413] train loss: 0.134193, tar: 0.013652 
l0: 0.009202, l1: 0.010285, l2: 0.008974, l3: 0.010409, l4: 0.025123, l5: 0.022178, l6: 0.022102

[epoch: 111/100000, batch:   148/  187, ite: 10414] train loss: 0.134131, tar: 0.013641 
l0: 0.009696, l1: 0.012972, l2: 0.011463, l3: 0.008108, l4: 0.014263, l5: 0.011637, l6: 0.014104

[epoch: 111/100000, batch:   150/  187, ite: 10415] train loss: 0.134006, tar: 0.013631 
l0: 0.019471, l1: 0.023140, l2: 0.023604, l3: 0.020777, l4: 0.029543, l5: 0.027133, l6: 0.021890

[epoch: 111/100000, batch:   152/  187, ite: 10416] train loss: 0.134081, tar: 0.013646 
l0: 0.023711, l1: 0.024738, l2: 0.027321, l3: 0.027691, l4: 0.040545, l5: 0.031728, l6: 0.030376

[epoch: 111/100000, batch:   154/  187, ite: 10417] train loss: 0.134254, tar: 0.013670 
l0: 0.017558, l1: 0.017390, l2: 0.016713, l3: 0.019798, l4: 0.039383, l5: 0.037758, l6: 0.031484

[epoch: 111/100000, batch:   156/  187, ite: 10418] train loss: 0.134364, tar: 0.013679 
l0: 0.012181, l1: 0.013469, l2: 0.015477, l3: 0.012159, l4: 0.034310, l5: 0.023875, l6: 0.018541

[epoch: 111/100000, batch:   158/  187, ite: 10419] train loss: 0.134353, tar: 0.013675 
l0: 0.011319, l1: 0.011730, l2: 0.013263, l3: 0.013421, l4: 0.020144, l5: 0.018613, l6: 0.016247

[epoch: 111/100000, batch:   160/  187, ite: 10420] train loss: 0.134283, tar: 0.013670 
l0: 0.012250, l1: 0.011670, l2: 0.012720, l3: 0.017237, l4: 0.027080, l5: 0.026804, l6: 0.021736

[epoch: 111/100000, batch:   162/  187, ite: 10421] train loss: 0.134272, tar: 0.013666 
l0: 0.016802, l1: 0.018846, l2: 0.015951, l3: 0.014899, l4: 0.026027, l5: 0.019495, l6: 0.016996

[epoch: 111/100000, batch:   164/  187, ite: 10422] train loss: 0.134259, tar: 0.013674 
l0: 0.082482, l1: 0.083240, l2: 0.096772, l3: 0.118964, l4: 0.083508, l5: 0.082970, l6: 0.060890

[epoch: 111/100000, batch:   166/  187, ite: 10423] train loss: 0.135381, tar: 0.013837 
l0: 0.010076, l1: 0.009915, l2: 0.011292, l3: 0.012041, l4: 0.021504, l5: 0.019733, l6: 0.025105

[epoch: 111/100000, batch:   168/  187, ite: 10424] train loss: 0.135320, tar: 0.013828 
l0: 0.009579, l1: 0.009689, l2: 0.011224, l3: 0.009791, l4: 0.021376, l5: 0.020548, l6: 0.022338

[epoch: 111/100000, batch:   170/  187, ite: 10425] train loss: 0.135248, tar: 0.013818 
l0: 0.014337, l1: 0.013680, l2: 0.018607, l3: 0.024163, l4: 0.065613, l5: 0.061502, l6: 0.055584

[epoch: 111/100000, batch:   172/  187, ite: 10426] train loss: 0.135526, tar: 0.013819 
l0: 0.130035, l1: 0.147340, l2: 0.121466, l3: 0.140001, l4: 0.089765, l5: 0.089778, l6: 0.101001

[epoch: 111/100000, batch:   174/  187, ite: 10427] train loss: 0.137127, tar: 0.014091 
l0: 0.040148, l1: 0.041693, l2: 0.066895, l3: 0.061937, l4: 0.069878, l5: 0.070690, l6: 0.081305

[epoch: 111/100000, batch:   176/  187, ite: 10428] train loss: 0.137817, tar: 0.014152 
l0: 0.031310, l1: 0.035586, l2: 0.048482, l3: 0.052514, l4: 0.031800, l5: 0.026829, l6: 0.027903

[epoch: 111/100000, batch:   178/  187, ite: 10429] train loss: 0.138089, tar: 0.014192 
l0: 0.016501, l1: 0.017454, l2: 0.020769, l3: 0.020785, l4: 0.034153, l5: 0.029273, l6: 0.034293

[epoch: 111/100000, batch:   180/  187, ite: 10430] train loss: 0.138171, tar: 0.014197 
l0: 0.018881, l1: 0.018017, l2: 0.024093, l3: 0.029807, l4: 0.061815, l5: 0.059217, l6: 0.062128

[epoch: 111/100000, batch:   182/  187, ite: 10431] train loss: 0.138486, tar: 0.014208 
l0: 0.046169, l1: 0.040483, l2: 0.052449, l3: 0.081244, l4: 0.103027, l5: 0.102783, l6: 0.085759

[epoch: 111/100000, batch:   184/  187, ite: 10432] train loss: 0.139350, tar: 0.014282 
l0: 0.050107, l1: 0.047234, l2: 0.048966, l3: 0.069389, l4: 0.059627, l5: 0.059540, l6: 0.066945

[epoch: 111/100000, batch:   186/  187, ite: 10433] train loss: 0.139956, tar: 0.014365 
l0: 0.168025, l1: 0.160600, l2: 0.163418, l3: 0.245917, l4: 0.183972, l5: 0.209281, l6: 0.176893

[epoch: 111/100000, batch:   188/  187, ite: 10434] train loss: 0.142648, tar: 0.014719 
l0: 0.069344, l1: 0.062781, l2: 0.093434, l3: 0.122677, l4: 0.239206, l5: 0.206057, l6: 0.241513

[epoch: 112/100000, batch:     2/  187, ite: 10435] train loss: 0.144699, tar: 0.014844 
l0: 0.024877, l1: 0.021513, l2: 0.095950, l3: 0.079157, l4: 0.108211, l5: 0.075516, l6: 0.101813

[epoch: 112/100000, batch:     4/  187, ite: 10436] train loss: 0.145531, tar: 0.014868 
l0: 0.019040, l1: 0.016889, l2: 0.027409, l3: 0.027494, l4: 0.048745, l5: 0.044167, l6: 0.054471

[epoch: 112/100000, batch:     6/  187, ite: 10437] train loss: 0.145743, tar: 0.014877 
l0: 0.026438, l1: 0.028531, l2: 0.026844, l3: 0.022669, l4: 0.066720, l5: 0.068159, l6: 0.055058

[epoch: 112/100000, batch:     8/  187, ite: 10438] train loss: 0.146082, tar: 0.014903 
l0: 0.029366, l1: 0.029898, l2: 0.029807, l3: 0.049799, l4: 0.071953, l5: 0.071614, l6: 0.054122

[epoch: 112/100000, batch:    10/  187, ite: 10439] train loss: 0.146516, tar: 0.014936 
l0: 0.117997, l1: 0.139356, l2: 0.180043, l3: 0.125660, l4: 0.067734, l5: 0.079472, l6: 0.079452

[epoch: 112/100000, batch:    12/  187, ite: 10440] train loss: 0.147978, tar: 0.015171 
l0: 0.046245, l1: 0.053721, l2: 0.041290, l3: 0.069727, l4: 0.071830, l5: 0.053964, l6: 0.056062

[epoch: 112/100000, batch:    14/  187, ite: 10441] train loss: 0.148533, tar: 0.015241 
l0: 0.028321, l1: 0.031063, l2: 0.046229, l3: 0.044518, l4: 0.057313, l5: 0.051092, l6: 0.049707

[epoch: 112/100000, batch:    16/  187, ite: 10442] train loss: 0.148894, tar: 0.015271 
l0: 0.052535, l1: 0.056612, l2: 0.061310, l3: 0.092160, l4: 0.089484, l5: 0.068579, l6: 0.084179

[epoch: 112/100000, batch:    18/  187, ite: 10443] train loss: 0.149698, tar: 0.015355 
l0: 0.047898, l1: 0.058174, l2: 0.040488, l3: 0.049951, l4: 0.076194, l5: 0.058248, l6: 0.053294

[epoch: 112/100000, batch:    20/  187, ite: 10444] train loss: 0.150226, tar: 0.015428 
l0: 0.030289, l1: 0.030762, l2: 0.026677, l3: 0.032071, l4: 0.047394, l5: 0.036742, l6: 0.041965

[epoch: 112/100000, batch:    22/  187, ite: 10445] train loss: 0.150441, tar: 0.015461 
l0: 0.049683, l1: 0.052174, l2: 0.050164, l3: 0.060989, l4: 0.090117, l5: 0.074356, l6: 0.092626

[epoch: 112/100000, batch:    24/  187, ite: 10446] train loss: 0.151158, tar: 0.015538 
l0: 0.030978, l1: 0.030803, l2: 0.032886, l3: 0.037249, l4: 0.064279, l5: 0.055077, l6: 0.061378

[epoch: 112/100000, batch:    26/  187, ite: 10447] train loss: 0.151519, tar: 0.015573 
l0: 0.050916, l1: 0.052855, l2: 0.049381, l3: 0.050017, l4: 0.077687, l5: 0.071442, l6: 0.074995

[epoch: 112/100000, batch:    28/  187, ite: 10448] train loss: 0.152135, tar: 0.015652 
l0: 0.036724, l1: 0.034290, l2: 0.038746, l3: 0.046371, l4: 0.058875, l5: 0.046206, l6: 0.051370

[epoch: 112/100000, batch:    30/  187, ite: 10449] train loss: 0.152492, tar: 0.015699 
l0: 0.022531, l1: 0.023241, l2: 0.024563, l3: 0.033298, l4: 0.054806, l5: 0.039030, l6: 0.041105

[epoch: 112/100000, batch:    32/  187, ite: 10450] train loss: 0.152683, tar: 0.015714 
l0: 0.038443, l1: 0.036140, l2: 0.032690, l3: 0.045424, l4: 0.059564, l5: 0.055183, l6: 0.051748

[epoch: 112/100000, batch:    34/  187, ite: 10451] train loss: 0.153053, tar: 0.015764 
l0: 0.029666, l1: 0.030947, l2: 0.035126, l3: 0.040786, l4: 0.034298, l5: 0.025784, l6: 0.029832

[epoch: 112/100000, batch:    36/  187, ite: 10452] train loss: 0.153215, tar: 0.015795 
l0: 0.035895, l1: 0.039088, l2: 0.032982, l3: 0.042064, l4: 0.066956, l5: 0.055679, l6: 0.046848

[epoch: 112/100000, batch:    38/  187, ite: 10453] train loss: 0.153582, tar: 0.015839 
l0: 0.029303, l1: 0.026493, l2: 0.024854, l3: 0.042126, l4: 0.053845, l5: 0.047495, l6: 0.058181

[epoch: 112/100000, batch:    40/  187, ite: 10454] train loss: 0.153866, tar: 0.015869 
l0: 0.033448, l1: 0.032244, l2: 0.031699, l3: 0.039595, l4: 0.049545, l5: 0.039482, l6: 0.053818

[epoch: 112/100000, batch:    42/  187, ite: 10455] train loss: 0.154142, tar: 0.015908 
l0: 0.022481, l1: 0.020396, l2: 0.021676, l3: 0.020916, l4: 0.038514, l5: 0.033738, l6: 0.034762

[epoch: 112/100000, batch:    44/  187, ite: 10456] train loss: 0.154226, tar: 0.015922 
l0: 0.024463, l1: 0.019977, l2: 0.017357, l3: 0.026639, l4: 0.049916, l5: 0.045432, l6: 0.052661

[epoch: 112/100000, batch:    46/  187, ite: 10457] train loss: 0.154406, tar: 0.015941 
l0: 0.026021, l1: 0.024085, l2: 0.025632, l3: 0.031486, l4: 0.070446, l5: 0.057477, l6: 0.051764

[epoch: 112/100000, batch:    48/  187, ite: 10458] train loss: 0.154696, tar: 0.015963 
l0: 0.032961, l1: 0.027473, l2: 0.043877, l3: 0.047601, l4: 0.044392, l5: 0.057672, l6: 0.059891

[epoch: 112/100000, batch:    50/  187, ite: 10459] train loss: 0.155042, tar: 0.016000 
l0: 0.033512, l1: 0.033224, l2: 0.032616, l3: 0.044799, l4: 0.061200, l5: 0.053361, l6: 0.057827

[epoch: 112/100000, batch:    52/  187, ite: 10460] train loss: 0.155394, tar: 0.016038 
l0: 0.020941, l1: 0.021362, l2: 0.021709, l3: 0.028418, l4: 0.043469, l5: 0.033173, l6: 0.035890

[epoch: 112/100000, batch:    54/  187, ite: 10461] train loss: 0.155501, tar: 0.016048 
l0: 0.026230, l1: 0.026768, l2: 0.029912, l3: 0.033093, l4: 0.028683, l5: 0.028505, l6: 0.027004

[epoch: 112/100000, batch:    56/  187, ite: 10462] train loss: 0.155598, tar: 0.016070 
l0: 0.018440, l1: 0.018039, l2: 0.020884, l3: 0.020014, l4: 0.035080, l5: 0.029690, l6: 0.033020

[epoch: 112/100000, batch:    58/  187, ite: 10463] train loss: 0.155640, tar: 0.016076 
l0: 0.027876, l1: 0.027169, l2: 0.028985, l3: 0.034431, l4: 0.047773, l5: 0.040782, l6: 0.051307

[epoch: 112/100000, batch:    60/  187, ite: 10464] train loss: 0.155861, tar: 0.016101 
l0: 0.021638, l1: 0.021538, l2: 0.023860, l3: 0.028339, l4: 0.040729, l5: 0.033439, l6: 0.038577

[epoch: 112/100000, batch:    62/  187, ite: 10465] train loss: 0.155974, tar: 0.016113 
l0: 0.054557, l1: 0.065531, l2: 0.038880, l3: 0.054966, l4: 0.082408, l5: 0.079217, l6: 0.075863

[epoch: 112/100000, batch:    64/  187, ite: 10466] train loss: 0.156608, tar: 0.016195 
l0: 0.019854, l1: 0.018554, l2: 0.021640, l3: 0.028136, l4: 0.037278, l5: 0.038423, l6: 0.041772

[epoch: 112/100000, batch:    66/  187, ite: 10467] train loss: 0.156713, tar: 0.016203 
l0: 0.089943, l1: 0.106569, l2: 0.091491, l3: 0.098802, l4: 0.120932, l5: 0.118773, l6: 0.105833

[epoch: 112/100000, batch:    68/  187, ite: 10468] train loss: 0.157943, tar: 0.016361 
l0: 0.026321, l1: 0.036547, l2: 0.036407, l3: 0.032785, l4: 0.030031, l5: 0.031765, l6: 0.027030

[epoch: 112/100000, batch:    70/  187, ite: 10469] train loss: 0.158077, tar: 0.016382 
l0: 0.014023, l1: 0.014345, l2: 0.013218, l3: 0.012068, l4: 0.033996, l5: 0.031557, l6: 0.029404

[epoch: 112/100000, batch:    72/  187, ite: 10470] train loss: 0.158057, tar: 0.016377 
l0: 0.014433, l1: 0.013845, l2: 0.013517, l3: 0.015444, l4: 0.024283, l5: 0.023185, l6: 0.027597

[epoch: 112/100000, batch:    74/  187, ite: 10471] train loss: 0.158002, tar: 0.016373 
l0: 0.021053, l1: 0.023496, l2: 0.020618, l3: 0.020268, l4: 0.026900, l5: 0.020920, l6: 0.023760

[epoch: 112/100000, batch:    76/  187, ite: 10472] train loss: 0.158000, tar: 0.016383 
l0: 0.024666, l1: 0.024477, l2: 0.021704, l3: 0.025210, l4: 0.034936, l5: 0.036834, l6: 0.039373

[epoch: 112/100000, batch:    78/  187, ite: 10473] train loss: 0.158104, tar: 0.016400 
l0: 0.032706, l1: 0.039158, l2: 0.039451, l3: 0.032841, l4: 0.040753, l5: 0.042692, l6: 0.042979

[epoch: 112/100000, batch:    80/  187, ite: 10474] train loss: 0.158341, tar: 0.016435 
l0: 0.017716, l1: 0.018812, l2: 0.015919, l3: 0.022111, l4: 0.056771, l5: 0.044757, l6: 0.067563

[epoch: 112/100000, batch:    82/  187, ite: 10475] train loss: 0.158521, tar: 0.016437 
l0: 0.027498, l1: 0.028568, l2: 0.029592, l3: 0.029001, l4: 0.038145, l5: 0.038466, l6: 0.036849

[epoch: 112/100000, batch:    84/  187, ite: 10476] train loss: 0.158667, tar: 0.016461 
l0: 0.023565, l1: 0.025609, l2: 0.028877, l3: 0.037042, l4: 0.024384, l5: 0.022930, l6: 0.021827

[epoch: 112/100000, batch:    86/  187, ite: 10477] train loss: 0.158721, tar: 0.016476 
l0: 0.011773, l1: 0.011850, l2: 0.013264, l3: 0.013139, l4: 0.023665, l5: 0.019909, l6: 0.020259

[epoch: 112/100000, batch:    88/  187, ite: 10478] train loss: 0.158627, tar: 0.016466 
l0: 0.037932, l1: 0.031775, l2: 0.028620, l3: 0.047952, l4: 0.051990, l5: 0.059518, l6: 0.083348

[epoch: 112/100000, batch:    90/  187, ite: 10479] train loss: 0.159008, tar: 0.016511 
l0: 0.017886, l1: 0.016202, l2: 0.017023, l3: 0.025416, l4: 0.037443, l5: 0.037313, l6: 0.051974

[epoch: 112/100000, batch:    92/  187, ite: 10480] train loss: 0.159100, tar: 0.016513 
l0: 0.009121, l1: 0.010019, l2: 0.011756, l3: 0.012427, l4: 0.019832, l5: 0.020312, l6: 0.028814

[epoch: 112/100000, batch:    94/  187, ite: 10481] train loss: 0.159003, tar: 0.016498 
l0: 0.061329, l1: 0.064519, l2: 0.064199, l3: 0.054992, l4: 0.057032, l5: 0.075054, l6: 0.072836

[epoch: 112/100000, batch:    96/  187, ite: 10482] train loss: 0.159606, tar: 0.016591 
l0: 0.020558, l1: 0.020182, l2: 0.020932, l3: 0.022958, l4: 0.026016, l5: 0.031973, l6: 0.034764

[epoch: 112/100000, batch:    98/  187, ite: 10483] train loss: 0.159643, tar: 0.016599 
l0: 0.027299, l1: 0.027966, l2: 0.032749, l3: 0.035656, l4: 0.032545, l5: 0.032616, l6: 0.042017

[epoch: 112/100000, batch:   100/  187, ite: 10484] train loss: 0.159790, tar: 0.016621 
l0: 0.021742, l1: 0.024926, l2: 0.024326, l3: 0.023705, l4: 0.023112, l5: 0.022623, l6: 0.030505

[epoch: 112/100000, batch:   102/  187, ite: 10485] train loss: 0.159813, tar: 0.016632 
l0: 0.015467, l1: 0.016309, l2: 0.019540, l3: 0.022073, l4: 0.036467, l5: 0.032171, l6: 0.034684

[epoch: 112/100000, batch:   104/  187, ite: 10486] train loss: 0.159848, tar: 0.016630 
l0: 0.015663, l1: 0.016870, l2: 0.015284, l3: 0.019243, l4: 0.028612, l5: 0.026140, l6: 0.026803

[epoch: 112/100000, batch:   106/  187, ite: 10487] train loss: 0.159825, tar: 0.016628 
l0: 0.021049, l1: 0.025793, l2: 0.026916, l3: 0.023796, l4: 0.052307, l5: 0.046759, l6: 0.049232

[epoch: 112/100000, batch:   108/  187, ite: 10488] train loss: 0.160001, tar: 0.016637 
l0: 0.022091, l1: 0.021694, l2: 0.025803, l3: 0.029971, l4: 0.042236, l5: 0.036464, l6: 0.043765

[epoch: 112/100000, batch:   110/  187, ite: 10489] train loss: 0.160128, tar: 0.016648 
l0: 0.028593, l1: 0.025527, l2: 0.034895, l3: 0.046267, l4: 0.073318, l5: 0.077106, l6: 0.073542

[epoch: 112/100000, batch:   112/  187, ite: 10490] train loss: 0.160535, tar: 0.016672 
l0: 0.017076, l1: 0.014761, l2: 0.015493, l3: 0.024975, l4: 0.060330, l5: 0.058453, l6: 0.070636

[epoch: 112/100000, batch:   114/  187, ite: 10491] train loss: 0.160741, tar: 0.016673 
l0: 0.015888, l1: 0.015587, l2: 0.016706, l3: 0.017530, l4: 0.026303, l5: 0.021945, l6: 0.023870

[epoch: 112/100000, batch:   116/  187, ite: 10492] train loss: 0.160694, tar: 0.016671 
l0: 0.033460, l1: 0.032846, l2: 0.037529, l3: 0.043443, l4: 0.053588, l5: 0.054092, l6: 0.054129

[epoch: 112/100000, batch:   118/  187, ite: 10493] train loss: 0.160995, tar: 0.016705 
l0: 0.021108, l1: 0.019558, l2: 0.020999, l3: 0.024209, l4: 0.048138, l5: 0.044870, l6: 0.046067

[epoch: 112/100000, batch:   120/  187, ite: 10494] train loss: 0.161125, tar: 0.016714 
l0: 0.016017, l1: 0.018096, l2: 0.016754, l3: 0.020126, l4: 0.028034, l5: 0.025277, l6: 0.024224

[epoch: 112/100000, batch:   122/  187, ite: 10495] train loss: 0.161099, tar: 0.016713 
l0: 0.018094, l1: 0.017593, l2: 0.019404, l3: 0.025669, l4: 0.026581, l5: 0.023423, l6: 0.024651

[epoch: 112/100000, batch:   124/  187, ite: 10496] train loss: 0.161088, tar: 0.016716 
l0: 0.018197, l1: 0.020933, l2: 0.021328, l3: 0.020017, l4: 0.018667, l5: 0.017099, l6: 0.028786

[epoch: 112/100000, batch:   126/  187, ite: 10497] train loss: 0.161055, tar: 0.016719 
l0: 0.019900, l1: 0.022954, l2: 0.022810, l3: 0.019586, l4: 0.024096, l5: 0.025836, l6: 0.025525

[epoch: 112/100000, batch:   128/  187, ite: 10498] train loss: 0.161055, tar: 0.016725 
l0: 0.031550, l1: 0.027947, l2: 0.031671, l3: 0.037996, l4: 0.086046, l5: 0.075257, l6: 0.107996

[epoch: 112/100000, batch:   130/  187, ite: 10499] train loss: 0.161530, tar: 0.016755 
l0: 0.021850, l1: 0.022580, l2: 0.021235, l3: 0.031209, l4: 0.042496, l5: 0.039484, l6: 0.033116

[epoch: 112/100000, batch:   132/  187, ite: 10500] train loss: 0.161631, tar: 0.016765 
l0: 0.017258, l1: 0.018911, l2: 0.024842, l3: 0.027055, l4: 0.021869, l5: 0.023776, l6: 0.027146

[epoch: 112/100000, batch:   134/  187, ite: 10501] train loss: 0.161630, tar: 0.016766 
l0: 0.014045, l1: 0.013760, l2: 0.014929, l3: 0.020817, l4: 0.027622, l5: 0.026047, l6: 0.025119

[epoch: 112/100000, batch:   136/  187, ite: 10502] train loss: 0.161591, tar: 0.016761 
l0: 0.016858, l1: 0.018594, l2: 0.022835, l3: 0.020965, l4: 0.027894, l5: 0.021123, l6: 0.017528

[epoch: 112/100000, batch:   138/  187, ite: 10503] train loss: 0.161560, tar: 0.016761 
l0: 0.027226, l1: 0.029600, l2: 0.027770, l3: 0.025106, l4: 0.030984, l5: 0.031268, l6: 0.030406

[epoch: 112/100000, batch:   140/  187, ite: 10504] train loss: 0.161641, tar: 0.016781 
l0: 0.039490, l1: 0.042927, l2: 0.038181, l3: 0.037505, l4: 0.040486, l5: 0.035880, l6: 0.060016

[epoch: 112/100000, batch:   142/  187, ite: 10505] train loss: 0.161904, tar: 0.016826 
l0: 0.026484, l1: 0.027225, l2: 0.024430, l3: 0.024699, l4: 0.037025, l5: 0.042778, l6: 0.045057

[epoch: 112/100000, batch:   144/  187, ite: 10506] train loss: 0.162034, tar: 0.016846 
l0: 0.040439, l1: 0.048242, l2: 0.037592, l3: 0.030869, l4: 0.037950, l5: 0.036773, l6: 0.035513

[epoch: 112/100000, batch:   146/  187, ite: 10507] train loss: 0.162242, tar: 0.016892 
l0: 0.029148, l1: 0.029145, l2: 0.033058, l3: 0.030679, l4: 0.045488, l5: 0.045903, l6: 0.047415

[epoch: 112/100000, batch:   148/  187, ite: 10508] train loss: 0.162436, tar: 0.016916 
l0: 0.019261, l1: 0.018989, l2: 0.023796, l3: 0.027562, l4: 0.088417, l5: 0.095671, l6: 0.091565

[epoch: 112/100000, batch:   150/  187, ite: 10509] train loss: 0.162834, tar: 0.016921 
l0: 0.014482, l1: 0.013521, l2: 0.023586, l3: 0.027071, l4: 0.029308, l5: 0.026780, l6: 0.036298

[epoch: 112/100000, batch:   152/  187, ite: 10510] train loss: 0.162850, tar: 0.016916 
l0: 0.016048, l1: 0.014983, l2: 0.020380, l3: 0.031172, l4: 0.047412, l5: 0.043955, l6: 0.040412

[epoch: 112/100000, batch:   154/  187, ite: 10511] train loss: 0.162951, tar: 0.016914 
l0: 0.012627, l1: 0.012672, l2: 0.014572, l3: 0.014787, l4: 0.035170, l5: 0.036853, l6: 0.031858

[epoch: 112/100000, batch:   156/  187, ite: 10512] train loss: 0.162943, tar: 0.016906 
l0: 0.024259, l1: 0.025930, l2: 0.027626, l3: 0.033084, l4: 0.029129, l5: 0.027835, l6: 0.026865

[epoch: 112/100000, batch:   158/  187, ite: 10513] train loss: 0.163004, tar: 0.016920 
l0: 0.021796, l1: 0.022226, l2: 0.026849, l3: 0.029947, l4: 0.067547, l5: 0.048830, l6: 0.044052

[epoch: 112/100000, batch:   160/  187, ite: 10514] train loss: 0.163196, tar: 0.016930 
l0: 0.022626, l1: 0.022269, l2: 0.024013, l3: 0.025501, l4: 0.037601, l5: 0.038070, l6: 0.041625

[epoch: 112/100000, batch:   162/  187, ite: 10515] train loss: 0.163290, tar: 0.016941 
l0: 0.017029, l1: 0.018168, l2: 0.020858, l3: 0.018902, l4: 0.030214, l5: 0.029079, l6: 0.030517

[epoch: 112/100000, batch:   164/  187, ite: 10516] train loss: 0.163293, tar: 0.016941 
l0: 0.029626, l1: 0.028621, l2: 0.039850, l3: 0.046471, l4: 0.037637, l5: 0.031327, l6: 0.055165

[epoch: 112/100000, batch:   166/  187, ite: 10517] train loss: 0.163497, tar: 0.016966 
l0: 0.017421, l1: 0.019224, l2: 0.023922, l3: 0.027324, l4: 0.027488, l5: 0.023789, l6: 0.021449

[epoch: 112/100000, batch:   168/  187, ite: 10518] train loss: 0.163491, tar: 0.016966 
l0: 0.012976, l1: 0.012861, l2: 0.012804, l3: 0.016550, l4: 0.030653, l5: 0.025140, l6: 0.022562

[epoch: 112/100000, batch:   170/  187, ite: 10519] train loss: 0.163433, tar: 0.016959 
l0: 0.010060, l1: 0.010022, l2: 0.010772, l3: 0.013729, l4: 0.024907, l5: 0.020588, l6: 0.016980

[epoch: 112/100000, batch:   172/  187, ite: 10520] train loss: 0.163325, tar: 0.016945 
l0: 0.013833, l1: 0.013615, l2: 0.014517, l3: 0.014276, l4: 0.035560, l5: 0.038663, l6: 0.033690

[epoch: 112/100000, batch:   174/  187, ite: 10521] train loss: 0.163326, tar: 0.016940 
l0: 0.019355, l1: 0.020337, l2: 0.023878, l3: 0.021591, l4: 0.017018, l5: 0.016444, l6: 0.017259

[epoch: 112/100000, batch:   176/  187, ite: 10522] train loss: 0.163274, tar: 0.016944 
l0: 0.006856, l1: 0.006663, l2: 0.006922, l3: 0.007283, l4: 0.017006, l5: 0.013068, l6: 0.017176

[epoch: 112/100000, batch:   178/  187, ite: 10523] train loss: 0.163105, tar: 0.016925 
l0: 0.014415, l1: 0.015150, l2: 0.016092, l3: 0.015884, l4: 0.027928, l5: 0.019825, l6: 0.022853

[epoch: 112/100000, batch:   180/  187, ite: 10524] train loss: 0.163046, tar: 0.016920 
l0: 0.039886, l1: 0.047808, l2: 0.034229, l3: 0.031856, l4: 0.047771, l5: 0.042921, l6: 0.041538

[epoch: 112/100000, batch:   182/  187, ite: 10525] train loss: 0.163280, tar: 0.016964 
l0: 0.059444, l1: 0.072361, l2: 0.062087, l3: 0.060047, l4: 0.054233, l5: 0.044620, l6: 0.051412

[epoch: 112/100000, batch:   184/  187, ite: 10526] train loss: 0.163738, tar: 0.017045 
l0: 0.017587, l1: 0.018737, l2: 0.018355, l3: 0.019769, l4: 0.023709, l5: 0.016716, l6: 0.022522

[epoch: 112/100000, batch:   186/  187, ite: 10527] train loss: 0.163688, tar: 0.017046 
l0: 0.008887, l1: 0.008708, l2: 0.009586, l3: 0.010595, l4: 0.018933, l5: 0.015873, l6: 0.018285

[epoch: 112/100000, batch:   188/  187, ite: 10528] train loss: 0.163550, tar: 0.017030 
l0: 0.008050, l1: 0.008289, l2: 0.009494, l3: 0.008912, l4: 0.013049, l5: 0.010881, l6: 0.013917

[epoch: 113/100000, batch:     2/  187, ite: 10529] train loss: 0.163378, tar: 0.017013 
l0: 0.017174, l1: 0.018881, l2: 0.019415, l3: 0.020525, l4: 0.028600, l5: 0.021317, l6: 0.024026

[epoch: 113/100000, batch:     4/  187, ite: 10530] train loss: 0.163353, tar: 0.017013 
l0: 0.028080, l1: 0.026512, l2: 0.032611, l3: 0.032694, l4: 0.032313, l5: 0.032303, l6: 0.035658

[epoch: 113/100000, batch:     6/  187, ite: 10531] train loss: 0.163460, tar: 0.017034 
l0: 0.024240, l1: 0.029047, l2: 0.033961, l3: 0.037380, l4: 0.027881, l5: 0.025801, l6: 0.040838

[epoch: 113/100000, batch:     8/  187, ite: 10532] train loss: 0.163565, tar: 0.017048 
l0: 0.011942, l1: 0.012980, l2: 0.013636, l3: 0.017743, l4: 0.026266, l5: 0.030012, l6: 0.026719

[epoch: 113/100000, batch:    10/  187, ite: 10533] train loss: 0.163519, tar: 0.017038 
l0: 0.019914, l1: 0.029396, l2: 0.025599, l3: 0.020503, l4: 0.017515, l5: 0.015115, l6: 0.012363

[epoch: 113/100000, batch:    12/  187, ite: 10534] train loss: 0.163476, tar: 0.017044 
l0: 0.014019, l1: 0.014072, l2: 0.017589, l3: 0.015726, l4: 0.020646, l5: 0.018142, l6: 0.023383

[epoch: 113/100000, batch:    14/  187, ite: 10535] train loss: 0.163401, tar: 0.017038 
l0: 0.020130, l1: 0.020681, l2: 0.018643, l3: 0.021041, l4: 0.034467, l5: 0.036116, l6: 0.028648

[epoch: 113/100000, batch:    16/  187, ite: 10536] train loss: 0.163432, tar: 0.017044 
l0: 0.017821, l1: 0.018667, l2: 0.021096, l3: 0.019814, l4: 0.029825, l5: 0.026377, l6: 0.029692

[epoch: 113/100000, batch:    18/  187, ite: 10537] train loss: 0.163431, tar: 0.017045 
l0: 0.010049, l1: 0.010962, l2: 0.009458, l3: 0.010446, l4: 0.023511, l5: 0.021395, l6: 0.017086

[epoch: 113/100000, batch:    20/  187, ite: 10538] train loss: 0.163319, tar: 0.017032 
l0: 0.011042, l1: 0.012326, l2: 0.015148, l3: 0.012858, l4: 0.018220, l5: 0.014939, l6: 0.016203

[epoch: 113/100000, batch:    22/  187, ite: 10539] train loss: 0.163203, tar: 0.017021 
l0: 0.007185, l1: 0.007279, l2: 0.008674, l3: 0.010850, l4: 0.019406, l5: 0.011117, l6: 0.017010

[epoch: 113/100000, batch:    24/  187, ite: 10540] train loss: 0.163052, tar: 0.017003 
l0: 0.022401, l1: 0.023444, l2: 0.023863, l3: 0.025902, l4: 0.032912, l5: 0.029026, l6: 0.034751

[epoch: 113/100000, batch:    26/  187, ite: 10541] train loss: 0.163106, tar: 0.017013 
l0: 0.020965, l1: 0.023246, l2: 0.016721, l3: 0.017222, l4: 0.030802, l5: 0.030556, l6: 0.030363

[epoch: 113/100000, batch:    28/  187, ite: 10542] train loss: 0.163118, tar: 0.017020 
l0: 0.017385, l1: 0.018345, l2: 0.014903, l3: 0.015416, l4: 0.020787, l5: 0.019318, l6: 0.029523

[epoch: 113/100000, batch:    30/  187, ite: 10543] train loss: 0.163068, tar: 0.017021 
l0: 0.009516, l1: 0.010273, l2: 0.009411, l3: 0.010198, l4: 0.018481, l5: 0.012739, l6: 0.014409

[epoch: 113/100000, batch:    32/  187, ite: 10544] train loss: 0.162924, tar: 0.017007 
l0: 0.018214, l1: 0.022671, l2: 0.028858, l3: 0.017072, l4: 0.026673, l5: 0.024890, l6: 0.026571

[epoch: 113/100000, batch:    34/  187, ite: 10545] train loss: 0.162928, tar: 0.017009 
l0: 0.011443, l1: 0.011934, l2: 0.011512, l3: 0.013037, l4: 0.029572, l5: 0.029676, l6: 0.022927

[epoch: 113/100000, batch:    36/  187, ite: 10546] train loss: 0.162868, tar: 0.016999 
l0: 0.010893, l1: 0.010755, l2: 0.013228, l3: 0.015198, l4: 0.014740, l5: 0.017588, l6: 0.018211

[epoch: 113/100000, batch:    38/  187, ite: 10547] train loss: 0.162754, tar: 0.016988 
l0: 0.018148, l1: 0.021641, l2: 0.019733, l3: 0.021308, l4: 0.038230, l5: 0.036862, l6: 0.040487

[epoch: 113/100000, batch:    40/  187, ite: 10548] train loss: 0.162815, tar: 0.016990 
l0: 0.013986, l1: 0.013727, l2: 0.012654, l3: 0.016151, l4: 0.024329, l5: 0.024329, l6: 0.026110

[epoch: 113/100000, batch:    42/  187, ite: 10549] train loss: 0.162758, tar: 0.016985 
l0: 0.014739, l1: 0.014438, l2: 0.018472, l3: 0.021063, l4: 0.030755, l5: 0.034111, l6: 0.020925

[epoch: 113/100000, batch:    44/  187, ite: 10550] train loss: 0.162743, tar: 0.016980 
l0: 0.052805, l1: 0.051644, l2: 0.059166, l3: 0.048921, l4: 0.095925, l5: 0.085291, l6: 0.095679

[epoch: 113/100000, batch:    46/  187, ite: 10551] train loss: 0.163336, tar: 0.017045 
l0: 0.023683, l1: 0.025244, l2: 0.017583, l3: 0.019087, l4: 0.031172, l5: 0.028853, l6: 0.044464

[epoch: 113/100000, batch:    48/  187, ite: 10552] train loss: 0.163384, tar: 0.017057 
l0: 0.015848, l1: 0.014657, l2: 0.018579, l3: 0.019319, l4: 0.038753, l5: 0.035077, l6: 0.028349

[epoch: 113/100000, batch:    50/  187, ite: 10553] train loss: 0.163397, tar: 0.017055 
l0: 0.019041, l1: 0.021612, l2: 0.021059, l3: 0.020512, l4: 0.024637, l5: 0.022096, l6: 0.021569

[epoch: 113/100000, batch:    52/  187, ite: 10554] train loss: 0.163374, tar: 0.017059 
l0: 0.010354, l1: 0.013779, l2: 0.013300, l3: 0.013418, l4: 0.025259, l5: 0.022385, l6: 0.020556

[epoch: 113/100000, batch:    54/  187, ite: 10555] train loss: 0.163294, tar: 0.017047 
l0: 0.017576, l1: 0.017026, l2: 0.017993, l3: 0.020635, l4: 0.042080, l5: 0.036839, l6: 0.032096

[epoch: 113/100000, batch:    56/  187, ite: 10556] train loss: 0.163332, tar: 0.017048 
l0: 0.014302, l1: 0.014088, l2: 0.018521, l3: 0.022469, l4: 0.024490, l5: 0.018877, l6: 0.026064

[epoch: 113/100000, batch:    58/  187, ite: 10557] train loss: 0.163288, tar: 0.017043 
l0: 0.007999, l1: 0.008794, l2: 0.008626, l3: 0.008521, l4: 0.013546, l5: 0.012319, l6: 0.008920

[epoch: 113/100000, batch:    60/  187, ite: 10558] train loss: 0.163118, tar: 0.017027 
l0: 0.011776, l1: 0.012081, l2: 0.011613, l3: 0.013223, l4: 0.026113, l5: 0.022529, l6: 0.021740

[epoch: 113/100000, batch:    62/  187, ite: 10559] train loss: 0.163040, tar: 0.017017 
l0: 0.036351, l1: 0.035271, l2: 0.037940, l3: 0.039411, l4: 0.059363, l5: 0.100061, l6: 0.038768

[epoch: 113/100000, batch:    64/  187, ite: 10560] train loss: 0.163368, tar: 0.017052 
l0: 0.011873, l1: 0.011598, l2: 0.011713, l3: 0.014692, l4: 0.019505, l5: 0.019674, l6: 0.018603

[epoch: 113/100000, batch:    66/  187, ite: 10561] train loss: 0.163269, tar: 0.017043 
l0: 0.010765, l1: 0.011255, l2: 0.010786, l3: 0.010957, l4: 0.021823, l5: 0.021738, l6: 0.022620

[epoch: 113/100000, batch:    68/  187, ite: 10562] train loss: 0.163174, tar: 0.017031 
l0: 0.032042, l1: 0.033301, l2: 0.036115, l3: 0.034668, l4: 0.046745, l5: 0.053983, l6: 0.051646

[epoch: 113/100000, batch:    70/  187, ite: 10563] train loss: 0.163397, tar: 0.017058 
l0: 0.007503, l1: 0.008286, l2: 0.007512, l3: 0.007592, l4: 0.017378, l5: 0.013789, l6: 0.020730

[epoch: 113/100000, batch:    72/  187, ite: 10564] train loss: 0.163254, tar: 0.017041 
l0: 0.014403, l1: 0.015309, l2: 0.015841, l3: 0.019018, l4: 0.045434, l5: 0.048470, l6: 0.034567

[epoch: 113/100000, batch:    74/  187, ite: 10565] train loss: 0.163307, tar: 0.017036 
l0: 0.009858, l1: 0.011536, l2: 0.010667, l3: 0.010220, l4: 0.022329, l5: 0.019063, l6: 0.023258

[epoch: 113/100000, batch:    76/  187, ite: 10566] train loss: 0.163207, tar: 0.017024 
l0: 0.015442, l1: 0.019157, l2: 0.016066, l3: 0.015843, l4: 0.021668, l5: 0.014927, l6: 0.018205

[epoch: 113/100000, batch:    78/  187, ite: 10567] train loss: 0.163133, tar: 0.017021 
l0: 0.013032, l1: 0.012667, l2: 0.012275, l3: 0.012989, l4: 0.030271, l5: 0.026095, l6: 0.032522

[epoch: 113/100000, batch:    80/  187, ite: 10568] train loss: 0.163092, tar: 0.017014 
l0: 0.020342, l1: 0.020862, l2: 0.020642, l3: 0.022611, l4: 0.029413, l5: 0.030088, l6: 0.028641

[epoch: 113/100000, batch:    82/  187, ite: 10569] train loss: 0.163109, tar: 0.017020 
l0: 0.012163, l1: 0.012588, l2: 0.012307, l3: 0.012994, l4: 0.020280, l5: 0.016136, l6: 0.021820

[epoch: 113/100000, batch:    84/  187, ite: 10570] train loss: 0.163013, tar: 0.017011 
l0: 0.012287, l1: 0.012849, l2: 0.013509, l3: 0.013770, l4: 0.027200, l5: 0.023167, l6: 0.024394

[epoch: 113/100000, batch:    86/  187, ite: 10571] train loss: 0.162950, tar: 0.017003 
l0: 0.016469, l1: 0.017292, l2: 0.019487, l3: 0.018682, l4: 0.025844, l5: 0.020853, l6: 0.022165

[epoch: 113/100000, batch:    88/  187, ite: 10572] train loss: 0.162911, tar: 0.017002 
l0: 0.014187, l1: 0.014222, l2: 0.015115, l3: 0.017456, l4: 0.030682, l5: 0.024318, l6: 0.024582

[epoch: 113/100000, batch:    90/  187, ite: 10573] train loss: 0.162872, tar: 0.016997 
l0: 0.018624, l1: 0.018985, l2: 0.018235, l3: 0.017662, l4: 0.022728, l5: 0.021390, l6: 0.024052

[epoch: 113/100000, batch:    92/  187, ite: 10574] train loss: 0.162835, tar: 0.017000 
l0: 0.018257, l1: 0.018139, l2: 0.020083, l3: 0.022659, l4: 0.035418, l5: 0.034844, l6: 0.034969

[epoch: 113/100000, batch:    94/  187, ite: 10575] train loss: 0.162873, tar: 0.017002 
l0: 0.027581, l1: 0.031159, l2: 0.033568, l3: 0.034619, l4: 0.037663, l5: 0.033016, l6: 0.027476

[epoch: 113/100000, batch:    96/  187, ite: 10576] train loss: 0.162981, tar: 0.017020 
l0: 0.010094, l1: 0.011417, l2: 0.010058, l3: 0.009350, l4: 0.012942, l5: 0.011645, l6: 0.010666

[epoch: 113/100000, batch:    98/  187, ite: 10577] train loss: 0.162830, tar: 0.017008 
l0: 0.018429, l1: 0.017316, l2: 0.021215, l3: 0.022514, l4: 0.035765, l5: 0.031369, l6: 0.029781

[epoch: 113/100000, batch:   100/  187, ite: 10578] train loss: 0.162854, tar: 0.017011 
l0: 0.009301, l1: 0.010123, l2: 0.007179, l3: 0.009404, l4: 0.029000, l5: 0.022918, l6: 0.028762

[epoch: 113/100000, batch:   102/  187, ite: 10579] train loss: 0.162774, tar: 0.016998 
l0: 0.008670, l1: 0.009054, l2: 0.010938, l3: 0.013090, l4: 0.023727, l5: 0.020172, l6: 0.025364

[epoch: 113/100000, batch:   104/  187, ite: 10580] train loss: 0.162685, tar: 0.016983 
l0: 0.012293, l1: 0.012498, l2: 0.011772, l3: 0.013518, l4: 0.019862, l5: 0.018905, l6: 0.018512

[epoch: 113/100000, batch:   106/  187, ite: 10581] train loss: 0.162590, tar: 0.016975 
l0: 0.015725, l1: 0.016520, l2: 0.018303, l3: 0.016443, l4: 0.026909, l5: 0.025133, l6: 0.025234

[epoch: 113/100000, batch:   108/  187, ite: 10582] train loss: 0.162558, tar: 0.016973 
l0: 0.007476, l1: 0.008181, l2: 0.007583, l3: 0.006534, l4: 0.016378, l5: 0.012932, l6: 0.016858

[epoch: 113/100000, batch:   110/  187, ite: 10583] train loss: 0.162409, tar: 0.016957 
l0: 0.014313, l1: 0.013097, l2: 0.013801, l3: 0.016681, l4: 0.028306, l5: 0.030068, l6: 0.033772

[epoch: 113/100000, batch:   112/  187, ite: 10584] train loss: 0.162388, tar: 0.016952 
l0: 0.020990, l1: 0.022178, l2: 0.021959, l3: 0.019327, l4: 0.038321, l5: 0.042566, l6: 0.038087

[epoch: 113/100000, batch:   114/  187, ite: 10585] train loss: 0.162458, tar: 0.016959 
l0: 0.008151, l1: 0.007254, l2: 0.010101, l3: 0.011982, l4: 0.019347, l5: 0.018236, l6: 0.018716

[epoch: 113/100000, batch:   116/  187, ite: 10586] train loss: 0.162341, tar: 0.016944 
l0: 0.016332, l1: 0.015785, l2: 0.021943, l3: 0.022037, l4: 0.028474, l5: 0.027080, l6: 0.028480

[epoch: 113/100000, batch:   118/  187, ite: 10587] train loss: 0.162337, tar: 0.016943 
l0: 0.010536, l1: 0.011095, l2: 0.011607, l3: 0.012396, l4: 0.016969, l5: 0.016266, l6: 0.018497

[epoch: 113/100000, batch:   120/  187, ite: 10588] train loss: 0.162227, tar: 0.016932 
l0: 0.018697, l1: 0.021056, l2: 0.022247, l3: 0.023107, l4: 0.028691, l5: 0.023601, l6: 0.022699

[epoch: 113/100000, batch:   122/  187, ite: 10589] train loss: 0.162223, tar: 0.016935 
l0: 0.015681, l1: 0.018080, l2: 0.022067, l3: 0.020449, l4: 0.023360, l5: 0.026191, l6: 0.025372

[epoch: 113/100000, batch:   124/  187, ite: 10590] train loss: 0.162205, tar: 0.016933 
l0: 0.010432, l1: 0.010360, l2: 0.012732, l3: 0.013955, l4: 0.018593, l5: 0.018759, l6: 0.021724

[epoch: 113/100000, batch:   126/  187, ite: 10591] train loss: 0.162111, tar: 0.016922 
l0: 0.012891, l1: 0.012786, l2: 0.017335, l3: 0.017515, l4: 0.020173, l5: 0.022154, l6: 0.019877

[epoch: 113/100000, batch:   128/  187, ite: 10592] train loss: 0.162044, tar: 0.016915 
l0: 0.015149, l1: 0.014858, l2: 0.015637, l3: 0.017760, l4: 0.028767, l5: 0.027837, l6: 0.027458

[epoch: 113/100000, batch:   130/  187, ite: 10593] train loss: 0.162019, tar: 0.016912 
l0: 0.012486, l1: 0.012480, l2: 0.013081, l3: 0.014903, l4: 0.019442, l5: 0.017890, l6: 0.019898

[epoch: 113/100000, batch:   132/  187, ite: 10594] train loss: 0.161932, tar: 0.016905 
l0: 0.010146, l1: 0.010917, l2: 0.010296, l3: 0.010199, l4: 0.017745, l5: 0.014102, l6: 0.014933

[epoch: 113/100000, batch:   134/  187, ite: 10595] train loss: 0.161808, tar: 0.016893 
l0: 0.019016, l1: 0.018448, l2: 0.026253, l3: 0.028600, l4: 0.020205, l5: 0.018249, l6: 0.018868

[epoch: 113/100000, batch:   136/  187, ite: 10596] train loss: 0.161788, tar: 0.016897 
l0: 0.008410, l1: 0.013561, l2: 0.012987, l3: 0.008079, l4: 0.019756, l5: 0.017730, l6: 0.014498

[epoch: 113/100000, batch:   138/  187, ite: 10597] train loss: 0.161676, tar: 0.016883 
l0: 0.011117, l1: 0.010392, l2: 0.012917, l3: 0.012040, l4: 0.018200, l5: 0.016723, l6: 0.021873

[epoch: 113/100000, batch:   140/  187, ite: 10598] train loss: 0.161579, tar: 0.016873 
l0: 0.010351, l1: 0.010254, l2: 0.010132, l3: 0.011591, l4: 0.012589, l5: 0.012892, l6: 0.014793

[epoch: 113/100000, batch:   142/  187, ite: 10599] train loss: 0.161447, tar: 0.016862 
l0: 0.010560, l1: 0.011176, l2: 0.014163, l3: 0.015106, l4: 0.018515, l5: 0.017918, l6: 0.016368

[epoch: 113/100000, batch:   144/  187, ite: 10600] train loss: 0.161351, tar: 0.016852 
l0: 0.010823, l1: 0.010058, l2: 0.010164, l3: 0.013839, l4: 0.032981, l5: 0.026511, l6: 0.028792

[epoch: 113/100000, batch:   146/  187, ite: 10601] train loss: 0.161304, tar: 0.016842 
l0: 0.008342, l1: 0.009056, l2: 0.005125, l3: 0.006884, l4: 0.016535, l5: 0.014912, l6: 0.012730

[epoch: 113/100000, batch:   148/  187, ite: 10602] train loss: 0.161158, tar: 0.016828 
l0: 0.008422, l1: 0.009775, l2: 0.013846, l3: 0.011870, l4: 0.015260, l5: 0.013068, l6: 0.013917

[epoch: 113/100000, batch:   150/  187, ite: 10603] train loss: 0.161034, tar: 0.016814 
l0: 0.009926, l1: 0.008719, l2: 0.007620, l3: 0.014512, l4: 0.018890, l5: 0.017602, l6: 0.029475

[epoch: 113/100000, batch:   152/  187, ite: 10604] train loss: 0.160944, tar: 0.016802 
l0: 0.008746, l1: 0.009235, l2: 0.009420, l3: 0.011798, l4: 0.016392, l5: 0.013958, l6: 0.015043

[epoch: 113/100000, batch:   154/  187, ite: 10605] train loss: 0.160818, tar: 0.016789 
l0: 0.011591, l1: 0.011753, l2: 0.013234, l3: 0.014085, l4: 0.012944, l5: 0.012415, l6: 0.013118

[epoch: 113/100000, batch:   156/  187, ite: 10606] train loss: 0.160699, tar: 0.016780 
l0: 0.007359, l1: 0.007453, l2: 0.007261, l3: 0.007919, l4: 0.017193, l5: 0.012960, l6: 0.013338

[epoch: 113/100000, batch:   158/  187, ite: 10607] train loss: 0.160556, tar: 0.016765 
l0: 0.012510, l1: 0.013285, l2: 0.014081, l3: 0.012563, l4: 0.026294, l5: 0.024458, l6: 0.025768

[epoch: 113/100000, batch:   160/  187, ite: 10608] train loss: 0.160504, tar: 0.016758 
l0: 0.009258, l1: 0.008871, l2: 0.012097, l3: 0.013037, l4: 0.018819, l5: 0.018034, l6: 0.016588

[epoch: 113/100000, batch:   162/  187, ite: 10609] train loss: 0.160399, tar: 0.016746 
l0: 0.011925, l1: 0.012770, l2: 0.013886, l3: 0.017641, l4: 0.016767, l5: 0.014387, l6: 0.012842

[epoch: 113/100000, batch:   164/  187, ite: 10610] train loss: 0.160300, tar: 0.016738 
l0: 0.007264, l1: 0.007612, l2: 0.006841, l3: 0.007335, l4: 0.015762, l5: 0.011161, l6: 0.015349

[epoch: 113/100000, batch:   166/  187, ite: 10611] train loss: 0.160155, tar: 0.016722 
l0: 0.006126, l1: 0.006681, l2: 0.005979, l3: 0.008748, l4: 0.011308, l5: 0.010208, l6: 0.009070

[epoch: 113/100000, batch:   168/  187, ite: 10612] train loss: 0.159988, tar: 0.016705 
l0: 0.008338, l1: 0.007715, l2: 0.007298, l3: 0.010522, l4: 0.017456, l5: 0.019268, l6: 0.018178

[epoch: 113/100000, batch:   170/  187, ite: 10613] train loss: 0.159872, tar: 0.016691 
l0: 0.007892, l1: 0.008181, l2: 0.008987, l3: 0.009019, l4: 0.015145, l5: 0.013236, l6: 0.018039

[epoch: 113/100000, batch:   172/  187, ite: 10614] train loss: 0.159742, tar: 0.016677 
l0: 0.011709, l1: 0.012060, l2: 0.011337, l3: 0.010847, l4: 0.020158, l5: 0.019562, l6: 0.023634

[epoch: 113/100000, batch:   174/  187, ite: 10615] train loss: 0.159660, tar: 0.016669 
l0: 0.009160, l1: 0.009818, l2: 0.012554, l3: 0.012024, l4: 0.012192, l5: 0.010235, l6: 0.010551

[epoch: 113/100000, batch:   176/  187, ite: 10616] train loss: 0.159525, tar: 0.016657 
l0: 0.010292, l1: 0.011553, l2: 0.010383, l3: 0.009890, l4: 0.013789, l5: 0.010847, l6: 0.012665

[epoch: 113/100000, batch:   178/  187, ite: 10617] train loss: 0.159396, tar: 0.016646 
l0: 0.016526, l1: 0.018975, l2: 0.015626, l3: 0.013070, l4: 0.016023, l5: 0.015775, l6: 0.019775

[epoch: 113/100000, batch:   180/  187, ite: 10618] train loss: 0.159325, tar: 0.016646 
l0: 0.007271, l1: 0.007065, l2: 0.015201, l3: 0.012248, l4: 0.026849, l5: 0.020856, l6: 0.015466

[epoch: 113/100000, batch:   182/  187, ite: 10619] train loss: 0.159237, tar: 0.016631 
l0: 0.011331, l1: 0.010565, l2: 0.010827, l3: 0.012473, l4: 0.020130, l5: 0.021678, l6: 0.021378

[epoch: 113/100000, batch:   184/  187, ite: 10620] train loss: 0.159155, tar: 0.016622 
l0: 0.011972, l1: 0.012056, l2: 0.013818, l3: 0.014729, l4: 0.026665, l5: 0.026298, l6: 0.024622

[epoch: 113/100000, batch:   186/  187, ite: 10621] train loss: 0.159108, tar: 0.016615 
l0: 0.005920, l1: 0.006057, l2: 0.007553, l3: 0.008013, l4: 0.010140, l5: 0.011450, l6: 0.014211

[epoch: 113/100000, batch:   188/  187, ite: 10622] train loss: 0.158955, tar: 0.016598 
l0: 0.009661, l1: 0.009383, l2: 0.012332, l3: 0.013456, l4: 0.024151, l5: 0.023668, l6: 0.027126

[epoch: 114/100000, batch:     2/  187, ite: 10623] train loss: 0.158892, tar: 0.016587 
l0: 0.009638, l1: 0.009457, l2: 0.010542, l3: 0.011183, l4: 0.016879, l5: 0.015103, l6: 0.017029

[epoch: 114/100000, batch:     4/  187, ite: 10624] train loss: 0.158781, tar: 0.016575 
l0: 0.011952, l1: 0.013073, l2: 0.011877, l3: 0.008992, l4: 0.013780, l5: 0.013273, l6: 0.012130

[epoch: 114/100000, batch:     6/  187, ite: 10625] train loss: 0.158663, tar: 0.016568 
l0: 0.010934, l1: 0.011762, l2: 0.014056, l3: 0.014517, l4: 0.012958, l5: 0.012447, l6: 0.010896

[epoch: 114/100000, batch:     8/  187, ite: 10626] train loss: 0.158549, tar: 0.016559 
l0: 0.009657, l1: 0.010471, l2: 0.009612, l3: 0.011499, l4: 0.027087, l5: 0.023917, l6: 0.022055

[epoch: 114/100000, batch:    10/  187, ite: 10627] train loss: 0.158479, tar: 0.016548 
l0: 0.010216, l1: 0.011077, l2: 0.011316, l3: 0.012021, l4: 0.021349, l5: 0.019806, l6: 0.022008

[epoch: 114/100000, batch:    12/  187, ite: 10628] train loss: 0.158398, tar: 0.016538 
l0: 0.006541, l1: 0.006541, l2: 0.006439, l3: 0.006530, l4: 0.013493, l5: 0.011261, l6: 0.014104

[epoch: 114/100000, batch:    14/  187, ite: 10629] train loss: 0.158250, tar: 0.016522 
l0: 0.011185, l1: 0.010947, l2: 0.011622, l3: 0.012979, l4: 0.020986, l5: 0.018246, l6: 0.023465

[epoch: 114/100000, batch:    16/  187, ite: 10630] train loss: 0.158172, tar: 0.016514 
l0: 0.012224, l1: 0.013500, l2: 0.014158, l3: 0.015134, l4: 0.016839, l5: 0.013004, l6: 0.014102

[epoch: 114/100000, batch:    18/  187, ite: 10631] train loss: 0.158078, tar: 0.016507 
l0: 0.007435, l1: 0.007753, l2: 0.008315, l3: 0.007398, l4: 0.009707, l5: 0.008896, l6: 0.009111

[epoch: 114/100000, batch:    20/  187, ite: 10632] train loss: 0.157921, tar: 0.016492 
l0: 0.010224, l1: 0.010853, l2: 0.011374, l3: 0.010567, l4: 0.016453, l5: 0.015824, l6: 0.015061

[epoch: 114/100000, batch:    22/  187, ite: 10633] train loss: 0.157814, tar: 0.016483 
l0: 0.014007, l1: 0.014306, l2: 0.017546, l3: 0.017794, l4: 0.027721, l5: 0.026589, l6: 0.025961

[epoch: 114/100000, batch:    24/  187, ite: 10634] train loss: 0.157792, tar: 0.016479 
l0: 0.009670, l1: 0.009711, l2: 0.012036, l3: 0.011606, l4: 0.015442, l5: 0.015772, l6: 0.016244

[epoch: 114/100000, batch:    26/  187, ite: 10635] train loss: 0.157686, tar: 0.016468 
l0: 0.014120, l1: 0.015900, l2: 0.013945, l3: 0.014585, l4: 0.014998, l5: 0.013479, l6: 0.015151

[epoch: 114/100000, batch:    28/  187, ite: 10636] train loss: 0.157599, tar: 0.016464 
l0: 0.018099, l1: 0.018159, l2: 0.022091, l3: 0.022938, l4: 0.028854, l5: 0.023431, l6: 0.030332

[epoch: 114/100000, batch:    30/  187, ite: 10637] train loss: 0.157609, tar: 0.016467 
l0: 0.008840, l1: 0.009273, l2: 0.009351, l3: 0.009243, l4: 0.019828, l5: 0.017187, l6: 0.016373

[epoch: 114/100000, batch:    32/  187, ite: 10638] train loss: 0.157503, tar: 0.016455 
l0: 0.014191, l1: 0.014258, l2: 0.016183, l3: 0.014899, l4: 0.015871, l5: 0.017964, l6: 0.019826

[epoch: 114/100000, batch:    34/  187, ite: 10639] train loss: 0.157434, tar: 0.016451 
l0: 0.004206, l1: 0.005352, l2: 0.007389, l3: 0.006243, l4: 0.007961, l5: 0.010212, l6: 0.008774

[epoch: 114/100000, batch:    36/  187, ite: 10640] train loss: 0.157266, tar: 0.016432 
l0: 0.007031, l1: 0.007677, l2: 0.008804, l3: 0.009365, l4: 0.009804, l5: 0.008754, l6: 0.010155

[epoch: 114/100000, batch:    38/  187, ite: 10641] train loss: 0.157117, tar: 0.016417 
l0: 0.008384, l1: 0.009779, l2: 0.009702, l3: 0.008116, l4: 0.013790, l5: 0.012392, l6: 0.014079

[epoch: 114/100000, batch:    40/  187, ite: 10642] train loss: 0.156991, tar: 0.016405 
l0: 0.008943, l1: 0.010113, l2: 0.011345, l3: 0.013214, l4: 0.014805, l5: 0.008464, l6: 0.009974

[epoch: 114/100000, batch:    42/  187, ite: 10643] train loss: 0.156866, tar: 0.016393 
l0: 0.008599, l1: 0.008964, l2: 0.009984, l3: 0.010886, l4: 0.019134, l5: 0.017630, l6: 0.016291

[epoch: 114/100000, batch:    44/  187, ite: 10644] train loss: 0.156765, tar: 0.016381 
l0: 0.015012, l1: 0.016642, l2: 0.015062, l3: 0.014884, l4: 0.019889, l5: 0.016839, l6: 0.021216

[epoch: 114/100000, batch:    46/  187, ite: 10645] train loss: 0.156707, tar: 0.016379 
l0: 0.021514, l1: 0.020591, l2: 0.023603, l3: 0.026802, l4: 0.024016, l5: 0.025467, l6: 0.023525

[epoch: 114/100000, batch:    48/  187, ite: 10646] train loss: 0.156721, tar: 0.016387 
l0: 0.009205, l1: 0.010177, l2: 0.012081, l3: 0.012043, l4: 0.018580, l5: 0.017156, l6: 0.019740

[epoch: 114/100000, batch:    50/  187, ite: 10647] train loss: 0.156631, tar: 0.016376 
l0: 0.005101, l1: 0.005379, l2: 0.005969, l3: 0.005849, l4: 0.007689, l5: 0.008680, l6: 0.008826

[epoch: 114/100000, batch:    52/  187, ite: 10648] train loss: 0.156463, tar: 0.016359 
l0: 0.011344, l1: 0.011130, l2: 0.011329, l3: 0.012435, l4: 0.019569, l5: 0.018142, l6: 0.022002

[epoch: 114/100000, batch:    54/  187, ite: 10649] train loss: 0.156385, tar: 0.016351 
l0: 0.005766, l1: 0.006414, l2: 0.006952, l3: 0.006022, l4: 0.009913, l5: 0.009302, l6: 0.010251

[epoch: 114/100000, batch:    56/  187, ite: 10650] train loss: 0.156228, tar: 0.016335 
l0: 0.006077, l1: 0.005890, l2: 0.006813, l3: 0.007147, l4: 0.009666, l5: 0.011684, l6: 0.013626

[epoch: 114/100000, batch:    58/  187, ite: 10651] train loss: 0.156082, tar: 0.016319 
l0: 0.006858, l1: 0.007702, l2: 0.006968, l3: 0.007778, l4: 0.014752, l5: 0.010158, l6: 0.008514

[epoch: 114/100000, batch:    60/  187, ite: 10652] train loss: 0.155939, tar: 0.016304 
l0: 0.012228, l1: 0.011306, l2: 0.013702, l3: 0.014359, l4: 0.021913, l5: 0.024601, l6: 0.024557

[epoch: 114/100000, batch:    62/  187, ite: 10653] train loss: 0.155888, tar: 0.016298 
l0: 0.013049, l1: 0.014110, l2: 0.013465, l3: 0.015393, l4: 0.021343, l5: 0.018113, l6: 0.018617

[epoch: 114/100000, batch:    64/  187, ite: 10654] train loss: 0.155824, tar: 0.016293 
l0: 0.009742, l1: 0.009943, l2: 0.012906, l3: 0.015864, l4: 0.018152, l5: 0.018502, l6: 0.015673

[epoch: 114/100000, batch:    66/  187, ite: 10655] train loss: 0.155740, tar: 0.016283 
l0: 0.006839, l1: 0.007099, l2: 0.007691, l3: 0.006799, l4: 0.009741, l5: 0.010323, l6: 0.010993

[epoch: 114/100000, batch:    68/  187, ite: 10656] train loss: 0.155593, tar: 0.016269 
l0: 0.009195, l1: 0.009480, l2: 0.010626, l3: 0.012393, l4: 0.017038, l5: 0.013971, l6: 0.018763

[epoch: 114/100000, batch:    70/  187, ite: 10657] train loss: 0.155496, tar: 0.016258 
l0: 0.008803, l1: 0.008782, l2: 0.009194, l3: 0.011727, l4: 0.021619, l5: 0.019413, l6: 0.019299

[epoch: 114/100000, batch:    72/  187, ite: 10658] train loss: 0.155410, tar: 0.016247 
l0: 0.005821, l1: 0.007048, l2: 0.006594, l3: 0.006077, l4: 0.011537, l5: 0.009456, l6: 0.010409

[epoch: 114/100000, batch:    74/  187, ite: 10659] train loss: 0.155260, tar: 0.016231 
l0: 0.008045, l1: 0.008080, l2: 0.008675, l3: 0.009169, l4: 0.017013, l5: 0.018850, l6: 0.018103

[epoch: 114/100000, batch:    76/  187, ite: 10660] train loss: 0.155158, tar: 0.016218 
l0: 0.009438, l1: 0.009621, l2: 0.009930, l3: 0.009810, l4: 0.012465, l5: 0.011203, l6: 0.012483

[epoch: 114/100000, batch:    78/  187, ite: 10661] train loss: 0.155037, tar: 0.016208 
l0: 0.010788, l1: 0.011855, l2: 0.008386, l3: 0.011370, l4: 0.045455, l5: 0.033010, l6: 0.023399

[epoch: 114/100000, batch:    80/  187, ite: 10662] train loss: 0.155020, tar: 0.016200 
l0: 0.009591, l1: 0.008432, l2: 0.011023, l3: 0.013272, l4: 0.031232, l5: 0.026168, l6: 0.022521

[epoch: 114/100000, batch:    82/  187, ite: 10663] train loss: 0.154971, tar: 0.016190 
l0: 0.013304, l1: 0.012583, l2: 0.014054, l3: 0.016115, l4: 0.019373, l5: 0.018106, l6: 0.021100

[epoch: 114/100000, batch:    84/  187, ite: 10664] train loss: 0.154910, tar: 0.016186 
l0: 0.008068, l1: 0.006864, l2: 0.008940, l3: 0.012227, l4: 0.023915, l5: 0.022207, l6: 0.021558

[epoch: 114/100000, batch:    86/  187, ite: 10665] train loss: 0.154833, tar: 0.016173 
l0: 0.009450, l1: 0.008624, l2: 0.014424, l3: 0.016759, l4: 0.018588, l5: 0.019324, l6: 0.016560

[epoch: 114/100000, batch:    88/  187, ite: 10666] train loss: 0.154757, tar: 0.016163 
l0: 0.005465, l1: 0.005765, l2: 0.007168, l3: 0.007230, l4: 0.015918, l5: 0.011531, l6: 0.012205

[epoch: 114/100000, batch:    90/  187, ite: 10667] train loss: 0.154623, tar: 0.016147 
l0: 0.011011, l1: 0.011242, l2: 0.012461, l3: 0.011901, l4: 0.019623, l5: 0.016879, l6: 0.017007

[epoch: 114/100000, batch:    92/  187, ite: 10668] train loss: 0.154541, tar: 0.016140 
l0: 0.015409, l1: 0.018132, l2: 0.018099, l3: 0.017773, l4: 0.025635, l5: 0.025811, l6: 0.019304

[epoch: 114/100000, batch:    94/  187, ite: 10669] train loss: 0.154519, tar: 0.016138 
l0: 0.011769, l1: 0.012268, l2: 0.013113, l3: 0.013931, l4: 0.016729, l5: 0.017046, l6: 0.020932

[epoch: 114/100000, batch:    96/  187, ite: 10670] train loss: 0.154447, tar: 0.016132 
l0: 0.013322, l1: 0.014235, l2: 0.012553, l3: 0.013710, l4: 0.018208, l5: 0.014542, l6: 0.021313

[epoch: 114/100000, batch:    98/  187, ite: 10671] train loss: 0.154377, tar: 0.016128 
l0: 0.003505, l1: 0.003859, l2: 0.005050, l3: 0.003620, l4: 0.012057, l5: 0.008758, l6: 0.006614

[epoch: 114/100000, batch:   100/  187, ite: 10672] train loss: 0.154212, tar: 0.016109 
l0: 0.012286, l1: 0.012704, l2: 0.014075, l3: 0.014419, l4: 0.025568, l5: 0.022443, l6: 0.025074

[epoch: 114/100000, batch:   102/  187, ite: 10673] train loss: 0.154171, tar: 0.016103 
l0: 0.008705, l1: 0.009155, l2: 0.009385, l3: 0.008993, l4: 0.017026, l5: 0.014662, l6: 0.013284

[epoch: 114/100000, batch:   104/  187, ite: 10674] train loss: 0.154063, tar: 0.016092 
l0: 0.015724, l1: 0.015221, l2: 0.015188, l3: 0.017754, l4: 0.020754, l5: 0.019331, l6: 0.019285

[epoch: 114/100000, batch:   106/  187, ite: 10675] train loss: 0.154017, tar: 0.016092 
l0: 0.007045, l1: 0.007008, l2: 0.008480, l3: 0.008351, l4: 0.020092, l5: 0.015339, l6: 0.014514

[epoch: 114/100000, batch:   108/  187, ite: 10676] train loss: 0.153909, tar: 0.016078 
l0: 0.009380, l1: 0.008604, l2: 0.008714, l3: 0.010287, l4: 0.016868, l5: 0.015938, l6: 0.020680

[epoch: 114/100000, batch:   110/  187, ite: 10677] train loss: 0.153815, tar: 0.016068 
l0: 0.007448, l1: 0.007767, l2: 0.008556, l3: 0.009024, l4: 0.024187, l5: 0.025776, l6: 0.032134

[epoch: 114/100000, batch:   112/  187, ite: 10678] train loss: 0.153758, tar: 0.016056 
l0: 0.008758, l1: 0.008967, l2: 0.010246, l3: 0.011991, l4: 0.018261, l5: 0.019495, l6: 0.016127

[epoch: 114/100000, batch:   114/  187, ite: 10679] train loss: 0.153670, tar: 0.016045 
l0: 0.006756, l1: 0.007691, l2: 0.008305, l3: 0.007962, l4: 0.013521, l5: 0.010631, l6: 0.012938

[epoch: 114/100000, batch:   116/  187, ite: 10680] train loss: 0.153543, tar: 0.016031 
l0: 0.007909, l1: 0.007363, l2: 0.009804, l3: 0.011353, l4: 0.020121, l5: 0.018667, l6: 0.018867

[epoch: 114/100000, batch:   118/  187, ite: 10681] train loss: 0.153456, tar: 0.016019 
l0: 0.008562, l1: 0.009274, l2: 0.009495, l3: 0.010512, l4: 0.019734, l5: 0.019995, l6: 0.022190

[epoch: 114/100000, batch:   120/  187, ite: 10682] train loss: 0.153377, tar: 0.016009 
l0: 0.011388, l1: 0.011289, l2: 0.011213, l3: 0.012762, l4: 0.024295, l5: 0.020495, l6: 0.022248

[epoch: 114/100000, batch:   122/  187, ite: 10683] train loss: 0.153319, tar: 0.016002 
l0: 0.008093, l1: 0.006971, l2: 0.005751, l3: 0.007156, l4: 0.014112, l5: 0.014348, l6: 0.017703

[epoch: 114/100000, batch:   124/  187, ite: 10684] train loss: 0.153204, tar: 0.015990 
l0: 0.008031, l1: 0.008292, l2: 0.009551, l3: 0.008641, l4: 0.013358, l5: 0.013735, l6: 0.018139

[epoch: 114/100000, batch:   126/  187, ite: 10685] train loss: 0.153096, tar: 0.015979 
l0: 0.012238, l1: 0.012261, l2: 0.013537, l3: 0.013360, l4: 0.021971, l5: 0.019475, l6: 0.021923

[epoch: 114/100000, batch:   128/  187, ite: 10686] train loss: 0.153040, tar: 0.015973 
l0: 0.010449, l1: 0.011992, l2: 0.008931, l3: 0.010282, l4: 0.015744, l5: 0.014001, l6: 0.018849

[epoch: 114/100000, batch:   130/  187, ite: 10687] train loss: 0.152949, tar: 0.015965 
l0: 0.008101, l1: 0.008336, l2: 0.010227, l3: 0.009951, l4: 0.022347, l5: 0.018712, l6: 0.023077

[epoch: 114/100000, batch:   132/  187, ite: 10688] train loss: 0.152873, tar: 0.015954 
l0: 0.003833, l1: 0.005450, l2: 0.003613, l3: 0.003684, l4: 0.012341, l5: 0.011153, l6: 0.015657

[epoch: 114/100000, batch:   134/  187, ite: 10689] train loss: 0.152732, tar: 0.015936 
l0: 0.009118, l1: 0.009554, l2: 0.010864, l3: 0.011612, l4: 0.020204, l5: 0.016381, l6: 0.017890

[epoch: 114/100000, batch:   136/  187, ite: 10690] train loss: 0.152649, tar: 0.015926 
l0: 0.005604, l1: 0.007000, l2: 0.006812, l3: 0.006959, l4: 0.015008, l5: 0.009344, l6: 0.007682

[epoch: 114/100000, batch:   138/  187, ite: 10691] train loss: 0.152513, tar: 0.015911 
l0: 0.004514, l1: 0.005055, l2: 0.004432, l3: 0.003866, l4: 0.004576, l5: 0.004110, l6: 0.005292

[epoch: 114/100000, batch:   140/  187, ite: 10692] train loss: 0.152339, tar: 0.015895 
l0: 0.021459, l1: 0.021470, l2: 0.024551, l3: 0.024023, l4: 0.042629, l5: 0.037847, l6: 0.028321

[epoch: 114/100000, batch:   142/  187, ite: 10693] train loss: 0.152408, tar: 0.015903 
l0: 0.009948, l1: 0.010727, l2: 0.012363, l3: 0.014277, l4: 0.015187, l5: 0.014077, l6: 0.017126

[epoch: 114/100000, batch:   144/  187, ite: 10694] train loss: 0.152323, tar: 0.015894 
l0: 0.009384, l1: 0.024205, l2: 0.030604, l3: 0.034351, l4: 0.067736, l5: 0.037478, l6: 0.046363

[epoch: 114/100000, batch:   146/  187, ite: 10695] train loss: 0.152464, tar: 0.015885 
l0: 0.010653, l1: 0.011700, l2: 0.011786, l3: 0.010751, l4: 0.018035, l5: 0.018909, l6: 0.021657

[epoch: 114/100000, batch:   148/  187, ite: 10696] train loss: 0.152394, tar: 0.015877 
l0: 0.013809, l1: 0.012845, l2: 0.012611, l3: 0.014142, l4: 0.026117, l5: 0.025120, l6: 0.025843

[epoch: 114/100000, batch:   150/  187, ite: 10697] train loss: 0.152362, tar: 0.015874 
l0: 0.007926, l1: 0.007168, l2: 0.008873, l3: 0.010327, l4: 0.032848, l5: 0.024427, l6: 0.025467

[epoch: 114/100000, batch:   152/  187, ite: 10698] train loss: 0.152312, tar: 0.015863 
l0: 0.010895, l1: 0.011789, l2: 0.009160, l3: 0.010008, l4: 0.011702, l5: 0.011243, l6: 0.012987

[epoch: 114/100000, batch:   154/  187, ite: 10699] train loss: 0.152205, tar: 0.015856 
l0: 0.012491, l1: 0.013858, l2: 0.012575, l3: 0.012721, l4: 0.016298, l5: 0.014370, l6: 0.017233

[epoch: 114/100000, batch:   156/  187, ite: 10700] train loss: 0.152130, tar: 0.015851 
l0: 0.010147, l1: 0.011502, l2: 0.010085, l3: 0.010451, l4: 0.022815, l5: 0.022193, l6: 0.022273

[epoch: 114/100000, batch:   158/  187, ite: 10701] train loss: 0.152069, tar: 0.015843 
l0: 0.008475, l1: 0.007588, l2: 0.009177, l3: 0.011613, l4: 0.021329, l5: 0.019012, l6: 0.020594

[epoch: 114/100000, batch:   160/  187, ite: 10702] train loss: 0.151992, tar: 0.015832 
l0: 0.004292, l1: 0.007011, l2: 0.011268, l3: 0.006222, l4: 0.008579, l5: 0.006116, l6: 0.005668

[epoch: 114/100000, batch:   162/  187, ite: 10703] train loss: 0.151845, tar: 0.015816 
l0: 0.022126, l1: 0.023786, l2: 0.025807, l3: 0.026665, l4: 0.033930, l5: 0.025174, l6: 0.026765

[epoch: 114/100000, batch:   164/  187, ite: 10704] train loss: 0.151891, tar: 0.015825 
l0: 0.010756, l1: 0.010195, l2: 0.015937, l3: 0.020236, l4: 0.021723, l5: 0.020354, l6: 0.022906

[epoch: 114/100000, batch:   166/  187, ite: 10705] train loss: 0.151849, tar: 0.015818 
l0: 0.007257, l1: 0.007040, l2: 0.008408, l3: 0.010056, l4: 0.019022, l5: 0.016412, l6: 0.020019

[epoch: 114/100000, batch:   168/  187, ite: 10706] train loss: 0.151759, tar: 0.015806 
l0: 0.015312, l1: 0.016190, l2: 0.015295, l3: 0.030877, l4: 0.022600, l5: 0.018769, l6: 0.016697

[epoch: 114/100000, batch:   170/  187, ite: 10707] train loss: 0.151736, tar: 0.015805 
l0: 0.022569, l1: 0.025752, l2: 0.031642, l3: 0.020239, l4: 0.024300, l5: 0.022162, l6: 0.032704

[epoch: 114/100000, batch:   172/  187, ite: 10708] train loss: 0.151775, tar: 0.015815 
l0: 0.011161, l1: 0.010563, l2: 0.011539, l3: 0.013892, l4: 0.029083, l5: 0.023402, l6: 0.029753

[epoch: 114/100000, batch:   174/  187, ite: 10709] train loss: 0.151744, tar: 0.015808 
l0: 0.009522, l1: 0.010013, l2: 0.012384, l3: 0.012129, l4: 0.041445, l5: 0.040302, l6: 0.038786

[epoch: 114/100000, batch:   176/  187, ite: 10710] train loss: 0.151762, tar: 0.015799 
l0: 0.009024, l1: 0.009285, l2: 0.009467, l3: 0.010326, l4: 0.018539, l5: 0.014854, l6: 0.017034

[epoch: 114/100000, batch:   178/  187, ite: 10711] train loss: 0.151673, tar: 0.015790 
l0: 0.022830, l1: 0.023002, l2: 0.020569, l3: 0.024770, l4: 0.049428, l5: 0.038092, l6: 0.031647

[epoch: 114/100000, batch:   180/  187, ite: 10712] train loss: 0.151755, tar: 0.015799 
l0: 0.017881, l1: 0.017354, l2: 0.020339, l3: 0.020821, l4: 0.025884, l5: 0.023508, l6: 0.027899

[epoch: 114/100000, batch:   182/  187, ite: 10713] train loss: 0.151758, tar: 0.015802 
l0: 0.020027, l1: 0.020584, l2: 0.021252, l3: 0.025673, l4: 0.043123, l5: 0.034824, l6: 0.027906

[epoch: 114/100000, batch:   184/  187, ite: 10714] train loss: 0.151816, tar: 0.015808 
l0: 0.009327, l1: 0.009233, l2: 0.010857, l3: 0.010590, l4: 0.016971, l5: 0.016523, l6: 0.022595

[epoch: 114/100000, batch:   186/  187, ite: 10715] train loss: 0.151738, tar: 0.015799 
l0: 0.014179, l1: 0.014146, l2: 0.021235, l3: 0.023801, l4: 0.019350, l5: 0.016371, l6: 0.014957

[epoch: 114/100000, batch:   188/  187, ite: 10716] train loss: 0.151700, tar: 0.015797 
l0: 0.012722, l1: 0.013046, l2: 0.013979, l3: 0.017371, l4: 0.026666, l5: 0.024346, l6: 0.033036

[epoch: 115/100000, batch:     2/  187, ite: 10717] train loss: 0.151685, tar: 0.015793 
l0: 0.011409, l1: 0.011475, l2: 0.013361, l3: 0.012289, l4: 0.030747, l5: 0.029570, l6: 0.035181

[epoch: 115/100000, batch:     4/  187, ite: 10718] train loss: 0.151674, tar: 0.015787 
l0: 0.005670, l1: 0.006818, l2: 0.006440, l3: 0.006981, l4: 0.016548, l5: 0.011236, l6: 0.016514

[epoch: 115/100000, batch:     6/  187, ite: 10719] train loss: 0.151561, tar: 0.015772 
l0: 0.012993, l1: 0.013498, l2: 0.012765, l3: 0.014066, l4: 0.019853, l5: 0.017132, l6: 0.021951

[epoch: 115/100000, batch:     8/  187, ite: 10720] train loss: 0.151506, tar: 0.015769 
l0: 0.009201, l1: 0.009971, l2: 0.010283, l3: 0.010290, l4: 0.015144, l5: 0.012936, l6: 0.014288

[epoch: 115/100000, batch:    10/  187, ite: 10721] train loss: 0.151410, tar: 0.015760 
l0: 0.018504, l1: 0.018386, l2: 0.019232, l3: 0.020552, l4: 0.024120, l5: 0.021275, l6: 0.022826

[epoch: 115/100000, batch:    12/  187, ite: 10722] train loss: 0.151401, tar: 0.015763 
l0: 0.008040, l1: 0.009061, l2: 0.010086, l3: 0.008682, l4: 0.011180, l5: 0.009738, l6: 0.013325

[epoch: 115/100000, batch:    14/  187, ite: 10723] train loss: 0.151289, tar: 0.015753 
l0: 0.011180, l1: 0.010816, l2: 0.012844, l3: 0.013253, l4: 0.023154, l5: 0.021015, l6: 0.022616

[epoch: 115/100000, batch:    16/  187, ite: 10724] train loss: 0.151238, tar: 0.015746 
l0: 0.011230, l1: 0.012463, l2: 0.016913, l3: 0.019060, l4: 0.017624, l5: 0.012709, l6: 0.015018

[epoch: 115/100000, batch:    18/  187, ite: 10725] train loss: 0.151175, tar: 0.015740 
l0: 0.011473, l1: 0.011710, l2: 0.012749, l3: 0.012644, l4: 0.022147, l5: 0.020126, l6: 0.020856

[epoch: 115/100000, batch:    20/  187, ite: 10726] train loss: 0.151120, tar: 0.015734 
l0: 0.007826, l1: 0.007977, l2: 0.008714, l3: 0.009717, l4: 0.016575, l5: 0.016444, l6: 0.019574

[epoch: 115/100000, batch:    22/  187, ite: 10727] train loss: 0.151032, tar: 0.015723 
l0: 0.007756, l1: 0.007931, l2: 0.009089, l3: 0.017997, l4: 0.023914, l5: 0.026519, l6: 0.022081

[epoch: 115/100000, batch:    24/  187, ite: 10728] train loss: 0.150983, tar: 0.015712 
l0: 0.012527, l1: 0.010138, l2: 0.013449, l3: 0.015844, l4: 0.025959, l5: 0.038246, l6: 0.037706

[epoch: 115/100000, batch:    26/  187, ite: 10729] train loss: 0.150987, tar: 0.015708 
l0: 0.008784, l1: 0.008763, l2: 0.007851, l3: 0.008021, l4: 0.013432, l5: 0.014318, l6: 0.018583

[epoch: 115/100000, batch:    28/  187, ite: 10730] train loss: 0.150889, tar: 0.015699 
l0: 0.009674, l1: 0.009924, l2: 0.009503, l3: 0.010707, l4: 0.018276, l5: 0.019724, l6: 0.019135

[epoch: 115/100000, batch:    30/  187, ite: 10731] train loss: 0.150815, tar: 0.015690 
l0: 0.005317, l1: 0.005737, l2: 0.005682, l3: 0.006613, l4: 0.013131, l5: 0.011394, l6: 0.009430

[epoch: 115/100000, batch:    32/  187, ite: 10732] train loss: 0.150688, tar: 0.015676 
l0: 0.011217, l1: 0.012321, l2: 0.011668, l3: 0.012314, l4: 0.015993, l5: 0.015513, l6: 0.016246

[epoch: 115/100000, batch:    34/  187, ite: 10733] train loss: 0.150612, tar: 0.015670 
l0: 0.006684, l1: 0.007069, l2: 0.007817, l3: 0.007114, l4: 0.015027, l5: 0.016357, l6: 0.015374

[epoch: 115/100000, batch:    36/  187, ite: 10734] train loss: 0.150510, tar: 0.015658 
l0: 0.007987, l1: 0.008185, l2: 0.008425, l3: 0.009335, l4: 0.015581, l5: 0.013752, l6: 0.011489

[epoch: 115/100000, batch:    38/  187, ite: 10735] train loss: 0.150406, tar: 0.015647 
l0: 0.004974, l1: 0.005299, l2: 0.005857, l3: 0.008567, l4: 0.014460, l5: 0.010391, l6: 0.009510

[epoch: 115/100000, batch:    40/  187, ite: 10736] train loss: 0.150282, tar: 0.015633 
l0: 0.013227, l1: 0.013868, l2: 0.014945, l3: 0.016076, l4: 0.023543, l5: 0.019597, l6: 0.019977

[epoch: 115/100000, batch:    42/  187, ite: 10737] train loss: 0.150243, tar: 0.015630 
l0: 0.016192, l1: 0.016571, l2: 0.017930, l3: 0.020494, l4: 0.017656, l5: 0.018366, l6: 0.021354

[epoch: 115/100000, batch:    44/  187, ite: 10738] train loss: 0.150214, tar: 0.015630 
l0: 0.017223, l1: 0.017607, l2: 0.016022, l3: 0.018589, l4: 0.019246, l5: 0.017923, l6: 0.018478

[epoch: 115/100000, batch:    46/  187, ite: 10739] train loss: 0.150180, tar: 0.015633 
l0: 0.011420, l1: 0.010753, l2: 0.014477, l3: 0.014625, l4: 0.020556, l5: 0.019472, l6: 0.021099

[epoch: 115/100000, batch:    48/  187, ite: 10740] train loss: 0.150129, tar: 0.015627 
l0: 0.006467, l1: 0.006285, l2: 0.007411, l3: 0.009645, l4: 0.008750, l5: 0.009429, l6: 0.009075

[epoch: 115/100000, batch:    50/  187, ite: 10741] train loss: 0.150003, tar: 0.015614 
l0: 0.008187, l1: 0.008348, l2: 0.008867, l3: 0.008301, l4: 0.021764, l5: 0.020597, l6: 0.023455

[epoch: 115/100000, batch:    52/  187, ite: 10742] train loss: 0.149935, tar: 0.015604 
l0: 0.009944, l1: 0.010366, l2: 0.011983, l3: 0.012205, l4: 0.019732, l5: 0.018988, l6: 0.022372

[epoch: 115/100000, batch:    54/  187, ite: 10743] train loss: 0.149875, tar: 0.015597 
l0: 0.013162, l1: 0.013762, l2: 0.012715, l3: 0.011717, l4: 0.020903, l5: 0.020183, l6: 0.017220

[epoch: 115/100000, batch:    56/  187, ite: 10744] train loss: 0.149821, tar: 0.015594 
l0: 0.007295, l1: 0.007211, l2: 0.006271, l3: 0.008772, l4: 0.024944, l5: 0.020485, l6: 0.017030

[epoch: 115/100000, batch:    58/  187, ite: 10745] train loss: 0.149744, tar: 0.015582 
l0: 0.007688, l1: 0.008154, l2: 0.011874, l3: 0.012505, l4: 0.013098, l5: 0.010957, l6: 0.011235

[epoch: 115/100000, batch:    60/  187, ite: 10746] train loss: 0.149644, tar: 0.015572 
l0: 0.008866, l1: 0.008015, l2: 0.011740, l3: 0.013326, l4: 0.023576, l5: 0.025393, l6: 0.019620

[epoch: 115/100000, batch:    62/  187, ite: 10747] train loss: 0.149592, tar: 0.015563 
l0: 0.011808, l1: 0.013167, l2: 0.013800, l3: 0.013726, l4: 0.015181, l5: 0.013217, l6: 0.013841

[epoch: 115/100000, batch:    64/  187, ite: 10748] train loss: 0.149518, tar: 0.015558 
l0: 0.008093, l1: 0.008653, l2: 0.009420, l3: 0.007337, l4: 0.016138, l5: 0.013491, l6: 0.019204

[epoch: 115/100000, batch:    66/  187, ite: 10749] train loss: 0.149429, tar: 0.015548 
l0: 0.005378, l1: 0.005792, l2: 0.005894, l3: 0.005522, l4: 0.007941, l5: 0.007680, l6: 0.008525

[epoch: 115/100000, batch:    68/  187, ite: 10750] train loss: 0.149292, tar: 0.015534 
l0: 0.009324, l1: 0.011048, l2: 0.009343, l3: 0.010058, l4: 0.012622, l5: 0.014213, l6: 0.016409

[epoch: 115/100000, batch:    70/  187, ite: 10751] train loss: 0.149203, tar: 0.015526 
l0: 0.009904, l1: 0.009715, l2: 0.009151, l3: 0.010086, l4: 0.019234, l5: 0.022762, l6: 0.019099

[epoch: 115/100000, batch:    72/  187, ite: 10752] train loss: 0.149138, tar: 0.015519 
l0: 0.008891, l1: 0.009665, l2: 0.009441, l3: 0.009497, l4: 0.012841, l5: 0.011085, l6: 0.011901

[epoch: 115/100000, batch:    74/  187, ite: 10753] train loss: 0.149037, tar: 0.015510 
l0: 0.006233, l1: 0.006158, l2: 0.007133, l3: 0.007228, l4: 0.013701, l5: 0.014533, l6: 0.015622

[epoch: 115/100000, batch:    76/  187, ite: 10754] train loss: 0.148933, tar: 0.015497 
l0: 0.008345, l1: 0.008696, l2: 0.010132, l3: 0.009243, l4: 0.020224, l5: 0.017112, l6: 0.013876

[epoch: 115/100000, batch:    78/  187, ite: 10755] train loss: 0.148852, tar: 0.015488 
l0: 0.007559, l1: 0.007265, l2: 0.006943, l3: 0.008089, l4: 0.016405, l5: 0.019322, l6: 0.018639

[epoch: 115/100000, batch:    80/  187, ite: 10756] train loss: 0.148767, tar: 0.015478 
l0: 0.007994, l1: 0.007824, l2: 0.009049, l3: 0.008814, l4: 0.014811, l5: 0.013141, l6: 0.016798

[epoch: 115/100000, batch:    82/  187, ite: 10757] train loss: 0.148674, tar: 0.015468 
l0: 0.004825, l1: 0.006350, l2: 0.005231, l3: 0.005756, l4: 0.014257, l5: 0.013221, l6: 0.013903

[epoch: 115/100000, batch:    84/  187, ite: 10758] train loss: 0.148561, tar: 0.015454 
l0: 0.007440, l1: 0.008108, l2: 0.008055, l3: 0.008186, l4: 0.022999, l5: 0.020771, l6: 0.028648

[epoch: 115/100000, batch:    86/  187, ite: 10759] train loss: 0.148503, tar: 0.015443 
l0: 0.010231, l1: 0.011708, l2: 0.008979, l3: 0.009104, l4: 0.014746, l5: 0.014231, l6: 0.015763

[epoch: 115/100000, batch:    88/  187, ite: 10760] train loss: 0.148419, tar: 0.015436 
l0: 0.006998, l1: 0.008120, l2: 0.006967, l3: 0.007930, l4: 0.021543, l5: 0.016499, l6: 0.015452

[epoch: 115/100000, batch:    90/  187, ite: 10761] train loss: 0.148334, tar: 0.015425 
l0: 0.007163, l1: 0.007431, l2: 0.007090, l3: 0.007545, l4: 0.017301, l5: 0.017125, l6: 0.021976

[epoch: 115/100000, batch:    92/  187, ite: 10762] train loss: 0.148251, tar: 0.015414 
l0: 0.009383, l1: 0.009204, l2: 0.009993, l3: 0.010276, l4: 0.014064, l5: 0.014365, l6: 0.018010

[epoch: 115/100000, batch:    94/  187, ite: 10763] train loss: 0.148169, tar: 0.015406 
l0: 0.011724, l1: 0.012143, l2: 0.014700, l3: 0.012635, l4: 0.017008, l5: 0.016316, l6: 0.019744

[epoch: 115/100000, batch:    96/  187, ite: 10764] train loss: 0.148112, tar: 0.015402 
l0: 0.007995, l1: 0.007706, l2: 0.006219, l3: 0.007447, l4: 0.017196, l5: 0.018828, l6: 0.020621

[epoch: 115/100000, batch:    98/  187, ite: 10765] train loss: 0.148030, tar: 0.015392 
l0: 0.017488, l1: 0.019256, l2: 0.018573, l3: 0.017805, l4: 0.019657, l5: 0.015658, l6: 0.020477

[epoch: 115/100000, batch:   100/  187, ite: 10766] train loss: 0.148005, tar: 0.015395 
l0: 0.007677, l1: 0.007783, l2: 0.009544, l3: 0.009185, l4: 0.019775, l5: 0.018525, l6: 0.024277

[epoch: 115/100000, batch:   102/  187, ite: 10767] train loss: 0.147939, tar: 0.015385 
l0: 0.014182, l1: 0.012985, l2: 0.015362, l3: 0.015850, l4: 0.021038, l5: 0.024174, l6: 0.022927

[epoch: 115/100000, batch:   104/  187, ite: 10768] train loss: 0.147911, tar: 0.015383 
l0: 0.010681, l1: 0.011923, l2: 0.012893, l3: 0.010679, l4: 0.016003, l5: 0.015559, l6: 0.014389

[epoch: 115/100000, batch:   106/  187, ite: 10769] train loss: 0.147838, tar: 0.015377 
l0: 0.007508, l1: 0.007667, l2: 0.009451, l3: 0.009955, l4: 0.012107, l5: 0.009642, l6: 0.011886

[epoch: 115/100000, batch:   108/  187, ite: 10770] train loss: 0.147735, tar: 0.015367 
l0: 0.012336, l1: 0.012723, l2: 0.016254, l3: 0.014588, l4: 0.020146, l5: 0.022746, l6: 0.020825

[epoch: 115/100000, batch:   110/  187, ite: 10771] train loss: 0.147698, tar: 0.015363 
l0: 0.007883, l1: 0.008253, l2: 0.008849, l3: 0.008833, l4: 0.017173, l5: 0.014472, l6: 0.016543

[epoch: 115/100000, batch:   112/  187, ite: 10772] train loss: 0.147613, tar: 0.015353 
l0: 0.007836, l1: 0.008082, l2: 0.008674, l3: 0.009343, l4: 0.016759, l5: 0.012144, l6: 0.011580

[epoch: 115/100000, batch:   114/  187, ite: 10773] train loss: 0.147518, tar: 0.015343 
l0: 0.010199, l1: 0.010328, l2: 0.010234, l3: 0.011446, l4: 0.020647, l5: 0.016646, l6: 0.016711

[epoch: 115/100000, batch:   116/  187, ite: 10774] train loss: 0.147452, tar: 0.015337 
l0: 0.010493, l1: 0.010538, l2: 0.016213, l3: 0.018919, l4: 0.022293, l5: 0.017444, l6: 0.019925

[epoch: 115/100000, batch:   118/  187, ite: 10775] train loss: 0.147411, tar: 0.015330 
l0: 0.006241, l1: 0.006285, l2: 0.007174, l3: 0.008474, l4: 0.017217, l5: 0.017355, l6: 0.019505

[epoch: 115/100000, batch:   120/  187, ite: 10776] train loss: 0.147327, tar: 0.015319 
l0: 0.010539, l1: 0.010813, l2: 0.013100, l3: 0.012591, l4: 0.016800, l5: 0.017693, l6: 0.017578

[epoch: 115/100000, batch:   122/  187, ite: 10777] train loss: 0.147265, tar: 0.015312 
l0: 0.007182, l1: 0.007236, l2: 0.007239, l3: 0.007355, l4: 0.013847, l5: 0.014064, l6: 0.014404

[epoch: 115/100000, batch:   124/  187, ite: 10778] train loss: 0.147168, tar: 0.015302 
l0: 0.008045, l1: 0.008301, l2: 0.009940, l3: 0.009252, l4: 0.016751, l5: 0.015781, l6: 0.016118

[epoch: 115/100000, batch:   126/  187, ite: 10779] train loss: 0.147087, tar: 0.015293 
l0: 0.008174, l1: 0.007316, l2: 0.010231, l3: 0.010195, l4: 0.032974, l5: 0.032009, l6: 0.029152

[epoch: 115/100000, batch:   128/  187, ite: 10780] train loss: 0.147065, tar: 0.015284 
l0: 0.005239, l1: 0.005486, l2: 0.006377, l3: 0.006427, l4: 0.017141, l5: 0.012487, l6: 0.011631

[epoch: 115/100000, batch:   130/  187, ite: 10781] train loss: 0.146960, tar: 0.015271 
l0: 0.003958, l1: 0.004384, l2: 0.004661, l3: 0.005704, l4: 0.009115, l5: 0.007840, l6: 0.007597

[epoch: 115/100000, batch:   132/  187, ite: 10782] train loss: 0.146827, tar: 0.015256 
l0: 0.010725, l1: 0.011938, l2: 0.012071, l3: 0.010940, l4: 0.021183, l5: 0.015055, l6: 0.016837

[epoch: 115/100000, batch:   134/  187, ite: 10783] train loss: 0.146766, tar: 0.015250 
l0: 0.012418, l1: 0.011616, l2: 0.010804, l3: 0.010897, l4: 0.033617, l5: 0.029880, l6: 0.044381

[epoch: 115/100000, batch:   136/  187, ite: 10784] train loss: 0.146774, tar: 0.015247 
l0: 0.015640, l1: 0.016116, l2: 0.017937, l3: 0.018410, l4: 0.030475, l5: 0.026759, l6: 0.022652

[epoch: 115/100000, batch:   138/  187, ite: 10785] train loss: 0.146776, tar: 0.015247 
l0: 0.013404, l1: 0.012235, l2: 0.015537, l3: 0.019071, l4: 0.022905, l5: 0.023924, l6: 0.021567

[epoch: 115/100000, batch:   140/  187, ite: 10786] train loss: 0.146753, tar: 0.015245 
l0: 0.007383, l1: 0.006714, l2: 0.007173, l3: 0.007491, l4: 0.015386, l5: 0.016429, l6: 0.021965

[epoch: 115/100000, batch:   142/  187, ite: 10787] train loss: 0.146671, tar: 0.015235 
l0: 0.008554, l1: 0.007823, l2: 0.011033, l3: 0.011509, l4: 0.017218, l5: 0.019457, l6: 0.016158

[epoch: 115/100000, batch:   144/  187, ite: 10788] train loss: 0.146602, tar: 0.015227 
l0: 0.006091, l1: 0.006399, l2: 0.006664, l3: 0.006279, l4: 0.006951, l5: 0.006080, l6: 0.007546

[epoch: 115/100000, batch:   146/  187, ite: 10789] train loss: 0.146474, tar: 0.015215 
l0: 0.006768, l1: 0.007432, l2: 0.010322, l3: 0.009500, l4: 0.012072, l5: 0.008415, l6: 0.009647

[epoch: 115/100000, batch:   148/  187, ite: 10790] train loss: 0.146370, tar: 0.015204 
l0: 0.006234, l1: 0.006625, l2: 0.007272, l3: 0.007850, l4: 0.014818, l5: 0.011095, l6: 0.013712

[epoch: 115/100000, batch:   150/  187, ite: 10791] train loss: 0.146270, tar: 0.015193 
l0: 0.009668, l1: 0.010045, l2: 0.011127, l3: 0.012226, l4: 0.015817, l5: 0.014188, l6: 0.013631

[epoch: 115/100000, batch:   152/  187, ite: 10792] train loss: 0.146195, tar: 0.015186 
l0: 0.008657, l1: 0.008964, l2: 0.010741, l3: 0.010085, l4: 0.008979, l5: 0.008821, l6: 0.009805

[epoch: 115/100000, batch:   154/  187, ite: 10793] train loss: 0.146094, tar: 0.015178 
l0: 0.007982, l1: 0.008077, l2: 0.009699, l3: 0.008080, l4: 0.011547, l5: 0.010156, l6: 0.010951

[epoch: 115/100000, batch:   156/  187, ite: 10794] train loss: 0.145994, tar: 0.015169 
l0: 0.011974, l1: 0.012621, l2: 0.013353, l3: 0.011644, l4: 0.015517, l5: 0.015025, l6: 0.019812

[epoch: 115/100000, batch:   158/  187, ite: 10795] train loss: 0.145936, tar: 0.015165 
l0: 0.010109, l1: 0.010582, l2: 0.011771, l3: 0.011609, l4: 0.013166, l5: 0.008743, l6: 0.011458

[epoch: 115/100000, batch:   160/  187, ite: 10796] train loss: 0.145850, tar: 0.015158 
l0: 0.009633, l1: 0.009871, l2: 0.010957, l3: 0.011612, l4: 0.018129, l5: 0.017650, l6: 0.020832

[epoch: 115/100000, batch:   162/  187, ite: 10797] train loss: 0.145791, tar: 0.015151 
l0: 0.007134, l1: 0.006840, l2: 0.010031, l3: 0.010542, l4: 0.019112, l5: 0.018190, l6: 0.022292

[epoch: 115/100000, batch:   164/  187, ite: 10798] train loss: 0.145726, tar: 0.015141 
l0: 0.009352, l1: 0.011472, l2: 0.010159, l3: 0.010514, l4: 0.016160, l5: 0.014479, l6: 0.014593

[epoch: 115/100000, batch:   166/  187, ite: 10799] train loss: 0.145652, tar: 0.015134 
l0: 0.006135, l1: 0.006967, l2: 0.006881, l3: 0.008009, l4: 0.015025, l5: 0.013569, l6: 0.015198

[epoch: 115/100000, batch:   168/  187, ite: 10800] train loss: 0.145560, tar: 0.015123 
l0: 0.008759, l1: 0.010001, l2: 0.008852, l3: 0.010109, l4: 0.011754, l5: 0.011023, l6: 0.012612

[epoch: 115/100000, batch:   170/  187, ite: 10801] train loss: 0.145469, tar: 0.015115 
l0: 0.006071, l1: 0.006442, l2: 0.006109, l3: 0.005864, l4: 0.008535, l5: 0.008902, l6: 0.009020

[epoch: 115/100000, batch:   172/  187, ite: 10802] train loss: 0.145351, tar: 0.015104 
l0: 0.008440, l1: 0.009577, l2: 0.009832, l3: 0.009307, l4: 0.013760, l5: 0.012516, l6: 0.012255

[epoch: 115/100000, batch:   174/  187, ite: 10803] train loss: 0.145265, tar: 0.015095 
l0: 0.006105, l1: 0.005803, l2: 0.006661, l3: 0.008850, l4: 0.019481, l5: 0.017204, l6: 0.017232

[epoch: 115/100000, batch:   176/  187, ite: 10804] train loss: 0.145185, tar: 0.015084 
l0: 0.008315, l1: 0.008763, l2: 0.009397, l3: 0.009791, l4: 0.020625, l5: 0.019230, l6: 0.017574

[epoch: 115/100000, batch:   178/  187, ite: 10805] train loss: 0.145121, tar: 0.015076 
l0: 0.012710, l1: 0.014501, l2: 0.011658, l3: 0.010627, l4: 0.014464, l5: 0.014296, l6: 0.015561

[epoch: 115/100000, batch:   180/  187, ite: 10806] train loss: 0.145058, tar: 0.015073 
l0: 0.004262, l1: 0.004650, l2: 0.004616, l3: 0.004394, l4: 0.010296, l5: 0.008906, l6: 0.009267

[epoch: 115/100000, batch:   182/  187, ite: 10807] train loss: 0.144935, tar: 0.015059 
l0: 0.012585, l1: 0.012051, l2: 0.014892, l3: 0.013858, l4: 0.020651, l5: 0.023508, l6: 0.022895

[epoch: 115/100000, batch:   184/  187, ite: 10808] train loss: 0.144905, tar: 0.015056 
l0: 0.007601, l1: 0.007634, l2: 0.009619, l3: 0.009801, l4: 0.018612, l5: 0.016546, l6: 0.013110

[epoch: 115/100000, batch:   186/  187, ite: 10809] train loss: 0.144828, tar: 0.015047 
l0: 0.011774, l1: 0.012874, l2: 0.018184, l3: 0.016638, l4: 0.019290, l5: 0.017689, l6: 0.029656

[epoch: 115/100000, batch:   188/  187, ite: 10810] train loss: 0.144805, tar: 0.015043 
l0: 0.012343, l1: 0.013196, l2: 0.014476, l3: 0.015849, l4: 0.026440, l5: 0.019631, l6: 0.017486

[epoch: 116/100000, batch:     2/  187, ite: 10811] train loss: 0.144774, tar: 0.015040 
l0: 0.008114, l1: 0.008709, l2: 0.008172, l3: 0.008412, l4: 0.010947, l5: 0.009413, l6: 0.011907

[epoch: 116/100000, batch:     4/  187, ite: 10812] train loss: 0.144677, tar: 0.015031 
l0: 0.006129, l1: 0.006658, l2: 0.007486, l3: 0.006637, l4: 0.011149, l5: 0.009981, l6: 0.009178

[epoch: 116/100000, batch:     6/  187, ite: 10813] train loss: 0.144569, tar: 0.015020 
l0: 0.009221, l1: 0.008184, l2: 0.008828, l3: 0.009383, l4: 0.018253, l5: 0.018661, l6: 0.021019

[epoch: 116/100000, batch:     8/  187, ite: 10814] train loss: 0.144506, tar: 0.015013 
l0: 0.007726, l1: 0.008042, l2: 0.007259, l3: 0.008503, l4: 0.016600, l5: 0.016501, l6: 0.014305

[epoch: 116/100000, batch:    10/  187, ite: 10815] train loss: 0.144426, tar: 0.015004 
l0: 0.010376, l1: 0.010737, l2: 0.011261, l3: 0.012865, l4: 0.011740, l5: 0.011886, l6: 0.013926

[epoch: 116/100000, batch:    12/  187, ite: 10816] train loss: 0.144350, tar: 0.014999 
l0: 0.007041, l1: 0.007341, l2: 0.010018, l3: 0.008864, l4: 0.017179, l5: 0.015174, l6: 0.014204

[epoch: 116/100000, batch:    14/  187, ite: 10817] train loss: 0.144271, tar: 0.014989 
l0: 0.009842, l1: 0.010208, l2: 0.013338, l3: 0.013212, l4: 0.012947, l5: 0.011979, l6: 0.013845

[epoch: 116/100000, batch:    16/  187, ite: 10818] train loss: 0.144199, tar: 0.014983 
l0: 0.010945, l1: 0.011339, l2: 0.011696, l3: 0.011888, l4: 0.012949, l5: 0.013262, l6: 0.014011

[epoch: 116/100000, batch:    18/  187, ite: 10819] train loss: 0.144128, tar: 0.014978 
l0: 0.004263, l1: 0.004051, l2: 0.005874, l3: 0.004893, l4: 0.010305, l5: 0.007463, l6: 0.008727

[epoch: 116/100000, batch:    20/  187, ite: 10820] train loss: 0.144008, tar: 0.014965 
l0: 0.005462, l1: 0.005529, l2: 0.006697, l3: 0.007381, l4: 0.012702, l5: 0.012750, l6: 0.010950

[epoch: 116/100000, batch:    22/  187, ite: 10821] train loss: 0.143908, tar: 0.014953 
l0: 0.003883, l1: 0.004265, l2: 0.005206, l3: 0.003738, l4: 0.006419, l5: 0.006923, l6: 0.007322

[epoch: 116/100000, batch:    24/  187, ite: 10822] train loss: 0.143779, tar: 0.014939 
l0: 0.011220, l1: 0.011378, l2: 0.008563, l3: 0.010813, l4: 0.027174, l5: 0.022636, l6: 0.026525

[epoch: 116/100000, batch:    26/  187, ite: 10823] train loss: 0.143748, tar: 0.014935 
l0: 0.010012, l1: 0.010768, l2: 0.010988, l3: 0.009361, l4: 0.020471, l5: 0.019324, l6: 0.018734

[epoch: 116/100000, batch:    28/  187, ite: 10824] train loss: 0.143694, tar: 0.014929 
l0: 0.004424, l1: 0.004833, l2: 0.006044, l3: 0.005855, l4: 0.011259, l5: 0.010388, l6: 0.012195

[epoch: 116/100000, batch:    30/  187, ite: 10825] train loss: 0.143587, tar: 0.014916 
l0: 0.006617, l1: 0.006526, l2: 0.008884, l3: 0.007508, l4: 0.009520, l5: 0.008332, l6: 0.013765

[epoch: 116/100000, batch:    32/  187, ite: 10826] train loss: 0.143487, tar: 0.014906 
l0: 0.005879, l1: 0.005375, l2: 0.007120, l3: 0.008068, l4: 0.013651, l5: 0.015475, l6: 0.012355

[epoch: 116/100000, batch:    34/  187, ite: 10827] train loss: 0.143395, tar: 0.014895 
l0: 0.005018, l1: 0.005310, l2: 0.004659, l3: 0.005106, l4: 0.009999, l5: 0.010935, l6: 0.014444

[epoch: 116/100000, batch:    36/  187, ite: 10828] train loss: 0.143289, tar: 0.014883 
l0: 0.005327, l1: 0.005534, l2: 0.008710, l3: 0.008431, l4: 0.011457, l5: 0.010045, l6: 0.010678

[epoch: 116/100000, batch:    38/  187, ite: 10829] train loss: 0.143189, tar: 0.014872 
l0: 0.008330, l1: 0.008789, l2: 0.009856, l3: 0.009624, l4: 0.012501, l5: 0.010740, l6: 0.013264

[epoch: 116/100000, batch:    40/  187, ite: 10830] train loss: 0.143105, tar: 0.014864 
l0: 0.009408, l1: 0.009294, l2: 0.010498, l3: 0.010795, l4: 0.021573, l5: 0.022342, l6: 0.019777

[epoch: 116/100000, batch:    42/  187, ite: 10831] train loss: 0.143057, tar: 0.014857 
l0: 0.008115, l1: 0.008080, l2: 0.009750, l3: 0.010209, l4: 0.013395, l5: 0.011971, l6: 0.013813

[epoch: 116/100000, batch:    44/  187, ite: 10832] train loss: 0.142976, tar: 0.014849 
l0: 0.005235, l1: 0.005814, l2: 0.006610, l3: 0.006685, l4: 0.010456, l5: 0.008893, l6: 0.011684

[epoch: 116/100000, batch:    46/  187, ite: 10833] train loss: 0.142871, tar: 0.014838 
l0: 0.009444, l1: 0.009125, l2: 0.010829, l3: 0.010597, l4: 0.016613, l5: 0.016418, l6: 0.021002

[epoch: 116/100000, batch:    48/  187, ite: 10834] train loss: 0.142812, tar: 0.014831 
l0: 0.008546, l1: 0.008774, l2: 0.009891, l3: 0.010445, l4: 0.013278, l5: 0.012077, l6: 0.012823

[epoch: 116/100000, batch:    50/  187, ite: 10835] train loss: 0.142732, tar: 0.014824 
l0: 0.006811, l1: 0.007427, l2: 0.006480, l3: 0.006322, l4: 0.008449, l5: 0.007463, l6: 0.007326

[epoch: 116/100000, batch:    52/  187, ite: 10836] train loss: 0.142621, tar: 0.014814 
l0: 0.003704, l1: 0.004415, l2: 0.003885, l3: 0.003965, l4: 0.007330, l5: 0.005685, l6: 0.005815

[epoch: 116/100000, batch:    54/  187, ite: 10837] train loss: 0.142492, tar: 0.014801 
l0: 0.007757, l1: 0.007930, l2: 0.006745, l3: 0.006901, l4: 0.008133, l5: 0.008838, l6: 0.010798

[epoch: 116/100000, batch:    56/  187, ite: 10838] train loss: 0.142390, tar: 0.014792 
l0: 0.004287, l1: 0.004216, l2: 0.006317, l3: 0.006256, l4: 0.012019, l5: 0.010524, l6: 0.013533

[epoch: 116/100000, batch:    58/  187, ite: 10839] train loss: 0.142289, tar: 0.014780 
l0: 0.007013, l1: 0.006159, l2: 0.007894, l3: 0.010429, l4: 0.010207, l5: 0.009992, l6: 0.010730

[epoch: 116/100000, batch:    60/  187, ite: 10840] train loss: 0.142194, tar: 0.014771 
l0: 0.007189, l1: 0.007563, l2: 0.007589, l3: 0.007748, l4: 0.013024, l5: 0.011193, l6: 0.010376

[epoch: 116/100000, batch:    62/  187, ite: 10841] train loss: 0.142102, tar: 0.014762 
l0: 0.006376, l1: 0.006979, l2: 0.006816, l3: 0.006312, l4: 0.009208, l5: 0.007955, l6: 0.009638

[epoch: 116/100000, batch:    64/  187, ite: 10842] train loss: 0.141996, tar: 0.014752 
l0: 0.015743, l1: 0.015584, l2: 0.016609, l3: 0.018704, l4: 0.029351, l5: 0.029575, l6: 0.028911

[epoch: 116/100000, batch:    66/  187, ite: 10843] train loss: 0.142011, tar: 0.014753 
l0: 0.006189, l1: 0.006453, l2: 0.007837, l3: 0.008371, l4: 0.010788, l5: 0.008919, l6: 0.011769

[epoch: 116/100000, batch:    68/  187, ite: 10844] train loss: 0.141914, tar: 0.014743 
l0: 0.007653, l1: 0.008194, l2: 0.007690, l3: 0.008340, l4: 0.010824, l5: 0.010832, l6: 0.013413

[epoch: 116/100000, batch:    70/  187, ite: 10845] train loss: 0.141825, tar: 0.014734 
l0: 0.009569, l1: 0.009665, l2: 0.016022, l3: 0.013819, l4: 0.019498, l5: 0.018009, l6: 0.017020

[epoch: 116/100000, batch:    72/  187, ite: 10846] train loss: 0.141780, tar: 0.014728 
l0: 0.009093, l1: 0.008541, l2: 0.009846, l3: 0.009881, l4: 0.016673, l5: 0.016739, l6: 0.020029

[epoch: 116/100000, batch:    74/  187, ite: 10847] train loss: 0.141720, tar: 0.014722 
l0: 0.006474, l1: 0.007379, l2: 0.008033, l3: 0.006588, l4: 0.010433, l5: 0.013776, l6: 0.015744

[epoch: 116/100000, batch:    76/  187, ite: 10848] train loss: 0.141634, tar: 0.014712 
l0: 0.013573, l1: 0.013120, l2: 0.012131, l3: 0.014184, l4: 0.033677, l5: 0.033222, l6: 0.027939

[epoch: 116/100000, batch:    78/  187, ite: 10849] train loss: 0.141641, tar: 0.014711 
l0: 0.007448, l1: 0.007657, l2: 0.007551, l3: 0.008106, l4: 0.017017, l5: 0.014569, l6: 0.017711

[epoch: 116/100000, batch:    80/  187, ite: 10850] train loss: 0.141568, tar: 0.014702 
l0: 0.007843, l1: 0.009518, l2: 0.008694, l3: 0.007788, l4: 0.006430, l5: 0.006172, l6: 0.006423

[epoch: 116/100000, batch:    82/  187, ite: 10851] train loss: 0.141464, tar: 0.014694 
l0: 0.007982, l1: 0.008167, l2: 0.010624, l3: 0.010535, l4: 0.019307, l5: 0.017638, l6: 0.022066

[epoch: 116/100000, batch:    84/  187, ite: 10852] train loss: 0.141411, tar: 0.014686 
l0: 0.004800, l1: 0.004681, l2: 0.005358, l3: 0.005285, l4: 0.010175, l5: 0.008981, l6: 0.009528

[epoch: 116/100000, batch:    86/  187, ite: 10853] train loss: 0.141303, tar: 0.014674 
l0: 0.007767, l1: 0.008543, l2: 0.008490, l3: 0.010216, l4: 0.009884, l5: 0.010309, l6: 0.011396

[epoch: 116/100000, batch:    88/  187, ite: 10854] train loss: 0.141215, tar: 0.014666 
l0: 0.007783, l1: 0.008393, l2: 0.011319, l3: 0.009894, l4: 0.012696, l5: 0.010765, l6: 0.012547

[epoch: 116/100000, batch:    90/  187, ite: 10855] train loss: 0.141136, tar: 0.014658 
l0: 0.008037, l1: 0.007935, l2: 0.010436, l3: 0.010208, l4: 0.010558, l5: 0.011100, l6: 0.012833

[epoch: 116/100000, batch:    92/  187, ite: 10856] train loss: 0.141054, tar: 0.014651 
l0: 0.005287, l1: 0.006002, l2: 0.006793, l3: 0.006303, l4: 0.009830, l5: 0.009622, l6: 0.010981

[epoch: 116/100000, batch:    94/  187, ite: 10857] train loss: 0.140953, tar: 0.014640 
l0: 0.007696, l1: 0.008219, l2: 0.008690, l3: 0.007357, l4: 0.012401, l5: 0.012915, l6: 0.012440

[epoch: 116/100000, batch:    96/  187, ite: 10858] train loss: 0.140870, tar: 0.014632 
l0: 0.009362, l1: 0.010848, l2: 0.008891, l3: 0.009442, l4: 0.018547, l5: 0.012565, l6: 0.016293

[epoch: 116/100000, batch:    98/  187, ite: 10859] train loss: 0.140807, tar: 0.014625 
l0: 0.011088, l1: 0.011726, l2: 0.014236, l3: 0.012447, l4: 0.019407, l5: 0.021239, l6: 0.019282

[epoch: 116/100000, batch:   100/  187, ite: 10860] train loss: 0.140770, tar: 0.014621 
l0: 0.006306, l1: 0.007022, l2: 0.007198, l3: 0.009840, l4: 0.032283, l5: 0.031504, l6: 0.021396

[epoch: 116/100000, batch:   102/  187, ite: 10861] train loss: 0.140741, tar: 0.014612 
l0: 0.010133, l1: 0.009979, l2: 0.007590, l3: 0.009897, l4: 0.012136, l5: 0.009655, l6: 0.015721

[epoch: 116/100000, batch:   104/  187, ite: 10862] train loss: 0.140665, tar: 0.014606 
l0: 0.008515, l1: 0.009352, l2: 0.009757, l3: 0.010281, l4: 0.013917, l5: 0.014261, l6: 0.018970

[epoch: 116/100000, batch:   106/  187, ite: 10863] train loss: 0.140600, tar: 0.014599 
l0: 0.005387, l1: 0.005665, l2: 0.007788, l3: 0.007220, l4: 0.014054, l5: 0.011755, l6: 0.015341

[epoch: 116/100000, batch:   108/  187, ite: 10864] train loss: 0.140515, tar: 0.014589 
l0: 0.005833, l1: 0.006389, l2: 0.008581, l3: 0.005853, l4: 0.025902, l5: 0.019175, l6: 0.015708

[epoch: 116/100000, batch:   110/  187, ite: 10865] train loss: 0.140454, tar: 0.014579 
l0: 0.004296, l1: 0.004452, l2: 0.005879, l3: 0.008003, l4: 0.022227, l5: 0.015556, l6: 0.010894

[epoch: 116/100000, batch:   112/  187, ite: 10866] train loss: 0.140374, tar: 0.014567 
l0: 0.008305, l1: 0.009226, l2: 0.009462, l3: 0.009305, l4: 0.016791, l5: 0.014856, l6: 0.014582

[epoch: 116/100000, batch:   114/  187, ite: 10867] train loss: 0.140307, tar: 0.014560 
l0: 0.011643, l1: 0.011174, l2: 0.015834, l3: 0.015052, l4: 0.022217, l5: 0.021464, l6: 0.022124

[epoch: 116/100000, batch:   116/  187, ite: 10868] train loss: 0.140283, tar: 0.014556 
l0: 0.007615, l1: 0.008073, l2: 0.006820, l3: 0.007283, l4: 0.011784, l5: 0.010543, l6: 0.013431

[epoch: 116/100000, batch:   118/  187, ite: 10869] train loss: 0.140197, tar: 0.014548 
l0: 0.010072, l1: 0.010846, l2: 0.009734, l3: 0.011093, l4: 0.018692, l5: 0.015809, l6: 0.016236

[epoch: 116/100000, batch:   120/  187, ite: 10870] train loss: 0.140142, tar: 0.014543 
l0: 0.010738, l1: 0.010966, l2: 0.010100, l3: 0.011307, l4: 0.018972, l5: 0.014644, l6: 0.015820

[epoch: 116/100000, batch:   122/  187, ite: 10871] train loss: 0.140088, tar: 0.014539 
l0: 0.004787, l1: 0.004810, l2: 0.005626, l3: 0.006969, l4: 0.011180, l5: 0.011642, l6: 0.012234

[epoch: 116/100000, batch:   124/  187, ite: 10872] train loss: 0.139993, tar: 0.014527 
l0: 0.006465, l1: 0.006299, l2: 0.006517, l3: 0.007492, l4: 0.010090, l5: 0.008355, l6: 0.012885

[epoch: 116/100000, batch:   126/  187, ite: 10873] train loss: 0.139899, tar: 0.014518 
l0: 0.006594, l1: 0.007451, l2: 0.007787, l3: 0.008779, l4: 0.011306, l5: 0.010238, l6: 0.009538

[epoch: 116/100000, batch:   128/  187, ite: 10874] train loss: 0.139810, tar: 0.014509 
l0: 0.011056, l1: 0.012219, l2: 0.010677, l3: 0.011050, l4: 0.013061, l5: 0.013404, l6: 0.014402

[epoch: 116/100000, batch:   130/  187, ite: 10875] train loss: 0.139748, tar: 0.014505 
l0: 0.010942, l1: 0.011120, l2: 0.010669, l3: 0.013914, l4: 0.024340, l5: 0.019743, l6: 0.020376

[epoch: 116/100000, batch:   132/  187, ite: 10876] train loss: 0.139715, tar: 0.014501 
l0: 0.010143, l1: 0.010129, l2: 0.010967, l3: 0.011099, l4: 0.021485, l5: 0.018869, l6: 0.020350

[epoch: 116/100000, batch:   134/  187, ite: 10877] train loss: 0.139673, tar: 0.014496 
l0: 0.008818, l1: 0.008771, l2: 0.009157, l3: 0.009457, l4: 0.011246, l5: 0.010561, l6: 0.013274

[epoch: 116/100000, batch:   136/  187, ite: 10878] train loss: 0.139596, tar: 0.014490 
l0: 0.009019, l1: 0.008797, l2: 0.009008, l3: 0.008800, l4: 0.017514, l5: 0.016694, l6: 0.017006

[epoch: 116/100000, batch:   138/  187, ite: 10879] train loss: 0.139535, tar: 0.014484 
l0: 0.009669, l1: 0.010155, l2: 0.010018, l3: 0.008611, l4: 0.014382, l5: 0.012372, l6: 0.016234

[epoch: 116/100000, batch:   140/  187, ite: 10880] train loss: 0.139469, tar: 0.014478 
l0: 0.008050, l1: 0.008438, l2: 0.008925, l3: 0.009654, l4: 0.007877, l5: 0.007381, l6: 0.008096

[epoch: 116/100000, batch:   142/  187, ite: 10881] train loss: 0.139377, tar: 0.014471 
l0: 0.008589, l1: 0.008146, l2: 0.008105, l3: 0.009391, l4: 0.011842, l5: 0.011491, l6: 0.016401

[epoch: 116/100000, batch:   144/  187, ite: 10882] train loss: 0.139303, tar: 0.014464 
l0: 0.008714, l1: 0.009722, l2: 0.009456, l3: 0.008413, l4: 0.013546, l5: 0.012010, l6: 0.012450

[epoch: 116/100000, batch:   146/  187, ite: 10883] train loss: 0.139230, tar: 0.014458 
l0: 0.010914, l1: 0.010839, l2: 0.010129, l3: 0.012640, l4: 0.016897, l5: 0.014456, l6: 0.012824

[epoch: 116/100000, batch:   148/  187, ite: 10884] train loss: 0.139173, tar: 0.014454 
l0: 0.004500, l1: 0.003966, l2: 0.003171, l3: 0.004020, l4: 0.011427, l5: 0.014863, l6: 0.014847

[epoch: 116/100000, batch:   150/  187, ite: 10885] train loss: 0.139079, tar: 0.014442 
l0: 0.007096, l1: 0.007851, l2: 0.007659, l3: 0.007757, l4: 0.016748, l5: 0.012422, l6: 0.011559

[epoch: 116/100000, batch:   152/  187, ite: 10886] train loss: 0.139003, tar: 0.014434 
l0: 0.008778, l1: 0.008595, l2: 0.008175, l3: 0.009806, l4: 0.017475, l5: 0.018811, l6: 0.018987

[epoch: 116/100000, batch:   154/  187, ite: 10887] train loss: 0.138948, tar: 0.014428 
l0: 0.005316, l1: 0.005451, l2: 0.007167, l3: 0.005947, l4: 0.009276, l5: 0.008329, l6: 0.010733

[epoch: 116/100000, batch:   156/  187, ite: 10888] train loss: 0.138851, tar: 0.014417 
l0: 0.006685, l1: 0.006591, l2: 0.007189, l3: 0.007080, l4: 0.015555, l5: 0.015662, l6: 0.016249

[epoch: 116/100000, batch:   158/  187, ite: 10889] train loss: 0.138779, tar: 0.014409 
l0: 0.011698, l1: 0.012879, l2: 0.011242, l3: 0.011855, l4: 0.019573, l5: 0.018438, l6: 0.019380

[epoch: 116/100000, batch:   160/  187, ite: 10890] train loss: 0.138741, tar: 0.014406 
l0: 0.009405, l1: 0.009665, l2: 0.008764, l3: 0.009731, l4: 0.018021, l5: 0.016726, l6: 0.022329

[epoch: 116/100000, batch:   162/  187, ite: 10891] train loss: 0.138691, tar: 0.014400 
l0: 0.007153, l1: 0.007719, l2: 0.008383, l3: 0.007788, l4: 0.019094, l5: 0.016879, l6: 0.013960

[epoch: 116/100000, batch:   164/  187, ite: 10892] train loss: 0.138627, tar: 0.014392 
l0: 0.006738, l1: 0.008031, l2: 0.009090, l3: 0.008475, l4: 0.017603, l5: 0.016862, l6: 0.017271

[epoch: 116/100000, batch:   166/  187, ite: 10893] train loss: 0.138566, tar: 0.014383 
l0: 0.011830, l1: 0.011699, l2: 0.014056, l3: 0.015072, l4: 0.023233, l5: 0.020795, l6: 0.019718

[epoch: 116/100000, batch:   168/  187, ite: 10894] train loss: 0.138541, tar: 0.014380 
l0: 0.009052, l1: 0.007901, l2: 0.009345, l3: 0.010702, l4: 0.023361, l5: 0.022091, l6: 0.025154

[epoch: 116/100000, batch:   170/  187, ite: 10895] train loss: 0.138506, tar: 0.014375 
l0: 0.007801, l1: 0.008245, l2: 0.008506, l3: 0.008252, l4: 0.020254, l5: 0.016034, l6: 0.019247

[epoch: 116/100000, batch:   172/  187, ite: 10896] train loss: 0.138450, tar: 0.014367 
l0: 0.007956, l1: 0.007826, l2: 0.009941, l3: 0.009098, l4: 0.015007, l5: 0.014161, l6: 0.014733

[epoch: 116/100000, batch:   174/  187, ite: 10897] train loss: 0.138384, tar: 0.014360 
l0: 0.011069, l1: 0.011497, l2: 0.011783, l3: 0.011239, l4: 0.017549, l5: 0.014820, l6: 0.016054

[epoch: 116/100000, batch:   176/  187, ite: 10898] train loss: 0.138334, tar: 0.014356 
l0: 0.010516, l1: 0.011057, l2: 0.012379, l3: 0.012989, l4: 0.016465, l5: 0.015506, l6: 0.018395

[epoch: 116/100000, batch:   178/  187, ite: 10899] train loss: 0.138289, tar: 0.014352 
l0: 0.008556, l1: 0.008808, l2: 0.009128, l3: 0.008871, l4: 0.016500, l5: 0.016203, l6: 0.017854

[epoch: 116/100000, batch:   180/  187, ite: 10900] train loss: 0.138230, tar: 0.014346 
l0: 0.006371, l1: 0.006160, l2: 0.006897, l3: 0.008057, l4: 0.017712, l5: 0.014083, l6: 0.015145

[epoch: 116/100000, batch:   182/  187, ite: 10901] train loss: 0.138160, tar: 0.014337 
l0: 0.010201, l1: 0.009757, l2: 0.011986, l3: 0.011427, l4: 0.020197, l5: 0.017980, l6: 0.024170

[epoch: 116/100000, batch:   184/  187, ite: 10902] train loss: 0.138124, tar: 0.014332 
l0: 0.010936, l1: 0.011397, l2: 0.011767, l3: 0.011728, l4: 0.018861, l5: 0.022358, l6: 0.025391

[epoch: 116/100000, batch:   186/  187, ite: 10903] train loss: 0.138095, tar: 0.014328 
l0: 0.005840, l1: 0.005758, l2: 0.007651, l3: 0.007640, l4: 0.018745, l5: 0.012897, l6: 0.015717

[epoch: 116/100000, batch:   188/  187, ite: 10904] train loss: 0.138025, tar: 0.014319 
l0: 0.007191, l1: 0.007500, l2: 0.008566, l3: 0.008562, l4: 0.019706, l5: 0.012655, l6: 0.009803

[epoch: 117/100000, batch:     2/  187, ite: 10905] train loss: 0.137954, tar: 0.014311 
l0: 0.011894, l1: 0.010895, l2: 0.010803, l3: 0.011835, l4: 0.021949, l5: 0.022769, l6: 0.026679

[epoch: 117/100000, batch:     4/  187, ite: 10906] train loss: 0.137930, tar: 0.014309 
l0: 0.007710, l1: 0.007810, l2: 0.009095, l3: 0.008068, l4: 0.010274, l5: 0.009884, l6: 0.010352

[epoch: 117/100000, batch:     6/  187, ite: 10907] train loss: 0.137848, tar: 0.014301 
l0: 0.008369, l1: 0.008965, l2: 0.010039, l3: 0.009130, l4: 0.011737, l5: 0.010498, l6: 0.010731

[epoch: 117/100000, batch:     8/  187, ite: 10908] train loss: 0.137773, tar: 0.014295 
l0: 0.008754, l1: 0.008984, l2: 0.009012, l3: 0.009227, l4: 0.021590, l5: 0.019486, l6: 0.017375

[epoch: 117/100000, batch:    10/  187, ite: 10909] train loss: 0.137725, tar: 0.014289 
l0: 0.005371, l1: 0.005785, l2: 0.005694, l3: 0.006480, l4: 0.010711, l5: 0.010098, l6: 0.010581

[epoch: 117/100000, batch:    12/  187, ite: 10910] train loss: 0.137634, tar: 0.014279 
l0: 0.004565, l1: 0.004932, l2: 0.005070, l3: 0.004660, l4: 0.009968, l5: 0.010318, l6: 0.008662

[epoch: 117/100000, batch:    14/  187, ite: 10911] train loss: 0.137536, tar: 0.014268 
l0: 0.007136, l1: 0.008386, l2: 0.008110, l3: 0.007221, l4: 0.010568, l5: 0.009602, l6: 0.010140

[epoch: 117/100000, batch:    16/  187, ite: 10912] train loss: 0.137452, tar: 0.014260 
l0: 0.011475, l1: 0.012052, l2: 0.014294, l3: 0.016227, l4: 0.013800, l5: 0.013930, l6: 0.011250

[epoch: 117/100000, batch:    18/  187, ite: 10913] train loss: 0.137403, tar: 0.014257 
l0: 0.005907, l1: 0.006546, l2: 0.006731, l3: 0.006902, l4: 0.013553, l5: 0.009744, l6: 0.011528

[epoch: 117/100000, batch:    20/  187, ite: 10914] train loss: 0.137320, tar: 0.014248 
l0: 0.010151, l1: 0.009910, l2: 0.010450, l3: 0.012156, l4: 0.020277, l5: 0.018691, l6: 0.020075

[epoch: 117/100000, batch:    22/  187, ite: 10915] train loss: 0.137281, tar: 0.014244 
l0: 0.002211, l1: 0.002628, l2: 0.002425, l3: 0.003109, l4: 0.004751, l5: 0.004383, l6: 0.005446

[epoch: 117/100000, batch:    24/  187, ite: 10916] train loss: 0.137158, tar: 0.014231 
l0: 0.004986, l1: 0.004405, l2: 0.006132, l3: 0.006480, l4: 0.013947, l5: 0.013744, l6: 0.013510

[epoch: 117/100000, batch:    26/  187, ite: 10917] train loss: 0.137077, tar: 0.014220 
l0: 0.008824, l1: 0.009501, l2: 0.010799, l3: 0.011177, l4: 0.018784, l5: 0.017087, l6: 0.016698

[epoch: 117/100000, batch:    28/  187, ite: 10918] train loss: 0.137029, tar: 0.014215 
l0: 0.008466, l1: 0.009084, l2: 0.008958, l3: 0.009309, l4: 0.010745, l5: 0.008812, l6: 0.010644

[epoch: 117/100000, batch:    30/  187, ite: 10919] train loss: 0.136952, tar: 0.014208 
l0: 0.013161, l1: 0.013353, l2: 0.011960, l3: 0.012839, l4: 0.029465, l5: 0.026127, l6: 0.021193

[epoch: 117/100000, batch:    32/  187, ite: 10920] train loss: 0.136942, tar: 0.014207 
l0: 0.015523, l1: 0.015685, l2: 0.014686, l3: 0.016340, l4: 0.025160, l5: 0.023067, l6: 0.027604

[epoch: 117/100000, batch:    34/  187, ite: 10921] train loss: 0.136944, tar: 0.014209 
l0: 0.005452, l1: 0.005319, l2: 0.004427, l3: 0.005099, l4: 0.008635, l5: 0.008802, l6: 0.008641

[epoch: 117/100000, batch:    36/  187, ite: 10922] train loss: 0.136845, tar: 0.014199 
l0: 0.006805, l1: 0.006939, l2: 0.008006, l3: 0.008329, l4: 0.011698, l5: 0.012484, l6: 0.013647

[epoch: 117/100000, batch:    38/  187, ite: 10923] train loss: 0.136771, tar: 0.014191 
l0: 0.010291, l1: 0.010299, l2: 0.011225, l3: 0.013008, l4: 0.021965, l5: 0.022685, l6: 0.022812

[epoch: 117/100000, batch:    40/  187, ite: 10924] train loss: 0.136744, tar: 0.014187 
l0: 0.009274, l1: 0.008991, l2: 0.009300, l3: 0.010372, l4: 0.025341, l5: 0.024504, l6: 0.031470

[epoch: 117/100000, batch:    42/  187, ite: 10925] train loss: 0.136725, tar: 0.014182 
l0: 0.004712, l1: 0.005122, l2: 0.006206, l3: 0.006110, l4: 0.006486, l5: 0.006069, l6: 0.007567

[epoch: 117/100000, batch:    44/  187, ite: 10926] train loss: 0.136623, tar: 0.014171 
l0: 0.009350, l1: 0.009920, l2: 0.011000, l3: 0.011620, l4: 0.012397, l5: 0.011550, l6: 0.010977

[epoch: 117/100000, batch:    46/  187, ite: 10927] train loss: 0.136559, tar: 0.014166 
l0: 0.010747, l1: 0.010913, l2: 0.010725, l3: 0.011117, l4: 0.015026, l5: 0.012496, l6: 0.015455

[epoch: 117/100000, batch:    48/  187, ite: 10928] train loss: 0.136505, tar: 0.014162 
l0: 0.008241, l1: 0.008289, l2: 0.009044, l3: 0.009145, l4: 0.013374, l5: 0.012375, l6: 0.014207

[epoch: 117/100000, batch:    50/  187, ite: 10929] train loss: 0.136438, tar: 0.014156 
l0: 0.008318, l1: 0.008615, l2: 0.008001, l3: 0.008323, l4: 0.014934, l5: 0.013987, l6: 0.016416

[epoch: 117/100000, batch:    52/  187, ite: 10930] train loss: 0.136376, tar: 0.014150 
l0: 0.004709, l1: 0.005258, l2: 0.007257, l3: 0.007440, l4: 0.012430, l5: 0.008123, l6: 0.005552

[epoch: 117/100000, batch:    54/  187, ite: 10931] train loss: 0.136284, tar: 0.014140 
l0: 0.005001, l1: 0.005245, l2: 0.006498, l3: 0.005351, l4: 0.008873, l5: 0.008627, l6: 0.007344

[epoch: 117/100000, batch:    56/  187, ite: 10932] train loss: 0.136188, tar: 0.014130 
l0: 0.007318, l1: 0.006403, l2: 0.008187, l3: 0.009334, l4: 0.015815, l5: 0.017882, l6: 0.015150

[epoch: 117/100000, batch:    58/  187, ite: 10933] train loss: 0.136128, tar: 0.014123 
l0: 0.004798, l1: 0.004729, l2: 0.005161, l3: 0.006069, l4: 0.013973, l5: 0.013816, l6: 0.014903

[epoch: 117/100000, batch:    60/  187, ite: 10934] train loss: 0.136050, tar: 0.014113 
l0: 0.006807, l1: 0.007060, l2: 0.006403, l3: 0.007204, l4: 0.009326, l5: 0.007897, l6: 0.011387

[epoch: 117/100000, batch:    62/  187, ite: 10935] train loss: 0.135965, tar: 0.014105 
l0: 0.008452, l1: 0.007711, l2: 0.009037, l3: 0.010394, l4: 0.015077, l5: 0.015750, l6: 0.016081

[epoch: 117/100000, batch:    64/  187, ite: 10936] train loss: 0.135908, tar: 0.014099 
l0: 0.007084, l1: 0.006861, l2: 0.008080, l3: 0.009658, l4: 0.019071, l5: 0.019406, l6: 0.019054

[epoch: 117/100000, batch:    66/  187, ite: 10937] train loss: 0.135858, tar: 0.014091 
l0: 0.010437, l1: 0.010815, l2: 0.012218, l3: 0.010992, l4: 0.018935, l5: 0.014989, l6: 0.019593

[epoch: 117/100000, batch:    68/  187, ite: 10938] train loss: 0.135817, tar: 0.014087 
l0: 0.006766, l1: 0.007178, l2: 0.006317, l3: 0.007358, l4: 0.010353, l5: 0.009299, l6: 0.009631

[epoch: 117/100000, batch:    70/  187, ite: 10939] train loss: 0.135733, tar: 0.014080 
l0: 0.005978, l1: 0.005922, l2: 0.005340, l3: 0.006429, l4: 0.011245, l5: 0.011103, l6: 0.011040

[epoch: 117/100000, batch:    72/  187, ite: 10940] train loss: 0.135650, tar: 0.014071 
l0: 0.007831, l1: 0.008227, l2: 0.006829, l3: 0.008721, l4: 0.017777, l5: 0.013155, l6: 0.011139

[epoch: 117/100000, batch:    74/  187, ite: 10941] train loss: 0.135584, tar: 0.014064 
l0: 0.003260, l1: 0.003443, l2: 0.004023, l3: 0.006139, l4: 0.013355, l5: 0.009347, l6: 0.009878

[epoch: 117/100000, batch:    76/  187, ite: 10942] train loss: 0.135492, tar: 0.014053 
l0: 0.003682, l1: 0.004543, l2: 0.002572, l3: 0.002672, l4: 0.002536, l5: 0.002507, l6: 0.005136

[epoch: 117/100000, batch:    78/  187, ite: 10943] train loss: 0.135374, tar: 0.014042 
l0: 0.013630, l1: 0.013333, l2: 0.012988, l3: 0.014732, l4: 0.016389, l5: 0.015885, l6: 0.015917

[epoch: 117/100000, batch:    80/  187, ite: 10944] train loss: 0.135339, tar: 0.014041 
l0: 0.009826, l1: 0.010720, l2: 0.010125, l3: 0.010640, l4: 0.015384, l5: 0.015341, l6: 0.016329

[epoch: 117/100000, batch:    82/  187, ite: 10945] train loss: 0.135290, tar: 0.014037 
l0: 0.008722, l1: 0.008692, l2: 0.009032, l3: 0.009654, l4: 0.013561, l5: 0.013749, l6: 0.015310

[epoch: 117/100000, batch:    84/  187, ite: 10946] train loss: 0.135230, tar: 0.014031 
l0: 0.004213, l1: 0.004457, l2: 0.004600, l3: 0.005591, l4: 0.010221, l5: 0.007605, l6: 0.008165

[epoch: 117/100000, batch:    86/  187, ite: 10947] train loss: 0.135134, tar: 0.014021 
l0: 0.004003, l1: 0.003796, l2: 0.005563, l3: 0.007044, l4: 0.006711, l5: 0.006843, l6: 0.008876

[epoch: 117/100000, batch:    88/  187, ite: 10948] train loss: 0.135037, tar: 0.014010 
l0: 0.005764, l1: 0.005509, l2: 0.007652, l3: 0.007374, l4: 0.011083, l5: 0.008712, l6: 0.010482

[epoch: 117/100000, batch:    90/  187, ite: 10949] train loss: 0.134954, tar: 0.014002 
l0: 0.005553, l1: 0.005498, l2: 0.004918, l3: 0.006693, l4: 0.013099, l5: 0.012040, l6: 0.013054

[epoch: 117/100000, batch:    92/  187, ite: 10950] train loss: 0.134876, tar: 0.013993 
l0: 0.010168, l1: 0.011584, l2: 0.011672, l3: 0.013188, l4: 0.015681, l5: 0.012173, l6: 0.012001

[epoch: 117/100000, batch:    94/  187, ite: 10951] train loss: 0.134825, tar: 0.013989 
l0: 0.005026, l1: 0.005450, l2: 0.005799, l3: 0.005539, l4: 0.009395, l5: 0.006935, l6: 0.009577

[epoch: 117/100000, batch:    96/  187, ite: 10952] train loss: 0.134734, tar: 0.013979 
l0: 0.004399, l1: 0.004509, l2: 0.004171, l3: 0.003541, l4: 0.011998, l5: 0.013794, l6: 0.011678

[epoch: 117/100000, batch:    98/  187, ite: 10953] train loss: 0.134649, tar: 0.013969 
l0: 0.006207, l1: 0.008278, l2: 0.007074, l3: 0.007714, l4: 0.008502, l5: 0.007645, l6: 0.009887

[epoch: 117/100000, batch:   100/  187, ite: 10954] train loss: 0.134566, tar: 0.013961 
l0: 0.006864, l1: 0.007326, l2: 0.006011, l3: 0.006150, l4: 0.012534, l5: 0.013856, l6: 0.013411

[epoch: 117/100000, batch:   102/  187, ite: 10955] train loss: 0.134494, tar: 0.013954 
l0: 0.007412, l1: 0.007814, l2: 0.008947, l3: 0.009674, l4: 0.016338, l5: 0.013801, l6: 0.013603

[epoch: 117/100000, batch:   104/  187, ite: 10956] train loss: 0.134435, tar: 0.013947 
l0: 0.006767, l1: 0.006758, l2: 0.009318, l3: 0.010097, l4: 0.016274, l5: 0.012335, l6: 0.013128

[epoch: 117/100000, batch:   106/  187, ite: 10957] train loss: 0.134372, tar: 0.013939 
l0: 0.009935, l1: 0.010326, l2: 0.011745, l3: 0.011632, l4: 0.022884, l5: 0.017533, l6: 0.017108

[epoch: 117/100000, batch:   108/  187, ite: 10958] train loss: 0.134338, tar: 0.013935 
l0: 0.008307, l1: 0.008471, l2: 0.008473, l3: 0.007038, l4: 0.013037, l5: 0.012742, l6: 0.013132

[epoch: 117/100000, batch:   110/  187, ite: 10959] train loss: 0.134272, tar: 0.013929 
l0: 0.007812, l1: 0.007899, l2: 0.009755, l3: 0.009087, l4: 0.011990, l5: 0.011626, l6: 0.014733

[epoch: 117/100000, batch:   112/  187, ite: 10960] train loss: 0.134208, tar: 0.013923 
l0: 0.008746, l1: 0.008638, l2: 0.009034, l3: 0.009086, l4: 0.011017, l5: 0.011185, l6: 0.013852

[epoch: 117/100000, batch:   114/  187, ite: 10961] train loss: 0.134143, tar: 0.013918 
l0: 0.007948, l1: 0.008791, l2: 0.012057, l3: 0.007364, l4: 0.019969, l5: 0.020089, l6: 0.014995

[epoch: 117/100000, batch:   116/  187, ite: 10962] train loss: 0.134098, tar: 0.013911 
l0: 0.005983, l1: 0.007125, l2: 0.007236, l3: 0.005388, l4: 0.018182, l5: 0.013789, l6: 0.011188

[epoch: 117/100000, batch:   118/  187, ite: 10963] train loss: 0.134031, tar: 0.013903 
l0: 0.005259, l1: 0.005183, l2: 0.005316, l3: 0.006553, l4: 0.015976, l5: 0.013507, l6: 0.013366

[epoch: 117/100000, batch:   120/  187, ite: 10964] train loss: 0.133959, tar: 0.013894 
l0: 0.002688, l1: 0.002885, l2: 0.003855, l3: 0.003520, l4: 0.007447, l5: 0.007243, l6: 0.008156

[epoch: 117/100000, batch:   122/  187, ite: 10965] train loss: 0.133857, tar: 0.013883 
l0: 0.005915, l1: 0.005743, l2: 0.007588, l3: 0.006566, l4: 0.010062, l5: 0.010339, l6: 0.011402

[epoch: 117/100000, batch:   124/  187, ite: 10966] train loss: 0.133778, tar: 0.013874 
l0: 0.006228, l1: 0.006215, l2: 0.007080, l3: 0.007752, l4: 0.016619, l5: 0.013646, l6: 0.011343

[epoch: 117/100000, batch:   126/  187, ite: 10967] train loss: 0.133711, tar: 0.013866 
l0: 0.011332, l1: 0.011801, l2: 0.012958, l3: 0.012565, l4: 0.018611, l5: 0.019174, l6: 0.020584

[epoch: 117/100000, batch:   128/  187, ite: 10968] train loss: 0.133684, tar: 0.013864 
l0: 0.008288, l1: 0.008177, l2: 0.009189, l3: 0.009550, l4: 0.014502, l5: 0.014834, l6: 0.016193

[epoch: 117/100000, batch:   130/  187, ite: 10969] train loss: 0.133629, tar: 0.013858 
l0: 0.008313, l1: 0.007974, l2: 0.007681, l3: 0.008174, l4: 0.009496, l5: 0.009406, l6: 0.013681

[epoch: 117/100000, batch:   132/  187, ite: 10970] train loss: 0.133558, tar: 0.013852 
l0: 0.003890, l1: 0.004172, l2: 0.004247, l3: 0.003936, l4: 0.008110, l5: 0.008584, l6: 0.010939

[epoch: 117/100000, batch:   134/  187, ite: 10971] train loss: 0.133466, tar: 0.013842 
l0: 0.003155, l1: 0.003092, l2: 0.004754, l3: 0.004302, l4: 0.009801, l5: 0.008396, l6: 0.008104

[epoch: 117/100000, batch:   136/  187, ite: 10972] train loss: 0.133371, tar: 0.013831 
l0: 0.007444, l1: 0.008072, l2: 0.007517, l3: 0.007880, l4: 0.012194, l5: 0.011586, l6: 0.011553

[epoch: 117/100000, batch:   138/  187, ite: 10973] train loss: 0.133302, tar: 0.013825 
l0: 0.005984, l1: 0.005800, l2: 0.005924, l3: 0.007063, l4: 0.013690, l5: 0.012298, l6: 0.014708

[epoch: 117/100000, batch:   140/  187, ite: 10974] train loss: 0.133233, tar: 0.013816 
l0: 0.005783, l1: 0.005610, l2: 0.006075, l3: 0.006989, l4: 0.010679, l5: 0.010460, l6: 0.013263

[epoch: 117/100000, batch:   142/  187, ite: 10975] train loss: 0.133156, tar: 0.013808 
l0: 0.007113, l1: 0.007801, l2: 0.008049, l3: 0.008612, l4: 0.010667, l5: 0.009325, l6: 0.010416

[epoch: 117/100000, batch:   144/  187, ite: 10976] train loss: 0.133083, tar: 0.013801 
l0: 0.003582, l1: 0.004235, l2: 0.004199, l3: 0.004020, l4: 0.008815, l5: 0.006471, l6: 0.007129

[epoch: 117/100000, batch:   146/  187, ite: 10977] train loss: 0.132987, tar: 0.013791 
l0: 0.008486, l1: 0.009386, l2: 0.009249, l3: 0.009550, l4: 0.012380, l5: 0.010915, l6: 0.011072

[epoch: 117/100000, batch:   148/  187, ite: 10978] train loss: 0.132923, tar: 0.013785 
l0: 0.005252, l1: 0.005207, l2: 0.005487, l3: 0.005784, l4: 0.010587, l5: 0.011063, l6: 0.012107

[epoch: 117/100000, batch:   150/  187, ite: 10979] train loss: 0.132844, tar: 0.013777 
l0: 0.007995, l1: 0.008059, l2: 0.009948, l3: 0.010560, l4: 0.016233, l5: 0.015316, l6: 0.015948

[epoch: 117/100000, batch:   152/  187, ite: 10980] train loss: 0.132794, tar: 0.013771 
l0: 0.009940, l1: 0.009846, l2: 0.009721, l3: 0.009684, l4: 0.015344, l5: 0.015369, l6: 0.016844

[epoch: 117/100000, batch:   154/  187, ite: 10981] train loss: 0.132747, tar: 0.013767 
l0: 0.004962, l1: 0.005538, l2: 0.006671, l3: 0.006248, l4: 0.008043, l5: 0.007239, l6: 0.007755

[epoch: 117/100000, batch:   156/  187, ite: 10982] train loss: 0.132659, tar: 0.013758 
l0: 0.009200, l1: 0.009727, l2: 0.009522, l3: 0.009244, l4: 0.017683, l5: 0.015532, l6: 0.018489

[epoch: 117/100000, batch:   158/  187, ite: 10983] train loss: 0.132615, tar: 0.013753 
l0: 0.010932, l1: 0.011555, l2: 0.011961, l3: 0.011752, l4: 0.012573, l5: 0.012824, l6: 0.013395

[epoch: 117/100000, batch:   160/  187, ite: 10984] train loss: 0.132567, tar: 0.013750 
l0: 0.006205, l1: 0.005941, l2: 0.006654, l3: 0.007064, l4: 0.011084, l5: 0.011382, l6: 0.012245

[epoch: 117/100000, batch:   162/  187, ite: 10985] train loss: 0.132494, tar: 0.013743 
l0: 0.007397, l1: 0.008092, l2: 0.007561, l3: 0.007818, l4: 0.009041, l5: 0.006771, l6: 0.009200

[epoch: 117/100000, batch:   164/  187, ite: 10986] train loss: 0.132416, tar: 0.013736 
l0: 0.006533, l1: 0.007152, l2: 0.006476, l3: 0.006580, l4: 0.010046, l5: 0.010386, l6: 0.013886

[epoch: 117/100000, batch:   166/  187, ite: 10987] train loss: 0.132344, tar: 0.013729 
l0: 0.006394, l1: 0.007039, l2: 0.007067, l3: 0.007428, l4: 0.009937, l5: 0.008752, l6: 0.009894

[epoch: 117/100000, batch:   168/  187, ite: 10988] train loss: 0.132267, tar: 0.013722 
l0: 0.009134, l1: 0.008336, l2: 0.009795, l3: 0.012726, l4: 0.021069, l5: 0.022928, l6: 0.027545

[epoch: 117/100000, batch:   170/  187, ite: 10989] train loss: 0.132246, tar: 0.013717 
l0: 0.007099, l1: 0.007091, l2: 0.009069, l3: 0.009427, l4: 0.021012, l5: 0.017219, l6: 0.016722

[epoch: 117/100000, batch:   172/  187, ite: 10990] train loss: 0.132201, tar: 0.013710 
l0: 0.007350, l1: 0.007294, l2: 0.007601, l3: 0.008955, l4: 0.021569, l5: 0.020786, l6: 0.020198

[epoch: 117/100000, batch:   174/  187, ite: 10991] train loss: 0.132162, tar: 0.013704 
l0: 0.003871, l1: 0.004065, l2: 0.004072, l3: 0.003803, l4: 0.006697, l5: 0.006621, l6: 0.007875

[epoch: 117/100000, batch:   176/  187, ite: 10992] train loss: 0.132066, tar: 0.013694 
l0: 0.004934, l1: 0.006146, l2: 0.006074, l3: 0.005361, l4: 0.010668, l5: 0.009934, l6: 0.009741

[epoch: 117/100000, batch:   178/  187, ite: 10993] train loss: 0.131987, tar: 0.013685 
l0: 0.008196, l1: 0.007799, l2: 0.009501, l3: 0.009407, l4: 0.017265, l5: 0.015314, l6: 0.019085

[epoch: 117/100000, batch:   180/  187, ite: 10994] train loss: 0.131941, tar: 0.013680 
l0: 0.011919, l1: 0.012300, l2: 0.015071, l3: 0.013425, l4: 0.022935, l5: 0.020108, l6: 0.020379

[epoch: 117/100000, batch:   182/  187, ite: 10995] train loss: 0.131925, tar: 0.013678 
l0: 0.007476, l1: 0.007778, l2: 0.008562, l3: 0.008378, l4: 0.013733, l5: 0.011160, l6: 0.014136

[epoch: 117/100000, batch:   184/  187, ite: 10996] train loss: 0.131864, tar: 0.013672 
l0: 0.013686, l1: 0.013908, l2: 0.014686, l3: 0.014948, l4: 0.016824, l5: 0.015145, l6: 0.019893

[epoch: 117/100000, batch:   186/  187, ite: 10997] train loss: 0.131841, tar: 0.013672 
l0: 0.006695, l1: 0.007101, l2: 0.007084, l3: 0.007663, l4: 0.010898, l5: 0.010010, l6: 0.010753

[epoch: 117/100000, batch:   188/  187, ite: 10998] train loss: 0.131770, tar: 0.013665 
l0: 0.013113, l1: 0.013087, l2: 0.014016, l3: 0.012067, l4: 0.021279, l5: 0.016985, l6: 0.018170

[epoch: 118/100000, batch:     2/  187, ite: 10999] train loss: 0.131746, tar: 0.013664 
l0: 0.005818, l1: 0.005913, l2: 0.006806, l3: 0.007698, l4: 0.011261, l5: 0.010782, l6: 0.010665

[epoch: 118/100000, batch:     4/  187, ite: 11000] train loss: 0.131674, tar: 0.013656 
l0: 0.006358, l1: 0.007387, l2: 0.006213, l3: 0.005067, l4: 0.007871, l5: 0.007463, l6: 0.009175

[epoch: 118/100000, batch:     6/  187, ite: 11001] train loss: 0.131592, tar: 0.013649 
l0: 0.005125, l1: 0.005647, l2: 0.008163, l3: 0.007693, l4: 0.009736, l5: 0.007577, l6: 0.006960

[epoch: 118/100000, batch:     8/  187, ite: 11002] train loss: 0.131511, tar: 0.013640 
l0: 0.005878, l1: 0.005767, l2: 0.007129, l3: 0.006836, l4: 0.010192, l5: 0.014083, l6: 0.012945

[epoch: 118/100000, batch:    10/  187, ite: 11003] train loss: 0.131443, tar: 0.013633 
l0: 0.005665, l1: 0.006402, l2: 0.006985, l3: 0.005588, l4: 0.011036, l5: 0.009725, l6: 0.007697

[epoch: 118/100000, batch:    12/  187, ite: 11004] train loss: 0.131365, tar: 0.013625 
l0: 0.006364, l1: 0.006595, l2: 0.006976, l3: 0.007598, l4: 0.011419, l5: 0.011795, l6: 0.013435

[epoch: 118/100000, batch:    14/  187, ite: 11005] train loss: 0.131298, tar: 0.013618 
l0: 0.010228, l1: 0.010976, l2: 0.010898, l3: 0.009179, l4: 0.014859, l5: 0.012591, l6: 0.016832

[epoch: 118/100000, batch:    16/  187, ite: 11006] train loss: 0.131252, tar: 0.013614 
l0: 0.008687, l1: 0.008485, l2: 0.009903, l3: 0.010416, l4: 0.011151, l5: 0.010983, l6: 0.015433

[epoch: 118/100000, batch:    18/  187, ite: 11007] train loss: 0.131196, tar: 0.013609 
l0: 0.003822, l1: 0.004096, l2: 0.004409, l3: 0.004717, l4: 0.009120, l5: 0.007090, l6: 0.006958

[epoch: 118/100000, batch:    20/  187, ite: 11008] train loss: 0.131106, tar: 0.013600 
l0: 0.004987, l1: 0.005315, l2: 0.006121, l3: 0.005498, l4: 0.013260, l5: 0.013048, l6: 0.015134

[epoch: 118/100000, batch:    22/  187, ite: 11009] train loss: 0.131039, tar: 0.013591 
l0: 0.006047, l1: 0.006538, l2: 0.006321, l3: 0.006200, l4: 0.009979, l5: 0.009433, l6: 0.011757

[epoch: 118/100000, batch:    24/  187, ite: 11010] train loss: 0.130965, tar: 0.013584 
l0: 0.005101, l1: 0.004987, l2: 0.006102, l3: 0.006852, l4: 0.012851, l5: 0.011234, l6: 0.010312

[epoch: 118/100000, batch:    26/  187, ite: 11011] train loss: 0.130892, tar: 0.013575 
l0: 0.006109, l1: 0.006699, l2: 0.006744, l3: 0.006689, l4: 0.011148, l5: 0.011075, l6: 0.014232

[epoch: 118/100000, batch:    28/  187, ite: 11012] train loss: 0.130825, tar: 0.013568 
l0: 0.006506, l1: 0.006140, l2: 0.006656, l3: 0.008243, l4: 0.011147, l5: 0.008865, l6: 0.013717

[epoch: 118/100000, batch:    30/  187, ite: 11013] train loss: 0.130756, tar: 0.013561 
l0: 0.004634, l1: 0.004954, l2: 0.005447, l3: 0.005634, l4: 0.008562, l5: 0.008566, l6: 0.007902

[epoch: 118/100000, batch:    32/  187, ite: 11014] train loss: 0.130672, tar: 0.013552 
l0: 0.011367, l1: 0.012384, l2: 0.012811, l3: 0.012361, l4: 0.013061, l5: 0.010147, l6: 0.011805

[epoch: 118/100000, batch:    34/  187, ite: 11015] train loss: 0.130626, tar: 0.013550 
l0: 0.010345, l1: 0.010846, l2: 0.011384, l3: 0.010966, l4: 0.014173, l5: 0.010941, l6: 0.015698

[epoch: 118/100000, batch:    36/  187, ite: 11016] train loss: 0.130581, tar: 0.013547 
l0: 0.003620, l1: 0.004146, l2: 0.004368, l3: 0.005183, l4: 0.005772, l5: 0.004927, l6: 0.006045

[epoch: 118/100000, batch:    38/  187, ite: 11017] train loss: 0.130486, tar: 0.013537 
l0: 0.006507, l1: 0.006876, l2: 0.006938, l3: 0.006023, l4: 0.007190, l5: 0.007837, l6: 0.008589

[epoch: 118/100000, batch:    40/  187, ite: 11018] train loss: 0.130407, tar: 0.013530 
l0: 0.005946, l1: 0.005953, l2: 0.005919, l3: 0.007270, l4: 0.008494, l5: 0.005826, l6: 0.007569

[epoch: 118/100000, batch:    42/  187, ite: 11019] train loss: 0.130325, tar: 0.013523 
l0: 0.006746, l1: 0.007540, l2: 0.007964, l3: 0.007782, l4: 0.009863, l5: 0.007957, l6: 0.009416

[epoch: 118/100000, batch:    44/  187, ite: 11020] train loss: 0.130253, tar: 0.013516 
l0: 0.007315, l1: 0.007294, l2: 0.008462, l3: 0.008031, l4: 0.010467, l5: 0.009505, l6: 0.012532

[epoch: 118/100000, batch:    46/  187, ite: 11021] train loss: 0.130188, tar: 0.013510 
l0: 0.004693, l1: 0.004328, l2: 0.006647, l3: 0.006117, l4: 0.010385, l5: 0.010100, l6: 0.008529

[epoch: 118/100000, batch:    48/  187, ite: 11022] train loss: 0.130110, tar: 0.013501 
l0: 0.009187, l1: 0.009160, l2: 0.011220, l3: 0.011351, l4: 0.015491, l5: 0.015529, l6: 0.015088

[epoch: 118/100000, batch:    50/  187, ite: 11023] train loss: 0.130068, tar: 0.013497 
l0: 0.007612, l1: 0.007561, l2: 0.008202, l3: 0.009889, l4: 0.011910, l5: 0.011999, l6: 0.017325

[epoch: 118/100000, batch:    52/  187, ite: 11024] train loss: 0.130014, tar: 0.013491 
l0: 0.010003, l1: 0.010016, l2: 0.011114, l3: 0.016760, l4: 0.009252, l5: 0.009283, l6: 0.007709

[epoch: 118/100000, batch:    54/  187, ite: 11025] train loss: 0.129959, tar: 0.013488 
l0: 0.012834, l1: 0.012914, l2: 0.012238, l3: 0.012973, l4: 0.028950, l5: 0.026063, l6: 0.021375

[epoch: 118/100000, batch:    56/  187, ite: 11026] train loss: 0.129957, tar: 0.013487 
l0: 0.008920, l1: 0.009189, l2: 0.009184, l3: 0.008961, l4: 0.014535, l5: 0.014408, l6: 0.016419

[epoch: 118/100000, batch:    58/  187, ite: 11027] train loss: 0.129910, tar: 0.013483 
l0: 0.009993, l1: 0.011038, l2: 0.011842, l3: 0.011110, l4: 0.018197, l5: 0.013704, l6: 0.017366

[epoch: 118/100000, batch:    60/  187, ite: 11028] train loss: 0.129874, tar: 0.013479 
l0: 0.007572, l1: 0.007919, l2: 0.007949, l3: 0.006658, l4: 0.009942, l5: 0.010154, l6: 0.011143

[epoch: 118/100000, batch:    62/  187, ite: 11029] train loss: 0.129808, tar: 0.013474 
l0: 0.005545, l1: 0.006137, l2: 0.005070, l3: 0.005595, l4: 0.009752, l5: 0.009590, l6: 0.009181

[epoch: 118/100000, batch:    64/  187, ite: 11030] train loss: 0.129731, tar: 0.013466 
l0: 0.006778, l1: 0.007953, l2: 0.007988, l3: 0.007818, l4: 0.013855, l5: 0.012406, l6: 0.015924

[epoch: 118/100000, batch:    66/  187, ite: 11031] train loss: 0.129676, tar: 0.013460 
l0: 0.009475, l1: 0.008665, l2: 0.010368, l3: 0.011740, l4: 0.019621, l5: 0.018502, l6: 0.020124

[epoch: 118/100000, batch:    68/  187, ite: 11032] train loss: 0.129645, tar: 0.013456 
l0: 0.009350, l1: 0.009714, l2: 0.010948, l3: 0.011865, l4: 0.016026, l5: 0.016176, l6: 0.015160

[epoch: 118/100000, batch:    70/  187, ite: 11033] train loss: 0.129606, tar: 0.013452 
l0: 0.009148, l1: 0.008449, l2: 0.013567, l3: 0.013358, l4: 0.012290, l5: 0.014177, l6: 0.015440

[epoch: 118/100000, batch:    72/  187, ite: 11034] train loss: 0.129565, tar: 0.013448 
l0: 0.007576, l1: 0.008310, l2: 0.010016, l3: 0.009359, l4: 0.011390, l5: 0.011966, l6: 0.012937

[epoch: 118/100000, batch:    74/  187, ite: 11035] train loss: 0.129508, tar: 0.013442 
l0: 0.005431, l1: 0.005487, l2: 0.005294, l3: 0.005139, l4: 0.006093, l5: 0.006018, l6: 0.009083

[epoch: 118/100000, batch:    76/  187, ite: 11036] train loss: 0.129425, tar: 0.013434 
l0: 0.005546, l1: 0.005907, l2: 0.005757, l3: 0.005691, l4: 0.012346, l5: 0.010755, l6: 0.011032

[epoch: 118/100000, batch:    78/  187, ite: 11037] train loss: 0.129355, tar: 0.013427 
l0: 0.014136, l1: 0.013841, l2: 0.014774, l3: 0.015205, l4: 0.021968, l5: 0.023180, l6: 0.024143

[epoch: 118/100000, batch:    80/  187, ite: 11038] train loss: 0.129353, tar: 0.013427 
l0: 0.006427, l1: 0.007044, l2: 0.008127, l3: 0.007756, l4: 0.010273, l5: 0.009669, l6: 0.007803

[epoch: 118/100000, batch:    82/  187, ite: 11039] train loss: 0.129283, tar: 0.013420 
l0: 0.003101, l1: 0.003966, l2: 0.003664, l3: 0.002956, l4: 0.009025, l5: 0.005781, l6: 0.004884

[epoch: 118/100000, batch:    84/  187, ite: 11040] train loss: 0.129191, tar: 0.013411 
l0: 0.005466, l1: 0.005790, l2: 0.005670, l3: 0.005686, l4: 0.007716, l5: 0.007283, l6: 0.009552

[epoch: 118/100000, batch:    86/  187, ite: 11041] train loss: 0.129112, tar: 0.013403 
l0: 0.008772, l1: 0.009517, l2: 0.009623, l3: 0.009133, l4: 0.011781, l5: 0.009839, l6: 0.015043

[epoch: 118/100000, batch:    88/  187, ite: 11042] train loss: 0.129059, tar: 0.013398 
l0: 0.007075, l1: 0.007136, l2: 0.007746, l3: 0.007474, l4: 0.015391, l5: 0.017172, l6: 0.018314

[epoch: 118/100000, batch:    90/  187, ite: 11043] train loss: 0.129012, tar: 0.013392 
l0: 0.009806, l1: 0.010540, l2: 0.009212, l3: 0.010859, l4: 0.021998, l5: 0.015684, l6: 0.017994

[epoch: 118/100000, batch:    92/  187, ite: 11044] train loss: 0.128981, tar: 0.013389 
l0: 0.008245, l1: 0.008867, l2: 0.009161, l3: 0.007141, l4: 0.010711, l5: 0.007277, l6: 0.010940

[epoch: 118/100000, batch:    94/  187, ite: 11045] train loss: 0.128917, tar: 0.013384 
l0: 0.012841, l1: 0.012831, l2: 0.012774, l3: 0.012890, l4: 0.026743, l5: 0.021718, l6: 0.024374

[epoch: 118/100000, batch:    96/  187, ite: 11046] train loss: 0.128912, tar: 0.013384 
l0: 0.006308, l1: 0.006225, l2: 0.006371, l3: 0.007323, l4: 0.012170, l5: 0.011842, l6: 0.011992

[epoch: 118/100000, batch:    98/  187, ite: 11047] train loss: 0.128849, tar: 0.013377 
l0: 0.005398, l1: 0.005401, l2: 0.005331, l3: 0.006100, l4: 0.014272, l5: 0.012820, l6: 0.009822

[epoch: 118/100000, batch:   100/  187, ite: 11048] train loss: 0.128782, tar: 0.013369 
l0: 0.006231, l1: 0.005880, l2: 0.007469, l3: 0.007526, l4: 0.013178, l5: 0.014089, l6: 0.014959

[epoch: 118/100000, batch:   102/  187, ite: 11049] train loss: 0.128726, tar: 0.013362 
l0: 0.007468, l1: 0.007549, l2: 0.008127, l3: 0.008347, l4: 0.011353, l5: 0.011124, l6: 0.012294

[epoch: 118/100000, batch:   104/  187, ite: 11050] train loss: 0.128666, tar: 0.013357 
l0: 0.003239, l1: 0.003283, l2: 0.003370, l3: 0.003388, l4: 0.004754, l5: 0.006472, l6: 0.006986

[epoch: 118/100000, batch:   106/  187, ite: 11051] train loss: 0.128574, tar: 0.013347 
l0: 0.008062, l1: 0.008549, l2: 0.008022, l3: 0.008937, l4: 0.014383, l5: 0.011996, l6: 0.012378

[epoch: 118/100000, batch:   108/  187, ite: 11052] train loss: 0.128520, tar: 0.013342 
l0: 0.005126, l1: 0.005436, l2: 0.005829, l3: 0.005559, l4: 0.012111, l5: 0.011519, l6: 0.011860

[epoch: 118/100000, batch:   110/  187, ite: 11053] train loss: 0.128453, tar: 0.013334 
l0: 0.005646, l1: 0.005761, l2: 0.007249, l3: 0.008098, l4: 0.012589, l5: 0.010894, l6: 0.010824

[epoch: 118/100000, batch:   112/  187, ite: 11054] train loss: 0.128389, tar: 0.013327 
l0: 0.009323, l1: 0.010416, l2: 0.011275, l3: 0.008864, l4: 0.009978, l5: 0.011572, l6: 0.011379

[epoch: 118/100000, batch:   114/  187, ite: 11055] train loss: 0.128336, tar: 0.013323 
l0: 0.008964, l1: 0.010750, l2: 0.013217, l3: 0.014288, l4: 0.011195, l5: 0.011657, l6: 0.014205

[epoch: 118/100000, batch:   116/  187, ite: 11056] train loss: 0.128294, tar: 0.013319 
l0: 0.005952, l1: 0.005716, l2: 0.005699, l3: 0.007039, l4: 0.015223, l5: 0.015317, l6: 0.015284

[epoch: 118/100000, batch:   118/  187, ite: 11057] train loss: 0.128239, tar: 0.013312 
l0: 0.005114, l1: 0.005377, l2: 0.004539, l3: 0.004873, l4: 0.008996, l5: 0.009181, l6: 0.008451

[epoch: 118/100000, batch:   120/  187, ite: 11058] train loss: 0.128162, tar: 0.013304 
l0: 0.004973, l1: 0.005482, l2: 0.005634, l3: 0.005972, l4: 0.010508, l5: 0.008222, l6: 0.008182

[epoch: 118/100000, batch:   122/  187, ite: 11059] train loss: 0.128087, tar: 0.013296 
l0: 0.004478, l1: 0.004353, l2: 0.003984, l3: 0.004178, l4: 0.006770, l5: 0.006291, l6: 0.009252

[epoch: 118/100000, batch:   124/  187, ite: 11060] train loss: 0.128004, tar: 0.013288 
l0: 0.006663, l1: 0.007231, l2: 0.008375, l3: 0.007866, l4: 0.014046, l5: 0.013206, l6: 0.014863

[epoch: 118/100000, batch:   126/  187, ite: 11061] train loss: 0.127951, tar: 0.013282 
l0: 0.008335, l1: 0.008514, l2: 0.010399, l3: 0.010211, l4: 0.015595, l5: 0.013965, l6: 0.013676

[epoch: 118/100000, batch:   128/  187, ite: 11062] train loss: 0.127907, tar: 0.013277 
l0: 0.008650, l1: 0.009067, l2: 0.010307, l3: 0.009555, l4: 0.019732, l5: 0.015273, l6: 0.016732

[epoch: 118/100000, batch:   130/  187, ite: 11063] train loss: 0.127870, tar: 0.013273 
l0: 0.009497, l1: 0.010329, l2: 0.009063, l3: 0.007755, l4: 0.010195, l5: 0.010619, l6: 0.010036

[epoch: 118/100000, batch:   132/  187, ite: 11064] train loss: 0.127813, tar: 0.013269 
l0: 0.006280, l1: 0.007043, l2: 0.006102, l3: 0.005997, l4: 0.010473, l5: 0.009907, l6: 0.009160

[epoch: 118/100000, batch:   134/  187, ite: 11065] train loss: 0.127745, tar: 0.013263 
l0: 0.003687, l1: 0.003818, l2: 0.004275, l3: 0.004889, l4: 0.006043, l5: 0.007110, l6: 0.008271

[epoch: 118/100000, batch:   136/  187, ite: 11066] train loss: 0.127661, tar: 0.013254 
l0: 0.006621, l1: 0.008216, l2: 0.007294, l3: 0.007572, l4: 0.012856, l5: 0.011387, l6: 0.010202

[epoch: 118/100000, batch:   138/  187, ite: 11067] train loss: 0.127601, tar: 0.013248 
l0: 0.010593, l1: 0.010213, l2: 0.009863, l3: 0.010370, l4: 0.017359, l5: 0.018900, l6: 0.020406

[epoch: 118/100000, batch:   140/  187, ite: 11068] train loss: 0.127573, tar: 0.013245 
l0: 0.010143, l1: 0.009457, l2: 0.008828, l3: 0.011438, l4: 0.020097, l5: 0.019580, l6: 0.019336

[epoch: 118/100000, batch:   142/  187, ite: 11069] train loss: 0.127547, tar: 0.013242 
l0: 0.010386, l1: 0.011222, l2: 0.010579, l3: 0.009641, l4: 0.014035, l5: 0.013860, l6: 0.014937

[epoch: 118/100000, batch:   144/  187, ite: 11070] train loss: 0.127507, tar: 0.013240 
l0: 0.003946, l1: 0.004415, l2: 0.004275, l3: 0.004600, l4: 0.007479, l5: 0.006899, l6: 0.008833

[epoch: 118/100000, batch:   146/  187, ite: 11071] train loss: 0.127425, tar: 0.013231 
l0: 0.011827, l1: 0.011422, l2: 0.012168, l3: 0.011509, l4: 0.011051, l5: 0.013190, l6: 0.013808

[epoch: 118/100000, batch:   148/  187, ite: 11072] train loss: 0.127386, tar: 0.013230 
l0: 0.004651, l1: 0.004611, l2: 0.004028, l3: 0.004222, l4: 0.007599, l5: 0.007511, l6: 0.009171

[epoch: 118/100000, batch:   150/  187, ite: 11073] train loss: 0.127306, tar: 0.013222 
l0: 0.007126, l1: 0.007026, l2: 0.007796, l3: 0.009055, l4: 0.015142, l5: 0.012796, l6: 0.013417

[epoch: 118/100000, batch:   152/  187, ite: 11074] train loss: 0.127255, tar: 0.013216 
l0: 0.017283, l1: 0.015455, l2: 0.015520, l3: 0.018847, l4: 0.029379, l5: 0.026164, l6: 0.028195

[epoch: 118/100000, batch:   154/  187, ite: 11075] train loss: 0.127277, tar: 0.013220 
l0: 0.007048, l1: 0.007330, l2: 0.005119, l3: 0.005343, l4: 0.011004, l5: 0.011513, l6: 0.014630

[epoch: 118/100000, batch:   156/  187, ite: 11076] train loss: 0.127216, tar: 0.013214 
l0: 0.010888, l1: 0.010999, l2: 0.010179, l3: 0.010664, l4: 0.019586, l5: 0.020260, l6: 0.022915

[epoch: 118/100000, batch:   158/  187, ite: 11077] train loss: 0.127196, tar: 0.013212 
l0: 0.007258, l1: 0.007684, l2: 0.008083, l3: 0.007107, l4: 0.010062, l5: 0.008536, l6: 0.009139

[epoch: 118/100000, batch:   160/  187, ite: 11078] train loss: 0.127131, tar: 0.013206 
l0: 0.009533, l1: 0.010185, l2: 0.009767, l3: 0.009399, l4: 0.016287, l5: 0.015243, l6: 0.013823

[epoch: 118/100000, batch:   162/  187, ite: 11079] train loss: 0.127092, tar: 0.013203 
l0: 0.008774, l1: 0.009314, l2: 0.009454, l3: 0.011269, l4: 0.013402, l5: 0.013014, l6: 0.012378

[epoch: 118/100000, batch:   164/  187, ite: 11080] train loss: 0.127046, tar: 0.013199 
l0: 0.003416, l1: 0.003641, l2: 0.004360, l3: 0.004234, l4: 0.005469, l5: 0.005774, l6: 0.004947

[epoch: 118/100000, batch:   166/  187, ite: 11081] train loss: 0.126958, tar: 0.013190 
l0: 0.006467, l1: 0.006712, l2: 0.007352, l3: 0.007467, l4: 0.008464, l5: 0.008274, l6: 0.010285

[epoch: 118/100000, batch:   168/  187, ite: 11082] train loss: 0.126891, tar: 0.013183 
l0: 0.012315, l1: 0.012032, l2: 0.012105, l3: 0.013059, l4: 0.019478, l5: 0.018443, l6: 0.018640

[epoch: 118/100000, batch:   170/  187, ite: 11083] train loss: 0.126872, tar: 0.013183 
l0: 0.005789, l1: 0.005973, l2: 0.011335, l3: 0.007915, l4: 0.016570, l5: 0.011867, l6: 0.009523

[epoch: 118/100000, batch:   172/  187, ite: 11084] train loss: 0.126819, tar: 0.013176 
l0: 0.012628, l1: 0.012432, l2: 0.018277, l3: 0.015042, l4: 0.014067, l5: 0.015745, l6: 0.012563

[epoch: 118/100000, batch:   174/  187, ite: 11085] train loss: 0.126795, tar: 0.013175 
l0: 0.005265, l1: 0.005150, l2: 0.005205, l3: 0.006478, l4: 0.010372, l5: 0.010553, l6: 0.011763

[epoch: 118/100000, batch:   176/  187, ite: 11086] train loss: 0.126728, tar: 0.013168 
l0: 0.007397, l1: 0.006179, l2: 0.006902, l3: 0.009424, l4: 0.025544, l5: 0.025851, l6: 0.028226

[epoch: 118/100000, batch:   178/  187, ite: 11087] train loss: 0.126713, tar: 0.013163 
l0: 0.004859, l1: 0.004740, l2: 0.005709, l3: 0.005976, l4: 0.010297, l5: 0.008158, l6: 0.011692

[epoch: 118/100000, batch:   180/  187, ite: 11088] train loss: 0.126643, tar: 0.013155 
l0: 0.009313, l1: 0.008851, l2: 0.012147, l3: 0.013589, l4: 0.021982, l5: 0.019591, l6: 0.019580

[epoch: 118/100000, batch:   182/  187, ite: 11089] train loss: 0.126624, tar: 0.013152 
l0: 0.006259, l1: 0.007185, l2: 0.006488, l3: 0.006006, l4: 0.010083, l5: 0.009585, l6: 0.011244

[epoch: 118/100000, batch:   184/  187, ite: 11090] train loss: 0.126560, tar: 0.013145 
l0: 0.005652, l1: 0.006056, l2: 0.006602, l3: 0.006174, l4: 0.007770, l5: 0.007386, l6: 0.008911

[epoch: 118/100000, batch:   186/  187, ite: 11091] train loss: 0.126488, tar: 0.013138 
l0: 0.003703, l1: 0.003725, l2: 0.004679, l3: 0.004568, l4: 0.009369, l5: 0.009918, l6: 0.012826

[epoch: 118/100000, batch:   188/  187, ite: 11092] train loss: 0.126417, tar: 0.013130 
l0: 0.009846, l1: 0.009748, l2: 0.009900, l3: 0.010699, l4: 0.013362, l5: 0.010666, l6: 0.013365

[epoch: 119/100000, batch:     2/  187, ite: 11093] train loss: 0.126372, tar: 0.013127 
l0: 0.007203, l1: 0.007399, l2: 0.008089, l3: 0.008367, l4: 0.015342, l5: 0.011144, l6: 0.017236

[epoch: 119/100000, batch:     4/  187, ite: 11094] train loss: 0.126325, tar: 0.013121 
l0: 0.010592, l1: 0.011562, l2: 0.011669, l3: 0.011661, l4: 0.011744, l5: 0.010510, l6: 0.016602

[epoch: 119/100000, batch:     6/  187, ite: 11095] train loss: 0.126287, tar: 0.013119 
l0: 0.006869, l1: 0.007037, l2: 0.009135, l3: 0.008869, l4: 0.010187, l5: 0.011080, l6: 0.012900

[epoch: 119/100000, batch:     8/  187, ite: 11096] train loss: 0.126232, tar: 0.013113 
l0: 0.006713, l1: 0.006662, l2: 0.006637, l3: 0.007676, l4: 0.013798, l5: 0.011868, l6: 0.008547

[epoch: 119/100000, batch:    10/  187, ite: 11097] train loss: 0.126173, tar: 0.013108 
l0: 0.005647, l1: 0.006045, l2: 0.006895, l3: 0.007533, l4: 0.008650, l5: 0.008616, l6: 0.007747

[epoch: 119/100000, batch:    12/  187, ite: 11098] train loss: 0.126105, tar: 0.013101 
l0: 0.012233, l1: 0.012251, l2: 0.014579, l3: 0.012617, l4: 0.015806, l5: 0.014074, l6: 0.015413

[epoch: 119/100000, batch:    14/  187, ite: 11099] train loss: 0.126078, tar: 0.013100 
l0: 0.005203, l1: 0.004989, l2: 0.005511, l3: 0.006386, l4: 0.010175, l5: 0.009814, l6: 0.012484

[epoch: 119/100000, batch:    16/  187, ite: 11100] train loss: 0.126013, tar: 0.013093 
l0: 0.007513, l1: 0.007649, l2: 0.007708, l3: 0.008687, l4: 0.015806, l5: 0.016384, l6: 0.014600

[epoch: 119/100000, batch:    18/  187, ite: 11101] train loss: 0.125970, tar: 0.013088 
l0: 0.011803, l1: 0.014392, l2: 0.012051, l3: 0.011119, l4: 0.013437, l5: 0.013092, l6: 0.015525

[epoch: 119/100000, batch:    20/  187, ite: 11102] train loss: 0.125939, tar: 0.013087 
l0: 0.007059, l1: 0.006564, l2: 0.007881, l3: 0.009704, l4: 0.044064, l5: 0.035335, l6: 0.024411

[epoch: 119/100000, batch:    22/  187, ite: 11103] train loss: 0.125947, tar: 0.013081 
l0: 0.010430, l1: 0.010921, l2: 0.013551, l3: 0.012720, l4: 0.009279, l5: 0.009315, l6: 0.009652

[epoch: 119/100000, batch:    24/  187, ite: 11104] train loss: 0.125901, tar: 0.013079 
l0: 0.006910, l1: 0.007811, l2: 0.006867, l3: 0.006748, l4: 0.011939, l5: 0.010953, l6: 0.013731

[epoch: 119/100000, batch:    26/  187, ite: 11105] train loss: 0.125846, tar: 0.013073 
l0: 0.005984, l1: 0.006118, l2: 0.006332, l3: 0.006127, l4: 0.009227, l5: 0.009774, l6: 0.008415

[epoch: 119/100000, batch:    28/  187, ite: 11106] train loss: 0.125780, tar: 0.013067 
l0: 0.010616, l1: 0.009977, l2: 0.012367, l3: 0.014294, l4: 0.025130, l5: 0.022298, l6: 0.020337

[epoch: 119/100000, batch:    30/  187, ite: 11107] train loss: 0.125770, tar: 0.013064 
l0: 0.013627, l1: 0.014963, l2: 0.013848, l3: 0.014449, l4: 0.018943, l5: 0.015908, l6: 0.014864

[epoch: 119/100000, batch:    32/  187, ite: 11108] train loss: 0.125753, tar: 0.013065 
l0: 0.005042, l1: 0.005037, l2: 0.006246, l3: 0.006778, l4: 0.012669, l5: 0.013486, l6: 0.013342

[epoch: 119/100000, batch:    34/  187, ite: 11109] train loss: 0.125696, tar: 0.013058 
l0: 0.003707, l1: 0.004218, l2: 0.003912, l3: 0.004016, l4: 0.005933, l5: 0.005706, l6: 0.006205

[epoch: 119/100000, batch:    36/  187, ite: 11110] train loss: 0.125613, tar: 0.013049 
l0: 0.006701, l1: 0.006899, l2: 0.008095, l3: 0.010945, l4: 0.008974, l5: 0.010303, l6: 0.009119

[epoch: 119/100000, batch:    38/  187, ite: 11111] train loss: 0.125555, tar: 0.013044 
l0: 0.005493, l1: 0.005660, l2: 0.005491, l3: 0.005528, l4: 0.008919, l5: 0.008265, l6: 0.010688

[epoch: 119/100000, batch:    40/  187, ite: 11112] train loss: 0.125487, tar: 0.013037 
l0: 0.007977, l1: 0.007347, l2: 0.010932, l3: 0.011086, l4: 0.015653, l5: 0.016342, l6: 0.012158

[epoch: 119/100000, batch:    42/  187, ite: 11113] train loss: 0.125447, tar: 0.013032 
l0: 0.007224, l1: 0.007774, l2: 0.008052, l3: 0.007715, l4: 0.013238, l5: 0.012022, l6: 0.015080

[epoch: 119/100000, batch:    44/  187, ite: 11114] train loss: 0.125398, tar: 0.013027 
l0: 0.004364, l1: 0.004329, l2: 0.004929, l3: 0.005406, l4: 0.007950, l5: 0.007315, l6: 0.008373

[epoch: 119/100000, batch:    46/  187, ite: 11115] train loss: 0.125324, tar: 0.013019 
l0: 0.013984, l1: 0.013226, l2: 0.016233, l3: 0.018408, l4: 0.036215, l5: 0.028208, l6: 0.025283

[epoch: 119/100000, batch:    48/  187, ite: 11116] train loss: 0.125348, tar: 0.013020 
l0: 0.010886, l1: 0.010885, l2: 0.011292, l3: 0.011968, l4: 0.022131, l5: 0.017676, l6: 0.024265

[epoch: 119/100000, batch:    50/  187, ite: 11117] train loss: 0.125333, tar: 0.013018 
l0: 0.006840, l1: 0.007384, l2: 0.005953, l3: 0.005708, l4: 0.011822, l5: 0.011115, l6: 0.010092

[epoch: 119/100000, batch:    52/  187, ite: 11118] train loss: 0.125274, tar: 0.013013 
l0: 0.007547, l1: 0.007855, l2: 0.008413, l3: 0.007811, l4: 0.008048, l5: 0.008106, l6: 0.007937

[epoch: 119/100000, batch:    54/  187, ite: 11119] train loss: 0.125212, tar: 0.013008 
l0: 0.008358, l1: 0.008700, l2: 0.009180, l3: 0.009169, l4: 0.011561, l5: 0.011216, l6: 0.010481

[epoch: 119/100000, batch:    56/  187, ite: 11120] train loss: 0.125161, tar: 0.013004 
l0: 0.010228, l1: 0.009555, l2: 0.010566, l3: 0.012108, l4: 0.015986, l5: 0.014924, l6: 0.019023

[epoch: 119/100000, batch:    58/  187, ite: 11121] train loss: 0.125132, tar: 0.013001 
l0: 0.003927, l1: 0.003206, l2: 0.006747, l3: 0.007303, l4: 0.017353, l5: 0.022318, l6: 0.026852

[epoch: 119/100000, batch:    60/  187, ite: 11122] train loss: 0.125098, tar: 0.012993 
l0: 0.007003, l1: 0.007784, l2: 0.007219, l3: 0.006937, l4: 0.010092, l5: 0.009462, l6: 0.009690

[epoch: 119/100000, batch:    62/  187, ite: 11123] train loss: 0.125039, tar: 0.012988 
l0: 0.006406, l1: 0.006877, l2: 0.007094, l3: 0.007550, l4: 0.012587, l5: 0.011171, l6: 0.009845

[epoch: 119/100000, batch:    64/  187, ite: 11124] train loss: 0.124982, tar: 0.012982 
l0: 0.007686, l1: 0.007920, l2: 0.009144, l3: 0.008504, l4: 0.015423, l5: 0.014095, l6: 0.015329

[epoch: 119/100000, batch:    66/  187, ite: 11125] train loss: 0.124941, tar: 0.012977 
l0: 0.007903, l1: 0.008211, l2: 0.008161, l3: 0.008135, l4: 0.013831, l5: 0.013168, l6: 0.015801

[epoch: 119/100000, batch:    68/  187, ite: 11126] train loss: 0.124897, tar: 0.012973 
l0: 0.008925, l1: 0.008803, l2: 0.009383, l3: 0.009871, l4: 0.010865, l5: 0.012477, l6: 0.015178

[epoch: 119/100000, batch:    70/  187, ite: 11127] train loss: 0.124853, tar: 0.012969 
l0: 0.007001, l1: 0.007379, l2: 0.007521, l3: 0.007881, l4: 0.013160, l5: 0.013035, l6: 0.015865

[epoch: 119/100000, batch:    72/  187, ite: 11128] train loss: 0.124806, tar: 0.012964 
l0: 0.005679, l1: 0.005133, l2: 0.006410, l3: 0.007320, l4: 0.018907, l5: 0.013451, l6: 0.013469

[epoch: 119/100000, batch:    74/  187, ite: 11129] train loss: 0.124758, tar: 0.012957 
l0: 0.013252, l1: 0.016667, l2: 0.017651, l3: 0.013147, l4: 0.020630, l5: 0.014815, l6: 0.015661

[epoch: 119/100000, batch:    76/  187, ite: 11130] train loss: 0.124746, tar: 0.012958 
l0: 0.011161, l1: 0.011577, l2: 0.010311, l3: 0.010897, l4: 0.011059, l5: 0.011948, l6: 0.012179

[epoch: 119/100000, batch:    78/  187, ite: 11131] train loss: 0.124706, tar: 0.012956 
l0: 0.005405, l1: 0.004803, l2: 0.006964, l3: 0.008072, l4: 0.013984, l5: 0.012596, l6: 0.016516

[epoch: 119/100000, batch:    80/  187, ite: 11132] train loss: 0.124656, tar: 0.012949 
l0: 0.006092, l1: 0.005763, l2: 0.007210, l3: 0.007252, l4: 0.015277, l5: 0.015031, l6: 0.015211

[epoch: 119/100000, batch:    82/  187, ite: 11133] train loss: 0.124609, tar: 0.012943 
l0: 0.008916, l1: 0.009563, l2: 0.009574, l3: 0.009778, l4: 0.013613, l5: 0.011597, l6: 0.010969

[epoch: 119/100000, batch:    84/  187, ite: 11134] train loss: 0.124565, tar: 0.012940 
l0: 0.007822, l1: 0.007829, l2: 0.009349, l3: 0.009096, l4: 0.011573, l5: 0.011089, l6: 0.013760

[epoch: 119/100000, batch:    86/  187, ite: 11135] train loss: 0.124517, tar: 0.012935 
l0: 0.006630, l1: 0.007142, l2: 0.007554, l3: 0.007419, l4: 0.012157, l5: 0.010745, l6: 0.009012

[epoch: 119/100000, batch:    88/  187, ite: 11136] train loss: 0.124461, tar: 0.012930 
l0: 0.004188, l1: 0.004336, l2: 0.004772, l3: 0.005122, l4: 0.010632, l5: 0.007817, l6: 0.007982

[epoch: 119/100000, batch:    90/  187, ite: 11137] train loss: 0.124391, tar: 0.012922 
l0: 0.009556, l1: 0.009482, l2: 0.009724, l3: 0.011150, l4: 0.017183, l5: 0.013759, l6: 0.015676

[epoch: 119/100000, batch:    92/  187, ite: 11138] train loss: 0.124358, tar: 0.012919 
l0: 0.005249, l1: 0.005509, l2: 0.003963, l3: 0.004745, l4: 0.007538, l5: 0.007555, l6: 0.009225

[epoch: 119/100000, batch:    94/  187, ite: 11139] train loss: 0.124287, tar: 0.012912 
l0: 0.008132, l1: 0.008103, l2: 0.008695, l3: 0.009097, l4: 0.017446, l5: 0.016484, l6: 0.017827

[epoch: 119/100000, batch:    96/  187, ite: 11140] train loss: 0.124253, tar: 0.012908 
l0: 0.005433, l1: 0.005511, l2: 0.006263, l3: 0.005952, l4: 0.010380, l5: 0.009672, l6: 0.011948

[epoch: 119/100000, batch:    98/  187, ite: 11141] train loss: 0.124193, tar: 0.012902 
l0: 0.003288, l1: 0.003137, l2: 0.003096, l3: 0.003882, l4: 0.012427, l5: 0.012581, l6: 0.011829

[epoch: 119/100000, batch:   100/  187, ite: 11142] train loss: 0.124128, tar: 0.012893 
l0: 0.006566, l1: 0.006355, l2: 0.007375, l3: 0.007446, l4: 0.015137, l5: 0.016618, l6: 0.018451

[epoch: 119/100000, batch:   102/  187, ite: 11143] train loss: 0.124087, tar: 0.012888 
l0: 0.006407, l1: 0.006773, l2: 0.006973, l3: 0.007176, l4: 0.010156, l5: 0.008830, l6: 0.011580

[epoch: 119/100000, batch:   104/  187, ite: 11144] train loss: 0.124029, tar: 0.012882 
l0: 0.010807, l1: 0.010230, l2: 0.011719, l3: 0.012724, l4: 0.015884, l5: 0.019429, l6: 0.013356

[epoch: 119/100000, batch:   106/  187, ite: 11145] train loss: 0.124003, tar: 0.012880 
l0: 0.004963, l1: 0.005538, l2: 0.007048, l3: 0.006981, l4: 0.012621, l5: 0.010024, l6: 0.008694

[epoch: 119/100000, batch:   108/  187, ite: 11146] train loss: 0.123944, tar: 0.012873 
l0: 0.008174, l1: 0.007772, l2: 0.008886, l3: 0.009561, l4: 0.017727, l5: 0.017923, l6: 0.013835

[epoch: 119/100000, batch:   110/  187, ite: 11147] train loss: 0.123909, tar: 0.012869 
l0: 0.007855, l1: 0.007506, l2: 0.008000, l3: 0.008812, l4: 0.010830, l5: 0.011380, l6: 0.013754

[epoch: 119/100000, batch:   112/  187, ite: 11148] train loss: 0.123860, tar: 0.012865 
l0: 0.009194, l1: 0.009535, l2: 0.008798, l3: 0.008543, l4: 0.013545, l5: 0.012727, l6: 0.012718

[epoch: 119/100000, batch:   114/  187, ite: 11149] train loss: 0.123818, tar: 0.012862 
l0: 0.005635, l1: 0.005598, l2: 0.005899, l3: 0.006578, l4: 0.015964, l5: 0.012967, l6: 0.012231

[epoch: 119/100000, batch:   116/  187, ite: 11150] train loss: 0.123767, tar: 0.012855 
l0: 0.008426, l1: 0.008075, l2: 0.010262, l3: 0.009818, l4: 0.013010, l5: 0.011793, l6: 0.013059

[epoch: 119/100000, batch:   118/  187, ite: 11151] train loss: 0.123724, tar: 0.012851 
l0: 0.014874, l1: 0.013856, l2: 0.013855, l3: 0.015395, l4: 0.020093, l5: 0.020272, l6: 0.025858

[epoch: 119/100000, batch:   120/  187, ite: 11152] train loss: 0.123724, tar: 0.012853 
l0: 0.009444, l1: 0.009930, l2: 0.008185, l3: 0.008300, l4: 0.011464, l5: 0.009474, l6: 0.011966

[epoch: 119/100000, batch:   122/  187, ite: 11153] train loss: 0.123677, tar: 0.012850 
l0: 0.002698, l1: 0.002574, l2: 0.002744, l3: 0.003098, l4: 0.006732, l5: 0.005663, l6: 0.006878

[epoch: 119/100000, batch:   124/  187, ite: 11154] train loss: 0.123596, tar: 0.012841 
l0: 0.016439, l1: 0.014828, l2: 0.015732, l3: 0.017007, l4: 0.032163, l5: 0.035829, l6: 0.031126

[epoch: 119/100000, batch:   126/  187, ite: 11155] train loss: 0.123630, tar: 0.012845 
l0: 0.009462, l1: 0.009694, l2: 0.012653, l3: 0.012746, l4: 0.014710, l5: 0.012712, l6: 0.013845

[epoch: 119/100000, batch:   128/  187, ite: 11156] train loss: 0.123597, tar: 0.012842 
l0: 0.007114, l1: 0.008203, l2: 0.007346, l3: 0.007336, l4: 0.008082, l5: 0.008231, l6: 0.010632

[epoch: 119/100000, batch:   130/  187, ite: 11157] train loss: 0.123540, tar: 0.012837 
l0: 0.006523, l1: 0.006655, l2: 0.008408, l3: 0.008517, l4: 0.014622, l5: 0.013337, l6: 0.016768

[epoch: 119/100000, batch:   132/  187, ite: 11158] train loss: 0.123498, tar: 0.012831 
l0: 0.004250, l1: 0.004703, l2: 0.004795, l3: 0.004634, l4: 0.008365, l5: 0.006270, l6: 0.007840

[epoch: 119/100000, batch:   134/  187, ite: 11159] train loss: 0.123426, tar: 0.012824 
l0: 0.004110, l1: 0.004172, l2: 0.004714, l3: 0.004737, l4: 0.008354, l5: 0.007549, l6: 0.006882

[epoch: 119/100000, batch:   136/  187, ite: 11160] train loss: 0.123355, tar: 0.012816 
l0: 0.007728, l1: 0.007350, l2: 0.010602, l3: 0.010736, l4: 0.018202, l5: 0.013509, l6: 0.018366

[epoch: 119/100000, batch:   138/  187, ite: 11161] train loss: 0.123323, tar: 0.012812 
l0: 0.005117, l1: 0.005727, l2: 0.005064, l3: 0.004816, l4: 0.008717, l5: 0.008027, l6: 0.009819

[epoch: 119/100000, batch:   140/  187, ite: 11162] train loss: 0.123258, tar: 0.012805 
l0: 0.002122, l1: 0.002106, l2: 0.002540, l3: 0.003626, l4: 0.004350, l5: 0.004647, l6: 0.007306

[epoch: 119/100000, batch:   142/  187, ite: 11163] train loss: 0.123175, tar: 0.012796 
l0: 0.003138, l1: 0.003816, l2: 0.002730, l3: 0.002857, l4: 0.005059, l5: 0.004786, l6: 0.003956

[epoch: 119/100000, batch:   144/  187, ite: 11164] train loss: 0.123091, tar: 0.012788 
l0: 0.009643, l1: 0.008979, l2: 0.010175, l3: 0.009892, l4: 0.017399, l5: 0.016625, l6: 0.018993

[epoch: 119/100000, batch:   146/  187, ite: 11165] train loss: 0.123064, tar: 0.012785 
l0: 0.005785, l1: 0.006083, l2: 0.006017, l3: 0.005441, l4: 0.007759, l5: 0.008820, l6: 0.012891

[epoch: 119/100000, batch:   148/  187, ite: 11166] train loss: 0.123004, tar: 0.012779 
l0: 0.007604, l1: 0.007272, l2: 0.008088, l3: 0.008439, l4: 0.020148, l5: 0.017323, l6: 0.017145

[epoch: 119/100000, batch:   150/  187, ite: 11167] train loss: 0.122973, tar: 0.012775 
l0: 0.010155, l1: 0.009862, l2: 0.011323, l3: 0.012212, l4: 0.023002, l5: 0.018091, l6: 0.017599

[epoch: 119/100000, batch:   152/  187, ite: 11168] train loss: 0.122955, tar: 0.012772 
l0: 0.011286, l1: 0.011180, l2: 0.014010, l3: 0.014107, l4: 0.018012, l5: 0.015192, l6: 0.013358

[epoch: 119/100000, batch:   154/  187, ite: 11169] train loss: 0.122933, tar: 0.012771 
l0: 0.012470, l1: 0.014148, l2: 0.016146, l3: 0.012248, l4: 0.039412, l5: 0.023884, l6: 0.024756

[epoch: 119/100000, batch:   156/  187, ite: 11170] train loss: 0.122950, tar: 0.012771 
l0: 0.005889, l1: 0.005981, l2: 0.009226, l3: 0.007922, l4: 0.009085, l5: 0.009511, l6: 0.010027

[epoch: 119/100000, batch:   158/  187, ite: 11171] train loss: 0.122894, tar: 0.012765 
l0: 0.006521, l1: 0.006495, l2: 0.008219, l3: 0.007601, l4: 0.011965, l5: 0.010904, l6: 0.015195

[epoch: 119/100000, batch:   160/  187, ite: 11172] train loss: 0.122846, tar: 0.012760 
l0: 0.008528, l1: 0.008802, l2: 0.010180, l3: 0.007666, l4: 0.020683, l5: 0.015928, l6: 0.018401

[epoch: 119/100000, batch:   162/  187, ite: 11173] train loss: 0.122819, tar: 0.012756 
l0: 0.011335, l1: 0.012069, l2: 0.014083, l3: 0.014168, l4: 0.011878, l5: 0.011788, l6: 0.014287

[epoch: 119/100000, batch:   164/  187, ite: 11174] train loss: 0.122790, tar: 0.012755 
l0: 0.006460, l1: 0.006387, l2: 0.007373, l3: 0.008468, l4: 0.011930, l5: 0.012035, l6: 0.012180

[epoch: 119/100000, batch:   166/  187, ite: 11175] train loss: 0.122741, tar: 0.012750 
l0: 0.002302, l1: 0.002443, l2: 0.002508, l3: 0.002652, l4: 0.004832, l5: 0.004166, l6: 0.004243

[epoch: 119/100000, batch:   168/  187, ite: 11176] train loss: 0.122656, tar: 0.012741 
l0: 0.006683, l1: 0.007044, l2: 0.008646, l3: 0.008039, l4: 0.017528, l5: 0.014877, l6: 0.013197

[epoch: 119/100000, batch:   170/  187, ite: 11177] train loss: 0.122617, tar: 0.012735 
l0: 0.007193, l1: 0.007991, l2: 0.009203, l3: 0.009396, l4: 0.013041, l5: 0.012306, l6: 0.013361

[epoch: 119/100000, batch:   172/  187, ite: 11178] train loss: 0.122574, tar: 0.012731 
l0: 0.006764, l1: 0.006969, l2: 0.005800, l3: 0.007530, l4: 0.018158, l5: 0.014436, l6: 0.011484

[epoch: 119/100000, batch:   174/  187, ite: 11179] train loss: 0.122530, tar: 0.012726 
l0: 0.007504, l1: 0.008276, l2: 0.007477, l3: 0.007657, l4: 0.013330, l5: 0.012985, l6: 0.012658

[epoch: 119/100000, batch:   176/  187, ite: 11180] train loss: 0.122486, tar: 0.012721 
l0: 0.008192, l1: 0.007347, l2: 0.007918, l3: 0.009234, l4: 0.014239, l5: 0.016227, l6: 0.018341

[epoch: 119/100000, batch:   178/  187, ite: 11181] train loss: 0.122451, tar: 0.012717 
l0: 0.010658, l1: 0.010698, l2: 0.010018, l3: 0.011128, l4: 0.020738, l5: 0.020460, l6: 0.019315

[epoch: 119/100000, batch:   180/  187, ite: 11182] train loss: 0.122435, tar: 0.012716 
l0: 0.009182, l1: 0.008544, l2: 0.010025, l3: 0.012257, l4: 0.019227, l5: 0.020006, l6: 0.018699

[epoch: 119/100000, batch:   182/  187, ite: 11183] train loss: 0.122414, tar: 0.012713 
l0: 0.008967, l1: 0.009813, l2: 0.009110, l3: 0.011046, l4: 0.006265, l5: 0.005141, l6: 0.010450

[epoch: 119/100000, batch:   184/  187, ite: 11184] train loss: 0.122362, tar: 0.012710 
l0: 0.005320, l1: 0.005704, l2: 0.004821, l3: 0.005045, l4: 0.008825, l5: 0.008055, l6: 0.012082

[epoch: 119/100000, batch:   186/  187, ite: 11185] train loss: 0.122301, tar: 0.012703 
l0: 0.008465, l1: 0.007770, l2: 0.012504, l3: 0.011926, l4: 0.021864, l5: 0.019093, l6: 0.015054

[epoch: 119/100000, batch:   188/  187, ite: 11186] train loss: 0.122279, tar: 0.012700 
l0: 0.008670, l1: 0.008978, l2: 0.008307, l3: 0.008434, l4: 0.013258, l5: 0.011272, l6: 0.013323

[epoch: 120/100000, batch:     2/  187, ite: 11187] train loss: 0.122237, tar: 0.012696 
l0: 0.006190, l1: 0.006216, l2: 0.006192, l3: 0.007024, l4: 0.013913, l5: 0.013935, l6: 0.013165

[epoch: 120/100000, batch:     4/  187, ite: 11188] train loss: 0.122190, tar: 0.012691 
l0: 0.021404, l1: 0.018767, l2: 0.019099, l3: 0.022652, l4: 0.038621, l5: 0.038627, l6: 0.038037

[epoch: 120/100000, batch:     6/  187, ite: 11189] train loss: 0.122253, tar: 0.012698 
l0: 0.005727, l1: 0.005545, l2: 0.006722, l3: 0.007103, l4: 0.014732, l5: 0.012305, l6: 0.012304

[epoch: 120/100000, batch:     8/  187, ite: 11190] train loss: 0.122205, tar: 0.012692 
l0: 0.009248, l1: 0.009430, l2: 0.009322, l3: 0.010556, l4: 0.014848, l5: 0.013693, l6: 0.014175

[epoch: 120/100000, batch:    10/  187, ite: 11191] train loss: 0.122170, tar: 0.012689 
l0: 0.009210, l1: 0.008685, l2: 0.011109, l3: 0.014559, l4: 0.024652, l5: 0.019663, l6: 0.023047

[epoch: 120/100000, batch:    12/  187, ite: 11192] train loss: 0.122161, tar: 0.012687 
l0: 0.006737, l1: 0.006995, l2: 0.006814, l3: 0.007678, l4: 0.012456, l5: 0.009618, l6: 0.011351

[epoch: 120/100000, batch:    14/  187, ite: 11193] train loss: 0.122110, tar: 0.012682 
l0: 0.002041, l1: 0.002222, l2: 0.002730, l3: 0.002460, l4: 0.004043, l5: 0.003400, l6: 0.005485

[epoch: 120/100000, batch:    16/  187, ite: 11194] train loss: 0.122027, tar: 0.012673 
l0: 0.005542, l1: 0.006282, l2: 0.004614, l3: 0.004776, l4: 0.008591, l5: 0.008463, l6: 0.008879

[epoch: 120/100000, batch:    18/  187, ite: 11195] train loss: 0.121964, tar: 0.012667 
l0: 0.010788, l1: 0.011217, l2: 0.009352, l3: 0.009904, l4: 0.018117, l5: 0.014568, l6: 0.018497

[epoch: 120/100000, batch:    20/  187, ite: 11196] train loss: 0.121939, tar: 0.012665 
l0: 0.008898, l1: 0.009038, l2: 0.008986, l3: 0.009794, l4: 0.018356, l5: 0.021466, l6: 0.021771

[epoch: 120/100000, batch:    22/  187, ite: 11197] train loss: 0.121920, tar: 0.012662 
l0: 0.007423, l1: 0.006668, l2: 0.010462, l3: 0.010646, l4: 0.016552, l5: 0.015579, l6: 0.009694

[epoch: 120/100000, batch:    24/  187, ite: 11198] train loss: 0.121882, tar: 0.012658 
l0: 0.005884, l1: 0.006456, l2: 0.006696, l3: 0.007139, l4: 0.008168, l5: 0.007649, l6: 0.008119

[epoch: 120/100000, batch:    26/  187, ite: 11199] train loss: 0.121822, tar: 0.012652 
l0: 0.012533, l1: 0.014993, l2: 0.009793, l3: 0.009964, l4: 0.019294, l5: 0.017360, l6: 0.042890

[epoch: 120/100000, batch:    28/  187, ite: 11200] train loss: 0.121826, tar: 0.012652 
l0: 0.010004, l1: 0.011026, l2: 0.013570, l3: 0.013817, l4: 0.018730, l5: 0.018073, l6: 0.020954

[epoch: 120/100000, batch:    30/  187, ite: 11201] train loss: 0.121813, tar: 0.012650 
l0: 0.009746, l1: 0.010126, l2: 0.011055, l3: 0.010932, l4: 0.019904, l5: 0.018164, l6: 0.020755

[epoch: 120/100000, batch:    32/  187, ite: 11202] train loss: 0.121796, tar: 0.012647 
l0: 0.006504, l1: 0.006692, l2: 0.007014, l3: 0.007960, l4: 0.012355, l5: 0.010162, l6: 0.011717

[epoch: 120/100000, batch:    34/  187, ite: 11203] train loss: 0.121746, tar: 0.012642 
l0: 0.007999, l1: 0.008428, l2: 0.009524, l3: 0.009205, l4: 0.009449, l5: 0.008889, l6: 0.011392

[epoch: 120/100000, batch:    36/  187, ite: 11204] train loss: 0.121699, tar: 0.012638 
l0: 0.007076, l1: 0.007019, l2: 0.006782, l3: 0.007165, l4: 0.013597, l5: 0.013605, l6: 0.019195

[epoch: 120/100000, batch:    38/  187, ite: 11205] train loss: 0.121660, tar: 0.012634 
l0: 0.009498, l1: 0.009770, l2: 0.009147, l3: 0.010032, l4: 0.012895, l5: 0.012671, l6: 0.013655

[epoch: 120/100000, batch:    40/  187, ite: 11206] train loss: 0.121623, tar: 0.012631 
l0: 0.006159, l1: 0.005810, l2: 0.006935, l3: 0.006716, l4: 0.013692, l5: 0.013766, l6: 0.014551

[epoch: 120/100000, batch:    42/  187, ite: 11207] train loss: 0.121579, tar: 0.012626 
l0: 0.010868, l1: 0.010508, l2: 0.012627, l3: 0.013496, l4: 0.018007, l5: 0.016003, l6: 0.020141

[epoch: 120/100000, batch:    44/  187, ite: 11208] train loss: 0.121562, tar: 0.012624 
l0: 0.008329, l1: 0.008296, l2: 0.009353, l3: 0.009174, l4: 0.014709, l5: 0.014085, l6: 0.018051

[epoch: 120/100000, batch:    46/  187, ite: 11209] train loss: 0.121529, tar: 0.012621 
l0: 0.005636, l1: 0.005465, l2: 0.005254, l3: 0.005604, l4: 0.009635, l5: 0.011587, l6: 0.010684

[epoch: 120/100000, batch:    48/  187, ite: 11210] train loss: 0.121474, tar: 0.012615 
l0: 0.007142, l1: 0.007478, l2: 0.008518, l3: 0.008636, l4: 0.013750, l5: 0.012299, l6: 0.013045

[epoch: 120/100000, batch:    50/  187, ite: 11211] train loss: 0.121432, tar: 0.012610 
l0: 0.007640, l1: 0.007250, l2: 0.008408, l3: 0.008819, l4: 0.009674, l5: 0.010026, l6: 0.012415

[epoch: 120/100000, batch:    52/  187, ite: 11212] train loss: 0.121385, tar: 0.012606 
l0: 0.005704, l1: 0.005708, l2: 0.006808, l3: 0.006924, l4: 0.009826, l5: 0.009689, l6: 0.011475

[epoch: 120/100000, batch:    54/  187, ite: 11213] train loss: 0.121331, tar: 0.012601 
l0: 0.004487, l1: 0.004438, l2: 0.005298, l3: 0.005374, l4: 0.013560, l5: 0.012783, l6: 0.012799

[epoch: 120/100000, batch:    56/  187, ite: 11214] train loss: 0.121279, tar: 0.012594 
l0: 0.009266, l1: 0.009220, l2: 0.009435, l3: 0.009467, l4: 0.013129, l5: 0.013250, l6: 0.014443

[epoch: 120/100000, batch:    58/  187, ite: 11215] train loss: 0.121244, tar: 0.012591 
l0: 0.004382, l1: 0.004343, l2: 0.005586, l3: 0.007497, l4: 0.008502, l5: 0.007062, l6: 0.007204

[epoch: 120/100000, batch:    60/  187, ite: 11216] train loss: 0.121181, tar: 0.012584 
l0: 0.004812, l1: 0.005052, l2: 0.004102, l3: 0.003710, l4: 0.008478, l5: 0.008621, l6: 0.009718

[epoch: 120/100000, batch:    62/  187, ite: 11217] train loss: 0.121118, tar: 0.012578 
l0: 0.005727, l1: 0.005954, l2: 0.007404, l3: 0.007797, l4: 0.010880, l5: 0.009664, l6: 0.011536

[epoch: 120/100000, batch:    64/  187, ite: 11218] train loss: 0.121067, tar: 0.012572 
l0: 0.009159, l1: 0.009415, l2: 0.008570, l3: 0.008590, l4: 0.013365, l5: 0.011967, l6: 0.014560

[epoch: 120/100000, batch:    66/  187, ite: 11219] train loss: 0.121029, tar: 0.012570 
l0: 0.005827, l1: 0.006540, l2: 0.006869, l3: 0.006592, l4: 0.008290, l5: 0.007809, l6: 0.008764

[epoch: 120/100000, batch:    68/  187, ite: 11220] train loss: 0.120972, tar: 0.012564 
l0: 0.005886, l1: 0.006653, l2: 0.006332, l3: 0.005816, l4: 0.009934, l5: 0.010114, l6: 0.011040

[epoch: 120/100000, batch:    70/  187, ite: 11221] train loss: 0.120918, tar: 0.012559 
l0: 0.002403, l1: 0.002511, l2: 0.003194, l3: 0.003266, l4: 0.004657, l5: 0.003624, l6: 0.004321

[epoch: 120/100000, batch:    72/  187, ite: 11222] train loss: 0.120839, tar: 0.012550 
l0: 0.006059, l1: 0.006251, l2: 0.006047, l3: 0.006570, l4: 0.010019, l5: 0.008523, l6: 0.010618

[epoch: 120/100000, batch:    74/  187, ite: 11223] train loss: 0.120784, tar: 0.012545 
l0: 0.005255, l1: 0.005239, l2: 0.007010, l3: 0.008811, l4: 0.012190, l5: 0.012091, l6: 0.014014

[epoch: 120/100000, batch:    76/  187, ite: 11224] train loss: 0.120739, tar: 0.012539 
l0: 0.006835, l1: 0.007311, l2: 0.008412, l3: 0.008543, l4: 0.008359, l5: 0.008704, l6: 0.009076

[epoch: 120/100000, batch:    78/  187, ite: 11225] train loss: 0.120687, tar: 0.012534 
l0: 0.009615, l1: 0.009484, l2: 0.010875, l3: 0.010109, l4: 0.014584, l5: 0.013631, l6: 0.014829

[epoch: 120/100000, batch:    80/  187, ite: 11226] train loss: 0.120656, tar: 0.012532 
l0: 0.010654, l1: 0.011617, l2: 0.011117, l3: 0.011303, l4: 0.016443, l5: 0.015253, l6: 0.017449

[epoch: 120/100000, batch:    82/  187, ite: 11227] train loss: 0.120634, tar: 0.012530 
l0: 0.004084, l1: 0.004509, l2: 0.004622, l3: 0.005764, l4: 0.009629, l5: 0.007724, l6: 0.008010

[epoch: 120/100000, batch:    84/  187, ite: 11228] train loss: 0.120572, tar: 0.012524 
l0: 0.006965, l1: 0.006947, l2: 0.007664, l3: 0.008146, l4: 0.011055, l5: 0.010056, l6: 0.015886

[epoch: 120/100000, batch:    86/  187, ite: 11229] train loss: 0.120528, tar: 0.012519 
l0: 0.006892, l1: 0.007537, l2: 0.008168, l3: 0.008301, l4: 0.012360, l5: 0.011067, l6: 0.013504

[epoch: 120/100000, batch:    88/  187, ite: 11230] train loss: 0.120485, tar: 0.012514 
l0: 0.006457, l1: 0.006532, l2: 0.006136, l3: 0.006901, l4: 0.008981, l5: 0.009089, l6: 0.009922

[epoch: 120/100000, batch:    90/  187, ite: 11231] train loss: 0.120431, tar: 0.012510 
l0: 0.010191, l1: 0.009813, l2: 0.011510, l3: 0.011993, l4: 0.020703, l5: 0.021015, l6: 0.020485

[epoch: 120/100000, batch:    92/  187, ite: 11232] train loss: 0.120419, tar: 0.012508 
l0: 0.006179, l1: 0.005596, l2: 0.010674, l3: 0.010410, l4: 0.009226, l5: 0.007791, l6: 0.010978

[epoch: 120/100000, batch:    94/  187, ite: 11233] train loss: 0.120371, tar: 0.012503 
l0: 0.007549, l1: 0.007791, l2: 0.007804, l3: 0.007998, l4: 0.011827, l5: 0.011771, l6: 0.012817

[epoch: 120/100000, batch:    96/  187, ite: 11234] train loss: 0.120328, tar: 0.012499 
l0: 0.007656, l1: 0.007556, l2: 0.009514, l3: 0.009512, l4: 0.016107, l5: 0.014187, l6: 0.013632

[epoch: 120/100000, batch:    98/  187, ite: 11235] train loss: 0.120294, tar: 0.012495 
l0: 0.004636, l1: 0.004641, l2: 0.006190, l3: 0.006422, l4: 0.006380, l5: 0.006401, l6: 0.008658

[epoch: 120/100000, batch:   100/  187, ite: 11236] train loss: 0.120232, tar: 0.012488 
l0: 0.004296, l1: 0.004734, l2: 0.004224, l3: 0.004945, l4: 0.009830, l5: 0.008224, l6: 0.007950

[epoch: 120/100000, batch:   102/  187, ite: 11237] train loss: 0.120171, tar: 0.012482 
l0: 0.010769, l1: 0.011349, l2: 0.010954, l3: 0.010876, l4: 0.013994, l5: 0.015473, l6: 0.016092

[epoch: 120/100000, batch:   104/  187, ite: 11238] train loss: 0.120146, tar: 0.012480 
l0: 0.004936, l1: 0.004951, l2: 0.004897, l3: 0.005671, l4: 0.012152, l5: 0.010417, l6: 0.011534

[epoch: 120/100000, batch:   106/  187, ite: 11239] train loss: 0.120093, tar: 0.012474 
l0: 0.007733, l1: 0.009074, l2: 0.009450, l3: 0.008340, l4: 0.010067, l5: 0.009684, l6: 0.011583

[epoch: 120/100000, batch:   108/  187, ite: 11240] train loss: 0.120049, tar: 0.012470 
l0: 0.008254, l1: 0.009071, l2: 0.009763, l3: 0.009212, l4: 0.011585, l5: 0.010854, l6: 0.014822

[epoch: 120/100000, batch:   110/  187, ite: 11241] train loss: 0.120012, tar: 0.012467 
l0: 0.005680, l1: 0.005978, l2: 0.006928, l3: 0.006926, l4: 0.016042, l5: 0.013844, l6: 0.014388

[epoch: 120/100000, batch:   112/  187, ite: 11242] train loss: 0.119971, tar: 0.012461 
l0: 0.005610, l1: 0.005716, l2: 0.007239, l3: 0.008971, l4: 0.012061, l5: 0.010779, l6: 0.007494

[epoch: 120/100000, batch:   114/  187, ite: 11243] train loss: 0.119921, tar: 0.012456 
l0: 0.010634, l1: 0.011185, l2: 0.011433, l3: 0.011453, l4: 0.015702, l5: 0.016293, l6: 0.016035

[epoch: 120/100000, batch:   116/  187, ite: 11244] train loss: 0.119899, tar: 0.012455 
l0: 0.010698, l1: 0.011900, l2: 0.009731, l3: 0.009218, l4: 0.014486, l5: 0.014434, l6: 0.012950

[epoch: 120/100000, batch:   118/  187, ite: 11245] train loss: 0.119870, tar: 0.012453 
l0: 0.006806, l1: 0.007014, l2: 0.006949, l3: 0.007253, l4: 0.014039, l5: 0.010836, l6: 0.012363

[epoch: 120/100000, batch:   120/  187, ite: 11246] train loss: 0.119826, tar: 0.012449 
l0: 0.006451, l1: 0.005381, l2: 0.007300, l3: 0.008541, l4: 0.028471, l5: 0.027508, l6: 0.026972

[epoch: 120/100000, batch:   122/  187, ite: 11247] train loss: 0.119819, tar: 0.012444 
l0: 0.007849, l1: 0.007950, l2: 0.009215, l3: 0.011531, l4: 0.016708, l5: 0.012713, l6: 0.019254

[epoch: 120/100000, batch:   124/  187, ite: 11248] train loss: 0.119791, tar: 0.012440 
l0: 0.006460, l1: 0.006661, l2: 0.007193, l3: 0.007370, l4: 0.009170, l5: 0.006164, l6: 0.012577

[epoch: 120/100000, batch:   126/  187, ite: 11249] train loss: 0.119740, tar: 0.012435 
l0: 0.004061, l1: 0.003867, l2: 0.006121, l3: 0.006770, l4: 0.008663, l5: 0.007029, l6: 0.007493

[epoch: 120/100000, batch:   128/  187, ite: 11250] train loss: 0.119679, tar: 0.012429 
l0: 0.006600, l1: 0.007375, l2: 0.006641, l3: 0.006607, l4: 0.009037, l5: 0.006960, l6: 0.009819

[epoch: 120/100000, batch:   130/  187, ite: 11251] train loss: 0.119626, tar: 0.012424 
l0: 0.011739, l1: 0.012635, l2: 0.013980, l3: 0.012902, l4: 0.022040, l5: 0.016550, l6: 0.014129

[epoch: 120/100000, batch:   132/  187, ite: 11252] train loss: 0.119613, tar: 0.012423 
l0: 0.011933, l1: 0.011515, l2: 0.012783, l3: 0.012066, l4: 0.027730, l5: 0.025874, l6: 0.025829

[epoch: 120/100000, batch:   134/  187, ite: 11253] train loss: 0.119620, tar: 0.012423 
l0: 0.007130, l1: 0.007474, l2: 0.007343, l3: 0.007158, l4: 0.011195, l5: 0.010516, l6: 0.019138

[epoch: 120/100000, batch:   136/  187, ite: 11254] train loss: 0.119580, tar: 0.012419 
l0: 0.008050, l1: 0.008350, l2: 0.008766, l3: 0.008560, l4: 0.012074, l5: 0.011371, l6: 0.012333

[epoch: 120/100000, batch:   138/  187, ite: 11255] train loss: 0.119540, tar: 0.012415 
l0: 0.004946, l1: 0.005893, l2: 0.004349, l3: 0.004471, l4: 0.006593, l5: 0.007609, l6: 0.008907

[epoch: 120/100000, batch:   140/  187, ite: 11256] train loss: 0.119479, tar: 0.012409 
l0: 0.004823, l1: 0.004527, l2: 0.005208, l3: 0.006036, l4: 0.010484, l5: 0.010763, l6: 0.010464

[epoch: 120/100000, batch:   142/  187, ite: 11257] train loss: 0.119426, tar: 0.012403 
l0: 0.008622, l1: 0.009186, l2: 0.008595, l3: 0.008397, l4: 0.012684, l5: 0.011765, l6: 0.013219

[epoch: 120/100000, batch:   144/  187, ite: 11258] train loss: 0.119388, tar: 0.012400 
l0: 0.006650, l1: 0.007091, l2: 0.007349, l3: 0.006860, l4: 0.014627, l5: 0.012888, l6: 0.013041

[epoch: 120/100000, batch:   146/  187, ite: 11259] train loss: 0.119348, tar: 0.012396 
l0: 0.006851, l1: 0.006456, l2: 0.006068, l3: 0.007202, l4: 0.017303, l5: 0.017429, l6: 0.015301

[epoch: 120/100000, batch:   148/  187, ite: 11260] train loss: 0.119314, tar: 0.012391 
l0: 0.005994, l1: 0.006044, l2: 0.006596, l3: 0.007029, l4: 0.011060, l5: 0.011173, l6: 0.010787

[epoch: 120/100000, batch:   150/  187, ite: 11261] train loss: 0.119266, tar: 0.012386 
l0: 0.006429, l1: 0.007535, l2: 0.006338, l3: 0.006328, l4: 0.010804, l5: 0.010361, l6: 0.012554

[epoch: 120/100000, batch:   152/  187, ite: 11262] train loss: 0.119219, tar: 0.012382 
l0: 0.007557, l1: 0.007525, l2: 0.007599, l3: 0.007763, l4: 0.015291, l5: 0.016278, l6: 0.013498

[epoch: 120/100000, batch:   154/  187, ite: 11263] train loss: 0.119185, tar: 0.012378 
l0: 0.010569, l1: 0.012774, l2: 0.008820, l3: 0.007976, l4: 0.006392, l5: 0.006050, l6: 0.006375

[epoch: 120/100000, batch:   156/  187, ite: 11264] train loss: 0.119137, tar: 0.012376 
l0: 0.021078, l1: 0.022411, l2: 0.018681, l3: 0.017529, l4: 0.025737, l5: 0.021707, l6: 0.026199

[epoch: 120/100000, batch:   158/  187, ite: 11265] train loss: 0.119164, tar: 0.012383 
l0: 0.004175, l1: 0.004615, l2: 0.004923, l3: 0.004368, l4: 0.007951, l5: 0.007647, l6: 0.009737

[epoch: 120/100000, batch:   160/  187, ite: 11266] train loss: 0.119104, tar: 0.012377 
l0: 0.003888, l1: 0.003998, l2: 0.004501, l3: 0.003588, l4: 0.004508, l5: 0.004763, l6: 0.006027

[epoch: 120/100000, batch:   162/  187, ite: 11267] train loss: 0.119035, tar: 0.012370 
l0: 0.004906, l1: 0.004656, l2: 0.005439, l3: 0.005122, l4: 0.009695, l5: 0.010212, l6: 0.012510

[epoch: 120/100000, batch:   164/  187, ite: 11268] train loss: 0.118983, tar: 0.012364 
l0: 0.011330, l1: 0.012242, l2: 0.013468, l3: 0.013631, l4: 0.017691, l5: 0.014079, l6: 0.012697

[epoch: 120/100000, batch:   166/  187, ite: 11269] train loss: 0.118964, tar: 0.012363 
l0: 0.009102, l1: 0.009501, l2: 0.009271, l3: 0.008123, l4: 0.011719, l5: 0.013995, l6: 0.013787

[epoch: 120/100000, batch:   168/  187, ite: 11270] train loss: 0.118930, tar: 0.012361 
l0: 0.006765, l1: 0.006835, l2: 0.006399, l3: 0.006022, l4: 0.009351, l5: 0.009343, l6: 0.013681

[epoch: 120/100000, batch:   170/  187, ite: 11271] train loss: 0.118882, tar: 0.012356 
l0: 0.005783, l1: 0.006101, l2: 0.005994, l3: 0.006698, l4: 0.015055, l5: 0.010810, l6: 0.013411

[epoch: 120/100000, batch:   172/  187, ite: 11272] train loss: 0.118839, tar: 0.012351 
l0: 0.007449, l1: 0.008297, l2: 0.008469, l3: 0.007980, l4: 0.012435, l5: 0.010900, l6: 0.013757

[epoch: 120/100000, batch:   174/  187, ite: 11273] train loss: 0.118800, tar: 0.012347 
l0: 0.005737, l1: 0.005958, l2: 0.005866, l3: 0.005703, l4: 0.017990, l5: 0.015568, l6: 0.013839

[epoch: 120/100000, batch:   176/  187, ite: 11274] train loss: 0.118762, tar: 0.012342 
l0: 0.009320, l1: 0.009879, l2: 0.009724, l3: 0.009786, l4: 0.015278, l5: 0.013371, l6: 0.015713

[epoch: 120/100000, batch:   178/  187, ite: 11275] train loss: 0.118734, tar: 0.012340 
l0: 0.004677, l1: 0.004749, l2: 0.005264, l3: 0.005201, l4: 0.012844, l5: 0.011306, l6: 0.010211

[epoch: 120/100000, batch:   180/  187, ite: 11276] train loss: 0.118683, tar: 0.012334 
l0: 0.006576, l1: 0.006749, l2: 0.006799, l3: 0.007069, l4: 0.011095, l5: 0.012156, l6: 0.010865

[epoch: 120/100000, batch:   182/  187, ite: 11277] train loss: 0.118639, tar: 0.012329 
l0: 0.004308, l1: 0.004124, l2: 0.006188, l3: 0.006064, l4: 0.005926, l5: 0.005418, l6: 0.006983

[epoch: 120/100000, batch:   184/  187, ite: 11278] train loss: 0.118576, tar: 0.012323 
l0: 0.009854, l1: 0.010542, l2: 0.009649, l3: 0.011023, l4: 0.012225, l5: 0.010586, l6: 0.008868

[epoch: 120/100000, batch:   186/  187, ite: 11279] train loss: 0.118540, tar: 0.012321 
l0: 0.003090, l1: 0.003020, l2: 0.003728, l3: 0.004052, l4: 0.005401, l5: 0.005412, l6: 0.006846

[epoch: 120/100000, batch:   188/  187, ite: 11280] train loss: 0.118472, tar: 0.012314 
l0: 0.008085, l1: 0.008535, l2: 0.007832, l3: 0.007752, l4: 0.012336, l5: 0.010696, l6: 0.013736

[epoch: 121/100000, batch:     2/  187, ite: 11281] train loss: 0.118434, tar: 0.012311 
l0: 0.005819, l1: 0.005988, l2: 0.006110, l3: 0.005590, l4: 0.009183, l5: 0.007926, l6: 0.009077

[epoch: 121/100000, batch:     4/  187, ite: 11282] train loss: 0.118380, tar: 0.012305 
l0: 0.007664, l1: 0.007929, l2: 0.009408, l3: 0.008671, l4: 0.011939, l5: 0.010064, l6: 0.010395

[epoch: 121/100000, batch:     6/  187, ite: 11283] train loss: 0.118339, tar: 0.012302 
l0: 0.006687, l1: 0.006331, l2: 0.008470, l3: 0.007114, l4: 0.009996, l5: 0.010618, l6: 0.012072

[epoch: 121/100000, batch:     8/  187, ite: 11284] train loss: 0.118295, tar: 0.012297 
l0: 0.007668, l1: 0.008181, l2: 0.009629, l3: 0.009375, l4: 0.012265, l5: 0.010372, l6: 0.012464

[epoch: 121/100000, batch:    10/  187, ite: 11285] train loss: 0.118257, tar: 0.012294 
l0: 0.006973, l1: 0.007471, l2: 0.007648, l3: 0.007271, l4: 0.010138, l5: 0.010067, l6: 0.010399

[epoch: 121/100000, batch:    12/  187, ite: 11286] train loss: 0.118212, tar: 0.012290 
l0: 0.005930, l1: 0.006417, l2: 0.006261, l3: 0.007303, l4: 0.009692, l5: 0.007697, l6: 0.009201

[epoch: 121/100000, batch:    14/  187, ite: 11287] train loss: 0.118161, tar: 0.012285 
l0: 0.005691, l1: 0.005865, l2: 0.005187, l3: 0.005951, l4: 0.009740, l5: 0.009322, l6: 0.009906

[epoch: 121/100000, batch:    16/  187, ite: 11288] train loss: 0.118109, tar: 0.012280 
l0: 0.010195, l1: 0.012117, l2: 0.012655, l3: 0.010583, l4: 0.016337, l5: 0.013607, l6: 0.015223

[epoch: 121/100000, batch:    18/  187, ite: 11289] train loss: 0.118088, tar: 0.012278 
l0: 0.006345, l1: 0.006530, l2: 0.006626, l3: 0.007023, l4: 0.010302, l5: 0.009577, l6: 0.011197

[epoch: 121/100000, batch:    20/  187, ite: 11290] train loss: 0.118041, tar: 0.012273 
l0: 0.010023, l1: 0.010164, l2: 0.010362, l3: 0.010012, l4: 0.026488, l5: 0.023633, l6: 0.019741

[epoch: 121/100000, batch:    22/  187, ite: 11291] train loss: 0.118035, tar: 0.012272 
l0: 0.005125, l1: 0.005751, l2: 0.005045, l3: 0.004734, l4: 0.006375, l5: 0.006905, l6: 0.008136

[epoch: 121/100000, batch:    24/  187, ite: 11292] train loss: 0.117976, tar: 0.012266 
l0: 0.006082, l1: 0.006442, l2: 0.006846, l3: 0.006975, l4: 0.010700, l5: 0.009415, l6: 0.009955

[epoch: 121/100000, batch:    26/  187, ite: 11293] train loss: 0.117929, tar: 0.012261 
l0: 0.006334, l1: 0.006847, l2: 0.006822, l3: 0.006501, l4: 0.011719, l5: 0.010306, l6: 0.013237

[epoch: 121/100000, batch:    28/  187, ite: 11294] train loss: 0.117885, tar: 0.012257 
l0: 0.007361, l1: 0.007601, l2: 0.008470, l3: 0.007953, l4: 0.011325, l5: 0.010697, l6: 0.010847

[epoch: 121/100000, batch:    30/  187, ite: 11295] train loss: 0.117844, tar: 0.012253 
l0: 0.005398, l1: 0.006141, l2: 0.006266, l3: 0.005827, l4: 0.011053, l5: 0.010173, l6: 0.016914

[epoch: 121/100000, batch:    32/  187, ite: 11296] train loss: 0.117801, tar: 0.012248 
l0: 0.005914, l1: 0.006177, l2: 0.006709, l3: 0.007770, l4: 0.008638, l5: 0.009430, l6: 0.010727

[epoch: 121/100000, batch:    34/  187, ite: 11297] train loss: 0.117753, tar: 0.012243 
l0: 0.006900, l1: 0.007307, l2: 0.007036, l3: 0.005975, l4: 0.009494, l5: 0.008759, l6: 0.010738

[epoch: 121/100000, batch:    36/  187, ite: 11298] train loss: 0.117705, tar: 0.012239 
l0: 0.005868, l1: 0.005836, l2: 0.008540, l3: 0.007861, l4: 0.010991, l5: 0.009909, l6: 0.011539

[epoch: 121/100000, batch:    38/  187, ite: 11299] train loss: 0.117661, tar: 0.012234 
l0: 0.008943, l1: 0.010023, l2: 0.010795, l3: 0.008966, l4: 0.009835, l5: 0.009346, l6: 0.010753

[epoch: 121/100000, batch:    40/  187, ite: 11300] train loss: 0.117624, tar: 0.012231 
l0: 0.008622, l1: 0.008933, l2: 0.008718, l3: 0.008987, l4: 0.011539, l5: 0.011730, l6: 0.013100

[epoch: 121/100000, batch:    42/  187, ite: 11301] train loss: 0.117588, tar: 0.012229 
l0: 0.006437, l1: 0.006684, l2: 0.006234, l3: 0.006143, l4: 0.014200, l5: 0.014980, l6: 0.016539

[epoch: 121/100000, batch:    44/  187, ite: 11302] train loss: 0.117553, tar: 0.012224 
l0: 0.004709, l1: 0.004924, l2: 0.005476, l3: 0.004841, l4: 0.006923, l5: 0.006844, l6: 0.007029

[epoch: 121/100000, batch:    46/  187, ite: 11303] train loss: 0.117494, tar: 0.012218 
l0: 0.003599, l1: 0.005183, l2: 0.003892, l3: 0.002453, l4: 0.004596, l5: 0.006165, l6: 0.005170

[epoch: 121/100000, batch:    48/  187, ite: 11304] train loss: 0.117427, tar: 0.012212 
l0: 0.005878, l1: 0.005937, l2: 0.006090, l3: 0.006648, l4: 0.012236, l5: 0.012850, l6: 0.010329

[epoch: 121/100000, batch:    50/  187, ite: 11305] train loss: 0.117383, tar: 0.012207 
l0: 0.006711, l1: 0.007063, l2: 0.009494, l3: 0.009640, l4: 0.011858, l5: 0.010911, l6: 0.010165

[epoch: 121/100000, batch:    52/  187, ite: 11306] train loss: 0.117344, tar: 0.012203 
l0: 0.006544, l1: 0.007358, l2: 0.008703, l3: 0.007970, l4: 0.008707, l5: 0.010399, l6: 0.011773

[epoch: 121/100000, batch:    54/  187, ite: 11307] train loss: 0.117301, tar: 0.012198 
l0: 0.012225, l1: 0.011442, l2: 0.010297, l3: 0.011166, l4: 0.016335, l5: 0.017747, l6: 0.021159

[epoch: 121/100000, batch:    56/  187, ite: 11308] train loss: 0.117288, tar: 0.012198 
l0: 0.006249, l1: 0.006451, l2: 0.006973, l3: 0.007759, l4: 0.010578, l5: 0.009592, l6: 0.007254

[epoch: 121/100000, batch:    58/  187, ite: 11309] train loss: 0.117240, tar: 0.012194 
l0: 0.017878, l1: 0.018733, l2: 0.019421, l3: 0.018301, l4: 0.019413, l5: 0.019990, l6: 0.024128

[epoch: 121/100000, batch:    60/  187, ite: 11310] train loss: 0.117256, tar: 0.012198 
l0: 0.006545, l1: 0.007299, l2: 0.006650, l3: 0.006274, l4: 0.012721, l5: 0.010706, l6: 0.013061

[epoch: 121/100000, batch:    62/  187, ite: 11311] train loss: 0.117215, tar: 0.012194 
l0: 0.004366, l1: 0.004456, l2: 0.006200, l3: 0.005991, l4: 0.008301, l5: 0.007274, l6: 0.008301

[epoch: 121/100000, batch:    64/  187, ite: 11312] train loss: 0.117160, tar: 0.012188 
l0: 0.007691, l1: 0.008826, l2: 0.008798, l3: 0.007057, l4: 0.010097, l5: 0.008408, l6: 0.010287

[epoch: 121/100000, batch:    66/  187, ite: 11313] train loss: 0.117117, tar: 0.012184 
l0: 0.009061, l1: 0.009074, l2: 0.010714, l3: 0.010113, l4: 0.016568, l5: 0.017184, l6: 0.018238

[epoch: 121/100000, batch:    68/  187, ite: 11314] train loss: 0.117097, tar: 0.012182 
l0: 0.005758, l1: 0.006282, l2: 0.006216, l3: 0.005852, l4: 0.012399, l5: 0.011300, l6: 0.010301

[epoch: 121/100000, batch:    70/  187, ite: 11315] train loss: 0.117052, tar: 0.012177 
l0: 0.006379, l1: 0.007276, l2: 0.007450, l3: 0.007008, l4: 0.009352, l5: 0.008724, l6: 0.009869

[epoch: 121/100000, batch:    72/  187, ite: 11316] train loss: 0.117006, tar: 0.012173 
l0: 0.006494, l1: 0.006875, l2: 0.005961, l3: 0.007222, l4: 0.011401, l5: 0.011446, l6: 0.010676

[epoch: 121/100000, batch:    74/  187, ite: 11317] train loss: 0.116963, tar: 0.012168 
l0: 0.007319, l1: 0.006996, l2: 0.009175, l3: 0.009943, l4: 0.015765, l5: 0.014154, l6: 0.015340

[epoch: 121/100000, batch:    76/  187, ite: 11318] train loss: 0.116934, tar: 0.012165 
l0: 0.004334, l1: 0.004317, l2: 0.004841, l3: 0.005220, l4: 0.007609, l5: 0.007770, l6: 0.010183

[epoch: 121/100000, batch:    78/  187, ite: 11319] train loss: 0.116879, tar: 0.012159 
l0: 0.004028, l1: 0.004612, l2: 0.003417, l3: 0.003665, l4: 0.004882, l5: 0.004616, l6: 0.005485

[epoch: 121/100000, batch:    80/  187, ite: 11320] train loss: 0.116813, tar: 0.012153 
l0: 0.007877, l1: 0.007869, l2: 0.006524, l3: 0.009141, l4: 0.011077, l5: 0.010186, l6: 0.012916

[epoch: 121/100000, batch:    82/  187, ite: 11321] train loss: 0.116775, tar: 0.012149 
l0: 0.005324, l1: 0.005627, l2: 0.006613, l3: 0.006096, l4: 0.007512, l5: 0.007294, l6: 0.008271

[epoch: 121/100000, batch:    84/  187, ite: 11322] train loss: 0.116722, tar: 0.012144 
l0: 0.010028, l1: 0.010365, l2: 0.010907, l3: 0.010737, l4: 0.014486, l5: 0.012486, l6: 0.013434

[epoch: 121/100000, batch:    86/  187, ite: 11323] train loss: 0.116696, tar: 0.012143 
l0: 0.005314, l1: 0.005674, l2: 0.005516, l3: 0.005453, l4: 0.008690, l5: 0.009884, l6: 0.011133

[epoch: 121/100000, batch:    88/  187, ite: 11324] train loss: 0.116647, tar: 0.012137 
l0: 0.006695, l1: 0.008177, l2: 0.007732, l3: 0.007148, l4: 0.009253, l5: 0.008493, l6: 0.010501

[epoch: 121/100000, batch:    90/  187, ite: 11325] train loss: 0.116602, tar: 0.012133 
l0: 0.005451, l1: 0.005422, l2: 0.005548, l3: 0.005533, l4: 0.009405, l5: 0.009905, l6: 0.010731

[epoch: 121/100000, batch:    92/  187, ite: 11326] train loss: 0.116554, tar: 0.012128 
l0: 0.004204, l1: 0.004382, l2: 0.003783, l3: 0.004985, l4: 0.005825, l5: 0.005687, l6: 0.006608

[epoch: 121/100000, batch:    94/  187, ite: 11327] train loss: 0.116493, tar: 0.012122 
l0: 0.008662, l1: 0.009049, l2: 0.010421, l3: 0.010318, l4: 0.013488, l5: 0.012550, l6: 0.013340

[epoch: 121/100000, batch:    96/  187, ite: 11328] train loss: 0.116463, tar: 0.012120 
l0: 0.006383, l1: 0.006198, l2: 0.006290, l3: 0.007045, l4: 0.010728, l5: 0.011418, l6: 0.020083

[epoch: 121/100000, batch:    98/  187, ite: 11329] train loss: 0.116427, tar: 0.012115 
l0: 0.007367, l1: 0.007308, l2: 0.008403, l3: 0.007741, l4: 0.011949, l5: 0.012892, l6: 0.014808

[epoch: 121/100000, batch:   100/  187, ite: 11330] train loss: 0.116393, tar: 0.012112 
l0: 0.006174, l1: 0.005649, l2: 0.007317, l3: 0.008667, l4: 0.014380, l5: 0.014073, l6: 0.015548

[epoch: 121/100000, batch:   102/  187, ite: 11331] train loss: 0.116359, tar: 0.012107 
l0: 0.006114, l1: 0.006096, l2: 0.006926, l3: 0.006813, l4: 0.008483, l5: 0.008945, l6: 0.010948

[epoch: 121/100000, batch:   104/  187, ite: 11332] train loss: 0.116312, tar: 0.012103 
l0: 0.005805, l1: 0.006117, l2: 0.006841, l3: 0.006362, l4: 0.009348, l5: 0.009186, l6: 0.008752

[epoch: 121/100000, batch:   106/  187, ite: 11333] train loss: 0.116265, tar: 0.012098 
l0: 0.006138, l1: 0.006757, l2: 0.006007, l3: 0.005520, l4: 0.012538, l5: 0.010658, l6: 0.012805

[epoch: 121/100000, batch:   108/  187, ite: 11334] train loss: 0.116223, tar: 0.012094 
l0: 0.005645, l1: 0.004826, l2: 0.005362, l3: 0.005081, l4: 0.012775, l5: 0.012607, l6: 0.013354

[epoch: 121/100000, batch:   110/  187, ite: 11335] train loss: 0.116180, tar: 0.012089 
l0: 0.005707, l1: 0.005723, l2: 0.005205, l3: 0.005980, l4: 0.019916, l5: 0.012663, l6: 0.014339

[epoch: 121/100000, batch:   112/  187, ite: 11336] train loss: 0.116145, tar: 0.012084 
l0: 0.011473, l1: 0.010327, l2: 0.013153, l3: 0.013253, l4: 0.019812, l5: 0.018824, l6: 0.018535

[epoch: 121/100000, batch:   114/  187, ite: 11337] train loss: 0.116137, tar: 0.012084 
l0: 0.005415, l1: 0.004910, l2: 0.005876, l3: 0.006979, l4: 0.015609, l5: 0.009996, l6: 0.014449

[epoch: 121/100000, batch:   116/  187, ite: 11338] train loss: 0.116098, tar: 0.012079 
l0: 0.009362, l1: 0.008946, l2: 0.008550, l3: 0.011507, l4: 0.015596, l5: 0.013475, l6: 0.015692

[epoch: 121/100000, batch:   118/  187, ite: 11339] train loss: 0.116073, tar: 0.012077 
l0: 0.007302, l1: 0.007600, l2: 0.007658, l3: 0.007489, l4: 0.010344, l5: 0.013604, l6: 0.012436

[epoch: 121/100000, batch:   120/  187, ite: 11340] train loss: 0.116036, tar: 0.012073 
l0: 0.005444, l1: 0.004681, l2: 0.004788, l3: 0.005856, l4: 0.012393, l5: 0.015890, l6: 0.013128

[epoch: 121/100000, batch:   122/  187, ite: 11341] train loss: 0.115996, tar: 0.012068 
l0: 0.006009, l1: 0.006226, l2: 0.005769, l3: 0.005905, l4: 0.010032, l5: 0.009840, l6: 0.010917

[epoch: 121/100000, batch:   124/  187, ite: 11342] train loss: 0.115950, tar: 0.012064 
l0: 0.005222, l1: 0.005111, l2: 0.005613, l3: 0.006177, l4: 0.008639, l5: 0.009916, l6: 0.010329

[epoch: 121/100000, batch:   126/  187, ite: 11343] train loss: 0.115902, tar: 0.012059 
l0: 0.004035, l1: 0.004222, l2: 0.004445, l3: 0.004806, l4: 0.010043, l5: 0.009712, l6: 0.008606

[epoch: 121/100000, batch:   128/  187, ite: 11344] train loss: 0.115850, tar: 0.012053 
l0: 0.008871, l1: 0.009561, l2: 0.009773, l3: 0.009880, l4: 0.016025, l5: 0.016530, l6: 0.016438

[epoch: 121/100000, batch:   130/  187, ite: 11345] train loss: 0.115828, tar: 0.012050 
l0: 0.004667, l1: 0.004545, l2: 0.004095, l3: 0.004711, l4: 0.007676, l5: 0.009241, l6: 0.008187

[epoch: 121/100000, batch:   132/  187, ite: 11346] train loss: 0.115774, tar: 0.012045 
l0: 0.003640, l1: 0.006317, l2: 0.003988, l3: 0.008951, l4: 0.010620, l5: 0.009363, l6: 0.007737

[epoch: 121/100000, batch:   134/  187, ite: 11347] train loss: 0.115726, tar: 0.012038 
l0: 0.009555, l1: 0.010318, l2: 0.010586, l3: 0.010061, l4: 0.008671, l5: 0.008076, l6: 0.007674

[epoch: 121/100000, batch:   136/  187, ite: 11348] train loss: 0.115688, tar: 0.012037 
l0: 0.005624, l1: 0.005454, l2: 0.005978, l3: 0.006603, l4: 0.012047, l5: 0.009330, l6: 0.013722

[epoch: 121/100000, batch:   138/  187, ite: 11349] train loss: 0.115646, tar: 0.012032 
l0: 0.006326, l1: 0.006473, l2: 0.006877, l3: 0.006147, l4: 0.012488, l5: 0.011584, l6: 0.012360

[epoch: 121/100000, batch:   140/  187, ite: 11350] train loss: 0.115607, tar: 0.012028 
l0: 0.008757, l1: 0.008857, l2: 0.009346, l3: 0.009062, l4: 0.013988, l5: 0.011814, l6: 0.014664

[epoch: 121/100000, batch:   142/  187, ite: 11351] train loss: 0.115578, tar: 0.012025 
l0: 0.004340, l1: 0.004871, l2: 0.005565, l3: 0.004277, l4: 0.008133, l5: 0.005784, l6: 0.005831

[epoch: 121/100000, batch:   144/  187, ite: 11352] train loss: 0.115521, tar: 0.012020 
l0: 0.006934, l1: 0.008093, l2: 0.007572, l3: 0.008971, l4: 0.008318, l5: 0.005926, l6: 0.007056

[epoch: 121/100000, batch:   146/  187, ite: 11353] train loss: 0.115475, tar: 0.012016 
l0: 0.007164, l1: 0.006744, l2: 0.007206, l3: 0.006846, l4: 0.010723, l5: 0.013065, l6: 0.011391

[epoch: 121/100000, batch:   148/  187, ite: 11354] train loss: 0.115436, tar: 0.012012 
l0: 0.007295, l1: 0.007628, l2: 0.008482, l3: 0.008432, l4: 0.013879, l5: 0.013317, l6: 0.016089

[epoch: 121/100000, batch:   150/  187, ite: 11355] train loss: 0.115406, tar: 0.012009 
l0: 0.009365, l1: 0.009472, l2: 0.010155, l3: 0.011488, l4: 0.015406, l5: 0.012222, l6: 0.013170

[epoch: 121/100000, batch:   152/  187, ite: 11356] train loss: 0.115381, tar: 0.012007 
l0: 0.005535, l1: 0.005200, l2: 0.005654, l3: 0.006182, l4: 0.009210, l5: 0.009791, l6: 0.014571

[epoch: 121/100000, batch:   154/  187, ite: 11357] train loss: 0.115337, tar: 0.012002 
l0: 0.005779, l1: 0.005459, l2: 0.005851, l3: 0.006431, l4: 0.009394, l5: 0.010152, l6: 0.014540

[epoch: 121/100000, batch:   156/  187, ite: 11358] train loss: 0.115295, tar: 0.011997 
l0: 0.004315, l1: 0.004087, l2: 0.004390, l3: 0.004983, l4: 0.008765, l5: 0.008781, l6: 0.009246

[epoch: 121/100000, batch:   158/  187, ite: 11359] train loss: 0.115243, tar: 0.011992 
l0: 0.009536, l1: 0.009459, l2: 0.009055, l3: 0.011115, l4: 0.013899, l5: 0.016744, l6: 0.011404

[epoch: 121/100000, batch:   160/  187, ite: 11360] train loss: 0.115218, tar: 0.011990 
l0: 0.005817, l1: 0.005640, l2: 0.005788, l3: 0.006350, l4: 0.011534, l5: 0.011905, l6: 0.014825

[epoch: 121/100000, batch:   162/  187, ite: 11361] train loss: 0.115179, tar: 0.011985 
l0: 0.010907, l1: 0.011901, l2: 0.012903, l3: 0.013204, l4: 0.011709, l5: 0.010636, l6: 0.012038

[epoch: 121/100000, batch:   164/  187, ite: 11362] train loss: 0.115155, tar: 0.011985 
l0: 0.005426, l1: 0.005859, l2: 0.006778, l3: 0.006786, l4: 0.012747, l5: 0.011575, l6: 0.010984

[epoch: 121/100000, batch:   166/  187, ite: 11363] train loss: 0.115115, tar: 0.011980 
l0: 0.005599, l1: 0.005793, l2: 0.005838, l3: 0.006647, l4: 0.010967, l5: 0.011039, l6: 0.010848

[epoch: 121/100000, batch:   168/  187, ite: 11364] train loss: 0.115072, tar: 0.011975 
l0: 0.009328, l1: 0.009557, l2: 0.009228, l3: 0.012100, l4: 0.015189, l5: 0.014264, l6: 0.012555

[epoch: 121/100000, batch:   170/  187, ite: 11365] train loss: 0.115048, tar: 0.011973 
l0: 0.006383, l1: 0.006327, l2: 0.006184, l3: 0.006540, l4: 0.010213, l5: 0.010190, l6: 0.011249

[epoch: 121/100000, batch:   172/  187, ite: 11366] train loss: 0.115006, tar: 0.011969 
l0: 0.007261, l1: 0.008166, l2: 0.008652, l3: 0.008879, l4: 0.016358, l5: 0.013187, l6: 0.016312

[epoch: 121/100000, batch:   174/  187, ite: 11367] train loss: 0.114979, tar: 0.011966 
l0: 0.006510, l1: 0.007145, l2: 0.007485, l3: 0.007971, l4: 0.013107, l5: 0.009270, l6: 0.008753

[epoch: 121/100000, batch:   176/  187, ite: 11368] train loss: 0.114939, tar: 0.011962 
l0: 0.004283, l1: 0.004873, l2: 0.005965, l3: 0.005201, l4: 0.006407, l5: 0.005212, l6: 0.006027

[epoch: 121/100000, batch:   178/  187, ite: 11369] train loss: 0.114883, tar: 0.011956 
l0: 0.008338, l1: 0.008666, l2: 0.010030, l3: 0.010279, l4: 0.006241, l5: 0.007588, l6: 0.007781

[epoch: 121/100000, batch:   180/  187, ite: 11370] train loss: 0.114842, tar: 0.011953 
l0: 0.015159, l1: 0.018319, l2: 0.017867, l3: 0.015619, l4: 0.010688, l5: 0.008314, l6: 0.008132

[epoch: 121/100000, batch:   182/  187, ite: 11371] train loss: 0.114827, tar: 0.011956 
l0: 0.012126, l1: 0.013098, l2: 0.014622, l3: 0.013266, l4: 0.013478, l5: 0.011814, l6: 0.011103

[epoch: 121/100000, batch:   184/  187, ite: 11372] train loss: 0.114808, tar: 0.011956 
l0: 0.005848, l1: 0.005086, l2: 0.006181, l3: 0.008295, l4: 0.014987, l5: 0.015247, l6: 0.013205

[epoch: 121/100000, batch:   186/  187, ite: 11373] train loss: 0.114775, tar: 0.011951 
l0: 0.004723, l1: 0.004884, l2: 0.006690, l3: 0.007238, l4: 0.007431, l5: 0.005251, l6: 0.008150

[epoch: 121/100000, batch:   188/  187, ite: 11374] train loss: 0.114724, tar: 0.011946 
l0: 0.007726, l1: 0.007674, l2: 0.009610, l3: 0.009567, l4: 0.011240, l5: 0.010853, l6: 0.013719

[epoch: 122/100000, batch:     2/  187, ite: 11375] train loss: 0.114691, tar: 0.011943 
l0: 0.003526, l1: 0.003697, l2: 0.004136, l3: 0.003843, l4: 0.006976, l5: 0.006080, l6: 0.005976

[epoch: 122/100000, batch:     4/  187, ite: 11376] train loss: 0.114633, tar: 0.011937 
l0: 0.010095, l1: 0.010351, l2: 0.008903, l3: 0.007866, l4: 0.008883, l5: 0.010875, l6: 0.009082

[epoch: 122/100000, batch:     6/  187, ite: 11377] train loss: 0.114598, tar: 0.011936 
l0: 0.007991, l1: 0.008988, l2: 0.009322, l3: 0.007597, l4: 0.009436, l5: 0.008440, l6: 0.010204

[epoch: 122/100000, batch:     8/  187, ite: 11378] train loss: 0.114559, tar: 0.011933 
l0: 0.004238, l1: 0.004249, l2: 0.004777, l3: 0.004754, l4: 0.008251, l5: 0.006354, l6: 0.009214

[epoch: 122/100000, batch:    10/  187, ite: 11379] train loss: 0.114507, tar: 0.011927 
l0: 0.006489, l1: 0.005722, l2: 0.006349, l3: 0.006616, l4: 0.014639, l5: 0.020340, l6: 0.021822

[epoch: 122/100000, batch:    12/  187, ite: 11380] train loss: 0.114483, tar: 0.011923 
l0: 0.005303, l1: 0.005478, l2: 0.006629, l3: 0.006238, l4: 0.014287, l5: 0.014556, l6: 0.013007

[epoch: 122/100000, batch:    14/  187, ite: 11381] train loss: 0.114448, tar: 0.011918 
l0: 0.018829, l1: 0.021294, l2: 0.021894, l3: 0.019451, l4: 0.021906, l5: 0.016140, l6: 0.019028

[epoch: 122/100000, batch:    16/  187, ite: 11382] train loss: 0.114465, tar: 0.011923 
l0: 0.008967, l1: 0.008696, l2: 0.009423, l3: 0.008341, l4: 0.010444, l5: 0.013472, l6: 0.019166

[epoch: 122/100000, batch:    18/  187, ite: 11383] train loss: 0.114439, tar: 0.011921 
l0: 0.006535, l1: 0.007210, l2: 0.008212, l3: 0.007325, l4: 0.011561, l5: 0.012587, l6: 0.013290

[epoch: 122/100000, batch:    20/  187, ite: 11384] train loss: 0.114405, tar: 0.011917 
l0: 0.009156, l1: 0.009369, l2: 0.011901, l3: 0.011029, l4: 0.015029, l5: 0.013737, l6: 0.014745

[epoch: 122/100000, batch:    22/  187, ite: 11385] train loss: 0.114383, tar: 0.011915 
l0: 0.005763, l1: 0.006114, l2: 0.006198, l3: 0.006536, l4: 0.010605, l5: 0.009059, l6: 0.012060

[epoch: 122/100000, batch:    24/  187, ite: 11386] train loss: 0.114342, tar: 0.011911 
l0: 0.007237, l1: 0.007188, l2: 0.008348, l3: 0.008149, l4: 0.015756, l5: 0.013670, l6: 0.011588

[epoch: 122/100000, batch:    26/  187, ite: 11387] train loss: 0.114311, tar: 0.011908 
l0: 0.006838, l1: 0.006848, l2: 0.008310, l3: 0.007883, l4: 0.013403, l5: 0.012226, l6: 0.012921

[epoch: 122/100000, batch:    28/  187, ite: 11388] train loss: 0.114278, tar: 0.011904 
l0: 0.005484, l1: 0.005776, l2: 0.006668, l3: 0.006633, l4: 0.009349, l5: 0.010111, l6: 0.010468

[epoch: 122/100000, batch:    30/  187, ite: 11389] train loss: 0.114235, tar: 0.011899 
l0: 0.004748, l1: 0.005081, l2: 0.005106, l3: 0.004943, l4: 0.006763, l5: 0.007222, l6: 0.009065

[epoch: 122/100000, batch:    32/  187, ite: 11390] train loss: 0.114184, tar: 0.011894 
l0: 0.011428, l1: 0.009755, l2: 0.012896, l3: 0.013421, l4: 0.017149, l5: 0.018926, l6: 0.013706

[epoch: 122/100000, batch:    34/  187, ite: 11391] train loss: 0.114171, tar: 0.011894 
l0: 0.006869, l1: 0.007319, l2: 0.006780, l3: 0.006386, l4: 0.008130, l5: 0.008609, l6: 0.009037

[epoch: 122/100000, batch:    36/  187, ite: 11392] train loss: 0.114128, tar: 0.011890 
l0: 0.007577, l1: 0.008717, l2: 0.006060, l3: 0.006611, l4: 0.009321, l5: 0.009492, l6: 0.011983

[epoch: 122/100000, batch:    38/  187, ite: 11393] train loss: 0.114089, tar: 0.011887 
l0: 0.004335, l1: 0.004343, l2: 0.004696, l3: 0.005617, l4: 0.006173, l5: 0.005569, l6: 0.006996

[epoch: 122/100000, batch:    40/  187, ite: 11394] train loss: 0.114034, tar: 0.011882 
l0: 0.007810, l1: 0.008886, l2: 0.008807, l3: 0.007691, l4: 0.010616, l5: 0.009438, l6: 0.012384

[epoch: 122/100000, batch:    42/  187, ite: 11395] train loss: 0.113999, tar: 0.011879 
l0: 0.009537, l1: 0.009515, l2: 0.010174, l3: 0.011434, l4: 0.014091, l5: 0.013104, l6: 0.015485

[epoch: 122/100000, batch:    44/  187, ite: 11396] train loss: 0.113977, tar: 0.011877 
l0: 0.006473, l1: 0.006902, l2: 0.006866, l3: 0.006194, l4: 0.011313, l5: 0.010849, l6: 0.012377

[epoch: 122/100000, batch:    46/  187, ite: 11397] train loss: 0.113939, tar: 0.011873 
l0: 0.008065, l1: 0.008563, l2: 0.008445, l3: 0.008736, l4: 0.012624, l5: 0.013036, l6: 0.011480

[epoch: 122/100000, batch:    48/  187, ite: 11398] train loss: 0.113908, tar: 0.011871 
l0: 0.011102, l1: 0.011223, l2: 0.012347, l3: 0.012473, l4: 0.018586, l5: 0.015925, l6: 0.016198

[epoch: 122/100000, batch:    50/  187, ite: 11399] train loss: 0.113897, tar: 0.011870 
l0: 0.005975, l1: 0.006106, l2: 0.006968, l3: 0.007582, l4: 0.013580, l5: 0.013912, l6: 0.010576

[epoch: 122/100000, batch:    52/  187, ite: 11400] train loss: 0.113862, tar: 0.011866 
l0: 0.004109, l1: 0.004920, l2: 0.005296, l3: 0.005591, l4: 0.008057, l5: 0.007103, l6: 0.008063

[epoch: 122/100000, batch:    54/  187, ite: 11401] train loss: 0.113811, tar: 0.011860 
l0: 0.006676, l1: 0.007148, l2: 0.006922, l3: 0.007359, l4: 0.009820, l5: 0.010508, l6: 0.008078

[epoch: 122/100000, batch:    56/  187, ite: 11402] train loss: 0.113770, tar: 0.011857 
l0: 0.008494, l1: 0.008427, l2: 0.009353, l3: 0.008304, l4: 0.011917, l5: 0.013509, l6: 0.012717

[epoch: 122/100000, batch:    58/  187, ite: 11403] train loss: 0.113741, tar: 0.011854 
l0: 0.010446, l1: 0.011855, l2: 0.012740, l3: 0.009866, l4: 0.014881, l5: 0.011944, l6: 0.015595

[epoch: 122/100000, batch:    60/  187, ite: 11404] train loss: 0.113722, tar: 0.011853 
l0: 0.005026, l1: 0.004850, l2: 0.006362, l3: 0.007350, l4: 0.009440, l5: 0.008407, l6: 0.010246

[epoch: 122/100000, batch:    62/  187, ite: 11405] train loss: 0.113678, tar: 0.011848 
l0: 0.007720, l1: 0.008412, l2: 0.008453, l3: 0.007791, l4: 0.009074, l5: 0.009489, l6: 0.009599

[epoch: 122/100000, batch:    64/  187, ite: 11406] train loss: 0.113640, tar: 0.011845 
l0: 0.006552, l1: 0.006621, l2: 0.006396, l3: 0.006067, l4: 0.007049, l5: 0.007447, l6: 0.010520

[epoch: 122/100000, batch:    66/  187, ite: 11407] train loss: 0.113596, tar: 0.011842 
l0: 0.006747, l1: 0.006734, l2: 0.008336, l3: 0.008913, l4: 0.010387, l5: 0.011035, l6: 0.012487

[epoch: 122/100000, batch:    68/  187, ite: 11408] train loss: 0.113561, tar: 0.011838 
l0: 0.007542, l1: 0.007854, l2: 0.008210, l3: 0.007178, l4: 0.011011, l5: 0.011863, l6: 0.011367

[epoch: 122/100000, batch:    70/  187, ite: 11409] train loss: 0.113526, tar: 0.011835 
l0: 0.006218, l1: 0.006710, l2: 0.006662, l3: 0.006749, l4: 0.010337, l5: 0.009260, l6: 0.010678

[epoch: 122/100000, batch:    72/  187, ite: 11410] train loss: 0.113486, tar: 0.011831 
l0: 0.011941, l1: 0.011698, l2: 0.012496, l3: 0.013110, l4: 0.011653, l5: 0.012260, l6: 0.008925

[epoch: 122/100000, batch:    74/  187, ite: 11411] train loss: 0.113464, tar: 0.011831 
l0: 0.006531, l1: 0.006634, l2: 0.006734, l3: 0.007209, l4: 0.009971, l5: 0.009685, l6: 0.012435

[epoch: 122/100000, batch:    76/  187, ite: 11412] train loss: 0.113425, tar: 0.011827 
l0: 0.005605, l1: 0.005813, l2: 0.006540, l3: 0.006317, l4: 0.010138, l5: 0.011960, l6: 0.015468

[epoch: 122/100000, batch:    78/  187, ite: 11413] train loss: 0.113389, tar: 0.011823 
l0: 0.003531, l1: 0.003433, l2: 0.004005, l3: 0.004177, l4: 0.007219, l5: 0.009866, l6: 0.007921

[epoch: 122/100000, batch:    80/  187, ite: 11414] train loss: 0.113337, tar: 0.011817 
l0: 0.008978, l1: 0.008791, l2: 0.009474, l3: 0.010032, l4: 0.013768, l5: 0.012932, l6: 0.014846

[epoch: 122/100000, batch:    82/  187, ite: 11415] train loss: 0.113313, tar: 0.011815 
l0: 0.007683, l1: 0.006949, l2: 0.010724, l3: 0.013120, l4: 0.011725, l5: 0.011060, l6: 0.010679

[epoch: 122/100000, batch:    84/  187, ite: 11416] train loss: 0.113283, tar: 0.011812 
l0: 0.004200, l1: 0.004698, l2: 0.005221, l3: 0.005129, l4: 0.009093, l5: 0.007580, l6: 0.008400

[epoch: 122/100000, batch:    86/  187, ite: 11417] train loss: 0.113235, tar: 0.011807 
l0: 0.002881, l1: 0.003242, l2: 0.003139, l3: 0.002963, l4: 0.007485, l5: 0.005730, l6: 0.005449

[epoch: 122/100000, batch:    88/  187, ite: 11418] train loss: 0.113177, tar: 0.011800 
l0: 0.002968, l1: 0.002400, l2: 0.002601, l3: 0.005621, l4: 0.013576, l5: 0.015137, l6: 0.007122

[epoch: 122/100000, batch:    90/  187, ite: 11419] train loss: 0.113132, tar: 0.011794 
l0: 0.006653, l1: 0.006711, l2: 0.007267, l3: 0.007953, l4: 0.010464, l5: 0.008181, l6: 0.011852

[epoch: 122/100000, batch:    92/  187, ite: 11420] train loss: 0.113094, tar: 0.011791 
l0: 0.011337, l1: 0.011824, l2: 0.013824, l3: 0.010462, l4: 0.015475, l5: 0.015414, l6: 0.017880

[epoch: 122/100000, batch:    94/  187, ite: 11421] train loss: 0.113082, tar: 0.011790 
l0: 0.003316, l1: 0.003529, l2: 0.003643, l3: 0.003271, l4: 0.005113, l5: 0.005492, l6: 0.006799

[epoch: 122/100000, batch:    96/  187, ite: 11422] train loss: 0.113024, tar: 0.011784 
l0: 0.003534, l1: 0.003729, l2: 0.003782, l3: 0.004666, l4: 0.010744, l5: 0.008736, l6: 0.008115

[epoch: 122/100000, batch:    98/  187, ite: 11423] train loss: 0.112975, tar: 0.011779 
l0: 0.005624, l1: 0.006109, l2: 0.008370, l3: 0.006833, l4: 0.014382, l5: 0.015575, l6: 0.010530

[epoch: 122/100000, batch:   100/  187, ite: 11424] train loss: 0.112943, tar: 0.011774 
l0: 0.005075, l1: 0.007814, l2: 0.005279, l3: 0.004512, l4: 0.008570, l5: 0.007846, l6: 0.007751

[epoch: 122/100000, batch:   102/  187, ite: 11425] train loss: 0.112897, tar: 0.011770 
l0: 0.006337, l1: 0.007087, l2: 0.006534, l3: 0.006971, l4: 0.011039, l5: 0.008696, l6: 0.008925

[epoch: 122/100000, batch:   104/  187, ite: 11426] train loss: 0.112857, tar: 0.011766 
l0: 0.005909, l1: 0.005254, l2: 0.005839, l3: 0.005809, l4: 0.023472, l5: 0.019632, l6: 0.014876

[epoch: 122/100000, batch:   106/  187, ite: 11427] train loss: 0.112834, tar: 0.011762 
l0: 0.005704, l1: 0.005488, l2: 0.007189, l3: 0.007242, l4: 0.012291, l5: 0.011519, l6: 0.012977

[epoch: 122/100000, batch:   108/  187, ite: 11428] train loss: 0.112799, tar: 0.011757 
l0: 0.004033, l1: 0.004349, l2: 0.006037, l3: 0.005463, l4: 0.008900, l5: 0.006840, l6: 0.007707

[epoch: 122/100000, batch:   110/  187, ite: 11429] train loss: 0.112750, tar: 0.011752 
l0: 0.005913, l1: 0.005517, l2: 0.007281, l3: 0.007425, l4: 0.010083, l5: 0.008611, l6: 0.010316

[epoch: 122/100000, batch:   112/  187, ite: 11430] train loss: 0.112710, tar: 0.011748 
l0: 0.008850, l1: 0.009300, l2: 0.008688, l3: 0.008412, l4: 0.010112, l5: 0.010239, l6: 0.011651

[epoch: 122/100000, batch:   114/  187, ite: 11431] train loss: 0.112678, tar: 0.011746 
l0: 0.012869, l1: 0.016656, l2: 0.013972, l3: 0.014291, l4: 0.014526, l5: 0.009754, l6: 0.010052

[epoch: 122/100000, batch:   116/  187, ite: 11432] train loss: 0.112664, tar: 0.011747 
l0: 0.010369, l1: 0.009074, l2: 0.010603, l3: 0.012602, l4: 0.022164, l5: 0.028500, l6: 0.027082

[epoch: 122/100000, batch:   118/  187, ite: 11433] train loss: 0.112669, tar: 0.011746 
l0: 0.006436, l1: 0.006413, l2: 0.005422, l3: 0.005796, l4: 0.011589, l5: 0.010920, l6: 0.010251

[epoch: 122/100000, batch:   120/  187, ite: 11434] train loss: 0.112630, tar: 0.011742 
l0: 0.007828, l1: 0.007405, l2: 0.008436, l3: 0.008399, l4: 0.014387, l5: 0.015404, l6: 0.017462

[epoch: 122/100000, batch:   122/  187, ite: 11435] train loss: 0.112607, tar: 0.011739 
l0: 0.006079, l1: 0.006271, l2: 0.006177, l3: 0.006640, l4: 0.013795, l5: 0.013580, l6: 0.011612

[epoch: 122/100000, batch:   124/  187, ite: 11436] train loss: 0.112573, tar: 0.011735 
l0: 0.005963, l1: 0.005666, l2: 0.006261, l3: 0.006812, l4: 0.015266, l5: 0.016037, l6: 0.013581

[epoch: 122/100000, batch:   126/  187, ite: 11437] train loss: 0.112543, tar: 0.011731 
l0: 0.009817, l1: 0.009678, l2: 0.010171, l3: 0.010063, l4: 0.010993, l5: 0.010977, l6: 0.012001

[epoch: 122/100000, batch:   128/  187, ite: 11438] train loss: 0.112516, tar: 0.011730 
l0: 0.002443, l1: 0.002648, l2: 0.002749, l3: 0.002734, l4: 0.005788, l5: 0.005440, l6: 0.006774

[epoch: 122/100000, batch:   130/  187, ite: 11439] train loss: 0.112458, tar: 0.011723 
l0: 0.004802, l1: 0.004901, l2: 0.006070, l3: 0.004940, l4: 0.005717, l5: 0.006646, l6: 0.007936

[epoch: 122/100000, batch:   132/  187, ite: 11440] train loss: 0.112408, tar: 0.011719 
l0: 0.008125, l1: 0.009466, l2: 0.009093, l3: 0.009449, l4: 0.008106, l5: 0.008687, l6: 0.010377

[epoch: 122/100000, batch:   134/  187, ite: 11441] train loss: 0.112374, tar: 0.011716 
l0: 0.007192, l1: 0.007397, l2: 0.008226, l3: 0.008869, l4: 0.013305, l5: 0.013482, l6: 0.010507

[epoch: 122/100000, batch:   136/  187, ite: 11442] train loss: 0.112344, tar: 0.011713 
l0: 0.006097, l1: 0.006657, l2: 0.007456, l3: 0.008300, l4: 0.006862, l5: 0.005581, l6: 0.005903

[epoch: 122/100000, batch:   138/  187, ite: 11443] train loss: 0.112299, tar: 0.011709 
l0: 0.008254, l1: 0.008606, l2: 0.008950, l3: 0.009449, l4: 0.009834, l5: 0.009302, l6: 0.010560

[epoch: 122/100000, batch:   140/  187, ite: 11444] train loss: 0.112266, tar: 0.011707 
l0: 0.007219, l1: 0.008164, l2: 0.007614, l3: 0.007179, l4: 0.011328, l5: 0.009288, l6: 0.011420

[epoch: 122/100000, batch:   142/  187, ite: 11445] train loss: 0.112232, tar: 0.011704 
l0: 0.005168, l1: 0.005404, l2: 0.006009, l3: 0.006998, l4: 0.012742, l5: 0.011294, l6: 0.010798

[epoch: 122/100000, batch:   144/  187, ite: 11446] train loss: 0.112194, tar: 0.011699 
l0: 0.005028, l1: 0.005166, l2: 0.005921, l3: 0.005892, l4: 0.013124, l5: 0.013233, l6: 0.014036

[epoch: 122/100000, batch:   146/  187, ite: 11447] train loss: 0.112160, tar: 0.011695 
l0: 0.006166, l1: 0.005921, l2: 0.007047, l3: 0.007934, l4: 0.011230, l5: 0.010213, l6: 0.013178

[epoch: 122/100000, batch:   148/  187, ite: 11448] train loss: 0.112125, tar: 0.011691 
l0: 0.008902, l1: 0.008632, l2: 0.010448, l3: 0.011651, l4: 0.019021, l5: 0.017168, l6: 0.019742

[epoch: 122/100000, batch:   150/  187, ite: 11449] train loss: 0.112114, tar: 0.011689 
l0: 0.005069, l1: 0.004971, l2: 0.005926, l3: 0.006373, l4: 0.010531, l5: 0.008418, l6: 0.008789

[epoch: 122/100000, batch:   152/  187, ite: 11450] train loss: 0.112071, tar: 0.011684 
l0: 0.006056, l1: 0.007046, l2: 0.006895, l3: 0.005995, l4: 0.011744, l5: 0.011191, l6: 0.013535

[epoch: 122/100000, batch:   154/  187, ite: 11451] train loss: 0.112037, tar: 0.011680 
l0: 0.003509, l1: 0.003643, l2: 0.004088, l3: 0.003964, l4: 0.005993, l5: 0.005965, l6: 0.008641

[epoch: 122/100000, batch:   156/  187, ite: 11452] train loss: 0.111984, tar: 0.011675 
l0: 0.006084, l1: 0.006055, l2: 0.006300, l3: 0.007442, l4: 0.008635, l5: 0.008767, l6: 0.008876

[epoch: 122/100000, batch:   158/  187, ite: 11453] train loss: 0.111943, tar: 0.011671 
l0: 0.004004, l1: 0.003461, l2: 0.005252, l3: 0.007373, l4: 0.013660, l5: 0.010570, l6: 0.009957

[epoch: 122/100000, batch:   160/  187, ite: 11454] train loss: 0.111903, tar: 0.011666 
l0: 0.004736, l1: 0.004787, l2: 0.005379, l3: 0.005939, l4: 0.008684, l5: 0.008903, l6: 0.009573

[epoch: 122/100000, batch:   162/  187, ite: 11455] train loss: 0.111859, tar: 0.011661 
l0: 0.006382, l1: 0.006157, l2: 0.006672, l3: 0.007314, l4: 0.010508, l5: 0.010465, l6: 0.014921

[epoch: 122/100000, batch:   164/  187, ite: 11456] train loss: 0.111825, tar: 0.011657 
l0: 0.003878, l1: 0.003790, l2: 0.004957, l3: 0.004964, l4: 0.009012, l5: 0.007767, l6: 0.009605

[epoch: 122/100000, batch:   166/  187, ite: 11457] train loss: 0.111779, tar: 0.011652 
l0: 0.007694, l1: 0.007519, l2: 0.007917, l3: 0.008450, l4: 0.015174, l5: 0.014661, l6: 0.015981

[epoch: 122/100000, batch:   168/  187, ite: 11458] train loss: 0.111755, tar: 0.011649 
l0: 0.010762, l1: 0.009819, l2: 0.010016, l3: 0.012731, l4: 0.016616, l5: 0.016263, l6: 0.016401

[epoch: 122/100000, batch:   170/  187, ite: 11459] train loss: 0.111742, tar: 0.011649 
l0: 0.007876, l1: 0.007842, l2: 0.007893, l3: 0.008425, l4: 0.008956, l5: 0.009317, l6: 0.011475

[epoch: 122/100000, batch:   172/  187, ite: 11460] train loss: 0.111708, tar: 0.011646 
l0: 0.004622, l1: 0.004903, l2: 0.005029, l3: 0.005190, l4: 0.007337, l5: 0.006776, l6: 0.008466

[epoch: 122/100000, batch:   174/  187, ite: 11461] train loss: 0.111660, tar: 0.011641 
l0: 0.011208, l1: 0.011429, l2: 0.013118, l3: 0.013871, l4: 0.015912, l5: 0.013672, l6: 0.015469

[epoch: 122/100000, batch:   176/  187, ite: 11462] train loss: 0.111649, tar: 0.011641 
l0: 0.007900, l1: 0.007734, l2: 0.008592, l3: 0.008667, l4: 0.013605, l5: 0.013617, l6: 0.014790

[epoch: 122/100000, batch:   178/  187, ite: 11463] train loss: 0.111624, tar: 0.011638 
l0: 0.004572, l1: 0.004997, l2: 0.005887, l3: 0.005864, l4: 0.012103, l5: 0.009948, l6: 0.011015

[epoch: 122/100000, batch:   180/  187, ite: 11464] train loss: 0.111585, tar: 0.011633 
l0: 0.007776, l1: 0.008388, l2: 0.007689, l3: 0.007170, l4: 0.013346, l5: 0.013775, l6: 0.017378

[epoch: 122/100000, batch:   182/  187, ite: 11465] train loss: 0.111560, tar: 0.011631 
l0: 0.009140, l1: 0.009511, l2: 0.009024, l3: 0.008960, l4: 0.015183, l5: 0.015582, l6: 0.014515

[epoch: 122/100000, batch:   184/  187, ite: 11466] train loss: 0.111540, tar: 0.011629 
l0: 0.006161, l1: 0.006863, l2: 0.007152, l3: 0.006078, l4: 0.011062, l5: 0.008429, l6: 0.015466

[epoch: 122/100000, batch:   186/  187, ite: 11467] train loss: 0.111505, tar: 0.011625 
l0: 0.005469, l1: 0.006476, l2: 0.007386, l3: 0.006416, l4: 0.006948, l5: 0.003125, l6: 0.004084

[epoch: 122/100000, batch:   188/  187, ite: 11468] train loss: 0.111457, tar: 0.011621 
l0: 0.008637, l1: 0.008735, l2: 0.010215, l3: 0.009834, l4: 0.011750, l5: 0.011419, l6: 0.011343

[epoch: 123/100000, batch:     2/  187, ite: 11469] train loss: 0.111430, tar: 0.011619 
l0: 0.004674, l1: 0.004723, l2: 0.005611, l3: 0.005805, l4: 0.009245, l5: 0.011152, l6: 0.011199

[epoch: 123/100000, batch:     4/  187, ite: 11470] train loss: 0.111390, tar: 0.011614 
l0: 0.005119, l1: 0.005822, l2: 0.006267, l3: 0.005795, l4: 0.007768, l5: 0.007040, l6: 0.007899

[epoch: 123/100000, batch:     6/  187, ite: 11471] train loss: 0.111345, tar: 0.011610 
l0: 0.005470, l1: 0.005288, l2: 0.006017, l3: 0.006529, l4: 0.012678, l5: 0.012879, l6: 0.011098

[epoch: 123/100000, batch:     8/  187, ite: 11472] train loss: 0.111310, tar: 0.011606 
l0: 0.003659, l1: 0.003580, l2: 0.003840, l3: 0.003802, l4: 0.007177, l5: 0.007133, l6: 0.009530

[epoch: 123/100000, batch:    10/  187, ite: 11473] train loss: 0.111261, tar: 0.011600 
l0: 0.004831, l1: 0.005513, l2: 0.005264, l3: 0.004915, l4: 0.006845, l5: 0.006194, l6: 0.007775

[epoch: 123/100000, batch:    12/  187, ite: 11474] train loss: 0.111213, tar: 0.011596 
l0: 0.005779, l1: 0.005773, l2: 0.006601, l3: 0.007227, l4: 0.009363, l5: 0.008701, l6: 0.008453

[epoch: 123/100000, batch:    14/  187, ite: 11475] train loss: 0.111173, tar: 0.011592 
l0: 0.006881, l1: 0.007010, l2: 0.008165, l3: 0.008084, l4: 0.015336, l5: 0.012952, l6: 0.011464

[epoch: 123/100000, batch:    16/  187, ite: 11476] train loss: 0.111145, tar: 0.011589 
l0: 0.008657, l1: 0.008538, l2: 0.009269, l3: 0.011081, l4: 0.017874, l5: 0.015162, l6: 0.015077

[epoch: 123/100000, batch:    18/  187, ite: 11477] train loss: 0.111128, tar: 0.011587 
l0: 0.004769, l1: 0.005060, l2: 0.004932, l3: 0.004740, l4: 0.008058, l5: 0.007309, l6: 0.009813

[epoch: 123/100000, batch:    20/  187, ite: 11478] train loss: 0.111083, tar: 0.011582 
l0: 0.006246, l1: 0.006603, l2: 0.007055, l3: 0.007334, l4: 0.011391, l5: 0.009958, l6: 0.010343

[epoch: 123/100000, batch:    22/  187, ite: 11479] train loss: 0.111048, tar: 0.011579 
l0: 0.006506, l1: 0.005498, l2: 0.005565, l3: 0.006357, l4: 0.008406, l5: 0.009632, l6: 0.011532

[epoch: 123/100000, batch:    24/  187, ite: 11480] train loss: 0.111009, tar: 0.011575 
l0: 0.007840, l1: 0.007669, l2: 0.009201, l3: 0.009638, l4: 0.013013, l5: 0.012260, l6: 0.013006

[epoch: 123/100000, batch:    26/  187, ite: 11481] train loss: 0.110983, tar: 0.011573 
l0: 0.005987, l1: 0.006081, l2: 0.007318, l3: 0.007533, l4: 0.011564, l5: 0.010755, l6: 0.010655

[epoch: 123/100000, batch:    28/  187, ite: 11482] train loss: 0.110948, tar: 0.011569 
l0: 0.005974, l1: 0.005844, l2: 0.006034, l3: 0.006614, l4: 0.007568, l5: 0.008054, l6: 0.012317

[epoch: 123/100000, batch:    30/  187, ite: 11483] train loss: 0.110909, tar: 0.011565 
l0: 0.005826, l1: 0.005987, l2: 0.005654, l3: 0.005194, l4: 0.009097, l5: 0.008529, l6: 0.009454

[epoch: 123/100000, batch:    32/  187, ite: 11484] train loss: 0.110868, tar: 0.011561 
l0: 0.011145, l1: 0.013039, l2: 0.012098, l3: 0.011136, l4: 0.015880, l5: 0.013190, l6: 0.014136

[epoch: 123/100000, batch:    34/  187, ite: 11485] train loss: 0.110854, tar: 0.011561 
l0: 0.004817, l1: 0.005362, l2: 0.004846, l3: 0.006487, l4: 0.013323, l5: 0.010542, l6: 0.008527

[epoch: 123/100000, batch:    36/  187, ite: 11486] train loss: 0.110816, tar: 0.011556 
l0: 0.007502, l1: 0.007526, l2: 0.008401, l3: 0.008371, l4: 0.014088, l5: 0.013635, l6: 0.010200

[epoch: 123/100000, batch:    38/  187, ite: 11487] train loss: 0.110788, tar: 0.011554 
l0: 0.006394, l1: 0.006527, l2: 0.007120, l3: 0.006795, l4: 0.009651, l5: 0.009777, l6: 0.012057

[epoch: 123/100000, batch:    40/  187, ite: 11488] train loss: 0.110753, tar: 0.011550 
l0: 0.008084, l1: 0.009239, l2: 0.008754, l3: 0.007464, l4: 0.009337, l5: 0.011133, l6: 0.015926

[epoch: 123/100000, batch:    42/  187, ite: 11489] train loss: 0.110725, tar: 0.011548 
l0: 0.006078, l1: 0.007176, l2: 0.006487, l3: 0.005042, l4: 0.007072, l5: 0.006507, l6: 0.007868

[epoch: 123/100000, batch:    44/  187, ite: 11490] train loss: 0.110682, tar: 0.011544 
l0: 0.002575, l1: 0.002058, l2: 0.003987, l3: 0.003991, l4: 0.007258, l5: 0.008296, l6: 0.008459

[epoch: 123/100000, batch:    46/  187, ite: 11491] train loss: 0.110633, tar: 0.011538 
l0: 0.011379, l1: 0.013389, l2: 0.011674, l3: 0.009656, l4: 0.010947, l5: 0.008921, l6: 0.010403

[epoch: 123/100000, batch:    48/  187, ite: 11492] train loss: 0.110610, tar: 0.011538 
l0: 0.003805, l1: 0.003366, l2: 0.003995, l3: 0.005953, l4: 0.011616, l5: 0.010136, l6: 0.011104

[epoch: 123/100000, batch:    50/  187, ite: 11493] train loss: 0.110569, tar: 0.011533 
l0: 0.004162, l1: 0.004014, l2: 0.003660, l3: 0.004348, l4: 0.007792, l5: 0.009121, l6: 0.014214

[epoch: 123/100000, batch:    52/  187, ite: 11494] train loss: 0.110527, tar: 0.011528 
l0: 0.005304, l1: 0.005332, l2: 0.006501, l3: 0.006579, l4: 0.012100, l5: 0.010481, l6: 0.009907

[epoch: 123/100000, batch:    54/  187, ite: 11495] train loss: 0.110490, tar: 0.011524 
l0: 0.006169, l1: 0.006305, l2: 0.005744, l3: 0.006536, l4: 0.011325, l5: 0.012370, l6: 0.014077

[epoch: 123/100000, batch:    56/  187, ite: 11496] train loss: 0.110458, tar: 0.011520 
l0: 0.005217, l1: 0.005428, l2: 0.005485, l3: 0.005923, l4: 0.011350, l5: 0.011583, l6: 0.014122

[epoch: 123/100000, batch:    58/  187, ite: 11497] train loss: 0.110424, tar: 0.011516 
l0: 0.004290, l1: 0.005019, l2: 0.005581, l3: 0.005155, l4: 0.006174, l5: 0.006980, l6: 0.009588

[epoch: 123/100000, batch:    60/  187, ite: 11498] train loss: 0.110379, tar: 0.011511 
l0: 0.005808, l1: 0.005799, l2: 0.007744, l3: 0.007357, l4: 0.011621, l5: 0.010937, l6: 0.010692

[epoch: 123/100000, batch:    62/  187, ite: 11499] train loss: 0.110345, tar: 0.011507 
l0: 0.005774, l1: 0.007649, l2: 0.005027, l3: 0.005925, l4: 0.014493, l5: 0.010783, l6: 0.010372

[epoch: 123/100000, batch:    64/  187, ite: 11500] train loss: 0.110312, tar: 0.011504 
l0: 0.003093, l1: 0.003373, l2: 0.003852, l3: 0.003535, l4: 0.005011, l5: 0.003863, l6: 0.005873

[epoch: 123/100000, batch:    66/  187, ite: 11501] train loss: 0.110257, tar: 0.011498 
l0: 0.008098, l1: 0.008558, l2: 0.009774, l3: 0.008866, l4: 0.012290, l5: 0.010964, l6: 0.012488

[epoch: 123/100000, batch:    68/  187, ite: 11502] train loss: 0.110231, tar: 0.011496 
l0: 0.005067, l1: 0.005320, l2: 0.005751, l3: 0.005092, l4: 0.012278, l5: 0.010403, l6: 0.009490

[epoch: 123/100000, batch:    70/  187, ite: 11503] train loss: 0.110193, tar: 0.011491 
l0: 0.013083, l1: 0.017502, l2: 0.016871, l3: 0.013144, l4: 0.009870, l5: 0.004244, l6: 0.003910

[epoch: 123/100000, batch:    72/  187, ite: 11504] train loss: 0.110172, tar: 0.011492 
l0: 0.015733, l1: 0.014458, l2: 0.014687, l3: 0.016237, l4: 0.023759, l5: 0.024393, l6: 0.024292

[epoch: 123/100000, batch:    74/  187, ite: 11505] train loss: 0.110188, tar: 0.011495 
l0: 0.004837, l1: 0.004988, l2: 0.004656, l3: 0.005263, l4: 0.007371, l5: 0.006254, l6: 0.009549

[epoch: 123/100000, batch:    76/  187, ite: 11506] train loss: 0.110143, tar: 0.011491 
l0: 0.006498, l1: 0.006866, l2: 0.005921, l3: 0.007765, l4: 0.008569, l5: 0.008397, l6: 0.008905

[epoch: 123/100000, batch:    78/  187, ite: 11507] train loss: 0.110105, tar: 0.011488 
l0: 0.003117, l1: 0.003011, l2: 0.003607, l3: 0.003902, l4: 0.008494, l5: 0.008200, l6: 0.011259

[epoch: 123/100000, batch:    80/  187, ite: 11508] train loss: 0.110060, tar: 0.011482 
l0: 0.004224, l1: 0.004212, l2: 0.006166, l3: 0.004798, l4: 0.011996, l5: 0.008145, l6: 0.007543

[epoch: 123/100000, batch:    82/  187, ite: 11509] train loss: 0.110018, tar: 0.011477 
l0: 0.008458, l1: 0.009728, l2: 0.011328, l3: 0.010109, l4: 0.010788, l5: 0.010237, l6: 0.013935

[epoch: 123/100000, batch:    84/  187, ite: 11510] train loss: 0.109994, tar: 0.011475 
l0: 0.004296, l1: 0.004522, l2: 0.006022, l3: 0.005914, l4: 0.008629, l5: 0.007015, l6: 0.007253

[epoch: 123/100000, batch:    86/  187, ite: 11511] train loss: 0.109951, tar: 0.011470 
l0: 0.005511, l1: 0.005643, l2: 0.006018, l3: 0.005953, l4: 0.008717, l5: 0.008882, l6: 0.009295

[epoch: 123/100000, batch:    88/  187, ite: 11512] train loss: 0.109911, tar: 0.011466 
l0: 0.008408, l1: 0.008372, l2: 0.009298, l3: 0.009821, l4: 0.009188, l5: 0.009032, l6: 0.009263

[epoch: 123/100000, batch:    90/  187, ite: 11513] train loss: 0.109880, tar: 0.011464 
l0: 0.012502, l1: 0.012070, l2: 0.010674, l3: 0.012037, l4: 0.022218, l5: 0.022283, l6: 0.020689

[epoch: 123/100000, batch:    92/  187, ite: 11514] train loss: 0.109882, tar: 0.011465 
l0: 0.003248, l1: 0.003805, l2: 0.004513, l3: 0.003001, l4: 0.006821, l5: 0.007697, l6: 0.004699

[epoch: 123/100000, batch:    94/  187, ite: 11515] train loss: 0.109832, tar: 0.011460 
l0: 0.008214, l1: 0.008657, l2: 0.008932, l3: 0.008949, l4: 0.010452, l5: 0.008919, l6: 0.010992

[epoch: 123/100000, batch:    96/  187, ite: 11516] train loss: 0.109802, tar: 0.011458 
l0: 0.007347, l1: 0.007261, l2: 0.008297, l3: 0.008859, l4: 0.014463, l5: 0.012771, l6: 0.016269

[epoch: 123/100000, batch:    98/  187, ite: 11517] train loss: 0.109779, tar: 0.011455 
l0: 0.006328, l1: 0.006658, l2: 0.006319, l3: 0.006364, l4: 0.011326, l5: 0.010540, l6: 0.008767

[epoch: 123/100000, batch:   100/  187, ite: 11518] train loss: 0.109744, tar: 0.011451 
l0: 0.005985, l1: 0.006280, l2: 0.006988, l3: 0.006392, l4: 0.007870, l5: 0.008789, l6: 0.008930

[epoch: 123/100000, batch:   102/  187, ite: 11519] train loss: 0.109706, tar: 0.011448 
l0: 0.007746, l1: 0.008397, l2: 0.010049, l3: 0.009775, l4: 0.006268, l5: 0.006203, l6: 0.005946

[epoch: 123/100000, batch:   104/  187, ite: 11520] train loss: 0.109669, tar: 0.011445 
l0: 0.004453, l1: 0.004347, l2: 0.006577, l3: 0.005535, l4: 0.009822, l5: 0.008533, l6: 0.010672

[epoch: 123/100000, batch:   106/  187, ite: 11521] train loss: 0.109630, tar: 0.011441 
l0: 0.007898, l1: 0.007885, l2: 0.009500, l3: 0.009338, l4: 0.015945, l5: 0.016453, l6: 0.015089

[epoch: 123/100000, batch:   108/  187, ite: 11522] train loss: 0.109612, tar: 0.011439 
l0: 0.008100, l1: 0.007367, l2: 0.009336, l3: 0.011910, l4: 0.020246, l5: 0.018296, l6: 0.021793

[epoch: 123/100000, batch:   110/  187, ite: 11523] train loss: 0.109604, tar: 0.011436 
l0: 0.004330, l1: 0.004593, l2: 0.005032, l3: 0.005606, l4: 0.006932, l5: 0.006623, l6: 0.006332

[epoch: 123/100000, batch:   112/  187, ite: 11524] train loss: 0.109558, tar: 0.011432 
l0: 0.012682, l1: 0.012227, l2: 0.017098, l3: 0.017654, l4: 0.018271, l5: 0.016511, l6: 0.013609

[epoch: 123/100000, batch:   114/  187, ite: 11525] train loss: 0.109557, tar: 0.011432 
l0: 0.005283, l1: 0.004272, l2: 0.008079, l3: 0.008711, l4: 0.010162, l5: 0.010395, l6: 0.013763

[epoch: 123/100000, batch:   116/  187, ite: 11526] train loss: 0.109525, tar: 0.011428 
l0: 0.005761, l1: 0.005773, l2: 0.006262, l3: 0.006783, l4: 0.007267, l5: 0.007653, l6: 0.007407

[epoch: 123/100000, batch:   118/  187, ite: 11527] train loss: 0.109484, tar: 0.011425 
l0: 0.008503, l1: 0.009163, l2: 0.010029, l3: 0.009617, l4: 0.010656, l5: 0.010556, l6: 0.014057

[epoch: 123/100000, batch:   120/  187, ite: 11528] train loss: 0.109459, tar: 0.011423 
l0: 0.008165, l1: 0.008204, l2: 0.008327, l3: 0.010645, l4: 0.011579, l5: 0.011676, l6: 0.013609

[epoch: 123/100000, batch:   122/  187, ite: 11529] train loss: 0.109435, tar: 0.011421 
l0: 0.006446, l1: 0.007109, l2: 0.006179, l3: 0.006053, l4: 0.010243, l5: 0.009591, l6: 0.009333

[epoch: 123/100000, batch:   124/  187, ite: 11530] train loss: 0.109399, tar: 0.011417 
l0: 0.005595, l1: 0.005847, l2: 0.006817, l3: 0.007298, l4: 0.014494, l5: 0.012467, l6: 0.010456

[epoch: 123/100000, batch:   126/  187, ite: 11531] train loss: 0.109369, tar: 0.011414 
l0: 0.007079, l1: 0.006790, l2: 0.007572, l3: 0.008218, l4: 0.014755, l5: 0.013455, l6: 0.013780

[epoch: 123/100000, batch:   128/  187, ite: 11532] train loss: 0.109345, tar: 0.011411 
l0: 0.007131, l1: 0.006591, l2: 0.007155, l3: 0.007103, l4: 0.015088, l5: 0.014820, l6: 0.014152

[epoch: 123/100000, batch:   130/  187, ite: 11533] train loss: 0.109320, tar: 0.011408 
l0: 0.004747, l1: 0.004972, l2: 0.005454, l3: 0.004853, l4: 0.010054, l5: 0.012217, l6: 0.011152

[epoch: 123/100000, batch:   132/  187, ite: 11534] train loss: 0.109284, tar: 0.011404 
l0: 0.007627, l1: 0.008560, l2: 0.008059, l3: 0.008965, l4: 0.015528, l5: 0.010616, l6: 0.011404

[epoch: 123/100000, batch:   134/  187, ite: 11535] train loss: 0.109259, tar: 0.011401 
l0: 0.006762, l1: 0.007643, l2: 0.008265, l3: 0.007692, l4: 0.009858, l5: 0.009338, l6: 0.009997

[epoch: 123/100000, batch:   136/  187, ite: 11536] train loss: 0.109226, tar: 0.011398 
l0: 0.007329, l1: 0.008903, l2: 0.007876, l3: 0.009164, l4: 0.016524, l5: 0.011077, l6: 0.012086

[epoch: 123/100000, batch:   138/  187, ite: 11537] train loss: 0.109203, tar: 0.011396 
l0: 0.009256, l1: 0.008886, l2: 0.010229, l3: 0.012770, l4: 0.020931, l5: 0.021967, l6: 0.015018

[epoch: 123/100000, batch:   140/  187, ite: 11538] train loss: 0.109196, tar: 0.011394 
l0: 0.010291, l1: 0.010370, l2: 0.010797, l3: 0.012698, l4: 0.017824, l5: 0.016023, l6: 0.021299

[epoch: 123/100000, batch:   142/  187, ite: 11539] train loss: 0.109190, tar: 0.011393 
l0: 0.004856, l1: 0.005142, l2: 0.006398, l3: 0.006309, l4: 0.008463, l5: 0.007645, l6: 0.011499

[epoch: 123/100000, batch:   144/  187, ite: 11540] train loss: 0.109151, tar: 0.011389 
l0: 0.006437, l1: 0.007077, l2: 0.007558, l3: 0.007718, l4: 0.009330, l5: 0.009148, l6: 0.009827

[epoch: 123/100000, batch:   146/  187, ite: 11541] train loss: 0.109118, tar: 0.011386 
l0: 0.005608, l1: 0.006247, l2: 0.005978, l3: 0.005970, l4: 0.008694, l5: 0.007788, l6: 0.008445

[epoch: 123/100000, batch:   148/  187, ite: 11542] train loss: 0.109079, tar: 0.011382 
l0: 0.003318, l1: 0.003424, l2: 0.004853, l3: 0.004725, l4: 0.005915, l5: 0.005391, l6: 0.006310

[epoch: 123/100000, batch:   150/  187, ite: 11543] train loss: 0.109030, tar: 0.011377 
l0: 0.006869, l1: 0.006954, l2: 0.007780, l3: 0.007771, l4: 0.009689, l5: 0.009888, l6: 0.012180

[epoch: 123/100000, batch:   152/  187, ite: 11544] train loss: 0.108999, tar: 0.011374 
l0: 0.006647, l1: 0.006382, l2: 0.008284, l3: 0.009547, l4: 0.010610, l5: 0.009559, l6: 0.013999

[epoch: 123/100000, batch:   154/  187, ite: 11545] train loss: 0.108970, tar: 0.011371 
l0: 0.006160, l1: 0.006624, l2: 0.007267, l3: 0.008272, l4: 0.010984, l5: 0.007703, l6: 0.007413

[epoch: 123/100000, batch:   156/  187, ite: 11546] train loss: 0.108935, tar: 0.011368 
l0: 0.006001, l1: 0.006285, l2: 0.008467, l3: 0.008955, l4: 0.011732, l5: 0.007243, l6: 0.007405

[epoch: 123/100000, batch:   158/  187, ite: 11547] train loss: 0.108901, tar: 0.011364 
l0: 0.004881, l1: 0.005438, l2: 0.005956, l3: 0.005335, l4: 0.008832, l5: 0.008173, l6: 0.009547

[epoch: 123/100000, batch:   160/  187, ite: 11548] train loss: 0.108862, tar: 0.011360 
l0: 0.011006, l1: 0.009849, l2: 0.012104, l3: 0.012903, l4: 0.015036, l5: 0.018630, l6: 0.019429

[epoch: 123/100000, batch:   162/  187, ite: 11549] train loss: 0.108855, tar: 0.011360 
l0: 0.005899, l1: 0.006336, l2: 0.006066, l3: 0.006122, l4: 0.013633, l5: 0.011251, l6: 0.013266

[epoch: 123/100000, batch:   164/  187, ite: 11550] train loss: 0.108825, tar: 0.011356 
l0: 0.003582, l1: 0.003505, l2: 0.005612, l3: 0.004946, l4: 0.004999, l5: 0.006382, l6: 0.005879

[epoch: 123/100000, batch:   166/  187, ite: 11551] train loss: 0.108778, tar: 0.011351 
l0: 0.004956, l1: 0.004434, l2: 0.005013, l3: 0.009663, l4: 0.020755, l5: 0.015871, l6: 0.014846

[epoch: 123/100000, batch:   168/  187, ite: 11552] train loss: 0.108756, tar: 0.011347 
l0: 0.007280, l1: 0.007339, l2: 0.008189, l3: 0.009138, l4: 0.015351, l5: 0.013370, l6: 0.014745

[epoch: 123/100000, batch:   170/  187, ite: 11553] train loss: 0.108735, tar: 0.011345 
l0: 0.009207, l1: 0.009216, l2: 0.009765, l3: 0.012481, l4: 0.018953, l5: 0.016631, l6: 0.017128

[epoch: 123/100000, batch:   172/  187, ite: 11554] train loss: 0.108725, tar: 0.011343 
l0: 0.003278, l1: 0.003733, l2: 0.003214, l3: 0.003201, l4: 0.007968, l5: 0.006681, l6: 0.007332

[epoch: 123/100000, batch:   174/  187, ite: 11555] train loss: 0.108678, tar: 0.011338 
l0: 0.002517, l1: 0.002607, l2: 0.003086, l3: 0.004149, l4: 0.008469, l5: 0.006657, l6: 0.006623

[epoch: 123/100000, batch:   176/  187, ite: 11556] train loss: 0.108630, tar: 0.011332 
l0: 0.009346, l1: 0.009100, l2: 0.012241, l3: 0.011578, l4: 0.022942, l5: 0.020793, l6: 0.017775

[epoch: 123/100000, batch:   178/  187, ite: 11557] train loss: 0.108627, tar: 0.011331 
l0: 0.007095, l1: 0.007696, l2: 0.007503, l3: 0.007753, l4: 0.010891, l5: 0.009326, l6: 0.010483

[epoch: 123/100000, batch:   180/  187, ite: 11558] train loss: 0.108596, tar: 0.011328 
l0: 0.005431, l1: 0.005744, l2: 0.006537, l3: 0.006547, l4: 0.009872, l5: 0.009441, l6: 0.009520

[epoch: 123/100000, batch:   182/  187, ite: 11559] train loss: 0.108560, tar: 0.011325 
l0: 0.005777, l1: 0.006422, l2: 0.007194, l3: 0.007323, l4: 0.011546, l5: 0.009799, l6: 0.016336

[epoch: 123/100000, batch:   184/  187, ite: 11560] train loss: 0.108532, tar: 0.011321 
l0: 0.003623, l1: 0.003869, l2: 0.003310, l3: 0.003386, l4: 0.006238, l5: 0.005681, l6: 0.008167

[epoch: 123/100000, batch:   186/  187, ite: 11561] train loss: 0.108485, tar: 0.011316 
l0: 0.003443, l1: 0.003685, l2: 0.004769, l3: 0.004124, l4: 0.010126, l5: 0.009803, l6: 0.008547

[epoch: 123/100000, batch:   188/  187, ite: 11562] train loss: 0.108444, tar: 0.011311 
l0: 0.007234, l1: 0.007101, l2: 0.007292, l3: 0.007772, l4: 0.013396, l5: 0.014454, l6: 0.015514

[epoch: 124/100000, batch:     2/  187, ite: 11563] train loss: 0.108421, tar: 0.011308 
l0: 0.007461, l1: 0.008398, l2: 0.009362, l3: 0.008158, l4: 0.010796, l5: 0.009483, l6: 0.011010

[epoch: 124/100000, batch:     4/  187, ite: 11564] train loss: 0.108393, tar: 0.011306 
l0: 0.005674, l1: 0.006591, l2: 0.005171, l3: 0.005042, l4: 0.007027, l5: 0.006310, l6: 0.008031

[epoch: 124/100000, batch:     6/  187, ite: 11565] train loss: 0.108352, tar: 0.011302 
l0: 0.005851, l1: 0.006276, l2: 0.006843, l3: 0.006951, l4: 0.010456, l5: 0.010602, l6: 0.010983

[epoch: 124/100000, batch:     8/  187, ite: 11566] train loss: 0.108319, tar: 0.011299 
l0: 0.008431, l1: 0.009119, l2: 0.007527, l3: 0.007926, l4: 0.021774, l5: 0.019743, l6: 0.022198

[epoch: 124/100000, batch:    10/  187, ite: 11567] train loss: 0.108312, tar: 0.011297 
l0: 0.004599, l1: 0.004876, l2: 0.004596, l3: 0.005465, l4: 0.006675, l5: 0.007209, l6: 0.008472

[epoch: 124/100000, batch:    12/  187, ite: 11568] train loss: 0.108270, tar: 0.011293 
l0: 0.006767, l1: 0.006319, l2: 0.007565, l3: 0.006974, l4: 0.013845, l5: 0.015350, l6: 0.014431

[epoch: 124/100000, batch:    14/  187, ite: 11569] train loss: 0.108246, tar: 0.011290 
l0: 0.003135, l1: 0.003242, l2: 0.002924, l3: 0.002903, l4: 0.006262, l5: 0.006796, l6: 0.007009

[epoch: 124/100000, batch:    16/  187, ite: 11570] train loss: 0.108198, tar: 0.011285 
l0: 0.004358, l1: 0.005059, l2: 0.005402, l3: 0.005964, l4: 0.010820, l5: 0.008905, l6: 0.011796

[epoch: 124/100000, batch:    18/  187, ite: 11571] train loss: 0.108162, tar: 0.011280 
l0: 0.004523, l1: 0.004356, l2: 0.006381, l3: 0.006975, l4: 0.012817, l5: 0.009908, l6: 0.009991

[epoch: 124/100000, batch:    20/  187, ite: 11572] train loss: 0.108128, tar: 0.011276 
l0: 0.010822, l1: 0.011540, l2: 0.008744, l3: 0.008549, l4: 0.014325, l5: 0.014853, l6: 0.014222

[epoch: 124/100000, batch:    22/  187, ite: 11573] train loss: 0.108112, tar: 0.011276 
l0: 0.004923, l1: 0.004966, l2: 0.005386, l3: 0.006587, l4: 0.008858, l5: 0.007532, l6: 0.008502

[epoch: 124/100000, batch:    24/  187, ite: 11574] train loss: 0.108073, tar: 0.011272 
l0: 0.008749, l1: 0.008567, l2: 0.009752, l3: 0.009223, l4: 0.015168, l5: 0.014484, l6: 0.018115

[epoch: 124/100000, batch:    26/  187, ite: 11575] train loss: 0.108058, tar: 0.011270 
l0: 0.006186, l1: 0.007189, l2: 0.006148, l3: 0.005981, l4: 0.010490, l5: 0.007184, l6: 0.008287

[epoch: 124/100000, batch:    28/  187, ite: 11576] train loss: 0.108022, tar: 0.011267 
l0: 0.004517, l1: 0.004638, l2: 0.005103, l3: 0.004985, l4: 0.009036, l5: 0.007072, l6: 0.008628

[epoch: 124/100000, batch:    30/  187, ite: 11577] train loss: 0.107982, tar: 0.011263 
l0: 0.002238, l1: 0.002451, l2: 0.002388, l3: 0.002726, l4: 0.006715, l5: 0.007632, l6: 0.007147

[epoch: 124/100000, batch:    32/  187, ite: 11578] train loss: 0.107933, tar: 0.011257 
l0: 0.006789, l1: 0.006808, l2: 0.005870, l3: 0.005488, l4: 0.008777, l5: 0.011525, l6: 0.014997

[epoch: 124/100000, batch:    34/  187, ite: 11579] train loss: 0.107903, tar: 0.011254 
l0: 0.006986, l1: 0.007391, l2: 0.006456, l3: 0.006756, l4: 0.010249, l5: 0.008603, l6: 0.009955

[epoch: 124/100000, batch:    36/  187, ite: 11580] train loss: 0.107870, tar: 0.011251 
l0: 0.007292, l1: 0.007713, l2: 0.007798, l3: 0.007817, l4: 0.012176, l5: 0.011944, l6: 0.013826

[epoch: 124/100000, batch:    38/  187, ite: 11581] train loss: 0.107845, tar: 0.011249 
l0: 0.007848, l1: 0.008359, l2: 0.010318, l3: 0.009430, l4: 0.013849, l5: 0.011588, l6: 0.010021

[epoch: 124/100000, batch:    40/  187, ite: 11582] train loss: 0.107822, tar: 0.011247 
l0: 0.007392, l1: 0.007988, l2: 0.008750, l3: 0.009206, l4: 0.011245, l5: 0.012151, l6: 0.012267

[epoch: 124/100000, batch:    42/  187, ite: 11583] train loss: 0.107798, tar: 0.011244 
l0: 0.002781, l1: 0.002573, l2: 0.003566, l3: 0.003823, l4: 0.008105, l5: 0.006677, l6: 0.007058

[epoch: 124/100000, batch:    44/  187, ite: 11584] train loss: 0.107751, tar: 0.011239 
l0: 0.004289, l1: 0.004410, l2: 0.005339, l3: 0.005681, l4: 0.008829, l5: 0.008046, l6: 0.009551

[epoch: 124/100000, batch:    46/  187, ite: 11585] train loss: 0.107713, tar: 0.011234 
l0: 0.003347, l1: 0.003611, l2: 0.005186, l3: 0.003528, l4: 0.004442, l5: 0.003149, l6: 0.004541

[epoch: 124/100000, batch:    48/  187, ite: 11586] train loss: 0.107662, tar: 0.011229 
l0: 0.007206, l1: 0.008206, l2: 0.007634, l3: 0.006377, l4: 0.008517, l5: 0.008490, l6: 0.008545

[epoch: 124/100000, batch:    50/  187, ite: 11587] train loss: 0.107629, tar: 0.011227 
l0: 0.008428, l1: 0.009581, l2: 0.009311, l3: 0.007685, l4: 0.007069, l5: 0.006600, l6: 0.007779

[epoch: 124/100000, batch:    52/  187, ite: 11588] train loss: 0.107597, tar: 0.011225 
l0: 0.009713, l1: 0.010422, l2: 0.011844, l3: 0.010690, l4: 0.012171, l5: 0.011801, l6: 0.015347

[epoch: 124/100000, batch:    54/  187, ite: 11589] train loss: 0.107581, tar: 0.011224 
l0: 0.007568, l1: 0.007717, l2: 0.007651, l3: 0.007052, l4: 0.009433, l5: 0.009837, l6: 0.008781

[epoch: 124/100000, batch:    56/  187, ite: 11590] train loss: 0.107550, tar: 0.011222 
l0: 0.005758, l1: 0.005872, l2: 0.007282, l3: 0.008151, l4: 0.012319, l5: 0.012003, l6: 0.011434

[epoch: 124/100000, batch:    58/  187, ite: 11591] train loss: 0.107521, tar: 0.011218 
l0: 0.014314, l1: 0.014152, l2: 0.015302, l3: 0.016360, l4: 0.025283, l5: 0.022955, l6: 0.017732

[epoch: 124/100000, batch:    60/  187, ite: 11592] train loss: 0.107533, tar: 0.011220 
l0: 0.007959, l1: 0.008419, l2: 0.008133, l3: 0.008082, l4: 0.010564, l5: 0.010687, l6: 0.010238

[epoch: 124/100000, batch:    62/  187, ite: 11593] train loss: 0.107506, tar: 0.011218 
l0: 0.006977, l1: 0.007087, l2: 0.007569, l3: 0.007827, l4: 0.012983, l5: 0.012289, l6: 0.016680

[epoch: 124/100000, batch:    64/  187, ite: 11594] train loss: 0.107483, tar: 0.011216 
l0: 0.010690, l1: 0.010420, l2: 0.011693, l3: 0.012464, l4: 0.018663, l5: 0.018341, l6: 0.018856

[epoch: 124/100000, batch:    66/  187, ite: 11595] train loss: 0.107479, tar: 0.011215 
l0: 0.007308, l1: 0.007664, l2: 0.010822, l3: 0.010959, l4: 0.011802, l5: 0.008644, l6: 0.007696

[epoch: 124/100000, batch:    68/  187, ite: 11596] train loss: 0.107452, tar: 0.011213 
l0: 0.008511, l1: 0.008324, l2: 0.008967, l3: 0.009278, l4: 0.016825, l5: 0.015661, l6: 0.017152

[epoch: 124/100000, batch:    70/  187, ite: 11597] train loss: 0.107438, tar: 0.011211 
l0: 0.008084, l1: 0.008495, l2: 0.008048, l3: 0.007867, l4: 0.013811, l5: 0.011763, l6: 0.014452

[epoch: 124/100000, batch:    72/  187, ite: 11598] train loss: 0.107416, tar: 0.011209 
l0: 0.004866, l1: 0.005077, l2: 0.005278, l3: 0.005543, l4: 0.009309, l5: 0.009383, l6: 0.010255

[epoch: 124/100000, batch:    74/  187, ite: 11599] train loss: 0.107380, tar: 0.011205 
l0: 0.002982, l1: 0.003033, l2: 0.004561, l3: 0.004081, l4: 0.006387, l5: 0.005342, l6: 0.005600

[epoch: 124/100000, batch:    76/  187, ite: 11600] train loss: 0.107333, tar: 0.011200 
l0: 0.004866, l1: 0.004647, l2: 0.005163, l3: 0.006795, l4: 0.010364, l5: 0.009776, l6: 0.012044

[epoch: 124/100000, batch:    78/  187, ite: 11601] train loss: 0.107300, tar: 0.011196 
l0: 0.003823, l1: 0.004673, l2: 0.004750, l3: 0.005302, l4: 0.005715, l5: 0.006172, l6: 0.004835

[epoch: 124/100000, batch:    80/  187, ite: 11602] train loss: 0.107255, tar: 0.011192 
l0: 0.006182, l1: 0.006108, l2: 0.007367, l3: 0.008209, l4: 0.009766, l5: 0.009021, l6: 0.017106

[epoch: 124/100000, batch:    82/  187, ite: 11603] train loss: 0.107228, tar: 0.011189 
l0: 0.003995, l1: 0.004492, l2: 0.004668, l3: 0.004826, l4: 0.006659, l5: 0.006222, l6: 0.007910

[epoch: 124/100000, batch:    84/  187, ite: 11604] train loss: 0.107185, tar: 0.011184 
l0: 0.004705, l1: 0.005239, l2: 0.004472, l3: 0.003959, l4: 0.005062, l5: 0.005176, l6: 0.004621

[epoch: 124/100000, batch:    86/  187, ite: 11605] train loss: 0.107139, tar: 0.011180 
l0: 0.008866, l1: 0.008927, l2: 0.008304, l3: 0.008089, l4: 0.013736, l5: 0.013802, l6: 0.012291

[epoch: 124/100000, batch:    88/  187, ite: 11606] train loss: 0.107118, tar: 0.011179 
l0: 0.007142, l1: 0.007687, l2: 0.008553, l3: 0.008099, l4: 0.009689, l5: 0.008374, l6: 0.008399

[epoch: 124/100000, batch:    90/  187, ite: 11607] train loss: 0.107088, tar: 0.011176 
l0: 0.003669, l1: 0.003895, l2: 0.005012, l3: 0.005099, l4: 0.008045, l5: 0.006458, l6: 0.005875

[epoch: 124/100000, batch:    92/  187, ite: 11608] train loss: 0.107045, tar: 0.011171 
l0: 0.004720, l1: 0.005278, l2: 0.005555, l3: 0.004833, l4: 0.006899, l5: 0.006529, l6: 0.008582

[epoch: 124/100000, batch:    94/  187, ite: 11609] train loss: 0.107004, tar: 0.011167 
l0: 0.010421, l1: 0.010588, l2: 0.012102, l3: 0.011226, l4: 0.011727, l5: 0.010615, l6: 0.013421

[epoch: 124/100000, batch:    96/  187, ite: 11610] train loss: 0.106988, tar: 0.011167 
l0: 0.009611, l1: 0.009962, l2: 0.008935, l3: 0.008872, l4: 0.010179, l5: 0.009389, l6: 0.011794

[epoch: 124/100000, batch:    98/  187, ite: 11611] train loss: 0.106964, tar: 0.011166 
l0: 0.007523, l1: 0.007647, l2: 0.007811, l3: 0.009628, l4: 0.007254, l5: 0.007258, l6: 0.009644

[epoch: 124/100000, batch:   100/  187, ite: 11612] train loss: 0.106933, tar: 0.011164 
l0: 0.008138, l1: 0.008410, l2: 0.008108, l3: 0.008001, l4: 0.010981, l5: 0.013862, l6: 0.010954

[epoch: 124/100000, batch:   102/  187, ite: 11613] train loss: 0.106909, tar: 0.011162 
l0: 0.006736, l1: 0.006574, l2: 0.008703, l3: 0.009361, l4: 0.012560, l5: 0.010406, l6: 0.010703

[epoch: 124/100000, batch:   104/  187, ite: 11614] train loss: 0.106883, tar: 0.011159 
l0: 0.005344, l1: 0.005444, l2: 0.006925, l3: 0.005997, l4: 0.009510, l5: 0.009661, l6: 0.012227

[epoch: 124/100000, batch:   106/  187, ite: 11615] train loss: 0.106851, tar: 0.011155 
l0: 0.007802, l1: 0.009266, l2: 0.008181, l3: 0.008602, l4: 0.008028, l5: 0.008975, l6: 0.009449

[epoch: 124/100000, batch:   108/  187, ite: 11616] train loss: 0.106822, tar: 0.011153 
l0: 0.005994, l1: 0.006037, l2: 0.006700, l3: 0.006659, l4: 0.009544, l5: 0.008728, l6: 0.009277

[epoch: 124/100000, batch:   110/  187, ite: 11617] train loss: 0.106789, tar: 0.011150 
l0: 0.005913, l1: 0.005967, l2: 0.005701, l3: 0.005522, l4: 0.009240, l5: 0.009120, l6: 0.010007

[epoch: 124/100000, batch:   112/  187, ite: 11618] train loss: 0.106755, tar: 0.011147 
l0: 0.005451, l1: 0.005363, l2: 0.005909, l3: 0.006908, l4: 0.013290, l5: 0.011051, l6: 0.009317

[epoch: 124/100000, batch:   114/  187, ite: 11619] train loss: 0.106724, tar: 0.011143 
l0: 0.007465, l1: 0.007427, l2: 0.008597, l3: 0.009364, l4: 0.012836, l5: 0.012055, l6: 0.014205

[epoch: 124/100000, batch:   116/  187, ite: 11620] train loss: 0.106703, tar: 0.011141 
l0: 0.003853, l1: 0.004191, l2: 0.003757, l3: 0.004369, l4: 0.005689, l5: 0.005123, l6: 0.005103

[epoch: 124/100000, batch:   118/  187, ite: 11621] train loss: 0.106657, tar: 0.011137 
l0: 0.007893, l1: 0.008660, l2: 0.008274, l3: 0.007861, l4: 0.009588, l5: 0.009024, l6: 0.010579

[epoch: 124/100000, batch:   120/  187, ite: 11622] train loss: 0.106629, tar: 0.011135 
l0: 0.005784, l1: 0.005816, l2: 0.006774, l3: 0.007057, l4: 0.010220, l5: 0.008555, l6: 0.010152

[epoch: 124/100000, batch:   122/  187, ite: 11623] train loss: 0.106597, tar: 0.011131 
l0: 0.005701, l1: 0.006585, l2: 0.006007, l3: 0.006082, l4: 0.008011, l5: 0.007554, l6: 0.008075

[epoch: 124/100000, batch:   124/  187, ite: 11624] train loss: 0.106561, tar: 0.011128 
l0: 0.007038, l1: 0.006904, l2: 0.007847, l3: 0.008286, l4: 0.012639, l5: 0.012236, l6: 0.014250

[epoch: 124/100000, batch:   126/  187, ite: 11625] train loss: 0.106538, tar: 0.011126 
l0: 0.004879, l1: 0.004990, l2: 0.005704, l3: 0.005542, l4: 0.010290, l5: 0.013879, l6: 0.016339

[epoch: 124/100000, batch:   128/  187, ite: 11626] train loss: 0.106510, tar: 0.011122 
l0: 0.009283, l1: 0.008598, l2: 0.008754, l3: 0.009189, l4: 0.013635, l5: 0.014653, l6: 0.016635

[epoch: 124/100000, batch:   130/  187, ite: 11627] train loss: 0.106494, tar: 0.011121 
l0: 0.004066, l1: 0.004333, l2: 0.004665, l3: 0.004610, l4: 0.006933, l5: 0.006339, l6: 0.009577

[epoch: 124/100000, batch:   132/  187, ite: 11628] train loss: 0.106454, tar: 0.011116 
l0: 0.009663, l1: 0.010205, l2: 0.010009, l3: 0.011738, l4: 0.016569, l5: 0.015840, l6: 0.014630

[epoch: 124/100000, batch:   134/  187, ite: 11629] train loss: 0.106443, tar: 0.011115 
l0: 0.008871, l1: 0.009058, l2: 0.008620, l3: 0.009223, l4: 0.012431, l5: 0.011899, l6: 0.011943

[epoch: 124/100000, batch:   136/  187, ite: 11630] train loss: 0.106422, tar: 0.011114 
l0: 0.021852, l1: 0.022081, l2: 0.017339, l3: 0.017951, l4: 0.029267, l5: 0.030240, l6: 0.023182

[epoch: 124/100000, batch:   138/  187, ite: 11631] train loss: 0.106456, tar: 0.011121 
l0: 0.005734, l1: 0.005998, l2: 0.006039, l3: 0.006744, l4: 0.009701, l5: 0.008765, l6: 0.011200

[epoch: 124/100000, batch:   140/  187, ite: 11632] train loss: 0.106424, tar: 0.011117 
l0: 0.005174, l1: 0.005447, l2: 0.005482, l3: 0.005688, l4: 0.007771, l5: 0.007838, l6: 0.011529

[epoch: 124/100000, batch:   142/  187, ite: 11633] train loss: 0.106389, tar: 0.011114 
l0: 0.005092, l1: 0.005260, l2: 0.004964, l3: 0.004840, l4: 0.007378, l5: 0.007282, l6: 0.008888

[epoch: 124/100000, batch:   144/  187, ite: 11634] train loss: 0.106350, tar: 0.011110 
l0: 0.004328, l1: 0.005244, l2: 0.005107, l3: 0.005136, l4: 0.009993, l5: 0.008454, l6: 0.008977

[epoch: 124/100000, batch:   146/  187, ite: 11635] train loss: 0.106314, tar: 0.011106 
l0: 0.005245, l1: 0.006398, l2: 0.007635, l3: 0.006791, l4: 0.009222, l5: 0.007828, l6: 0.007201

[epoch: 124/100000, batch:   148/  187, ite: 11636] train loss: 0.106280, tar: 0.011102 
l0: 0.006094, l1: 0.006667, l2: 0.006847, l3: 0.006386, l4: 0.010751, l5: 0.009138, l6: 0.009071

[epoch: 124/100000, batch:   150/  187, ite: 11637] train loss: 0.106248, tar: 0.011099 
l0: 0.006565, l1: 0.006669, l2: 0.007126, l3: 0.007252, l4: 0.016590, l5: 0.012721, l6: 0.015514

[epoch: 124/100000, batch:   152/  187, ite: 11638] train loss: 0.106228, tar: 0.011096 
l0: 0.005048, l1: 0.005608, l2: 0.005005, l3: 0.005408, l4: 0.009332, l5: 0.008942, l6: 0.008092

[epoch: 124/100000, batch:   154/  187, ite: 11639] train loss: 0.106192, tar: 0.011093 
l0: 0.005482, l1: 0.004918, l2: 0.004869, l3: 0.006513, l4: 0.009360, l5: 0.010059, l6: 0.012245

[epoch: 124/100000, batch:   156/  187, ite: 11640] train loss: 0.106160, tar: 0.011089 
l0: 0.003473, l1: 0.004200, l2: 0.003627, l3: 0.003615, l4: 0.006297, l5: 0.005846, l6: 0.007085

[epoch: 124/100000, batch:   158/  187, ite: 11641] train loss: 0.106116, tar: 0.011085 
l0: 0.005914, l1: 0.006130, l2: 0.006391, l3: 0.007506, l4: 0.010601, l5: 0.008592, l6: 0.009714

[epoch: 124/100000, batch:   160/  187, ite: 11642] train loss: 0.106085, tar: 0.011081 
l0: 0.005119, l1: 0.005965, l2: 0.005844, l3: 0.005749, l4: 0.009565, l5: 0.007664, l6: 0.008349

[epoch: 124/100000, batch:   162/  187, ite: 11643] train loss: 0.106049, tar: 0.011078 
l0: 0.011903, l1: 0.012030, l2: 0.014836, l3: 0.013829, l4: 0.016000, l5: 0.015682, l6: 0.014364

[epoch: 124/100000, batch:   164/  187, ite: 11644] train loss: 0.106045, tar: 0.011078 
l0: 0.005352, l1: 0.005364, l2: 0.005544, l3: 0.005427, l4: 0.005270, l5: 0.006581, l6: 0.007332

[epoch: 124/100000, batch:   166/  187, ite: 11645] train loss: 0.106005, tar: 0.011075 
l0: 0.005999, l1: 0.006286, l2: 0.006468, l3: 0.006617, l4: 0.016808, l5: 0.014044, l6: 0.013045

[epoch: 124/100000, batch:   168/  187, ite: 11646] train loss: 0.105983, tar: 0.011072 
l0: 0.011103, l1: 0.010537, l2: 0.016173, l3: 0.020313, l4: 0.018197, l5: 0.017287, l6: 0.015168

[epoch: 124/100000, batch:   170/  187, ite: 11647] train loss: 0.105985, tar: 0.011072 
l0: 0.004081, l1: 0.004416, l2: 0.004502, l3: 0.004830, l4: 0.006547, l5: 0.005926, l6: 0.006368

[epoch: 124/100000, batch:   172/  187, ite: 11648] train loss: 0.105943, tar: 0.011068 
l0: 0.003943, l1: 0.004110, l2: 0.005071, l3: 0.004765, l4: 0.006194, l5: 0.006043, l6: 0.007081

[epoch: 124/100000, batch:   174/  187, ite: 11649] train loss: 0.105901, tar: 0.011063 
l0: 0.003704, l1: 0.003426, l2: 0.004076, l3: 0.004744, l4: 0.010011, l5: 0.012488, l6: 0.010760

[epoch: 124/100000, batch:   176/  187, ite: 11650] train loss: 0.105867, tar: 0.011059 
l0: 0.009002, l1: 0.009413, l2: 0.009598, l3: 0.010307, l4: 0.012217, l5: 0.011968, l6: 0.011704

[epoch: 124/100000, batch:   178/  187, ite: 11651] train loss: 0.105847, tar: 0.011057 
l0: 0.006142, l1: 0.005858, l2: 0.007360, l3: 0.006790, l4: 0.010882, l5: 0.009493, l6: 0.011133

[epoch: 124/100000, batch:   180/  187, ite: 11652] train loss: 0.105818, tar: 0.011055 
l0: 0.004143, l1: 0.004322, l2: 0.005302, l3: 0.005016, l4: 0.006594, l5: 0.006267, l6: 0.006355

[epoch: 124/100000, batch:   182/  187, ite: 11653] train loss: 0.105777, tar: 0.011050 
l0: 0.005441, l1: 0.006084, l2: 0.005719, l3: 0.005870, l4: 0.008061, l5: 0.006601, l6: 0.008237

[epoch: 124/100000, batch:   184/  187, ite: 11654] train loss: 0.105741, tar: 0.011047 
l0: 0.007181, l1: 0.006756, l2: 0.008546, l3: 0.011047, l4: 0.017467, l5: 0.013603, l6: 0.012542

[epoch: 124/100000, batch:   186/  187, ite: 11655] train loss: 0.105724, tar: 0.011045 
l0: 0.021430, l1: 0.023536, l2: 0.021595, l3: 0.016035, l4: 0.037943, l5: 0.032812, l6: 0.030999

[epoch: 124/100000, batch:   188/  187, ite: 11656] train loss: 0.105771, tar: 0.011051 
l0: 0.003218, l1: 0.003098, l2: 0.003038, l3: 0.003137, l4: 0.009761, l5: 0.009861, l6: 0.009528

[epoch: 125/100000, batch:     2/  187, ite: 11657] train loss: 0.105733, tar: 0.011046 
l0: 0.007703, l1: 0.007419, l2: 0.008344, l3: 0.008902, l4: 0.010361, l5: 0.011306, l6: 0.012350

[epoch: 125/100000, batch:     4/  187, ite: 11658] train loss: 0.105709, tar: 0.011044 
l0: 0.003242, l1: 0.003335, l2: 0.004139, l3: 0.004155, l4: 0.005226, l5: 0.005335, l6: 0.008398

[epoch: 125/100000, batch:     6/  187, ite: 11659] train loss: 0.105666, tar: 0.011039 
l0: 0.006452, l1: 0.006788, l2: 0.008084, l3: 0.008088, l4: 0.013756, l5: 0.011278, l6: 0.010638

[epoch: 125/100000, batch:     8/  187, ite: 11660] train loss: 0.105641, tar: 0.011037 
l0: 0.004375, l1: 0.004432, l2: 0.004940, l3: 0.005099, l4: 0.008653, l5: 0.006714, l6: 0.007243

[epoch: 125/100000, batch:    10/  187, ite: 11661] train loss: 0.105602, tar: 0.011033 
l0: 0.005653, l1: 0.005505, l2: 0.006037, l3: 0.006308, l4: 0.012869, l5: 0.011299, l6: 0.012713

[epoch: 125/100000, batch:    12/  187, ite: 11662] train loss: 0.105575, tar: 0.011029 
l0: 0.007245, l1: 0.008056, l2: 0.008120, l3: 0.007768, l4: 0.009510, l5: 0.009194, l6: 0.010713

[epoch: 125/100000, batch:    14/  187, ite: 11663] train loss: 0.105548, tar: 0.011027 
l0: 0.003687, l1: 0.004057, l2: 0.004311, l3: 0.004341, l4: 0.007611, l5: 0.007377, l6: 0.009040

[epoch: 125/100000, batch:    16/  187, ite: 11664] train loss: 0.105509, tar: 0.011023 
l0: 0.006341, l1: 0.005970, l2: 0.007193, l3: 0.006669, l4: 0.012086, l5: 0.011141, l6: 0.010724

[epoch: 125/100000, batch:    18/  187, ite: 11665] train loss: 0.105482, tar: 0.011020 
l0: 0.007657, l1: 0.007992, l2: 0.007574, l3: 0.007734, l4: 0.009433, l5: 0.011712, l6: 0.013700

[epoch: 125/100000, batch:    20/  187, ite: 11666] train loss: 0.105458, tar: 0.011018 
l0: 0.002923, l1: 0.002865, l2: 0.002878, l3: 0.004037, l4: 0.006120, l5: 0.007769, l6: 0.007807

[epoch: 125/100000, batch:    22/  187, ite: 11667] train loss: 0.105415, tar: 0.011013 
l0: 0.006790, l1: 0.006749, l2: 0.007747, l3: 0.007643, l4: 0.012131, l5: 0.012068, l6: 0.013277

[epoch: 125/100000, batch:    24/  187, ite: 11668] train loss: 0.105392, tar: 0.011011 
l0: 0.006371, l1: 0.005721, l2: 0.006316, l3: 0.007780, l4: 0.016013, l5: 0.020623, l6: 0.019423

[epoch: 125/100000, batch:    26/  187, ite: 11669] train loss: 0.105378, tar: 0.011008 
l0: 0.009903, l1: 0.012449, l2: 0.011002, l3: 0.008726, l4: 0.007659, l5: 0.007811, l6: 0.008564

[epoch: 125/100000, batch:    28/  187, ite: 11670] train loss: 0.105355, tar: 0.011007 
l0: 0.004231, l1: 0.003571, l2: 0.004165, l3: 0.004321, l4: 0.010224, l5: 0.011932, l6: 0.012363

[epoch: 125/100000, batch:    30/  187, ite: 11671] train loss: 0.105322, tar: 0.011003 
l0: 0.006997, l1: 0.007055, l2: 0.007123, l3: 0.009102, l4: 0.014468, l5: 0.011771, l6: 0.014093

[epoch: 125/100000, batch:    32/  187, ite: 11672] train loss: 0.105301, tar: 0.011001 
l0: 0.007047, l1: 0.006880, l2: 0.006970, l3: 0.007106, l4: 0.013123, l5: 0.012834, l6: 0.014228

[epoch: 125/100000, batch:    34/  187, ite: 11673] train loss: 0.105279, tar: 0.010998 
l0: 0.006930, l1: 0.007638, l2: 0.008642, l3: 0.008521, l4: 0.015752, l5: 0.016029, l6: 0.012900

[epoch: 125/100000, batch:    36/  187, ite: 11674] train loss: 0.105262, tar: 0.010996 
l0: 0.008684, l1: 0.008914, l2: 0.009747, l3: 0.010039, l4: 0.020702, l5: 0.017853, l6: 0.016620

[epoch: 125/100000, batch:    38/  187, ite: 11675] train loss: 0.105254, tar: 0.010994 
l0: 0.004423, l1: 0.004595, l2: 0.004901, l3: 0.004351, l4: 0.005429, l5: 0.005761, l6: 0.006212

[epoch: 125/100000, batch:    40/  187, ite: 11676] train loss: 0.105213, tar: 0.010991 
l0: 0.002140, l1: 0.002259, l2: 0.002414, l3: 0.002973, l4: 0.003772, l5: 0.004241, l6: 0.003292

[epoch: 125/100000, batch:    42/  187, ite: 11677] train loss: 0.105163, tar: 0.010985 
l0: 0.002894, l1: 0.003310, l2: 0.003270, l3: 0.003256, l4: 0.005810, l5: 0.004628, l6: 0.005866

[epoch: 125/100000, batch:    44/  187, ite: 11678] train loss: 0.105117, tar: 0.010980 
l0: 0.006609, l1: 0.006528, l2: 0.007571, l3: 0.007675, l4: 0.010025, l5: 0.010142, l6: 0.012995

[epoch: 125/100000, batch:    46/  187, ite: 11679] train loss: 0.105091, tar: 0.010978 
l0: 0.004523, l1: 0.004884, l2: 0.004809, l3: 0.004937, l4: 0.006333, l5: 0.006700, l6: 0.007143

[epoch: 125/100000, batch:    48/  187, ite: 11680] train loss: 0.105052, tar: 0.010974 
l0: 0.005139, l1: 0.005278, l2: 0.005805, l3: 0.006328, l4: 0.008774, l5: 0.007685, l6: 0.009837

[epoch: 125/100000, batch:    50/  187, ite: 11681] train loss: 0.105019, tar: 0.010971 
l0: 0.007833, l1: 0.008760, l2: 0.010162, l3: 0.009557, l4: 0.011216, l5: 0.010899, l6: 0.011637

[epoch: 125/100000, batch:    52/  187, ite: 11682] train loss: 0.104998, tar: 0.010969 
l0: 0.005506, l1: 0.008171, l2: 0.005779, l3: 0.004969, l4: 0.006859, l5: 0.007078, l6: 0.006494

[epoch: 125/100000, batch:    54/  187, ite: 11683] train loss: 0.104962, tar: 0.010965 
l0: 0.008558, l1: 0.008285, l2: 0.008582, l3: 0.009614, l4: 0.008192, l5: 0.008093, l6: 0.009261

[epoch: 125/100000, batch:    56/  187, ite: 11684] train loss: 0.104936, tar: 0.010964 
l0: 0.003176, l1: 0.003238, l2: 0.003250, l3: 0.003717, l4: 0.004853, l5: 0.004697, l6: 0.006406

[epoch: 125/100000, batch:    58/  187, ite: 11685] train loss: 0.104891, tar: 0.010959 
l0: 0.012409, l1: 0.011980, l2: 0.011933, l3: 0.014475, l4: 0.027176, l5: 0.024549, l6: 0.023937

[epoch: 125/100000, batch:    60/  187, ite: 11686] train loss: 0.104904, tar: 0.010960 
l0: 0.003862, l1: 0.004040, l2: 0.004876, l3: 0.004757, l4: 0.007839, l5: 0.008379, l6: 0.009640

[epoch: 125/100000, batch:    62/  187, ite: 11687] train loss: 0.104867, tar: 0.010956 
l0: 0.009489, l1: 0.010497, l2: 0.009779, l3: 0.009706, l4: 0.009299, l5: 0.008781, l6: 0.009031

[epoch: 125/100000, batch:    64/  187, ite: 11688] train loss: 0.104845, tar: 0.010955 
l0: 0.004386, l1: 0.004282, l2: 0.004330, l3: 0.004650, l4: 0.006475, l5: 0.007683, l6: 0.006932

[epoch: 125/100000, batch:    66/  187, ite: 11689] train loss: 0.104805, tar: 0.010951 
l0: 0.008260, l1: 0.009343, l2: 0.007857, l3: 0.008810, l4: 0.011034, l5: 0.007153, l6: 0.007531

[epoch: 125/100000, batch:    68/  187, ite: 11690] train loss: 0.104779, tar: 0.010950 
l0: 0.008867, l1: 0.008671, l2: 0.009371, l3: 0.010144, l4: 0.014824, l5: 0.013120, l6: 0.012564

[epoch: 125/100000, batch:    70/  187, ite: 11691] train loss: 0.104763, tar: 0.010948 
l0: 0.004044, l1: 0.003931, l2: 0.004423, l3: 0.005649, l4: 0.014005, l5: 0.011097, l6: 0.008852

[epoch: 125/100000, batch:    72/  187, ite: 11692] train loss: 0.104732, tar: 0.010944 
l0: 0.006515, l1: 0.005726, l2: 0.007376, l3: 0.009259, l4: 0.015021, l5: 0.013629, l6: 0.012947

[epoch: 125/100000, batch:    74/  187, ite: 11693] train loss: 0.104711, tar: 0.010942 
l0: 0.008010, l1: 0.008000, l2: 0.007452, l3: 0.007954, l4: 0.017000, l5: 0.016678, l6: 0.017601

[epoch: 125/100000, batch:    76/  187, ite: 11694] train loss: 0.104698, tar: 0.010940 
l0: 0.017322, l1: 0.017679, l2: 0.017344, l3: 0.017138, l4: 0.028397, l5: 0.025510, l6: 0.025075

[epoch: 125/100000, batch:    78/  187, ite: 11695] train loss: 0.104724, tar: 0.010944 
l0: 0.011321, l1: 0.011775, l2: 0.013522, l3: 0.014317, l4: 0.019124, l5: 0.016072, l6: 0.013777

[epoch: 125/100000, batch:    80/  187, ite: 11696] train loss: 0.104721, tar: 0.010944 
l0: 0.005755, l1: 0.006557, l2: 0.006314, l3: 0.005121, l4: 0.011894, l5: 0.008535, l6: 0.009756

[epoch: 125/100000, batch:    82/  187, ite: 11697] train loss: 0.104691, tar: 0.010941 
l0: 0.007447, l1: 0.006681, l2: 0.008575, l3: 0.009472, l4: 0.011145, l5: 0.012429, l6: 0.013008

[epoch: 125/100000, batch:    84/  187, ite: 11698] train loss: 0.104670, tar: 0.010939 
l0: 0.005983, l1: 0.006579, l2: 0.005565, l3: 0.006963, l4: 0.006160, l5: 0.006109, l6: 0.006574

[epoch: 125/100000, batch:    86/  187, ite: 11699] train loss: 0.104635, tar: 0.010936 
l0: 0.005054, l1: 0.005549, l2: 0.005648, l3: 0.006719, l4: 0.009737, l5: 0.008218, l6: 0.008044

[epoch: 125/100000, batch:    88/  187, ite: 11700] train loss: 0.104602, tar: 0.010932 
l0: 0.006705, l1: 0.007499, l2: 0.007436, l3: 0.006896, l4: 0.012021, l5: 0.011809, l6: 0.010251

[epoch: 125/100000, batch:    90/  187, ite: 11701] train loss: 0.104577, tar: 0.010930 
l0: 0.006514, l1: 0.006886, l2: 0.006981, l3: 0.007127, l4: 0.009674, l5: 0.008542, l6: 0.009512

[epoch: 125/100000, batch:    92/  187, ite: 11702] train loss: 0.104548, tar: 0.010927 
l0: 0.006039, l1: 0.006466, l2: 0.007237, l3: 0.007285, l4: 0.007843, l5: 0.008896, l6: 0.007158

[epoch: 125/100000, batch:    94/  187, ite: 11703] train loss: 0.104517, tar: 0.010925 
l0: 0.002252, l1: 0.003158, l2: 0.003373, l3: 0.003729, l4: 0.010314, l5: 0.005629, l6: 0.007208

[epoch: 125/100000, batch:    96/  187, ite: 11704] train loss: 0.104476, tar: 0.010919 
l0: 0.009264, l1: 0.009365, l2: 0.009692, l3: 0.009603, l4: 0.010465, l5: 0.012891, l6: 0.014089

[epoch: 125/100000, batch:    98/  187, ite: 11705] train loss: 0.104459, tar: 0.010918 
l0: 0.006785, l1: 0.007004, l2: 0.007519, l3: 0.007139, l4: 0.012321, l5: 0.012263, l6: 0.011273

[epoch: 125/100000, batch:   100/  187, ite: 11706] train loss: 0.104436, tar: 0.010916 
l0: 0.005059, l1: 0.005549, l2: 0.005384, l3: 0.005302, l4: 0.012077, l5: 0.010382, l6: 0.010945

[epoch: 125/100000, batch:   102/  187, ite: 11707] train loss: 0.104406, tar: 0.010913 
l0: 0.008280, l1: 0.008261, l2: 0.009342, l3: 0.009152, l4: 0.015211, l5: 0.013850, l6: 0.011975

[epoch: 125/100000, batch:   104/  187, ite: 11708] train loss: 0.104390, tar: 0.010911 
l0: 0.007580, l1: 0.008038, l2: 0.008248, l3: 0.008496, l4: 0.012843, l5: 0.011225, l6: 0.012247

[epoch: 125/100000, batch:   106/  187, ite: 11709] train loss: 0.104369, tar: 0.010909 
l0: 0.006176, l1: 0.006241, l2: 0.007699, l3: 0.008226, l4: 0.009127, l5: 0.009504, l6: 0.009527

[epoch: 125/100000, batch:   108/  187, ite: 11710] train loss: 0.104341, tar: 0.010906 
l0: 0.007301, l1: 0.007245, l2: 0.007123, l3: 0.007291, l4: 0.008564, l5: 0.008525, l6: 0.010919

[epoch: 125/100000, batch:   110/  187, ite: 11711] train loss: 0.104313, tar: 0.010904 
l0: 0.011193, l1: 0.010972, l2: 0.013561, l3: 0.013948, l4: 0.019254, l5: 0.015120, l6: 0.017576

[epoch: 125/100000, batch:   112/  187, ite: 11712] train loss: 0.104312, tar: 0.010904 
l0: 0.017942, l1: 0.017702, l2: 0.023138, l3: 0.021415, l4: 0.018506, l5: 0.017011, l6: 0.020895

[epoch: 125/100000, batch:   114/  187, ite: 11713] train loss: 0.104331, tar: 0.010909 
l0: 0.006998, l1: 0.005865, l2: 0.007046, l3: 0.009120, l4: 0.013371, l5: 0.014096, l6: 0.017339

[epoch: 125/100000, batch:   116/  187, ite: 11714] train loss: 0.104313, tar: 0.010906 
l0: 0.010654, l1: 0.010327, l2: 0.011988, l3: 0.012710, l4: 0.015308, l5: 0.017373, l6: 0.016729

[epoch: 125/100000, batch:   118/  187, ite: 11715] train loss: 0.104307, tar: 0.010906 
l0: 0.010544, l1: 0.010488, l2: 0.010543, l3: 0.012752, l4: 0.016176, l5: 0.015062, l6: 0.013238

[epoch: 125/100000, batch:   120/  187, ite: 11716] train loss: 0.104298, tar: 0.010906 
l0: 0.005474, l1: 0.005871, l2: 0.006767, l3: 0.006878, l4: 0.012018, l5: 0.009329, l6: 0.011192

[epoch: 125/100000, batch:   122/  187, ite: 11717] train loss: 0.104271, tar: 0.010903 
l0: 0.005859, l1: 0.005825, l2: 0.005918, l3: 0.006372, l4: 0.016143, l5: 0.020059, l6: 0.020067

[epoch: 125/100000, batch:   124/  187, ite: 11718] train loss: 0.104257, tar: 0.010900 
l0: 0.005021, l1: 0.005009, l2: 0.005404, l3: 0.005055, l4: 0.008278, l5: 0.006913, l6: 0.010581

[epoch: 125/100000, batch:   126/  187, ite: 11719] train loss: 0.104223, tar: 0.010896 
l0: 0.005431, l1: 0.004986, l2: 0.005510, l3: 0.006525, l4: 0.013404, l5: 0.012706, l6: 0.012518

[epoch: 125/100000, batch:   128/  187, ite: 11720] train loss: 0.104198, tar: 0.010893 
l0: 0.004933, l1: 0.005446, l2: 0.006410, l3: 0.006747, l4: 0.009204, l5: 0.006703, l6: 0.007618

[epoch: 125/100000, batch:   130/  187, ite: 11721] train loss: 0.104165, tar: 0.010890 
l0: 0.004052, l1: 0.004365, l2: 0.004381, l3: 0.004033, l4: 0.007981, l5: 0.006825, l6: 0.007253

[epoch: 125/100000, batch:   132/  187, ite: 11722] train loss: 0.104127, tar: 0.010886 
l0: 0.007923, l1: 0.007741, l2: 0.007448, l3: 0.007975, l4: 0.010397, l5: 0.010567, l6: 0.013867

[epoch: 125/100000, batch:   134/  187, ite: 11723] train loss: 0.104105, tar: 0.010884 
l0: 0.005423, l1: 0.005618, l2: 0.007834, l3: 0.006996, l4: 0.007788, l5: 0.007887, l6: 0.007883

[epoch: 125/100000, batch:   136/  187, ite: 11724] train loss: 0.104073, tar: 0.010881 
l0: 0.006286, l1: 0.006118, l2: 0.006497, l3: 0.007131, l4: 0.012870, l5: 0.014918, l6: 0.013892

[epoch: 125/100000, batch:   138/  187, ite: 11725] train loss: 0.104052, tar: 0.010878 
l0: 0.006118, l1: 0.006081, l2: 0.006576, l3: 0.006740, l4: 0.014268, l5: 0.013622, l6: 0.012116

[epoch: 125/100000, batch:   140/  187, ite: 11726] train loss: 0.104030, tar: 0.010875 
l0: 0.011803, l1: 0.013593, l2: 0.011712, l3: 0.012625, l4: 0.016923, l5: 0.013968, l6: 0.014521

[epoch: 125/100000, batch:   142/  187, ite: 11727] train loss: 0.104025, tar: 0.010876 
l0: 0.006502, l1: 0.006645, l2: 0.008979, l3: 0.009691, l4: 0.014796, l5: 0.011329, l6: 0.011260

[epoch: 125/100000, batch:   144/  187, ite: 11728] train loss: 0.104005, tar: 0.010873 
l0: 0.005024, l1: 0.004999, l2: 0.004568, l3: 0.004999, l4: 0.016311, l5: 0.013819, l6: 0.017452

[epoch: 125/100000, batch:   146/  187, ite: 11729] train loss: 0.103983, tar: 0.010870 
l0: 0.014419, l1: 0.013841, l2: 0.013898, l3: 0.016339, l4: 0.031325, l5: 0.026418, l6: 0.025910

[epoch: 125/100000, batch:   148/  187, ite: 11730] train loss: 0.104005, tar: 0.010872 
l0: 0.008216, l1: 0.008886, l2: 0.008408, l3: 0.008629, l4: 0.010689, l5: 0.008999, l6: 0.010500

[epoch: 125/100000, batch:   150/  187, ite: 11731] train loss: 0.103982, tar: 0.010871 
l0: 0.005965, l1: 0.006616, l2: 0.005929, l3: 0.006310, l4: 0.010707, l5: 0.009199, l6: 0.013345

[epoch: 125/100000, batch:   152/  187, ite: 11732] train loss: 0.103956, tar: 0.010868 
l0: 0.009430, l1: 0.008745, l2: 0.007743, l3: 0.008694, l4: 0.007642, l5: 0.010033, l6: 0.012825

[epoch: 125/100000, batch:   154/  187, ite: 11733] train loss: 0.103934, tar: 0.010867 
l0: 0.007503, l1: 0.007611, l2: 0.007184, l3: 0.007552, l4: 0.012361, l5: 0.011757, l6: 0.010642

[epoch: 125/100000, batch:   156/  187, ite: 11734] train loss: 0.103911, tar: 0.010865 
l0: 0.003542, l1: 0.003699, l2: 0.003464, l3: 0.004377, l4: 0.014822, l5: 0.010426, l6: 0.008966

[epoch: 125/100000, batch:   158/  187, ite: 11735] train loss: 0.103879, tar: 0.010861 
l0: 0.005369, l1: 0.004624, l2: 0.004733, l3: 0.006343, l4: 0.008686, l5: 0.009093, l6: 0.013480

[epoch: 125/100000, batch:   160/  187, ite: 11736] train loss: 0.103850, tar: 0.010858 
l0: 0.007950, l1: 0.008360, l2: 0.008411, l3: 0.008512, l4: 0.010200, l5: 0.008980, l6: 0.011089

[epoch: 125/100000, batch:   162/  187, ite: 11737] train loss: 0.103826, tar: 0.010856 
l0: 0.012181, l1: 0.013643, l2: 0.010880, l3: 0.010441, l4: 0.012732, l5: 0.011384, l6: 0.011487

[epoch: 125/100000, batch:   164/  187, ite: 11738] train loss: 0.103814, tar: 0.010857 
l0: 0.007027, l1: 0.007088, l2: 0.007430, l3: 0.007786, l4: 0.016122, l5: 0.011454, l6: 0.013088

[epoch: 125/100000, batch:   166/  187, ite: 11739] train loss: 0.103795, tar: 0.010854 
l0: 0.008243, l1: 0.007887, l2: 0.007843, l3: 0.009359, l4: 0.011748, l5: 0.012626, l6: 0.014159

[epoch: 125/100000, batch:   168/  187, ite: 11740] train loss: 0.103777, tar: 0.010853 
l0: 0.004053, l1: 0.003906, l2: 0.004482, l3: 0.004747, l4: 0.010332, l5: 0.009453, l6: 0.009133

[epoch: 125/100000, batch:   170/  187, ite: 11741] train loss: 0.103743, tar: 0.010849 
l0: 0.002938, l1: 0.003695, l2: 0.003439, l3: 0.003625, l4: 0.006121, l5: 0.004614, l6: 0.005570

[epoch: 125/100000, batch:   172/  187, ite: 11742] train loss: 0.103701, tar: 0.010845 
l0: 0.007127, l1: 0.007853, l2: 0.008514, l3: 0.007617, l4: 0.012369, l5: 0.011105, l6: 0.009418

[epoch: 125/100000, batch:   174/  187, ite: 11743] train loss: 0.103678, tar: 0.010842 
l0: 0.007587, l1: 0.007993, l2: 0.008886, l3: 0.009135, l4: 0.014630, l5: 0.012014, l6: 0.012512

[epoch: 125/100000, batch:   176/  187, ite: 11744] train loss: 0.103661, tar: 0.010841 
l0: 0.015590, l1: 0.015550, l2: 0.016890, l3: 0.016687, l4: 0.028059, l5: 0.025283, l6: 0.024867

[epoch: 125/100000, batch:   178/  187, ite: 11745] train loss: 0.103683, tar: 0.010843 
l0: 0.006865, l1: 0.007387, l2: 0.007607, l3: 0.008213, l4: 0.008679, l5: 0.007533, l6: 0.010707

[epoch: 125/100000, batch:   180/  187, ite: 11746] train loss: 0.103656, tar: 0.010841 
l0: 0.004421, l1: 0.004563, l2: 0.005616, l3: 0.005258, l4: 0.007570, l5: 0.005166, l6: 0.005239

[epoch: 125/100000, batch:   182/  187, ite: 11747] train loss: 0.103619, tar: 0.010837 
l0: 0.003073, l1: 0.004449, l2: 0.007287, l3: 0.004601, l4: 0.005012, l5: 0.005062, l6: 0.003311

[epoch: 125/100000, batch:   184/  187, ite: 11748] train loss: 0.103578, tar: 0.010833 
l0: 0.008585, l1: 0.008524, l2: 0.009638, l3: 0.009368, l4: 0.016441, l5: 0.014502, l6: 0.016409

[epoch: 125/100000, batch:   186/  187, ite: 11749] train loss: 0.103567, tar: 0.010832 
l0: 0.004251, l1: 0.004589, l2: 0.005268, l3: 0.006034, l4: 0.006521, l5: 0.006583, l6: 0.006103

[epoch: 125/100000, batch:   188/  187, ite: 11750] train loss: 0.103530, tar: 0.010828 
l0: 0.010870, l1: 0.011006, l2: 0.012093, l3: 0.011371, l4: 0.012514, l5: 0.013858, l6: 0.016025

[epoch: 126/100000, batch:     2/  187, ite: 11751] train loss: 0.103521, tar: 0.010828 
l0: 0.009549, l1: 0.009698, l2: 0.010386, l3: 0.010552, l4: 0.012798, l5: 0.012696, l6: 0.013155

[epoch: 126/100000, batch:     4/  187, ite: 11752] train loss: 0.103507, tar: 0.010827 
l0: 0.002975, l1: 0.003039, l2: 0.003844, l3: 0.004830, l4: 0.007542, l5: 0.006004, l6: 0.007979

[epoch: 126/100000, batch:     6/  187, ite: 11753] train loss: 0.103468, tar: 0.010823 
l0: 0.007645, l1: 0.007981, l2: 0.007312, l3: 0.007062, l4: 0.013070, l5: 0.011852, l6: 0.012051

[epoch: 126/100000, batch:     8/  187, ite: 11754] train loss: 0.103448, tar: 0.010821 
l0: 0.006830, l1: 0.006775, l2: 0.007425, l3: 0.008126, l4: 0.012395, l5: 0.012595, l6: 0.012820

[epoch: 126/100000, batch:    10/  187, ite: 11755] train loss: 0.103427, tar: 0.010819 
l0: 0.006443, l1: 0.006992, l2: 0.006352, l3: 0.007507, l4: 0.011743, l5: 0.011021, l6: 0.008691

[epoch: 126/100000, batch:    12/  187, ite: 11756] train loss: 0.103401, tar: 0.010816 
l0: 0.009019, l1: 0.009405, l2: 0.010707, l3: 0.010062, l4: 0.009415, l5: 0.009122, l6: 0.011619

[epoch: 126/100000, batch:    14/  187, ite: 11757] train loss: 0.103382, tar: 0.010815 
l0: 0.013918, l1: 0.013579, l2: 0.012074, l3: 0.012731, l4: 0.020515, l5: 0.019622, l6: 0.023906

[epoch: 126/100000, batch:    16/  187, ite: 11758] train loss: 0.103389, tar: 0.010817 
l0: 0.009767, l1: 0.010139, l2: 0.010856, l3: 0.011353, l4: 0.015394, l5: 0.013548, l6: 0.012230

[epoch: 126/100000, batch:    18/  187, ite: 11759] train loss: 0.103378, tar: 0.010816 
l0: 0.006519, l1: 0.006724, l2: 0.007638, l3: 0.007127, l4: 0.014149, l5: 0.015006, l6: 0.015860

[epoch: 126/100000, batch:    20/  187, ite: 11760] train loss: 0.103361, tar: 0.010814 
l0: 0.010180, l1: 0.010991, l2: 0.010567, l3: 0.008896, l4: 0.012332, l5: 0.014107, l6: 0.013392

[epoch: 126/100000, batch:    22/  187, ite: 11761] train loss: 0.103348, tar: 0.010813 
l0: 0.005191, l1: 0.006112, l2: 0.007289, l3: 0.006950, l4: 0.014163, l5: 0.010450, l6: 0.009627

[epoch: 126/100000, batch:    24/  187, ite: 11762] train loss: 0.103323, tar: 0.010810 
l0: 0.005490, l1: 0.005206, l2: 0.006500, l3: 0.006086, l4: 0.008651, l5: 0.007273, l6: 0.012612

[epoch: 126/100000, batch:    26/  187, ite: 11763] train loss: 0.103294, tar: 0.010807 
l0: 0.006839, l1: 0.006001, l2: 0.007972, l3: 0.008314, l4: 0.017403, l5: 0.015759, l6: 0.020914

[epoch: 126/100000, batch:    28/  187, ite: 11764] train loss: 0.103282, tar: 0.010805 
l0: 0.004463, l1: 0.004494, l2: 0.004605, l3: 0.006655, l4: 0.006960, l5: 0.007186, l6: 0.007448

[epoch: 126/100000, batch:    30/  187, ite: 11765] train loss: 0.103248, tar: 0.010801 
l0: 0.004688, l1: 0.004962, l2: 0.005488, l3: 0.005525, l4: 0.008090, l5: 0.009046, l6: 0.010294

[epoch: 126/100000, batch:    32/  187, ite: 11766] train loss: 0.103216, tar: 0.010798 
l0: 0.004324, l1: 0.004463, l2: 0.004499, l3: 0.005055, l4: 0.009412, l5: 0.008514, l6: 0.009082

[epoch: 126/100000, batch:    34/  187, ite: 11767] train loss: 0.103184, tar: 0.010794 
l0: 0.002320, l1: 0.002701, l2: 0.003045, l3: 0.002866, l4: 0.006571, l5: 0.005922, l6: 0.008042

[epoch: 126/100000, batch:    36/  187, ite: 11768] train loss: 0.103143, tar: 0.010789 
l0: 0.007007, l1: 0.006939, l2: 0.006129, l3: 0.006586, l4: 0.013771, l5: 0.012940, l6: 0.014870

[epoch: 126/100000, batch:    38/  187, ite: 11769] train loss: 0.103123, tar: 0.010787 
l0: 0.007055, l1: 0.006970, l2: 0.008006, l3: 0.009461, l4: 0.013556, l5: 0.012016, l6: 0.019153

[epoch: 126/100000, batch:    40/  187, ite: 11770] train loss: 0.103108, tar: 0.010785 
l0: 0.006069, l1: 0.005563, l2: 0.006004, l3: 0.007071, l4: 0.010216, l5: 0.013230, l6: 0.009634

[epoch: 126/100000, batch:    42/  187, ite: 11771] train loss: 0.103082, tar: 0.010783 
l0: 0.006007, l1: 0.006068, l2: 0.006268, l3: 0.006290, l4: 0.010254, l5: 0.009540, l6: 0.010803

[epoch: 126/100000, batch:    44/  187, ite: 11772] train loss: 0.103055, tar: 0.010780 
l0: 0.005948, l1: 0.006237, l2: 0.005996, l3: 0.006478, l4: 0.010197, l5: 0.008967, l6: 0.009160

[epoch: 126/100000, batch:    46/  187, ite: 11773] train loss: 0.103027, tar: 0.010777 
l0: 0.009962, l1: 0.009835, l2: 0.011144, l3: 0.010675, l4: 0.018257, l5: 0.019698, l6: 0.014125

[epoch: 126/100000, batch:    48/  187, ite: 11774] train loss: 0.103022, tar: 0.010777 
l0: 0.006297, l1: 0.006949, l2: 0.006884, l3: 0.006837, l4: 0.015521, l5: 0.012840, l6: 0.016468

[epoch: 126/100000, batch:    50/  187, ite: 11775] train loss: 0.103004, tar: 0.010774 
l0: 0.009174, l1: 0.009345, l2: 0.010413, l3: 0.010374, l4: 0.014330, l5: 0.012338, l6: 0.013698

[epoch: 126/100000, batch:    52/  187, ite: 11776] train loss: 0.102991, tar: 0.010773 
l0: 0.004973, l1: 0.005128, l2: 0.004693, l3: 0.005148, l4: 0.006773, l5: 0.006851, l6: 0.007799

[epoch: 126/100000, batch:    54/  187, ite: 11777] train loss: 0.102957, tar: 0.010770 
l0: 0.006172, l1: 0.006583, l2: 0.007201, l3: 0.007778, l4: 0.011220, l5: 0.009132, l6: 0.012734

[epoch: 126/100000, batch:    56/  187, ite: 11778] train loss: 0.102933, tar: 0.010767 
l0: 0.004063, l1: 0.004185, l2: 0.004757, l3: 0.005081, l4: 0.008573, l5: 0.008636, l6: 0.007661

[epoch: 126/100000, batch:    58/  187, ite: 11779] train loss: 0.102899, tar: 0.010764 
l0: 0.005526, l1: 0.005720, l2: 0.006399, l3: 0.006183, l4: 0.008132, l5: 0.007911, l6: 0.010267

[epoch: 126/100000, batch:    60/  187, ite: 11780] train loss: 0.102870, tar: 0.010761 
l0: 0.005229, l1: 0.005241, l2: 0.006274, l3: 0.006363, l4: 0.010767, l5: 0.008928, l6: 0.008555

[epoch: 126/100000, batch:    62/  187, ite: 11781] train loss: 0.102841, tar: 0.010758 
l0: 0.001724, l1: 0.001990, l2: 0.002324, l3: 0.002066, l4: 0.005218, l5: 0.004434, l6: 0.004520

[epoch: 126/100000, batch:    64/  187, ite: 11782] train loss: 0.102795, tar: 0.010752 
l0: 0.006684, l1: 0.006200, l2: 0.006846, l3: 0.008469, l4: 0.013812, l5: 0.011580, l6: 0.013291

[epoch: 126/100000, batch:    66/  187, ite: 11783] train loss: 0.102775, tar: 0.010750 
l0: 0.008920, l1: 0.009434, l2: 0.009892, l3: 0.009690, l4: 0.015899, l5: 0.012564, l6: 0.016095

[epoch: 126/100000, batch:    68/  187, ite: 11784] train loss: 0.102764, tar: 0.010749 
l0: 0.007054, l1: 0.006360, l2: 0.008350, l3: 0.009312, l4: 0.014759, l5: 0.014710, l6: 0.014069

[epoch: 126/100000, batch:    70/  187, ite: 11785] train loss: 0.102748, tar: 0.010747 
l0: 0.002812, l1: 0.003274, l2: 0.003149, l3: 0.002656, l4: 0.005146, l5: 0.004220, l6: 0.003833

[epoch: 126/100000, batch:    72/  187, ite: 11786] train loss: 0.102705, tar: 0.010743 
l0: 0.007575, l1: 0.007793, l2: 0.009153, l3: 0.008769, l4: 0.010141, l5: 0.010647, l6: 0.011528

[epoch: 126/100000, batch:    74/  187, ite: 11787] train loss: 0.102684, tar: 0.010741 
l0: 0.011908, l1: 0.013268, l2: 0.011382, l3: 0.011203, l4: 0.013795, l5: 0.011515, l6: 0.015871

[epoch: 126/100000, batch:    76/  187, ite: 11788] train loss: 0.102676, tar: 0.010742 
l0: 0.011582, l1: 0.009905, l2: 0.014710, l3: 0.014341, l4: 0.022558, l5: 0.024902, l6: 0.023766

[epoch: 126/100000, batch:    78/  187, ite: 11789] train loss: 0.102687, tar: 0.010742 
l0: 0.005140, l1: 0.004943, l2: 0.005120, l3: 0.005886, l4: 0.012287, l5: 0.013526, l6: 0.010322

[epoch: 126/100000, batch:    80/  187, ite: 11790] train loss: 0.102661, tar: 0.010739 
l0: 0.003934, l1: 0.003671, l2: 0.005023, l3: 0.006410, l4: 0.008423, l5: 0.006235, l6: 0.007569

[epoch: 126/100000, batch:    82/  187, ite: 11791] train loss: 0.102627, tar: 0.010735 
l0: 0.005336, l1: 0.005892, l2: 0.005829, l3: 0.005766, l4: 0.007559, l5: 0.006807, l6: 0.007095

[epoch: 126/100000, batch:    84/  187, ite: 11792] train loss: 0.102595, tar: 0.010732 
l0: 0.006178, l1: 0.007536, l2: 0.005503, l3: 0.005528, l4: 0.011248, l5: 0.006831, l6: 0.009200

[epoch: 126/100000, batch:    86/  187, ite: 11793] train loss: 0.102566, tar: 0.010730 
l0: 0.003904, l1: 0.004266, l2: 0.004021, l3: 0.004102, l4: 0.005596, l5: 0.006134, l6: 0.006198

[epoch: 126/100000, batch:    88/  187, ite: 11794] train loss: 0.102528, tar: 0.010726 
l0: 0.008200, l1: 0.008707, l2: 0.009349, l3: 0.008792, l4: 0.013458, l5: 0.012107, l6: 0.014132

[epoch: 126/100000, batch:    90/  187, ite: 11795] train loss: 0.102513, tar: 0.010724 
l0: 0.003267, l1: 0.003681, l2: 0.004492, l3: 0.005144, l4: 0.003552, l5: 0.002974, l6: 0.002430

[epoch: 126/100000, batch:    92/  187, ite: 11796] train loss: 0.102470, tar: 0.010720 
l0: 0.005326, l1: 0.005596, l2: 0.005403, l3: 0.005679, l4: 0.009064, l5: 0.009501, l6: 0.009814

[epoch: 126/100000, batch:    94/  187, ite: 11797] train loss: 0.102441, tar: 0.010717 
l0: 0.005210, l1: 0.005109, l2: 0.006865, l3: 0.007599, l4: 0.010176, l5: 0.010124, l6: 0.011114

[epoch: 126/100000, batch:    96/  187, ite: 11798] train loss: 0.102415, tar: 0.010714 
l0: 0.008827, l1: 0.009515, l2: 0.008433, l3: 0.007899, l4: 0.010305, l5: 0.010336, l6: 0.007606

[epoch: 126/100000, batch:    98/  187, ite: 11799] train loss: 0.102393, tar: 0.010713 
l0: 0.006433, l1: 0.006357, l2: 0.007128, l3: 0.008237, l4: 0.013956, l5: 0.013307, l6: 0.014363

[epoch: 126/100000, batch:   100/  187, ite: 11800] train loss: 0.102375, tar: 0.010711 
l0: 0.005315, l1: 0.005575, l2: 0.006314, l3: 0.006137, l4: 0.013438, l5: 0.010386, l6: 0.011127

[epoch: 126/100000, batch:   102/  187, ite: 11801] train loss: 0.102351, tar: 0.010708 
l0: 0.003830, l1: 0.004310, l2: 0.003703, l3: 0.004524, l4: 0.005298, l5: 0.005642, l6: 0.005977

[epoch: 126/100000, batch:   104/  187, ite: 11802] train loss: 0.102312, tar: 0.010704 
l0: 0.006567, l1: 0.007221, l2: 0.007755, l3: 0.006797, l4: 0.009949, l5: 0.009945, l6: 0.014042

[epoch: 126/100000, batch:   106/  187, ite: 11803] train loss: 0.102290, tar: 0.010702 
l0: 0.007333, l1: 0.009310, l2: 0.008757, l3: 0.007780, l4: 0.006774, l5: 0.006440, l6: 0.007176

[epoch: 126/100000, batch:   108/  187, ite: 11804] train loss: 0.102263, tar: 0.010700 
l0: 0.005064, l1: 0.005038, l2: 0.007685, l3: 0.008614, l4: 0.008486, l5: 0.007397, l6: 0.009783

[epoch: 126/100000, batch:   110/  187, ite: 11805] train loss: 0.102235, tar: 0.010697 
l0: 0.003027, l1: 0.003247, l2: 0.003284, l3: 0.004592, l4: 0.006095, l5: 0.003629, l6: 0.004543

[epoch: 126/100000, batch:   112/  187, ite: 11806] train loss: 0.102195, tar: 0.010692 
l0: 0.007584, l1: 0.006880, l2: 0.008843, l3: 0.008625, l4: 0.011261, l5: 0.012334, l6: 0.012801

[epoch: 126/100000, batch:   114/  187, ite: 11807] train loss: 0.102176, tar: 0.010691 
l0: 0.005083, l1: 0.005164, l2: 0.006647, l3: 0.006705, l4: 0.009768, l5: 0.008676, l6: 0.010041

[epoch: 126/100000, batch:   116/  187, ite: 11808] train loss: 0.102148, tar: 0.010688 
l0: 0.002076, l1: 0.001878, l2: 0.002055, l3: 0.002264, l4: 0.002381, l5: 0.003412, l6: 0.003319

[epoch: 126/100000, batch:   118/  187, ite: 11809] train loss: 0.102101, tar: 0.010683 
l0: 0.007821, l1: 0.007273, l2: 0.009209, l3: 0.009736, l4: 0.016402, l5: 0.015897, l6: 0.016690

[epoch: 126/100000, batch:   120/  187, ite: 11810] train loss: 0.102091, tar: 0.010681 
l0: 0.003903, l1: 0.004055, l2: 0.004408, l3: 0.004304, l4: 0.009398, l5: 0.009973, l6: 0.009771

[epoch: 126/100000, batch:   122/  187, ite: 11811] train loss: 0.102060, tar: 0.010677 
l0: 0.005803, l1: 0.006539, l2: 0.007214, l3: 0.007735, l4: 0.007560, l5: 0.007612, l6: 0.008345

[epoch: 126/100000, batch:   124/  187, ite: 11812] train loss: 0.102031, tar: 0.010675 
l0: 0.004530, l1: 0.004685, l2: 0.004567, l3: 0.008269, l4: 0.008529, l5: 0.009367, l6: 0.011710

[epoch: 126/100000, batch:   126/  187, ite: 11813] train loss: 0.102004, tar: 0.010671 
l0: 0.005699, l1: 0.005570, l2: 0.005910, l3: 0.005280, l4: 0.008083, l5: 0.008092, l6: 0.008959

[epoch: 126/100000, batch:   128/  187, ite: 11814] train loss: 0.101974, tar: 0.010669 
l0: 0.007461, l1: 0.008851, l2: 0.008598, l3: 0.007430, l4: 0.007224, l5: 0.006661, l6: 0.008905

[epoch: 126/100000, batch:   130/  187, ite: 11815] train loss: 0.101948, tar: 0.010667 
l0: 0.003525, l1: 0.004068, l2: 0.004392, l3: 0.003306, l4: 0.003482, l5: 0.004061, l6: 0.005119

[epoch: 126/100000, batch:   132/  187, ite: 11816] train loss: 0.101907, tar: 0.010663 
l0: 0.008454, l1: 0.008779, l2: 0.009566, l3: 0.008851, l4: 0.013606, l5: 0.014411, l6: 0.014063

[epoch: 126/100000, batch:   134/  187, ite: 11817] train loss: 0.101894, tar: 0.010662 
l0: 0.003575, l1: 0.004651, l2: 0.004164, l3: 0.003906, l4: 0.004326, l5: 0.003117, l6: 0.004217

[epoch: 126/100000, batch:   136/  187, ite: 11818] train loss: 0.101853, tar: 0.010658 
l0: 0.002905, l1: 0.003150, l2: 0.003138, l3: 0.002596, l4: 0.004657, l5: 0.003630, l6: 0.004083

[epoch: 126/100000, batch:   138/  187, ite: 11819] train loss: 0.101810, tar: 0.010654 
l0: 0.009953, l1: 0.009969, l2: 0.010000, l3: 0.009923, l4: 0.013591, l5: 0.013533, l6: 0.015491

[epoch: 126/100000, batch:   140/  187, ite: 11820] train loss: 0.101800, tar: 0.010653 
l0: 0.007533, l1: 0.007702, l2: 0.008339, l3: 0.007606, l4: 0.010424, l5: 0.009859, l6: 0.011566

[epoch: 126/100000, batch:   142/  187, ite: 11821] train loss: 0.101778, tar: 0.010651 
l0: 0.006101, l1: 0.006527, l2: 0.006658, l3: 0.005944, l4: 0.008351, l5: 0.008591, l6: 0.009058

[epoch: 126/100000, batch:   144/  187, ite: 11822] train loss: 0.101751, tar: 0.010649 
l0: 0.005178, l1: 0.004977, l2: 0.005278, l3: 0.005490, l4: 0.007999, l5: 0.007810, l6: 0.010031

[epoch: 126/100000, batch:   146/  187, ite: 11823] train loss: 0.101720, tar: 0.010646 
l0: 0.010637, l1: 0.010931, l2: 0.011784, l3: 0.012765, l4: 0.016667, l5: 0.015783, l6: 0.014465

[epoch: 126/100000, batch:   148/  187, ite: 11824] train loss: 0.101716, tar: 0.010646 
l0: 0.004925, l1: 0.005275, l2: 0.005864, l3: 0.005998, l4: 0.006688, l5: 0.006021, l6: 0.007341

[epoch: 126/100000, batch:   150/  187, ite: 11825] train loss: 0.101683, tar: 0.010643 
l0: 0.009075, l1: 0.009679, l2: 0.010753, l3: 0.012083, l4: 0.011286, l5: 0.010163, l6: 0.010925

[epoch: 126/100000, batch:   152/  187, ite: 11826] train loss: 0.101668, tar: 0.010642 
l0: 0.005062, l1: 0.005892, l2: 0.005622, l3: 0.005607, l4: 0.010541, l5: 0.007991, l6: 0.010093

[epoch: 126/100000, batch:   154/  187, ite: 11827] train loss: 0.101640, tar: 0.010639 
l0: 0.004779, l1: 0.005166, l2: 0.005673, l3: 0.006286, l4: 0.007401, l5: 0.007106, l6: 0.006945

[epoch: 126/100000, batch:   156/  187, ite: 11828] train loss: 0.101608, tar: 0.010636 
l0: 0.003064, l1: 0.003328, l2: 0.003282, l3: 0.003485, l4: 0.006030, l5: 0.005198, l6: 0.005311

[epoch: 126/100000, batch:   158/  187, ite: 11829] train loss: 0.101569, tar: 0.010632 
l0: 0.007738, l1: 0.007228, l2: 0.007819, l3: 0.008366, l4: 0.011244, l5: 0.011022, l6: 0.015039

[epoch: 126/100000, batch:   160/  187, ite: 11830] train loss: 0.101551, tar: 0.010630 
l0: 0.008443, l1: 0.008814, l2: 0.010471, l3: 0.009647, l4: 0.012159, l5: 0.011638, l6: 0.011673

[epoch: 126/100000, batch:   162/  187, ite: 11831] train loss: 0.101535, tar: 0.010629 
l0: 0.006305, l1: 0.007181, l2: 0.008327, l3: 0.007772, l4: 0.008504, l5: 0.005605, l6: 0.006447

[epoch: 126/100000, batch:   164/  187, ite: 11832] train loss: 0.101507, tar: 0.010626 
l0: 0.005774, l1: 0.005806, l2: 0.007271, l3: 0.007524, l4: 0.006094, l5: 0.005805, l6: 0.008681

[epoch: 126/100000, batch:   166/  187, ite: 11833] train loss: 0.101477, tar: 0.010624 
l0: 0.008710, l1: 0.009003, l2: 0.009917, l3: 0.009027, l4: 0.010128, l5: 0.010092, l6: 0.016499

[epoch: 126/100000, batch:   168/  187, ite: 11834] train loss: 0.101462, tar: 0.010623 
l0: 0.005770, l1: 0.005732, l2: 0.006820, l3: 0.007194, l4: 0.011420, l5: 0.010684, l6: 0.012724

[epoch: 126/100000, batch:   170/  187, ite: 11835] train loss: 0.101439, tar: 0.010620 
l0: 0.005623, l1: 0.005707, l2: 0.005223, l3: 0.005614, l4: 0.010168, l5: 0.009891, l6: 0.010066

[epoch: 126/100000, batch:   172/  187, ite: 11836] train loss: 0.101413, tar: 0.010617 
l0: 0.008040, l1: 0.008044, l2: 0.006804, l3: 0.007753, l4: 0.011912, l5: 0.011976, l6: 0.016014

[epoch: 126/100000, batch:   174/  187, ite: 11837] train loss: 0.101396, tar: 0.010616 
l0: 0.002979, l1: 0.002966, l2: 0.003025, l3: 0.003372, l4: 0.004422, l5: 0.004602, l6: 0.005268

[epoch: 126/100000, batch:   176/  187, ite: 11838] train loss: 0.101355, tar: 0.010612 
l0: 0.010442, l1: 0.011453, l2: 0.009686, l3: 0.009611, l4: 0.012228, l5: 0.013144, l6: 0.013270

[epoch: 126/100000, batch:   178/  187, ite: 11839] train loss: 0.101344, tar: 0.010612 
l0: 0.006118, l1: 0.006514, l2: 0.005845, l3: 0.006118, l4: 0.010917, l5: 0.012273, l6: 0.012005

[epoch: 126/100000, batch:   180/  187, ite: 11840] train loss: 0.101321, tar: 0.010609 
l0: 0.009764, l1: 0.010031, l2: 0.009127, l3: 0.010440, l4: 0.016537, l5: 0.015093, l6: 0.012519

[epoch: 126/100000, batch:   182/  187, ite: 11841] train loss: 0.101311, tar: 0.010609 
l0: 0.006829, l1: 0.006990, l2: 0.007899, l3: 0.007404, l4: 0.011490, l5: 0.011353, l6: 0.013933

[epoch: 126/100000, batch:   184/  187, ite: 11842] train loss: 0.101292, tar: 0.010607 
l0: 0.003914, l1: 0.003253, l2: 0.003821, l3: 0.006047, l4: 0.009982, l5: 0.009083, l6: 0.008464

[epoch: 126/100000, batch:   186/  187, ite: 11843] train loss: 0.101261, tar: 0.010603 
l0: 0.014200, l1: 0.014135, l2: 0.012550, l3: 0.011525, l4: 0.013188, l5: 0.015360, l6: 0.021993

[epoch: 126/100000, batch:   188/  187, ite: 11844] train loss: 0.101262, tar: 0.010605 
l0: 0.003746, l1: 0.004172, l2: 0.004620, l3: 0.004704, l4: 0.006092, l5: 0.006404, l6: 0.006245

[epoch: 127/100000, batch:     2/  187, ite: 11845] train loss: 0.101227, tar: 0.010601 
l0: 0.006749, l1: 0.007312, l2: 0.006253, l3: 0.006143, l4: 0.011259, l5: 0.010979, l6: 0.014784

[epoch: 127/100000, batch:     4/  187, ite: 11846] train loss: 0.101206, tar: 0.010599 
l0: 0.004462, l1: 0.004171, l2: 0.004673, l3: 0.005272, l4: 0.011222, l5: 0.010923, l6: 0.013272

[epoch: 127/100000, batch:     6/  187, ite: 11847] train loss: 0.101181, tar: 0.010596 
l0: 0.005644, l1: 0.005303, l2: 0.006684, l3: 0.007124, l4: 0.011665, l5: 0.012582, l6: 0.010717

[epoch: 127/100000, batch:     8/  187, ite: 11848] train loss: 0.101158, tar: 0.010593 
l0: 0.006408, l1: 0.007202, l2: 0.006186, l3: 0.006399, l4: 0.010193, l5: 0.009515, l6: 0.011103

[epoch: 127/100000, batch:    10/  187, ite: 11849] train loss: 0.101134, tar: 0.010591 
l0: 0.008094, l1: 0.008615, l2: 0.008522, l3: 0.010261, l4: 0.015269, l5: 0.011128, l6: 0.009539

[epoch: 127/100000, batch:    12/  187, ite: 11850] train loss: 0.101118, tar: 0.010590 
l0: 0.004415, l1: 0.004928, l2: 0.004813, l3: 0.005650, l4: 0.008343, l5: 0.006611, l6: 0.006087

[epoch: 127/100000, batch:    14/  187, ite: 11851] train loss: 0.101086, tar: 0.010586 
l0: 0.002675, l1: 0.002741, l2: 0.002430, l3: 0.003439, l4: 0.007427, l5: 0.005443, l6: 0.006586

[epoch: 127/100000, batch:    16/  187, ite: 11852] train loss: 0.101048, tar: 0.010582 
l0: 0.006194, l1: 0.006970, l2: 0.006554, l3: 0.007135, l4: 0.009323, l5: 0.008400, l6: 0.010283

[epoch: 127/100000, batch:    18/  187, ite: 11853] train loss: 0.101023, tar: 0.010580 
l0: 0.007518, l1: 0.008407, l2: 0.007601, l3: 0.007328, l4: 0.009158, l5: 0.008761, l6: 0.010242

[epoch: 127/100000, batch:    20/  187, ite: 11854] train loss: 0.101000, tar: 0.010578 
l0: 0.007582, l1: 0.007577, l2: 0.007484, l3: 0.008569, l4: 0.011887, l5: 0.010466, l6: 0.010600

[epoch: 127/100000, batch:    22/  187, ite: 11855] train loss: 0.100980, tar: 0.010576 
l0: 0.004412, l1: 0.004151, l2: 0.004584, l3: 0.007534, l4: 0.020797, l5: 0.015529, l6: 0.013796

[epoch: 127/100000, batch:    24/  187, ite: 11856] train loss: 0.100964, tar: 0.010573 
l0: 0.004862, l1: 0.005007, l2: 0.005960, l3: 0.005824, l4: 0.010305, l5: 0.008713, l6: 0.009657

[epoch: 127/100000, batch:    26/  187, ite: 11857] train loss: 0.100937, tar: 0.010570 
l0: 0.004520, l1: 0.004288, l2: 0.005579, l3: 0.004763, l4: 0.004773, l5: 0.005194, l6: 0.006397

[epoch: 127/100000, batch:    28/  187, ite: 11858] train loss: 0.100902, tar: 0.010567 
l0: 0.011615, l1: 0.013153, l2: 0.010860, l3: 0.010724, l4: 0.011920, l5: 0.012445, l6: 0.014605

[epoch: 127/100000, batch:    30/  187, ite: 11859] train loss: 0.100893, tar: 0.010567 
l0: 0.006097, l1: 0.006316, l2: 0.007249, l3: 0.007060, l4: 0.008430, l5: 0.009158, l6: 0.010179

[epoch: 127/100000, batch:    32/  187, ite: 11860] train loss: 0.100868, tar: 0.010565 
l0: 0.006111, l1: 0.005732, l2: 0.005745, l3: 0.006913, l4: 0.012130, l5: 0.013218, l6: 0.011499

[epoch: 127/100000, batch:    34/  187, ite: 11861] train loss: 0.100847, tar: 0.010563 
l0: 0.004219, l1: 0.004128, l2: 0.005026, l3: 0.005414, l4: 0.011322, l5: 0.012619, l6: 0.010334

[epoch: 127/100000, batch:    36/  187, ite: 11862] train loss: 0.100821, tar: 0.010559 
l0: 0.006441, l1: 0.006805, l2: 0.005511, l3: 0.004925, l4: 0.008111, l5: 0.009882, l6: 0.009916

[epoch: 127/100000, batch:    38/  187, ite: 11863] train loss: 0.100795, tar: 0.010557 
l0: 0.009353, l1: 0.008818, l2: 0.009470, l3: 0.009290, l4: 0.011962, l5: 0.013368, l6: 0.018031

[epoch: 127/100000, batch:    40/  187, ite: 11864] train loss: 0.100784, tar: 0.010556 
l0: 0.004354, l1: 0.004100, l2: 0.004100, l3: 0.005825, l4: 0.011868, l5: 0.013228, l6: 0.014812

[epoch: 127/100000, batch:    42/  187, ite: 11865] train loss: 0.100761, tar: 0.010553 
l0: 0.003030, l1: 0.003205, l2: 0.003435, l3: 0.003974, l4: 0.006958, l5: 0.005007, l6: 0.005596

[epoch: 127/100000, batch:    44/  187, ite: 11866] train loss: 0.100724, tar: 0.010549 
l0: 0.004102, l1: 0.004224, l2: 0.004040, l3: 0.005063, l4: 0.011476, l5: 0.010549, l6: 0.008309

[epoch: 127/100000, batch:    46/  187, ite: 11867] train loss: 0.100696, tar: 0.010545 
l0: 0.007814, l1: 0.007922, l2: 0.007855, l3: 0.007973, l4: 0.025284, l5: 0.020005, l6: 0.018916

[epoch: 127/100000, batch:    48/  187, ite: 11868] train loss: 0.100693, tar: 0.010544 
l0: 0.005661, l1: 0.005467, l2: 0.005679, l3: 0.006467, l4: 0.010814, l5: 0.010662, l6: 0.012803

[epoch: 127/100000, batch:    50/  187, ite: 11869] train loss: 0.100670, tar: 0.010541 
l0: 0.009451, l1: 0.008884, l2: 0.009562, l3: 0.009561, l4: 0.014272, l5: 0.016393, l6: 0.016096

[epoch: 127/100000, batch:    52/  187, ite: 11870] train loss: 0.100661, tar: 0.010541 
l0: 0.004963, l1: 0.004971, l2: 0.007733, l3: 0.007774, l4: 0.007086, l5: 0.008046, l6: 0.007270

[epoch: 127/100000, batch:    54/  187, ite: 11871] train loss: 0.100633, tar: 0.010538 
l0: 0.015470, l1: 0.014238, l2: 0.015869, l3: 0.014774, l4: 0.025566, l5: 0.023981, l6: 0.030281

[epoch: 127/100000, batch:    56/  187, ite: 11872] train loss: 0.100654, tar: 0.010540 
l0: 0.003215, l1: 0.003300, l2: 0.004043, l3: 0.004000, l4: 0.007022, l5: 0.006082, l6: 0.006343

[epoch: 127/100000, batch:    58/  187, ite: 11873] train loss: 0.100618, tar: 0.010537 
l0: 0.004136, l1: 0.004163, l2: 0.005023, l3: 0.005911, l4: 0.007074, l5: 0.006602, l6: 0.006636

[epoch: 127/100000, batch:    60/  187, ite: 11874] train loss: 0.100586, tar: 0.010533 
l0: 0.004911, l1: 0.004913, l2: 0.005376, l3: 0.006267, l4: 0.008824, l5: 0.008389, l6: 0.010860

[epoch: 127/100000, batch:    62/  187, ite: 11875] train loss: 0.100559, tar: 0.010530 
l0: 0.003504, l1: 0.003283, l2: 0.004656, l3: 0.006358, l4: 0.010229, l5: 0.008820, l6: 0.008684

[epoch: 127/100000, batch:    64/  187, ite: 11876] train loss: 0.100529, tar: 0.010526 
l0: 0.003705, l1: 0.003671, l2: 0.003841, l3: 0.005083, l4: 0.005627, l5: 0.006116, l6: 0.006345

[epoch: 127/100000, batch:    66/  187, ite: 11877] train loss: 0.100494, tar: 0.010523 
l0: 0.006039, l1: 0.006326, l2: 0.007254, l3: 0.008609, l4: 0.011130, l5: 0.009422, l6: 0.011017

[epoch: 127/100000, batch:    68/  187, ite: 11878] train loss: 0.100472, tar: 0.010520 
l0: 0.009007, l1: 0.009057, l2: 0.009396, l3: 0.010296, l4: 0.009925, l5: 0.010577, l6: 0.010441

[epoch: 127/100000, batch:    70/  187, ite: 11879] train loss: 0.100455, tar: 0.010520 
l0: 0.005112, l1: 0.005036, l2: 0.004824, l3: 0.005560, l4: 0.010946, l5: 0.010731, l6: 0.011341

[epoch: 127/100000, batch:    72/  187, ite: 11880] train loss: 0.100431, tar: 0.010517 
l0: 0.006630, l1: 0.007144, l2: 0.006765, l3: 0.006531, l4: 0.008963, l5: 0.007666, l6: 0.009288

[epoch: 127/100000, batch:    74/  187, ite: 11881] train loss: 0.100405, tar: 0.010515 
l0: 0.004184, l1: 0.004700, l2: 0.004479, l3: 0.004126, l4: 0.008095, l5: 0.007248, l6: 0.007805

[epoch: 127/100000, batch:    76/  187, ite: 11882] train loss: 0.100374, tar: 0.010511 
l0: 0.008269, l1: 0.009089, l2: 0.009894, l3: 0.007692, l4: 0.012128, l5: 0.010461, l6: 0.009442

[epoch: 127/100000, batch:    78/  187, ite: 11883] train loss: 0.100356, tar: 0.010510 
l0: 0.006073, l1: 0.005783, l2: 0.005996, l3: 0.007482, l4: 0.007884, l5: 0.008801, l6: 0.008475

[epoch: 127/100000, batch:    80/  187, ite: 11884] train loss: 0.100329, tar: 0.010508 
l0: 0.005972, l1: 0.006439, l2: 0.006186, l3: 0.006542, l4: 0.013004, l5: 0.010394, l6: 0.012524

[epoch: 127/100000, batch:    82/  187, ite: 11885] train loss: 0.100308, tar: 0.010505 
l0: 0.005572, l1: 0.005590, l2: 0.005438, l3: 0.005783, l4: 0.008878, l5: 0.009041, l6: 0.009964

[epoch: 127/100000, batch:    84/  187, ite: 11886] train loss: 0.100282, tar: 0.010503 
l0: 0.003137, l1: 0.003150, l2: 0.003905, l3: 0.004042, l4: 0.006428, l5: 0.006464, l6: 0.006380

[epoch: 127/100000, batch:    86/  187, ite: 11887] train loss: 0.100247, tar: 0.010499 
l0: 0.007703, l1: 0.007453, l2: 0.009620, l3: 0.010362, l4: 0.015026, l5: 0.014850, l6: 0.014870

[epoch: 127/100000, batch:    88/  187, ite: 11888] train loss: 0.100236, tar: 0.010497 
l0: 0.004553, l1: 0.004490, l2: 0.005193, l3: 0.005313, l4: 0.009091, l5: 0.006337, l6: 0.008393

[epoch: 127/100000, batch:    90/  187, ite: 11889] train loss: 0.100206, tar: 0.010494 
l0: 0.008920, l1: 0.009680, l2: 0.008486, l3: 0.009352, l4: 0.014032, l5: 0.013260, l6: 0.013511

[epoch: 127/100000, batch:    92/  187, ite: 11890] train loss: 0.100194, tar: 0.010493 
l0: 0.002744, l1: 0.003059, l2: 0.003452, l3: 0.003275, l4: 0.009060, l5: 0.007231, l6: 0.005821

[epoch: 127/100000, batch:    94/  187, ite: 11891] train loss: 0.100159, tar: 0.010489 
l0: 0.004114, l1: 0.004479, l2: 0.005680, l3: 0.005145, l4: 0.006964, l5: 0.005475, l6: 0.006396

[epoch: 127/100000, batch:    96/  187, ite: 11892] train loss: 0.100126, tar: 0.010486 
l0: 0.007169, l1: 0.007486, l2: 0.007124, l3: 0.007472, l4: 0.011795, l5: 0.012515, l6: 0.012634

[epoch: 127/100000, batch:    98/  187, ite: 11893] train loss: 0.100108, tar: 0.010484 
l0: 0.005244, l1: 0.005920, l2: 0.005333, l3: 0.005542, l4: 0.010617, l5: 0.008803, l6: 0.009063

[epoch: 127/100000, batch:   100/  187, ite: 11894] train loss: 0.100082, tar: 0.010481 
l0: 0.007339, l1: 0.007787, l2: 0.006046, l3: 0.006774, l4: 0.008195, l5: 0.008768, l6: 0.011058

[epoch: 127/100000, batch:   102/  187, ite: 11895] train loss: 0.100059, tar: 0.010480 
l0: 0.007720, l1: 0.007736, l2: 0.007502, l3: 0.007812, l4: 0.012704, l5: 0.010991, l6: 0.014066

[epoch: 127/100000, batch:   104/  187, ite: 11896] train loss: 0.100042, tar: 0.010478 
l0: 0.004889, l1: 0.005323, l2: 0.005424, l3: 0.005381, l4: 0.005864, l5: 0.004244, l6: 0.005948

[epoch: 127/100000, batch:   106/  187, ite: 11897] train loss: 0.100009, tar: 0.010475 
l0: 0.003640, l1: 0.003620, l2: 0.003578, l3: 0.004717, l4: 0.015234, l5: 0.009566, l6: 0.009105

[epoch: 127/100000, batch:   108/  187, ite: 11898] train loss: 0.099982, tar: 0.010472 
l0: 0.005377, l1: 0.005587, l2: 0.006023, l3: 0.006606, l4: 0.012916, l5: 0.012176, l6: 0.013268

[epoch: 127/100000, batch:   110/  187, ite: 11899] train loss: 0.099962, tar: 0.010469 
l0: 0.008860, l1: 0.010272, l2: 0.010713, l3: 0.009499, l4: 0.016384, l5: 0.013268, l6: 0.012439

[epoch: 127/100000, batch:   112/  187, ite: 11900] train loss: 0.099953, tar: 0.010468 
l0: 0.011199, l1: 0.011776, l2: 0.011826, l3: 0.011328, l4: 0.013774, l5: 0.011228, l6: 0.012410

[epoch: 127/100000, batch:   114/  187, ite: 11901] train loss: 0.099944, tar: 0.010469 
l0: 0.002550, l1: 0.002630, l2: 0.002711, l3: 0.003937, l4: 0.012758, l5: 0.008298, l6: 0.007206

[epoch: 127/100000, batch:   116/  187, ite: 11902] train loss: 0.099912, tar: 0.010464 
l0: 0.008070, l1: 0.008547, l2: 0.008731, l3: 0.008177, l4: 0.012127, l5: 0.010815, l6: 0.012188

[epoch: 127/100000, batch:   118/  187, ite: 11903] train loss: 0.099896, tar: 0.010463 
l0: 0.003664, l1: 0.003857, l2: 0.004199, l3: 0.003738, l4: 0.006483, l5: 0.005979, l6: 0.006632

[epoch: 127/100000, batch:   120/  187, ite: 11904] train loss: 0.099862, tar: 0.010460 
l0: 0.005044, l1: 0.004859, l2: 0.004933, l3: 0.005288, l4: 0.008476, l5: 0.008894, l6: 0.007522

[epoch: 127/100000, batch:   122/  187, ite: 11905] train loss: 0.099833, tar: 0.010457 
l0: 0.006917, l1: 0.007191, l2: 0.008387, l3: 0.008020, l4: 0.009367, l5: 0.007712, l6: 0.008351

[epoch: 127/100000, batch:   124/  187, ite: 11906] train loss: 0.099810, tar: 0.010455 
l0: 0.005970, l1: 0.006456, l2: 0.005432, l3: 0.005880, l4: 0.009464, l5: 0.007013, l6: 0.010582

[epoch: 127/100000, batch:   126/  187, ite: 11907] train loss: 0.099784, tar: 0.010452 
l0: 0.005447, l1: 0.006749, l2: 0.007003, l3: 0.005824, l4: 0.004805, l5: 0.006637, l6: 0.005771

[epoch: 127/100000, batch:   128/  187, ite: 11908] train loss: 0.099754, tar: 0.010450 
l0: 0.009658, l1: 0.009722, l2: 0.008934, l3: 0.008740, l4: 0.015719, l5: 0.014419, l6: 0.016911

[epoch: 127/100000, batch:   130/  187, ite: 11909] train loss: 0.099746, tar: 0.010449 
l0: 0.009358, l1: 0.008908, l2: 0.008410, l3: 0.008686, l4: 0.013351, l5: 0.015057, l6: 0.014936

[epoch: 127/100000, batch:   132/  187, ite: 11910] train loss: 0.099735, tar: 0.010449 
l0: 0.007128, l1: 0.006591, l2: 0.007225, l3: 0.008770, l4: 0.009780, l5: 0.008767, l6: 0.012791

[epoch: 127/100000, batch:   134/  187, ite: 11911] train loss: 0.099715, tar: 0.010447 
l0: 0.006586, l1: 0.006698, l2: 0.005760, l3: 0.006686, l4: 0.009022, l5: 0.008054, l6: 0.010688

[epoch: 127/100000, batch:   136/  187, ite: 11912] train loss: 0.099690, tar: 0.010445 
l0: 0.005620, l1: 0.006177, l2: 0.005292, l3: 0.005000, l4: 0.009321, l5: 0.008178, l6: 0.008898

[epoch: 127/100000, batch:   138/  187, ite: 11913] train loss: 0.099664, tar: 0.010443 
l0: 0.003848, l1: 0.004443, l2: 0.004580, l3: 0.004422, l4: 0.005384, l5: 0.004715, l6: 0.006211

[epoch: 127/100000, batch:   140/  187, ite: 11914] train loss: 0.099629, tar: 0.010439 
l0: 0.010115, l1: 0.010764, l2: 0.010573, l3: 0.009516, l4: 0.012789, l5: 0.013729, l6: 0.012409

[epoch: 127/100000, batch:   142/  187, ite: 11915] train loss: 0.099619, tar: 0.010439 
l0: 0.004303, l1: 0.004872, l2: 0.004415, l3: 0.004438, l4: 0.007726, l5: 0.005508, l6: 0.007974

[epoch: 127/100000, batch:   144/  187, ite: 11916] train loss: 0.099587, tar: 0.010436 
l0: 0.013029, l1: 0.015360, l2: 0.013650, l3: 0.011084, l4: 0.015605, l5: 0.013473, l6: 0.016507

[epoch: 127/100000, batch:   146/  187, ite: 11917] train loss: 0.099587, tar: 0.010437 
l0: 0.005684, l1: 0.005725, l2: 0.006772, l3: 0.006735, l4: 0.007408, l5: 0.007398, l6: 0.008408

[epoch: 127/100000, batch:   148/  187, ite: 11918] train loss: 0.099560, tar: 0.010435 
l0: 0.006267, l1: 0.006116, l2: 0.006817, l3: 0.006754, l4: 0.010591, l5: 0.010947, l6: 0.013942

[epoch: 127/100000, batch:   150/  187, ite: 11919] train loss: 0.099540, tar: 0.010432 
l0: 0.007524, l1: 0.007507, l2: 0.007472, l3: 0.007534, l4: 0.012169, l5: 0.011399, l6: 0.012623

[epoch: 127/100000, batch:   152/  187, ite: 11920] train loss: 0.099523, tar: 0.010431 
l0: 0.006462, l1: 0.006149, l2: 0.008257, l3: 0.007909, l4: 0.013927, l5: 0.012958, l6: 0.012637

[epoch: 127/100000, batch:   154/  187, ite: 11921] train loss: 0.099507, tar: 0.010429 
l0: 0.008496, l1: 0.008760, l2: 0.009629, l3: 0.010518, l4: 0.014322, l5: 0.012236, l6: 0.012481

[epoch: 127/100000, batch:   156/  187, ite: 11922] train loss: 0.099495, tar: 0.010428 
l0: 0.010921, l1: 0.010771, l2: 0.012281, l3: 0.013470, l4: 0.011356, l5: 0.010709, l6: 0.012200

[epoch: 127/100000, batch:   158/  187, ite: 11923] train loss: 0.099485, tar: 0.010428 
l0: 0.006844, l1: 0.006674, l2: 0.007735, l3: 0.007972, l4: 0.015160, l5: 0.012811, l6: 0.014502

[epoch: 127/100000, batch:   160/  187, ite: 11924] train loss: 0.099471, tar: 0.010426 
l0: 0.007811, l1: 0.008753, l2: 0.007064, l3: 0.007053, l4: 0.012213, l5: 0.010961, l6: 0.010379

[epoch: 127/100000, batch:   162/  187, ite: 11925] train loss: 0.099453, tar: 0.010425 
l0: 0.010980, l1: 0.012058, l2: 0.012598, l3: 0.011266, l4: 0.013975, l5: 0.010592, l6: 0.011038

[epoch: 127/100000, batch:   164/  187, ite: 11926] train loss: 0.099444, tar: 0.010425 
l0: 0.005765, l1: 0.006122, l2: 0.006544, l3: 0.006060, l4: 0.010307, l5: 0.009346, l6: 0.009462

[epoch: 127/100000, batch:   166/  187, ite: 11927] train loss: 0.099420, tar: 0.010423 
l0: 0.006562, l1: 0.006707, l2: 0.006402, l3: 0.006940, l4: 0.009654, l5: 0.009352, l6: 0.010817

[epoch: 127/100000, batch:   168/  187, ite: 11928] train loss: 0.099398, tar: 0.010421 
l0: 0.010778, l1: 0.010330, l2: 0.014228, l3: 0.016408, l4: 0.017260, l5: 0.014528, l6: 0.011287

[epoch: 127/100000, batch:   170/  187, ite: 11929] train loss: 0.099395, tar: 0.010421 
l0: 0.005889, l1: 0.006066, l2: 0.007170, l3: 0.006091, l4: 0.010891, l5: 0.009955, l6: 0.010104

[epoch: 127/100000, batch:   172/  187, ite: 11930] train loss: 0.099373, tar: 0.010419 
l0: 0.003228, l1: 0.003291, l2: 0.003813, l3: 0.003547, l4: 0.006939, l5: 0.005653, l6: 0.007012

[epoch: 127/100000, batch:   174/  187, ite: 11931] train loss: 0.099339, tar: 0.010415 
l0: 0.011567, l1: 0.013303, l2: 0.013324, l3: 0.012377, l4: 0.016490, l5: 0.012424, l6: 0.012204

[epoch: 127/100000, batch:   176/  187, ite: 11932] train loss: 0.099335, tar: 0.010415 
l0: 0.004316, l1: 0.004574, l2: 0.005087, l3: 0.005259, l4: 0.011837, l5: 0.008419, l6: 0.007955

[epoch: 127/100000, batch:   178/  187, ite: 11933] train loss: 0.099308, tar: 0.010412 
l0: 0.004938, l1: 0.005104, l2: 0.005125, l3: 0.005618, l4: 0.007969, l5: 0.007843, l6: 0.007639

[epoch: 127/100000, batch:   180/  187, ite: 11934] train loss: 0.099279, tar: 0.010410 
l0: 0.009696, l1: 0.009639, l2: 0.010140, l3: 0.010984, l4: 0.018915, l5: 0.016827, l6: 0.016394

[epoch: 127/100000, batch:   182/  187, ite: 11935] train loss: 0.099276, tar: 0.010409 
l0: 0.009128, l1: 0.009061, l2: 0.007801, l3: 0.009648, l4: 0.020362, l5: 0.017922, l6: 0.019789

[epoch: 127/100000, batch:   184/  187, ite: 11936] train loss: 0.099273, tar: 0.010408 
l0: 0.005179, l1: 0.006029, l2: 0.006004, l3: 0.005470, l4: 0.010382, l5: 0.008737, l6: 0.007786

[epoch: 127/100000, batch:   186/  187, ite: 11937] train loss: 0.099247, tar: 0.010406 
l0: 0.004982, l1: 0.005172, l2: 0.005799, l3: 0.005466, l4: 0.010923, l5: 0.008256, l6: 0.008413

[epoch: 127/100000, batch:   188/  187, ite: 11938] train loss: 0.099222, tar: 0.010403 
l0: 0.006148, l1: 0.006897, l2: 0.006307, l3: 0.007085, l4: 0.014633, l5: 0.012829, l6: 0.014894

[epoch: 128/100000, batch:     2/  187, ite: 11939] train loss: 0.099206, tar: 0.010401 
l0: 0.005288, l1: 0.005966, l2: 0.005894, l3: 0.006186, l4: 0.010992, l5: 0.008244, l6: 0.010913

[epoch: 128/100000, batch:     4/  187, ite: 11940] train loss: 0.099182, tar: 0.010398 
l0: 0.004493, l1: 0.004320, l2: 0.004525, l3: 0.005411, l4: 0.007252, l5: 0.005345, l6: 0.008235

[epoch: 128/100000, batch:     6/  187, ite: 11941] train loss: 0.099152, tar: 0.010395 
l0: 0.007590, l1: 0.007318, l2: 0.009138, l3: 0.009310, l4: 0.013043, l5: 0.012203, l6: 0.010453

[epoch: 128/100000, batch:     8/  187, ite: 11942] train loss: 0.099136, tar: 0.010394 
l0: 0.006483, l1: 0.006840, l2: 0.008485, l3: 0.007063, l4: 0.007522, l5: 0.007035, l6: 0.008609

[epoch: 128/100000, batch:    10/  187, ite: 11943] train loss: 0.099112, tar: 0.010392 
l0: 0.009585, l1: 0.009455, l2: 0.011046, l3: 0.011309, l4: 0.013099, l5: 0.012861, l6: 0.013965

[epoch: 128/100000, batch:    12/  187, ite: 11944] train loss: 0.099103, tar: 0.010391 
l0: 0.004672, l1: 0.004265, l2: 0.005407, l3: 0.006088, l4: 0.012780, l5: 0.012061, l6: 0.009201

[epoch: 128/100000, batch:    14/  187, ite: 11945] train loss: 0.099080, tar: 0.010388 
l0: 0.006163, l1: 0.006571, l2: 0.007359, l3: 0.007007, l4: 0.009768, l5: 0.009045, l6: 0.009428

[epoch: 128/100000, batch:    16/  187, ite: 11946] train loss: 0.099057, tar: 0.010386 
l0: 0.007583, l1: 0.008387, l2: 0.008513, l3: 0.008098, l4: 0.010339, l5: 0.009347, l6: 0.011625

[epoch: 128/100000, batch:    18/  187, ite: 11947] train loss: 0.099039, tar: 0.010385 
l0: 0.015601, l1: 0.014961, l2: 0.018170, l3: 0.016254, l4: 0.014734, l5: 0.016516, l6: 0.017101

[epoch: 128/100000, batch:    20/  187, ite: 11948] train loss: 0.099047, tar: 0.010387 
l0: 0.010882, l1: 0.009386, l2: 0.012123, l3: 0.014858, l4: 0.022523, l5: 0.022326, l6: 0.024532

[epoch: 128/100000, batch:    22/  187, ite: 11949] train loss: 0.099056, tar: 0.010388 
l0: 0.011700, l1: 0.010329, l2: 0.010751, l3: 0.013474, l4: 0.027290, l5: 0.027277, l6: 0.026086

[epoch: 128/100000, batch:    24/  187, ite: 11950] train loss: 0.099070, tar: 0.010388 
l0: 0.007001, l1: 0.007501, l2: 0.005913, l3: 0.006847, l4: 0.012316, l5: 0.011998, l6: 0.012988

[epoch: 128/100000, batch:    26/  187, ite: 11951] train loss: 0.099052, tar: 0.010387 
l0: 0.008534, l1: 0.008510, l2: 0.007650, l3: 0.008792, l4: 0.012640, l5: 0.011741, l6: 0.015063

[epoch: 128/100000, batch:    28/  187, ite: 11952] train loss: 0.099039, tar: 0.010386 
l0: 0.005338, l1: 0.005812, l2: 0.005712, l3: 0.005297, l4: 0.008462, l5: 0.008799, l6: 0.008475

[epoch: 128/100000, batch:    30/  187, ite: 11953] train loss: 0.099013, tar: 0.010383 
l0: 0.006979, l1: 0.007591, l2: 0.007932, l3: 0.008595, l4: 0.009324, l5: 0.008830, l6: 0.009133

[epoch: 128/100000, batch:    32/  187, ite: 11954] train loss: 0.098992, tar: 0.010381 
l0: 0.007147, l1: 0.007197, l2: 0.006235, l3: 0.006929, l4: 0.008914, l5: 0.009749, l6: 0.007690

[epoch: 128/100000, batch:    34/  187, ite: 11955] train loss: 0.098969, tar: 0.010380 
l0: 0.002104, l1: 0.002315, l2: 0.002387, l3: 0.002261, l4: 0.005352, l5: 0.003821, l6: 0.004847

[epoch: 128/100000, batch:    36/  187, ite: 11956] train loss: 0.098930, tar: 0.010375 
l0: 0.008935, l1: 0.008735, l2: 0.009784, l3: 0.009499, l4: 0.016554, l5: 0.016114, l6: 0.012164

[epoch: 128/100000, batch:    38/  187, ite: 11957] train loss: 0.098921, tar: 0.010375 
l0: 0.006204, l1: 0.006239, l2: 0.007825, l3: 0.007012, l4: 0.010016, l5: 0.010121, l6: 0.010856

[epoch: 128/100000, batch:    40/  187, ite: 11958] train loss: 0.098900, tar: 0.010373 
l0: 0.005901, l1: 0.006034, l2: 0.006257, l3: 0.006575, l4: 0.011196, l5: 0.010903, l6: 0.011738

[epoch: 128/100000, batch:    42/  187, ite: 11959] train loss: 0.098880, tar: 0.010370 
l0: 0.006698, l1: 0.006275, l2: 0.006228, l3: 0.007109, l4: 0.018943, l5: 0.019131, l6: 0.020943

[epoch: 128/100000, batch:    44/  187, ite: 11960] train loss: 0.098873, tar: 0.010368 
l0: 0.003308, l1: 0.002880, l2: 0.003390, l3: 0.005323, l4: 0.008906, l5: 0.009398, l6: 0.010903

[epoch: 128/100000, batch:    46/  187, ite: 11961] train loss: 0.098845, tar: 0.010365 
l0: 0.004334, l1: 0.004522, l2: 0.005483, l3: 0.005202, l4: 0.008412, l5: 0.008936, l6: 0.008680

[epoch: 128/100000, batch:    48/  187, ite: 11962] train loss: 0.098818, tar: 0.010362 
l0: 0.004377, l1: 0.004446, l2: 0.004163, l3: 0.004352, l4: 0.007931, l5: 0.007231, l6: 0.009832

[epoch: 128/100000, batch:    50/  187, ite: 11963] train loss: 0.098789, tar: 0.010359 
l0: 0.006741, l1: 0.006888, l2: 0.007111, l3: 0.007586, l4: 0.015539, l5: 0.013383, l6: 0.013922

[epoch: 128/100000, batch:    52/  187, ite: 11964] train loss: 0.098775, tar: 0.010357 
l0: 0.008198, l1: 0.008414, l2: 0.008137, l3: 0.008380, l4: 0.009139, l5: 0.009833, l6: 0.011109

[epoch: 128/100000, batch:    54/  187, ite: 11965] train loss: 0.098757, tar: 0.010356 
l0: 0.009440, l1: 0.009538, l2: 0.010742, l3: 0.011591, l4: 0.018831, l5: 0.014348, l6: 0.014603

[epoch: 128/100000, batch:    56/  187, ite: 11966] train loss: 0.098752, tar: 0.010355 
l0: 0.004958, l1: 0.004776, l2: 0.005803, l3: 0.006348, l4: 0.014048, l5: 0.011314, l6: 0.010764

[epoch: 128/100000, batch:    58/  187, ite: 11967] train loss: 0.098731, tar: 0.010352 
l0: 0.012380, l1: 0.012127, l2: 0.015592, l3: 0.015945, l4: 0.018688, l5: 0.015781, l6: 0.018811

[epoch: 128/100000, batch:    60/  187, ite: 11968] train loss: 0.098737, tar: 0.010354 
l0: 0.009094, l1: 0.008298, l2: 0.009686, l3: 0.011838, l4: 0.025731, l5: 0.027788, l6: 0.022968

[epoch: 128/100000, batch:    62/  187, ite: 11969] train loss: 0.098745, tar: 0.010353 
l0: 0.007138, l1: 0.008348, l2: 0.007182, l3: 0.007315, l4: 0.010976, l5: 0.009326, l6: 0.012481

[epoch: 128/100000, batch:    64/  187, ite: 11970] train loss: 0.098727, tar: 0.010351 
l0: 0.004368, l1: 0.004767, l2: 0.004493, l3: 0.005029, l4: 0.005466, l5: 0.003988, l6: 0.005470

[epoch: 128/100000, batch:    66/  187, ite: 11971] train loss: 0.098694, tar: 0.010348 
l0: 0.005785, l1: 0.006298, l2: 0.005559, l3: 0.006172, l4: 0.010357, l5: 0.009312, l6: 0.012055

[epoch: 128/100000, batch:    68/  187, ite: 11972] train loss: 0.098672, tar: 0.010346 
l0: 0.006521, l1: 0.005787, l2: 0.006254, l3: 0.008834, l4: 0.013859, l5: 0.013899, l6: 0.012156

[epoch: 128/100000, batch:    70/  187, ite: 11973] train loss: 0.098656, tar: 0.010344 
l0: 0.006583, l1: 0.006619, l2: 0.006483, l3: 0.008025, l4: 0.010089, l5: 0.009047, l6: 0.011515

[epoch: 128/100000, batch:    72/  187, ite: 11974] train loss: 0.098636, tar: 0.010342 
l0: 0.005995, l1: 0.006006, l2: 0.005766, l3: 0.005707, l4: 0.006274, l5: 0.006813, l6: 0.007527

[epoch: 128/100000, batch:    74/  187, ite: 11975] train loss: 0.098608, tar: 0.010340 
l0: 0.009724, l1: 0.011823, l2: 0.008355, l3: 0.007470, l4: 0.007312, l5: 0.009140, l6: 0.007913

[epoch: 128/100000, batch:    76/  187, ite: 11976] train loss: 0.098589, tar: 0.010340 
l0: 0.012261, l1: 0.011395, l2: 0.009741, l3: 0.009751, l4: 0.021758, l5: 0.025378, l6: 0.024778

[epoch: 128/100000, batch:    78/  187, ite: 11977] train loss: 0.098598, tar: 0.010341 
l0: 0.002738, l1: 0.003008, l2: 0.002911, l3: 0.002853, l4: 0.005196, l5: 0.004854, l6: 0.005821

[epoch: 128/100000, batch:    80/  187, ite: 11978] train loss: 0.098562, tar: 0.010337 
l0: 0.016166, l1: 0.015094, l2: 0.015584, l3: 0.014523, l4: 0.023142, l5: 0.023111, l6: 0.033088

[epoch: 128/100000, batch:    82/  187, ite: 11979] train loss: 0.098583, tar: 0.010340 
l0: 0.002686, l1: 0.003013, l2: 0.002528, l3: 0.002959, l4: 0.005856, l5: 0.004877, l6: 0.005458

[epoch: 128/100000, batch:    84/  187, ite: 11980] train loss: 0.098547, tar: 0.010336 
l0: 0.007183, l1: 0.007200, l2: 0.008281, l3: 0.007816, l4: 0.009271, l5: 0.009051, l6: 0.010049

[epoch: 128/100000, batch:    86/  187, ite: 11981] train loss: 0.098527, tar: 0.010334 
l0: 0.006276, l1: 0.006150, l2: 0.005940, l3: 0.005692, l4: 0.011869, l5: 0.011137, l6: 0.009386

[epoch: 128/100000, batch:    88/  187, ite: 11982] train loss: 0.098506, tar: 0.010332 
l0: 0.007156, l1: 0.007328, l2: 0.006888, l3: 0.007387, l4: 0.013936, l5: 0.012909, l6: 0.011519

[epoch: 128/100000, batch:    90/  187, ite: 11983] train loss: 0.098490, tar: 0.010331 
l0: 0.005785, l1: 0.005896, l2: 0.006682, l3: 0.006966, l4: 0.010632, l5: 0.011170, l6: 0.012480

[epoch: 128/100000, batch:    92/  187, ite: 11984] train loss: 0.098470, tar: 0.010328 
l0: 0.008274, l1: 0.007996, l2: 0.008681, l3: 0.009990, l4: 0.012468, l5: 0.011072, l6: 0.012893

[epoch: 128/100000, batch:    94/  187, ite: 11985] train loss: 0.098457, tar: 0.010327 
l0: 0.010111, l1: 0.010169, l2: 0.009685, l3: 0.010685, l4: 0.013678, l5: 0.014427, l6: 0.020073

[epoch: 128/100000, batch:    96/  187, ite: 11986] train loss: 0.098452, tar: 0.010327 
l0: 0.006475, l1: 0.006774, l2: 0.006690, l3: 0.006790, l4: 0.010352, l5: 0.009794, l6: 0.011910

[epoch: 128/100000, batch:    98/  187, ite: 11987] train loss: 0.098432, tar: 0.010325 
l0: 0.012926, l1: 0.012173, l2: 0.012357, l3: 0.014113, l4: 0.016234, l5: 0.016054, l6: 0.021728

[epoch: 128/100000, batch:   100/  187, ite: 11988] train loss: 0.098435, tar: 0.010326 
l0: 0.005420, l1: 0.005682, l2: 0.004902, l3: 0.004583, l4: 0.008191, l5: 0.008648, l6: 0.009439

[epoch: 128/100000, batch:   102/  187, ite: 11989] train loss: 0.098410, tar: 0.010324 
l0: 0.006932, l1: 0.006798, l2: 0.007262, l3: 0.007232, l4: 0.018521, l5: 0.013896, l6: 0.017610

[epoch: 128/100000, batch:   104/  187, ite: 11990] train loss: 0.098399, tar: 0.010322 
l0: 0.004554, l1: 0.005045, l2: 0.005492, l3: 0.005063, l4: 0.010014, l5: 0.008000, l6: 0.010099

[epoch: 128/100000, batch:   106/  187, ite: 11991] train loss: 0.098374, tar: 0.010319 
l0: 0.007058, l1: 0.007276, l2: 0.008258, l3: 0.007832, l4: 0.011619, l5: 0.010161, l6: 0.010132

[epoch: 128/100000, batch:   108/  187, ite: 11992] train loss: 0.098356, tar: 0.010318 
l0: 0.004041, l1: 0.004146, l2: 0.004314, l3: 0.004715, l4: 0.006619, l5: 0.005775, l6: 0.006226

[epoch: 128/100000, batch:   110/  187, ite: 11993] train loss: 0.098325, tar: 0.010315 
l0: 0.008328, l1: 0.008201, l2: 0.009200, l3: 0.009672, l4: 0.011038, l5: 0.010720, l6: 0.012044

[epoch: 128/100000, batch:   112/  187, ite: 11994] train loss: 0.098310, tar: 0.010314 
l0: 0.004275, l1: 0.004756, l2: 0.004291, l3: 0.004278, l4: 0.007664, l5: 0.007330, l6: 0.008441

[epoch: 128/100000, batch:   114/  187, ite: 11995] train loss: 0.098281, tar: 0.010311 
l0: 0.001988, l1: 0.002183, l2: 0.002374, l3: 0.002572, l4: 0.006296, l5: 0.005146, l6: 0.003874

[epoch: 128/100000, batch:   116/  187, ite: 11996] train loss: 0.098244, tar: 0.010306 
l0: 0.011256, l1: 0.011577, l2: 0.010712, l3: 0.011187, l4: 0.013254, l5: 0.014865, l6: 0.015114

[epoch: 128/100000, batch:   118/  187, ite: 11997] train loss: 0.098239, tar: 0.010307 
l0: 0.005284, l1: 0.005333, l2: 0.005719, l3: 0.005338, l4: 0.006591, l5: 0.007284, l6: 0.008135

[epoch: 128/100000, batch:   120/  187, ite: 11998] train loss: 0.098212, tar: 0.010304 
l0: 0.005649, l1: 0.006567, l2: 0.006079, l3: 0.006360, l4: 0.009589, l5: 0.008172, l6: 0.008427

[epoch: 128/100000, batch:   122/  187, ite: 11999] train loss: 0.098188, tar: 0.010302 
l0: 0.005919, l1: 0.005993, l2: 0.006817, l3: 0.006801, l4: 0.010298, l5: 0.009192, l6: 0.009563

[epoch: 128/100000, batch:   124/  187, ite: 12000] train loss: 0.098166, tar: 0.010300 
l0: 0.003234, l1: 0.003503, l2: 0.004080, l3: 0.003309, l4: 0.005866, l5: 0.005312, l6: 0.006694

[epoch: 128/100000, batch:   126/  187, ite: 12001] train loss: 0.031996, tar: 0.003234 
l0: 0.006086, l1: 0.006945, l2: 0.006429, l3: 0.005862, l4: 0.007380, l5: 0.007749, l6: 0.007082

[epoch: 128/100000, batch:   128/  187, ite: 12002] train loss: 0.039765, tar: 0.004660 
l0: 0.003953, l1: 0.004086, l2: 0.005034, l3: 0.005201, l4: 0.007169, l5: 0.005603, l6: 0.006447

[epoch: 128/100000, batch:   130/  187, ite: 12003] train loss: 0.039008, tar: 0.004425 
l0: 0.004632, l1: 0.004960, l2: 0.005243, l3: 0.005503, l4: 0.007960, l5: 0.007051, l6: 0.008594

[epoch: 128/100000, batch:   132/  187, ite: 12004] train loss: 0.040242, tar: 0.004476 
l0: 0.007505, l1: 0.007304, l2: 0.008090, l3: 0.008641, l4: 0.018720, l5: 0.017851, l6: 0.014538

[epoch: 128/100000, batch:   134/  187, ite: 12005] train loss: 0.048723, tar: 0.005082 
l0: 0.006058, l1: 0.006254, l2: 0.007023, l3: 0.006714, l4: 0.012590, l5: 0.012324, l6: 0.009484

[epoch: 128/100000, batch:   136/  187, ite: 12006] train loss: 0.050677, tar: 0.005245 
l0: 0.005417, l1: 0.006126, l2: 0.006576, l3: 0.005722, l4: 0.010360, l5: 0.008613, l6: 0.010732

[epoch: 128/100000, batch:   138/  187, ite: 12007] train loss: 0.051087, tar: 0.005269 
l0: 0.003443, l1: 0.003727, l2: 0.003058, l3: 0.003554, l4: 0.004311, l5: 0.004471, l6: 0.004673

[epoch: 128/100000, batch:   140/  187, ite: 12008] train loss: 0.048106, tar: 0.005041 
l0: 0.008636, l1: 0.008219, l2: 0.008490, l3: 0.010140, l4: 0.013589, l5: 0.013674, l6: 0.015470

[epoch: 128/100000, batch:   142/  187, ite: 12009] train loss: 0.051452, tar: 0.005440 
l0: 0.008374, l1: 0.009708, l2: 0.009437, l3: 0.008857, l4: 0.009707, l5: 0.008949, l6: 0.010551

[epoch: 128/100000, batch:   144/  187, ite: 12010] train loss: 0.052865, tar: 0.005734 
l0: 0.007203, l1: 0.007906, l2: 0.008126, l3: 0.008612, l4: 0.013210, l5: 0.012006, l6: 0.011514

[epoch: 128/100000, batch:   146/  187, ite: 12011] train loss: 0.054293, tar: 0.005867 
l0: 0.006997, l1: 0.007349, l2: 0.007551, l3: 0.006078, l4: 0.009347, l5: 0.009306, l6: 0.011252

[epoch: 128/100000, batch:   148/  187, ite: 12012] train loss: 0.054592, tar: 0.005962 
l0: 0.007979, l1: 0.008272, l2: 0.008898, l3: 0.006824, l4: 0.006549, l5: 0.007207, l6: 0.007649

[epoch: 128/100000, batch:   150/  187, ite: 12013] train loss: 0.054499, tar: 0.006117 
l0: 0.006420, l1: 0.006627, l2: 0.006668, l3: 0.006513, l4: 0.010135, l5: 0.009410, l6: 0.010699

[epoch: 128/100000, batch:   152/  187, ite: 12014] train loss: 0.054640, tar: 0.006138 
l0: 0.010217, l1: 0.010048, l2: 0.011657, l3: 0.012119, l4: 0.019230, l5: 0.017887, l6: 0.018403

[epoch: 128/100000, batch:   154/  187, ite: 12015] train loss: 0.057634, tar: 0.006410 
l0: 0.008306, l1: 0.008221, l2: 0.009356, l3: 0.009354, l4: 0.013408, l5: 0.011706, l6: 0.015435

[epoch: 128/100000, batch:   156/  187, ite: 12016] train loss: 0.058769, tar: 0.006529 
l0: 0.007081, l1: 0.007492, l2: 0.007128, l3: 0.007256, l4: 0.011255, l5: 0.011881, l6: 0.014211

[epoch: 128/100000, batch:   158/  187, ite: 12017] train loss: 0.059212, tar: 0.006561 
l0: 0.005243, l1: 0.005647, l2: 0.005374, l3: 0.005325, l4: 0.007491, l5: 0.006755, l6: 0.007782

[epoch: 128/100000, batch:   160/  187, ite: 12018] train loss: 0.058346, tar: 0.006488 
l0: 0.005446, l1: 0.005955, l2: 0.005841, l3: 0.005282, l4: 0.007523, l5: 0.007266, l6: 0.009537

[epoch: 128/100000, batch:   162/  187, ite: 12019] train loss: 0.057741, tar: 0.006433 
l0: 0.009457, l1: 0.009599, l2: 0.008641, l3: 0.011618, l4: 0.011498, l5: 0.011177, l6: 0.010901

[epoch: 128/100000, batch:   164/  187, ite: 12020] train loss: 0.058498, tar: 0.006584 
l0: 0.009481, l1: 0.010502, l2: 0.009261, l3: 0.009262, l4: 0.010427, l5: 0.009870, l6: 0.012106

[epoch: 128/100000, batch:   166/  187, ite: 12021] train loss: 0.059089, tar: 0.006722 
l0: 0.005254, l1: 0.005397, l2: 0.005139, l3: 0.004476, l4: 0.006969, l5: 0.007391, l6: 0.008518

[epoch: 128/100000, batch:   168/  187, ite: 12022] train loss: 0.058365, tar: 0.006656 
l0: 0.005519, l1: 0.005893, l2: 0.007322, l3: 0.009250, l4: 0.014646, l5: 0.011085, l6: 0.010054

[epoch: 128/100000, batch:   170/  187, ite: 12023] train loss: 0.058600, tar: 0.006606 
l0: 0.006343, l1: 0.006938, l2: 0.007084, l3: 0.006422, l4: 0.008556, l5: 0.008518, l6: 0.009050

[epoch: 128/100000, batch:   172/  187, ite: 12024] train loss: 0.058362, tar: 0.006595 
l0: 0.002923, l1: 0.003452, l2: 0.003336, l3: 0.002600, l4: 0.004420, l5: 0.004399, l6: 0.004817

[epoch: 128/100000, batch:   174/  187, ite: 12025] train loss: 0.057066, tar: 0.006448 
l0: 0.014262, l1: 0.015704, l2: 0.016185, l3: 0.016871, l4: 0.024022, l5: 0.017265, l6: 0.015080

[epoch: 128/100000, batch:   176/  187, ite: 12026] train loss: 0.059463, tar: 0.006749 
l0: 0.010180, l1: 0.011273, l2: 0.011642, l3: 0.010221, l4: 0.010140, l5: 0.009655, l6: 0.011394

[epoch: 128/100000, batch:   178/  187, ite: 12027] train loss: 0.060020, tar: 0.006876 
l0: 0.007473, l1: 0.007308, l2: 0.009517, l3: 0.009969, l4: 0.016481, l5: 0.013857, l6: 0.012603

[epoch: 128/100000, batch:   180/  187, ite: 12028] train loss: 0.060634, tar: 0.006897 
l0: 0.005195, l1: 0.004974, l2: 0.005775, l3: 0.005824, l4: 0.010977, l5: 0.011395, l6: 0.011498

[epoch: 128/100000, batch:   182/  187, ite: 12029] train loss: 0.060462, tar: 0.006839 
l0: 0.007946, l1: 0.008167, l2: 0.009200, l3: 0.008656, l4: 0.014251, l5: 0.014368, l6: 0.015793

[epoch: 128/100000, batch:   184/  187, ite: 12030] train loss: 0.061059, tar: 0.006875 
l0: 0.004936, l1: 0.006332, l2: 0.005422, l3: 0.004169, l4: 0.009234, l5: 0.005085, l6: 0.006411

[epoch: 128/100000, batch:   186/  187, ite: 12031] train loss: 0.060431, tar: 0.006813 
l0: 0.005253, l1: 0.005523, l2: 0.007594, l3: 0.006716, l4: 0.007996, l5: 0.005969, l6: 0.007244

[epoch: 128/100000, batch:   188/  187, ite: 12032] train loss: 0.059989, tar: 0.006764 
l0: 0.003017, l1: 0.003206, l2: 0.002853, l3: 0.004112, l4: 0.005193, l5: 0.004998, l6: 0.005743

[epoch: 129/100000, batch:     2/  187, ite: 12033] train loss: 0.059054, tar: 0.006651 
l0: 0.003305, l1: 0.003315, l2: 0.003778, l3: 0.003830, l4: 0.004846, l5: 0.005102, l6: 0.005737

[epoch: 129/100000, batch:     4/  187, ite: 12034] train loss: 0.058197, tar: 0.006552 
l0: 0.005297, l1: 0.005693, l2: 0.005924, l3: 0.006611, l4: 0.008331, l5: 0.007711, l6: 0.011476

[epoch: 129/100000, batch:     6/  187, ite: 12035] train loss: 0.057992, tar: 0.006516 
l0: 0.009211, l1: 0.008302, l2: 0.009830, l3: 0.012010, l4: 0.012742, l5: 0.014317, l6: 0.013211

[epoch: 129/100000, batch:     8/  187, ite: 12036] train loss: 0.058593, tar: 0.006591 
l0: 0.008514, l1: 0.008773, l2: 0.008246, l3: 0.009514, l4: 0.011485, l5: 0.011525, l6: 0.012153

[epoch: 129/100000, batch:    10/  187, ite: 12037] train loss: 0.058907, tar: 0.006643 
l0: 0.006373, l1: 0.007272, l2: 0.006130, l3: 0.006386, l4: 0.006910, l5: 0.006113, l6: 0.007376

[epoch: 129/100000, batch:    12/  187, ite: 12038] train loss: 0.058582, tar: 0.006636 
l0: 0.012523, l1: 0.013399, l2: 0.012593, l3: 0.014524, l4: 0.014173, l5: 0.012044, l6: 0.014651

[epoch: 129/100000, batch:    14/  187, ite: 12039] train loss: 0.059488, tar: 0.006787 
l0: 0.006866, l1: 0.007158, l2: 0.007759, l3: 0.007450, l4: 0.008948, l5: 0.008134, l6: 0.006722

[epoch: 129/100000, batch:    16/  187, ite: 12040] train loss: 0.059327, tar: 0.006789 
l0: 0.005056, l1: 0.005382, l2: 0.006694, l3: 0.007019, l4: 0.008898, l5: 0.007591, l6: 0.006546

[epoch: 129/100000, batch:    18/  187, ite: 12041] train loss: 0.059030, tar: 0.006747 
l0: 0.004095, l1: 0.003787, l2: 0.004638, l3: 0.005351, l4: 0.005484, l5: 0.007496, l6: 0.006295

[epoch: 129/100000, batch:    20/  187, ite: 12042] train loss: 0.058509, tar: 0.006684 
l0: 0.013316, l1: 0.012587, l2: 0.015470, l3: 0.015906, l4: 0.014419, l5: 0.015006, l6: 0.015578

[epoch: 129/100000, batch:    22/  187, ite: 12043] train loss: 0.059527, tar: 0.006838 
l0: 0.006959, l1: 0.006975, l2: 0.007008, l3: 0.007247, l4: 0.013170, l5: 0.012676, l6: 0.009979

[epoch: 129/100000, batch:    24/  187, ite: 12044] train loss: 0.059629, tar: 0.006841 
l0: 0.007964, l1: 0.008587, l2: 0.008299, l3: 0.008659, l4: 0.011554, l5: 0.011207, l6: 0.012393

[epoch: 129/100000, batch:    26/  187, ite: 12045] train loss: 0.059830, tar: 0.006866 
l0: 0.013550, l1: 0.013576, l2: 0.014288, l3: 0.013119, l4: 0.011776, l5: 0.014151, l6: 0.017358

[epoch: 129/100000, batch:    28/  187, ite: 12046] train loss: 0.060656, tar: 0.007011 
l0: 0.006615, l1: 0.006299, l2: 0.008004, l3: 0.008928, l4: 0.013514, l5: 0.011899, l6: 0.013439

[epoch: 129/100000, batch:    30/  187, ite: 12047] train loss: 0.060827, tar: 0.007002 
l0: 0.001910, l1: 0.002015, l2: 0.002000, l3: 0.002097, l4: 0.003966, l5: 0.003107, l6: 0.004427

[epoch: 129/100000, batch:    32/  187, ite: 12048] train loss: 0.059967, tar: 0.006896 
l0: 0.007473, l1: 0.007948, l2: 0.007438, l3: 0.009271, l4: 0.007711, l5: 0.007092, l6: 0.006796

[epoch: 129/100000, batch:    34/  187, ite: 12049] train loss: 0.059839, tar: 0.006908 
l0: 0.003836, l1: 0.004482, l2: 0.004342, l3: 0.004055, l4: 0.005543, l5: 0.004922, l6: 0.005883

[epoch: 129/100000, batch:    36/  187, ite: 12050] train loss: 0.059304, tar: 0.006847 
l0: 0.008614, l1: 0.009006, l2: 0.008335, l3: 0.009324, l4: 0.013420, l5: 0.011708, l6: 0.013354

[epoch: 129/100000, batch:    38/  187, ite: 12051] train loss: 0.059587, tar: 0.006881 
l0: 0.014957, l1: 0.015697, l2: 0.013322, l3: 0.014725, l4: 0.017507, l5: 0.016644, l6: 0.019614

[epoch: 129/100000, batch:    40/  187, ite: 12052] train loss: 0.060604, tar: 0.007037 
l0: 0.004571, l1: 0.004309, l2: 0.005876, l3: 0.006023, l4: 0.007356, l5: 0.007621, l6: 0.008138

[epoch: 129/100000, batch:    42/  187, ite: 12053] train loss: 0.060289, tar: 0.006990 
l0: 0.004974, l1: 0.004846, l2: 0.006472, l3: 0.006382, l4: 0.005674, l5: 0.006189, l6: 0.005268

[epoch: 129/100000, batch:    44/  187, ite: 12054] train loss: 0.059909, tar: 0.006953 
l0: 0.004272, l1: 0.004282, l2: 0.004467, l3: 0.004503, l4: 0.008950, l5: 0.007673, l6: 0.009663

[epoch: 129/100000, batch:    46/  187, ite: 12055] train loss: 0.059617, tar: 0.006904 
l0: 0.008485, l1: 0.008714, l2: 0.009391, l3: 0.009185, l4: 0.011747, l5: 0.013443, l6: 0.015272

[epoch: 129/100000, batch:    48/  187, ite: 12056] train loss: 0.059914, tar: 0.006932 
l0: 0.004643, l1: 0.004923, l2: 0.005265, l3: 0.004827, l4: 0.005485, l5: 0.005342, l6: 0.005429

[epoch: 129/100000, batch:    50/  187, ite: 12057] train loss: 0.059492, tar: 0.006892 
l0: 0.004128, l1: 0.004160, l2: 0.005223, l3: 0.005173, l4: 0.007361, l5: 0.008045, l6: 0.008295

[epoch: 129/100000, batch:    52/  187, ite: 12058] train loss: 0.059198, tar: 0.006844 
l0: 0.003437, l1: 0.003982, l2: 0.003536, l3: 0.003110, l4: 0.005978, l5: 0.005347, l6: 0.006964

[epoch: 129/100000, batch:    54/  187, ite: 12059] train loss: 0.058743, tar: 0.006787 
l0: 0.004222, l1: 0.004484, l2: 0.004388, l3: 0.004475, l4: 0.007911, l5: 0.006481, l6: 0.007356

[epoch: 129/100000, batch:    56/  187, ite: 12060] train loss: 0.058419, tar: 0.006744 
l0: 0.006605, l1: 0.006879, l2: 0.008072, l3: 0.007243, l4: 0.011170, l5: 0.010642, l6: 0.010091

[epoch: 129/100000, batch:    58/  187, ite: 12061] train loss: 0.058456, tar: 0.006742 
l0: 0.005532, l1: 0.006049, l2: 0.005783, l3: 0.006241, l4: 0.009057, l5: 0.009058, l6: 0.009539

[epoch: 129/100000, batch:    60/  187, ite: 12062] train loss: 0.058340, tar: 0.006722 
l0: 0.005071, l1: 0.005066, l2: 0.005622, l3: 0.005056, l4: 0.006359, l5: 0.005639, l6: 0.005616

[epoch: 129/100000, batch:    62/  187, ite: 12063] train loss: 0.058024, tar: 0.006696 
l0: 0.013174, l1: 0.011779, l2: 0.014780, l3: 0.016881, l4: 0.021707, l5: 0.020660, l6: 0.023558

[epoch: 129/100000, batch:    64/  187, ite: 12064] train loss: 0.059032, tar: 0.006797 
l0: 0.012155, l1: 0.012447, l2: 0.013883, l3: 0.013976, l4: 0.012063, l5: 0.012265, l6: 0.012775

[epoch: 129/100000, batch:    66/  187, ite: 12065] train loss: 0.059502, tar: 0.006880 
l0: 0.010754, l1: 0.010833, l2: 0.010597, l3: 0.010268, l4: 0.009628, l5: 0.010862, l6: 0.010388

[epoch: 129/100000, batch:    68/  187, ite: 12066] train loss: 0.059711, tar: 0.006938 
l0: 0.007880, l1: 0.007955, l2: 0.008228, l3: 0.008949, l4: 0.009697, l5: 0.008379, l6: 0.008551

[epoch: 129/100000, batch:    70/  187, ite: 12067] train loss: 0.059710, tar: 0.006952 
l0: 0.010845, l1: 0.011276, l2: 0.013239, l3: 0.011484, l4: 0.012464, l5: 0.011040, l6: 0.011076

[epoch: 129/100000, batch:    72/  187, ite: 12068] train loss: 0.060030, tar: 0.007010 
l0: 0.012215, l1: 0.011141, l2: 0.013713, l3: 0.014643, l4: 0.020614, l5: 0.020783, l6: 0.017725

[epoch: 129/100000, batch:    74/  187, ite: 12069] train loss: 0.060766, tar: 0.007085 
l0: 0.003626, l1: 0.003589, l2: 0.004748, l3: 0.005038, l4: 0.013090, l5: 0.013166, l6: 0.016544

[epoch: 129/100000, batch:    76/  187, ite: 12070] train loss: 0.060752, tar: 0.007036 
l0: 0.004353, l1: 0.004992, l2: 0.004816, l3: 0.004964, l4: 0.007245, l5: 0.006032, l6: 0.007416

[epoch: 129/100000, batch:    78/  187, ite: 12071] train loss: 0.060457, tar: 0.006998 
l0: 0.004042, l1: 0.004397, l2: 0.004467, l3: 0.004505, l4: 0.006809, l5: 0.005376, l6: 0.006158

[epoch: 129/100000, batch:    80/  187, ite: 12072] train loss: 0.060114, tar: 0.006957 
l0: 0.005008, l1: 0.005618, l2: 0.004893, l3: 0.004876, l4: 0.010736, l5: 0.007939, l6: 0.007966

[epoch: 129/100000, batch:    82/  187, ite: 12073] train loss: 0.059935, tar: 0.006930 
l0: 0.005511, l1: 0.006261, l2: 0.005540, l3: 0.006239, l4: 0.007513, l5: 0.006926, l6: 0.007467

[epoch: 129/100000, batch:    84/  187, ite: 12074] train loss: 0.059739, tar: 0.006911 
l0: 0.004489, l1: 0.005091, l2: 0.005242, l3: 0.004870, l4: 0.006178, l5: 0.005758, l6: 0.007222

[epoch: 129/100000, batch:    86/  187, ite: 12075] train loss: 0.059461, tar: 0.006879 
l0: 0.007596, l1: 0.008121, l2: 0.008546, l3: 0.008541, l4: 0.010664, l5: 0.010693, l6: 0.011515

[epoch: 129/100000, batch:    88/  187, ite: 12076] train loss: 0.059543, tar: 0.006888 
l0: 0.013078, l1: 0.013154, l2: 0.012616, l3: 0.012531, l4: 0.020873, l5: 0.021121, l6: 0.019910

[epoch: 129/100000, batch:    90/  187, ite: 12077] train loss: 0.060241, tar: 0.006968 
l0: 0.011622, l1: 0.010966, l2: 0.011536, l3: 0.012569, l4: 0.016884, l5: 0.016734, l6: 0.016480

[epoch: 129/100000, batch:    92/  187, ite: 12078] train loss: 0.060709, tar: 0.007028 
l0: 0.006966, l1: 0.007166, l2: 0.008144, l3: 0.007660, l4: 0.014889, l5: 0.011943, l6: 0.012946

[epoch: 129/100000, batch:    94/  187, ite: 12079] train loss: 0.060823, tar: 0.007027 
l0: 0.006509, l1: 0.006248, l2: 0.007061, l3: 0.007590, l4: 0.011560, l5: 0.011280, l6: 0.010546

[epoch: 129/100000, batch:    96/  187, ite: 12080] train loss: 0.060823, tar: 0.007021 
l0: 0.007110, l1: 0.006517, l2: 0.007165, l3: 0.007883, l4: 0.017722, l5: 0.014315, l6: 0.019167

[epoch: 129/100000, batch:    98/  187, ite: 12081] train loss: 0.061058, tar: 0.007022 
l0: 0.005575, l1: 0.005865, l2: 0.005887, l3: 0.006016, l4: 0.006912, l5: 0.006509, l6: 0.005702

[epoch: 129/100000, batch:   100/  187, ite: 12082] train loss: 0.060831, tar: 0.007004 
l0: 0.013140, l1: 0.012909, l2: 0.013238, l3: 0.014306, l4: 0.017603, l5: 0.015765, l6: 0.015893

[epoch: 129/100000, batch:   102/  187, ite: 12083] train loss: 0.061338, tar: 0.007078 
l0: 0.006841, l1: 0.007091, l2: 0.006713, l3: 0.006894, l4: 0.012299, l5: 0.011190, l6: 0.012289

[epoch: 129/100000, batch:   104/  187, ite: 12084] train loss: 0.061361, tar: 0.007075 
l0: 0.010131, l1: 0.010696, l2: 0.011811, l3: 0.012509, l4: 0.016778, l5: 0.014087, l6: 0.014264

[epoch: 129/100000, batch:   106/  187, ite: 12085] train loss: 0.061701, tar: 0.007111 
l0: 0.003684, l1: 0.003709, l2: 0.004265, l3: 0.004364, l4: 0.005648, l5: 0.005340, l6: 0.006802

[epoch: 129/100000, batch:   108/  187, ite: 12086] train loss: 0.061377, tar: 0.007071 
l0: 0.007247, l1: 0.007539, l2: 0.008146, l3: 0.009041, l4: 0.011617, l5: 0.009904, l6: 0.009774

[epoch: 129/100000, batch:   110/  187, ite: 12087] train loss: 0.061399, tar: 0.007073 
l0: 0.011102, l1: 0.011924, l2: 0.013798, l3: 0.012549, l4: 0.012437, l5: 0.012151, l6: 0.010880

[epoch: 129/100000, batch:   112/  187, ite: 12088] train loss: 0.061665, tar: 0.007119 
l0: 0.008621, l1: 0.008879, l2: 0.010180, l3: 0.009577, l4: 0.012286, l5: 0.011801, l6: 0.014736

[epoch: 129/100000, batch:   114/  187, ite: 12089] train loss: 0.061827, tar: 0.007136 
l0: 0.007985, l1: 0.008034, l2: 0.007813, l3: 0.007790, l4: 0.007642, l5: 0.008144, l6: 0.010739

[epoch: 129/100000, batch:   116/  187, ite: 12090] train loss: 0.061786, tar: 0.007146 
l0: 0.010913, l1: 0.011699, l2: 0.010581, l3: 0.011278, l4: 0.020618, l5: 0.017690, l6: 0.020719

[epoch: 129/100000, batch:   118/  187, ite: 12091] train loss: 0.062245, tar: 0.007187 
l0: 0.004322, l1: 0.004671, l2: 0.004959, l3: 0.004508, l4: 0.006792, l5: 0.005918, l6: 0.006405

[epoch: 129/100000, batch:   120/  187, ite: 12092] train loss: 0.061976, tar: 0.007156 
l0: 0.006950, l1: 0.008311, l2: 0.008003, l3: 0.006778, l4: 0.009064, l5: 0.007139, l6: 0.005488

[epoch: 129/100000, batch:   122/  187, ite: 12093] train loss: 0.061866, tar: 0.007154 
l0: 0.005465, l1: 0.005273, l2: 0.006696, l3: 0.007002, l4: 0.011284, l5: 0.011881, l6: 0.012548

[epoch: 129/100000, batch:   124/  187, ite: 12094] train loss: 0.061848, tar: 0.007136 
l0: 0.007456, l1: 0.009264, l2: 0.009439, l3: 0.008788, l4: 0.018499, l5: 0.011894, l6: 0.010108

[epoch: 129/100000, batch:   126/  187, ite: 12095] train loss: 0.061991, tar: 0.007139 
l0: 0.007701, l1: 0.008229, l2: 0.009104, l3: 0.009091, l4: 0.010689, l5: 0.008667, l6: 0.006985

[epoch: 129/100000, batch:   128/  187, ite: 12096] train loss: 0.061975, tar: 0.007145 
l0: 0.006267, l1: 0.006479, l2: 0.006336, l3: 0.006905, l4: 0.012449, l5: 0.010938, l6: 0.010392

[epoch: 129/100000, batch:   130/  187, ite: 12097] train loss: 0.061953, tar: 0.007136 
l0: 0.006649, l1: 0.006747, l2: 0.006988, l3: 0.006749, l4: 0.010985, l5: 0.010701, l6: 0.011410

[epoch: 129/100000, batch:   132/  187, ite: 12098] train loss: 0.061935, tar: 0.007131 
l0: 0.005528, l1: 0.005999, l2: 0.006251, l3: 0.005461, l4: 0.008597, l5: 0.007065, l6: 0.008861

[epoch: 129/100000, batch:   134/  187, ite: 12099] train loss: 0.061792, tar: 0.007115 
l0: 0.007563, l1: 0.007478, l2: 0.008359, l3: 0.007818, l4: 0.008535, l5: 0.008342, l6: 0.010260

[epoch: 129/100000, batch:   136/  187, ite: 12100] train loss: 0.061757, tar: 0.007119 
l0: 0.007643, l1: 0.007975, l2: 0.008501, l3: 0.008048, l4: 0.009860, l5: 0.009852, l6: 0.010945

[epoch: 129/100000, batch:   138/  187, ite: 12101] train loss: 0.061768, tar: 0.007124 
l0: 0.006988, l1: 0.006905, l2: 0.007363, l3: 0.007772, l4: 0.018913, l5: 0.017344, l6: 0.018343

[epoch: 129/100000, batch:   140/  187, ite: 12102] train loss: 0.061982, tar: 0.007123 
l0: 0.007622, l1: 0.008384, l2: 0.008527, l3: 0.008848, l4: 0.010941, l5: 0.009913, l6: 0.009726

[epoch: 129/100000, batch:   142/  187, ite: 12103] train loss: 0.062002, tar: 0.007128 
l0: 0.006201, l1: 0.006242, l2: 0.007666, l3: 0.006885, l4: 0.007830, l5: 0.008254, l6: 0.008378

[epoch: 129/100000, batch:   144/  187, ite: 12104] train loss: 0.061900, tar: 0.007119 
l0: 0.008537, l1: 0.010065, l2: 0.010573, l3: 0.010082, l4: 0.009008, l5: 0.007465, l6: 0.008337

[epoch: 129/100000, batch:   146/  187, ite: 12105] train loss: 0.061921, tar: 0.007132 
l0: 0.006376, l1: 0.006028, l2: 0.006732, l3: 0.007060, l4: 0.007985, l5: 0.010348, l6: 0.012399

[epoch: 129/100000, batch:   148/  187, ite: 12106] train loss: 0.061874, tar: 0.007125 
l0: 0.007198, l1: 0.007242, l2: 0.007726, l3: 0.008543, l4: 0.007315, l5: 0.007923, l6: 0.008691

[epoch: 129/100000, batch:   150/  187, ite: 12107] train loss: 0.061806, tar: 0.007126 
l0: 0.002588, l1: 0.003342, l2: 0.003363, l3: 0.002312, l4: 0.003166, l5: 0.002655, l6: 0.002633

[epoch: 129/100000, batch:   152/  187, ite: 12108] train loss: 0.061419, tar: 0.007084 
l0: 0.009756, l1: 0.009991, l2: 0.011335, l3: 0.011341, l4: 0.011955, l5: 0.012892, l6: 0.011084

[epoch: 129/100000, batch:   154/  187, ite: 12109] train loss: 0.061575, tar: 0.007108 
l0: 0.007688, l1: 0.006830, l2: 0.007565, l3: 0.010085, l4: 0.021242, l5: 0.018437, l6: 0.016896

[epoch: 129/100000, batch:   156/  187, ite: 12110] train loss: 0.061822, tar: 0.007114 
l0: 0.008694, l1: 0.007585, l2: 0.011241, l3: 0.014304, l4: 0.021164, l5: 0.016135, l6: 0.019041

[epoch: 129/100000, batch:   158/  187, ite: 12111] train loss: 0.062149, tar: 0.007128 
l0: 0.006602, l1: 0.006195, l2: 0.007302, l3: 0.008508, l4: 0.013834, l5: 0.012808, l6: 0.012252

[epoch: 129/100000, batch:   160/  187, ite: 12112] train loss: 0.062197, tar: 0.007123 
l0: 0.009408, l1: 0.010627, l2: 0.011823, l3: 0.011291, l4: 0.007609, l5: 0.007484, l6: 0.007762

[epoch: 129/100000, batch:   162/  187, ite: 12113] train loss: 0.062231, tar: 0.007144 
l0: 0.012443, l1: 0.009454, l2: 0.012619, l3: 0.014174, l4: 0.026493, l5: 0.031602, l6: 0.038613

[epoch: 129/100000, batch:   164/  187, ite: 12114] train loss: 0.062960, tar: 0.007190 
l0: 0.006127, l1: 0.006180, l2: 0.007930, l3: 0.007717, l4: 0.009478, l5: 0.008748, l6: 0.009181

[epoch: 129/100000, batch:   166/  187, ite: 12115] train loss: 0.062894, tar: 0.007181 
l0: 0.006208, l1: 0.005904, l2: 0.006242, l3: 0.008045, l4: 0.014013, l5: 0.011143, l6: 0.013300

[epoch: 129/100000, batch:   168/  187, ite: 12116] train loss: 0.062911, tar: 0.007172 
l0: 0.006797, l1: 0.006003, l2: 0.007152, l3: 0.009012, l4: 0.011144, l5: 0.012533, l6: 0.013756

[epoch: 129/100000, batch:   170/  187, ite: 12117] train loss: 0.062941, tar: 0.007169 
l0: 0.005493, l1: 0.005527, l2: 0.005934, l3: 0.006509, l4: 0.010667, l5: 0.009828, l6: 0.010824

[epoch: 129/100000, batch:   172/  187, ite: 12118] train loss: 0.062872, tar: 0.007155 
l0: 0.008125, l1: 0.008444, l2: 0.009700, l3: 0.009710, l4: 0.013941, l5: 0.010531, l6: 0.009512

[epoch: 129/100000, batch:   174/  187, ite: 12119] train loss: 0.062931, tar: 0.007163 
l0: 0.005154, l1: 0.005508, l2: 0.005424, l3: 0.006196, l4: 0.006606, l5: 0.006352, l6: 0.008384

[epoch: 129/100000, batch:   176/  187, ite: 12120] train loss: 0.062770, tar: 0.007146 
l0: 0.007965, l1: 0.008313, l2: 0.008076, l3: 0.009139, l4: 0.013803, l5: 0.012379, l6: 0.015208

[epoch: 129/100000, batch:   178/  187, ite: 12121] train loss: 0.062870, tar: 0.007153 
l0: 0.004286, l1: 0.004436, l2: 0.004175, l3: 0.005177, l4: 0.010371, l5: 0.010924, l6: 0.010498

[epoch: 129/100000, batch:   180/  187, ite: 12122] train loss: 0.062764, tar: 0.007130 
l0: 0.008199, l1: 0.008666, l2: 0.007859, l3: 0.009307, l4: 0.014737, l5: 0.010823, l6: 0.009760

[epoch: 129/100000, batch:   182/  187, ite: 12123] train loss: 0.062817, tar: 0.007138 
l0: 0.005411, l1: 0.005848, l2: 0.005096, l3: 0.004943, l4: 0.009462, l5: 0.008606, l6: 0.009644

[epoch: 129/100000, batch:   184/  187, ite: 12124] train loss: 0.062706, tar: 0.007124 
l0: 0.009050, l1: 0.007687, l2: 0.010393, l3: 0.011030, l4: 0.015720, l5: 0.019192, l6: 0.021343

[epoch: 129/100000, batch:   186/  187, ite: 12125] train loss: 0.062960, tar: 0.007140 
l0: 0.007159, l1: 0.007456, l2: 0.006011, l3: 0.005590, l4: 0.013729, l5: 0.011360, l6: 0.012920

[epoch: 129/100000, batch:   188/  187, ite: 12126] train loss: 0.062970, tar: 0.007140 
l0: 0.005521, l1: 0.005083, l2: 0.007984, l3: 0.008617, l4: 0.011253, l5: 0.011162, l6: 0.010082

[epoch: 130/100000, batch:     2/  187, ite: 12127] train loss: 0.062944, tar: 0.007127 
l0: 0.003579, l1: 0.003846, l2: 0.004357, l3: 0.004367, l4: 0.005385, l5: 0.006955, l6: 0.007666

[epoch: 130/100000, batch:     4/  187, ite: 12128] train loss: 0.062735, tar: 0.007099 
l0: 0.004874, l1: 0.004728, l2: 0.006250, l3: 0.005844, l4: 0.009724, l5: 0.008520, l6: 0.010046

[epoch: 130/100000, batch:     6/  187, ite: 12129] train loss: 0.062636, tar: 0.007082 
l0: 0.005207, l1: 0.005647, l2: 0.005035, l3: 0.005430, l4: 0.010442, l5: 0.008789, l6: 0.009018

[epoch: 130/100000, batch:     8/  187, ite: 12130] train loss: 0.062535, tar: 0.007068 
l0: 0.007679, l1: 0.007155, l2: 0.009429, l3: 0.010281, l4: 0.020311, l5: 0.019010, l6: 0.015056

[epoch: 130/100000, batch:    10/  187, ite: 12131] train loss: 0.062737, tar: 0.007072 
l0: 0.007374, l1: 0.007243, l2: 0.007612, l3: 0.008083, l4: 0.017332, l5: 0.019490, l6: 0.012871

[epoch: 130/100000, batch:    12/  187, ite: 12132] train loss: 0.062868, tar: 0.007075 
l0: 0.005063, l1: 0.004784, l2: 0.005792, l3: 0.006852, l4: 0.011980, l5: 0.012239, l6: 0.014260

[epoch: 130/100000, batch:    14/  187, ite: 12133] train loss: 0.062853, tar: 0.007060 
l0: 0.013082, l1: 0.014170, l2: 0.014833, l3: 0.013947, l4: 0.016263, l5: 0.015944, l6: 0.016189

[epoch: 130/100000, batch:    16/  187, ite: 12134] train loss: 0.063164, tar: 0.007105 
l0: 0.007540, l1: 0.007807, l2: 0.008550, l3: 0.008207, l4: 0.012249, l5: 0.011452, l6: 0.013302

[epoch: 130/100000, batch:    18/  187, ite: 12135] train loss: 0.063208, tar: 0.007108 
l0: 0.007665, l1: 0.008494, l2: 0.008544, l3: 0.009028, l4: 0.009136, l5: 0.006542, l6: 0.007149

[epoch: 130/100000, batch:    20/  187, ite: 12136] train loss: 0.063159, tar: 0.007112 
l0: 0.007197, l1: 0.006833, l2: 0.008820, l3: 0.008341, l4: 0.010346, l5: 0.010657, l6: 0.013124

[epoch: 130/100000, batch:    22/  187, ite: 12137] train loss: 0.063175, tar: 0.007113 
l0: 0.006458, l1: 0.006699, l2: 0.006474, l3: 0.006490, l4: 0.011685, l5: 0.011234, l6: 0.013550

[epoch: 130/100000, batch:    24/  187, ite: 12138] train loss: 0.063170, tar: 0.007108 
l0: 0.008149, l1: 0.008461, l2: 0.007713, l3: 0.008107, l4: 0.012575, l5: 0.011090, l6: 0.011117

[epoch: 130/100000, batch:    26/  187, ite: 12139] train loss: 0.063199, tar: 0.007115 
l0: 0.004428, l1: 0.004408, l2: 0.004668, l3: 0.005278, l4: 0.008904, l5: 0.007491, l6: 0.009122

[epoch: 130/100000, batch:    28/  187, ite: 12140] train loss: 0.063064, tar: 0.007096 
l0: 0.007842, l1: 0.008126, l2: 0.008157, l3: 0.008437, l4: 0.007691, l5: 0.007463, l6: 0.008299

[epoch: 130/100000, batch:    30/  187, ite: 12141] train loss: 0.063014, tar: 0.007101 
l0: 0.008398, l1: 0.009527, l2: 0.006261, l3: 0.006013, l4: 0.008711, l5: 0.010213, l6: 0.011620

[epoch: 130/100000, batch:    32/  187, ite: 12142] train loss: 0.062998, tar: 0.007110 
l0: 0.007281, l1: 0.007831, l2: 0.009542, l3: 0.008448, l4: 0.010233, l5: 0.010666, l6: 0.008554

[epoch: 130/100000, batch:    34/  187, ite: 12143] train loss: 0.062995, tar: 0.007112 
l0: 0.006423, l1: 0.006635, l2: 0.006936, l3: 0.007307, l4: 0.012596, l5: 0.012155, l6: 0.011850

[epoch: 130/100000, batch:    36/  187, ite: 12144] train loss: 0.063002, tar: 0.007107 
l0: 0.006035, l1: 0.008728, l2: 0.004414, l3: 0.005301, l4: 0.024333, l5: 0.017619, l6: 0.016088

[epoch: 130/100000, batch:    38/  187, ite: 12145] train loss: 0.063136, tar: 0.007100 
l0: 0.006219, l1: 0.005930, l2: 0.006539, l3: 0.007833, l4: 0.010351, l5: 0.012645, l6: 0.012296

[epoch: 130/100000, batch:    40/  187, ite: 12146] train loss: 0.063127, tar: 0.007093 
l0: 0.004147, l1: 0.004815, l2: 0.005185, l3: 0.005028, l4: 0.005417, l5: 0.004626, l6: 0.005722

[epoch: 130/100000, batch:    42/  187, ite: 12147] train loss: 0.062935, tar: 0.007073 
l0: 0.003792, l1: 0.003825, l2: 0.003780, l3: 0.005049, l4: 0.007056, l5: 0.006068, l6: 0.005267

[epoch: 130/100000, batch:    44/  187, ite: 12148] train loss: 0.062746, tar: 0.007051 
l0: 0.004908, l1: 0.005664, l2: 0.005383, l3: 0.005207, l4: 0.009448, l5: 0.008114, l6: 0.007931

[epoch: 130/100000, batch:    46/  187, ite: 12149] train loss: 0.062638, tar: 0.007037 
l0: 0.009187, l1: 0.009446, l2: 0.009418, l3: 0.009000, l4: 0.016673, l5: 0.012894, l6: 0.015779

[epoch: 130/100000, batch:    48/  187, ite: 12150] train loss: 0.062769, tar: 0.007051 
l0: 0.006209, l1: 0.006088, l2: 0.005967, l3: 0.006853, l4: 0.011760, l5: 0.010234, l6: 0.008752

[epoch: 130/100000, batch:    50/  187, ite: 12151] train loss: 0.062724, tar: 0.007046 
l0: 0.007528, l1: 0.008099, l2: 0.007640, l3: 0.008671, l4: 0.014342, l5: 0.013160, l6: 0.009705

[epoch: 130/100000, batch:    52/  187, ite: 12152] train loss: 0.062766, tar: 0.007049 
l0: 0.005840, l1: 0.005766, l2: 0.005739, l3: 0.006707, l4: 0.013425, l5: 0.011297, l6: 0.013149

[epoch: 130/100000, batch:    54/  187, ite: 12153] train loss: 0.062760, tar: 0.007041 
l0: 0.006266, l1: 0.007139, l2: 0.007862, l3: 0.008469, l4: 0.017564, l5: 0.011332, l6: 0.009646

[epoch: 130/100000, batch:    56/  187, ite: 12154] train loss: 0.062796, tar: 0.007036 
l0: 0.015590, l1: 0.013530, l2: 0.013709, l3: 0.019547, l4: 0.035854, l5: 0.037401, l6: 0.034570

[epoch: 130/100000, batch:    58/  187, ite: 12155] train loss: 0.063489, tar: 0.007091 
l0: 0.005495, l1: 0.006022, l2: 0.005618, l3: 0.005661, l4: 0.009202, l5: 0.007737, l6: 0.008690

[epoch: 130/100000, batch:    60/  187, ite: 12156] train loss: 0.063392, tar: 0.007081 
l0: 0.005135, l1: 0.005574, l2: 0.005615, l3: 0.006556, l4: 0.011356, l5: 0.012710, l6: 0.011628

[epoch: 130/100000, batch:    62/  187, ite: 12157] train loss: 0.063362, tar: 0.007068 
l0: 0.005224, l1: 0.005559, l2: 0.006318, l3: 0.005833, l4: 0.010284, l5: 0.008734, l6: 0.009459

[epoch: 130/100000, batch:    64/  187, ite: 12158] train loss: 0.063286, tar: 0.007057 
l0: 0.009460, l1: 0.009575, l2: 0.010658, l3: 0.010683, l4: 0.012446, l5: 0.013910, l6: 0.013244

[epoch: 130/100000, batch:    66/  187, ite: 12159] train loss: 0.063391, tar: 0.007072 
l0: 0.011638, l1: 0.012802, l2: 0.016540, l3: 0.013332, l4: 0.019372, l5: 0.013594, l6: 0.016027

[epoch: 130/100000, batch:    68/  187, ite: 12160] train loss: 0.063641, tar: 0.007100 
l0: 0.008277, l1: 0.008999, l2: 0.009223, l3: 0.008398, l4: 0.013132, l5: 0.012436, l6: 0.011348

[epoch: 130/100000, batch:    70/  187, ite: 12161] train loss: 0.063691, tar: 0.007108 
l0: 0.004655, l1: 0.005189, l2: 0.005942, l3: 0.005612, l4: 0.008727, l5: 0.005997, l6: 0.006050

[epoch: 130/100000, batch:    72/  187, ite: 12162] train loss: 0.063558, tar: 0.007093 
l0: 0.005556, l1: 0.005991, l2: 0.006676, l3: 0.007778, l4: 0.014020, l5: 0.009730, l6: 0.007516

[epoch: 130/100000, batch:    74/  187, ite: 12163] train loss: 0.063520, tar: 0.007083 
l0: 0.007081, l1: 0.005528, l2: 0.006250, l3: 0.007368, l4: 0.008302, l5: 0.011344, l6: 0.015316

[epoch: 130/100000, batch:    76/  187, ite: 12164] train loss: 0.063506, tar: 0.007083 
l0: 0.006214, l1: 0.005984, l2: 0.006712, l3: 0.007478, l4: 0.017809, l5: 0.012570, l6: 0.023485

[epoch: 130/100000, batch:    78/  187, ite: 12165] train loss: 0.063607, tar: 0.007078 
l0: 0.007051, l1: 0.007811, l2: 0.007480, l3: 0.006381, l4: 0.012062, l5: 0.010451, l6: 0.012348

[epoch: 130/100000, batch:    80/  187, ite: 12166] train loss: 0.063607, tar: 0.007078 
l0: 0.010535, l1: 0.011106, l2: 0.012825, l3: 0.012262, l4: 0.015327, l5: 0.015469, l6: 0.017175

[epoch: 130/100000, batch:    82/  187, ite: 12167] train loss: 0.063793, tar: 0.007098 
l0: 0.009292, l1: 0.009584, l2: 0.011729, l3: 0.012297, l4: 0.012617, l5: 0.011206, l6: 0.009277

[epoch: 130/100000, batch:    84/  187, ite: 12168] train loss: 0.063866, tar: 0.007111 
l0: 0.031940, l1: 0.036515, l2: 0.034009, l3: 0.023821, l4: 0.018899, l5: 0.017902, l6: 0.022405

[epoch: 130/100000, batch:    86/  187, ite: 12169] train loss: 0.064586, tar: 0.007258 
l0: 0.007293, l1: 0.007437, l2: 0.007305, l3: 0.007328, l4: 0.009878, l5: 0.009566, l6: 0.012253

[epoch: 130/100000, batch:    88/  187, ite: 12170] train loss: 0.064565, tar: 0.007259 
l0: 0.005081, l1: 0.005092, l2: 0.007173, l3: 0.008727, l4: 0.014439, l5: 0.012882, l6: 0.013250

[epoch: 130/100000, batch:    90/  187, ite: 12171] train loss: 0.064577, tar: 0.007246 
l0: 0.004413, l1: 0.004548, l2: 0.004747, l3: 0.005614, l4: 0.008847, l5: 0.007945, l6: 0.005482

[epoch: 130/100000, batch:    92/  187, ite: 12172] train loss: 0.064443, tar: 0.007229 
l0: 0.010726, l1: 0.010204, l2: 0.012313, l3: 0.013945, l4: 0.019079, l5: 0.015117, l6: 0.020755

[epoch: 130/100000, batch:    94/  187, ite: 12173] train loss: 0.064661, tar: 0.007250 
l0: 0.008292, l1: 0.007866, l2: 0.009825, l3: 0.008275, l4: 0.010175, l5: 0.009795, l6: 0.010942

[epoch: 130/100000, batch:    96/  187, ite: 12174] train loss: 0.064664, tar: 0.007256 
l0: 0.010007, l1: 0.009707, l2: 0.010013, l3: 0.010603, l4: 0.011225, l5: 0.011784, l6: 0.011734

[epoch: 130/100000, batch:    98/  187, ite: 12175] train loss: 0.064724, tar: 0.007271 
l0: 0.005267, l1: 0.005599, l2: 0.006785, l3: 0.005458, l4: 0.013021, l5: 0.012079, l6: 0.011769

[epoch: 130/100000, batch:   100/  187, ite: 12176] train loss: 0.064697, tar: 0.007260 
l0: 0.010004, l1: 0.009417, l2: 0.010775, l3: 0.011327, l4: 0.021727, l5: 0.018033, l6: 0.018011

[epoch: 130/100000, batch:   102/  187, ite: 12177] train loss: 0.064892, tar: 0.007275 
l0: 0.005275, l1: 0.005358, l2: 0.010004, l3: 0.007090, l4: 0.010482, l5: 0.009395, l6: 0.009172

[epoch: 130/100000, batch:   104/  187, ite: 12178] train loss: 0.064847, tar: 0.007264 
l0: 0.010155, l1: 0.010253, l2: 0.011798, l3: 0.012638, l4: 0.015237, l5: 0.014548, l6: 0.016622

[epoch: 130/100000, batch:   106/  187, ite: 12179] train loss: 0.064994, tar: 0.007280 
l0: 0.008032, l1: 0.009636, l2: 0.008719, l3: 0.008855, l4: 0.011759, l5: 0.010551, l6: 0.012241

[epoch: 130/100000, batch:   108/  187, ite: 12180] train loss: 0.065021, tar: 0.007285 
l0: 0.004631, l1: 0.004946, l2: 0.005330, l3: 0.005127, l4: 0.009336, l5: 0.011249, l6: 0.011982

[epoch: 130/100000, batch:   110/  187, ite: 12181] train loss: 0.064952, tar: 0.007270 
l0: 0.015693, l1: 0.016655, l2: 0.016883, l3: 0.016994, l4: 0.024783, l5: 0.024869, l6: 0.021214

[epoch: 130/100000, batch:   112/  187, ite: 12182] train loss: 0.065348, tar: 0.007316 
l0: 0.006720, l1: 0.006795, l2: 0.009430, l3: 0.009053, l4: 0.008116, l5: 0.006914, l6: 0.007698

[epoch: 130/100000, batch:   114/  187, ite: 12183] train loss: 0.065290, tar: 0.007313 
l0: 0.025391, l1: 0.030601, l2: 0.033179, l3: 0.027604, l4: 0.015726, l5: 0.012728, l6: 0.011910

[epoch: 130/100000, batch:   116/  187, ite: 12184] train loss: 0.065790, tar: 0.007411 
l0: 0.007591, l1: 0.007942, l2: 0.007278, l3: 0.009640, l4: 0.009594, l5: 0.009173, l6: 0.011698

[epoch: 130/100000, batch:   118/  187, ite: 12185] train loss: 0.065774, tar: 0.007412 
l0: 0.008042, l1: 0.008452, l2: 0.009057, l3: 0.007554, l4: 0.013866, l5: 0.013252, l6: 0.016952

[epoch: 130/100000, batch:   120/  187, ite: 12186] train loss: 0.065835, tar: 0.007416 
l0: 0.010091, l1: 0.009679, l2: 0.009476, l3: 0.011143, l4: 0.015902, l5: 0.016157, l6: 0.015532

[epoch: 130/100000, batch:   122/  187, ite: 12187] train loss: 0.065954, tar: 0.007430 
l0: 0.009602, l1: 0.008919, l2: 0.011482, l3: 0.011979, l4: 0.013969, l5: 0.014163, l6: 0.016539

[epoch: 130/100000, batch:   124/  187, ite: 12188] train loss: 0.066064, tar: 0.007441 
l0: 0.010483, l1: 0.010175, l2: 0.013492, l3: 0.015642, l4: 0.008744, l5: 0.008732, l6: 0.011720

[epoch: 130/100000, batch:   126/  187, ite: 12189] train loss: 0.066132, tar: 0.007457 
l0: 0.008409, l1: 0.008596, l2: 0.009818, l3: 0.009783, l4: 0.011895, l5: 0.011491, l6: 0.012324

[epoch: 130/100000, batch:   128/  187, ite: 12190] train loss: 0.066165, tar: 0.007462 
l0: 0.008818, l1: 0.009594, l2: 0.009122, l3: 0.011022, l4: 0.012273, l5: 0.009003, l6: 0.012412

[epoch: 130/100000, batch:   130/  187, ite: 12191] train loss: 0.066197, tar: 0.007470 
l0: 0.005971, l1: 0.007350, l2: 0.006517, l3: 0.006554, l4: 0.008694, l5: 0.007607, l6: 0.007448

[epoch: 130/100000, batch:   132/  187, ite: 12192] train loss: 0.066113, tar: 0.007462 
l0: 0.004635, l1: 0.004914, l2: 0.006045, l3: 0.005851, l4: 0.013006, l5: 0.010810, l6: 0.011721

[epoch: 130/100000, batch:   134/  187, ite: 12193] train loss: 0.066066, tar: 0.007447 
l0: 0.005578, l1: 0.005660, l2: 0.006550, l3: 0.005704, l4: 0.005525, l5: 0.005974, l6: 0.008466

[epoch: 130/100000, batch:   136/  187, ite: 12194] train loss: 0.065949, tar: 0.007437 
l0: 0.019668, l1: 0.016455, l2: 0.014349, l3: 0.021394, l4: 0.039509, l5: 0.037271, l6: 0.047820

[epoch: 130/100000, batch:   138/  187, ite: 12195] train loss: 0.066618, tar: 0.007500 
l0: 0.010949, l1: 0.011082, l2: 0.013177, l3: 0.014746, l4: 0.017539, l5: 0.013379, l6: 0.013610

[epoch: 130/100000, batch:   140/  187, ite: 12196] train loss: 0.066761, tar: 0.007518 
l0: 0.009484, l1: 0.012249, l2: 0.011164, l3: 0.010155, l4: 0.013726, l5: 0.011498, l6: 0.011817

[epoch: 130/100000, batch:   142/  187, ite: 12197] train loss: 0.066828, tar: 0.007528 
l0: 0.007166, l1: 0.007368, l2: 0.008980, l3: 0.007423, l4: 0.009769, l5: 0.010134, l6: 0.011430

[epoch: 130/100000, batch:   144/  187, ite: 12198] train loss: 0.066805, tar: 0.007526 
l0: 0.006826, l1: 0.006972, l2: 0.008023, l3: 0.008086, l4: 0.016815, l5: 0.014754, l6: 0.017000

[epoch: 130/100000, batch:   146/  187, ite: 12199] train loss: 0.066864, tar: 0.007522 
l0: 0.007717, l1: 0.009112, l2: 0.006504, l3: 0.010843, l4: 0.009895, l5: 0.009309, l6: 0.007347

[epoch: 130/100000, batch:   148/  187, ite: 12200] train loss: 0.066833, tar: 0.007523 
l0: 0.009793, l1: 0.008782, l2: 0.009216, l3: 0.011027, l4: 0.019337, l5: 0.019807, l6: 0.020619

[epoch: 130/100000, batch:   150/  187, ite: 12201] train loss: 0.066991, tar: 0.007535 
l0: 0.005223, l1: 0.005887, l2: 0.004706, l3: 0.006604, l4: 0.014906, l5: 0.013048, l6: 0.009243

[epoch: 130/100000, batch:   152/  187, ite: 12202] train loss: 0.066955, tar: 0.007523 
l0: 0.006992, l1: 0.006467, l2: 0.007170, l3: 0.008891, l4: 0.015413, l5: 0.014129, l6: 0.014983

[epoch: 130/100000, batch:   154/  187, ite: 12203] train loss: 0.066990, tar: 0.007521 
l0: 0.007559, l1: 0.008159, l2: 0.007525, l3: 0.006555, l4: 0.008010, l5: 0.007378, l6: 0.007119

[epoch: 130/100000, batch:   156/  187, ite: 12204] train loss: 0.066918, tar: 0.007521 
l0: 0.010360, l1: 0.010391, l2: 0.010581, l3: 0.011237, l4: 0.020385, l5: 0.021347, l6: 0.021807

[epoch: 130/100000, batch:   158/  187, ite: 12205] train loss: 0.067109, tar: 0.007535 
l0: 0.008830, l1: 0.008807, l2: 0.010267, l3: 0.009923, l4: 0.014356, l5: 0.015046, l6: 0.010859

[epoch: 130/100000, batch:   160/  187, ite: 12206] train loss: 0.067162, tar: 0.007541 
l0: 0.015441, l1: 0.016107, l2: 0.018359, l3: 0.018496, l4: 0.021896, l5: 0.017288, l6: 0.018436

[epoch: 130/100000, batch:   162/  187, ite: 12207] train loss: 0.067446, tar: 0.007579 
l0: 0.009273, l1: 0.008245, l2: 0.009996, l3: 0.011089, l4: 0.017345, l5: 0.021209, l6: 0.023878

[epoch: 130/100000, batch:   164/  187, ite: 12208] train loss: 0.067608, tar: 0.007587 
l0: 0.011247, l1: 0.010719, l2: 0.015100, l3: 0.014412, l4: 0.019548, l5: 0.020348, l6: 0.021633

[epoch: 130/100000, batch:   166/  187, ite: 12209] train loss: 0.067825, tar: 0.007605 
l0: 0.007008, l1: 0.007640, l2: 0.007674, l3: 0.007689, l4: 0.018147, l5: 0.018265, l6: 0.016109

[epoch: 130/100000, batch:   168/  187, ite: 12210] train loss: 0.067895, tar: 0.007602 
l0: 0.010244, l1: 0.010705, l2: 0.011266, l3: 0.010135, l4: 0.014642, l5: 0.014561, l6: 0.018920

[epoch: 130/100000, batch:   170/  187, ite: 12211] train loss: 0.068002, tar: 0.007614 
l0: 0.007641, l1: 0.008457, l2: 0.010628, l3: 0.008728, l4: 0.003900, l5: 0.006314, l6: 0.003901

[epoch: 130/100000, batch:   172/  187, ite: 12212] train loss: 0.067915, tar: 0.007615 
l0: 0.006080, l1: 0.005935, l2: 0.006266, l3: 0.005590, l4: 0.014933, l5: 0.013012, l6: 0.014135

[epoch: 130/100000, batch:   174/  187, ite: 12213] train loss: 0.067906, tar: 0.007607 
l0: 0.010044, l1: 0.010576, l2: 0.008770, l3: 0.009953, l4: 0.016100, l5: 0.016627, l6: 0.025432

[epoch: 130/100000, batch:   176/  187, ite: 12214] train loss: 0.068044, tar: 0.007619 
l0: 0.014672, l1: 0.015767, l2: 0.013029, l3: 0.014982, l4: 0.018982, l5: 0.019572, l6: 0.017748

[epoch: 130/100000, batch:   178/  187, ite: 12215] train loss: 0.068262, tar: 0.007652 
l0: 0.009001, l1: 0.009533, l2: 0.008398, l3: 0.008530, l4: 0.013315, l5: 0.010085, l6: 0.014102

[epoch: 130/100000, batch:   180/  187, ite: 12216] train loss: 0.068283, tar: 0.007658 
l0: 0.008143, l1: 0.007780, l2: 0.007507, l3: 0.008280, l4: 0.018508, l5: 0.016731, l6: 0.019528

[epoch: 130/100000, batch:   182/  187, ite: 12217] train loss: 0.068367, tar: 0.007660 
l0: 0.009665, l1: 0.010016, l2: 0.008904, l3: 0.009241, l4: 0.014596, l5: 0.014330, l6: 0.014660

[epoch: 130/100000, batch:   184/  187, ite: 12218] train loss: 0.068427, tar: 0.007669 
l0: 0.003189, l1: 0.003287, l2: 0.007513, l3: 0.006395, l4: 0.018337, l5: 0.012226, l6: 0.006808

[epoch: 130/100000, batch:   186/  187, ite: 12219] train loss: 0.068378, tar: 0.007649 
l0: 0.006278, l1: 0.005536, l2: 0.007073, l3: 0.009946, l4: 0.017209, l5: 0.017404, l6: 0.017028

[epoch: 130/100000, batch:   188/  187, ite: 12220] train loss: 0.068433, tar: 0.007643 
l0: 0.012743, l1: 0.011844, l2: 0.013513, l3: 0.013746, l4: 0.021721, l5: 0.023493, l6: 0.030739

[epoch: 131/100000, batch:     2/  187, ite: 12221] train loss: 0.068702, tar: 0.007666 
l0: 0.008208, l1: 0.008078, l2: 0.009200, l3: 0.009533, l4: 0.010821, l5: 0.010955, l6: 0.013119

[epoch: 131/100000, batch:     4/  187, ite: 12222] train loss: 0.068707, tar: 0.007668 
l0: 0.004696, l1: 0.004412, l2: 0.005546, l3: 0.007489, l4: 0.014159, l5: 0.014258, l6: 0.017646

[epoch: 131/100000, batch:     6/  187, ite: 12223] train loss: 0.068705, tar: 0.007655 
l0: 0.006852, l1: 0.007370, l2: 0.007102, l3: 0.007252, l4: 0.010312, l5: 0.008749, l6: 0.010892

[epoch: 131/100000, batch:     8/  187, ite: 12224] train loss: 0.068660, tar: 0.007651 
l0: 0.005041, l1: 0.004766, l2: 0.004450, l3: 0.004941, l4: 0.007151, l5: 0.007611, l6: 0.010478

[epoch: 131/100000, batch:    10/  187, ite: 12225] train loss: 0.068552, tar: 0.007640 
l0: 0.011058, l1: 0.010972, l2: 0.011497, l3: 0.014068, l4: 0.024996, l5: 0.021713, l6: 0.023123

[epoch: 131/100000, batch:    12/  187, ite: 12226] train loss: 0.068768, tar: 0.007655 
l0: 0.006742, l1: 0.006837, l2: 0.006258, l3: 0.007614, l4: 0.011007, l5: 0.010028, l6: 0.011895

[epoch: 131/100000, batch:    14/  187, ite: 12227] train loss: 0.068731, tar: 0.007651 
l0: 0.010605, l1: 0.009129, l2: 0.010802, l3: 0.014070, l4: 0.033371, l5: 0.032899, l6: 0.023786

[epoch: 131/100000, batch:    16/  187, ite: 12228] train loss: 0.069021, tar: 0.007664 
l0: 0.007292, l1: 0.007169, l2: 0.007501, l3: 0.007151, l4: 0.009865, l5: 0.010131, l6: 0.011503

[epoch: 131/100000, batch:    18/  187, ite: 12229] train loss: 0.068984, tar: 0.007662 
l0: 0.007463, l1: 0.008274, l2: 0.009512, l3: 0.007732, l4: 0.011539, l5: 0.009929, l6: 0.008368

[epoch: 131/100000, batch:    20/  187, ite: 12230] train loss: 0.068957, tar: 0.007661 
l0: 0.003832, l1: 0.004391, l2: 0.005715, l3: 0.006626, l4: 0.007119, l5: 0.006070, l6: 0.008257

[epoch: 131/100000, batch:    22/  187, ite: 12231] train loss: 0.068840, tar: 0.007645 
l0: 0.009095, l1: 0.009368, l2: 0.008168, l3: 0.009762, l4: 0.019925, l5: 0.018992, l6: 0.012523

[epoch: 131/100000, batch:    24/  187, ite: 12232] train loss: 0.068922, tar: 0.007651 
l0: 0.013047, l1: 0.014143, l2: 0.013743, l3: 0.012075, l4: 0.019571, l5: 0.017342, l6: 0.016972

[epoch: 131/100000, batch:    26/  187, ite: 12233] train loss: 0.069085, tar: 0.007674 
l0: 0.014594, l1: 0.015204, l2: 0.012645, l3: 0.011566, l4: 0.027687, l5: 0.025636, l6: 0.028097

[epoch: 131/100000, batch:    28/  187, ite: 12234] train loss: 0.069369, tar: 0.007704 
l0: 0.009710, l1: 0.010481, l2: 0.010083, l3: 0.010149, l4: 0.010048, l5: 0.008893, l6: 0.009309

[epoch: 131/100000, batch:    30/  187, ite: 12235] train loss: 0.069366, tar: 0.007712 
l0: 0.014240, l1: 0.013823, l2: 0.015189, l3: 0.014827, l4: 0.017687, l5: 0.017712, l6: 0.019687

[epoch: 131/100000, batch:    32/  187, ite: 12236] train loss: 0.069551, tar: 0.007740 
l0: 0.003918, l1: 0.004302, l2: 0.004727, l3: 0.004388, l4: 0.006394, l5: 0.006999, l6: 0.008678

[epoch: 131/100000, batch:    34/  187, ite: 12237] train loss: 0.069424, tar: 0.007724 
l0: 0.007947, l1: 0.007788, l2: 0.009838, l3: 0.010653, l4: 0.019159, l5: 0.016465, l6: 0.016246

[epoch: 131/100000, batch:    36/  187, ite: 12238] train loss: 0.069503, tar: 0.007725 
l0: 0.009896, l1: 0.009236, l2: 0.009302, l3: 0.010651, l4: 0.020500, l5: 0.019000, l6: 0.022972

[epoch: 131/100000, batch:    38/  187, ite: 12239] train loss: 0.069637, tar: 0.007734 
l0: 0.009395, l1: 0.009976, l2: 0.010993, l3: 0.010654, l4: 0.020314, l5: 0.017078, l6: 0.014825

[epoch: 131/100000, batch:    40/  187, ite: 12240] train loss: 0.069735, tar: 0.007741 
l0: 0.002604, l1: 0.003106, l2: 0.003852, l3: 0.004248, l4: 0.009911, l5: 0.007626, l6: 0.008867

[epoch: 131/100000, batch:    42/  187, ite: 12241] train loss: 0.069613, tar: 0.007719 
l0: 0.019759, l1: 0.025450, l2: 0.017869, l3: 0.011555, l4: 0.009018, l5: 0.009475, l6: 0.013714

[epoch: 131/100000, batch:    44/  187, ite: 12242] train loss: 0.069766, tar: 0.007769 
l0: 0.009066, l1: 0.010141, l2: 0.009012, l3: 0.008546, l4: 0.012919, l5: 0.013929, l6: 0.011729

[epoch: 131/100000, batch:    46/  187, ite: 12243] train loss: 0.069789, tar: 0.007774 
l0: 0.010844, l1: 0.012185, l2: 0.011939, l3: 0.011289, l4: 0.015492, l5: 0.014785, l6: 0.014264

[epoch: 131/100000, batch:    48/  187, ite: 12244] train loss: 0.069875, tar: 0.007787 
l0: 0.006452, l1: 0.006552, l2: 0.006797, l3: 0.007161, l4: 0.011240, l5: 0.010859, l6: 0.011052

[epoch: 131/100000, batch:    50/  187, ite: 12245] train loss: 0.069836, tar: 0.007781 
l0: 0.008327, l1: 0.009499, l2: 0.010337, l3: 0.010187, l4: 0.012493, l5: 0.010144, l6: 0.012593

[epoch: 131/100000, batch:    52/  187, ite: 12246] train loss: 0.069851, tar: 0.007784 
l0: 0.004321, l1: 0.006073, l2: 0.004084, l3: 0.005671, l4: 0.005696, l5: 0.004630, l6: 0.007842

[epoch: 131/100000, batch:    54/  187, ite: 12247] train loss: 0.069723, tar: 0.007770 
l0: 0.009813, l1: 0.009468, l2: 0.009754, l3: 0.011295, l4: 0.029915, l5: 0.025394, l6: 0.027089

[epoch: 131/100000, batch:    56/  187, ite: 12248] train loss: 0.069937, tar: 0.007778 
l0: 0.018541, l1: 0.026856, l2: 0.019187, l3: 0.009397, l4: 0.010110, l5: 0.008516, l6: 0.008549

[epoch: 131/100000, batch:    58/  187, ite: 12249] train loss: 0.070062, tar: 0.007821 
l0: 0.010573, l1: 0.011068, l2: 0.011138, l3: 0.011145, l4: 0.016847, l5: 0.015136, l6: 0.017135

[epoch: 131/100000, batch:    60/  187, ite: 12250] train loss: 0.070154, tar: 0.007832 
l0: 0.007420, l1: 0.007558, l2: 0.008257, l3: 0.007583, l4: 0.010168, l5: 0.009683, l6: 0.010577

[epoch: 131/100000, batch:    62/  187, ite: 12251] train loss: 0.070119, tar: 0.007831 
l0: 0.007005, l1: 0.006737, l2: 0.007057, l3: 0.008213, l4: 0.011599, l5: 0.011498, l6: 0.010804

[epoch: 131/100000, batch:    64/  187, ite: 12252] train loss: 0.070090, tar: 0.007827 
l0: 0.007032, l1: 0.007390, l2: 0.008218, l3: 0.007801, l4: 0.016472, l5: 0.015630, l6: 0.012185

[epoch: 131/100000, batch:    66/  187, ite: 12253] train loss: 0.070108, tar: 0.007824 
l0: 0.010736, l1: 0.010387, l2: 0.012153, l3: 0.012064, l4: 0.017943, l5: 0.018667, l6: 0.021882

[epoch: 131/100000, batch:    68/  187, ite: 12254] train loss: 0.070241, tar: 0.007836 
l0: 0.007494, l1: 0.009302, l2: 0.009701, l3: 0.008674, l4: 0.009525, l5: 0.008590, l6: 0.009274

[epoch: 131/100000, batch:    70/  187, ite: 12255] train loss: 0.070211, tar: 0.007834 
l0: 0.012326, l1: 0.012664, l2: 0.014234, l3: 0.015749, l4: 0.017872, l5: 0.015309, l6: 0.012974

[epoch: 131/100000, batch:    72/  187, ite: 12256] train loss: 0.070332, tar: 0.007852 
l0: 0.008237, l1: 0.009122, l2: 0.009765, l3: 0.009247, l4: 0.013018, l5: 0.011836, l6: 0.014488

[epoch: 131/100000, batch:    74/  187, ite: 12257] train loss: 0.070353, tar: 0.007853 
l0: 0.005470, l1: 0.005122, l2: 0.007845, l3: 0.009571, l4: 0.015558, l5: 0.011443, l6: 0.015337

[epoch: 131/100000, batch:    76/  187, ite: 12258] train loss: 0.070353, tar: 0.007844 
l0: 0.005659, l1: 0.006207, l2: 0.007129, l3: 0.006843, l4: 0.007239, l5: 0.006755, l6: 0.008470

[epoch: 131/100000, batch:    78/  187, ite: 12259] train loss: 0.070268, tar: 0.007836 
l0: 0.005411, l1: 0.005550, l2: 0.005995, l3: 0.005547, l4: 0.008383, l5: 0.006745, l6: 0.011895

[epoch: 131/100000, batch:    80/  187, ite: 12260] train loss: 0.070188, tar: 0.007826 
l0: 0.012072, l1: 0.012859, l2: 0.014069, l3: 0.013709, l4: 0.013066, l5: 0.013694, l6: 0.013689

[epoch: 131/100000, batch:    82/  187, ite: 12261] train loss: 0.070276, tar: 0.007843 
l0: 0.012400, l1: 0.014823, l2: 0.014556, l3: 0.013592, l4: 0.012589, l5: 0.010844, l6: 0.011803

[epoch: 131/100000, batch:    84/  187, ite: 12262] train loss: 0.070353, tar: 0.007860 
l0: 0.015579, l1: 0.015875, l2: 0.020286, l3: 0.019826, l4: 0.018381, l5: 0.017587, l6: 0.019263

[epoch: 131/100000, batch:    86/  187, ite: 12263] train loss: 0.070568, tar: 0.007889 
l0: 0.011966, l1: 0.013247, l2: 0.013725, l3: 0.012177, l4: 0.018262, l5: 0.015580, l6: 0.012968

[epoch: 131/100000, batch:    88/  187, ite: 12264] train loss: 0.070672, tar: 0.007905 
l0: 0.012604, l1: 0.013581, l2: 0.013483, l3: 0.012599, l4: 0.015959, l5: 0.015349, l6: 0.015486

[epoch: 131/100000, batch:    90/  187, ite: 12265] train loss: 0.070779, tar: 0.007922 
l0: 0.006127, l1: 0.006315, l2: 0.006559, l3: 0.007074, l4: 0.009816, l5: 0.007988, l6: 0.008376

[epoch: 131/100000, batch:    92/  187, ite: 12266] train loss: 0.070709, tar: 0.007916 
l0: 0.005330, l1: 0.005601, l2: 0.006072, l3: 0.006380, l4: 0.020636, l5: 0.012152, l6: 0.013571

[epoch: 131/100000, batch:    94/  187, ite: 12267] train loss: 0.070706, tar: 0.007906 
l0: 0.004742, l1: 0.005321, l2: 0.009098, l3: 0.006487, l4: 0.011863, l5: 0.010132, l6: 0.009258

[epoch: 131/100000, batch:    96/  187, ite: 12268] train loss: 0.070654, tar: 0.007894 
l0: 0.017286, l1: 0.016178, l2: 0.018847, l3: 0.019752, l4: 0.026250, l5: 0.024058, l6: 0.027364

[epoch: 131/100000, batch:    98/  187, ite: 12269] train loss: 0.070948, tar: 0.007929 
l0: 0.012190, l1: 0.012374, l2: 0.013571, l3: 0.013949, l4: 0.013326, l5: 0.014491, l6: 0.012166

[epoch: 131/100000, batch:   100/  187, ite: 12270] train loss: 0.071026, tar: 0.007945 
l0: 0.011239, l1: 0.010880, l2: 0.012879, l3: 0.013207, l4: 0.016937, l5: 0.017173, l6: 0.015839

[epoch: 131/100000, batch:   102/  187, ite: 12271] train loss: 0.071126, tar: 0.007957 
l0: 0.005238, l1: 0.005403, l2: 0.006847, l3: 0.006358, l4: 0.009745, l5: 0.009209, l6: 0.007496

[epoch: 131/100000, batch:   104/  187, ite: 12272] train loss: 0.071050, tar: 0.007947 
l0: 0.007834, l1: 0.008376, l2: 0.008274, l3: 0.007845, l4: 0.012310, l5: 0.011713, l6: 0.013923

[epoch: 131/100000, batch:   106/  187, ite: 12273] train loss: 0.071047, tar: 0.007947 
l0: 0.016374, l1: 0.016008, l2: 0.019392, l3: 0.019770, l4: 0.010525, l5: 0.013734, l6: 0.012597

[epoch: 131/100000, batch:   108/  187, ite: 12274] train loss: 0.071183, tar: 0.007977 
l0: 0.009301, l1: 0.010015, l2: 0.010589, l3: 0.011048, l4: 0.019410, l5: 0.014707, l6: 0.011885

[epoch: 131/100000, batch:   110/  187, ite: 12275] train loss: 0.071241, tar: 0.007982 
l0: 0.004606, l1: 0.005218, l2: 0.004563, l3: 0.004823, l4: 0.006187, l5: 0.005748, l6: 0.006401

[epoch: 131/100000, batch:   112/  187, ite: 12276] train loss: 0.071118, tar: 0.007970 
l0: 0.010438, l1: 0.010173, l2: 0.010474, l3: 0.012306, l4: 0.016394, l5: 0.015681, l6: 0.017139

[epoch: 131/100000, batch:   114/  187, ite: 12277] train loss: 0.071196, tar: 0.007979 
l0: 0.013796, l1: 0.015317, l2: 0.014244, l3: 0.014789, l4: 0.016848, l5: 0.013059, l6: 0.015603

[epoch: 131/100000, batch:   116/  187, ite: 12278] train loss: 0.071313, tar: 0.008000 
l0: 0.011605, l1: 0.014317, l2: 0.015706, l3: 0.013363, l4: 0.011703, l5: 0.009131, l6: 0.009440

[epoch: 131/100000, batch:   118/  187, ite: 12279] train loss: 0.071363, tar: 0.008013 
l0: 0.007348, l1: 0.007822, l2: 0.009749, l3: 0.009018, l4: 0.011819, l5: 0.011607, l6: 0.013106

[epoch: 131/100000, batch:   120/  187, ite: 12280] train loss: 0.071360, tar: 0.008010 
l0: 0.007598, l1: 0.009137, l2: 0.008546, l3: 0.007262, l4: 0.009308, l5: 0.007318, l6: 0.008287

[epoch: 131/100000, batch:   122/  187, ite: 12281] train loss: 0.071310, tar: 0.008009 
l0: 0.005817, l1: 0.007020, l2: 0.007369, l3: 0.005405, l4: 0.009309, l5: 0.009109, l6: 0.008564

[epoch: 131/100000, batch:   124/  187, ite: 12282] train loss: 0.071244, tar: 0.008001 
l0: 0.004935, l1: 0.005010, l2: 0.005373, l3: 0.005597, l4: 0.007524, l5: 0.006522, l6: 0.009753

[epoch: 131/100000, batch:   126/  187, ite: 12283] train loss: 0.071150, tar: 0.007990 
l0: 0.005444, l1: 0.005517, l2: 0.004478, l3: 0.004599, l4: 0.013260, l5: 0.010928, l6: 0.012163

[epoch: 131/100000, batch:   128/  187, ite: 12284] train loss: 0.071098, tar: 0.007981 
l0: 0.008387, l1: 0.008706, l2: 0.009163, l3: 0.010689, l4: 0.013195, l5: 0.012048, l6: 0.013388

[epoch: 131/100000, batch:   130/  187, ite: 12285] train loss: 0.071114, tar: 0.007983 
l0: 0.005316, l1: 0.006289, l2: 0.005626, l3: 0.005911, l4: 0.008275, l5: 0.008794, l6: 0.005693

[epoch: 131/100000, batch:   132/  187, ite: 12286] train loss: 0.071026, tar: 0.007973 
l0: 0.007842, l1: 0.008292, l2: 0.008064, l3: 0.009731, l4: 0.020564, l5: 0.016813, l6: 0.015897

[epoch: 131/100000, batch:   134/  187, ite: 12287] train loss: 0.071082, tar: 0.007973 
l0: 0.008380, l1: 0.008714, l2: 0.010099, l3: 0.010538, l4: 0.013432, l5: 0.012848, l6: 0.010586

[epoch: 131/100000, batch:   136/  187, ite: 12288] train loss: 0.071094, tar: 0.007974 
l0: 0.010958, l1: 0.011285, l2: 0.012757, l3: 0.012997, l4: 0.014417, l5: 0.014923, l6: 0.014558

[epoch: 131/100000, batch:   138/  187, ite: 12289] train loss: 0.071166, tar: 0.007985 
l0: 0.020950, l1: 0.018452, l2: 0.020540, l3: 0.023841, l4: 0.022628, l5: 0.025615, l6: 0.029822

[epoch: 131/100000, batch:   140/  187, ite: 12290] train loss: 0.071479, tar: 0.008029 
l0: 0.009844, l1: 0.008130, l2: 0.009206, l3: 0.010799, l4: 0.027057, l5: 0.028627, l6: 0.035821

[epoch: 131/100000, batch:   142/  187, ite: 12291] train loss: 0.071678, tar: 0.008036 
l0: 0.008400, l1: 0.008230, l2: 0.012253, l3: 0.011242, l4: 0.011149, l5: 0.011351, l6: 0.011246

[epoch: 131/100000, batch:   144/  187, ite: 12292] train loss: 0.071686, tar: 0.008037 
l0: 0.009182, l1: 0.009379, l2: 0.008813, l3: 0.009638, l4: 0.012793, l5: 0.012137, l6: 0.013051

[epoch: 131/100000, batch:   146/  187, ite: 12293] train loss: 0.071697, tar: 0.008041 
l0: 0.006657, l1: 0.006012, l2: 0.008057, l3: 0.007212, l4: 0.018694, l5: 0.014748, l6: 0.020477

[epoch: 131/100000, batch:   148/  187, ite: 12294] train loss: 0.071732, tar: 0.008036 
l0: 0.005414, l1: 0.005967, l2: 0.005988, l3: 0.005807, l4: 0.010205, l5: 0.009366, l6: 0.010324

[epoch: 131/100000, batch:   150/  187, ite: 12295] train loss: 0.071668, tar: 0.008027 
l0: 0.007838, l1: 0.008469, l2: 0.008801, l3: 0.009273, l4: 0.010917, l5: 0.010506, l6: 0.010613

[epoch: 131/100000, batch:   152/  187, ite: 12296] train loss: 0.071651, tar: 0.008027 
l0: 0.005143, l1: 0.004977, l2: 0.005097, l3: 0.005532, l4: 0.008597, l5: 0.008492, l6: 0.010679

[epoch: 131/100000, batch:   154/  187, ite: 12297] train loss: 0.071573, tar: 0.008017 
l0: 0.007444, l1: 0.008436, l2: 0.009455, l3: 0.008008, l4: 0.012524, l5: 0.011986, l6: 0.012375

[epoch: 131/100000, batch:   156/  187, ite: 12298] train loss: 0.071568, tar: 0.008015 
l0: 0.006774, l1: 0.006551, l2: 0.007312, l3: 0.008757, l4: 0.014297, l5: 0.015199, l6: 0.013512

[epoch: 131/100000, batch:   158/  187, ite: 12299] train loss: 0.071571, tar: 0.008011 
l0: 0.007229, l1: 0.007747, l2: 0.008835, l3: 0.009233, l4: 0.015166, l5: 0.012435, l6: 0.015177

[epoch: 131/100000, batch:   160/  187, ite: 12300] train loss: 0.071585, tar: 0.008008 
l0: 0.007051, l1: 0.007200, l2: 0.009320, l3: 0.009048, l4: 0.012088, l5: 0.011838, l6: 0.014100

[epoch: 131/100000, batch:   162/  187, ite: 12301] train loss: 0.071582, tar: 0.008005 
l0: 0.004202, l1: 0.004251, l2: 0.005004, l3: 0.005832, l4: 0.007681, l5: 0.006149, l6: 0.008161

[epoch: 131/100000, batch:   164/  187, ite: 12302] train loss: 0.071482, tar: 0.007992 
l0: 0.005799, l1: 0.005883, l2: 0.006545, l3: 0.007008, l4: 0.008003, l5: 0.008267, l6: 0.009282

[epoch: 131/100000, batch:   166/  187, ite: 12303] train loss: 0.071413, tar: 0.007985 
l0: 0.008483, l1: 0.008750, l2: 0.007284, l3: 0.009463, l4: 0.011657, l5: 0.011677, l6: 0.013349

[epoch: 131/100000, batch:   168/  187, ite: 12304] train loss: 0.071411, tar: 0.007987 
l0: 0.006777, l1: 0.007385, l2: 0.007549, l3: 0.007155, l4: 0.008696, l5: 0.008611, l6: 0.009410

[epoch: 131/100000, batch:   170/  187, ite: 12305] train loss: 0.071359, tar: 0.007983 
l0: 0.010020, l1: 0.009244, l2: 0.011379, l3: 0.011600, l4: 0.020605, l5: 0.021921, l6: 0.018004

[epoch: 131/100000, batch:   172/  187, ite: 12306] train loss: 0.071462, tar: 0.007989 
l0: 0.008039, l1: 0.007729, l2: 0.009204, l3: 0.012026, l4: 0.008890, l5: 0.009250, l6: 0.008979

[epoch: 131/100000, batch:   174/  187, ite: 12307] train loss: 0.071438, tar: 0.007990 
l0: 0.007126, l1: 0.007947, l2: 0.008037, l3: 0.007676, l4: 0.013923, l5: 0.011318, l6: 0.009497

[epoch: 131/100000, batch:   176/  187, ite: 12308] train loss: 0.071418, tar: 0.007987 
l0: 0.005847, l1: 0.005591, l2: 0.007178, l3: 0.008733, l4: 0.011133, l5: 0.009727, l6: 0.011535

[epoch: 131/100000, batch:   178/  187, ite: 12309] train loss: 0.071381, tar: 0.007980 
l0: 0.008829, l1: 0.008369, l2: 0.008817, l3: 0.008868, l4: 0.018138, l5: 0.016006, l6: 0.019079

[epoch: 131/100000, batch:   180/  187, ite: 12310] train loss: 0.071435, tar: 0.007983 
l0: 0.005177, l1: 0.005654, l2: 0.005629, l3: 0.005314, l4: 0.009691, l5: 0.008619, l6: 0.008450

[epoch: 131/100000, batch:   182/  187, ite: 12311] train loss: 0.071361, tar: 0.007974 
l0: 0.008040, l1: 0.007894, l2: 0.008339, l3: 0.009176, l4: 0.021093, l5: 0.020260, l6: 0.022290

[epoch: 131/100000, batch:   184/  187, ite: 12312] train loss: 0.071444, tar: 0.007974 
l0: 0.007341, l1: 0.008170, l2: 0.009522, l3: 0.007785, l4: 0.013130, l5: 0.012145, l6: 0.011777

[epoch: 131/100000, batch:   186/  187, ite: 12313] train loss: 0.071438, tar: 0.007972 
l0: 0.005230, l1: 0.005021, l2: 0.005451, l3: 0.005543, l4: 0.013809, l5: 0.016203, l6: 0.011133

[epoch: 131/100000, batch:   188/  187, ite: 12314] train loss: 0.071410, tar: 0.007963 
l0: 0.010812, l1: 0.011105, l2: 0.011393, l3: 0.011091, l4: 0.015794, l5: 0.014649, l6: 0.016769

[epoch: 132/100000, batch:     2/  187, ite: 12315] train loss: 0.071474, tar: 0.007972 
l0: 0.008202, l1: 0.009060, l2: 0.011851, l3: 0.010539, l4: 0.011557, l5: 0.010225, l6: 0.009687

[epoch: 132/100000, batch:     4/  187, ite: 12316] train loss: 0.071473, tar: 0.007973 
l0: 0.009870, l1: 0.011193, l2: 0.010812, l3: 0.009329, l4: 0.010054, l5: 0.009500, l6: 0.008499

[epoch: 132/100000, batch:     6/  187, ite: 12317] train loss: 0.071466, tar: 0.007979 
l0: 0.008265, l1: 0.008150, l2: 0.007965, l3: 0.008715, l4: 0.015750, l5: 0.016449, l6: 0.014963

[epoch: 132/100000, batch:     8/  187, ite: 12318] train loss: 0.071493, tar: 0.007980 
l0: 0.008862, l1: 0.009721, l2: 0.009551, l3: 0.010917, l4: 0.012669, l5: 0.012216, l6: 0.013810

[epoch: 132/100000, batch:    10/  187, ite: 12319] train loss: 0.071513, tar: 0.007983 
l0: 0.002394, l1: 0.003150, l2: 0.002497, l3: 0.003209, l4: 0.005478, l5: 0.004622, l6: 0.003577

[epoch: 132/100000, batch:    12/  187, ite: 12320] train loss: 0.071367, tar: 0.007965 
l0: 0.005888, l1: 0.006377, l2: 0.007833, l3: 0.007436, l4: 0.011170, l5: 0.011026, l6: 0.011838

[epoch: 132/100000, batch:    14/  187, ite: 12321] train loss: 0.071337, tar: 0.007959 
l0: 0.007530, l1: 0.006549, l2: 0.010720, l3: 0.011877, l4: 0.017868, l5: 0.014918, l6: 0.019778

[epoch: 132/100000, batch:    16/  187, ite: 12322] train loss: 0.071392, tar: 0.007957 
l0: 0.007597, l1: 0.008045, l2: 0.007198, l3: 0.007746, l4: 0.012352, l5: 0.011271, l6: 0.010235

[epoch: 132/100000, batch:    18/  187, ite: 12323] train loss: 0.071371, tar: 0.007956 
l0: 0.006128, l1: 0.006469, l2: 0.005981, l3: 0.006255, l4: 0.008423, l5: 0.008866, l6: 0.007401

[epoch: 132/100000, batch:    20/  187, ite: 12324] train loss: 0.071303, tar: 0.007951 
l0: 0.005545, l1: 0.005903, l2: 0.006082, l3: 0.006121, l4: 0.011930, l5: 0.010614, l6: 0.011364

[epoch: 132/100000, batch:    22/  187, ite: 12325] train loss: 0.071261, tar: 0.007943 
l0: 0.005000, l1: 0.005673, l2: 0.005988, l3: 0.006224, l4: 0.009159, l5: 0.008289, l6: 0.009869

[epoch: 132/100000, batch:    24/  187, ite: 12326] train loss: 0.071197, tar: 0.007934 
l0: 0.005552, l1: 0.005524, l2: 0.006164, l3: 0.008122, l4: 0.011485, l5: 0.010990, l6: 0.012572

[epoch: 132/100000, batch:    26/  187, ite: 12327] train loss: 0.071164, tar: 0.007927 
l0: 0.007694, l1: 0.007235, l2: 0.008542, l3: 0.010193, l4: 0.021252, l5: 0.019201, l6: 0.015280

[epoch: 132/100000, batch:    28/  187, ite: 12328] train loss: 0.071219, tar: 0.007926 
l0: 0.004137, l1: 0.004492, l2: 0.003634, l3: 0.004172, l4: 0.005582, l5: 0.004822, l6: 0.004111

[epoch: 132/100000, batch:    30/  187, ite: 12329] train loss: 0.071097, tar: 0.007915 
l0: 0.004926, l1: 0.004570, l2: 0.005122, l3: 0.005040, l4: 0.012732, l5: 0.014749, l6: 0.015830

[epoch: 132/100000, batch:    32/  187, ite: 12330] train loss: 0.071072, tar: 0.007906 
l0: 0.004320, l1: 0.004714, l2: 0.004539, l3: 0.005210, l4: 0.006905, l5: 0.006878, l6: 0.006437

[epoch: 132/100000, batch:    34/  187, ite: 12331] train loss: 0.070975, tar: 0.007895 
l0: 0.007604, l1: 0.007419, l2: 0.009137, l3: 0.009535, l4: 0.014741, l5: 0.014710, l6: 0.014245

[epoch: 132/100000, batch:    36/  187, ite: 12332] train loss: 0.070995, tar: 0.007894 
l0: 0.005498, l1: 0.005310, l2: 0.006361, l3: 0.007628, l4: 0.008086, l5: 0.007036, l6: 0.007401

[epoch: 132/100000, batch:    38/  187, ite: 12333] train loss: 0.070924, tar: 0.007887 
l0: 0.003843, l1: 0.003581, l2: 0.003694, l3: 0.005016, l4: 0.007685, l5: 0.008281, l6: 0.009625

[epoch: 132/100000, batch:    40/  187, ite: 12334] train loss: 0.070836, tar: 0.007875 
l0: 0.010385, l1: 0.011748, l2: 0.011698, l3: 0.012768, l4: 0.019452, l5: 0.013620, l6: 0.013887

[epoch: 132/100000, batch:    42/  187, ite: 12335] train loss: 0.070904, tar: 0.007882 
l0: 0.005847, l1: 0.007029, l2: 0.005376, l3: 0.004322, l4: 0.005758, l5: 0.005982, l6: 0.011167

[epoch: 132/100000, batch:    44/  187, ite: 12336] train loss: 0.070828, tar: 0.007876 
l0: 0.007165, l1: 0.007499, l2: 0.008569, l3: 0.007788, l4: 0.014789, l5: 0.011847, l6: 0.013734

[epoch: 132/100000, batch:    46/  187, ite: 12337] train loss: 0.070830, tar: 0.007874 
l0: 0.002935, l1: 0.003649, l2: 0.003496, l3: 0.002968, l4: 0.005363, l5: 0.003951, l6: 0.003762

[epoch: 132/100000, batch:    48/  187, ite: 12338] train loss: 0.070698, tar: 0.007859 
l0: 0.006956, l1: 0.007126, l2: 0.007495, l3: 0.008522, l4: 0.013002, l5: 0.011421, l6: 0.010953

[epoch: 132/100000, batch:    50/  187, ite: 12339] train loss: 0.070682, tar: 0.007857 
l0: 0.002186, l1: 0.002144, l2: 0.005063, l3: 0.004510, l4: 0.004823, l5: 0.004642, l6: 0.011732

[epoch: 132/100000, batch:    52/  187, ite: 12340] train loss: 0.070578, tar: 0.007840 
l0: 0.008558, l1: 0.008635, l2: 0.008477, l3: 0.009950, l4: 0.010380, l5: 0.010881, l6: 0.011656

[epoch: 132/100000, batch:    54/  187, ite: 12341] train loss: 0.070572, tar: 0.007842 
l0: 0.006655, l1: 0.006108, l2: 0.006678, l3: 0.008585, l4: 0.012533, l5: 0.011872, l6: 0.014594

[epoch: 132/100000, batch:    56/  187, ite: 12342] train loss: 0.070561, tar: 0.007839 
l0: 0.002576, l1: 0.003000, l2: 0.003474, l3: 0.002837, l4: 0.009050, l5: 0.008261, l6: 0.006489

[epoch: 132/100000, batch:    58/  187, ite: 12343] train loss: 0.070460, tar: 0.007823 
l0: 0.008140, l1: 0.008444, l2: 0.008639, l3: 0.010031, l4: 0.018971, l5: 0.016146, l6: 0.018003

[epoch: 132/100000, batch:    60/  187, ite: 12344] train loss: 0.070512, tar: 0.007824 
l0: 0.016063, l1: 0.014673, l2: 0.014982, l3: 0.017957, l4: 0.029612, l5: 0.028418, l6: 0.032352

[epoch: 132/100000, batch:    62/  187, ite: 12345] train loss: 0.070754, tar: 0.007848 
l0: 0.007802, l1: 0.011666, l2: 0.009523, l3: 0.007567, l4: 0.005944, l5: 0.003977, l6: 0.004803

[epoch: 132/100000, batch:    64/  187, ite: 12346] train loss: 0.070698, tar: 0.007848 
l0: 0.010105, l1: 0.009754, l2: 0.010288, l3: 0.012722, l4: 0.013844, l5: 0.015185, l6: 0.015070

[epoch: 132/100000, batch:    66/  187, ite: 12347] train loss: 0.070744, tar: 0.007854 
l0: 0.008955, l1: 0.009522, l2: 0.009491, l3: 0.010943, l4: 0.008901, l5: 0.008184, l6: 0.009429

[epoch: 132/100000, batch:    68/  187, ite: 12348] train loss: 0.070729, tar: 0.007858 
l0: 0.005595, l1: 0.006253, l2: 0.005433, l3: 0.005520, l4: 0.008105, l5: 0.006163, l6: 0.007146

[epoch: 132/100000, batch:    70/  187, ite: 12349] train loss: 0.070653, tar: 0.007851 
l0: 0.008181, l1: 0.008804, l2: 0.009178, l3: 0.010219, l4: 0.011443, l5: 0.010138, l6: 0.011435

[epoch: 132/100000, batch:    72/  187, ite: 12350] train loss: 0.070650, tar: 0.007852 
l0: 0.003826, l1: 0.003923, l2: 0.004146, l3: 0.004410, l4: 0.007146, l5: 0.006516, l6: 0.007242

[epoch: 132/100000, batch:    74/  187, ite: 12351] train loss: 0.070554, tar: 0.007840 
l0: 0.007768, l1: 0.008466, l2: 0.009748, l3: 0.010382, l4: 0.011911, l5: 0.011094, l6: 0.013441

[epoch: 132/100000, batch:    76/  187, ite: 12352] train loss: 0.070561, tar: 0.007840 
l0: 0.008214, l1: 0.008905, l2: 0.013151, l3: 0.010506, l4: 0.008978, l5: 0.009326, l6: 0.011980

[epoch: 132/100000, batch:    78/  187, ite: 12353] train loss: 0.070562, tar: 0.007841 
l0: 0.006285, l1: 0.006706, l2: 0.007232, l3: 0.007491, l4: 0.011354, l5: 0.009786, l6: 0.009746

[epoch: 132/100000, batch:    80/  187, ite: 12354] train loss: 0.070528, tar: 0.007837 
l0: 0.006515, l1: 0.006977, l2: 0.006795, l3: 0.007556, l4: 0.008966, l5: 0.007737, l6: 0.010028

[epoch: 132/100000, batch:    82/  187, ite: 12355] train loss: 0.070483, tar: 0.007833 
l0: 0.006675, l1: 0.008521, l2: 0.006561, l3: 0.005775, l4: 0.007234, l5: 0.007064, l6: 0.008073

[epoch: 132/100000, batch:    84/  187, ite: 12356] train loss: 0.070426, tar: 0.007830 
l0: 0.007939, l1: 0.009908, l2: 0.008725, l3: 0.007131, l4: 0.007409, l5: 0.006908, l6: 0.006697

[epoch: 132/100000, batch:    86/  187, ite: 12357] train loss: 0.070382, tar: 0.007830 
l0: 0.007281, l1: 0.007543, l2: 0.009949, l3: 0.008944, l4: 0.010079, l5: 0.009827, l6: 0.009722

[epoch: 132/100000, batch:    88/  187, ite: 12358] train loss: 0.070362, tar: 0.007829 
l0: 0.005053, l1: 0.005006, l2: 0.005155, l3: 0.005185, l4: 0.006778, l5: 0.007909, l6: 0.007254

[epoch: 132/100000, batch:    90/  187, ite: 12359] train loss: 0.070284, tar: 0.007821 
l0: 0.004373, l1: 0.004312, l2: 0.004976, l3: 0.004886, l4: 0.004463, l5: 0.004608, l6: 0.004706

[epoch: 132/100000, batch:    92/  187, ite: 12360] train loss: 0.070178, tar: 0.007811 
l0: 0.005713, l1: 0.005871, l2: 0.006677, l3: 0.006681, l4: 0.012936, l5: 0.011052, l6: 0.011219

[epoch: 132/100000, batch:    94/  187, ite: 12361] train loss: 0.070151, tar: 0.007806 
l0: 0.006091, l1: 0.006096, l2: 0.007022, l3: 0.007275, l4: 0.013057, l5: 0.012012, l6: 0.012775

[epoch: 132/100000, batch:    96/  187, ite: 12362] train loss: 0.070135, tar: 0.007801 
l0: 0.004162, l1: 0.004197, l2: 0.004480, l3: 0.004297, l4: 0.007952, l5: 0.007390, l6: 0.006414

[epoch: 132/100000, batch:    98/  187, ite: 12363] train loss: 0.070048, tar: 0.007791 
l0: 0.009089, l1: 0.014632, l2: 0.008986, l3: 0.006714, l4: 0.004124, l5: 0.003748, l6: 0.007741

[epoch: 132/100000, batch:   100/  187, ite: 12364] train loss: 0.070007, tar: 0.007794 
l0: 0.003942, l1: 0.004478, l2: 0.005714, l3: 0.003636, l4: 0.005021, l5: 0.005700, l6: 0.005157

[epoch: 132/100000, batch:   102/  187, ite: 12365] train loss: 0.069908, tar: 0.007784 
l0: 0.006032, l1: 0.006171, l2: 0.005845, l3: 0.006155, l4: 0.009178, l5: 0.010263, l6: 0.011584

[epoch: 132/100000, batch:   104/  187, ite: 12366] train loss: 0.069868, tar: 0.007779 
l0: 0.003215, l1: 0.003695, l2: 0.003197, l3: 0.003713, l4: 0.006259, l5: 0.004476, l6: 0.004361

[epoch: 132/100000, batch:   106/  187, ite: 12367] train loss: 0.069756, tar: 0.007767 
l0: 0.009871, l1: 0.009371, l2: 0.010379, l3: 0.010517, l4: 0.009506, l5: 0.010094, l6: 0.014459

[epoch: 132/100000, batch:   108/  187, ite: 12368] train loss: 0.069768, tar: 0.007772 
l0: 0.012665, l1: 0.013208, l2: 0.013465, l3: 0.013581, l4: 0.021968, l5: 0.020607, l6: 0.016523

[epoch: 132/100000, batch:   110/  187, ite: 12369] train loss: 0.069882, tar: 0.007786 
l0: 0.008305, l1: 0.008125, l2: 0.008700, l3: 0.008801, l4: 0.010130, l5: 0.010762, l6: 0.015691

[epoch: 132/100000, batch:   112/  187, ite: 12370] train loss: 0.069884, tar: 0.007787 
l0: 0.004747, l1: 0.004407, l2: 0.004647, l3: 0.006086, l4: 0.009606, l5: 0.008881, l6: 0.011410

[epoch: 132/100000, batch:   114/  187, ite: 12371] train loss: 0.069830, tar: 0.007779 
l0: 0.003641, l1: 0.003671, l2: 0.003563, l3: 0.003477, l4: 0.006081, l5: 0.005211, l6: 0.005518

[epoch: 132/100000, batch:   116/  187, ite: 12372] train loss: 0.069726, tar: 0.007768 
l0: 0.006797, l1: 0.006934, l2: 0.007090, l3: 0.007232, l4: 0.013019, l5: 0.011306, l6: 0.012431

[epoch: 132/100000, batch:   118/  187, ite: 12373] train loss: 0.069713, tar: 0.007765 
l0: 0.005211, l1: 0.005385, l2: 0.006156, l3: 0.006104, l4: 0.008605, l5: 0.008970, l6: 0.008699

[epoch: 132/100000, batch:   120/  187, ite: 12374] train loss: 0.069658, tar: 0.007758 
l0: 0.008060, l1: 0.008548, l2: 0.009396, l3: 0.008668, l4: 0.010266, l5: 0.011828, l6: 0.012401

[epoch: 132/100000, batch:   122/  187, ite: 12375] train loss: 0.069657, tar: 0.007759 
l0: 0.002995, l1: 0.003438, l2: 0.003369, l3: 0.003569, l4: 0.005552, l5: 0.004858, l6: 0.006679

[epoch: 132/100000, batch:   124/  187, ite: 12376] train loss: 0.069552, tar: 0.007746 
l0: 0.008710, l1: 0.009599, l2: 0.009463, l3: 0.009227, l4: 0.012723, l5: 0.011314, l6: 0.010580

[epoch: 132/100000, batch:   126/  187, ite: 12377] train loss: 0.069558, tar: 0.007749 
l0: 0.007578, l1: 0.006901, l2: 0.008895, l3: 0.008850, l4: 0.011663, l5: 0.014073, l6: 0.016812

[epoch: 132/100000, batch:   128/  187, ite: 12378] train loss: 0.069572, tar: 0.007749 
l0: 0.005855, l1: 0.006311, l2: 0.005943, l3: 0.006230, l4: 0.008539, l5: 0.008372, l6: 0.009117

[epoch: 132/100000, batch:   130/  187, ite: 12379] train loss: 0.069521, tar: 0.007744 
l0: 0.013238, l1: 0.012936, l2: 0.014848, l3: 0.015145, l4: 0.016569, l5: 0.014530, l6: 0.017505

[epoch: 132/100000, batch:   132/  187, ite: 12380] train loss: 0.069614, tar: 0.007758 
l0: 0.006690, l1: 0.007134, l2: 0.007843, l3: 0.007463, l4: 0.009314, l5: 0.008313, l6: 0.010515

[epoch: 132/100000, batch:   134/  187, ite: 12381] train loss: 0.069581, tar: 0.007755 
l0: 0.003381, l1: 0.002960, l2: 0.004050, l3: 0.003308, l4: 0.006971, l5: 0.007839, l6: 0.010891

[epoch: 132/100000, batch:   136/  187, ite: 12382] train loss: 0.069502, tar: 0.007744 
l0: 0.003315, l1: 0.003563, l2: 0.003701, l3: 0.004490, l4: 0.006080, l5: 0.004793, l6: 0.005195

[epoch: 132/100000, batch:   138/  187, ite: 12383] train loss: 0.069402, tar: 0.007732 
l0: 0.002868, l1: 0.003490, l2: 0.003263, l3: 0.002993, l4: 0.006591, l5: 0.006389, l6: 0.005603

[epoch: 132/100000, batch:   140/  187, ite: 12384] train loss: 0.069303, tar: 0.007719 
l0: 0.009029, l1: 0.008985, l2: 0.009503, l3: 0.010143, l4: 0.015547, l5: 0.014947, l6: 0.014757

[epoch: 132/100000, batch:   142/  187, ite: 12385] train loss: 0.069338, tar: 0.007723 
l0: 0.006331, l1: 0.006378, l2: 0.006950, l3: 0.007384, l4: 0.009539, l5: 0.008682, l6: 0.009937

[epoch: 132/100000, batch:   144/  187, ite: 12386] train loss: 0.069301, tar: 0.007719 
l0: 0.010353, l1: 0.011510, l2: 0.011595, l3: 0.010237, l4: 0.017967, l5: 0.016465, l6: 0.017415

[epoch: 132/100000, batch:   146/  187, ite: 12387] train loss: 0.069369, tar: 0.007726 
l0: 0.006226, l1: 0.005887, l2: 0.006478, l3: 0.007002, l4: 0.015610, l5: 0.016048, l6: 0.015188

[epoch: 132/100000, batch:   148/  187, ite: 12388] train loss: 0.069377, tar: 0.007722 
l0: 0.008356, l1: 0.009298, l2: 0.008041, l3: 0.008814, l4: 0.009707, l5: 0.008960, l6: 0.009997

[epoch: 132/100000, batch:   150/  187, ite: 12389] train loss: 0.069361, tar: 0.007724 
l0: 0.003952, l1: 0.004716, l2: 0.005008, l3: 0.004577, l4: 0.004082, l5: 0.003620, l6: 0.003779

[epoch: 132/100000, batch:   152/  187, ite: 12390] train loss: 0.069259, tar: 0.007714 
l0: 0.005851, l1: 0.006047, l2: 0.006620, l3: 0.006319, l4: 0.011838, l5: 0.011830, l6: 0.015920

[epoch: 132/100000, batch:   154/  187, ite: 12391] train loss: 0.069247, tar: 0.007709 
l0: 0.006114, l1: 0.005788, l2: 0.006157, l3: 0.007760, l4: 0.014742, l5: 0.014517, l6: 0.013035

[epoch: 132/100000, batch:   156/  187, ite: 12392] train loss: 0.069244, tar: 0.007705 
l0: 0.005103, l1: 0.005212, l2: 0.005379, l3: 0.005736, l4: 0.007255, l5: 0.006432, l6: 0.008469

[epoch: 132/100000, batch:   158/  187, ite: 12393] train loss: 0.069179, tar: 0.007699 
l0: 0.009059, l1: 0.009909, l2: 0.007512, l3: 0.009844, l4: 0.012590, l5: 0.011854, l6: 0.010835

[epoch: 132/100000, batch:   160/  187, ite: 12394] train loss: 0.069185, tar: 0.007702 
l0: 0.004813, l1: 0.005604, l2: 0.005052, l3: 0.004757, l4: 0.007207, l5: 0.005330, l6: 0.005875

[epoch: 132/100000, batch:   162/  187, ite: 12395] train loss: 0.069108, tar: 0.007695 
l0: 0.007300, l1: 0.007619, l2: 0.007203, l3: 0.007445, l4: 0.010853, l5: 0.008820, l6: 0.010118

[epoch: 132/100000, batch:   164/  187, ite: 12396] train loss: 0.069083, tar: 0.007694 
l0: 0.004455, l1: 0.004276, l2: 0.005293, l3: 0.004844, l4: 0.009535, l5: 0.011317, l6: 0.011727

[epoch: 132/100000, batch:   166/  187, ite: 12397] train loss: 0.069039, tar: 0.007686 
l0: 0.006691, l1: 0.006554, l2: 0.007174, l3: 0.007008, l4: 0.009014, l5: 0.010143, l6: 0.009520

[epoch: 132/100000, batch:   168/  187, ite: 12398] train loss: 0.069006, tar: 0.007683 
l0: 0.006861, l1: 0.007023, l2: 0.007562, l3: 0.007666, l4: 0.011181, l5: 0.009378, l6: 0.010990

[epoch: 132/100000, batch:   170/  187, ite: 12399] train loss: 0.068985, tar: 0.007681 
l0: 0.004051, l1: 0.004109, l2: 0.004845, l3: 0.004921, l4: 0.010829, l5: 0.009851, l6: 0.010035

[epoch: 132/100000, batch:   172/  187, ite: 12400] train loss: 0.068934, tar: 0.007672 
l0: 0.005516, l1: 0.005316, l2: 0.006150, l3: 0.006189, l4: 0.011106, l5: 0.012218, l6: 0.014467

[epoch: 132/100000, batch:   174/  187, ite: 12401] train loss: 0.068915, tar: 0.007667 
l0: 0.012030, l1: 0.012221, l2: 0.012688, l3: 0.013143, l4: 0.018289, l5: 0.016793, l6: 0.017900

[epoch: 132/100000, batch:   176/  187, ite: 12402] train loss: 0.069000, tar: 0.007678 
l0: 0.006337, l1: 0.006939, l2: 0.008064, l3: 0.007804, l4: 0.011126, l5: 0.010284, l6: 0.008770

[epoch: 132/100000, batch:   178/  187, ite: 12403] train loss: 0.068975, tar: 0.007674 
l0: 0.006652, l1: 0.006699, l2: 0.006742, l3: 0.007259, l4: 0.009403, l5: 0.008691, l6: 0.012946

[epoch: 132/100000, batch:   180/  187, ite: 12404] train loss: 0.068949, tar: 0.007672 
l0: 0.005112, l1: 0.006191, l2: 0.004485, l3: 0.004823, l4: 0.007510, l5: 0.007449, l6: 0.010126

[epoch: 132/100000, batch:   182/  187, ite: 12405] train loss: 0.068892, tar: 0.007665 
l0: 0.012304, l1: 0.012929, l2: 0.014287, l3: 0.014258, l4: 0.021866, l5: 0.015923, l6: 0.013200

[epoch: 132/100000, batch:   184/  187, ite: 12406] train loss: 0.068980, tar: 0.007677 
l0: 0.010298, l1: 0.010408, l2: 0.010253, l3: 0.010290, l4: 0.012467, l5: 0.013898, l6: 0.013303

[epoch: 132/100000, batch:   186/  187, ite: 12407] train loss: 0.069010, tar: 0.007683 
l0: 0.007061, l1: 0.007593, l2: 0.007828, l3: 0.007654, l4: 0.011135, l5: 0.009134, l6: 0.009215

[epoch: 132/100000, batch:   188/  187, ite: 12408] train loss: 0.068987, tar: 0.007682 
l0: 0.008325, l1: 0.008492, l2: 0.007861, l3: 0.008153, l4: 0.011261, l5: 0.011003, l6: 0.012540

[epoch: 133/100000, batch:     2/  187, ite: 12409] train loss: 0.068983, tar: 0.007683 
l0: 0.007175, l1: 0.007411, l2: 0.006550, l3: 0.008414, l4: 0.008868, l5: 0.006759, l6: 0.007137

[epoch: 133/100000, batch:     4/  187, ite: 12410] train loss: 0.068943, tar: 0.007682 
l0: 0.006976, l1: 0.006623, l2: 0.006655, l3: 0.007164, l4: 0.009799, l5: 0.009322, l6: 0.009971

[epoch: 133/100000, batch:     6/  187, ite: 12411] train loss: 0.068912, tar: 0.007680 
l0: 0.010219, l1: 0.010489, l2: 0.009597, l3: 0.010203, l4: 0.014992, l5: 0.013877, l6: 0.011282

[epoch: 133/100000, batch:     8/  187, ite: 12412] train loss: 0.068941, tar: 0.007686 
l0: 0.007962, l1: 0.008973, l2: 0.007959, l3: 0.008541, l4: 0.010664, l5: 0.009994, l6: 0.009923

[epoch: 133/100000, batch:    10/  187, ite: 12413] train loss: 0.068929, tar: 0.007687 
l0: 0.006533, l1: 0.006937, l2: 0.006842, l3: 0.007231, l4: 0.008198, l5: 0.008792, l6: 0.009277

[epoch: 133/100000, batch:    12/  187, ite: 12414] train loss: 0.068892, tar: 0.007684 
l0: 0.006983, l1: 0.007397, l2: 0.008500, l3: 0.006745, l4: 0.009203, l5: 0.009054, l6: 0.007058

[epoch: 133/100000, batch:    14/  187, ite: 12415] train loss: 0.068859, tar: 0.007683 
l0: 0.009008, l1: 0.010066, l2: 0.011011, l3: 0.009694, l4: 0.008102, l5: 0.007993, l6: 0.008362

[epoch: 133/100000, batch:    16/  187, ite: 12416] train loss: 0.068848, tar: 0.007686 
l0: 0.006074, l1: 0.007135, l2: 0.006589, l3: 0.006309, l4: 0.008207, l5: 0.007508, l6: 0.007941

[epoch: 133/100000, batch:    18/  187, ite: 12417] train loss: 0.068802, tar: 0.007682 
l0: 0.006158, l1: 0.007915, l2: 0.005036, l3: 0.004939, l4: 0.007375, l5: 0.009089, l6: 0.010191

[epoch: 133/100000, batch:    20/  187, ite: 12418] train loss: 0.068759, tar: 0.007678 
l0: 0.008610, l1: 0.009160, l2: 0.010422, l3: 0.009427, l4: 0.011093, l5: 0.009954, l6: 0.010460

[epoch: 133/100000, batch:    22/  187, ite: 12419] train loss: 0.068760, tar: 0.007681 
l0: 0.008783, l1: 0.009676, l2: 0.007598, l3: 0.009364, l4: 0.011286, l5: 0.009223, l6: 0.008686

[epoch: 133/100000, batch:    24/  187, ite: 12420] train loss: 0.068750, tar: 0.007683 
l0: 0.007864, l1: 0.008422, l2: 0.008322, l3: 0.008131, l4: 0.010736, l5: 0.008651, l6: 0.008596

[epoch: 133/100000, batch:    26/  187, ite: 12421] train loss: 0.068731, tar: 0.007684 
l0: 0.003617, l1: 0.003328, l2: 0.003545, l3: 0.004612, l4: 0.004599, l5: 0.005146, l6: 0.009363

[epoch: 133/100000, batch:    28/  187, ite: 12422] train loss: 0.068649, tar: 0.007674 
l0: 0.006021, l1: 0.006564, l2: 0.007357, l3: 0.007319, l4: 0.009648, l5: 0.008127, l6: 0.009879

[epoch: 133/100000, batch:    30/  187, ite: 12423] train loss: 0.068616, tar: 0.007670 
l0: 0.013923, l1: 0.012546, l2: 0.014356, l3: 0.016610, l4: 0.022748, l5: 0.023852, l6: 0.022141

[epoch: 133/100000, batch:    32/  187, ite: 12424] train loss: 0.068752, tar: 0.007685 
l0: 0.003792, l1: 0.003884, l2: 0.004031, l3: 0.004482, l4: 0.004655, l5: 0.004314, l6: 0.004459

[epoch: 133/100000, batch:    34/  187, ite: 12425] train loss: 0.068660, tar: 0.007676 
l0: 0.010135, l1: 0.010269, l2: 0.011685, l3: 0.010870, l4: 0.015357, l5: 0.013757, l6: 0.017826

[epoch: 133/100000, batch:    36/  187, ite: 12426] train loss: 0.068710, tar: 0.007681 
l0: 0.002805, l1: 0.002860, l2: 0.003127, l3: 0.003484, l4: 0.005272, l5: 0.004786, l6: 0.005423

[epoch: 133/100000, batch:    38/  187, ite: 12427] train loss: 0.068614, tar: 0.007670 
l0: 0.004626, l1: 0.004887, l2: 0.004906, l3: 0.004761, l4: 0.008828, l5: 0.007818, l6: 0.007841

[epoch: 133/100000, batch:    40/  187, ite: 12428] train loss: 0.068556, tar: 0.007663 
l0: 0.006293, l1: 0.007012, l2: 0.006903, l3: 0.006725, l4: 0.009300, l5: 0.009551, l6: 0.009219

[epoch: 133/100000, batch:    42/  187, ite: 12429] train loss: 0.068524, tar: 0.007660 
l0: 0.005919, l1: 0.006021, l2: 0.006647, l3: 0.006516, l4: 0.010031, l5: 0.009366, l6: 0.009724

[epoch: 133/100000, batch:    44/  187, ite: 12430] train loss: 0.068491, tar: 0.007656 
l0: 0.008860, l1: 0.008846, l2: 0.009749, l3: 0.010161, l4: 0.012084, l5: 0.013063, l6: 0.010025

[epoch: 133/100000, batch:    46/  187, ite: 12431] train loss: 0.068501, tar: 0.007658 
l0: 0.008155, l1: 0.007544, l2: 0.007333, l3: 0.008376, l4: 0.011304, l5: 0.012327, l6: 0.014859

[epoch: 133/100000, batch:    48/  187, ite: 12432] train loss: 0.068504, tar: 0.007660 
l0: 0.006865, l1: 0.006132, l2: 0.005845, l3: 0.007368, l4: 0.013084, l5: 0.013773, l6: 0.016216

[epoch: 133/100000, batch:    50/  187, ite: 12433] train loss: 0.068506, tar: 0.007658 
l0: 0.001379, l1: 0.001741, l2: 0.001658, l3: 0.002097, l4: 0.003679, l5: 0.002736, l6: 0.003761

[epoch: 133/100000, batch:    52/  187, ite: 12434] train loss: 0.068387, tar: 0.007643 
l0: 0.007990, l1: 0.007112, l2: 0.008596, l3: 0.011299, l4: 0.019131, l5: 0.018364, l6: 0.015518

[epoch: 133/100000, batch:    54/  187, ite: 12435] train loss: 0.068432, tar: 0.007644 
l0: 0.009387, l1: 0.010031, l2: 0.010067, l3: 0.009710, l4: 0.013569, l5: 0.015002, l6: 0.017239

[epoch: 133/100000, batch:    56/  187, ite: 12436] train loss: 0.068470, tar: 0.007648 
l0: 0.009256, l1: 0.008673, l2: 0.010440, l3: 0.010805, l4: 0.018416, l5: 0.015422, l6: 0.019235

[epoch: 133/100000, batch:    58/  187, ite: 12437] train loss: 0.068525, tar: 0.007652 
l0: 0.003795, l1: 0.004301, l2: 0.004167, l3: 0.003773, l4: 0.007573, l5: 0.005402, l6: 0.004419

[epoch: 133/100000, batch:    60/  187, ite: 12438] train loss: 0.068445, tar: 0.007643 
l0: 0.009227, l1: 0.010650, l2: 0.009017, l3: 0.009448, l4: 0.010315, l5: 0.010346, l6: 0.012350

[epoch: 133/100000, batch:    62/  187, ite: 12439] train loss: 0.068451, tar: 0.007647 
l0: 0.004174, l1: 0.004349, l2: 0.004397, l3: 0.004296, l4: 0.006700, l5: 0.007043, l6: 0.006572

[epoch: 133/100000, batch:    64/  187, ite: 12440] train loss: 0.068381, tar: 0.007639 
l0: 0.010843, l1: 0.013564, l2: 0.008792, l3: 0.006671, l4: 0.010238, l5: 0.010221, l6: 0.011522

[epoch: 133/100000, batch:    66/  187, ite: 12441] train loss: 0.068389, tar: 0.007646 
l0: 0.007111, l1: 0.007466, l2: 0.007979, l3: 0.007943, l4: 0.010332, l5: 0.010123, l6: 0.011504

[epoch: 133/100000, batch:    68/  187, ite: 12442] train loss: 0.068375, tar: 0.007645 
l0: 0.003597, l1: 0.003487, l2: 0.003804, l3: 0.004050, l4: 0.006386, l5: 0.008146, l6: 0.007019

[epoch: 133/100000, batch:    70/  187, ite: 12443] train loss: 0.068303, tar: 0.007636 
l0: 0.008429, l1: 0.008267, l2: 0.008827, l3: 0.009164, l4: 0.010049, l5: 0.010258, l6: 0.009961

[epoch: 133/100000, batch:    72/  187, ite: 12444] train loss: 0.068296, tar: 0.007637 
l0: 0.007531, l1: 0.006800, l2: 0.006565, l3: 0.007288, l4: 0.014511, l5: 0.014690, l6: 0.018266

[epoch: 133/100000, batch:    74/  187, ite: 12445] train loss: 0.068312, tar: 0.007637 
l0: 0.009438, l1: 0.010869, l2: 0.011564, l3: 0.010086, l4: 0.014919, l5: 0.012361, l6: 0.013412

[epoch: 133/100000, batch:    76/  187, ite: 12446] train loss: 0.068345, tar: 0.007641 
l0: 0.003954, l1: 0.003802, l2: 0.004978, l3: 0.004708, l4: 0.003603, l5: 0.003461, l6: 0.004879

[epoch: 133/100000, batch:    78/  187, ite: 12447] train loss: 0.068257, tar: 0.007633 
l0: 0.005298, l1: 0.005742, l2: 0.006028, l3: 0.006347, l4: 0.009461, l5: 0.008159, l6: 0.007406

[epoch: 133/100000, batch:    80/  187, ite: 12448] train loss: 0.068213, tar: 0.007628 
l0: 0.008560, l1: 0.009580, l2: 0.009155, l3: 0.008994, l4: 0.012601, l5: 0.010512, l6: 0.010631

[epoch: 133/100000, batch:    82/  187, ite: 12449] train loss: 0.068217, tar: 0.007630 
l0: 0.005767, l1: 0.005759, l2: 0.006155, l3: 0.005958, l4: 0.010438, l5: 0.009409, l6: 0.011472

[epoch: 133/100000, batch:    84/  187, ite: 12450] train loss: 0.068188, tar: 0.007626 
l0: 0.002146, l1: 0.002219, l2: 0.001980, l3: 0.003097, l4: 0.004609, l5: 0.003703, l6: 0.003458

[epoch: 133/100000, batch:    86/  187, ite: 12451] train loss: 0.068084, tar: 0.007614 
l0: 0.004203, l1: 0.004329, l2: 0.004235, l3: 0.004646, l4: 0.009245, l5: 0.007040, l6: 0.008530

[epoch: 133/100000, batch:    88/  187, ite: 12452] train loss: 0.068026, tar: 0.007606 
l0: 0.002329, l1: 0.001772, l2: 0.002233, l3: 0.003235, l4: 0.008357, l5: 0.010484, l6: 0.013159

[epoch: 133/100000, batch:    90/  187, ite: 12453] train loss: 0.067968, tar: 0.007594 
l0: 0.007392, l1: 0.007410, l2: 0.008787, l3: 0.009689, l4: 0.009307, l5: 0.008541, l6: 0.010177

[epoch: 133/100000, batch:    92/  187, ite: 12454] train loss: 0.067953, tar: 0.007594 
l0: 0.006801, l1: 0.006953, l2: 0.006003, l3: 0.010265, l4: 0.013391, l5: 0.009368, l6: 0.011372

[epoch: 133/100000, batch:    94/  187, ite: 12455] train loss: 0.067945, tar: 0.007592 
l0: 0.005847, l1: 0.005158, l2: 0.006020, l3: 0.007513, l4: 0.008217, l5: 0.009393, l6: 0.010075

[epoch: 133/100000, batch:    96/  187, ite: 12456] train loss: 0.067911, tar: 0.007588 
l0: 0.013798, l1: 0.012593, l2: 0.011463, l3: 0.013221, l4: 0.017648, l5: 0.021342, l6: 0.022384

[epoch: 133/100000, batch:    98/  187, ite: 12457] train loss: 0.068008, tar: 0.007602 
l0: 0.006212, l1: 0.005931, l2: 0.006234, l3: 0.006820, l4: 0.012406, l5: 0.014465, l6: 0.012694

[epoch: 133/100000, batch:   100/  187, ite: 12458] train loss: 0.068001, tar: 0.007599 
l0: 0.006573, l1: 0.006588, l2: 0.006572, l3: 0.006735, l4: 0.008919, l5: 0.010391, l6: 0.010727

[epoch: 133/100000, batch:   102/  187, ite: 12459] train loss: 0.067976, tar: 0.007597 
l0: 0.002864, l1: 0.003151, l2: 0.002870, l3: 0.003215, l4: 0.004848, l5: 0.004924, l6: 0.005665

[epoch: 133/100000, batch:   104/  187, ite: 12460] train loss: 0.067888, tar: 0.007586 
l0: 0.004689, l1: 0.005406, l2: 0.006420, l3: 0.005444, l4: 0.007324, l5: 0.005833, l6: 0.006445

[epoch: 133/100000, batch:   106/  187, ite: 12461] train loss: 0.067831, tar: 0.007580 
l0: 0.004138, l1: 0.004042, l2: 0.004084, l3: 0.005049, l4: 0.011934, l5: 0.011886, l6: 0.009846

[epoch: 133/100000, batch:   108/  187, ite: 12462] train loss: 0.067794, tar: 0.007573 
l0: 0.007125, l1: 0.007256, l2: 0.006767, l3: 0.007615, l4: 0.011841, l5: 0.010715, l6: 0.012697

[epoch: 133/100000, batch:   110/  187, ite: 12463] train loss: 0.067786, tar: 0.007572 
l0: 0.004579, l1: 0.004678, l2: 0.005436, l3: 0.005985, l4: 0.016063, l5: 0.013194, l6: 0.014794

[epoch: 133/100000, batch:   112/  187, ite: 12464] train loss: 0.067780, tar: 0.007565 
l0: 0.008234, l1: 0.009200, l2: 0.008768, l3: 0.009965, l4: 0.010459, l5: 0.009493, l6: 0.010034

[epoch: 133/100000, batch:   114/  187, ite: 12465] train loss: 0.067776, tar: 0.007567 
l0: 0.006342, l1: 0.006389, l2: 0.006794, l3: 0.007101, l4: 0.012375, l5: 0.010478, l6: 0.010964

[epoch: 133/100000, batch:   116/  187, ite: 12466] train loss: 0.067760, tar: 0.007564 
l0: 0.005736, l1: 0.005807, l2: 0.006190, l3: 0.006590, l4: 0.010073, l5: 0.009172, l6: 0.010747

[epoch: 133/100000, batch:   118/  187, ite: 12467] train loss: 0.067732, tar: 0.007560 
l0: 0.005912, l1: 0.005317, l2: 0.005405, l3: 0.005752, l4: 0.015397, l5: 0.014867, l6: 0.016372

[epoch: 133/100000, batch:   120/  187, ite: 12468] train loss: 0.067734, tar: 0.007557 
l0: 0.005853, l1: 0.005544, l2: 0.006224, l3: 0.007077, l4: 0.013845, l5: 0.010777, l6: 0.013997

[epoch: 133/100000, batch:   122/  187, ite: 12469] train loss: 0.067725, tar: 0.007553 
l0: 0.006205, l1: 0.005463, l2: 0.006157, l3: 0.008274, l4: 0.011488, l5: 0.012007, l6: 0.012921

[epoch: 133/100000, batch:   124/  187, ite: 12470] train loss: 0.067714, tar: 0.007550 
l0: 0.006403, l1: 0.006313, l2: 0.006724, l3: 0.006690, l4: 0.009838, l5: 0.009732, l6: 0.010338

[epoch: 133/100000, batch:   126/  187, ite: 12471] train loss: 0.067689, tar: 0.007548 
l0: 0.008999, l1: 0.008343, l2: 0.008657, l3: 0.009678, l4: 0.020719, l5: 0.021144, l6: 0.021847

[epoch: 133/100000, batch:   128/  187, ite: 12472] train loss: 0.067756, tar: 0.007551 
l0: 0.003333, l1: 0.003380, l2: 0.003848, l3: 0.004800, l4: 0.006429, l5: 0.006539, l6: 0.006924

[epoch: 133/100000, batch:   130/  187, ite: 12473] train loss: 0.067687, tar: 0.007542 
l0: 0.005159, l1: 0.005551, l2: 0.005948, l3: 0.005788, l4: 0.010904, l5: 0.009765, l6: 0.010898

[epoch: 133/100000, batch:   132/  187, ite: 12474] train loss: 0.067659, tar: 0.007537 
l0: 0.005575, l1: 0.005250, l2: 0.005528, l3: 0.006432, l4: 0.009526, l5: 0.009210, l6: 0.008846

[epoch: 133/100000, batch:   134/  187, ite: 12475] train loss: 0.067622, tar: 0.007533 
l0: 0.004315, l1: 0.004515, l2: 0.004552, l3: 0.004766, l4: 0.006617, l5: 0.006499, l6: 0.007184

[epoch: 133/100000, batch:   136/  187, ite: 12476] train loss: 0.067561, tar: 0.007526 
l0: 0.008431, l1: 0.009808, l2: 0.010954, l3: 0.010269, l4: 0.008618, l5: 0.008586, l6: 0.010196

[epoch: 133/100000, batch:   138/  187, ite: 12477] train loss: 0.067559, tar: 0.007528 
l0: 0.004187, l1: 0.004118, l2: 0.004727, l3: 0.005019, l4: 0.006921, l5: 0.007196, l6: 0.008430

[epoch: 133/100000, batch:   140/  187, ite: 12478] train loss: 0.067503, tar: 0.007521 
l0: 0.004665, l1: 0.004524, l2: 0.005497, l3: 0.005416, l4: 0.009155, l5: 0.009738, l6: 0.009052

[epoch: 133/100000, batch:   142/  187, ite: 12479] train loss: 0.067462, tar: 0.007515 
l0: 0.005059, l1: 0.005376, l2: 0.005019, l3: 0.003869, l4: 0.009931, l5: 0.009227, l6: 0.007960

[epoch: 133/100000, batch:   144/  187, ite: 12480] train loss: 0.067419, tar: 0.007510 
l0: 0.008134, l1: 0.007984, l2: 0.007371, l3: 0.010047, l4: 0.015505, l5: 0.015677, l6: 0.021008

[epoch: 133/100000, batch:   146/  187, ite: 12481] train loss: 0.067457, tar: 0.007511 
l0: 0.004612, l1: 0.004492, l2: 0.004490, l3: 0.004822, l4: 0.007043, l5: 0.007706, l6: 0.012219

[epoch: 133/100000, batch:   148/  187, ite: 12482] train loss: 0.067411, tar: 0.007505 
l0: 0.005911, l1: 0.006203, l2: 0.006905, l3: 0.006058, l4: 0.006113, l5: 0.006399, l6: 0.007417

[epoch: 133/100000, batch:   150/  187, ite: 12483] train loss: 0.067365, tar: 0.007502 
l0: 0.010122, l1: 0.011251, l2: 0.011983, l3: 0.010786, l4: 0.012950, l5: 0.012065, l6: 0.015543

[epoch: 133/100000, batch:   152/  187, ite: 12484] train loss: 0.067400, tar: 0.007507 
l0: 0.008637, l1: 0.008308, l2: 0.010263, l3: 0.009713, l4: 0.015689, l5: 0.015037, l6: 0.014867

[epoch: 133/100000, batch:   154/  187, ite: 12485] train loss: 0.067432, tar: 0.007509 
l0: 0.007842, l1: 0.007406, l2: 0.007782, l3: 0.008096, l4: 0.013034, l5: 0.015227, l6: 0.017454

[epoch: 133/100000, batch:   156/  187, ite: 12486] train loss: 0.067451, tar: 0.007510 
l0: 0.007751, l1: 0.008214, l2: 0.008165, l3: 0.008151, l4: 0.010025, l5: 0.009748, l6: 0.010256

[epoch: 133/100000, batch:   158/  187, ite: 12487] train loss: 0.067440, tar: 0.007511 
l0: 0.002467, l1: 0.002376, l2: 0.003640, l3: 0.003401, l4: 0.004574, l5: 0.004940, l6: 0.006249

[epoch: 133/100000, batch:   160/  187, ite: 12488] train loss: 0.067359, tar: 0.007500 
l0: 0.005982, l1: 0.005988, l2: 0.005724, l3: 0.006418, l4: 0.009125, l5: 0.009027, l6: 0.009909

[epoch: 133/100000, batch:   162/  187, ite: 12489] train loss: 0.067328, tar: 0.007497 
l0: 0.004871, l1: 0.005054, l2: 0.005413, l3: 0.005276, l4: 0.006965, l5: 0.006450, l6: 0.007753

[epoch: 133/100000, batch:   164/  187, ite: 12490] train loss: 0.067276, tar: 0.007492 
l0: 0.006124, l1: 0.006835, l2: 0.006861, l3: 0.006618, l4: 0.012056, l5: 0.011377, l6: 0.010473

[epoch: 133/100000, batch:   166/  187, ite: 12491] train loss: 0.067261, tar: 0.007489 
l0: 0.006645, l1: 0.007168, l2: 0.007535, l3: 0.007906, l4: 0.012869, l5: 0.010001, l6: 0.009316

[epoch: 133/100000, batch:   168/  187, ite: 12492] train loss: 0.067250, tar: 0.007487 
l0: 0.011004, l1: 0.011239, l2: 0.010814, l3: 0.010103, l4: 0.015498, l5: 0.013270, l6: 0.016878

[epoch: 133/100000, batch:   170/  187, ite: 12493] train loss: 0.067293, tar: 0.007494 
l0: 0.006408, l1: 0.005866, l2: 0.007544, l3: 0.008083, l4: 0.008987, l5: 0.007791, l6: 0.011048

[epoch: 133/100000, batch:   172/  187, ite: 12494] train loss: 0.067270, tar: 0.007492 
l0: 0.005079, l1: 0.004768, l2: 0.005265, l3: 0.005361, l4: 0.006327, l5: 0.005880, l6: 0.007239

[epoch: 133/100000, batch:   174/  187, ite: 12495] train loss: 0.067215, tar: 0.007487 
l0: 0.009068, l1: 0.008415, l2: 0.008606, l3: 0.010772, l4: 0.015691, l5: 0.014792, l6: 0.020756

[epoch: 133/100000, batch:   176/  187, ite: 12496] train loss: 0.067257, tar: 0.007491 
l0: 0.005953, l1: 0.006083, l2: 0.007016, l3: 0.007808, l4: 0.009313, l5: 0.007937, l6: 0.009298

[epoch: 133/100000, batch:   178/  187, ite: 12497] train loss: 0.067229, tar: 0.007487 
l0: 0.004130, l1: 0.004428, l2: 0.004388, l3: 0.005213, l4: 0.010225, l5: 0.007059, l6: 0.007011

[epoch: 133/100000, batch:   180/  187, ite: 12498] train loss: 0.067179, tar: 0.007481 
l0: 0.009936, l1: 0.011164, l2: 0.011343, l3: 0.009532, l4: 0.009000, l5: 0.010083, l6: 0.008816

[epoch: 133/100000, batch:   182/  187, ite: 12499] train loss: 0.067185, tar: 0.007486 
l0: 0.009131, l1: 0.009079, l2: 0.009999, l3: 0.010741, l4: 0.018950, l5: 0.016467, l6: 0.015070

[epoch: 133/100000, batch:   184/  187, ite: 12500] train loss: 0.067229, tar: 0.007489 
l0: 0.003529, l1: 0.003858, l2: 0.004606, l3: 0.004260, l4: 0.004391, l5: 0.004785, l6: 0.005946

[epoch: 133/100000, batch:   186/  187, ite: 12501] train loss: 0.067158, tar: 0.007481 
l0: 0.005734, l1: 0.006158, l2: 0.004764, l3: 0.004708, l4: 0.008442, l5: 0.006953, l6: 0.007989

[epoch: 133/100000, batch:   188/  187, ite: 12502] train loss: 0.067113, tar: 0.007478 
l0: 0.004702, l1: 0.004588, l2: 0.005426, l3: 0.005292, l4: 0.006766, l5: 0.006200, l6: 0.007819

[epoch: 134/100000, batch:     2/  187, ite: 12503] train loss: 0.067061, tar: 0.007472 
l0: 0.003432, l1: 0.003330, l2: 0.004663, l3: 0.004597, l4: 0.007081, l5: 0.006831, l6: 0.007351

[epoch: 134/100000, batch:     4/  187, ite: 12504] train loss: 0.067001, tar: 0.007464 
l0: 0.002888, l1: 0.003006, l2: 0.002981, l3: 0.003651, l4: 0.005196, l5: 0.005412, l6: 0.006174

[epoch: 134/100000, batch:     6/  187, ite: 12505] train loss: 0.066927, tar: 0.007455 
l0: 0.009302, l1: 0.009703, l2: 0.009307, l3: 0.009286, l4: 0.012284, l5: 0.011254, l6: 0.015153

[epoch: 134/100000, batch:     8/  187, ite: 12506] train loss: 0.066945, tar: 0.007459 
l0: 0.006726, l1: 0.006798, l2: 0.006970, l3: 0.006178, l4: 0.011314, l5: 0.011267, l6: 0.009395

[epoch: 134/100000, batch:    10/  187, ite: 12507] train loss: 0.066929, tar: 0.007457 
l0: 0.004848, l1: 0.005009, l2: 0.005206, l3: 0.005761, l4: 0.012084, l5: 0.011085, l6: 0.009106

[epoch: 134/100000, batch:    12/  187, ite: 12508] train loss: 0.066902, tar: 0.007452 
l0: 0.004329, l1: 0.004675, l2: 0.006024, l3: 0.005876, l4: 0.007168, l5: 0.007816, l6: 0.008084

[epoch: 134/100000, batch:    14/  187, ite: 12509] train loss: 0.066857, tar: 0.007446 
l0: 0.002637, l1: 0.002680, l2: 0.002647, l3: 0.002658, l4: 0.004639, l5: 0.005334, l6: 0.004733

[epoch: 134/100000, batch:    16/  187, ite: 12510] train loss: 0.066775, tar: 0.007436 
l0: 0.005710, l1: 0.006114, l2: 0.006031, l3: 0.006040, l4: 0.009973, l5: 0.009110, l6: 0.012459

[epoch: 134/100000, batch:    18/  187, ite: 12511] train loss: 0.066753, tar: 0.007433 
l0: 0.006126, l1: 0.006097, l2: 0.006884, l3: 0.007195, l4: 0.008577, l5: 0.008641, l6: 0.010422

[epoch: 134/100000, batch:    20/  187, ite: 12512] train loss: 0.066728, tar: 0.007431 
l0: 0.006106, l1: 0.006593, l2: 0.006508, l3: 0.006558, l4: 0.007798, l5: 0.007577, l6: 0.008984

[epoch: 134/100000, batch:    22/  187, ite: 12513] train loss: 0.066696, tar: 0.007428 
l0: 0.005168, l1: 0.005215, l2: 0.005829, l3: 0.005449, l4: 0.009667, l5: 0.009154, l6: 0.013908

[epoch: 134/100000, batch:    24/  187, ite: 12514] train loss: 0.066672, tar: 0.007424 
l0: 0.009214, l1: 0.008492, l2: 0.009196, l3: 0.010012, l4: 0.014742, l5: 0.014513, l6: 0.015107

[epoch: 134/100000, batch:    26/  187, ite: 12515] train loss: 0.066700, tar: 0.007427 
l0: 0.009337, l1: 0.009854, l2: 0.010167, l3: 0.009498, l4: 0.010061, l5: 0.009793, l6: 0.010331

[epoch: 134/100000, batch:    28/  187, ite: 12516] train loss: 0.066705, tar: 0.007431 
l0: 0.006738, l1: 0.005681, l2: 0.006255, l3: 0.008720, l4: 0.014169, l5: 0.014497, l6: 0.018543

[epoch: 134/100000, batch:    30/  187, ite: 12517] train loss: 0.066720, tar: 0.007429 
l0: 0.004465, l1: 0.004324, l2: 0.004409, l3: 0.005258, l4: 0.006215, l5: 0.006388, l6: 0.007816

[epoch: 134/100000, batch:    32/  187, ite: 12518] train loss: 0.066666, tar: 0.007424 
l0: 0.003767, l1: 0.003674, l2: 0.003970, l3: 0.004664, l4: 0.008540, l5: 0.007967, l6: 0.008253

[epoch: 134/100000, batch:    34/  187, ite: 12519] train loss: 0.066616, tar: 0.007417 
l0: 0.007184, l1: 0.007990, l2: 0.009346, l3: 0.008208, l4: 0.012334, l5: 0.011541, l6: 0.014311

[epoch: 134/100000, batch:    36/  187, ite: 12520] train loss: 0.066625, tar: 0.007416 
l0: 0.009067, l1: 0.009734, l2: 0.009428, l3: 0.008047, l4: 0.009897, l5: 0.009991, l6: 0.011076

[epoch: 134/100000, batch:    38/  187, ite: 12521] train loss: 0.066626, tar: 0.007419 
l0: 0.015701, l1: 0.013711, l2: 0.016608, l3: 0.020182, l4: 0.027367, l5: 0.028839, l6: 0.024243

[epoch: 134/100000, batch:    40/  187, ite: 12522] train loss: 0.066779, tar: 0.007435 
l0: 0.007112, l1: 0.007652, l2: 0.007392, l3: 0.006610, l4: 0.014808, l5: 0.010908, l6: 0.011193

[epoch: 134/100000, batch:    42/  187, ite: 12523] train loss: 0.066777, tar: 0.007435 
l0: 0.007577, l1: 0.008218, l2: 0.007623, l3: 0.007711, l4: 0.015228, l5: 0.012625, l6: 0.012778

[epoch: 134/100000, batch:    44/  187, ite: 12524] train loss: 0.066787, tar: 0.007435 
l0: 0.006120, l1: 0.005965, l2: 0.006129, l3: 0.005911, l4: 0.008891, l5: 0.008768, l6: 0.009139

[epoch: 134/100000, batch:    46/  187, ite: 12525] train loss: 0.066756, tar: 0.007432 
l0: 0.004244, l1: 0.004258, l2: 0.004704, l3: 0.005346, l4: 0.010772, l5: 0.006804, l6: 0.006498

[epoch: 134/100000, batch:    48/  187, ite: 12526] train loss: 0.066710, tar: 0.007426 
l0: 0.003588, l1: 0.003416, l2: 0.003420, l3: 0.003941, l4: 0.009473, l5: 0.008209, l6: 0.009896

[epoch: 134/100000, batch:    50/  187, ite: 12527] train loss: 0.066663, tar: 0.007419 
l0: 0.006725, l1: 0.006292, l2: 0.008209, l3: 0.007901, l4: 0.015792, l5: 0.014994, l6: 0.016814

[epoch: 134/100000, batch:    52/  187, ite: 12528] train loss: 0.066683, tar: 0.007418 
l0: 0.003871, l1: 0.003842, l2: 0.003782, l3: 0.005161, l4: 0.005837, l5: 0.006228, l6: 0.006337

[epoch: 134/100000, batch:    54/  187, ite: 12529] train loss: 0.066623, tar: 0.007411 
l0: 0.011375, l1: 0.012038, l2: 0.013607, l3: 0.012740, l4: 0.015455, l5: 0.013279, l6: 0.013330

[epoch: 134/100000, batch:    56/  187, ite: 12530] train loss: 0.066670, tar: 0.007418 
l0: 0.005023, l1: 0.005649, l2: 0.005192, l3: 0.005296, l4: 0.009609, l5: 0.010570, l6: 0.010094

[epoch: 134/100000, batch:    58/  187, ite: 12531] train loss: 0.066642, tar: 0.007414 
l0: 0.004004, l1: 0.004147, l2: 0.004059, l3: 0.004466, l4: 0.009400, l5: 0.008114, l6: 0.008006

[epoch: 134/100000, batch:    60/  187, ite: 12532] train loss: 0.066596, tar: 0.007408 
l0: 0.005652, l1: 0.005968, l2: 0.006782, l3: 0.006187, l4: 0.011147, l5: 0.009626, l6: 0.010407

[epoch: 134/100000, batch:    62/  187, ite: 12533] train loss: 0.066575, tar: 0.007404 
l0: 0.004390, l1: 0.004606, l2: 0.004651, l3: 0.004673, l4: 0.008955, l5: 0.006653, l6: 0.008748

[epoch: 134/100000, batch:    64/  187, ite: 12534] train loss: 0.066531, tar: 0.007399 
l0: 0.001918, l1: 0.001921, l2: 0.002714, l3: 0.003033, l4: 0.003069, l5: 0.004230, l6: 0.002246

[epoch: 134/100000, batch:    66/  187, ite: 12535] train loss: 0.066442, tar: 0.007388 
l0: 0.007251, l1: 0.007608, l2: 0.008664, l3: 0.007892, l4: 0.006255, l5: 0.006583, l6: 0.005655

[epoch: 134/100000, batch:    68/  187, ite: 12536] train loss: 0.066411, tar: 0.007388 
l0: 0.003940, l1: 0.004011, l2: 0.004793, l3: 0.004656, l4: 0.007654, l5: 0.007170, l6: 0.007393

[epoch: 134/100000, batch:    70/  187, ite: 12537] train loss: 0.066361, tar: 0.007382 
l0: 0.005322, l1: 0.004876, l2: 0.006352, l3: 0.006041, l4: 0.005514, l5: 0.007327, l6: 0.006543

[epoch: 134/100000, batch:    72/  187, ite: 12538] train loss: 0.066316, tar: 0.007378 
l0: 0.004744, l1: 0.005036, l2: 0.004479, l3: 0.005196, l4: 0.011677, l5: 0.007332, l6: 0.010540

[epoch: 134/100000, batch:    74/  187, ite: 12539] train loss: 0.066284, tar: 0.007373 
l0: 0.006649, l1: 0.006456, l2: 0.006919, l3: 0.007875, l4: 0.012742, l5: 0.011926, l6: 0.013322

[epoch: 134/100000, batch:    76/  187, ite: 12540] train loss: 0.066283, tar: 0.007372 
l0: 0.008833, l1: 0.009395, l2: 0.008493, l3: 0.009304, l4: 0.012130, l5: 0.010786, l6: 0.011570

[epoch: 134/100000, batch:    78/  187, ite: 12541] train loss: 0.066291, tar: 0.007374 
l0: 0.009556, l1: 0.009202, l2: 0.010916, l3: 0.011158, l4: 0.025593, l5: 0.023561, l6: 0.024855

[epoch: 134/100000, batch:    80/  187, ite: 12542] train loss: 0.066380, tar: 0.007378 
l0: 0.008289, l1: 0.008665, l2: 0.008875, l3: 0.007940, l4: 0.015611, l5: 0.013438, l6: 0.012395

[epoch: 134/100000, batch:    82/  187, ite: 12543] train loss: 0.066397, tar: 0.007380 
l0: 0.007249, l1: 0.007001, l2: 0.008157, l3: 0.007885, l4: 0.010241, l5: 0.009858, l6: 0.012045

[epoch: 134/100000, batch:    84/  187, ite: 12544] train loss: 0.066389, tar: 0.007380 
l0: 0.005338, l1: 0.005117, l2: 0.006103, l3: 0.006318, l4: 0.007969, l5: 0.008439, l6: 0.009578

[epoch: 134/100000, batch:    86/  187, ite: 12545] train loss: 0.066357, tar: 0.007376 
l0: 0.004816, l1: 0.004971, l2: 0.006363, l3: 0.006110, l4: 0.008476, l5: 0.006319, l6: 0.006140

[epoch: 134/100000, batch:    88/  187, ite: 12546] train loss: 0.066315, tar: 0.007371 
l0: 0.008230, l1: 0.007481, l2: 0.009719, l3: 0.011194, l4: 0.014477, l5: 0.014058, l6: 0.014586

[epoch: 134/100000, batch:    90/  187, ite: 12547] train loss: 0.066339, tar: 0.007373 
l0: 0.015588, l1: 0.015765, l2: 0.016447, l3: 0.016612, l4: 0.022219, l5: 0.019420, l6: 0.017476

[epoch: 134/100000, batch:    92/  187, ite: 12548] train loss: 0.066444, tar: 0.007388 
l0: 0.006685, l1: 0.007568, l2: 0.007350, l3: 0.007632, l4: 0.011557, l5: 0.009350, l6: 0.010919

[epoch: 134/100000, batch:    94/  187, ite: 12549] train loss: 0.066434, tar: 0.007387 
l0: 0.007307, l1: 0.007989, l2: 0.009493, l3: 0.007810, l4: 0.008272, l5: 0.007296, l6: 0.007948

[epoch: 134/100000, batch:    96/  187, ite: 12550] train loss: 0.066415, tar: 0.007387 
l0: 0.004950, l1: 0.005426, l2: 0.005669, l3: 0.006661, l4: 0.007412, l5: 0.006910, l6: 0.007645

[epoch: 134/100000, batch:    98/  187, ite: 12551] train loss: 0.066376, tar: 0.007382 
l0: 0.006127, l1: 0.005829, l2: 0.007201, l3: 0.007783, l4: 0.012431, l5: 0.013539, l6: 0.015229

[epoch: 134/100000, batch:   100/  187, ite: 12552] train loss: 0.066379, tar: 0.007380 
l0: 0.007712, l1: 0.008356, l2: 0.009420, l3: 0.007758, l4: 0.008066, l5: 0.006962, l6: 0.008044

[epoch: 134/100000, batch:   102/  187, ite: 12553] train loss: 0.066361, tar: 0.007380 
l0: 0.009382, l1: 0.009388, l2: 0.009829, l3: 0.009827, l4: 0.010396, l5: 0.010623, l6: 0.015000

[epoch: 134/100000, batch:   104/  187, ite: 12554] train loss: 0.066375, tar: 0.007384 
l0: 0.005873, l1: 0.006479, l2: 0.006307, l3: 0.006091, l4: 0.011370, l5: 0.009899, l6: 0.008985

[epoch: 134/100000, batch:   106/  187, ite: 12555] train loss: 0.066355, tar: 0.007381 
l0: 0.009548, l1: 0.009622, l2: 0.010220, l3: 0.010232, l4: 0.011461, l5: 0.011779, l6: 0.011275

[epoch: 134/100000, batch:   108/  187, ite: 12556] train loss: 0.066369, tar: 0.007385 
l0: 0.006439, l1: 0.006206, l2: 0.007285, l3: 0.007788, l4: 0.011350, l5: 0.011497, l6: 0.009079

[epoch: 134/100000, batch:   110/  187, ite: 12557] train loss: 0.066357, tar: 0.007384 
l0: 0.008615, l1: 0.007875, l2: 0.010533, l3: 0.008672, l4: 0.007644, l5: 0.009749, l6: 0.010415

[epoch: 134/100000, batch:   112/  187, ite: 12558] train loss: 0.066352, tar: 0.007386 
l0: 0.007309, l1: 0.007373, l2: 0.007115, l3: 0.006129, l4: 0.006775, l5: 0.008117, l6: 0.009376

[epoch: 134/100000, batch:   114/  187, ite: 12559] train loss: 0.066326, tar: 0.007386 
l0: 0.008951, l1: 0.008687, l2: 0.008718, l3: 0.009780, l4: 0.017708, l5: 0.015148, l6: 0.019365

[epoch: 134/100000, batch:   116/  187, ite: 12560] train loss: 0.066366, tar: 0.007388 
l0: 0.005745, l1: 0.006092, l2: 0.005249, l3: 0.004622, l4: 0.007421, l5: 0.008593, l6: 0.008700

[epoch: 134/100000, batch:   118/  187, ite: 12561] train loss: 0.066330, tar: 0.007385 
l0: 0.003038, l1: 0.003343, l2: 0.003840, l3: 0.003668, l4: 0.003602, l5: 0.003040, l6: 0.004003

[epoch: 134/100000, batch:   120/  187, ite: 12562] train loss: 0.066256, tar: 0.007378 
l0: 0.003902, l1: 0.004190, l2: 0.005442, l3: 0.005507, l4: 0.006833, l5: 0.006255, l6: 0.006812

[epoch: 134/100000, batch:   122/  187, ite: 12563] train loss: 0.066207, tar: 0.007372 
l0: 0.004969, l1: 0.005160, l2: 0.004706, l3: 0.005024, l4: 0.010841, l5: 0.009852, l6: 0.008783

[epoch: 134/100000, batch:   124/  187, ite: 12564] train loss: 0.066177, tar: 0.007367 
l0: 0.006556, l1: 0.006409, l2: 0.006207, l3: 0.006899, l4: 0.010709, l5: 0.009328, l6: 0.011960

[epoch: 134/100000, batch:   126/  187, ite: 12565] train loss: 0.066163, tar: 0.007366 
l0: 0.003472, l1: 0.003711, l2: 0.004726, l3: 0.004386, l4: 0.015303, l5: 0.012341, l6: 0.012257

[epoch: 134/100000, batch:   128/  187, ite: 12566] train loss: 0.066145, tar: 0.007359 
l0: 0.006053, l1: 0.006317, l2: 0.007443, l3: 0.006600, l4: 0.010826, l5: 0.009853, l6: 0.010220

[epoch: 134/100000, batch:   130/  187, ite: 12567] train loss: 0.066130, tar: 0.007357 
l0: 0.012011, l1: 0.012795, l2: 0.013573, l3: 0.013626, l4: 0.020543, l5: 0.016823, l6: 0.017496

[epoch: 134/100000, batch:   132/  187, ite: 12568] train loss: 0.066202, tar: 0.007365 
l0: 0.007317, l1: 0.007539, l2: 0.008061, l3: 0.008113, l4: 0.014921, l5: 0.013376, l6: 0.015023

[epoch: 134/100000, batch:   134/  187, ite: 12569] train loss: 0.066216, tar: 0.007365 
l0: 0.003497, l1: 0.003727, l2: 0.003856, l3: 0.003681, l4: 0.006220, l5: 0.005710, l6: 0.005958

[epoch: 134/100000, batch:   136/  187, ite: 12570] train loss: 0.066157, tar: 0.007358 
l0: 0.004614, l1: 0.004858, l2: 0.004968, l3: 0.005499, l4: 0.006332, l5: 0.006395, l6: 0.006398

[epoch: 134/100000, batch:   138/  187, ite: 12571] train loss: 0.066109, tar: 0.007353 
l0: 0.002402, l1: 0.002531, l2: 0.002680, l3: 0.002895, l4: 0.003636, l5: 0.003868, l6: 0.004566

[epoch: 134/100000, batch:   140/  187, ite: 12572] train loss: 0.066033, tar: 0.007345 
l0: 0.007079, l1: 0.007244, l2: 0.007220, l3: 0.006582, l4: 0.010374, l5: 0.008859, l6: 0.011845

[epoch: 134/100000, batch:   142/  187, ite: 12573] train loss: 0.066021, tar: 0.007344 
l0: 0.006830, l1: 0.006967, l2: 0.007224, l3: 0.007551, l4: 0.013747, l5: 0.010961, l6: 0.011636

[epoch: 134/100000, batch:   144/  187, ite: 12574] train loss: 0.066020, tar: 0.007343 
l0: 0.001902, l1: 0.002015, l2: 0.002246, l3: 0.002640, l4: 0.004216, l5: 0.003854, l6: 0.005143

[epoch: 134/100000, batch:   146/  187, ite: 12575] train loss: 0.065943, tar: 0.007334 
l0: 0.007079, l1: 0.006682, l2: 0.009865, l3: 0.010083, l4: 0.011562, l5: 0.010960, l6: 0.013002

[epoch: 134/100000, batch:   148/  187, ite: 12576] train loss: 0.065949, tar: 0.007333 
l0: 0.003963, l1: 0.004685, l2: 0.005253, l3: 0.004717, l4: 0.005837, l5: 0.004282, l6: 0.006328

[epoch: 134/100000, batch:   150/  187, ite: 12577] train loss: 0.065895, tar: 0.007327 
l0: 0.005727, l1: 0.006343, l2: 0.006656, l3: 0.005545, l4: 0.007706, l5: 0.008277, l6: 0.008362

[epoch: 134/100000, batch:   152/  187, ite: 12578] train loss: 0.065865, tar: 0.007325 
l0: 0.004131, l1: 0.004331, l2: 0.005252, l3: 0.004561, l4: 0.007152, l5: 0.006166, l6: 0.007463

[epoch: 134/100000, batch:   154/  187, ite: 12579] train loss: 0.065819, tar: 0.007319 
l0: 0.008044, l1: 0.008700, l2: 0.008341, l3: 0.008484, l4: 0.013109, l5: 0.011230, l6: 0.013735

[epoch: 134/100000, batch:   156/  187, ite: 12580] train loss: 0.065829, tar: 0.007320 
l0: 0.006283, l1: 0.005969, l2: 0.006346, l3: 0.006258, l4: 0.012207, l5: 0.010848, l6: 0.009444

[epoch: 134/100000, batch:   158/  187, ite: 12581] train loss: 0.065814, tar: 0.007319 
l0: 0.013608, l1: 0.014390, l2: 0.010870, l3: 0.012842, l4: 0.014940, l5: 0.016439, l6: 0.015464

[epoch: 134/100000, batch:   160/  187, ite: 12582] train loss: 0.065871, tar: 0.007329 
l0: 0.009682, l1: 0.009055, l2: 0.010907, l3: 0.010804, l4: 0.013274, l5: 0.013534, l6: 0.017100

[epoch: 134/100000, batch:   162/  187, ite: 12583] train loss: 0.065902, tar: 0.007333 
l0: 0.003639, l1: 0.003892, l2: 0.004008, l3: 0.004262, l4: 0.007543, l5: 0.006242, l6: 0.006827

[epoch: 134/100000, batch:   164/  187, ite: 12584] train loss: 0.065852, tar: 0.007327 
l0: 0.005834, l1: 0.005625, l2: 0.005930, l3: 0.005901, l4: 0.012259, l5: 0.013357, l6: 0.014008

[epoch: 134/100000, batch:   166/  187, ite: 12585] train loss: 0.065847, tar: 0.007325 
l0: 0.005662, l1: 0.005736, l2: 0.006020, l3: 0.006563, l4: 0.018146, l5: 0.013938, l6: 0.016261

[epoch: 134/100000, batch:   168/  187, ite: 12586] train loss: 0.065858, tar: 0.007322 
l0: 0.007623, l1: 0.007880, l2: 0.008274, l3: 0.008932, l4: 0.011228, l5: 0.012411, l6: 0.012027

[epoch: 134/100000, batch:   170/  187, ite: 12587] train loss: 0.065862, tar: 0.007322 
l0: 0.009562, l1: 0.009876, l2: 0.009898, l3: 0.009516, l4: 0.011568, l5: 0.011098, l6: 0.011073

[epoch: 134/100000, batch:   172/  187, ite: 12588] train loss: 0.065874, tar: 0.007326 
l0: 0.004835, l1: 0.005162, l2: 0.005891, l3: 0.005592, l4: 0.009470, l5: 0.008275, l6: 0.009567

[epoch: 134/100000, batch:   174/  187, ite: 12589] train loss: 0.065845, tar: 0.007322 
l0: 0.004118, l1: 0.004325, l2: 0.004184, l3: 0.003874, l4: 0.008402, l5: 0.011160, l6: 0.008818

[epoch: 134/100000, batch:   176/  187, ite: 12590] train loss: 0.065809, tar: 0.007316 
l0: 0.006758, l1: 0.006516, l2: 0.007508, l3: 0.007595, l4: 0.009397, l5: 0.009448, l6: 0.009138

[epoch: 134/100000, batch:   178/  187, ite: 12591] train loss: 0.065793, tar: 0.007315 
l0: 0.006204, l1: 0.005966, l2: 0.005065, l3: 0.008501, l4: 0.006294, l5: 0.007743, l6: 0.009375

[epoch: 134/100000, batch:   180/  187, ite: 12592] train loss: 0.065765, tar: 0.007314 
l0: 0.006647, l1: 0.007371, l2: 0.007286, l3: 0.006923, l4: 0.005227, l5: 0.004557, l6: 0.006007

[epoch: 134/100000, batch:   182/  187, ite: 12593] train loss: 0.065728, tar: 0.007312 
l0: 0.006132, l1: 0.006355, l2: 0.005902, l3: 0.006580, l4: 0.010097, l5: 0.009627, l6: 0.010824

[epoch: 134/100000, batch:   184/  187, ite: 12594] train loss: 0.065711, tar: 0.007310 
l0: 0.006689, l1: 0.006582, l2: 0.007050, l3: 0.006737, l4: 0.007882, l5: 0.008533, l6: 0.008345

[epoch: 134/100000, batch:   186/  187, ite: 12595] train loss: 0.065688, tar: 0.007309 
l0: 0.006714, l1: 0.008385, l2: 0.006674, l3: 0.008045, l4: 0.006036, l5: 0.005902, l6: 0.006873

[epoch: 134/100000, batch:   188/  187, ite: 12596] train loss: 0.065659, tar: 0.007308 
l0: 0.002533, l1: 0.002346, l2: 0.003078, l3: 0.003117, l4: 0.004184, l5: 0.004063, l6: 0.007328

[epoch: 135/100000, batch:     2/  187, ite: 12597] train loss: 0.065594, tar: 0.007300 
l0: 0.007175, l1: 0.007188, l2: 0.008332, l3: 0.008320, l4: 0.012847, l5: 0.009840, l6: 0.010203

[epoch: 135/100000, batch:     4/  187, ite: 12598] train loss: 0.065591, tar: 0.007300 
l0: 0.004354, l1: 0.004512, l2: 0.005292, l3: 0.004590, l4: 0.007914, l5: 0.006875, l6: 0.009685

[epoch: 135/100000, batch:     6/  187, ite: 12599] train loss: 0.065554, tar: 0.007295 
l0: 0.004626, l1: 0.005355, l2: 0.005278, l3: 0.005491, l4: 0.011078, l5: 0.007559, l6: 0.007009

[epoch: 135/100000, batch:     8/  187, ite: 12600] train loss: 0.065522, tar: 0.007291 
l0: 0.005477, l1: 0.005409, l2: 0.006813, l3: 0.006258, l4: 0.006979, l5: 0.007207, l6: 0.007622

[epoch: 135/100000, batch:    10/  187, ite: 12601] train loss: 0.065489, tar: 0.007288 
l0: 0.003907, l1: 0.003899, l2: 0.004203, l3: 0.004950, l4: 0.007035, l5: 0.006881, l6: 0.007229

[epoch: 135/100000, batch:    12/  187, ite: 12602] train loss: 0.065443, tar: 0.007282 
l0: 0.005417, l1: 0.005224, l2: 0.005419, l3: 0.005956, l4: 0.010065, l5: 0.011924, l6: 0.008689

[epoch: 135/100000, batch:    14/  187, ite: 12603] train loss: 0.065422, tar: 0.007279 
l0: 0.005957, l1: 0.006862, l2: 0.007474, l3: 0.006984, l4: 0.009104, l5: 0.007609, l6: 0.007902

[epoch: 135/100000, batch:    16/  187, ite: 12604] train loss: 0.065400, tar: 0.007277 
l0: 0.009012, l1: 0.009354, l2: 0.007952, l3: 0.008647, l4: 0.012175, l5: 0.012176, l6: 0.012950

[epoch: 135/100000, batch:    18/  187, ite: 12605] train loss: 0.065411, tar: 0.007280 
l0: 0.006818, l1: 0.006832, l2: 0.006313, l3: 0.007031, l4: 0.011774, l5: 0.012228, l6: 0.013423

[epoch: 135/100000, batch:    20/  187, ite: 12606] train loss: 0.065410, tar: 0.007279 
l0: 0.006905, l1: 0.007280, l2: 0.007441, l3: 0.007970, l4: 0.011556, l5: 0.011736, l6: 0.012358

[epoch: 135/100000, batch:    22/  187, ite: 12607] train loss: 0.065409, tar: 0.007278 
l0: 0.007738, l1: 0.008267, l2: 0.008600, l3: 0.008799, l4: 0.010901, l5: 0.009581, l6: 0.010685

[epoch: 135/100000, batch:    24/  187, ite: 12608] train loss: 0.065408, tar: 0.007279 
l0: 0.006208, l1: 0.006707, l2: 0.007558, l3: 0.006119, l4: 0.007979, l5: 0.008163, l6: 0.008169

[epoch: 135/100000, batch:    26/  187, ite: 12609] train loss: 0.065384, tar: 0.007277 
l0: 0.004553, l1: 0.004765, l2: 0.004781, l3: 0.004968, l4: 0.005819, l5: 0.005998, l6: 0.007362

[epoch: 135/100000, batch:    28/  187, ite: 12610] train loss: 0.065340, tar: 0.007273 
l0: 0.004287, l1: 0.004211, l2: 0.005183, l3: 0.005953, l4: 0.007370, l5: 0.006583, l6: 0.007430

[epoch: 135/100000, batch:    30/  187, ite: 12611] train loss: 0.065300, tar: 0.007268 
l0: 0.005341, l1: 0.005380, l2: 0.007785, l3: 0.006905, l4: 0.007402, l5: 0.007613, l6: 0.006777

[epoch: 135/100000, batch:    32/  187, ite: 12612] train loss: 0.065270, tar: 0.007265 
l0: 0.009632, l1: 0.009228, l2: 0.009730, l3: 0.010032, l4: 0.014503, l5: 0.014550, l6: 0.016336

[epoch: 135/100000, batch:    34/  187, ite: 12613] train loss: 0.065301, tar: 0.007269 
l0: 0.005362, l1: 0.005598, l2: 0.005019, l3: 0.005359, l4: 0.007215, l5: 0.008676, l6: 0.010210

[epoch: 135/100000, batch:    36/  187, ite: 12614] train loss: 0.065272, tar: 0.007266 
l0: 0.007890, l1: 0.008345, l2: 0.007915, l3: 0.007762, l4: 0.009432, l5: 0.008261, l6: 0.008464

[epoch: 135/100000, batch:    38/  187, ite: 12615] train loss: 0.065260, tar: 0.007267 
l0: 0.011576, l1: 0.011120, l2: 0.011620, l3: 0.011642, l4: 0.022506, l5: 0.017815, l6: 0.021852

[epoch: 135/100000, batch:    40/  187, ite: 12616] train loss: 0.065330, tar: 0.007274 
l0: 0.003626, l1: 0.003625, l2: 0.003240, l3: 0.003663, l4: 0.011745, l5: 0.008255, l6: 0.007876

[epoch: 135/100000, batch:    42/  187, ite: 12617] train loss: 0.065292, tar: 0.007268 
l0: 0.009025, l1: 0.009164, l2: 0.008528, l3: 0.008482, l4: 0.012028, l5: 0.011202, l6: 0.012284

[epoch: 135/100000, batch:    44/  187, ite: 12618] train loss: 0.065301, tar: 0.007271 
l0: 0.005838, l1: 0.006028, l2: 0.005828, l3: 0.005959, l4: 0.007398, l5: 0.006855, l6: 0.009837

[epoch: 135/100000, batch:    46/  187, ite: 12619] train loss: 0.065272, tar: 0.007268 
l0: 0.006284, l1: 0.006578, l2: 0.006611, l3: 0.006485, l4: 0.009214, l5: 0.008649, l6: 0.009441

[epoch: 135/100000, batch:    48/  187, ite: 12620] train loss: 0.065253, tar: 0.007267 
l0: 0.003671, l1: 0.004323, l2: 0.005307, l3: 0.003786, l4: 0.005272, l5: 0.005556, l6: 0.005232

[epoch: 135/100000, batch:    50/  187, ite: 12621] train loss: 0.065201, tar: 0.007261 
l0: 0.002274, l1: 0.002366, l2: 0.002406, l3: 0.002522, l4: 0.004457, l5: 0.004030, l6: 0.005107

[epoch: 135/100000, batch:    52/  187, ite: 12622] train loss: 0.065134, tar: 0.007253 
l0: 0.003671, l1: 0.003778, l2: 0.004246, l3: 0.004206, l4: 0.007497, l5: 0.007437, l6: 0.007637

[epoch: 135/100000, batch:    54/  187, ite: 12623] train loss: 0.065091, tar: 0.007247 
l0: 0.003988, l1: 0.003329, l2: 0.004117, l3: 0.004964, l4: 0.011066, l5: 0.011204, l6: 0.013464

[epoch: 135/100000, batch:    56/  187, ite: 12624] train loss: 0.065070, tar: 0.007242 
l0: 0.005338, l1: 0.005429, l2: 0.005041, l3: 0.005780, l4: 0.008665, l5: 0.009061, l6: 0.008763

[epoch: 135/100000, batch:    58/  187, ite: 12625] train loss: 0.065043, tar: 0.007239 
l0: 0.004365, l1: 0.004576, l2: 0.004649, l3: 0.004695, l4: 0.008679, l5: 0.008685, l6: 0.008297

[epoch: 135/100000, batch:    60/  187, ite: 12626] train loss: 0.065009, tar: 0.007234 
l0: 0.006476, l1: 0.005878, l2: 0.007078, l3: 0.009191, l4: 0.013599, l5: 0.013322, l6: 0.015210

[epoch: 135/100000, batch:    62/  187, ite: 12627] train loss: 0.065018, tar: 0.007233 
l0: 0.007711, l1: 0.007969, l2: 0.009171, l3: 0.010411, l4: 0.011432, l5: 0.010504, l6: 0.013320

[epoch: 135/100000, batch:    64/  187, ite: 12628] train loss: 0.065027, tar: 0.007234 
l0: 0.007787, l1: 0.007719, l2: 0.008545, l3: 0.008381, l4: 0.019045, l5: 0.018699, l6: 0.016075

[epoch: 135/100000, batch:    66/  187, ite: 12629] train loss: 0.065061, tar: 0.007235 
l0: 0.002167, l1: 0.002476, l2: 0.002992, l3: 0.003315, l4: 0.005534, l5: 0.005813, l6: 0.005337

[epoch: 135/100000, batch:    68/  187, ite: 12630] train loss: 0.065001, tar: 0.007227 
l0: 0.003856, l1: 0.004311, l2: 0.004600, l3: 0.004587, l4: 0.006088, l5: 0.004850, l6: 0.005378

[epoch: 135/100000, batch:    70/  187, ite: 12631] train loss: 0.064952, tar: 0.007221 
l0: 0.009174, l1: 0.008791, l2: 0.011064, l3: 0.010277, l4: 0.011267, l5: 0.011977, l6: 0.014546

[epoch: 135/100000, batch:    72/  187, ite: 12632] train loss: 0.064971, tar: 0.007224 
l0: 0.014621, l1: 0.015452, l2: 0.014944, l3: 0.016343, l4: 0.015945, l5: 0.016318, l6: 0.016768

[epoch: 135/100000, batch:    74/  187, ite: 12633] train loss: 0.065043, tar: 0.007236 
l0: 0.009092, l1: 0.009453, l2: 0.010441, l3: 0.009086, l4: 0.011173, l5: 0.010329, l6: 0.012594

[epoch: 135/100000, batch:    76/  187, ite: 12634] train loss: 0.065054, tar: 0.007239 
l0: 0.004214, l1: 0.005035, l2: 0.005387, l3: 0.005373, l4: 0.005447, l5: 0.004915, l6: 0.004472

[epoch: 135/100000, batch:    78/  187, ite: 12635] train loss: 0.065006, tar: 0.007234 
l0: 0.008593, l1: 0.008810, l2: 0.009028, l3: 0.008520, l4: 0.010939, l5: 0.010638, l6: 0.011977

[epoch: 135/100000, batch:    80/  187, ite: 12636] train loss: 0.065012, tar: 0.007236 
l0: 0.001760, l1: 0.001783, l2: 0.001914, l3: 0.002275, l4: 0.005863, l5: 0.004828, l6: 0.004613

[epoch: 135/100000, batch:    82/  187, ite: 12637] train loss: 0.064946, tar: 0.007228 
l0: 0.003956, l1: 0.003525, l2: 0.004427, l3: 0.004390, l4: 0.007069, l5: 0.008548, l6: 0.011558

[epoch: 135/100000, batch:    84/  187, ite: 12638] train loss: 0.064912, tar: 0.007223 
l0: 0.010521, l1: 0.009320, l2: 0.011947, l3: 0.012180, l4: 0.016176, l5: 0.016542, l6: 0.019704

[epoch: 135/100000, batch:    86/  187, ite: 12639] train loss: 0.064962, tar: 0.007228 
l0: 0.009950, l1: 0.010144, l2: 0.011727, l3: 0.012527, l4: 0.012183, l5: 0.011181, l6: 0.012472

[epoch: 135/100000, batch:    88/  187, ite: 12640] train loss: 0.064985, tar: 0.007232 
l0: 0.004509, l1: 0.004830, l2: 0.004353, l3: 0.004653, l4: 0.008589, l5: 0.007081, l6: 0.007711

[epoch: 135/100000, batch:    90/  187, ite: 12641] train loss: 0.064949, tar: 0.007228 
l0: 0.008165, l1: 0.008472, l2: 0.009271, l3: 0.010298, l4: 0.012911, l5: 0.012605, l6: 0.013293

[epoch: 135/100000, batch:    92/  187, ite: 12642] train loss: 0.064965, tar: 0.007229 
l0: 0.008014, l1: 0.008263, l2: 0.007759, l3: 0.009603, l4: 0.012960, l5: 0.012271, l6: 0.011671

[epoch: 135/100000, batch:    94/  187, ite: 12643] train loss: 0.064973, tar: 0.007231 
l0: 0.007215, l1: 0.007478, l2: 0.006968, l3: 0.007208, l4: 0.011819, l5: 0.012144, l6: 0.013413

[epoch: 135/100000, batch:    96/  187, ite: 12644] train loss: 0.064975, tar: 0.007230 
l0: 0.005666, l1: 0.006066, l2: 0.005573, l3: 0.006299, l4: 0.011044, l5: 0.010567, l6: 0.012244

[epoch: 135/100000, batch:    98/  187, ite: 12645] train loss: 0.064964, tar: 0.007228 
l0: 0.005225, l1: 0.005692, l2: 0.005820, l3: 0.005471, l4: 0.007886, l5: 0.007688, l6: 0.007583

[epoch: 135/100000, batch:   100/  187, ite: 12646] train loss: 0.064933, tar: 0.007225 
l0: 0.007014, l1: 0.006881, l2: 0.007466, l3: 0.008760, l4: 0.009380, l5: 0.009076, l6: 0.011354

[epoch: 135/100000, batch:   102/  187, ite: 12647] train loss: 0.064926, tar: 0.007225 
l0: 0.007419, l1: 0.007385, l2: 0.007362, l3: 0.008415, l4: 0.010207, l5: 0.010131, l6: 0.010651

[epoch: 135/100000, batch:   104/  187, ite: 12648] train loss: 0.064921, tar: 0.007225 
l0: 0.010104, l1: 0.010223, l2: 0.010987, l3: 0.010803, l4: 0.011769, l5: 0.011369, l6: 0.011720

[epoch: 135/100000, batch:   106/  187, ite: 12649] train loss: 0.064939, tar: 0.007229 
l0: 0.005193, l1: 0.005265, l2: 0.005707, l3: 0.006228, l4: 0.007046, l5: 0.007393, l6: 0.007167

[epoch: 135/100000, batch:   108/  187, ite: 12650] train loss: 0.064907, tar: 0.007226 
l0: 0.006952, l1: 0.006846, l2: 0.007744, l3: 0.008350, l4: 0.015779, l5: 0.013481, l6: 0.015524

[epoch: 135/100000, batch:   110/  187, ite: 12651] train loss: 0.064922, tar: 0.007226 
l0: 0.006844, l1: 0.006601, l2: 0.007642, l3: 0.008905, l4: 0.007732, l5: 0.008140, l6: 0.009108

[epoch: 135/100000, batch:   112/  187, ite: 12652] train loss: 0.064907, tar: 0.007225 
l0: 0.003970, l1: 0.004442, l2: 0.004827, l3: 0.004572, l4: 0.007594, l5: 0.007737, l6: 0.009767

[epoch: 135/100000, batch:   114/  187, ite: 12653] train loss: 0.064873, tar: 0.007220 
l0: 0.005192, l1: 0.005980, l2: 0.004748, l3: 0.003614, l4: 0.007196, l5: 0.006212, l6: 0.006810

[epoch: 135/100000, batch:   116/  187, ite: 12654] train loss: 0.064835, tar: 0.007217 
l0: 0.003227, l1: 0.004003, l2: 0.002884, l3: 0.002971, l4: 0.003813, l5: 0.003686, l6: 0.004645

[epoch: 135/100000, batch:   118/  187, ite: 12655] train loss: 0.064774, tar: 0.007211 
l0: 0.001848, l1: 0.001844, l2: 0.001915, l3: 0.002790, l4: 0.003117, l5: 0.002524, l6: 0.002983

[epoch: 135/100000, batch:   120/  187, ite: 12656] train loss: 0.064701, tar: 0.007203 
l0: 0.004996, l1: 0.005056, l2: 0.005118, l3: 0.005557, l4: 0.009621, l5: 0.014060, l6: 0.013301

[epoch: 135/100000, batch:   122/  187, ite: 12657] train loss: 0.064691, tar: 0.007200 
l0: 0.004492, l1: 0.005230, l2: 0.004917, l3: 0.006155, l4: 0.006247, l5: 0.005745, l6: 0.007983

[epoch: 135/100000, batch:   124/  187, ite: 12658] train loss: 0.064654, tar: 0.007195 
l0: 0.011780, l1: 0.011252, l2: 0.012878, l3: 0.011974, l4: 0.020426, l5: 0.023925, l6: 0.019620

[epoch: 135/100000, batch:   126/  187, ite: 12659] train loss: 0.064726, tar: 0.007202 
l0: 0.003772, l1: 0.004204, l2: 0.003768, l3: 0.004389, l4: 0.004714, l5: 0.004235, l6: 0.006124

[epoch: 135/100000, batch:   128/  187, ite: 12660] train loss: 0.064675, tar: 0.007197 
l0: 0.002914, l1: 0.003125, l2: 0.002847, l3: 0.003263, l4: 0.004094, l5: 0.003263, l6: 0.004547

[epoch: 135/100000, batch:   130/  187, ite: 12661] train loss: 0.064614, tar: 0.007191 
l0: 0.006310, l1: 0.005692, l2: 0.006910, l3: 0.005568, l4: 0.013389, l5: 0.012294, l6: 0.015734

[epoch: 135/100000, batch:   132/  187, ite: 12662] train loss: 0.064616, tar: 0.007189 
l0: 0.004691, l1: 0.005124, l2: 0.004546, l3: 0.004696, l4: 0.007505, l5: 0.006895, l6: 0.008687

[epoch: 135/100000, batch:   134/  187, ite: 12663] train loss: 0.064582, tar: 0.007186 
l0: 0.009293, l1: 0.009516, l2: 0.010762, l3: 0.010360, l4: 0.010066, l5: 0.009555, l6: 0.011199

[epoch: 135/100000, batch:   136/  187, ite: 12664] train loss: 0.064591, tar: 0.007189 
l0: 0.007542, l1: 0.007968, l2: 0.008234, l3: 0.008444, l4: 0.009367, l5: 0.009375, l6: 0.010232

[epoch: 135/100000, batch:   138/  187, ite: 12665] train loss: 0.064586, tar: 0.007189 
l0: 0.005843, l1: 0.005804, l2: 0.006852, l3: 0.007209, l4: 0.007951, l5: 0.006931, l6: 0.008685

[epoch: 135/100000, batch:   140/  187, ite: 12666] train loss: 0.064563, tar: 0.007187 
l0: 0.006603, l1: 0.007173, l2: 0.007401, l3: 0.006520, l4: 0.008562, l5: 0.008167, l6: 0.011609

[epoch: 135/100000, batch:   142/  187, ite: 12667] train loss: 0.064550, tar: 0.007186 
l0: 0.005530, l1: 0.005066, l2: 0.005464, l3: 0.007108, l4: 0.009893, l5: 0.008982, l6: 0.009356

[epoch: 135/100000, batch:   144/  187, ite: 12668] train loss: 0.064530, tar: 0.007184 
l0: 0.003180, l1: 0.003525, l2: 0.003696, l3: 0.003397, l4: 0.006482, l5: 0.004617, l6: 0.005928

[epoch: 135/100000, batch:   146/  187, ite: 12669] train loss: 0.064480, tar: 0.007178 
l0: 0.003045, l1: 0.003418, l2: 0.003236, l3: 0.002952, l4: 0.004985, l5: 0.005325, l6: 0.006412

[epoch: 135/100000, batch:   148/  187, ite: 12670] train loss: 0.064428, tar: 0.007172 
l0: 0.005272, l1: 0.005277, l2: 0.005273, l3: 0.005811, l4: 0.007519, l5: 0.007777, l6: 0.009190

[epoch: 135/100000, batch:   150/  187, ite: 12671] train loss: 0.064400, tar: 0.007169 
l0: 0.006646, l1: 0.006688, l2: 0.007938, l3: 0.008383, l4: 0.008874, l5: 0.009647, l6: 0.010305

[epoch: 135/100000, batch:   152/  187, ite: 12672] train loss: 0.064391, tar: 0.007168 
l0: 0.003180, l1: 0.003241, l2: 0.002604, l3: 0.002656, l4: 0.004020, l5: 0.003851, l6: 0.004930

[epoch: 135/100000, batch:   154/  187, ite: 12673] train loss: 0.064332, tar: 0.007162 
l0: 0.004968, l1: 0.005466, l2: 0.005925, l3: 0.006648, l4: 0.007932, l5: 0.006614, l6: 0.006680

[epoch: 135/100000, batch:   156/  187, ite: 12674] train loss: 0.064302, tar: 0.007159 
l0: 0.010982, l1: 0.010920, l2: 0.009916, l3: 0.011445, l4: 0.015326, l5: 0.015271, l6: 0.015417

[epoch: 135/100000, batch:   158/  187, ite: 12675] train loss: 0.064339, tar: 0.007165 
l0: 0.005178, l1: 0.005743, l2: 0.005402, l3: 0.004644, l4: 0.012811, l5: 0.010278, l6: 0.008448

[epoch: 135/100000, batch:   160/  187, ite: 12676] train loss: 0.064322, tar: 0.007162 
l0: 0.004388, l1: 0.004038, l2: 0.004027, l3: 0.004224, l4: 0.008502, l5: 0.007877, l6: 0.011883

[epoch: 135/100000, batch:   162/  187, ite: 12677] train loss: 0.064293, tar: 0.007158 
l0: 0.004477, l1: 0.004617, l2: 0.004887, l3: 0.005435, l4: 0.007822, l5: 0.008705, l6: 0.009245

[epoch: 135/100000, batch:   164/  187, ite: 12678] train loss: 0.064265, tar: 0.007154 
l0: 0.003922, l1: 0.003910, l2: 0.004985, l3: 0.004217, l4: 0.007139, l5: 0.006740, l6: 0.007809

[epoch: 135/100000, batch:   166/  187, ite: 12679] train loss: 0.064227, tar: 0.007149 
l0: 0.005949, l1: 0.006341, l2: 0.006803, l3: 0.006522, l4: 0.008086, l5: 0.007364, l6: 0.008435

[epoch: 135/100000, batch:   168/  187, ite: 12680] train loss: 0.064206, tar: 0.007147 
l0: 0.006959, l1: 0.006196, l2: 0.008368, l3: 0.007805, l4: 0.010270, l5: 0.014306, l6: 0.014561

[epoch: 135/100000, batch:   170/  187, ite: 12681] train loss: 0.064212, tar: 0.007147 
l0: 0.011651, l1: 0.010664, l2: 0.011816, l3: 0.013032, l4: 0.014435, l5: 0.015573, l6: 0.019590

[epoch: 135/100000, batch:   172/  187, ite: 12682] train loss: 0.064260, tar: 0.007153 
l0: 0.004446, l1: 0.004235, l2: 0.005658, l3: 0.006428, l4: 0.006016, l5: 0.006422, l6: 0.006022

[epoch: 135/100000, batch:   174/  187, ite: 12683] train loss: 0.064223, tar: 0.007149 
l0: 0.004151, l1: 0.004843, l2: 0.004649, l3: 0.005356, l4: 0.010870, l5: 0.006890, l6: 0.005325

[epoch: 135/100000, batch:   176/  187, ite: 12684] train loss: 0.064191, tar: 0.007145 
l0: 0.006827, l1: 0.007330, l2: 0.009255, l3: 0.008292, l4: 0.009583, l5: 0.009363, l6: 0.009072

[epoch: 135/100000, batch:   178/  187, ite: 12685] train loss: 0.064184, tar: 0.007145 
l0: 0.007752, l1: 0.009213, l2: 0.008065, l3: 0.007520, l4: 0.009488, l5: 0.010007, l6: 0.011711

[epoch: 135/100000, batch:   180/  187, ite: 12686] train loss: 0.064184, tar: 0.007146 
l0: 0.004703, l1: 0.004767, l2: 0.004831, l3: 0.004372, l4: 0.008337, l5: 0.007673, l6: 0.008412

[epoch: 135/100000, batch:   182/  187, ite: 12687] train loss: 0.064153, tar: 0.007142 
l0: 0.005089, l1: 0.005008, l2: 0.005741, l3: 0.005726, l4: 0.008865, l5: 0.008699, l6: 0.008602

[epoch: 135/100000, batch:   184/  187, ite: 12688] train loss: 0.064129, tar: 0.007139 
l0: 0.009343, l1: 0.009162, l2: 0.008399, l3: 0.009651, l4: 0.013294, l5: 0.013526, l6: 0.015707

[epoch: 135/100000, batch:   186/  187, ite: 12689] train loss: 0.064151, tar: 0.007142 
l0: 0.015226, l1: 0.015088, l2: 0.015076, l3: 0.015373, l4: 0.019880, l5: 0.019544, l6: 0.015781

[epoch: 135/100000, batch:   188/  187, ite: 12690] train loss: 0.064226, tar: 0.007154 
l0: 0.003009, l1: 0.003453, l2: 0.002677, l3: 0.003182, l4: 0.007749, l5: 0.004881, l6: 0.006180

[epoch: 136/100000, batch:     2/  187, ite: 12691] train loss: 0.064178, tar: 0.007148 
l0: 0.011006, l1: 0.009859, l2: 0.012015, l3: 0.012048, l4: 0.019386, l5: 0.019017, l6: 0.022404

[epoch: 136/100000, batch:     4/  187, ite: 12692] train loss: 0.064238, tar: 0.007153 
l0: 0.014736, l1: 0.014638, l2: 0.018822, l3: 0.020159, l4: 0.019356, l5: 0.017039, l6: 0.012576

[epoch: 136/100000, batch:     6/  187, ite: 12693] train loss: 0.064315, tar: 0.007164 
l0: 0.003566, l1: 0.003597, l2: 0.004260, l3: 0.003912, l4: 0.005923, l5: 0.006453, l6: 0.009838

[epoch: 136/100000, batch:     8/  187, ite: 12694] train loss: 0.064276, tar: 0.007159 
l0: 0.003197, l1: 0.003217, l2: 0.005059, l3: 0.004972, l4: 0.009971, l5: 0.007363, l6: 0.007629

[epoch: 136/100000, batch:    10/  187, ite: 12695] train loss: 0.064243, tar: 0.007154 
l0: 0.007547, l1: 0.007200, l2: 0.008448, l3: 0.008543, l4: 0.012079, l5: 0.012834, l6: 0.016321

[epoch: 136/100000, batch:    12/  187, ite: 12696] train loss: 0.064256, tar: 0.007154 
l0: 0.012205, l1: 0.012480, l2: 0.013417, l3: 0.015340, l4: 0.013554, l5: 0.011969, l6: 0.011329

[epoch: 136/100000, batch:    14/  187, ite: 12697] train loss: 0.064293, tar: 0.007161 
l0: 0.005101, l1: 0.005483, l2: 0.005421, l3: 0.005036, l4: 0.007040, l5: 0.007775, l6: 0.009783

[epoch: 136/100000, batch:    16/  187, ite: 12698] train loss: 0.064266, tar: 0.007158 
l0: 0.004629, l1: 0.004992, l2: 0.005944, l3: 0.005757, l4: 0.007463, l5: 0.006408, l6: 0.006950

[epoch: 136/100000, batch:    18/  187, ite: 12699] train loss: 0.064235, tar: 0.007155 
l0: 0.006565, l1: 0.006369, l2: 0.006587, l3: 0.007199, l4: 0.007411, l5: 0.008065, l6: 0.009441

[epoch: 136/100000, batch:    20/  187, ite: 12700] train loss: 0.064217, tar: 0.007154 
l0: 0.004818, l1: 0.005193, l2: 0.004725, l3: 0.005507, l4: 0.005603, l5: 0.006079, l6: 0.006259

[epoch: 136/100000, batch:    22/  187, ite: 12701] train loss: 0.064180, tar: 0.007151 
l0: 0.006383, l1: 0.006430, l2: 0.006654, l3: 0.006432, l4: 0.012003, l5: 0.011059, l6: 0.011431

[epoch: 136/100000, batch:    24/  187, ite: 12702] train loss: 0.064174, tar: 0.007150 
l0: 0.002529, l1: 0.002696, l2: 0.003007, l3: 0.003173, l4: 0.007252, l5: 0.006516, l6: 0.007442

[epoch: 136/100000, batch:    26/  187, ite: 12703] train loss: 0.064129, tar: 0.007143 
l0: 0.003236, l1: 0.003574, l2: 0.004078, l3: 0.003530, l4: 0.005057, l5: 0.005192, l6: 0.004577

[epoch: 136/100000, batch:    28/  187, ite: 12704] train loss: 0.064080, tar: 0.007137 
l0: 0.004229, l1: 0.004882, l2: 0.005027, l3: 0.004416, l4: 0.007486, l5: 0.006439, l6: 0.006583

[epoch: 136/100000, batch:    30/  187, ite: 12705] train loss: 0.064044, tar: 0.007133 
l0: 0.005392, l1: 0.005518, l2: 0.005552, l3: 0.006508, l4: 0.012222, l5: 0.010690, l6: 0.012904

[epoch: 136/100000, batch:    32/  187, ite: 12706] train loss: 0.064037, tar: 0.007131 
l0: 0.004185, l1: 0.004673, l2: 0.005107, l3: 0.005188, l4: 0.006414, l5: 0.007215, l6: 0.005806

[epoch: 136/100000, batch:    34/  187, ite: 12707] train loss: 0.064001, tar: 0.007127 
l0: 0.011409, l1: 0.011814, l2: 0.012783, l3: 0.013619, l4: 0.015702, l5: 0.016757, l6: 0.019217

[epoch: 136/100000, batch:    36/  187, ite: 12708] train loss: 0.064053, tar: 0.007133 
l0: 0.007626, l1: 0.007548, l2: 0.008333, l3: 0.008065, l4: 0.009616, l5: 0.011079, l6: 0.011789

[epoch: 136/100000, batch:    38/  187, ite: 12709] train loss: 0.064053, tar: 0.007133 
l0: 0.002213, l1: 0.002168, l2: 0.002024, l3: 0.002034, l4: 0.004096, l5: 0.003993, l6: 0.003376

[epoch: 136/100000, batch:    40/  187, ite: 12710] train loss: 0.063991, tar: 0.007126 
l0: 0.003967, l1: 0.004409, l2: 0.004317, l3: 0.004660, l4: 0.008264, l5: 0.008405, l6: 0.010366

[epoch: 136/100000, batch:    42/  187, ite: 12711] train loss: 0.063964, tar: 0.007122 
l0: 0.007480, l1: 0.007122, l2: 0.010908, l3: 0.009329, l4: 0.014472, l5: 0.015296, l6: 0.018960

[epoch: 136/100000, batch:    44/  187, ite: 12712] train loss: 0.063991, tar: 0.007123 
l0: 0.009522, l1: 0.010181, l2: 0.009901, l3: 0.010507, l4: 0.014020, l5: 0.012188, l6: 0.012679

[epoch: 136/100000, batch:    46/  187, ite: 12713] train loss: 0.064012, tar: 0.007126 
l0: 0.008660, l1: 0.009080, l2: 0.008284, l3: 0.009262, l4: 0.018729, l5: 0.017680, l6: 0.020874

[epoch: 136/100000, batch:    48/  187, ite: 12714] train loss: 0.064052, tar: 0.007128 
l0: 0.006004, l1: 0.006271, l2: 0.006573, l3: 0.006690, l4: 0.008855, l5: 0.008423, l6: 0.009172

[epoch: 136/100000, batch:    50/  187, ite: 12715] train loss: 0.064035, tar: 0.007126 
l0: 0.007045, l1: 0.006978, l2: 0.006510, l3: 0.006871, l4: 0.011042, l5: 0.012926, l6: 0.014547

[epoch: 136/100000, batch:    52/  187, ite: 12716] train loss: 0.064038, tar: 0.007126 
l0: 0.006220, l1: 0.006735, l2: 0.006900, l3: 0.007312, l4: 0.012538, l5: 0.012242, l6: 0.013179

[epoch: 136/100000, batch:    54/  187, ite: 12717] train loss: 0.064040, tar: 0.007125 
l0: 0.006696, l1: 0.006790, l2: 0.006919, l3: 0.006607, l4: 0.008822, l5: 0.008153, l6: 0.008732

[epoch: 136/100000, batch:    56/  187, ite: 12718] train loss: 0.064024, tar: 0.007124 
l0: 0.010799, l1: 0.011293, l2: 0.011088, l3: 0.011450, l4: 0.013442, l5: 0.013674, l6: 0.014610

[epoch: 136/100000, batch:    58/  187, ite: 12719] train loss: 0.064055, tar: 0.007130 
l0: 0.013058, l1: 0.012865, l2: 0.012102, l3: 0.012391, l4: 0.016761, l5: 0.015179, l6: 0.018273

[epoch: 136/100000, batch:    60/  187, ite: 12720] train loss: 0.064106, tar: 0.007138 
l0: 0.007631, l1: 0.007544, l2: 0.007510, l3: 0.008517, l4: 0.021264, l5: 0.021276, l6: 0.016508

[epoch: 136/100000, batch:    62/  187, ite: 12721] train loss: 0.064142, tar: 0.007138 
l0: 0.004400, l1: 0.005405, l2: 0.004137, l3: 0.003920, l4: 0.006728, l5: 0.005586, l6: 0.007322

[epoch: 136/100000, batch:    64/  187, ite: 12722] train loss: 0.064105, tar: 0.007135 
l0: 0.003722, l1: 0.004039, l2: 0.003711, l3: 0.003809, l4: 0.005985, l5: 0.005147, l6: 0.004821

[epoch: 136/100000, batch:    66/  187, ite: 12723] train loss: 0.064060, tar: 0.007130 
l0: 0.008363, l1: 0.009058, l2: 0.008933, l3: 0.008450, l4: 0.010708, l5: 0.011814, l6: 0.011739

[epoch: 136/100000, batch:    68/  187, ite: 12724] train loss: 0.064066, tar: 0.007132 
l0: 0.004950, l1: 0.004850, l2: 0.004014, l3: 0.004649, l4: 0.008225, l5: 0.009686, l6: 0.007027

[epoch: 136/100000, batch:    70/  187, ite: 12725] train loss: 0.064038, tar: 0.007129 
l0: 0.007083, l1: 0.007426, l2: 0.007669, l3: 0.007850, l4: 0.008826, l5: 0.009171, l6: 0.012360

[epoch: 136/100000, batch:    72/  187, ite: 12726] train loss: 0.064033, tar: 0.007129 
l0: 0.008494, l1: 0.008723, l2: 0.009123, l3: 0.009421, l4: 0.012415, l5: 0.011297, l6: 0.011892

[epoch: 136/100000, batch:    74/  187, ite: 12727] train loss: 0.064043, tar: 0.007130 
l0: 0.006669, l1: 0.006582, l2: 0.007446, l3: 0.007257, l4: 0.007882, l5: 0.009557, l6: 0.009571

[epoch: 136/100000, batch:    76/  187, ite: 12728] train loss: 0.064030, tar: 0.007130 
l0: 0.010389, l1: 0.011645, l2: 0.011071, l3: 0.011593, l4: 0.017144, l5: 0.014843, l6: 0.014629

[epoch: 136/100000, batch:    78/  187, ite: 12729] train loss: 0.064068, tar: 0.007134 
l0: 0.005469, l1: 0.006492, l2: 0.005979, l3: 0.005393, l4: 0.008860, l5: 0.007342, l6: 0.008368

[epoch: 136/100000, batch:    80/  187, ite: 12730] train loss: 0.064046, tar: 0.007132 
l0: 0.003189, l1: 0.002831, l2: 0.003093, l3: 0.003959, l4: 0.004761, l5: 0.004406, l6: 0.008507

[epoch: 136/100000, batch:    82/  187, ite: 12731] train loss: 0.064000, tar: 0.007127 
l0: 0.013995, l1: 0.013848, l2: 0.024384, l3: 0.024614, l4: 0.022443, l5: 0.022567, l6: 0.022042

[epoch: 136/100000, batch:    84/  187, ite: 12732] train loss: 0.064109, tar: 0.007136 
l0: 0.008816, l1: 0.008560, l2: 0.008186, l3: 0.008819, l4: 0.017429, l5: 0.016453, l6: 0.019529

[epoch: 136/100000, batch:    86/  187, ite: 12733] train loss: 0.064142, tar: 0.007138 
l0: 0.006510, l1: 0.006656, l2: 0.007783, l3: 0.007596, l4: 0.014262, l5: 0.012443, l6: 0.012458

[epoch: 136/100000, batch:    88/  187, ite: 12734] train loss: 0.064147, tar: 0.007137 
l0: 0.005583, l1: 0.005014, l2: 0.006546, l3: 0.006410, l4: 0.013646, l5: 0.016145, l6: 0.019223

[epoch: 136/100000, batch:    90/  187, ite: 12735] train loss: 0.064158, tar: 0.007135 
l0: 0.008654, l1: 0.009558, l2: 0.009471, l3: 0.009309, l4: 0.007070, l5: 0.007318, l6: 0.008539

[epoch: 136/100000, batch:    92/  187, ite: 12736] train loss: 0.064152, tar: 0.007137 
l0: 0.010357, l1: 0.011526, l2: 0.011225, l3: 0.011163, l4: 0.013902, l5: 0.013377, l6: 0.015534

[epoch: 136/100000, batch:    94/  187, ite: 12737] train loss: 0.064183, tar: 0.007142 
l0: 0.008446, l1: 0.008109, l2: 0.008743, l3: 0.010171, l4: 0.015001, l5: 0.014740, l6: 0.012708

[epoch: 136/100000, batch:    96/  187, ite: 12738] train loss: 0.064202, tar: 0.007144 
l0: 0.004208, l1: 0.004535, l2: 0.004754, l3: 0.005229, l4: 0.005658, l5: 0.004671, l6: 0.006467

[epoch: 136/100000, batch:    98/  187, ite: 12739] train loss: 0.064163, tar: 0.007140 
l0: 0.009219, l1: 0.009864, l2: 0.011470, l3: 0.011117, l4: 0.014367, l5: 0.013928, l6: 0.014805

[epoch: 136/100000, batch:   100/  187, ite: 12740] train loss: 0.064191, tar: 0.007142 
l0: 0.011621, l1: 0.011538, l2: 0.014726, l3: 0.012642, l4: 0.011278, l5: 0.013173, l6: 0.015293

[epoch: 136/100000, batch:   102/  187, ite: 12741] train loss: 0.064226, tar: 0.007148 
l0: 0.004779, l1: 0.005116, l2: 0.005837, l3: 0.006713, l4: 0.012165, l5: 0.010980, l6: 0.008846

[epoch: 136/100000, batch:   104/  187, ite: 12742] train loss: 0.064213, tar: 0.007145 
l0: 0.010877, l1: 0.010794, l2: 0.011611, l3: 0.013271, l4: 0.014535, l5: 0.013680, l6: 0.011729

[epoch: 136/100000, batch:   106/  187, ite: 12743] train loss: 0.064243, tar: 0.007150 
l0: 0.064979, l1: 0.083145, l2: 0.094814, l3: 0.035582, l4: 0.040587, l5: 0.030254, l6: 0.037941

[epoch: 136/100000, batch:   108/  187, ite: 12744] train loss: 0.064677, tar: 0.007228 
l0: 0.006125, l1: 0.007130, l2: 0.006387, l3: 0.005929, l4: 0.008759, l5: 0.008852, l6: 0.009599

[epoch: 136/100000, batch:   110/  187, ite: 12745] train loss: 0.064661, tar: 0.007227 
l0: 0.007943, l1: 0.008691, l2: 0.008623, l3: 0.010254, l4: 0.014138, l5: 0.009851, l6: 0.010782

[epoch: 136/100000, batch:   112/  187, ite: 12746] train loss: 0.064669, tar: 0.007227 
l0: 0.007255, l1: 0.007579, l2: 0.008131, l3: 0.008014, l4: 0.011169, l5: 0.009923, l6: 0.012059

[epoch: 136/100000, batch:   114/  187, ite: 12747] train loss: 0.064668, tar: 0.007228 
l0: 0.009967, l1: 0.010152, l2: 0.013263, l3: 0.018203, l4: 0.020724, l5: 0.016488, l6: 0.016078

[epoch: 136/100000, batch:   116/  187, ite: 12748] train loss: 0.064722, tar: 0.007231 
l0: 0.007442, l1: 0.007228, l2: 0.009233, l3: 0.011344, l4: 0.019867, l5: 0.015526, l6: 0.019373

[epoch: 136/100000, batch:   118/  187, ite: 12749] train loss: 0.064756, tar: 0.007231 
l0: 0.011218, l1: 0.013375, l2: 0.016753, l3: 0.014680, l4: 0.015670, l5: 0.014323, l6: 0.013146

[epoch: 136/100000, batch:   120/  187, ite: 12750] train loss: 0.064801, tar: 0.007237 
l0: 0.007010, l1: 0.006602, l2: 0.007333, l3: 0.008552, l4: 0.015034, l5: 0.015908, l6: 0.019469

[epoch: 136/100000, batch:   122/  187, ite: 12751] train loss: 0.064822, tar: 0.007236 
l0: 0.017658, l1: 0.018384, l2: 0.022660, l3: 0.022571, l4: 0.027804, l5: 0.027120, l6: 0.022690

[epoch: 136/100000, batch:   124/  187, ite: 12752] train loss: 0.064947, tar: 0.007250 
l0: 0.015254, l1: 0.016327, l2: 0.018130, l3: 0.016147, l4: 0.016089, l5: 0.013832, l6: 0.015530

[epoch: 136/100000, batch:   126/  187, ite: 12753] train loss: 0.065008, tar: 0.007261 
l0: 0.019073, l1: 0.019442, l2: 0.019040, l3: 0.020511, l4: 0.028066, l5: 0.025238, l6: 0.026296

[epoch: 136/100000, batch:   128/  187, ite: 12754] train loss: 0.065131, tar: 0.007277 
l0: 0.016043, l1: 0.017128, l2: 0.020130, l3: 0.021168, l4: 0.016514, l5: 0.017496, l6: 0.019810

[epoch: 136/100000, batch:   130/  187, ite: 12755] train loss: 0.065215, tar: 0.007288 
l0: 0.014413, l1: 0.014454, l2: 0.016737, l3: 0.020554, l4: 0.019513, l5: 0.018174, l6: 0.023768

[epoch: 136/100000, batch:   132/  187, ite: 12756] train loss: 0.065297, tar: 0.007298 
l0: 0.008700, l1: 0.009652, l2: 0.008547, l3: 0.007031, l4: 0.007285, l5: 0.009564, l6: 0.008107

[epoch: 136/100000, batch:   134/  187, ite: 12757] train loss: 0.065289, tar: 0.007300 
l0: 0.006033, l1: 0.007849, l2: 0.009087, l3: 0.007296, l4: 0.008146, l5: 0.006085, l6: 0.007176

[epoch: 136/100000, batch:   136/  187, ite: 12758] train loss: 0.065271, tar: 0.007298 
l0: 0.010843, l1: 0.011677, l2: 0.011542, l3: 0.013919, l4: 0.014347, l5: 0.013380, l6: 0.012935

[epoch: 136/100000, batch:   138/  187, ite: 12759] train loss: 0.065302, tar: 0.007303 
l0: 0.011726, l1: 0.012929, l2: 0.016680, l3: 0.014270, l4: 0.022986, l5: 0.018273, l6: 0.015177

[epoch: 136/100000, batch:   140/  187, ite: 12760] train loss: 0.065363, tar: 0.007308 
l0: 0.017524, l1: 0.020487, l2: 0.013619, l3: 0.013332, l4: 0.018679, l5: 0.019774, l6: 0.021822

[epoch: 136/100000, batch:   142/  187, ite: 12761] train loss: 0.065442, tar: 0.007322 
l0: 0.006970, l1: 0.008525, l2: 0.007790, l3: 0.006312, l4: 0.011126, l5: 0.008440, l6: 0.007073

[epoch: 136/100000, batch:   144/  187, ite: 12762] train loss: 0.065430, tar: 0.007321 
l0: 0.004921, l1: 0.005183, l2: 0.007029, l3: 0.005510, l4: 0.018455, l5: 0.015111, l6: 0.011930

[epoch: 136/100000, batch:   146/  187, ite: 12763] train loss: 0.065433, tar: 0.007318 
l0: 0.037509, l1: 0.046594, l2: 0.046795, l3: 0.037846, l4: 0.054101, l5: 0.050052, l6: 0.033527

[epoch: 136/100000, batch:   148/  187, ite: 12764] train loss: 0.065749, tar: 0.007358 
l0: 0.009100, l1: 0.010429, l2: 0.010040, l3: 0.011410, l4: 0.013400, l5: 0.009781, l6: 0.010580

[epoch: 136/100000, batch:   150/  187, ite: 12765] train loss: 0.065760, tar: 0.007360 
l0: 0.007144, l1: 0.007740, l2: 0.007784, l3: 0.009546, l4: 0.012666, l5: 0.011098, l6: 0.008346

[epoch: 136/100000, batch:   152/  187, ite: 12766] train loss: 0.065759, tar: 0.007360 
l0: 0.019478, l1: 0.022598, l2: 0.022784, l3: 0.014882, l4: 0.018796, l5: 0.019099, l6: 0.021921

[epoch: 136/100000, batch:   154/  187, ite: 12767] train loss: 0.065855, tar: 0.007375 
l0: 0.013912, l1: 0.014151, l2: 0.019804, l3: 0.018348, l4: 0.013070, l5: 0.018792, l6: 0.013174

[epoch: 136/100000, batch:   156/  187, ite: 12768] train loss: 0.065914, tar: 0.007384 
l0: 0.027347, l1: 0.030712, l2: 0.022591, l3: 0.021378, l4: 0.031339, l5: 0.030800, l6: 0.032054

[epoch: 136/100000, batch:   158/  187, ite: 12769] train loss: 0.066083, tar: 0.007410 
l0: 0.012517, l1: 0.013569, l2: 0.019734, l3: 0.017852, l4: 0.019701, l5: 0.019445, l6: 0.019139

[epoch: 136/100000, batch:   160/  187, ite: 12770] train loss: 0.066156, tar: 0.007417 
l0: 0.009482, l1: 0.010113, l2: 0.011127, l3: 0.010115, l4: 0.011286, l5: 0.011575, l6: 0.014293

[epoch: 136/100000, batch:   162/  187, ite: 12771] train loss: 0.066171, tar: 0.007419 
l0: 0.009870, l1: 0.012284, l2: 0.011953, l3: 0.010968, l4: 0.013036, l5: 0.011068, l6: 0.008993

[epoch: 136/100000, batch:   164/  187, ite: 12772] train loss: 0.066187, tar: 0.007422 
l0: 0.007791, l1: 0.010084, l2: 0.010502, l3: 0.006739, l4: 0.007331, l5: 0.006381, l6: 0.005828

[epoch: 136/100000, batch:   166/  187, ite: 12773] train loss: 0.066172, tar: 0.007423 
l0: 0.013919, l1: 0.015488, l2: 0.014113, l3: 0.013711, l4: 0.014073, l5: 0.012995, l6: 0.015199

[epoch: 136/100000, batch:   168/  187, ite: 12774] train loss: 0.066215, tar: 0.007431 
l0: 0.022460, l1: 0.027164, l2: 0.024795, l3: 0.020067, l4: 0.015965, l5: 0.013030, l6: 0.020366

[epoch: 136/100000, batch:   170/  187, ite: 12775] train loss: 0.066315, tar: 0.007451 
l0: 0.016155, l1: 0.017569, l2: 0.014634, l3: 0.015514, l4: 0.016966, l5: 0.015929, l6: 0.015620

[epoch: 136/100000, batch:   172/  187, ite: 12776] train loss: 0.066375, tar: 0.007462 
l0: 0.006461, l1: 0.007835, l2: 0.008046, l3: 0.007922, l4: 0.007793, l5: 0.009637, l6: 0.007208

[epoch: 136/100000, batch:   174/  187, ite: 12777] train loss: 0.066360, tar: 0.007461 
l0: 0.016320, l1: 0.015388, l2: 0.017615, l3: 0.019601, l4: 0.025614, l5: 0.029746, l6: 0.027663

[epoch: 136/100000, batch:   176/  187, ite: 12778] train loss: 0.066470, tar: 0.007472 
l0: 0.020592, l1: 0.020459, l2: 0.020464, l3: 0.023262, l4: 0.020767, l5: 0.020277, l6: 0.023844

[epoch: 136/100000, batch:   178/  187, ite: 12779] train loss: 0.066577, tar: 0.007489 
l0: 0.010620, l1: 0.011885, l2: 0.013848, l3: 0.012815, l4: 0.012237, l5: 0.011687, l6: 0.012348

[epoch: 136/100000, batch:   180/  187, ite: 12780] train loss: 0.066601, tar: 0.007493 
l0: 0.009311, l1: 0.008866, l2: 0.009293, l3: 0.009521, l4: 0.012569, l5: 0.014507, l6: 0.013073

[epoch: 136/100000, batch:   182/  187, ite: 12781] train loss: 0.066614, tar: 0.007495 
l0: 0.011379, l1: 0.011247, l2: 0.008877, l3: 0.010388, l4: 0.017774, l5: 0.020590, l6: 0.025273

[epoch: 136/100000, batch:   184/  187, ite: 12782] train loss: 0.066664, tar: 0.007500 
l0: 0.008311, l1: 0.009022, l2: 0.009686, l3: 0.009647, l4: 0.010551, l5: 0.010217, l6: 0.012320

[epoch: 136/100000, batch:   186/  187, ite: 12783] train loss: 0.066668, tar: 0.007501 
l0: 0.004550, l1: 0.004654, l2: 0.005232, l3: 0.005008, l4: 0.007912, l5: 0.005585, l6: 0.005037

[epoch: 136/100000, batch:   188/  187, ite: 12784] train loss: 0.066631, tar: 0.007497 
l0: 0.005204, l1: 0.005060, l2: 0.004963, l3: 0.005578, l4: 0.009009, l5: 0.010432, l6: 0.009164

[epoch: 137/100000, batch:     2/  187, ite: 12785] train loss: 0.066609, tar: 0.007494 
l0: 0.008676, l1: 0.008067, l2: 0.008664, l3: 0.009659, l4: 0.013757, l5: 0.017061, l6: 0.013616

[epoch: 137/100000, batch:     4/  187, ite: 12786] train loss: 0.066626, tar: 0.007496 
l0: 0.008178, l1: 0.007689, l2: 0.009061, l3: 0.010039, l4: 0.015503, l5: 0.014100, l6: 0.014529

[epoch: 137/100000, batch:     6/  187, ite: 12787] train loss: 0.066642, tar: 0.007497 
l0: 0.010533, l1: 0.010375, l2: 0.009951, l3: 0.009652, l4: 0.014067, l5: 0.014309, l6: 0.018227

[epoch: 137/100000, batch:     8/  187, ite: 12788] train loss: 0.066668, tar: 0.007501 
l0: 0.008982, l1: 0.008901, l2: 0.008041, l3: 0.008346, l4: 0.010947, l5: 0.011369, l6: 0.013029

[epoch: 137/100000, batch:    10/  187, ite: 12789] train loss: 0.066671, tar: 0.007503 
l0: 0.015481, l1: 0.017684, l2: 0.015068, l3: 0.014418, l4: 0.018084, l5: 0.020826, l6: 0.018209

[epoch: 137/100000, batch:    12/  187, ite: 12790] train loss: 0.066739, tar: 0.007513 
l0: 0.010134, l1: 0.010082, l2: 0.013079, l3: 0.012947, l4: 0.017735, l5: 0.015604, l6: 0.015732

[epoch: 137/100000, batch:    14/  187, ite: 12791] train loss: 0.066775, tar: 0.007516 
l0: 0.012181, l1: 0.012216, l2: 0.013660, l3: 0.011241, l4: 0.023046, l5: 0.026879, l6: 0.032060

[epoch: 137/100000, batch:    16/  187, ite: 12792] train loss: 0.066856, tar: 0.007522 
l0: 0.007308, l1: 0.008809, l2: 0.007601, l3: 0.006048, l4: 0.007258, l5: 0.007591, l6: 0.008867

[epoch: 137/100000, batch:    18/  187, ite: 12793] train loss: 0.066839, tar: 0.007522 
l0: 0.016506, l1: 0.017216, l2: 0.017265, l3: 0.018159, l4: 0.017384, l5: 0.017605, l6: 0.019391

[epoch: 137/100000, batch:    20/  187, ite: 12794] train loss: 0.066911, tar: 0.007533 
l0: 0.012082, l1: 0.012353, l2: 0.012987, l3: 0.012941, l4: 0.024461, l5: 0.030168, l6: 0.023599

[epoch: 137/100000, batch:    22/  187, ite: 12795] train loss: 0.066988, tar: 0.007539 
l0: 0.019521, l1: 0.023076, l2: 0.020372, l3: 0.020678, l4: 0.013294, l5: 0.012754, l6: 0.014295

[epoch: 137/100000, batch:    24/  187, ite: 12796] train loss: 0.067060, tar: 0.007554 
l0: 0.008615, l1: 0.009072, l2: 0.008876, l3: 0.008354, l4: 0.011497, l5: 0.010961, l6: 0.009421

[epoch: 137/100000, batch:    26/  187, ite: 12797] train loss: 0.067060, tar: 0.007555 
l0: 0.013117, l1: 0.011785, l2: 0.013418, l3: 0.013736, l4: 0.017101, l5: 0.021233, l6: 0.021986

[epoch: 137/100000, batch:    28/  187, ite: 12798] train loss: 0.067116, tar: 0.007562 
l0: 0.009201, l1: 0.009934, l2: 0.009848, l3: 0.009286, l4: 0.019758, l5: 0.017493, l6: 0.013376

[epoch: 137/100000, batch:    30/  187, ite: 12799] train loss: 0.067144, tar: 0.007564 
l0: 0.009558, l1: 0.008458, l2: 0.009435, l3: 0.010081, l4: 0.015668, l5: 0.017663, l6: 0.020912

[epoch: 137/100000, batch:    32/  187, ite: 12800] train loss: 0.067174, tar: 0.007567 
l0: 0.008590, l1: 0.009831, l2: 0.008675, l3: 0.009123, l4: 0.011463, l5: 0.010668, l6: 0.012290

[epoch: 137/100000, batch:    34/  187, ite: 12801] train loss: 0.067179, tar: 0.007568 
l0: 0.009256, l1: 0.010431, l2: 0.008558, l3: 0.007972, l4: 0.013020, l5: 0.012511, l6: 0.012998

[epoch: 137/100000, batch:    36/  187, ite: 12802] train loss: 0.067188, tar: 0.007570 
l0: 0.009706, l1: 0.009776, l2: 0.009409, l3: 0.009568, l4: 0.016497, l5: 0.014092, l6: 0.015816

[epoch: 137/100000, batch:    38/  187, ite: 12803] train loss: 0.067210, tar: 0.007573 
l0: 0.011419, l1: 0.012223, l2: 0.011025, l3: 0.009966, l4: 0.010622, l5: 0.012515, l6: 0.015645

[epoch: 137/100000, batch:    40/  187, ite: 12804] train loss: 0.067230, tar: 0.007577 
l0: 0.019760, l1: 0.022701, l2: 0.021595, l3: 0.021835, l4: 0.013836, l5: 0.013922, l6: 0.016445

[epoch: 137/100000, batch:    42/  187, ite: 12805] train loss: 0.067308, tar: 0.007593 
l0: 0.008069, l1: 0.009309, l2: 0.009645, l3: 0.009127, l4: 0.011585, l5: 0.009872, l6: 0.010864

[epoch: 137/100000, batch:    44/  187, ite: 12806] train loss: 0.067310, tar: 0.007593 
l0: 0.009638, l1: 0.009534, l2: 0.009587, l3: 0.009519, l4: 0.014563, l5: 0.017582, l6: 0.017462

[epoch: 137/100000, batch:    46/  187, ite: 12807] train loss: 0.067335, tar: 0.007596 
l0: 0.009633, l1: 0.010207, l2: 0.009258, l3: 0.010557, l4: 0.012934, l5: 0.013036, l6: 0.013026

[epoch: 137/100000, batch:    48/  187, ite: 12808] train loss: 0.067349, tar: 0.007598 
l0: 0.006966, l1: 0.008313, l2: 0.007608, l3: 0.007161, l4: 0.011787, l5: 0.010934, l6: 0.013979

[epoch: 137/100000, batch:    50/  187, ite: 12809] train loss: 0.067349, tar: 0.007597 
l0: 0.008584, l1: 0.010487, l2: 0.011022, l3: 0.009212, l4: 0.012407, l5: 0.010035, l6: 0.010312

[epoch: 137/100000, batch:    52/  187, ite: 12810] train loss: 0.067354, tar: 0.007599 
l0: 0.006564, l1: 0.007210, l2: 0.007339, l3: 0.006618, l4: 0.007413, l5: 0.006933, l6: 0.008078

[epoch: 137/100000, batch:    54/  187, ite: 12811] train loss: 0.067333, tar: 0.007597 
l0: 0.009602, l1: 0.010940, l2: 0.010748, l3: 0.009974, l4: 0.013490, l5: 0.011734, l6: 0.013785

[epoch: 137/100000, batch:    56/  187, ite: 12812] train loss: 0.067349, tar: 0.007600 
l0: 0.014526, l1: 0.013313, l2: 0.015359, l3: 0.015872, l4: 0.015799, l5: 0.017588, l6: 0.021693

[epoch: 137/100000, batch:    58/  187, ite: 12813] train loss: 0.067407, tar: 0.007608 
l0: 0.003845, l1: 0.004327, l2: 0.005361, l3: 0.004838, l4: 0.008330, l5: 0.006249, l6: 0.007136

[epoch: 137/100000, batch:    60/  187, ite: 12814] train loss: 0.067373, tar: 0.007604 
l0: 0.008472, l1: 0.008927, l2: 0.010022, l3: 0.009988, l4: 0.011265, l5: 0.009857, l6: 0.013936

[epoch: 137/100000, batch:    62/  187, ite: 12815] train loss: 0.067379, tar: 0.007605 
l0: 0.014359, l1: 0.013733, l2: 0.016180, l3: 0.016852, l4: 0.023295, l5: 0.022402, l6: 0.023701

[epoch: 137/100000, batch:    64/  187, ite: 12816] train loss: 0.067457, tar: 0.007613 
l0: 0.007555, l1: 0.007984, l2: 0.008508, l3: 0.007526, l4: 0.009274, l5: 0.009908, l6: 0.008553

[epoch: 137/100000, batch:    66/  187, ite: 12817] train loss: 0.067447, tar: 0.007613 
l0: 0.012699, l1: 0.015327, l2: 0.015387, l3: 0.011117, l4: 0.012505, l5: 0.014275, l6: 0.017399

[epoch: 137/100000, batch:    68/  187, ite: 12818] train loss: 0.067485, tar: 0.007619 
l0: 0.007985, l1: 0.009140, l2: 0.009082, l3: 0.008362, l4: 0.009909, l5: 0.008996, l6: 0.010730

[epoch: 137/100000, batch:    70/  187, ite: 12819] train loss: 0.067481, tar: 0.007620 
l0: 0.007086, l1: 0.007072, l2: 0.007251, l3: 0.007312, l4: 0.010287, l5: 0.010898, l6: 0.010086

[epoch: 137/100000, batch:    72/  187, ite: 12820] train loss: 0.067472, tar: 0.007619 
l0: 0.008811, l1: 0.010839, l2: 0.011942, l3: 0.011485, l4: 0.012362, l5: 0.012497, l6: 0.011968

[epoch: 137/100000, batch:    74/  187, ite: 12821] train loss: 0.067487, tar: 0.007620 
l0: 0.008598, l1: 0.008638, l2: 0.009792, l3: 0.009048, l4: 0.011642, l5: 0.011782, l6: 0.012908

[epoch: 137/100000, batch:    76/  187, ite: 12822] train loss: 0.067493, tar: 0.007622 
l0: 0.009134, l1: 0.009392, l2: 0.009809, l3: 0.009637, l4: 0.016945, l5: 0.015120, l6: 0.014701

[epoch: 137/100000, batch:    78/  187, ite: 12823] train loss: 0.067514, tar: 0.007623 
l0: 0.007779, l1: 0.008667, l2: 0.009142, l3: 0.008433, l4: 0.012865, l5: 0.011519, l6: 0.009596

[epoch: 137/100000, batch:    80/  187, ite: 12824] train loss: 0.067515, tar: 0.007624 
l0: 0.010355, l1: 0.010672, l2: 0.011019, l3: 0.009257, l4: 0.010717, l5: 0.012115, l6: 0.012915

[epoch: 137/100000, batch:    82/  187, ite: 12825] train loss: 0.067526, tar: 0.007627 
l0: 0.007218, l1: 0.007739, l2: 0.008067, l3: 0.007941, l4: 0.011427, l5: 0.009991, l6: 0.011718

[epoch: 137/100000, batch:    84/  187, ite: 12826] train loss: 0.067522, tar: 0.007626 
l0: 0.006102, l1: 0.005590, l2: 0.005507, l3: 0.005263, l4: 0.011807, l5: 0.012233, l6: 0.014779

[epoch: 137/100000, batch:    86/  187, ite: 12827] train loss: 0.067514, tar: 0.007625 
l0: 0.007391, l1: 0.008476, l2: 0.008552, l3: 0.007918, l4: 0.011984, l5: 0.009964, l6: 0.010762

[epoch: 137/100000, batch:    88/  187, ite: 12828] train loss: 0.067511, tar: 0.007624 
l0: 0.011038, l1: 0.010463, l2: 0.009924, l3: 0.009815, l4: 0.010062, l5: 0.011604, l6: 0.017305

[epoch: 137/100000, batch:    90/  187, ite: 12829] train loss: 0.067527, tar: 0.007628 
l0: 0.010160, l1: 0.009989, l2: 0.011101, l3: 0.012069, l4: 0.012047, l5: 0.012495, l6: 0.013315

[epoch: 137/100000, batch:    92/  187, ite: 12830] train loss: 0.067543, tar: 0.007632 
l0: 0.006388, l1: 0.007197, l2: 0.008327, l3: 0.007971, l4: 0.008314, l5: 0.006851, l6: 0.009295

[epoch: 137/100000, batch:    94/  187, ite: 12831] train loss: 0.067527, tar: 0.007630 
l0: 0.006184, l1: 0.008142, l2: 0.006771, l3: 0.007483, l4: 0.004970, l5: 0.005420, l6: 0.004563

[epoch: 137/100000, batch:    96/  187, ite: 12832] train loss: 0.067499, tar: 0.007628 
l0: 0.004604, l1: 0.004622, l2: 0.005020, l3: 0.004553, l4: 0.005061, l5: 0.006508, l6: 0.005275

[epoch: 137/100000, batch:    98/  187, ite: 12833] train loss: 0.067460, tar: 0.007625 
l0: 0.008768, l1: 0.009002, l2: 0.009207, l3: 0.009569, l4: 0.014928, l5: 0.013996, l6: 0.015726

[epoch: 137/100000, batch:   100/  187, ite: 12834] train loss: 0.067477, tar: 0.007626 
l0: 0.004745, l1: 0.004910, l2: 0.004676, l3: 0.004622, l4: 0.007602, l5: 0.006720, l6: 0.006879

[epoch: 137/100000, batch:   102/  187, ite: 12835] train loss: 0.067444, tar: 0.007623 
l0: 0.018737, l1: 0.020081, l2: 0.018505, l3: 0.018419, l4: 0.017297, l5: 0.017965, l6: 0.020159

[epoch: 137/100000, batch:   104/  187, ite: 12836] train loss: 0.067520, tar: 0.007636 
l0: 0.003439, l1: 0.004109, l2: 0.003915, l3: 0.003717, l4: 0.004375, l5: 0.004714, l6: 0.006953

[epoch: 137/100000, batch:   106/  187, ite: 12837] train loss: 0.067477, tar: 0.007631 
l0: 0.005074, l1: 0.005620, l2: 0.005921, l3: 0.005983, l4: 0.008029, l5: 0.008019, l6: 0.007090

[epoch: 137/100000, batch:   108/  187, ite: 12838] train loss: 0.067451, tar: 0.007628 
l0: 0.005441, l1: 0.005079, l2: 0.007006, l3: 0.007833, l4: 0.020874, l5: 0.012696, l6: 0.011781

[epoch: 137/100000, batch:   110/  187, ite: 12839] train loss: 0.067455, tar: 0.007625 
l0: 0.008891, l1: 0.010132, l2: 0.010312, l3: 0.009357, l4: 0.012214, l5: 0.010544, l6: 0.011312

[epoch: 137/100000, batch:   112/  187, ite: 12840] train loss: 0.067461, tar: 0.007627 
l0: 0.007706, l1: 0.006784, l2: 0.006850, l3: 0.007678, l4: 0.014824, l5: 0.014075, l6: 0.016507

[epoch: 137/100000, batch:   114/  187, ite: 12841] train loss: 0.067469, tar: 0.007627 
l0: 0.008413, l1: 0.008677, l2: 0.009521, l3: 0.009159, l4: 0.011434, l5: 0.010395, l6: 0.013030

[epoch: 137/100000, batch:   116/  187, ite: 12842] train loss: 0.067473, tar: 0.007628 
l0: 0.004852, l1: 0.005589, l2: 0.006161, l3: 0.005926, l4: 0.007640, l5: 0.007077, l6: 0.006680

[epoch: 137/100000, batch:   118/  187, ite: 12843] train loss: 0.067445, tar: 0.007624 
l0: 0.009795, l1: 0.009678, l2: 0.011195, l3: 0.012364, l4: 0.014337, l5: 0.015247, l6: 0.018130

[epoch: 137/100000, batch:   120/  187, ite: 12844] train loss: 0.067473, tar: 0.007627 
l0: 0.008106, l1: 0.008719, l2: 0.008820, l3: 0.008068, l4: 0.008492, l5: 0.008774, l6: 0.009834

[epoch: 137/100000, batch:   122/  187, ite: 12845] train loss: 0.067465, tar: 0.007628 
l0: 0.007727, l1: 0.007469, l2: 0.008236, l3: 0.007988, l4: 0.014182, l5: 0.013342, l6: 0.012619

[epoch: 137/100000, batch:   124/  187, ite: 12846] train loss: 0.067470, tar: 0.007628 
l0: 0.006099, l1: 0.005287, l2: 0.008153, l3: 0.009133, l4: 0.009631, l5: 0.010030, l6: 0.014564

[epoch: 137/100000, batch:   126/  187, ite: 12847] train loss: 0.067464, tar: 0.007626 
l0: 0.005911, l1: 0.006949, l2: 0.007692, l3: 0.005609, l4: 0.004184, l5: 0.004745, l6: 0.005033

[epoch: 137/100000, batch:   128/  187, ite: 12848] train loss: 0.067432, tar: 0.007624 
l0: 0.007427, l1: 0.007394, l2: 0.007718, l3: 0.008549, l4: 0.008499, l5: 0.010144, l6: 0.010085

[epoch: 137/100000, batch:   130/  187, ite: 12849] train loss: 0.067423, tar: 0.007624 
l0: 0.010696, l1: 0.011245, l2: 0.012338, l3: 0.011108, l4: 0.014539, l5: 0.012590, l6: 0.015731

[epoch: 137/100000, batch:   132/  187, ite: 12850] train loss: 0.067448, tar: 0.007627 
l0: 0.006751, l1: 0.007572, l2: 0.008113, l3: 0.007715, l4: 0.012789, l5: 0.010481, l6: 0.010452

[epoch: 137/100000, batch:   134/  187, ite: 12851] train loss: 0.067443, tar: 0.007626 
l0: 0.006393, l1: 0.005975, l2: 0.007308, l3: 0.008680, l4: 0.012542, l5: 0.011707, l6: 0.010437

[epoch: 137/100000, batch:   136/  187, ite: 12852] train loss: 0.067438, tar: 0.007625 
l0: 0.008447, l1: 0.008653, l2: 0.009184, l3: 0.009225, l4: 0.011536, l5: 0.011480, l6: 0.011683

[epoch: 137/100000, batch:   138/  187, ite: 12853] train loss: 0.067442, tar: 0.007626 
l0: 0.006541, l1: 0.007962, l2: 0.007414, l3: 0.006771, l4: 0.009578, l5: 0.010281, l6: 0.007731

[epoch: 137/100000, batch:   140/  187, ite: 12854] train loss: 0.067428, tar: 0.007624 
l0: 0.006659, l1: 0.006510, l2: 0.006329, l3: 0.005937, l4: 0.013187, l5: 0.013520, l6: 0.013629

[epoch: 137/100000, batch:   142/  187, ite: 12855] train loss: 0.067427, tar: 0.007623 
l0: 0.008722, l1: 0.008704, l2: 0.009170, l3: 0.009545, l4: 0.016152, l5: 0.013367, l6: 0.014697

[epoch: 137/100000, batch:   144/  187, ite: 12856] train loss: 0.067442, tar: 0.007625 
l0: 0.006094, l1: 0.006299, l2: 0.006958, l3: 0.006914, l4: 0.006885, l5: 0.006575, l6: 0.008511

[epoch: 137/100000, batch:   146/  187, ite: 12857] train loss: 0.067419, tar: 0.007623 
l0: 0.009036, l1: 0.009759, l2: 0.011673, l3: 0.011344, l4: 0.011611, l5: 0.010913, l6: 0.010928

[epoch: 137/100000, batch:   148/  187, ite: 12858] train loss: 0.067428, tar: 0.007624 
l0: 0.008726, l1: 0.008563, l2: 0.007926, l3: 0.008628, l4: 0.011182, l5: 0.012618, l6: 0.012299

[epoch: 137/100000, batch:   150/  187, ite: 12859] train loss: 0.067431, tar: 0.007626 
l0: 0.004087, l1: 0.004322, l2: 0.003752, l3: 0.004486, l4: 0.008823, l5: 0.008358, l6: 0.006502

[epoch: 137/100000, batch:   152/  187, ite: 12860] train loss: 0.067400, tar: 0.007622 
l0: 0.006575, l1: 0.006362, l2: 0.006301, l3: 0.006691, l4: 0.009498, l5: 0.010420, l6: 0.010457

[epoch: 137/100000, batch:   154/  187, ite: 12861] train loss: 0.067387, tar: 0.007620 
l0: 0.005007, l1: 0.005270, l2: 0.005002, l3: 0.005292, l4: 0.009881, l5: 0.008213, l6: 0.009967

[epoch: 137/100000, batch:   156/  187, ite: 12862] train loss: 0.067365, tar: 0.007617 
l0: 0.011764, l1: 0.011880, l2: 0.011362, l3: 0.012143, l4: 0.015548, l5: 0.014018, l6: 0.019685

[epoch: 137/100000, batch:   158/  187, ite: 12863] train loss: 0.067399, tar: 0.007622 
l0: 0.012581, l1: 0.011449, l2: 0.011328, l3: 0.014002, l4: 0.020616, l5: 0.017296, l6: 0.024157

[epoch: 137/100000, batch:   160/  187, ite: 12864] train loss: 0.067450, tar: 0.007628 
l0: 0.003906, l1: 0.005221, l2: 0.003729, l3: 0.005441, l4: 0.004309, l5: 0.003282, l6: 0.003957

[epoch: 137/100000, batch:   162/  187, ite: 12865] train loss: 0.067406, tar: 0.007624 
l0: 0.008709, l1: 0.009597, l2: 0.007991, l3: 0.008114, l4: 0.011962, l5: 0.012811, l6: 0.012386

[epoch: 137/100000, batch:   164/  187, ite: 12866] train loss: 0.067411, tar: 0.007625 
l0: 0.004286, l1: 0.004628, l2: 0.004380, l3: 0.004477, l4: 0.004573, l5: 0.004860, l6: 0.006189

[epoch: 137/100000, batch:   166/  187, ite: 12867] train loss: 0.067372, tar: 0.007621 
l0: 0.007937, l1: 0.007208, l2: 0.007455, l3: 0.007980, l4: 0.009959, l5: 0.011529, l6: 0.014767

[epoch: 137/100000, batch:   168/  187, ite: 12868] train loss: 0.067371, tar: 0.007621 
l0: 0.007338, l1: 0.007690, l2: 0.007269, l3: 0.007389, l4: 0.010507, l5: 0.011306, l6: 0.012071

[epoch: 137/100000, batch:   170/  187, ite: 12869] train loss: 0.067367, tar: 0.007621 
l0: 0.009217, l1: 0.009721, l2: 0.011622, l3: 0.011410, l4: 0.010780, l5: 0.011736, l6: 0.011772

[epoch: 137/100000, batch:   172/  187, ite: 12870] train loss: 0.067377, tar: 0.007623 
l0: 0.003700, l1: 0.003842, l2: 0.003534, l3: 0.003758, l4: 0.008561, l5: 0.006145, l6: 0.007651

[epoch: 137/100000, batch:   174/  187, ite: 12871] train loss: 0.067342, tar: 0.007618 
l0: 0.005538, l1: 0.006238, l2: 0.006453, l3: 0.005982, l4: 0.011021, l5: 0.008772, l6: 0.010552

[epoch: 137/100000, batch:   176/  187, ite: 12872] train loss: 0.067328, tar: 0.007616 
l0: 0.008784, l1: 0.008251, l2: 0.007751, l3: 0.008725, l4: 0.018137, l5: 0.016198, l6: 0.016479

[epoch: 137/100000, batch:   178/  187, ite: 12873] train loss: 0.067347, tar: 0.007617 
l0: 0.005512, l1: 0.005275, l2: 0.003946, l3: 0.004345, l4: 0.005331, l5: 0.006259, l6: 0.008382

[epoch: 137/100000, batch:   180/  187, ite: 12874] train loss: 0.067315, tar: 0.007615 
l0: 0.006346, l1: 0.006599, l2: 0.006851, l3: 0.006424, l4: 0.010249, l5: 0.009535, l6: 0.009552

[epoch: 137/100000, batch:   182/  187, ite: 12875] train loss: 0.067301, tar: 0.007613 
l0: 0.009054, l1: 0.008766, l2: 0.010558, l3: 0.013132, l4: 0.021479, l5: 0.017534, l6: 0.015531

[epoch: 137/100000, batch:   184/  187, ite: 12876] train loss: 0.067334, tar: 0.007615 
l0: 0.008983, l1: 0.008343, l2: 0.009194, l3: 0.009281, l4: 0.014327, l5: 0.013203, l6: 0.015826

[epoch: 137/100000, batch:   186/  187, ite: 12877] train loss: 0.067348, tar: 0.007617 
l0: 0.018851, l1: 0.019833, l2: 0.019508, l3: 0.020090, l4: 0.030685, l5: 0.020970, l6: 0.026935

[epoch: 137/100000, batch:   188/  187, ite: 12878] train loss: 0.067450, tar: 0.007629 
l0: 0.010202, l1: 0.010717, l2: 0.011029, l3: 0.010263, l4: 0.013583, l5: 0.013665, l6: 0.014329

[epoch: 138/100000, batch:     2/  187, ite: 12879] train loss: 0.067468, tar: 0.007632 
l0: 0.002619, l1: 0.003283, l2: 0.003267, l3: 0.003206, l4: 0.004734, l5: 0.003428, l6: 0.003855

[epoch: 138/100000, batch:     4/  187, ite: 12880] train loss: 0.067419, tar: 0.007627 
l0: 0.005313, l1: 0.004906, l2: 0.004912, l3: 0.005366, l4: 0.008645, l5: 0.009775, l6: 0.013056

[epoch: 138/100000, batch:     6/  187, ite: 12881] train loss: 0.067402, tar: 0.007624 
l0: 0.004995, l1: 0.005229, l2: 0.005802, l3: 0.006551, l4: 0.008959, l5: 0.007590, l6: 0.011579

[epoch: 138/100000, batch:     8/  187, ite: 12882] train loss: 0.067383, tar: 0.007621 
l0: 0.009098, l1: 0.008120, l2: 0.008839, l3: 0.009966, l4: 0.013733, l5: 0.013177, l6: 0.015492

[epoch: 138/100000, batch:    10/  187, ite: 12883] train loss: 0.067395, tar: 0.007623 
l0: 0.003089, l1: 0.003417, l2: 0.003661, l3: 0.004352, l4: 0.012563, l5: 0.006578, l6: 0.010917

[epoch: 138/100000, batch:    12/  187, ite: 12884] train loss: 0.067370, tar: 0.007618 
l0: 0.009115, l1: 0.008550, l2: 0.010340, l3: 0.011181, l4: 0.015135, l5: 0.013480, l6: 0.015646

[epoch: 138/100000, batch:    14/  187, ite: 12885] train loss: 0.067388, tar: 0.007619 
l0: 0.004265, l1: 0.004176, l2: 0.004585, l3: 0.005114, l4: 0.007811, l5: 0.007590, l6: 0.008596

[epoch: 138/100000, batch:    16/  187, ite: 12886] train loss: 0.067359, tar: 0.007616 
l0: 0.012679, l1: 0.012560, l2: 0.012453, l3: 0.013108, l4: 0.019791, l5: 0.015149, l6: 0.019117

[epoch: 138/100000, batch:    18/  187, ite: 12887] train loss: 0.067401, tar: 0.007621 
l0: 0.006693, l1: 0.007429, l2: 0.007695, l3: 0.007967, l4: 0.009150, l5: 0.006765, l6: 0.006777

[epoch: 138/100000, batch:    20/  187, ite: 12888] train loss: 0.067385, tar: 0.007620 
l0: 0.006953, l1: 0.007693, l2: 0.007364, l3: 0.007232, l4: 0.009496, l5: 0.009067, l6: 0.008574

[epoch: 138/100000, batch:    22/  187, ite: 12889] train loss: 0.067372, tar: 0.007619 
l0: 0.031677, l1: 0.029845, l2: 0.029489, l3: 0.031109, l4: 0.038397, l5: 0.044333, l6: 0.040327

[epoch: 138/100000, batch:    24/  187, ite: 12890] train loss: 0.067572, tar: 0.007647 
l0: 0.004413, l1: 0.004364, l2: 0.004786, l3: 0.005503, l4: 0.009295, l5: 0.008426, l6: 0.008513

[epoch: 138/100000, batch:    26/  187, ite: 12891] train loss: 0.067547, tar: 0.007643 
l0: 0.009004, l1: 0.009569, l2: 0.009985, l3: 0.010577, l4: 0.018456, l5: 0.016018, l6: 0.015931

[epoch: 138/100000, batch:    28/  187, ite: 12892] train loss: 0.067572, tar: 0.007644 
l0: 0.006404, l1: 0.005459, l2: 0.006512, l3: 0.007501, l4: 0.013917, l5: 0.015501, l6: 0.012733

[epoch: 138/100000, batch:    30/  187, ite: 12893] train loss: 0.067572, tar: 0.007643 
l0: 0.017049, l1: 0.018151, l2: 0.015428, l3: 0.013575, l4: 0.017577, l5: 0.019353, l6: 0.018004

[epoch: 138/100000, batch:    32/  187, ite: 12894] train loss: 0.067630, tar: 0.007654 
l0: 0.008730, l1: 0.008526, l2: 0.009113, l3: 0.009342, l4: 0.013094, l5: 0.014480, l6: 0.015930

[epoch: 138/100000, batch:    34/  187, ite: 12895] train loss: 0.067643, tar: 0.007655 
l0: 0.006519, l1: 0.006278, l2: 0.005800, l3: 0.007286, l4: 0.009218, l5: 0.009346, l6: 0.011689

[epoch: 138/100000, batch:    36/  187, ite: 12896] train loss: 0.067630, tar: 0.007653 
l0: 0.011320, l1: 0.010571, l2: 0.009707, l3: 0.011475, l4: 0.020699, l5: 0.018827, l6: 0.030099

[epoch: 138/100000, batch:    38/  187, ite: 12897] train loss: 0.067680, tar: 0.007658 
l0: 0.009468, l1: 0.009981, l2: 0.009963, l3: 0.009616, l4: 0.013226, l5: 0.014748, l6: 0.014332

[epoch: 138/100000, batch:    40/  187, ite: 12898] train loss: 0.067695, tar: 0.007660 
l0: 0.002978, l1: 0.003141, l2: 0.003807, l3: 0.003580, l4: 0.004611, l5: 0.003836, l6: 0.004592

[epoch: 138/100000, batch:    42/  187, ite: 12899] train loss: 0.067650, tar: 0.007654 
l0: 0.009639, l1: 0.010895, l2: 0.016011, l3: 0.014323, l4: 0.018495, l5: 0.012182, l6: 0.008771

[epoch: 138/100000, batch:    44/  187, ite: 12900] train loss: 0.067675, tar: 0.007657 
l0: 0.008520, l1: 0.007879, l2: 0.009104, l3: 0.010092, l4: 0.017537, l5: 0.016067, l6: 0.018846

[epoch: 138/100000, batch:    46/  187, ite: 12901] train loss: 0.067697, tar: 0.007658 
l0: 0.008565, l1: 0.007598, l2: 0.009730, l3: 0.009450, l4: 0.016731, l5: 0.016358, l6: 0.018523

[epoch: 138/100000, batch:    48/  187, ite: 12902] train loss: 0.067719, tar: 0.007659 
l0: 0.008265, l1: 0.007550, l2: 0.008986, l3: 0.010215, l4: 0.017723, l5: 0.015191, l6: 0.016591

[epoch: 138/100000, batch:    50/  187, ite: 12903] train loss: 0.067737, tar: 0.007659 
l0: 0.006356, l1: 0.006586, l2: 0.007179, l3: 0.007080, l4: 0.011257, l5: 0.009077, l6: 0.010779

[epoch: 138/100000, batch:    52/  187, ite: 12904] train loss: 0.067727, tar: 0.007658 
l0: 0.007424, l1: 0.007382, l2: 0.006938, l3: 0.010811, l4: 0.009435, l5: 0.010560, l6: 0.010470

[epoch: 138/100000, batch:    54/  187, ite: 12905] train loss: 0.067722, tar: 0.007658 
l0: 0.006389, l1: 0.006560, l2: 0.006967, l3: 0.006116, l4: 0.013695, l5: 0.012110, l6: 0.011216

[epoch: 138/100000, batch:    56/  187, ite: 12906] train loss: 0.067717, tar: 0.007656 
l0: 0.005074, l1: 0.005650, l2: 0.005783, l3: 0.004860, l4: 0.008374, l5: 0.006888, l6: 0.007964

[epoch: 138/100000, batch:    58/  187, ite: 12907] train loss: 0.067691, tar: 0.007653 
l0: 0.008315, l1: 0.007676, l2: 0.007763, l3: 0.007778, l4: 0.013043, l5: 0.013982, l6: 0.012645

[epoch: 138/100000, batch:    60/  187, ite: 12908] train loss: 0.067695, tar: 0.007654 
l0: 0.002930, l1: 0.003678, l2: 0.003245, l3: 0.006211, l4: 0.014253, l5: 0.004946, l6: 0.005849

[epoch: 138/100000, batch:    62/  187, ite: 12909] train loss: 0.067666, tar: 0.007649 
l0: 0.004023, l1: 0.004217, l2: 0.004001, l3: 0.004046, l4: 0.005984, l5: 0.006837, l6: 0.008447

[epoch: 138/100000, batch:    64/  187, ite: 12910] train loss: 0.067633, tar: 0.007645 
l0: 0.007058, l1: 0.006953, l2: 0.008709, l3: 0.010700, l4: 0.016806, l5: 0.011431, l6: 0.010282

[epoch: 138/100000, batch:    66/  187, ite: 12911] train loss: 0.067637, tar: 0.007644 
l0: 0.007040, l1: 0.007303, l2: 0.007485, l3: 0.008611, l4: 0.013348, l5: 0.011319, l6: 0.010548

[epoch: 138/100000, batch:    68/  187, ite: 12912] train loss: 0.067635, tar: 0.007644 
l0: 0.006024, l1: 0.006457, l2: 0.006786, l3: 0.007150, l4: 0.012422, l5: 0.009676, l6: 0.009651

[epoch: 138/100000, batch:    70/  187, ite: 12913] train loss: 0.067625, tar: 0.007642 
l0: 0.012096, l1: 0.011488, l2: 0.011438, l3: 0.012669, l4: 0.019573, l5: 0.019329, l6: 0.022202

[epoch: 138/100000, batch:    72/  187, ite: 12914] train loss: 0.067670, tar: 0.007647 
l0: 0.004445, l1: 0.003813, l2: 0.004419, l3: 0.004517, l4: 0.011813, l5: 0.012393, l6: 0.011356

[epoch: 138/100000, batch:    74/  187, ite: 12915] train loss: 0.067654, tar: 0.007643 
l0: 0.005687, l1: 0.005825, l2: 0.006578, l3: 0.005952, l4: 0.017868, l5: 0.014995, l6: 0.015151

[epoch: 138/100000, batch:    76/  187, ite: 12916] train loss: 0.067658, tar: 0.007641 
l0: 0.005940, l1: 0.006271, l2: 0.007882, l3: 0.007930, l4: 0.006783, l5: 0.007432, l6: 0.008343

[epoch: 138/100000, batch:    78/  187, ite: 12917] train loss: 0.067640, tar: 0.007639 
l0: 0.005503, l1: 0.005598, l2: 0.005964, l3: 0.006168, l4: 0.009424, l5: 0.008430, l6: 0.007516

[epoch: 138/100000, batch:    80/  187, ite: 12918] train loss: 0.067619, tar: 0.007637 
l0: 0.002157, l1: 0.002963, l2: 0.003038, l3: 0.002505, l4: 0.004488, l5: 0.005629, l6: 0.006051

[epoch: 138/100000, batch:    82/  187, ite: 12919] train loss: 0.067575, tar: 0.007631 
l0: 0.010263, l1: 0.008520, l2: 0.009476, l3: 0.010166, l4: 0.040188, l5: 0.038357, l6: 0.040370

[epoch: 138/100000, batch:    84/  187, ite: 12920] train loss: 0.067672, tar: 0.007634 
l0: 0.011173, l1: 0.012519, l2: 0.010277, l3: 0.011570, l4: 0.016674, l5: 0.014875, l6: 0.016192

[epoch: 138/100000, batch:    86/  187, ite: 12921] train loss: 0.067700, tar: 0.007638 
l0: 0.005614, l1: 0.006706, l2: 0.005619, l3: 0.005988, l4: 0.009838, l5: 0.006099, l6: 0.006559

[epoch: 138/100000, batch:    88/  187, ite: 12922] train loss: 0.067677, tar: 0.007635 
l0: 0.005530, l1: 0.005992, l2: 0.006358, l3: 0.006685, l4: 0.009124, l5: 0.008142, l6: 0.009050

[epoch: 138/100000, batch:    90/  187, ite: 12923] train loss: 0.067659, tar: 0.007633 
l0: 0.008162, l1: 0.007979, l2: 0.007553, l3: 0.007542, l4: 0.012914, l5: 0.012604, l6: 0.015737

[epoch: 138/100000, batch:    92/  187, ite: 12924] train loss: 0.067664, tar: 0.007634 
l0: 0.006375, l1: 0.006665, l2: 0.007845, l3: 0.007906, l4: 0.011824, l5: 0.011815, l6: 0.011512

[epoch: 138/100000, batch:    94/  187, ite: 12925] train loss: 0.067660, tar: 0.007632 
l0: 0.008806, l1: 0.010502, l2: 0.009231, l3: 0.009778, l4: 0.011216, l5: 0.012276, l6: 0.011076

[epoch: 138/100000, batch:    96/  187, ite: 12926] train loss: 0.067666, tar: 0.007634 
l0: 0.008164, l1: 0.008465, l2: 0.008447, l3: 0.009012, l4: 0.012193, l5: 0.011753, l6: 0.011344

[epoch: 138/100000, batch:    98/  187, ite: 12927] train loss: 0.067667, tar: 0.007634 
l0: 0.009922, l1: 0.010578, l2: 0.010426, l3: 0.010832, l4: 0.012285, l5: 0.012298, l6: 0.012795

[epoch: 138/100000, batch:   100/  187, ite: 12928] train loss: 0.067680, tar: 0.007637 
l0: 0.006317, l1: 0.006306, l2: 0.007843, l3: 0.006912, l4: 0.009672, l5: 0.009268, l6: 0.008389

[epoch: 138/100000, batch:   102/  187, ite: 12929] train loss: 0.067666, tar: 0.007635 
l0: 0.009574, l1: 0.009703, l2: 0.010079, l3: 0.009530, l4: 0.018002, l5: 0.016040, l6: 0.017005

[epoch: 138/100000, batch:   104/  187, ite: 12930] train loss: 0.067690, tar: 0.007637 
l0: 0.004180, l1: 0.004282, l2: 0.004298, l3: 0.005334, l4: 0.005877, l5: 0.006539, l6: 0.008073

[epoch: 138/100000, batch:   106/  187, ite: 12931] train loss: 0.067659, tar: 0.007634 
l0: 0.004773, l1: 0.004540, l2: 0.005052, l3: 0.004586, l4: 0.010738, l5: 0.010408, l6: 0.010332

[epoch: 138/100000, batch:   108/  187, ite: 12932] train loss: 0.067640, tar: 0.007630 
l0: 0.009339, l1: 0.009758, l2: 0.010833, l3: 0.012311, l4: 0.014953, l5: 0.013321, l6: 0.015050

[epoch: 138/100000, batch:   110/  187, ite: 12933] train loss: 0.067659, tar: 0.007632 
l0: 0.009350, l1: 0.010050, l2: 0.011956, l3: 0.012050, l4: 0.016534, l5: 0.016976, l6: 0.015135

[epoch: 138/100000, batch:   112/  187, ite: 12934] train loss: 0.067685, tar: 0.007634 
l0: 0.009109, l1: 0.010155, l2: 0.008967, l3: 0.008692, l4: 0.014870, l5: 0.011796, l6: 0.014901

[epoch: 138/100000, batch:   114/  187, ite: 12935] train loss: 0.067697, tar: 0.007636 
l0: 0.004245, l1: 0.004596, l2: 0.004626, l3: 0.004204, l4: 0.007201, l5: 0.007142, l6: 0.007002

[epoch: 138/100000, batch:   116/  187, ite: 12936] train loss: 0.067666, tar: 0.007632 
l0: 0.002784, l1: 0.002962, l2: 0.003594, l3: 0.003380, l4: 0.005694, l5: 0.006189, l6: 0.006018

[epoch: 138/100000, batch:   118/  187, ite: 12937] train loss: 0.067627, tar: 0.007627 
l0: 0.005706, l1: 0.005711, l2: 0.007035, l3: 0.007389, l4: 0.009737, l5: 0.010769, l6: 0.009003

[epoch: 138/100000, batch:   120/  187, ite: 12938] train loss: 0.067614, tar: 0.007625 
l0: 0.007786, l1: 0.008174, l2: 0.009190, l3: 0.009426, l4: 0.014533, l5: 0.014648, l6: 0.016030

[epoch: 138/100000, batch:   122/  187, ite: 12939] train loss: 0.067627, tar: 0.007625 
l0: 0.004611, l1: 0.004808, l2: 0.004950, l3: 0.005495, l4: 0.008908, l5: 0.008657, l6: 0.007930

[epoch: 138/100000, batch:   124/  187, ite: 12940] train loss: 0.067603, tar: 0.007622 
l0: 0.008118, l1: 0.008179, l2: 0.007921, l3: 0.008272, l4: 0.012206, l5: 0.012884, l6: 0.015124

[epoch: 138/100000, batch:   126/  187, ite: 12941] train loss: 0.067608, tar: 0.007622 
l0: 0.008568, l1: 0.008610, l2: 0.012463, l3: 0.013505, l4: 0.012254, l5: 0.009624, l6: 0.010418

[epoch: 138/100000, batch:   128/  187, ite: 12942] train loss: 0.067617, tar: 0.007623 
l0: 0.005559, l1: 0.005781, l2: 0.006650, l3: 0.006688, l4: 0.008211, l5: 0.007664, l6: 0.007376

[epoch: 138/100000, batch:   130/  187, ite: 12943] train loss: 0.067596, tar: 0.007621 
l0: 0.003845, l1: 0.003950, l2: 0.004271, l3: 0.004404, l4: 0.009372, l5: 0.009536, l6: 0.008086

[epoch: 138/100000, batch:   132/  187, ite: 12944] train loss: 0.067570, tar: 0.007617 
l0: 0.006872, l1: 0.006968, l2: 0.007277, l3: 0.007418, l4: 0.011192, l5: 0.010818, l6: 0.013282

[epoch: 138/100000, batch:   134/  187, ite: 12945] train loss: 0.067566, tar: 0.007616 
l0: 0.016336, l1: 0.015278, l2: 0.019487, l3: 0.020126, l4: 0.022752, l5: 0.022062, l6: 0.020385

[epoch: 138/100000, batch:   136/  187, ite: 12946] train loss: 0.067639, tar: 0.007626 
l0: 0.006647, l1: 0.006150, l2: 0.008310, l3: 0.007846, l4: 0.010559, l5: 0.010454, l6: 0.011015

[epoch: 138/100000, batch:   138/  187, ite: 12947] train loss: 0.067632, tar: 0.007625 
l0: 0.004654, l1: 0.005152, l2: 0.005244, l3: 0.005455, l4: 0.008732, l5: 0.008533, l6: 0.006760

[epoch: 138/100000, batch:   140/  187, ite: 12948] train loss: 0.067608, tar: 0.007621 
l0: 0.007656, l1: 0.006918, l2: 0.009375, l3: 0.010350, l4: 0.014225, l5: 0.012587, l6: 0.016059

[epoch: 138/100000, batch:   142/  187, ite: 12949] train loss: 0.067618, tar: 0.007621 
l0: 0.005676, l1: 0.005608, l2: 0.005497, l3: 0.005718, l4: 0.009242, l5: 0.010080, l6: 0.013044

[epoch: 138/100000, batch:   144/  187, ite: 12950] train loss: 0.067604, tar: 0.007619 
l0: 0.005138, l1: 0.005755, l2: 0.005584, l3: 0.005557, l4: 0.009374, l5: 0.007386, l6: 0.007497

[epoch: 138/100000, batch:   146/  187, ite: 12951] train loss: 0.067582, tar: 0.007617 
l0: 0.002694, l1: 0.003051, l2: 0.003093, l3: 0.002849, l4: 0.005427, l5: 0.004799, l6: 0.005448

[epoch: 138/100000, batch:   148/  187, ite: 12952] train loss: 0.067540, tar: 0.007612 
l0: 0.006488, l1: 0.006993, l2: 0.006269, l3: 0.005885, l4: 0.007595, l5: 0.007745, l6: 0.007985

[epoch: 138/100000, batch:   150/  187, ite: 12953] train loss: 0.067520, tar: 0.007610 
l0: 0.004620, l1: 0.005053, l2: 0.004768, l3: 0.005113, l4: 0.008001, l5: 0.008213, l6: 0.007708

[epoch: 138/100000, batch:   152/  187, ite: 12954] train loss: 0.067495, tar: 0.007607 
l0: 0.004590, l1: 0.004300, l2: 0.004367, l3: 0.004678, l4: 0.009120, l5: 0.009437, l6: 0.009501

[epoch: 138/100000, batch:   154/  187, ite: 12955] train loss: 0.067472, tar: 0.007604 
l0: 0.011978, l1: 0.012115, l2: 0.011881, l3: 0.011937, l4: 0.018527, l5: 0.018277, l6: 0.020162

[epoch: 138/100000, batch:   156/  187, ite: 12956] train loss: 0.067512, tar: 0.007609 
l0: 0.007169, l1: 0.007133, l2: 0.006945, l3: 0.007672, l4: 0.013535, l5: 0.013953, l6: 0.011118

[epoch: 138/100000, batch:   158/  187, ite: 12957] train loss: 0.067512, tar: 0.007608 
l0: 0.009406, l1: 0.009323, l2: 0.010971, l3: 0.010879, l4: 0.009268, l5: 0.009739, l6: 0.010346

[epoch: 138/100000, batch:   160/  187, ite: 12958] train loss: 0.067514, tar: 0.007610 
l0: 0.005588, l1: 0.005923, l2: 0.006143, l3: 0.006451, l4: 0.013341, l5: 0.010937, l6: 0.009799

[epoch: 138/100000, batch:   162/  187, ite: 12959] train loss: 0.067504, tar: 0.007608 
l0: 0.010317, l1: 0.009925, l2: 0.011976, l3: 0.011481, l4: 0.013980, l5: 0.014769, l6: 0.017938

[epoch: 138/100000, batch:   164/  187, ite: 12960] train loss: 0.067528, tar: 0.007611 
l0: 0.006595, l1: 0.007353, l2: 0.006813, l3: 0.006588, l4: 0.009840, l5: 0.008515, l6: 0.007953

[epoch: 138/100000, batch:   166/  187, ite: 12961] train loss: 0.067514, tar: 0.007610 
l0: 0.006071, l1: 0.006907, l2: 0.007062, l3: 0.006036, l4: 0.007164, l5: 0.005715, l6: 0.007834

[epoch: 138/100000, batch:   168/  187, ite: 12962] train loss: 0.067492, tar: 0.007608 
l0: 0.007999, l1: 0.008244, l2: 0.009617, l3: 0.009136, l4: 0.008132, l5: 0.008332, l6: 0.009513

[epoch: 138/100000, batch:   170/  187, ite: 12963] train loss: 0.067485, tar: 0.007609 
l0: 0.006465, l1: 0.006429, l2: 0.006067, l3: 0.008202, l4: 0.010373, l5: 0.010339, l6: 0.009249

[epoch: 138/100000, batch:   172/  187, ite: 12964] train loss: 0.067475, tar: 0.007607 
l0: 0.007805, l1: 0.007860, l2: 0.008263, l3: 0.009474, l4: 0.008875, l5: 0.008112, l6: 0.010684

[epoch: 138/100000, batch:   174/  187, ite: 12965] train loss: 0.067468, tar: 0.007608 
l0: 0.004545, l1: 0.004363, l2: 0.005002, l3: 0.005819, l4: 0.012673, l5: 0.012059, l6: 0.012015

[epoch: 138/100000, batch:   176/  187, ite: 12966] train loss: 0.067457, tar: 0.007604 
l0: 0.005191, l1: 0.005204, l2: 0.004915, l3: 0.005364, l4: 0.010926, l5: 0.009028, l6: 0.011576

[epoch: 138/100000, batch:   178/  187, ite: 12967] train loss: 0.067441, tar: 0.007602 
l0: 0.008679, l1: 0.009640, l2: 0.009019, l3: 0.009093, l4: 0.015318, l5: 0.012657, l6: 0.013118

[epoch: 138/100000, batch:   180/  187, ite: 12968] train loss: 0.067451, tar: 0.007603 
l0: 0.005202, l1: 0.006512, l2: 0.005697, l3: 0.004902, l4: 0.008838, l5: 0.006582, l6: 0.006544

[epoch: 138/100000, batch:   182/  187, ite: 12969] train loss: 0.067427, tar: 0.007601 
l0: 0.005727, l1: 0.006045, l2: 0.005467, l3: 0.005279, l4: 0.007497, l5: 0.007220, l6: 0.008741

[epoch: 138/100000, batch:   184/  187, ite: 12970] train loss: 0.067405, tar: 0.007599 
l0: 0.009031, l1: 0.009981, l2: 0.010106, l3: 0.009483, l4: 0.007129, l5: 0.007495, l6: 0.009947

[epoch: 138/100000, batch:   186/  187, ite: 12971] train loss: 0.067401, tar: 0.007600 
l0: 0.006575, l1: 0.006945, l2: 0.006571, l3: 0.005732, l4: 0.011968, l5: 0.010419, l6: 0.011009

[epoch: 138/100000, batch:   188/  187, ite: 12972] train loss: 0.067393, tar: 0.007599 
l0: 0.003135, l1: 0.003294, l2: 0.004003, l3: 0.004182, l4: 0.006044, l5: 0.005628, l6: 0.005365

[epoch: 139/100000, batch:     2/  187, ite: 12973] train loss: 0.067356, tar: 0.007595 
l0: 0.007542, l1: 0.007743, l2: 0.006024, l3: 0.006535, l4: 0.014990, l5: 0.014550, l6: 0.017202

[epoch: 139/100000, batch:     4/  187, ite: 12974] train loss: 0.067363, tar: 0.007594 
l0: 0.007397, l1: 0.008160, l2: 0.008797, l3: 0.008245, l4: 0.012444, l5: 0.010342, l6: 0.011769

[epoch: 139/100000, batch:     6/  187, ite: 12975] train loss: 0.067363, tar: 0.007594 
l0: 0.007367, l1: 0.007459, l2: 0.007888, l3: 0.010497, l4: 0.014734, l5: 0.012475, l6: 0.011146

[epoch: 139/100000, batch:     8/  187, ite: 12976] train loss: 0.067367, tar: 0.007594 
l0: 0.006697, l1: 0.006851, l2: 0.007800, l3: 0.007500, l4: 0.010728, l5: 0.009787, l6: 0.010552

[epoch: 139/100000, batch:    10/  187, ite: 12977] train loss: 0.067360, tar: 0.007593 
l0: 0.003451, l1: 0.003466, l2: 0.003234, l3: 0.003845, l4: 0.005708, l5: 0.005309, l6: 0.007332

[epoch: 139/100000, batch:    12/  187, ite: 12978] train loss: 0.067324, tar: 0.007589 
l0: 0.005102, l1: 0.005592, l2: 0.005510, l3: 0.005220, l4: 0.007671, l5: 0.006039, l6: 0.008991

[epoch: 139/100000, batch:    14/  187, ite: 12979] train loss: 0.067300, tar: 0.007586 
l0: 0.004299, l1: 0.005109, l2: 0.004669, l3: 0.004495, l4: 0.006921, l5: 0.005933, l6: 0.006578

[epoch: 139/100000, batch:    16/  187, ite: 12980] train loss: 0.067270, tar: 0.007583 
l0: 0.004931, l1: 0.004578, l2: 0.006310, l3: 0.006672, l4: 0.013280, l5: 0.010205, l6: 0.014212

[epoch: 139/100000, batch:    18/  187, ite: 12981] train loss: 0.067263, tar: 0.007580 
l0: 0.006094, l1: 0.006092, l2: 0.006863, l3: 0.007164, l4: 0.009492, l5: 0.008655, l6: 0.009771

[epoch: 139/100000, batch:    20/  187, ite: 12982] train loss: 0.067250, tar: 0.007579 
l0: 0.006518, l1: 0.006975, l2: 0.007033, l3: 0.006965, l4: 0.008978, l5: 0.008786, l6: 0.009600

[epoch: 139/100000, batch:    22/  187, ite: 12983] train loss: 0.067237, tar: 0.007578 
l0: 0.006635, l1: 0.006324, l2: 0.007617, l3: 0.007904, l4: 0.011501, l5: 0.013175, l6: 0.014435

[epoch: 139/100000, batch:    24/  187, ite: 12984] train loss: 0.067237, tar: 0.007577 
l0: 0.007240, l1: 0.007739, l2: 0.007511, l3: 0.007127, l4: 0.011995, l5: 0.011748, l6: 0.013929

[epoch: 139/100000, batch:    26/  187, ite: 12985] train loss: 0.067238, tar: 0.007576 
l0: 0.005645, l1: 0.005477, l2: 0.005721, l3: 0.005755, l4: 0.010968, l5: 0.010719, l6: 0.012090

[epoch: 139/100000, batch:    28/  187, ite: 12986] train loss: 0.067227, tar: 0.007574 
l0: 0.005103, l1: 0.006000, l2: 0.005501, l3: 0.005605, l4: 0.006283, l5: 0.004463, l6: 0.003971

[epoch: 139/100000, batch:    30/  187, ite: 12987] train loss: 0.067196, tar: 0.007572 
l0: 0.005770, l1: 0.005596, l2: 0.005113, l3: 0.005595, l4: 0.012320, l5: 0.009762, l6: 0.009937

[epoch: 139/100000, batch:    32/  187, ite: 12988] train loss: 0.067183, tar: 0.007570 
l0: 0.007105, l1: 0.007023, l2: 0.007643, l3: 0.007675, l4: 0.008586, l5: 0.008594, l6: 0.010940

[epoch: 139/100000, batch:    34/  187, ite: 12989] train loss: 0.067173, tar: 0.007570 
l0: 0.006271, l1: 0.006551, l2: 0.006183, l3: 0.006280, l4: 0.012148, l5: 0.010599, l6: 0.007914

[epoch: 139/100000, batch:    36/  187, ite: 12990] train loss: 0.067162, tar: 0.007568 
l0: 0.007126, l1: 0.007428, l2: 0.008534, l3: 0.007493, l4: 0.012139, l5: 0.011102, l6: 0.013089

[epoch: 139/100000, batch:    38/  187, ite: 12991] train loss: 0.067161, tar: 0.007568 
l0: 0.004223, l1: 0.003982, l2: 0.004154, l3: 0.004739, l4: 0.012124, l5: 0.011880, l6: 0.010904

[epoch: 139/100000, batch:    40/  187, ite: 12992] train loss: 0.067146, tar: 0.007564 
l0: 0.005126, l1: 0.005518, l2: 0.005882, l3: 0.005910, l4: 0.009376, l5: 0.007688, l6: 0.008230

[epoch: 139/100000, batch:    42/  187, ite: 12993] train loss: 0.067126, tar: 0.007562 
l0: 0.008952, l1: 0.008614, l2: 0.007373, l3: 0.009685, l4: 0.015212, l5: 0.015294, l6: 0.015410

[epoch: 139/100000, batch:    44/  187, ite: 12994] train loss: 0.067140, tar: 0.007563 
l0: 0.007290, l1: 0.007444, l2: 0.008437, l3: 0.007727, l4: 0.011611, l5: 0.012667, l6: 0.012802

[epoch: 139/100000, batch:    46/  187, ite: 12995] train loss: 0.067141, tar: 0.007563 
l0: 0.009162, l1: 0.009802, l2: 0.009597, l3: 0.010182, l4: 0.011904, l5: 0.010699, l6: 0.009762

[epoch: 139/100000, batch:    48/  187, ite: 12996] train loss: 0.067145, tar: 0.007565 
l0: 0.008003, l1: 0.008324, l2: 0.008250, l3: 0.008880, l4: 0.010025, l5: 0.010433, l6: 0.011000

[epoch: 139/100000, batch:    50/  187, ite: 12997] train loss: 0.067143, tar: 0.007565 
l0: 0.005734, l1: 0.005805, l2: 0.006066, l3: 0.005691, l4: 0.009593, l5: 0.010060, l6: 0.010150

[epoch: 139/100000, batch:    52/  187, ite: 12998] train loss: 0.067128, tar: 0.007563 
l0: 0.006329, l1: 0.006860, l2: 0.006910, l3: 0.007498, l4: 0.011191, l5: 0.009110, l6: 0.007812

[epoch: 139/100000, batch:    54/  187, ite: 12999] train loss: 0.067117, tar: 0.007562 
l0: 0.006634, l1: 0.006941, l2: 0.007308, l3: 0.006907, l4: 0.011787, l5: 0.010285, l6: 0.013806

[epoch: 139/100000, batch:    56/  187, ite: 13000] train loss: 0.067114, tar: 0.007561 
l0: 0.004769, l1: 0.005272, l2: 0.005248, l3: 0.005465, l4: 0.007399, l5: 0.008571, l6: 0.009051

[epoch: 139/100000, batch:    58/  187, ite: 13001] train loss: 0.067092, tar: 0.007558 
l0: 0.005565, l1: 0.004757, l2: 0.006177, l3: 0.006782, l4: 0.016200, l5: 0.014466, l6: 0.016433

[epoch: 139/100000, batch:    60/  187, ite: 13002] train loss: 0.067096, tar: 0.007556 
l0: 0.005294, l1: 0.005459, l2: 0.006736, l3: 0.006561, l4: 0.014530, l5: 0.013027, l6: 0.011149

[epoch: 139/100000, batch:    62/  187, ite: 13003] train loss: 0.067091, tar: 0.007554 
l0: 0.009198, l1: 0.009371, l2: 0.009087, l3: 0.009594, l4: 0.017603, l5: 0.015924, l6: 0.017947

[epoch: 139/100000, batch:    64/  187, ite: 13004] train loss: 0.067113, tar: 0.007556 
l0: 0.004945, l1: 0.004988, l2: 0.005520, l3: 0.005102, l4: 0.010865, l5: 0.009876, l6: 0.011188

[epoch: 139/100000, batch:    66/  187, ite: 13005] train loss: 0.067098, tar: 0.007553 
l0: 0.004916, l1: 0.004890, l2: 0.005236, l3: 0.005716, l4: 0.011438, l5: 0.010813, l6: 0.011887

[epoch: 139/100000, batch:    68/  187, ite: 13006] train loss: 0.067086, tar: 0.007551 
l0: 0.003928, l1: 0.003857, l2: 0.003822, l3: 0.003820, l4: 0.006623, l5: 0.006067, l6: 0.007960

[epoch: 139/100000, batch:    70/  187, ite: 13007] train loss: 0.067055, tar: 0.007547 
l0: 0.005020, l1: 0.004968, l2: 0.005769, l3: 0.006977, l4: 0.008074, l5: 0.007635, l6: 0.007481

[epoch: 139/100000, batch:    72/  187, ite: 13008] train loss: 0.067034, tar: 0.007544 
l0: 0.005787, l1: 0.006318, l2: 0.006144, l3: 0.006001, l4: 0.008326, l5: 0.007471, l6: 0.009820

[epoch: 139/100000, batch:    74/  187, ite: 13009] train loss: 0.067017, tar: 0.007543 
l0: 0.007303, l1: 0.007129, l2: 0.006872, l3: 0.007414, l4: 0.011943, l5: 0.011666, l6: 0.016175

[epoch: 139/100000, batch:    76/  187, ite: 13010] train loss: 0.067019, tar: 0.007542 
l0: 0.003480, l1: 0.003469, l2: 0.004442, l3: 0.004522, l4: 0.008991, l5: 0.008522, l6: 0.007064

[epoch: 139/100000, batch:    78/  187, ite: 13011] train loss: 0.066993, tar: 0.007538 
l0: 0.010222, l1: 0.009926, l2: 0.010423, l3: 0.012402, l4: 0.008801, l5: 0.011674, l6: 0.009930

[epoch: 139/100000, batch:    80/  187, ite: 13012] train loss: 0.066999, tar: 0.007541 
l0: 0.004878, l1: 0.005469, l2: 0.005581, l3: 0.005913, l4: 0.007591, l5: 0.005964, l6: 0.008620

[epoch: 139/100000, batch:    82/  187, ite: 13013] train loss: 0.066976, tar: 0.007539 
l0: 0.004649, l1: 0.005391, l2: 0.005804, l3: 0.005212, l4: 0.006149, l5: 0.006047, l6: 0.006576

[epoch: 139/100000, batch:    84/  187, ite: 13014] train loss: 0.066949, tar: 0.007536 
l0: 0.003912, l1: 0.003831, l2: 0.003752, l3: 0.004231, l4: 0.004465, l5: 0.004140, l6: 0.006751

[epoch: 139/100000, batch:    86/  187, ite: 13015] train loss: 0.066914, tar: 0.007532 
l0: 0.003101, l1: 0.003077, l2: 0.003905, l3: 0.003682, l4: 0.006486, l5: 0.005708, l6: 0.006904

[epoch: 139/100000, batch:    88/  187, ite: 13016] train loss: 0.066881, tar: 0.007528 
l0: 0.008211, l1: 0.008011, l2: 0.008984, l3: 0.009170, l4: 0.013485, l5: 0.011752, l6: 0.012212

[epoch: 139/100000, batch:    90/  187, ite: 13017] train loss: 0.066885, tar: 0.007528 
l0: 0.011210, l1: 0.009461, l2: 0.014161, l3: 0.015592, l4: 0.017775, l5: 0.021808, l6: 0.025078

[epoch: 139/100000, batch:    92/  187, ite: 13018] train loss: 0.066933, tar: 0.007532 
l0: 0.006047, l1: 0.006082, l2: 0.006352, l3: 0.006874, l4: 0.008806, l5: 0.007958, l6: 0.011866

[epoch: 139/100000, batch:    94/  187, ite: 13019] train loss: 0.066920, tar: 0.007531 
l0: 0.005417, l1: 0.005626, l2: 0.006430, l3: 0.006644, l4: 0.008783, l5: 0.007779, l6: 0.008422

[epoch: 139/100000, batch:    96/  187, ite: 13020] train loss: 0.066903, tar: 0.007528 
l0: 0.003125, l1: 0.003413, l2: 0.004075, l3: 0.003921, l4: 0.008861, l5: 0.006992, l6: 0.006338

[epoch: 139/100000, batch:    98/  187, ite: 13021] train loss: 0.066873, tar: 0.007524 
l0: 0.003895, l1: 0.004044, l2: 0.004480, l3: 0.004770, l4: 0.007251, l5: 0.006813, l6: 0.006469

[epoch: 139/100000, batch:   100/  187, ite: 13022] train loss: 0.066844, tar: 0.007521 
l0: 0.006812, l1: 0.006817, l2: 0.007052, l3: 0.007239, l4: 0.009392, l5: 0.008394, l6: 0.010126

[epoch: 139/100000, batch:   102/  187, ite: 13023] train loss: 0.066834, tar: 0.007520 
l0: 0.004200, l1: 0.004499, l2: 0.004228, l3: 0.004143, l4: 0.005223, l5: 0.005674, l6: 0.007505

[epoch: 139/100000, batch:   104/  187, ite: 13024] train loss: 0.066803, tar: 0.007517 
l0: 0.006539, l1: 0.006307, l2: 0.008446, l3: 0.010581, l4: 0.008399, l5: 0.008133, l6: 0.007577

[epoch: 139/100000, batch:   106/  187, ite: 13025] train loss: 0.066793, tar: 0.007516 
l0: 0.005602, l1: 0.005903, l2: 0.006653, l3: 0.007578, l4: 0.007324, l5: 0.006124, l6: 0.005978

[epoch: 139/100000, batch:   108/  187, ite: 13026] train loss: 0.066771, tar: 0.007514 
l0: 0.005382, l1: 0.006012, l2: 0.006300, l3: 0.005695, l4: 0.007973, l5: 0.007882, l6: 0.008533

[epoch: 139/100000, batch:   110/  187, ite: 13027] train loss: 0.066753, tar: 0.007512 
l0: 0.006186, l1: 0.007082, l2: 0.004553, l3: 0.004911, l4: 0.005124, l5: 0.005008, l6: 0.006389

[epoch: 139/100000, batch:   112/  187, ite: 13028] train loss: 0.066726, tar: 0.007510 
l0: 0.005537, l1: 0.006640, l2: 0.005874, l3: 0.006456, l4: 0.008393, l5: 0.007484, l6: 0.006739

[epoch: 139/100000, batch:   114/  187, ite: 13029] train loss: 0.066707, tar: 0.007509 
l0: 0.005907, l1: 0.005963, l2: 0.005810, l3: 0.006554, l4: 0.009588, l5: 0.010174, l6: 0.009667

[epoch: 139/100000, batch:   116/  187, ite: 13030] train loss: 0.066694, tar: 0.007507 
l0: 0.009498, l1: 0.009758, l2: 0.009046, l3: 0.008425, l4: 0.008827, l5: 0.010168, l6: 0.012924

[epoch: 139/100000, batch:   118/  187, ite: 13031] train loss: 0.066696, tar: 0.007509 
l0: 0.011781, l1: 0.011903, l2: 0.012468, l3: 0.012910, l4: 0.013094, l5: 0.013315, l6: 0.014637

[epoch: 139/100000, batch:   120/  187, ite: 13032] train loss: 0.066719, tar: 0.007513 
l0: 0.010712, l1: 0.010195, l2: 0.012149, l3: 0.013800, l4: 0.016170, l5: 0.015150, l6: 0.019890

[epoch: 139/100000, batch:   122/  187, ite: 13033] train loss: 0.066749, tar: 0.007516 
l0: 0.004840, l1: 0.005240, l2: 0.005322, l3: 0.005516, l4: 0.006522, l5: 0.005736, l6: 0.006753

[epoch: 139/100000, batch:   124/  187, ite: 13034] train loss: 0.066723, tar: 0.007514 
l0: 0.006169, l1: 0.005987, l2: 0.006588, l3: 0.006386, l4: 0.010067, l5: 0.009930, l6: 0.012584

[epoch: 139/100000, batch:   126/  187, ite: 13035] train loss: 0.066715, tar: 0.007512 
l0: 0.007351, l1: 0.007604, l2: 0.007905, l3: 0.008982, l4: 0.006318, l5: 0.006433, l6: 0.007911

[epoch: 139/100000, batch:   128/  187, ite: 13036] train loss: 0.066701, tar: 0.007512 
l0: 0.007043, l1: 0.007592, l2: 0.008032, l3: 0.007464, l4: 0.007388, l5: 0.007241, l6: 0.010277

[epoch: 139/100000, batch:   130/  187, ite: 13037] train loss: 0.066690, tar: 0.007512 
l0: 0.008382, l1: 0.009253, l2: 0.008303, l3: 0.007642, l4: 0.012143, l5: 0.010929, l6: 0.012004

[epoch: 139/100000, batch:   132/  187, ite: 13038] train loss: 0.066692, tar: 0.007513 
l0: 0.004375, l1: 0.004513, l2: 0.005084, l3: 0.005285, l4: 0.007588, l5: 0.007213, l6: 0.007426

[epoch: 139/100000, batch:   134/  187, ite: 13039] train loss: 0.066667, tar: 0.007510 
l0: 0.009513, l1: 0.009352, l2: 0.009352, l3: 0.009013, l4: 0.011101, l5: 0.011045, l6: 0.012188

[epoch: 139/100000, batch:   136/  187, ite: 13040] train loss: 0.066672, tar: 0.007511 
l0: 0.005654, l1: 0.005383, l2: 0.006595, l3: 0.005830, l4: 0.010635, l5: 0.009305, l6: 0.010560

[epoch: 139/100000, batch:   138/  187, ite: 13041] train loss: 0.066660, tar: 0.007510 
l0: 0.005503, l1: 0.005678, l2: 0.006032, l3: 0.006417, l4: 0.008096, l5: 0.008014, l6: 0.009442

[epoch: 139/100000, batch:   140/  187, ite: 13042] train loss: 0.066643, tar: 0.007508 
l0: 0.007026, l1: 0.006828, l2: 0.006324, l3: 0.006388, l4: 0.009881, l5: 0.009586, l6: 0.014142

[epoch: 139/100000, batch:   142/  187, ite: 13043] train loss: 0.066637, tar: 0.007507 
l0: 0.005682, l1: 0.005686, l2: 0.006860, l3: 0.008404, l4: 0.007777, l5: 0.008108, l6: 0.008416

[epoch: 139/100000, batch:   144/  187, ite: 13044] train loss: 0.066622, tar: 0.007506 
l0: 0.006665, l1: 0.006888, l2: 0.006454, l3: 0.006385, l4: 0.009901, l5: 0.010229, l6: 0.010081

[epoch: 139/100000, batch:   146/  187, ite: 13045] train loss: 0.066612, tar: 0.007505 
l0: 0.008214, l1: 0.008627, l2: 0.008414, l3: 0.007200, l4: 0.009490, l5: 0.009608, l6: 0.013910

[epoch: 139/100000, batch:   148/  187, ite: 13046] train loss: 0.066611, tar: 0.007505 
l0: 0.005845, l1: 0.006252, l2: 0.006549, l3: 0.006553, l4: 0.008125, l5: 0.008127, l6: 0.008354

[epoch: 139/100000, batch:   150/  187, ite: 13047] train loss: 0.066595, tar: 0.007504 
l0: 0.003633, l1: 0.003876, l2: 0.004229, l3: 0.004384, l4: 0.011933, l5: 0.010568, l6: 0.007576

[epoch: 139/100000, batch:   152/  187, ite: 13048] train loss: 0.066576, tar: 0.007500 
l0: 0.008176, l1: 0.008876, l2: 0.007953, l3: 0.008066, l4: 0.009182, l5: 0.008496, l6: 0.010923

[epoch: 139/100000, batch:   154/  187, ite: 13049] train loss: 0.066571, tar: 0.007501 
l0: 0.007038, l1: 0.006851, l2: 0.005867, l3: 0.007657, l4: 0.008072, l5: 0.007219, l6: 0.008848

[epoch: 139/100000, batch:   156/  187, ite: 13050] train loss: 0.066557, tar: 0.007500 
l0: 0.003510, l1: 0.003278, l2: 0.003324, l3: 0.003564, l4: 0.006586, l5: 0.006568, l6: 0.006920

[epoch: 139/100000, batch:   158/  187, ite: 13051] train loss: 0.066525, tar: 0.007497 
l0: 0.006407, l1: 0.007018, l2: 0.007241, l3: 0.006366, l4: 0.015450, l5: 0.013313, l6: 0.007415

[epoch: 139/100000, batch:   160/  187, ite: 13052] train loss: 0.066522, tar: 0.007495 
l0: 0.006465, l1: 0.006835, l2: 0.007448, l3: 0.006347, l4: 0.008303, l5: 0.006864, l6: 0.008971

[epoch: 139/100000, batch:   162/  187, ite: 13053] train loss: 0.066508, tar: 0.007495 
l0: 0.004311, l1: 0.004159, l2: 0.004897, l3: 0.005068, l4: 0.006229, l5: 0.007008, l6: 0.005462

[epoch: 139/100000, batch:   164/  187, ite: 13054] train loss: 0.066480, tar: 0.007491 
l0: 0.006039, l1: 0.006537, l2: 0.007810, l3: 0.007275, l4: 0.006511, l5: 0.006184, l6: 0.008969

[epoch: 139/100000, batch:   166/  187, ite: 13055] train loss: 0.066464, tar: 0.007490 
l0: 0.009724, l1: 0.009996, l2: 0.010774, l3: 0.010313, l4: 0.009244, l5: 0.008954, l6: 0.012743

[epoch: 139/100000, batch:   168/  187, ite: 13056] train loss: 0.066469, tar: 0.007492 
l0: 0.005340, l1: 0.005738, l2: 0.005620, l3: 0.005266, l4: 0.009494, l5: 0.008685, l6: 0.008847

[epoch: 139/100000, batch:   170/  187, ite: 13057] train loss: 0.066452, tar: 0.007490 
l0: 0.006794, l1: 0.006996, l2: 0.007584, l3: 0.007443, l4: 0.011139, l5: 0.012365, l6: 0.010210

[epoch: 139/100000, batch:   172/  187, ite: 13058] train loss: 0.066448, tar: 0.007490 
l0: 0.002056, l1: 0.002141, l2: 0.002509, l3: 0.002429, l4: 0.004628, l5: 0.004054, l6: 0.003791

[epoch: 139/100000, batch:   174/  187, ite: 13059] train loss: 0.066406, tar: 0.007484 
l0: 0.005100, l1: 0.005663, l2: 0.005873, l3: 0.005974, l4: 0.007608, l5: 0.007826, l6: 0.009460

[epoch: 139/100000, batch:   176/  187, ite: 13060] train loss: 0.066388, tar: 0.007482 
l0: 0.006316, l1: 0.005613, l2: 0.006226, l3: 0.006913, l4: 0.010924, l5: 0.009739, l6: 0.014047

[epoch: 139/100000, batch:   178/  187, ite: 13061] train loss: 0.066382, tar: 0.007481 
l0: 0.006400, l1: 0.006485, l2: 0.008257, l3: 0.007956, l4: 0.008580, l5: 0.008020, l6: 0.009316

[epoch: 139/100000, batch:   180/  187, ite: 13062] train loss: 0.066371, tar: 0.007480 
l0: 0.005364, l1: 0.005392, l2: 0.005008, l3: 0.004699, l4: 0.008767, l5: 0.010015, l6: 0.008382

[epoch: 139/100000, batch:   182/  187, ite: 13063] train loss: 0.066354, tar: 0.007478 
l0: 0.004499, l1: 0.004576, l2: 0.004855, l3: 0.004570, l4: 0.009259, l5: 0.008260, l6: 0.008983

[epoch: 139/100000, batch:   184/  187, ite: 13064] train loss: 0.066334, tar: 0.007475 
l0: 0.004199, l1: 0.004041, l2: 0.004358, l3: 0.005353, l4: 0.009434, l5: 0.007893, l6: 0.009211

[epoch: 139/100000, batch:   186/  187, ite: 13065] train loss: 0.066313, tar: 0.007472 
l0: 0.003060, l1: 0.002551, l2: 0.002120, l3: 0.002828, l4: 0.002951, l5: 0.005391, l6: 0.007190

[epoch: 139/100000, batch:   188/  187, ite: 13066] train loss: 0.066275, tar: 0.007468 
l0: 0.006874, l1: 0.006921, l2: 0.007599, l3: 0.008508, l4: 0.013209, l5: 0.009849, l6: 0.009457

[epoch: 140/100000, batch:     2/  187, ite: 13067] train loss: 0.066272, tar: 0.007467 
l0: 0.004561, l1: 0.005312, l2: 0.006421, l3: 0.004356, l4: 0.005526, l5: 0.004672, l6: 0.005600

[epoch: 140/100000, batch:     4/  187, ite: 13068] train loss: 0.066244, tar: 0.007465 
l0: 0.004294, l1: 0.004643, l2: 0.007592, l3: 0.006021, l4: 0.012099, l5: 0.006325, l6: 0.007258

[epoch: 140/100000, batch:     6/  187, ite: 13069] train loss: 0.066227, tar: 0.007462 
l0: 0.005456, l1: 0.005285, l2: 0.006488, l3: 0.005705, l4: 0.008043, l5: 0.008745, l6: 0.012269

[epoch: 140/100000, batch:     8/  187, ite: 13070] train loss: 0.066214, tar: 0.007460 
l0: 0.011797, l1: 0.011556, l2: 0.011673, l3: 0.013752, l4: 0.016181, l5: 0.015803, l6: 0.014566

[epoch: 140/100000, batch:    10/  187, ite: 13071] train loss: 0.066241, tar: 0.007464 
l0: 0.002536, l1: 0.002508, l2: 0.002431, l3: 0.002884, l4: 0.005322, l5: 0.004856, l6: 0.008005

[epoch: 140/100000, batch:    12/  187, ite: 13072] train loss: 0.066206, tar: 0.007459 
l0: 0.009889, l1: 0.009669, l2: 0.012231, l3: 0.013396, l4: 0.021893, l5: 0.017212, l6: 0.016059

[epoch: 140/100000, batch:    14/  187, ite: 13073] train loss: 0.066238, tar: 0.007462 
l0: 0.004797, l1: 0.005478, l2: 0.004905, l3: 0.004746, l4: 0.007915, l5: 0.007371, l6: 0.005101

[epoch: 140/100000, batch:    16/  187, ite: 13074] train loss: 0.066213, tar: 0.007459 
l0: 0.006296, l1: 0.005733, l2: 0.007035, l3: 0.007025, l4: 0.009810, l5: 0.009992, l6: 0.011808

[epoch: 140/100000, batch:    18/  187, ite: 13075] train loss: 0.066205, tar: 0.007458 
l0: 0.003565, l1: 0.003800, l2: 0.004701, l3: 0.004474, l4: 0.007662, l5: 0.010615, l6: 0.006567

[epoch: 140/100000, batch:    20/  187, ite: 13076] train loss: 0.066182, tar: 0.007454 
l0: 0.002629, l1: 0.002377, l2: 0.003400, l3: 0.003448, l4: 0.007723, l5: 0.006769, l6: 0.008770

[epoch: 140/100000, batch:    22/  187, ite: 13077] train loss: 0.066154, tar: 0.007450 
l0: 0.006012, l1: 0.006083, l2: 0.006621, l3: 0.006200, l4: 0.011573, l5: 0.009790, l6: 0.011285

[epoch: 140/100000, batch:    24/  187, ite: 13078] train loss: 0.066146, tar: 0.007449 
l0: 0.009620, l1: 0.009777, l2: 0.009483, l3: 0.009247, l4: 0.012420, l5: 0.011507, l6: 0.012995

[epoch: 140/100000, batch:    26/  187, ite: 13079] train loss: 0.066154, tar: 0.007451 
l0: 0.004719, l1: 0.005619, l2: 0.005976, l3: 0.005526, l4: 0.006214, l5: 0.005589, l6: 0.004459

[epoch: 140/100000, batch:    28/  187, ite: 13080] train loss: 0.066128, tar: 0.007448 
l0: 0.004341, l1: 0.004650, l2: 0.004393, l3: 0.004460, l4: 0.009106, l5: 0.007497, l6: 0.008528

[epoch: 140/100000, batch:    30/  187, ite: 13081] train loss: 0.066106, tar: 0.007445 
l0: 0.006379, l1: 0.006403, l2: 0.007831, l3: 0.008057, l4: 0.011975, l5: 0.009856, l6: 0.009573

[epoch: 140/100000, batch:    32/  187, ite: 13082] train loss: 0.066101, tar: 0.007444 
l0: 0.005573, l1: 0.005531, l2: 0.005602, l3: 0.006111, l4: 0.007885, l5: 0.006518, l6: 0.009230

[epoch: 140/100000, batch:    34/  187, ite: 13083] train loss: 0.066083, tar: 0.007443 
l0: 0.004518, l1: 0.004663, l2: 0.004115, l3: 0.004297, l4: 0.006992, l5: 0.006714, l6: 0.006932

[epoch: 140/100000, batch:    36/  187, ite: 13084] train loss: 0.066057, tar: 0.007440 
l0: 0.003123, l1: 0.003793, l2: 0.003128, l3: 0.003303, l4: 0.004526, l5: 0.004317, l6: 0.004256

[epoch: 140/100000, batch:    38/  187, ite: 13085] train loss: 0.066021, tar: 0.007436 
l0: 0.005931, l1: 0.006004, l2: 0.006664, l3: 0.007848, l4: 0.009131, l5: 0.008332, l6: 0.008024

[epoch: 140/100000, batch:    40/  187, ite: 13086] train loss: 0.066008, tar: 0.007434 
l0: 0.009024, l1: 0.009059, l2: 0.010510, l3: 0.011405, l4: 0.015011, l5: 0.011278, l6: 0.012080

[epoch: 140/100000, batch:    42/  187, ite: 13087] train loss: 0.066019, tar: 0.007436 
l0: 0.006196, l1: 0.006136, l2: 0.006826, l3: 0.006062, l4: 0.008475, l5: 0.009576, l6: 0.010046

[epoch: 140/100000, batch:    44/  187, ite: 13088] train loss: 0.066007, tar: 0.007435 
l0: 0.007595, l1: 0.007518, l2: 0.008025, l3: 0.008377, l4: 0.012663, l5: 0.013214, l6: 0.016699

[epoch: 140/100000, batch:    46/  187, ite: 13089] train loss: 0.066015, tar: 0.007435 
l0: 0.004824, l1: 0.004973, l2: 0.004515, l3: 0.004697, l4: 0.005959, l5: 0.005527, l6: 0.007196

[epoch: 140/100000, batch:    48/  187, ite: 13090] train loss: 0.065989, tar: 0.007433 
l0: 0.010838, l1: 0.009385, l2: 0.010485, l3: 0.011456, l4: 0.015018, l5: 0.016807, l6: 0.019076

[epoch: 140/100000, batch:    50/  187, ite: 13091] train loss: 0.066014, tar: 0.007436 
l0: 0.005315, l1: 0.005567, l2: 0.005494, l3: 0.005206, l4: 0.008641, l5: 0.008114, l6: 0.008224

[epoch: 140/100000, batch:    52/  187, ite: 13092] train loss: 0.065996, tar: 0.007434 
l0: 0.005506, l1: 0.005588, l2: 0.006937, l3: 0.005430, l4: 0.008991, l5: 0.008472, l6: 0.008443

[epoch: 140/100000, batch:    54/  187, ite: 13093] train loss: 0.065980, tar: 0.007432 
l0: 0.015529, l1: 0.016921, l2: 0.017359, l3: 0.015711, l4: 0.017606, l5: 0.014721, l6: 0.014737

[epoch: 140/100000, batch:    56/  187, ite: 13094] train loss: 0.066023, tar: 0.007439 
l0: 0.010225, l1: 0.009612, l2: 0.011527, l3: 0.011098, l4: 0.018316, l5: 0.017653, l6: 0.016615

[epoch: 140/100000, batch:    58/  187, ite: 13095] train loss: 0.066050, tar: 0.007442 
l0: 0.008195, l1: 0.008038, l2: 0.009202, l3: 0.009220, l4: 0.012471, l5: 0.013006, l6: 0.014041

[epoch: 140/100000, batch:    60/  187, ite: 13096] train loss: 0.066057, tar: 0.007443 
l0: 0.005012, l1: 0.005126, l2: 0.005714, l3: 0.005901, l4: 0.007674, l5: 0.007021, l6: 0.009581

[epoch: 140/100000, batch:    62/  187, ite: 13097] train loss: 0.066039, tar: 0.007440 
l0: 0.008154, l1: 0.008420, l2: 0.007535, l3: 0.007869, l4: 0.011190, l5: 0.009790, l6: 0.010661

[epoch: 140/100000, batch:    64/  187, ite: 13098] train loss: 0.066037, tar: 0.007441 
l0: 0.005164, l1: 0.005004, l2: 0.005901, l3: 0.006754, l4: 0.010092, l5: 0.009007, l6: 0.009411

[epoch: 140/100000, batch:    66/  187, ite: 13099] train loss: 0.066023, tar: 0.007439 
l0: 0.004297, l1: 0.008012, l2: 0.005549, l3: 0.003900, l4: 0.002852, l5: 0.003132, l6: 0.004370

[epoch: 140/100000, batch:    68/  187, ite: 13100] train loss: 0.065992, tar: 0.007436 
l0: 0.006505, l1: 0.005630, l2: 0.006848, l3: 0.007706, l4: 0.012655, l5: 0.012833, l6: 0.016824

[epoch: 140/100000, batch:    70/  187, ite: 13101] train loss: 0.065995, tar: 0.007435 
l0: 0.004094, l1: 0.004519, l2: 0.004977, l3: 0.005338, l4: 0.005474, l5: 0.005135, l6: 0.005495

[epoch: 140/100000, batch:    72/  187, ite: 13102] train loss: 0.065967, tar: 0.007432 
l0: 0.008921, l1: 0.009640, l2: 0.009739, l3: 0.009089, l4: 0.016658, l5: 0.013755, l6: 0.013296

[epoch: 140/100000, batch:    74/  187, ite: 13103] train loss: 0.065981, tar: 0.007434 
l0: 0.008613, l1: 0.008359, l2: 0.009020, l3: 0.008822, l4: 0.012964, l5: 0.013359, l6: 0.014093

[epoch: 140/100000, batch:    76/  187, ite: 13104] train loss: 0.065989, tar: 0.007435 
l0: 0.005960, l1: 0.006374, l2: 0.006449, l3: 0.006182, l4: 0.009090, l5: 0.008871, l6: 0.009471

[epoch: 140/100000, batch:    78/  187, ite: 13105] train loss: 0.065977, tar: 0.007433 
l0: 0.004531, l1: 0.004451, l2: 0.004454, l3: 0.004990, l4: 0.007017, l5: 0.007122, l6: 0.007130

[epoch: 140/100000, batch:    80/  187, ite: 13106] train loss: 0.065953, tar: 0.007431 
l0: 0.004967, l1: 0.004764, l2: 0.005303, l3: 0.005762, l4: 0.012568, l5: 0.010963, l6: 0.008914

[epoch: 140/100000, batch:    82/  187, ite: 13107] train loss: 0.065942, tar: 0.007428 
l0: 0.007531, l1: 0.007936, l2: 0.007571, l3: 0.010981, l4: 0.014484, l5: 0.010926, l6: 0.008234

[epoch: 140/100000, batch:    84/  187, ite: 13108] train loss: 0.065943, tar: 0.007429 
l0: 0.003764, l1: 0.003660, l2: 0.003729, l3: 0.006358, l4: 0.006946, l5: 0.012402, l6: 0.011538

[epoch: 140/100000, batch:    86/  187, ite: 13109] train loss: 0.065927, tar: 0.007425 
l0: 0.006882, l1: 0.006868, l2: 0.007435, l3: 0.007366, l4: 0.015125, l5: 0.013764, l6: 0.015716

[epoch: 140/100000, batch:    88/  187, ite: 13110] train loss: 0.065934, tar: 0.007425 
l0: 0.005694, l1: 0.005694, l2: 0.006685, l3: 0.007285, l4: 0.007806, l5: 0.006969, l6: 0.008192

[epoch: 140/100000, batch:    90/  187, ite: 13111] train loss: 0.065918, tar: 0.007423 
l0: 0.008283, l1: 0.007599, l2: 0.007649, l3: 0.007818, l4: 0.013597, l5: 0.013962, l6: 0.014834

[epoch: 140/100000, batch:    92/  187, ite: 13112] train loss: 0.065925, tar: 0.007424 
l0: 0.008374, l1: 0.008349, l2: 0.008987, l3: 0.009428, l4: 0.010451, l5: 0.009616, l6: 0.013808

[epoch: 140/100000, batch:    94/  187, ite: 13113] train loss: 0.065928, tar: 0.007425 
l0: 0.006077, l1: 0.006175, l2: 0.007729, l3: 0.007358, l4: 0.010073, l5: 0.010102, l6: 0.010010

[epoch: 140/100000, batch:    96/  187, ite: 13114] train loss: 0.065920, tar: 0.007424 
l0: 0.006654, l1: 0.007058, l2: 0.006753, l3: 0.006536, l4: 0.010792, l5: 0.010196, l6: 0.013501

[epoch: 140/100000, batch:    98/  187, ite: 13115] train loss: 0.065916, tar: 0.007423 
l0: 0.006902, l1: 0.007261, l2: 0.006788, l3: 0.006064, l4: 0.009787, l5: 0.009405, l6: 0.010536

[epoch: 140/100000, batch:   100/  187, ite: 13116] train loss: 0.065908, tar: 0.007422 
l0: 0.005664, l1: 0.005658, l2: 0.006050, l3: 0.006677, l4: 0.011436, l5: 0.010705, l6: 0.013877

[epoch: 140/100000, batch:   102/  187, ite: 13117] train loss: 0.065903, tar: 0.007421 
l0: 0.002592, l1: 0.002736, l2: 0.004026, l3: 0.004363, l4: 0.009759, l5: 0.012391, l6: 0.010530

[epoch: 140/100000, batch:   104/  187, ite: 13118] train loss: 0.065885, tar: 0.007417 
l0: 0.012006, l1: 0.011350, l2: 0.011306, l3: 0.013803, l4: 0.018695, l5: 0.019157, l6: 0.016753

[epoch: 140/100000, batch:   106/  187, ite: 13119] train loss: 0.065919, tar: 0.007421 
l0: 0.007506, l1: 0.007404, l2: 0.007707, l3: 0.008319, l4: 0.013502, l5: 0.013982, l6: 0.014422

[epoch: 140/100000, batch:   108/  187, ite: 13120] train loss: 0.065925, tar: 0.007421 
l0: 0.004661, l1: 0.004805, l2: 0.005343, l3: 0.005799, l4: 0.006866, l5: 0.005306, l6: 0.006201

[epoch: 140/100000, batch:   110/  187, ite: 13121] train loss: 0.065901, tar: 0.007418 
l0: 0.007674, l1: 0.008429, l2: 0.008367, l3: 0.008619, l4: 0.012436, l5: 0.012836, l6: 0.016900

[epoch: 140/100000, batch:   112/  187, ite: 13122] train loss: 0.065909, tar: 0.007418 
l0: 0.005505, l1: 0.005463, l2: 0.005678, l3: 0.006053, l4: 0.011541, l5: 0.010157, l6: 0.011805

[epoch: 140/100000, batch:   114/  187, ite: 13123] train loss: 0.065900, tar: 0.007417 
l0: 0.003554, l1: 0.003828, l2: 0.004035, l3: 0.003933, l4: 0.007217, l5: 0.005639, l6: 0.006775

[epoch: 140/100000, batch:   116/  187, ite: 13124] train loss: 0.065873, tar: 0.007413 
l0: 0.003125, l1: 0.003087, l2: 0.003873, l3: 0.003917, l4: 0.009269, l5: 0.006944, l6: 0.006896

[epoch: 140/100000, batch:   118/  187, ite: 13125] train loss: 0.065847, tar: 0.007410 
l0: 0.004040, l1: 0.004406, l2: 0.004182, l3: 0.004502, l4: 0.005559, l5: 0.004759, l6: 0.005637

[epoch: 140/100000, batch:   120/  187, ite: 13126] train loss: 0.065818, tar: 0.007407 
l0: 0.006621, l1: 0.006760, l2: 0.008325, l3: 0.009632, l4: 0.012879, l5: 0.008514, l6: 0.008901

[epoch: 140/100000, batch:   122/  187, ite: 13127] train loss: 0.065815, tar: 0.007406 
l0: 0.006360, l1: 0.006836, l2: 0.007034, l3: 0.007245, l4: 0.011259, l5: 0.009035, l6: 0.008327

[epoch: 140/100000, batch:   124/  187, ite: 13128] train loss: 0.065806, tar: 0.007405 
l0: 0.006808, l1: 0.006936, l2: 0.007125, l3: 0.006638, l4: 0.012263, l5: 0.011563, l6: 0.011587

[epoch: 140/100000, batch:   126/  187, ite: 13129] train loss: 0.065803, tar: 0.007404 
l0: 0.003982, l1: 0.004532, l2: 0.004238, l3: 0.003936, l4: 0.006898, l5: 0.006693, l6: 0.011756

[epoch: 140/100000, batch:   128/  187, ite: 13130] train loss: 0.065782, tar: 0.007401 
l0: 0.004627, l1: 0.004917, l2: 0.005344, l3: 0.005284, l4: 0.007550, l5: 0.005972, l6: 0.006093

[epoch: 140/100000, batch:   130/  187, ite: 13131] train loss: 0.065759, tar: 0.007399 
l0: 0.003824, l1: 0.003808, l2: 0.003992, l3: 0.003841, l4: 0.007609, l5: 0.007675, l6: 0.008191

[epoch: 140/100000, batch:   132/  187, ite: 13132] train loss: 0.065736, tar: 0.007396 
l0: 0.008896, l1: 0.010005, l2: 0.008699, l3: 0.008635, l4: 0.009447, l5: 0.007224, l6: 0.009350

[epoch: 140/100000, batch:   134/  187, ite: 13133] train loss: 0.065733, tar: 0.007397 
l0: 0.003740, l1: 0.003715, l2: 0.004360, l3: 0.004299, l4: 0.008397, l5: 0.008344, l6: 0.008031

[epoch: 140/100000, batch:   136/  187, ite: 13134] train loss: 0.065711, tar: 0.007394 
l0: 0.007242, l1: 0.006591, l2: 0.008412, l3: 0.008663, l4: 0.016340, l5: 0.017552, l6: 0.013370

[epoch: 140/100000, batch:   138/  187, ite: 13135] train loss: 0.065722, tar: 0.007394 
l0: 0.006416, l1: 0.007184, l2: 0.008797, l3: 0.008117, l4: 0.006540, l5: 0.005703, l6: 0.006205

[epoch: 140/100000, batch:   140/  187, ite: 13136] train loss: 0.065707, tar: 0.007393 
l0: 0.008440, l1: 0.008120, l2: 0.009096, l3: 0.009019, l4: 0.011689, l5: 0.011439, l6: 0.016417

[epoch: 140/100000, batch:   142/  187, ite: 13137] train loss: 0.065714, tar: 0.007394 
l0: 0.003157, l1: 0.003217, l2: 0.003107, l3: 0.002666, l4: 0.006679, l5: 0.007653, l6: 0.005935

[epoch: 140/100000, batch:   144/  187, ite: 13138] train loss: 0.065685, tar: 0.007390 
l0: 0.015555, l1: 0.016197, l2: 0.025843, l3: 0.024042, l4: 0.015027, l5: 0.014084, l6: 0.011282

[epoch: 140/100000, batch:   146/  187, ite: 13139] train loss: 0.065735, tar: 0.007397 
l0: 0.006310, l1: 0.006517, l2: 0.007652, l3: 0.007696, l4: 0.010790, l5: 0.009196, l6: 0.011554

[epoch: 140/100000, batch:   148/  187, ite: 13140] train loss: 0.065729, tar: 0.007396 
l0: 0.007699, l1: 0.008373, l2: 0.007912, l3: 0.007529, l4: 0.007196, l5: 0.007658, l6: 0.007247

[epoch: 140/100000, batch:   150/  187, ite: 13141] train loss: 0.065719, tar: 0.007397 
l0: 0.005211, l1: 0.005292, l2: 0.004686, l3: 0.005260, l4: 0.007064, l5: 0.006946, l6: 0.007468

[epoch: 140/100000, batch:   152/  187, ite: 13142] train loss: 0.065698, tar: 0.007395 
l0: 0.009758, l1: 0.010048, l2: 0.009398, l3: 0.010106, l4: 0.013034, l5: 0.012152, l6: 0.016603

[epoch: 140/100000, batch:   154/  187, ite: 13143] train loss: 0.065711, tar: 0.007397 
l0: 0.004849, l1: 0.005239, l2: 0.006141, l3: 0.005182, l4: 0.008481, l5: 0.007044, l6: 0.008309

[epoch: 140/100000, batch:   156/  187, ite: 13144] train loss: 0.065693, tar: 0.007394 
l0: 0.009561, l1: 0.008636, l2: 0.009392, l3: 0.009433, l4: 0.017382, l5: 0.019058, l6: 0.018757

[epoch: 140/100000, batch:   158/  187, ite: 13145] train loss: 0.065717, tar: 0.007396 
l0: 0.005985, l1: 0.005990, l2: 0.006321, l3: 0.006748, l4: 0.009738, l5: 0.008741, l6: 0.008853

[epoch: 140/100000, batch:   160/  187, ite: 13146] train loss: 0.065705, tar: 0.007395 
l0: 0.002835, l1: 0.002899, l2: 0.002786, l3: 0.003226, l4: 0.005446, l5: 0.005667, l6: 0.005198

[epoch: 140/100000, batch:   162/  187, ite: 13147] train loss: 0.065672, tar: 0.007391 
l0: 0.005892, l1: 0.006551, l2: 0.005216, l3: 0.005301, l4: 0.008612, l5: 0.007635, l6: 0.007834

[epoch: 140/100000, batch:   164/  187, ite: 13148] train loss: 0.065656, tar: 0.007390 
l0: 0.002596, l1: 0.002967, l2: 0.003511, l3: 0.001858, l4: 0.003529, l5: 0.002368, l6: 0.002835

[epoch: 140/100000, batch:   166/  187, ite: 13149] train loss: 0.065616, tar: 0.007386 
l0: 0.012857, l1: 0.012928, l2: 0.013678, l3: 0.016480, l4: 0.024883, l5: 0.021782, l6: 0.018872

[epoch: 140/100000, batch:   168/  187, ite: 13150] train loss: 0.065664, tar: 0.007390 
l0: 0.005448, l1: 0.005635, l2: 0.005655, l3: 0.006432, l4: 0.008285, l5: 0.008129, l6: 0.009414

[epoch: 140/100000, batch:   170/  187, ite: 13151] train loss: 0.065650, tar: 0.007389 
l0: 0.005096, l1: 0.005755, l2: 0.004947, l3: 0.005113, l4: 0.006418, l5: 0.006318, l6: 0.006624

[epoch: 140/100000, batch:   172/  187, ite: 13152] train loss: 0.065628, tar: 0.007387 
l0: 0.005741, l1: 0.005803, l2: 0.007021, l3: 0.007509, l4: 0.016311, l5: 0.012204, l6: 0.012785

[epoch: 140/100000, batch:   174/  187, ite: 13153] train loss: 0.065629, tar: 0.007385 
l0: 0.011560, l1: 0.011290, l2: 0.011889, l3: 0.011757, l4: 0.011616, l5: 0.012948, l6: 0.016792

[epoch: 140/100000, batch:   176/  187, ite: 13154] train loss: 0.065649, tar: 0.007389 
l0: 0.006498, l1: 0.007115, l2: 0.006590, l3: 0.006197, l4: 0.009699, l5: 0.009695, l6: 0.011266

[epoch: 140/100000, batch:   178/  187, ite: 13155] train loss: 0.065641, tar: 0.007388 
l0: 0.003791, l1: 0.004294, l2: 0.003996, l3: 0.003910, l4: 0.005526, l5: 0.005566, l6: 0.005591

[epoch: 140/100000, batch:   180/  187, ite: 13156] train loss: 0.065613, tar: 0.007385 
l0: 0.007139, l1: 0.007508, l2: 0.008526, l3: 0.008649, l4: 0.011429, l5: 0.011414, l6: 0.011501

[epoch: 140/100000, batch:   182/  187, ite: 13157] train loss: 0.065613, tar: 0.007385 
l0: 0.005774, l1: 0.005627, l2: 0.007468, l3: 0.007918, l4: 0.005374, l5: 0.006075, l6: 0.010299

[epoch: 140/100000, batch:   184/  187, ite: 13158] train loss: 0.065598, tar: 0.007383 
l0: 0.004118, l1: 0.003557, l2: 0.005680, l3: 0.005669, l4: 0.008208, l5: 0.010099, l6: 0.007861

[epoch: 140/100000, batch:   186/  187, ite: 13159] train loss: 0.065581, tar: 0.007381 
l0: 0.006987, l1: 0.007459, l2: 0.008399, l3: 0.007432, l4: 0.010700, l5: 0.011485, l6: 0.013610

[epoch: 140/100000, batch:   188/  187, ite: 13160] train loss: 0.065581, tar: 0.007380 
l0: 0.008427, l1: 0.008907, l2: 0.008577, l3: 0.007902, l4: 0.007166, l5: 0.007906, l6: 0.007797

[epoch: 141/100000, batch:     2/  187, ite: 13161] train loss: 0.065574, tar: 0.007381 
l0: 0.005265, l1: 0.005647, l2: 0.005566, l3: 0.005732, l4: 0.008721, l5: 0.007984, l6: 0.009072

[epoch: 141/100000, batch:     4/  187, ite: 13162] train loss: 0.065558, tar: 0.007379 
l0: 0.015262, l1: 0.015340, l2: 0.013396, l3: 0.014957, l4: 0.016179, l5: 0.015452, l6: 0.017342

[epoch: 141/100000, batch:     6/  187, ite: 13163] train loss: 0.065595, tar: 0.007386 
l0: 0.003114, l1: 0.003585, l2: 0.003652, l3: 0.003913, l4: 0.005865, l5: 0.004839, l6: 0.004105

[epoch: 141/100000, batch:     8/  187, ite: 13164] train loss: 0.065564, tar: 0.007382 
l0: 0.006368, l1: 0.006208, l2: 0.006561, l3: 0.006237, l4: 0.007734, l5: 0.010547, l6: 0.010059

[epoch: 141/100000, batch:    10/  187, ite: 13165] train loss: 0.065553, tar: 0.007382 
l0: 0.005241, l1: 0.005636, l2: 0.005760, l3: 0.006587, l4: 0.009866, l5: 0.010041, l6: 0.009056

[epoch: 141/100000, batch:    12/  187, ite: 13166] train loss: 0.065542, tar: 0.007380 
l0: 0.006568, l1: 0.006757, l2: 0.006374, l3: 0.006797, l4: 0.010977, l5: 0.010246, l6: 0.007886

[epoch: 141/100000, batch:    14/  187, ite: 13167] train loss: 0.065533, tar: 0.007379 
l0: 0.004821, l1: 0.004204, l2: 0.005037, l3: 0.005306, l4: 0.008052, l5: 0.008755, l6: 0.010542

[epoch: 141/100000, batch:    16/  187, ite: 13168] train loss: 0.065517, tar: 0.007377 
l0: 0.010656, l1: 0.011999, l2: 0.011338, l3: 0.010476, l4: 0.012348, l5: 0.012438, l6: 0.014632

[epoch: 141/100000, batch:    18/  187, ite: 13169] train loss: 0.065533, tar: 0.007380 
l0: 0.004342, l1: 0.004642, l2: 0.005169, l3: 0.005007, l4: 0.005989, l5: 0.006044, l6: 0.007601

[epoch: 141/100000, batch:    20/  187, ite: 13170] train loss: 0.065510, tar: 0.007377 
l0: 0.010893, l1: 0.009888, l2: 0.011438, l3: 0.012286, l4: 0.020743, l5: 0.021395, l6: 0.018480

[epoch: 141/100000, batch:    22/  187, ite: 13171] train loss: 0.065544, tar: 0.007380 
l0: 0.005200, l1: 0.005510, l2: 0.005734, l3: 0.005685, l4: 0.006899, l5: 0.006556, l6: 0.009088

[epoch: 141/100000, batch:    24/  187, ite: 13172] train loss: 0.065526, tar: 0.007378 
l0: 0.004941, l1: 0.004925, l2: 0.004766, l3: 0.005064, l4: 0.006635, l5: 0.005809, l6: 0.011677

[epoch: 141/100000, batch:    26/  187, ite: 13173] train loss: 0.065508, tar: 0.007376 
l0: 0.007122, l1: 0.007458, l2: 0.008196, l3: 0.009009, l4: 0.009997, l5: 0.008871, l6: 0.007151

[epoch: 141/100000, batch:    28/  187, ite: 13174] train loss: 0.065501, tar: 0.007376 
l0: 0.007522, l1: 0.006902, l2: 0.007463, l3: 0.007579, l4: 0.012074, l5: 0.011128, l6: 0.015448

[epoch: 141/100000, batch:    30/  187, ite: 13175] train loss: 0.065503, tar: 0.007376 
l0: 0.005062, l1: 0.005288, l2: 0.005822, l3: 0.005479, l4: 0.006521, l5: 0.006604, l6: 0.007542

[epoch: 141/100000, batch:    32/  187, ite: 13176] train loss: 0.065484, tar: 0.007374 
l0: 0.008763, l1: 0.008978, l2: 0.008830, l3: 0.008932, l4: 0.015199, l5: 0.014682, l6: 0.014751

[epoch: 141/100000, batch:    34/  187, ite: 13177] train loss: 0.065496, tar: 0.007375 
l0: 0.004719, l1: 0.004471, l2: 0.004642, l3: 0.005281, l4: 0.009697, l5: 0.007647, l6: 0.011069

[epoch: 141/100000, batch:    36/  187, ite: 13178] train loss: 0.065481, tar: 0.007373 
l0: 0.010341, l1: 0.009096, l2: 0.010448, l3: 0.011259, l4: 0.015873, l5: 0.017453, l6: 0.021129

[epoch: 141/100000, batch:    38/  187, ite: 13179] train loss: 0.065506, tar: 0.007376 
l0: 0.004480, l1: 0.004015, l2: 0.004033, l3: 0.005233, l4: 0.013356, l5: 0.012801, l6: 0.011787

[epoch: 141/100000, batch:    40/  187, ite: 13180] train loss: 0.065498, tar: 0.007373 
l0: 0.005761, l1: 0.006552, l2: 0.005581, l3: 0.005252, l4: 0.005368, l5: 0.005126, l6: 0.005424

[epoch: 141/100000, batch:    42/  187, ite: 13181] train loss: 0.065476, tar: 0.007372 
l0: 0.006697, l1: 0.007512, l2: 0.008241, l3: 0.007998, l4: 0.009533, l5: 0.008146, l6: 0.010980

[epoch: 141/100000, batch:    44/  187, ite: 13182] train loss: 0.065470, tar: 0.007371 
l0: 0.004398, l1: 0.004420, l2: 0.004211, l3: 0.004384, l4: 0.006118, l5: 0.006115, l6: 0.007614

[epoch: 141/100000, batch:    46/  187, ite: 13183] train loss: 0.065446, tar: 0.007369 
l0: 0.006337, l1: 0.006700, l2: 0.006719, l3: 0.007028, l4: 0.010741, l5: 0.010256, l6: 0.009130

[epoch: 141/100000, batch:    48/  187, ite: 13184] train loss: 0.065439, tar: 0.007368 
l0: 0.014316, l1: 0.014270, l2: 0.014714, l3: 0.013167, l4: 0.024756, l5: 0.023251, l6: 0.024380

[epoch: 141/100000, batch:    50/  187, ite: 13185] train loss: 0.065493, tar: 0.007374 
l0: 0.005923, l1: 0.007164, l2: 0.006573, l3: 0.006723, l4: 0.006054, l5: 0.005959, l6: 0.005798

[epoch: 141/100000, batch:    52/  187, ite: 13186] train loss: 0.065475, tar: 0.007372 
l0: 0.005483, l1: 0.006165, l2: 0.005592, l3: 0.005306, l4: 0.006956, l5: 0.006403, l6: 0.008384

[epoch: 141/100000, batch:    54/  187, ite: 13187] train loss: 0.065457, tar: 0.007371 
l0: 0.004058, l1: 0.004238, l2: 0.004548, l3: 0.004439, l4: 0.004877, l5: 0.005431, l6: 0.008058

[epoch: 141/100000, batch:    56/  187, ite: 13188] train loss: 0.065432, tar: 0.007368 
l0: 0.005185, l1: 0.005679, l2: 0.005181, l3: 0.004860, l4: 0.007094, l5: 0.007469, l6: 0.008389

[epoch: 141/100000, batch:    58/  187, ite: 13189] train loss: 0.065414, tar: 0.007366 
l0: 0.007683, l1: 0.007935, l2: 0.009501, l3: 0.009064, l4: 0.012572, l5: 0.010577, l6: 0.011314

[epoch: 141/100000, batch:    60/  187, ite: 13190] train loss: 0.065416, tar: 0.007366 
l0: 0.005405, l1: 0.005655, l2: 0.005736, l3: 0.005979, l4: 0.010707, l5: 0.009772, l6: 0.007036

[epoch: 141/100000, batch:    62/  187, ite: 13191] train loss: 0.065404, tar: 0.007365 
l0: 0.006032, l1: 0.006951, l2: 0.007041, l3: 0.006997, l4: 0.005764, l5: 0.004767, l6: 0.005263

[epoch: 141/100000, batch:    64/  187, ite: 13192] train loss: 0.065385, tar: 0.007364 
l0: 0.007830, l1: 0.008936, l2: 0.007974, l3: 0.007857, l4: 0.008666, l5: 0.008869, l6: 0.009544

[epoch: 141/100000, batch:    66/  187, ite: 13193] train loss: 0.065380, tar: 0.007364 
l0: 0.007703, l1: 0.007166, l2: 0.009063, l3: 0.008860, l4: 0.010831, l5: 0.011893, l6: 0.013230

[epoch: 141/100000, batch:    68/  187, ite: 13194] train loss: 0.065383, tar: 0.007364 
l0: 0.004701, l1: 0.004814, l2: 0.004611, l3: 0.005224, l4: 0.007005, l5: 0.005436, l6: 0.007152

[epoch: 141/100000, batch:    70/  187, ite: 13195] train loss: 0.065361, tar: 0.007362 
l0: 0.002733, l1: 0.003034, l2: 0.003023, l3: 0.002691, l4: 0.006483, l5: 0.005706, l6: 0.005297

[epoch: 141/100000, batch:    72/  187, ite: 13196] train loss: 0.065330, tar: 0.007358 
l0: 0.006607, l1: 0.006251, l2: 0.007148, l3: 0.007538, l4: 0.013911, l5: 0.013993, l6: 0.014166

[epoch: 141/100000, batch:    74/  187, ite: 13197] train loss: 0.065334, tar: 0.007358 
l0: 0.004506, l1: 0.005708, l2: 0.005891, l3: 0.005892, l4: 0.008639, l5: 0.007465, l6: 0.009956

[epoch: 141/100000, batch:    76/  187, ite: 13198] train loss: 0.065319, tar: 0.007355 
l0: 0.005974, l1: 0.005577, l2: 0.005696, l3: 0.006400, l4: 0.009177, l5: 0.008193, l6: 0.009980

[epoch: 141/100000, batch:    78/  187, ite: 13199] train loss: 0.065307, tar: 0.007354 
l0: 0.005034, l1: 0.005087, l2: 0.005453, l3: 0.005636, l4: 0.009053, l5: 0.008972, l6: 0.009312

[epoch: 141/100000, batch:    80/  187, ite: 13200] train loss: 0.065293, tar: 0.007352 
l0: 0.008194, l1: 0.008333, l2: 0.009302, l3: 0.010048, l4: 0.013229, l5: 0.011970, l6: 0.011709

[epoch: 141/100000, batch:    82/  187, ite: 13201] train loss: 0.065300, tar: 0.007353 
l0: 0.006881, l1: 0.007092, l2: 0.006528, l3: 0.006501, l4: 0.007500, l5: 0.008148, l6: 0.008365

[epoch: 141/100000, batch:    84/  187, ite: 13202] train loss: 0.065288, tar: 0.007352 
l0: 0.007129, l1: 0.006980, l2: 0.008815, l3: 0.008885, l4: 0.008857, l5: 0.010213, l6: 0.008473

[epoch: 141/100000, batch:    86/  187, ite: 13203] train loss: 0.065283, tar: 0.007352 
l0: 0.010383, l1: 0.009816, l2: 0.011153, l3: 0.011830, l4: 0.014719, l5: 0.013485, l6: 0.014727

[epoch: 141/100000, batch:    88/  187, ite: 13204] train loss: 0.065300, tar: 0.007355 
l0: 0.005220, l1: 0.005304, l2: 0.005681, l3: 0.004983, l4: 0.006302, l5: 0.006406, l6: 0.005849

[epoch: 141/100000, batch:    90/  187, ite: 13205] train loss: 0.065279, tar: 0.007353 
l0: 0.009009, l1: 0.009081, l2: 0.008520, l3: 0.008207, l4: 0.011719, l5: 0.013471, l6: 0.015149

[epoch: 141/100000, batch:    92/  187, ite: 13206] train loss: 0.065287, tar: 0.007354 
l0: 0.005973, l1: 0.006235, l2: 0.007583, l3: 0.007171, l4: 0.011209, l5: 0.010227, l6: 0.011618

[epoch: 141/100000, batch:    94/  187, ite: 13207] train loss: 0.065283, tar: 0.007353 
l0: 0.002973, l1: 0.003073, l2: 0.002799, l3: 0.003236, l4: 0.006859, l5: 0.007715, l6: 0.006293

[epoch: 141/100000, batch:    96/  187, ite: 13208] train loss: 0.065256, tar: 0.007350 
l0: 0.010360, l1: 0.010592, l2: 0.011997, l3: 0.012923, l4: 0.013435, l5: 0.013356, l6: 0.011355

[epoch: 141/100000, batch:    98/  187, ite: 13209] train loss: 0.065272, tar: 0.007352 
l0: 0.005948, l1: 0.005759, l2: 0.006270, l3: 0.006958, l4: 0.009543, l5: 0.009861, l6: 0.009972

[epoch: 141/100000, batch:   100/  187, ite: 13210] train loss: 0.065263, tar: 0.007351 
l0: 0.013943, l1: 0.014766, l2: 0.019147, l3: 0.016299, l4: 0.011280, l5: 0.012294, l6: 0.011890

[epoch: 141/100000, batch:   102/  187, ite: 13211] train loss: 0.065291, tar: 0.007356 
l0: 0.007605, l1: 0.007902, l2: 0.009163, l3: 0.010774, l4: 0.011741, l5: 0.009257, l6: 0.011209

[epoch: 141/100000, batch:   104/  187, ite: 13212] train loss: 0.065293, tar: 0.007357 
l0: 0.007636, l1: 0.008014, l2: 0.008117, l3: 0.007730, l4: 0.008146, l5: 0.007525, l6: 0.009059

[epoch: 141/100000, batch:   106/  187, ite: 13213] train loss: 0.065285, tar: 0.007357 
l0: 0.008758, l1: 0.008177, l2: 0.008974, l3: 0.009437, l4: 0.013233, l5: 0.013208, l6: 0.014197

[epoch: 141/100000, batch:   108/  187, ite: 13214] train loss: 0.065294, tar: 0.007358 
l0: 0.006772, l1: 0.007361, l2: 0.006700, l3: 0.005802, l4: 0.008074, l5: 0.010721, l6: 0.011051

[epoch: 141/100000, batch:   110/  187, ite: 13215] train loss: 0.065287, tar: 0.007358 
l0: 0.004250, l1: 0.004608, l2: 0.004747, l3: 0.003655, l4: 0.007003, l5: 0.007105, l6: 0.010281

[epoch: 141/100000, batch:   112/  187, ite: 13216] train loss: 0.065267, tar: 0.007355 
l0: 0.009332, l1: 0.009117, l2: 0.009786, l3: 0.009087, l4: 0.009043, l5: 0.010493, l6: 0.013978

[epoch: 141/100000, batch:   114/  187, ite: 13217] train loss: 0.065272, tar: 0.007357 
l0: 0.008125, l1: 0.008668, l2: 0.010191, l3: 0.009870, l4: 0.012114, l5: 0.010065, l6: 0.012351

[epoch: 141/100000, batch:   116/  187, ite: 13218] train loss: 0.065277, tar: 0.007357 
l0: 0.008501, l1: 0.010175, l2: 0.008753, l3: 0.008008, l4: 0.009122, l5: 0.007411, l6: 0.005926

[epoch: 141/100000, batch:   118/  187, ite: 13219] train loss: 0.065271, tar: 0.007358 
l0: 0.017048, l1: 0.014758, l2: 0.019904, l3: 0.023426, l4: 0.029977, l5: 0.028473, l6: 0.029671

[epoch: 141/100000, batch:   120/  187, ite: 13220] train loss: 0.065351, tar: 0.007366 
l0: 0.005162, l1: 0.005207, l2: 0.004750, l3: 0.005977, l4: 0.010492, l5: 0.008808, l6: 0.012079

[epoch: 141/100000, batch:   122/  187, ite: 13221] train loss: 0.065341, tar: 0.007364 
l0: 0.003403, l1: 0.003227, l2: 0.004052, l3: 0.004920, l4: 0.005705, l5: 0.005216, l6: 0.004104

[epoch: 141/100000, batch:   124/  187, ite: 13222] train loss: 0.065312, tar: 0.007361 
l0: 0.008744, l1: 0.009813, l2: 0.009657, l3: 0.009013, l4: 0.009694, l5: 0.008446, l6: 0.009336

[epoch: 141/100000, batch:   126/  187, ite: 13223] train loss: 0.065312, tar: 0.007362 
l0: 0.002049, l1: 0.002086, l2: 0.001855, l3: 0.002451, l4: 0.005541, l5: 0.006311, l6: 0.005619

[epoch: 141/100000, batch:   128/  187, ite: 13224] train loss: 0.065280, tar: 0.007358 
l0: 0.007115, l1: 0.007669, l2: 0.007697, l3: 0.007710, l4: 0.011006, l5: 0.011706, l6: 0.013871

[epoch: 141/100000, batch:   130/  187, ite: 13225] train loss: 0.065281, tar: 0.007358 
l0: 0.019277, l1: 0.019106, l2: 0.023381, l3: 0.022024, l4: 0.020919, l5: 0.020844, l6: 0.024305

[epoch: 141/100000, batch:   132/  187, ite: 13226] train loss: 0.065350, tar: 0.007367 
l0: 0.005176, l1: 0.005017, l2: 0.006389, l3: 0.007377, l4: 0.008303, l5: 0.007578, l6: 0.009841

[epoch: 141/100000, batch:   134/  187, ite: 13227] train loss: 0.065337, tar: 0.007366 
l0: 0.004303, l1: 0.004220, l2: 0.004301, l3: 0.004664, l4: 0.006077, l5: 0.005596, l6: 0.007970

[epoch: 141/100000, batch:   136/  187, ite: 13228] train loss: 0.065314, tar: 0.007363 
l0: 0.004521, l1: 0.005399, l2: 0.004691, l3: 0.004177, l4: 0.006162, l5: 0.007571, l6: 0.008122

[epoch: 141/100000, batch:   138/  187, ite: 13229] train loss: 0.065294, tar: 0.007361 
l0: 0.003607, l1: 0.004218, l2: 0.002696, l3: 0.002498, l4: 0.003075, l5: 0.004193, l6: 0.003553

[epoch: 141/100000, batch:   140/  187, ite: 13230] train loss: 0.065260, tar: 0.007358 
l0: 0.006684, l1: 0.007822, l2: 0.008265, l3: 0.007863, l4: 0.006050, l5: 0.006039, l6: 0.009091

[epoch: 141/100000, batch:   142/  187, ite: 13231] train loss: 0.065249, tar: 0.007357 
l0: 0.006226, l1: 0.006695, l2: 0.005791, l3: 0.007680, l4: 0.013134, l5: 0.013479, l6: 0.012052

[epoch: 141/100000, batch:   144/  187, ite: 13232] train loss: 0.065249, tar: 0.007356 
l0: 0.005580, l1: 0.006001, l2: 0.006371, l3: 0.006059, l4: 0.011267, l5: 0.009864, l6: 0.008150

[epoch: 141/100000, batch:   146/  187, ite: 13233] train loss: 0.065240, tar: 0.007355 
l0: 0.007430, l1: 0.007733, l2: 0.007912, l3: 0.007621, l4: 0.009643, l5: 0.008774, l6: 0.011155

[epoch: 141/100000, batch:   148/  187, ite: 13234] train loss: 0.065236, tar: 0.007355 
l0: 0.004941, l1: 0.005833, l2: 0.005378, l3: 0.005474, l4: 0.008010, l5: 0.007170, l6: 0.006754

[epoch: 141/100000, batch:   150/  187, ite: 13235] train loss: 0.065218, tar: 0.007353 
l0: 0.006305, l1: 0.007121, l2: 0.006239, l3: 0.005140, l4: 0.009968, l5: 0.008878, l6: 0.009329

[epoch: 141/100000, batch:   152/  187, ite: 13236] train loss: 0.065208, tar: 0.007352 
l0: 0.009032, l1: 0.010598, l2: 0.011608, l3: 0.011110, l4: 0.013199, l5: 0.010154, l6: 0.010557

[epoch: 141/100000, batch:   154/  187, ite: 13237] train loss: 0.065217, tar: 0.007353 
l0: 0.004820, l1: 0.005537, l2: 0.005621, l3: 0.005429, l4: 0.008890, l5: 0.006422, l6: 0.006863

[epoch: 141/100000, batch:   156/  187, ite: 13238] train loss: 0.065200, tar: 0.007351 
l0: 0.006527, l1: 0.006621, l2: 0.006680, l3: 0.006929, l4: 0.015795, l5: 0.016793, l6: 0.015647

[epoch: 141/100000, batch:   158/  187, ite: 13239] train loss: 0.065207, tar: 0.007351 
l0: 0.003832, l1: 0.004117, l2: 0.003908, l3: 0.003971, l4: 0.005541, l5: 0.004857, l6: 0.006059

[epoch: 141/100000, batch:   160/  187, ite: 13240] train loss: 0.065181, tar: 0.007348 
l0: 0.006317, l1: 0.006475, l2: 0.005889, l3: 0.006206, l4: 0.007841, l5: 0.008145, l6: 0.008474

[epoch: 141/100000, batch:   162/  187, ite: 13241] train loss: 0.065168, tar: 0.007347 
l0: 0.007186, l1: 0.007384, l2: 0.007172, l3: 0.006643, l4: 0.009583, l5: 0.009941, l6: 0.009669

[epoch: 141/100000, batch:   164/  187, ite: 13242] train loss: 0.065162, tar: 0.007347 
l0: 0.003779, l1: 0.003481, l2: 0.003933, l3: 0.004058, l4: 0.006210, l5: 0.006733, l6: 0.008157

[epoch: 141/100000, batch:   166/  187, ite: 13243] train loss: 0.065139, tar: 0.007344 
l0: 0.009609, l1: 0.011380, l2: 0.009785, l3: 0.009519, l4: 0.012237, l5: 0.009677, l6: 0.010198

[epoch: 141/100000, batch:   168/  187, ite: 13244] train loss: 0.065145, tar: 0.007346 
l0: 0.005029, l1: 0.005077, l2: 0.004743, l3: 0.005014, l4: 0.006123, l5: 0.006092, l6: 0.006371

[epoch: 141/100000, batch:   170/  187, ite: 13245] train loss: 0.065123, tar: 0.007344 
l0: 0.008061, l1: 0.008221, l2: 0.008421, l3: 0.009154, l4: 0.009022, l5: 0.009976, l6: 0.013254

[epoch: 141/100000, batch:   172/  187, ite: 13246] train loss: 0.065124, tar: 0.007345 
l0: 0.005672, l1: 0.006185, l2: 0.005304, l3: 0.005399, l4: 0.007232, l5: 0.007005, l6: 0.008415

[epoch: 141/100000, batch:   174/  187, ite: 13247] train loss: 0.065108, tar: 0.007343 
l0: 0.006368, l1: 0.006154, l2: 0.007407, l3: 0.008543, l4: 0.016602, l5: 0.013754, l6: 0.013763

[epoch: 141/100000, batch:   176/  187, ite: 13248] train loss: 0.065114, tar: 0.007342 
l0: 0.004306, l1: 0.004136, l2: 0.004004, l3: 0.004568, l4: 0.008158, l5: 0.008258, l6: 0.012721

[epoch: 141/100000, batch:   178/  187, ite: 13249] train loss: 0.065099, tar: 0.007340 
l0: 0.005108, l1: 0.005652, l2: 0.005252, l3: 0.005686, l4: 0.007087, l5: 0.007080, l6: 0.007516

[epoch: 141/100000, batch:   180/  187, ite: 13250] train loss: 0.065082, tar: 0.007338 
l0: 0.002599, l1: 0.002774, l2: 0.003018, l3: 0.002408, l4: 0.005364, l5: 0.005148, l6: 0.004692

[epoch: 141/100000, batch:   182/  187, ite: 13251] train loss: 0.065050, tar: 0.007334 
l0: 0.004276, l1: 0.004583, l2: 0.004768, l3: 0.004781, l4: 0.009203, l5: 0.007092, l6: 0.006954

[epoch: 141/100000, batch:   184/  187, ite: 13252] train loss: 0.065032, tar: 0.007332 
l0: 0.005340, l1: 0.005775, l2: 0.006123, l3: 0.006746, l4: 0.008319, l5: 0.008135, l6: 0.008270

[epoch: 141/100000, batch:   186/  187, ite: 13253] train loss: 0.065019, tar: 0.007330 
l0: 0.006226, l1: 0.005825, l2: 0.007333, l3: 0.007235, l4: 0.009566, l5: 0.010342, l6: 0.013247

[epoch: 141/100000, batch:   188/  187, ite: 13254] train loss: 0.065014, tar: 0.007330 
l0: 0.008219, l1: 0.008008, l2: 0.011151, l3: 0.010235, l4: 0.017557, l5: 0.015696, l6: 0.019633

[epoch: 142/100000, batch:     2/  187, ite: 13255] train loss: 0.065035, tar: 0.007330 
l0: 0.005608, l1: 0.006517, l2: 0.006425, l3: 0.006716, l4: 0.008564, l5: 0.008436, l6: 0.009396

[epoch: 142/100000, batch:     4/  187, ite: 13256] train loss: 0.065024, tar: 0.007329 
l0: 0.006421, l1: 0.006532, l2: 0.007702, l3: 0.008341, l4: 0.008910, l5: 0.007596, l6: 0.007720

[epoch: 142/100000, batch:     6/  187, ite: 13257] train loss: 0.065015, tar: 0.007328 
l0: 0.005772, l1: 0.006025, l2: 0.006768, l3: 0.006267, l4: 0.008299, l5: 0.007777, l6: 0.007773

[epoch: 142/100000, batch:     8/  187, ite: 13258] train loss: 0.065002, tar: 0.007327 
l0: 0.016159, l1: 0.015184, l2: 0.013814, l3: 0.021565, l4: 0.028377, l5: 0.025874, l6: 0.021153

[epoch: 142/100000, batch:    10/  187, ite: 13259] train loss: 0.065063, tar: 0.007334 
l0: 0.004218, l1: 0.003971, l2: 0.004676, l3: 0.005217, l4: 0.006594, l5: 0.006805, l6: 0.008060

[epoch: 142/100000, batch:    12/  187, ite: 13260] train loss: 0.065043, tar: 0.007331 
l0: 0.006060, l1: 0.006103, l2: 0.006581, l3: 0.007281, l4: 0.010486, l5: 0.010605, l6: 0.012320

[epoch: 142/100000, batch:    14/  187, ite: 13261] train loss: 0.065038, tar: 0.007330 
l0: 0.005085, l1: 0.005070, l2: 0.005687, l3: 0.005470, l4: 0.006574, l5: 0.007181, l6: 0.007127

[epoch: 142/100000, batch:    16/  187, ite: 13262] train loss: 0.065020, tar: 0.007329 
l0: 0.004861, l1: 0.004981, l2: 0.004928, l3: 0.004816, l4: 0.006355, l5: 0.005510, l6: 0.006110

[epoch: 142/100000, batch:    18/  187, ite: 13263] train loss: 0.064998, tar: 0.007327 
l0: 0.011033, l1: 0.010737, l2: 0.009719, l3: 0.010797, l4: 0.012502, l5: 0.013250, l6: 0.014853

[epoch: 142/100000, batch:    20/  187, ite: 13264] train loss: 0.065013, tar: 0.007330 
l0: 0.006119, l1: 0.006434, l2: 0.006169, l3: 0.006357, l4: 0.007060, l5: 0.006460, l6: 0.010156

[epoch: 142/100000, batch:    22/  187, ite: 13265] train loss: 0.065000, tar: 0.007329 
l0: 0.006810, l1: 0.007119, l2: 0.006755, l3: 0.006636, l4: 0.010649, l5: 0.010726, l6: 0.012252

[epoch: 142/100000, batch:    24/  187, ite: 13266] train loss: 0.064997, tar: 0.007328 
l0: 0.008918, l1: 0.008709, l2: 0.009579, l3: 0.009182, l4: 0.013060, l5: 0.013596, l6: 0.012669

[epoch: 142/100000, batch:    26/  187, ite: 13267] train loss: 0.065005, tar: 0.007330 
l0: 0.008209, l1: 0.008251, l2: 0.008318, l3: 0.008028, l4: 0.012194, l5: 0.011467, l6: 0.013783

[epoch: 142/100000, batch:    28/  187, ite: 13268] train loss: 0.065009, tar: 0.007330 
l0: 0.005976, l1: 0.006323, l2: 0.005728, l3: 0.005533, l4: 0.011175, l5: 0.008255, l6: 0.009727

[epoch: 142/100000, batch:    30/  187, ite: 13269] train loss: 0.064999, tar: 0.007329 
l0: 0.010157, l1: 0.009617, l2: 0.008944, l3: 0.009686, l4: 0.015452, l5: 0.016090, l6: 0.016867

[epoch: 142/100000, batch:    32/  187, ite: 13270] train loss: 0.065017, tar: 0.007331 
l0: 0.006936, l1: 0.007035, l2: 0.007560, l3: 0.008199, l4: 0.010882, l5: 0.010942, l6: 0.013007

[epoch: 142/100000, batch:    34/  187, ite: 13271] train loss: 0.065016, tar: 0.007331 
l0: 0.007662, l1: 0.007754, l2: 0.008920, l3: 0.008298, l4: 0.009394, l5: 0.010139, l6: 0.010035

[epoch: 142/100000, batch:    36/  187, ite: 13272] train loss: 0.065014, tar: 0.007331 
l0: 0.004899, l1: 0.005120, l2: 0.005302, l3: 0.005437, l4: 0.009140, l5: 0.008650, l6: 0.009773

[epoch: 142/100000, batch:    38/  187, ite: 13273] train loss: 0.065001, tar: 0.007329 
l0: 0.003258, l1: 0.003534, l2: 0.003539, l3: 0.003697, l4: 0.005531, l5: 0.005525, l6: 0.006552

[epoch: 142/100000, batch:    40/  187, ite: 13274] train loss: 0.064975, tar: 0.007326 
l0: 0.006204, l1: 0.006568, l2: 0.006844, l3: 0.006864, l4: 0.009426, l5: 0.008540, l6: 0.008750

[epoch: 142/100000, batch:    42/  187, ite: 13275] train loss: 0.064965, tar: 0.007325 
l0: 0.003733, l1: 0.003650, l2: 0.003575, l3: 0.003554, l4: 0.007750, l5: 0.007947, l6: 0.009023

[epoch: 142/100000, batch:    44/  187, ite: 13276] train loss: 0.064945, tar: 0.007323 
l0: 0.007256, l1: 0.007745, l2: 0.007434, l3: 0.007388, l4: 0.014781, l5: 0.012573, l6: 0.012438

[epoch: 142/100000, batch:    46/  187, ite: 13277] train loss: 0.064949, tar: 0.007323 
l0: 0.006544, l1: 0.006013, l2: 0.006996, l3: 0.007841, l4: 0.012807, l5: 0.013241, l6: 0.012795

[epoch: 142/100000, batch:    48/  187, ite: 13278] train loss: 0.064950, tar: 0.007322 
l0: 0.008559, l1: 0.009839, l2: 0.007256, l3: 0.006697, l4: 0.010778, l5: 0.010867, l6: 0.013369

[epoch: 142/100000, batch:    50/  187, ite: 13279] train loss: 0.064952, tar: 0.007323 
l0: 0.003680, l1: 0.003664, l2: 0.003907, l3: 0.003808, l4: 0.007146, l5: 0.006821, l6: 0.007790

[epoch: 142/100000, batch:    52/  187, ite: 13280] train loss: 0.064930, tar: 0.007320 
l0: 0.005632, l1: 0.005515, l2: 0.005683, l3: 0.005415, l4: 0.011471, l5: 0.010970, l6: 0.012598

[epoch: 142/100000, batch:    54/  187, ite: 13281] train loss: 0.064924, tar: 0.007319 
l0: 0.007185, l1: 0.007991, l2: 0.007427, l3: 0.006998, l4: 0.010271, l5: 0.009286, l6: 0.009000

[epoch: 142/100000, batch:    56/  187, ite: 13282] train loss: 0.064919, tar: 0.007319 
l0: 0.007013, l1: 0.006967, l2: 0.006087, l3: 0.006580, l4: 0.012407, l5: 0.012924, l6: 0.010843

[epoch: 142/100000, batch:    58/  187, ite: 13283] train loss: 0.064917, tar: 0.007318 
l0: 0.005520, l1: 0.005637, l2: 0.005455, l3: 0.006344, l4: 0.009707, l5: 0.007669, l6: 0.008799

[epoch: 142/100000, batch:    60/  187, ite: 13284] train loss: 0.064905, tar: 0.007317 
l0: 0.007287, l1: 0.007335, l2: 0.007720, l3: 0.007631, l4: 0.011145, l5: 0.011267, l6: 0.011862

[epoch: 142/100000, batch:    62/  187, ite: 13285] train loss: 0.064904, tar: 0.007317 
l0: 0.004381, l1: 0.005662, l2: 0.005448, l3: 0.004314, l4: 0.005317, l5: 0.004675, l6: 0.005361

[epoch: 142/100000, batch:    64/  187, ite: 13286] train loss: 0.064881, tar: 0.007315 
l0: 0.004761, l1: 0.005100, l2: 0.005975, l3: 0.005657, l4: 0.008280, l5: 0.006775, l6: 0.007883

[epoch: 142/100000, batch:    66/  187, ite: 13287] train loss: 0.064865, tar: 0.007313 
l0: 0.002544, l1: 0.003326, l2: 0.003135, l3: 0.002826, l4: 0.002882, l5: 0.002579, l6: 0.004567

[epoch: 142/100000, batch:    68/  187, ite: 13288] train loss: 0.064832, tar: 0.007309 
l0: 0.003400, l1: 0.003391, l2: 0.003980, l3: 0.004233, l4: 0.005160, l5: 0.005009, l6: 0.006328

[epoch: 142/100000, batch:    70/  187, ite: 13289] train loss: 0.064806, tar: 0.007306 
l0: 0.001994, l1: 0.002181, l2: 0.002132, l3: 0.002305, l4: 0.003747, l5: 0.003092, l6: 0.003236

[epoch: 142/100000, batch:    72/  187, ite: 13290] train loss: 0.064770, tar: 0.007302 
l0: 0.005730, l1: 0.005702, l2: 0.004610, l3: 0.004394, l4: 0.008036, l5: 0.009411, l6: 0.010222

[epoch: 142/100000, batch:    74/  187, ite: 13291] train loss: 0.064757, tar: 0.007301 
l0: 0.005126, l1: 0.004713, l2: 0.005152, l3: 0.005809, l4: 0.008363, l5: 0.009429, l6: 0.008206

[epoch: 142/100000, batch:    76/  187, ite: 13292] train loss: 0.064743, tar: 0.007299 
l0: 0.005966, l1: 0.005775, l2: 0.005755, l3: 0.006394, l4: 0.011464, l5: 0.011977, l6: 0.009226

[epoch: 142/100000, batch:    78/  187, ite: 13293] train loss: 0.064737, tar: 0.007298 
l0: 0.008850, l1: 0.008568, l2: 0.010136, l3: 0.012488, l4: 0.017751, l5: 0.015867, l6: 0.011928

[epoch: 142/100000, batch:    80/  187, ite: 13294] train loss: 0.064753, tar: 0.007299 
l0: 0.004335, l1: 0.004342, l2: 0.005381, l3: 0.005691, l4: 0.006893, l5: 0.007454, l6: 0.008569

[epoch: 142/100000, batch:    82/  187, ite: 13295] train loss: 0.064736, tar: 0.007297 
l0: 0.005481, l1: 0.005308, l2: 0.005860, l3: 0.006006, l4: 0.010620, l5: 0.009500, l6: 0.010286

[epoch: 142/100000, batch:    84/  187, ite: 13296] train loss: 0.064727, tar: 0.007295 
l0: 0.008927, l1: 0.008936, l2: 0.009880, l3: 0.009985, l4: 0.014751, l5: 0.013915, l6: 0.016679

[epoch: 142/100000, batch:    86/  187, ite: 13297] train loss: 0.064741, tar: 0.007297 
l0: 0.001725, l1: 0.001837, l2: 0.002284, l3: 0.001786, l4: 0.004686, l5: 0.003360, l6: 0.002596

[epoch: 142/100000, batch:    88/  187, ite: 13298] train loss: 0.064705, tar: 0.007292 
l0: 0.002085, l1: 0.002036, l2: 0.002008, l3: 0.002170, l4: 0.005393, l5: 0.004529, l6: 0.005056

[epoch: 142/100000, batch:    90/  187, ite: 13299] train loss: 0.064674, tar: 0.007288 
l0: 0.011793, l1: 0.011526, l2: 0.012941, l3: 0.013541, l4: 0.017007, l5: 0.016466, l6: 0.016292

[epoch: 142/100000, batch:    92/  187, ite: 13300] train loss: 0.064700, tar: 0.007292 
l0: 0.006105, l1: 0.006796, l2: 0.006866, l3: 0.007168, l4: 0.008289, l5: 0.007974, l6: 0.009117

[epoch: 142/100000, batch:    94/  187, ite: 13301] train loss: 0.064691, tar: 0.007291 
l0: 0.004991, l1: 0.004702, l2: 0.005712, l3: 0.005663, l4: 0.008648, l5: 0.008431, l6: 0.008700

[epoch: 142/100000, batch:    96/  187, ite: 13302] train loss: 0.064677, tar: 0.007289 
l0: 0.006809, l1: 0.006893, l2: 0.006622, l3: 0.006745, l4: 0.008402, l5: 0.007563, l6: 0.010255

[epoch: 142/100000, batch:    98/  187, ite: 13303] train loss: 0.064668, tar: 0.007289 
l0: 0.009458, l1: 0.009972, l2: 0.009323, l3: 0.010356, l4: 0.010594, l5: 0.010041, l6: 0.011640

[epoch: 142/100000, batch:   100/  187, ite: 13304] train loss: 0.064674, tar: 0.007290 
l0: 0.001788, l1: 0.001958, l2: 0.002042, l3: 0.002335, l4: 0.004459, l5: 0.003232, l6: 0.003716

[epoch: 142/100000, batch:   102/  187, ite: 13305] train loss: 0.064639, tar: 0.007286 
l0: 0.002085, l1: 0.002836, l2: 0.002028, l3: 0.003952, l4: 0.007268, l5: 0.006976, l6: 0.009601

[epoch: 142/100000, batch:   104/  187, ite: 13306] train loss: 0.064616, tar: 0.007282 
l0: 0.005672, l1: 0.005307, l2: 0.005822, l3: 0.006287, l4: 0.009322, l5: 0.009080, l6: 0.012205

[epoch: 142/100000, batch:   106/  187, ite: 13307] train loss: 0.064608, tar: 0.007281 
l0: 0.006890, l1: 0.007145, l2: 0.007041, l3: 0.007144, l4: 0.013796, l5: 0.011789, l6: 0.012103

[epoch: 142/100000, batch:   108/  187, ite: 13308] train loss: 0.064609, tar: 0.007281 
l0: 0.003472, l1: 0.003536, l2: 0.003636, l3: 0.003772, l4: 0.008080, l5: 0.007589, l6: 0.007917

[epoch: 142/100000, batch:   110/  187, ite: 13309] train loss: 0.064588, tar: 0.007278 
l0: 0.006320, l1: 0.006277, l2: 0.006298, l3: 0.005971, l4: 0.009669, l5: 0.011388, l6: 0.012500

[epoch: 142/100000, batch:   112/  187, ite: 13310] train loss: 0.064584, tar: 0.007277 
l0: 0.006230, l1: 0.006567, l2: 0.006240, l3: 0.006529, l4: 0.008909, l5: 0.007324, l6: 0.006776

[epoch: 142/100000, batch:   114/  187, ite: 13311] train loss: 0.064571, tar: 0.007276 
l0: 0.001903, l1: 0.002009, l2: 0.001928, l3: 0.002041, l4: 0.003425, l5: 0.003233, l6: 0.004085

[epoch: 142/100000, batch:   116/  187, ite: 13312] train loss: 0.064536, tar: 0.007272 
l0: 0.006232, l1: 0.005638, l2: 0.006732, l3: 0.007556, l4: 0.016099, l5: 0.016779, l6: 0.012341

[epoch: 142/100000, batch:   118/  187, ite: 13313] train loss: 0.064542, tar: 0.007271 
l0: 0.003307, l1: 0.004017, l2: 0.003351, l3: 0.002867, l4: 0.006742, l5: 0.006276, l6: 0.009568

[epoch: 142/100000, batch:   120/  187, ite: 13314] train loss: 0.064520, tar: 0.007268 
l0: 0.005911, l1: 0.005783, l2: 0.007051, l3: 0.006678, l4: 0.008311, l5: 0.009306, l6: 0.013153

[epoch: 142/100000, batch:   122/  187, ite: 13315] train loss: 0.064514, tar: 0.007267 
l0: 0.002793, l1: 0.002761, l2: 0.003101, l3: 0.003099, l4: 0.004690, l5: 0.004833, l6: 0.005894

[epoch: 142/100000, batch:   124/  187, ite: 13316] train loss: 0.064485, tar: 0.007264 
l0: 0.006973, l1: 0.008713, l2: 0.007793, l3: 0.005138, l4: 0.013491, l5: 0.011412, l6: 0.006900

[epoch: 142/100000, batch:   126/  187, ite: 13317] train loss: 0.064482, tar: 0.007264 
l0: 0.005543, l1: 0.005692, l2: 0.006182, l3: 0.006685, l4: 0.006544, l5: 0.006168, l6: 0.006830

[epoch: 142/100000, batch:   128/  187, ite: 13318] train loss: 0.064466, tar: 0.007262 
l0: 0.006748, l1: 0.006368, l2: 0.006056, l3: 0.008716, l4: 0.011609, l5: 0.010652, l6: 0.013715

[epoch: 142/100000, batch:   130/  187, ite: 13319] train loss: 0.064466, tar: 0.007262 
l0: 0.003337, l1: 0.003329, l2: 0.003625, l3: 0.003933, l4: 0.008866, l5: 0.005981, l6: 0.008430

[epoch: 142/100000, batch:   132/  187, ite: 13320] train loss: 0.064446, tar: 0.007259 
l0: 0.007326, l1: 0.007374, l2: 0.006676, l3: 0.007015, l4: 0.012607, l5: 0.011349, l6: 0.015127

[epoch: 142/100000, batch:   134/  187, ite: 13321] train loss: 0.064448, tar: 0.007259 
l0: 0.005841, l1: 0.006254, l2: 0.006119, l3: 0.005837, l4: 0.009714, l5: 0.008354, l6: 0.009822

[epoch: 142/100000, batch:   136/  187, ite: 13322] train loss: 0.064438, tar: 0.007258 
l0: 0.004426, l1: 0.004708, l2: 0.004768, l3: 0.004709, l4: 0.007427, l5: 0.007510, l6: 0.006570

[epoch: 142/100000, batch:   138/  187, ite: 13323] train loss: 0.064420, tar: 0.007256 
l0: 0.007389, l1: 0.007467, l2: 0.008381, l3: 0.008068, l4: 0.013727, l5: 0.012510, l6: 0.014142

[epoch: 142/100000, batch:   140/  187, ite: 13324] train loss: 0.064425, tar: 0.007256 
l0: 0.006472, l1: 0.006940, l2: 0.007264, l3: 0.007484, l4: 0.010511, l5: 0.009665, l6: 0.010140

[epoch: 142/100000, batch:   142/  187, ite: 13325] train loss: 0.064421, tar: 0.007255 
l0: 0.007347, l1: 0.007256, l2: 0.007959, l3: 0.009190, l4: 0.014848, l5: 0.012688, l6: 0.013662

[epoch: 142/100000, batch:   144/  187, ite: 13326] train loss: 0.064427, tar: 0.007255 
l0: 0.006172, l1: 0.005991, l2: 0.006961, l3: 0.008007, l4: 0.008668, l5: 0.010050, l6: 0.010496

[epoch: 142/100000, batch:   146/  187, ite: 13327] train loss: 0.064421, tar: 0.007255 
l0: 0.005769, l1: 0.005719, l2: 0.005939, l3: 0.006690, l4: 0.009715, l5: 0.009589, l6: 0.009863

[epoch: 142/100000, batch:   148/  187, ite: 13328] train loss: 0.064413, tar: 0.007254 
l0: 0.008719, l1: 0.009577, l2: 0.010792, l3: 0.009012, l4: 0.014090, l5: 0.012572, l6: 0.014666

[epoch: 142/100000, batch:   150/  187, ite: 13329] train loss: 0.064424, tar: 0.007255 
l0: 0.004362, l1: 0.005075, l2: 0.004852, l3: 0.005008, l4: 0.006171, l5: 0.006361, l6: 0.006486

[epoch: 142/100000, batch:   152/  187, ite: 13330] train loss: 0.064405, tar: 0.007252 
l0: 0.003464, l1: 0.003464, l2: 0.003482, l3: 0.003797, l4: 0.005604, l5: 0.005134, l6: 0.007843

[epoch: 142/100000, batch:   154/  187, ite: 13331] train loss: 0.064381, tar: 0.007250 
l0: 0.008409, l1: 0.007725, l2: 0.006584, l3: 0.007269, l4: 0.012492, l5: 0.012604, l6: 0.015833

[epoch: 142/100000, batch:   156/  187, ite: 13332] train loss: 0.064386, tar: 0.007250 
l0: 0.008836, l1: 0.010020, l2: 0.009750, l3: 0.010277, l4: 0.008528, l5: 0.007506, l6: 0.007175

[epoch: 142/100000, batch:   158/  187, ite: 13333] train loss: 0.064384, tar: 0.007252 
l0: 0.004620, l1: 0.003782, l2: 0.004640, l3: 0.005244, l4: 0.007037, l5: 0.008947, l6: 0.009506

[epoch: 142/100000, batch:   160/  187, ite: 13334] train loss: 0.064369, tar: 0.007250 
l0: 0.004764, l1: 0.004515, l2: 0.005243, l3: 0.005336, l4: 0.009509, l5: 0.007758, l6: 0.006984

[epoch: 142/100000, batch:   162/  187, ite: 13335] train loss: 0.064353, tar: 0.007248 
l0: 0.003476, l1: 0.003735, l2: 0.003937, l3: 0.003895, l4: 0.004971, l5: 0.004088, l6: 0.006146

[epoch: 142/100000, batch:   164/  187, ite: 13336] train loss: 0.064328, tar: 0.007245 
l0: 0.008985, l1: 0.009543, l2: 0.009717, l3: 0.008672, l4: 0.015444, l5: 0.013805, l6: 0.011661

[epoch: 142/100000, batch:   166/  187, ite: 13337] train loss: 0.064338, tar: 0.007246 
l0: 0.005944, l1: 0.006055, l2: 0.006673, l3: 0.007169, l4: 0.012887, l5: 0.011558, l6: 0.011757

[epoch: 142/100000, batch:   168/  187, ite: 13338] train loss: 0.064336, tar: 0.007245 
l0: 0.008557, l1: 0.007899, l2: 0.009785, l3: 0.010151, l4: 0.011362, l5: 0.011691, l6: 0.009846

[epoch: 142/100000, batch:   170/  187, ite: 13339] train loss: 0.064340, tar: 0.007246 
l0: 0.002215, l1: 0.002591, l2: 0.002621, l3: 0.002196, l4: 0.004117, l5: 0.002993, l6: 0.003285

[epoch: 142/100000, batch:   172/  187, ite: 13340] train loss: 0.064307, tar: 0.007243 
l0: 0.006225, l1: 0.006191, l2: 0.005980, l3: 0.005302, l4: 0.013825, l5: 0.013091, l6: 0.011433

[epoch: 142/100000, batch:   174/  187, ite: 13341] train loss: 0.064305, tar: 0.007242 
l0: 0.004958, l1: 0.004746, l2: 0.004748, l3: 0.004742, l4: 0.006700, l5: 0.007828, l6: 0.011190

[epoch: 142/100000, batch:   176/  187, ite: 13342] train loss: 0.064291, tar: 0.007240 